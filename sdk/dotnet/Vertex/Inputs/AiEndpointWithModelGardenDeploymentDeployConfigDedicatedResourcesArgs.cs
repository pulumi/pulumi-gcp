// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Gcp.Vertex.Inputs
{

    public sealed class AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs : global::Pulumi.ResourceArgs
    {
        [Input("autoscalingMetricSpecs")]
        private InputList<Inputs.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArgs>? _autoscalingMetricSpecs;

        /// <summary>
        /// The metric specifications that overrides a resource
        /// utilization metric (CPU utilization, accelerator's duty cycle, and so on)
        /// target value (default to 60 if not set). At most one entry is allowed per
        /// metric.
        /// If machine_spec.accelerator_count is
        /// above 0, the autoscaling will be based on both CPU utilization and
        /// accelerator's duty cycle metrics and scale up when either metrics exceeds
        /// its target value while scale down if both metrics are under their target
        /// value. The default target value is 60 for both metrics.
        /// If machine_spec.accelerator_count is
        /// 0, the autoscaling will be based on CPU utilization metric only with
        /// default target value 60 if not explicitly set.
        /// For example, in the case of Online Prediction, if you want to override
        /// target CPU utilization to 80, you should set
        /// autoscaling_metric_specs.metric_name
        /// to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and
        /// autoscaling_metric_specs.target to `80`.
        /// Structure is documented below.
        /// </summary>
        public InputList<Inputs.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArgs> AutoscalingMetricSpecs
        {
            get => _autoscalingMetricSpecs ?? (_autoscalingMetricSpecs = new InputList<Inputs.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArgs>());
            set => _autoscalingMetricSpecs = value;
        }

        /// <summary>
        /// Specification of a single machine.
        /// Structure is documented below.
        /// </summary>
        [Input("machineSpec", required: true)]
        public Input<Inputs.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs> MachineSpec { get; set; } = null!;

        /// <summary>
        /// The maximum number of replicas that may be deployed on when the traffic
        /// against it increases. If the requested value is too large, the deployment
        /// will error, but if deployment succeeds then the ability to scale to that
        /// many replicas is guaranteed (barring service outages). If traffic increases
        /// beyond what its replicas at maximum may handle, a portion of the traffic
        /// will be dropped. If this value is not provided, will use
        /// min_replica_count as the default value.
        /// The value of this field impacts the charge against Vertex CPU and GPU
        /// quotas. Specifically, you will be charged for (max_replica_count *
        /// number of cores in the selected machine type) and (max_replica_count *
        /// number of GPUs per replica in the selected machine type).
        /// </summary>
        [Input("maxReplicaCount")]
        public Input<int>? MaxReplicaCount { get; set; }

        /// <summary>
        /// The minimum number of machine replicas that will be always deployed on.
        /// This value must be greater than or equal to 1.
        /// If traffic increases, it may dynamically be deployed onto more replicas,
        /// and as traffic decreases, some of these extra replicas may be freed.
        /// </summary>
        [Input("minReplicaCount", required: true)]
        public Input<int> MinReplicaCount { get; set; } = null!;

        /// <summary>
        /// Number of required available replicas for the deployment to succeed.
        /// This field is only needed when partial deployment/mutation is
        /// desired. If set, the deploy/mutate operation will succeed once
        /// available_replica_count reaches required_replica_count, and the rest of
        /// the replicas will be retried. If not set, the default
        /// required_replica_count will be min_replica_count.
        /// </summary>
        [Input("requiredReplicaCount")]
        public Input<int>? RequiredReplicaCount { get; set; }

        /// <summary>
        /// If true, schedule the deployment workload on [spot
        /// VMs](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms).
        /// </summary>
        [Input("spot")]
        public Input<bool>? Spot { get; set; }

        public AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs()
        {
        }
        public static new AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs Empty => new AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs();
    }
}
