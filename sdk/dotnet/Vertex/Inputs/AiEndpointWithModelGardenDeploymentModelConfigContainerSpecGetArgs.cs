// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Gcp.Vertex.Inputs
{

    public sealed class AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGetArgs : global::Pulumi.ResourceArgs
    {
        [Input("args")]
        private InputList<string>? _args;

        /// <summary>
        /// Specifies arguments for the command that runs when the container starts.
        /// This overrides the container's
        /// [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify
        /// this field as an array of executable and arguments, similar to a Docker
        /// `CMD`'s "default parameters" form.
        /// If you don't specify this field but do specify the
        /// command field, then the command from the
        /// `Command` field runs without any additional arguments. See the
        /// [Kubernetes documentation about how the
        /// `Command` and `Args` fields interact with a container's `ENTRYPOINT` and
        /// `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
        /// If you don't specify this field and don't specify the `Command` field,
        /// then the container's
        /// [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and
        /// `CMD` determine what runs based on their default behavior. See the Docker
        /// documentation about [how `CMD` and `ENTRYPOINT`
        /// interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
        /// In this field, you can reference [environment variables
        /// set by Vertex
        /// AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
        /// and environment variables set in the env field.
        /// You cannot reference environment variables set in the Docker image. In
        /// order for environment variables to be expanded, reference them by using the
        /// following syntax:$(VARIABLE_NAME)
        /// Note that this differs from Bash variable expansion, which does not use
        /// parentheses. If a variable cannot be resolved, the reference in the input
        /// string is used unchanged. To avoid variable expansion, you can escape this
        /// syntax with `$$`; for example:$$(VARIABLE_NAME)
        /// This field corresponds to the `Args` field of the Kubernetes Containers
        /// [v1 core
        /// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
        /// </summary>
        public InputList<string> Args
        {
            get => _args ?? (_args = new InputList<string>());
            set => _args = value;
        }

        [Input("commands")]
        private InputList<string>? _commands;

        /// <summary>
        /// Specifies the command that runs when the container starts. This overrides
        /// the container's
        /// [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint).
        /// Specify this field as an array of executable and arguments, similar to a
        /// Docker `ENTRYPOINT`'s "exec" form, not its "shell" form.
        /// If you do not specify this field, then the container's `ENTRYPOINT` runs,
        /// in conjunction with the args field or the
        /// container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd),
        /// if either exists. If this field is not specified and the container does not
        /// have an `ENTRYPOINT`, then refer to the Docker documentation about [how
        /// `CMD` and `ENTRYPOINT`
        /// interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
        /// If you specify this field, then you can also specify the `Args` field to
        /// provide additional arguments for this command. However, if you specify this
        /// field, then the container's `CMD` is ignored. See the
        /// [Kubernetes documentation about how the
        /// `Command` and `Args` fields interact with a container's `ENTRYPOINT` and
        /// `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
        /// In this field, you can reference [environment variables set by Vertex
        /// AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
        /// and environment variables set in the env field.
        /// You cannot reference environment variables set in the Docker image. In
        /// order for environment variables to be expanded, reference them by using the
        /// following syntax:$(VARIABLE_NAME)
        /// Note that this differs from Bash variable expansion, which does not use
        /// parentheses. If a variable cannot be resolved, the reference in the input
        /// string is used unchanged. To avoid variable expansion, you can escape this
        /// syntax with `$$`; for example:$$(VARIABLE_NAME)
        /// This field corresponds to the `Command` field of the Kubernetes Containers
        /// [v1 core
        /// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
        /// </summary>
        public InputList<string> Commands
        {
            get => _commands ?? (_commands = new InputList<string>());
            set => _commands = value;
        }

        /// <summary>
        /// Deployment timeout.
        /// Limit for deployment timeout is 2 hours.
        /// </summary>
        [Input("deploymentTimeout")]
        public Input<string>? DeploymentTimeout { get; set; }

        [Input("envs")]
        private InputList<Inputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvGetArgs>? _envs;

        /// <summary>
        /// List of environment variables to set in the container. After the container
        /// starts running, code running in the container can read these environment
        /// variables.
        /// Additionally, the command and
        /// args fields can reference these variables. Later
        /// entries in this list can also reference earlier entries. For example, the
        /// following example sets the variable `VAR_2` to have the value `foo bar`:
        /// ```json
        /// [
        /// {
        /// "name": "VAR_1",
        /// "value": "foo"
        /// },
        /// {
        /// "name": "VAR_2",
        /// "value": "$(VAR_1) bar"
        /// }
        /// ]
        /// ```
        /// If you switch the order of the variables in the example, then the expansion
        /// does not occur.
        /// This field corresponds to the `Env` field of the Kubernetes Containers
        /// [v1 core
        /// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
        /// Structure is documented below.
        /// </summary>
        public InputList<Inputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvGetArgs> Envs
        {
            get => _envs ?? (_envs = new InputList<Inputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvGetArgs>());
            set => _envs = value;
        }

        [Input("grpcPorts")]
        private InputList<Inputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortGetArgs>? _grpcPorts;

        /// <summary>
        /// List of ports to expose from the container. Vertex AI sends gRPC
        /// prediction requests that it receives to the first port on this list. Vertex
        /// AI also sends liveness and health checks to this port.
        /// If you do not specify this field, gRPC requests to the container will be
        /// disabled.
        /// Vertex AI does not use ports other than the first one listed. This field
        /// corresponds to the `Ports` field of the Kubernetes Containers v1 core API.
        /// Structure is documented below.
        /// </summary>
        public InputList<Inputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortGetArgs> GrpcPorts
        {
            get => _grpcPorts ?? (_grpcPorts = new InputList<Inputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortGetArgs>());
            set => _grpcPorts = value;
        }

        /// <summary>
        /// Probe describes a health check to be performed against a container to
        /// determine whether it is alive or ready to receive traffic.
        /// Structure is documented below.
        /// </summary>
        [Input("healthProbe")]
        public Input<Inputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGetArgs>? HealthProbe { get; set; }

        /// <summary>
        /// HTTP path on the container to send health checks to. Vertex AI
        /// intermittently sends GET requests to this path on the container's IP
        /// address and port to check that the container is healthy. Read more about
        /// [health
        /// checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health).
        /// For example, if you set this field to `/bar`, then Vertex AI
        /// intermittently sends a GET request to the `/bar` path on the port of your
        /// container specified by the first value of this `ModelContainerSpec`'s
        /// ports field.
        /// If you don't specify this field, it defaults to the following value when
        /// you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
        /// The placeholders in this value are replaced as follows:
        /// * ENDPOINT: The last segment (following `endpoints/`)of the
        /// Endpoint.name][] field of the Endpoint where this Model has been
        /// deployed. (Vertex AI makes this value available to your container code
        /// as the [`AIP_ENDPOINT_ID` environment
        /// variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
        /// * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
        /// (Vertex AI makes this value available to your container code as the
        /// [`AIP_DEPLOYED_MODEL_ID` environment
        /// variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
        /// </summary>
        [Input("healthRoute")]
        public Input<string>? HealthRoute { get; set; }

        /// <summary>
        /// URI of the Docker image to be used as the custom container for serving
        /// predictions. This URI must identify an image in Artifact Registry or
        /// Container Registry. Learn more about the [container publishing
        /// requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing),
        /// including permissions requirements for the Vertex AI Service Agent.
        /// The container image is ingested upon ModelService.UploadModel, stored
        /// internally, and this original path is afterwards not used.
        /// To learn about the requirements for the Docker image itself, see
        /// [Custom container
        /// requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#).
        /// You can use the URI to one of Vertex AI's [pre-built container images for
        /// prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)
        /// in this field.
        /// </summary>
        [Input("imageUri", required: true)]
        public Input<string> ImageUri { get; set; } = null!;

        /// <summary>
        /// Probe describes a health check to be performed against a container to
        /// determine whether it is alive or ready to receive traffic.
        /// Structure is documented below.
        /// </summary>
        [Input("livenessProbe")]
        public Input<Inputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGetArgs>? LivenessProbe { get; set; }

        [Input("ports")]
        private InputList<Inputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortGetArgs>? _ports;

        /// <summary>
        /// List of ports to expose from the container. Vertex AI sends any
        /// prediction requests that it receives to the first port on this list. Vertex
        /// AI also sends
        /// [liveness and health
        /// checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness)
        /// to this port.
        /// If you do not specify this field, it defaults to following value:
        /// ```json
        /// [
        /// {
        /// "containerPort": 8080
        /// }
        /// ]
        /// ```
        /// Vertex AI does not use ports other than the first one listed. This field
        /// corresponds to the `Ports` field of the Kubernetes Containers
        /// [v1 core
        /// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
        /// Structure is documented below.
        /// </summary>
        public InputList<Inputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortGetArgs> Ports
        {
            get => _ports ?? (_ports = new InputList<Inputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortGetArgs>());
            set => _ports = value;
        }

        /// <summary>
        /// HTTP path on the container to send prediction requests to. Vertex AI
        /// forwards requests sent using
        /// projects.locations.endpoints.predict to this
        /// path on the container's IP address and port. Vertex AI then returns the
        /// container's response in the API response.
        /// For example, if you set this field to `/foo`, then when Vertex AI
        /// receives a prediction request, it forwards the request body in a POST
        /// request to the `/foo` path on the port of your container specified by the
        /// first value of this `ModelContainerSpec`'s
        /// ports field.
        /// If you don't specify this field, it defaults to the following value when
        /// you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
        /// The placeholders in this value are replaced as follows:
        /// * ENDPOINT: The last segment (following `endpoints/`)of the
        /// Endpoint.name][] field of the Endpoint where this Model has been
        /// deployed. (Vertex AI makes this value available to your container code
        /// as the [`AIP_ENDPOINT_ID` environment
        /// variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
        /// * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
        /// (Vertex AI makes this value available to your container code
        /// as the [`AIP_DEPLOYED_MODEL_ID` environment
        /// variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
        /// </summary>
        [Input("predictRoute")]
        public Input<string>? PredictRoute { get; set; }

        /// <summary>
        /// The amount of the VM memory to reserve as the shared memory for the model
        /// in megabytes.
        /// </summary>
        [Input("sharedMemorySizeMb")]
        public Input<string>? SharedMemorySizeMb { get; set; }

        /// <summary>
        /// Probe describes a health check to be performed against a container to
        /// determine whether it is alive or ready to receive traffic.
        /// Structure is documented below.
        /// </summary>
        [Input("startupProbe")]
        public Input<Inputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGetArgs>? StartupProbe { get; set; }

        public AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGetArgs()
        {
        }
        public static new AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGetArgs Empty => new AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGetArgs();
    }
}
