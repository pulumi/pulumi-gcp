// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Gcp.Vertex.Inputs
{

    public sealed class AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecGetArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// (Output)
        /// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
        /// </summary>
        [Input("metricName")]
        public Input<string>? MetricName { get; set; }

        /// <summary>
        /// (Output)
        /// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
        /// </summary>
        [Input("target")]
        public Input<int>? Target { get; set; }

        public AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecGetArgs()
        {
        }
        public static new AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecGetArgs Empty => new AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecGetArgs();
    }
}
