// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Gcp.Container.Inputs
{

    public sealed class ClusterNodePoolGetArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
        /// </summary>
        [Input("autoscaling")]
        public Input<Inputs.ClusterNodePoolAutoscalingGetArgs>? Autoscaling { get; set; }

        /// <summary>
        /// The number of nodes to create in this
        /// cluster's default node pool. In regional or multi-zonal clusters, this is the
        /// number of nodes per zone. Must be set if `NodePool` is not set. If you're using
        /// `gcp.container.NodePool` objects with no default node pool, you'll need to
        /// set this to a value of at least `1`, alongside setting
        /// `RemoveDefaultNodePool` to `True`.
        /// </summary>
        [Input("initialNodeCount")]
        public Input<int>? InitialNodeCount { get; set; }

        [Input("instanceGroupUrls")]
        private InputList<string>? _instanceGroupUrls;

        /// <summary>
        /// The resource URLs of the managed instance groups associated with this node pool.
        /// </summary>
        public InputList<string> InstanceGroupUrls
        {
            get => _instanceGroupUrls ?? (_instanceGroupUrls = new InputList<string>());
            set => _instanceGroupUrls = value;
        }

        [Input("managedInstanceGroupUrls")]
        private InputList<string>? _managedInstanceGroupUrls;

        /// <summary>
        /// List of instance group URLs which have been assigned to this node pool.
        /// </summary>
        public InputList<string> ManagedInstanceGroupUrls
        {
            get => _managedInstanceGroupUrls ?? (_managedInstanceGroupUrls = new InputList<string>());
            set => _managedInstanceGroupUrls = value;
        }

        /// <summary>
        /// Node management configuration, wherein auto-repair and auto-upgrade is configured.
        /// </summary>
        [Input("management")]
        public Input<Inputs.ClusterNodePoolManagementGetArgs>? Management { get; set; }

        /// <summary>
        /// The maximum number of pods per node in this node pool. Note that this does not work on node pools which are "route-based" - that is, node pools belonging to clusters that do not have IP Aliasing enabled.
        /// </summary>
        [Input("maxPodsPerNode")]
        public Input<int>? MaxPodsPerNode { get; set; }

        /// <summary>
        /// The name of the cluster, unique within the project and
        /// location.
        /// 
        /// - - -
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.
        /// </summary>
        [Input("namePrefix")]
        public Input<string>? NamePrefix { get; set; }

        /// <summary>
        /// Configuration for
        /// [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
        /// </summary>
        [Input("networkConfig")]
        public Input<Inputs.ClusterNodePoolNetworkConfigGetArgs>? NetworkConfig { get; set; }

        /// <summary>
        /// Parameters used in creating the default node pool.
        /// Generally, this field should not be used at the same time as a
        /// `gcp.container.NodePool` or a `NodePool` block; this configuration
        /// manages the default node pool, which isn't recommended to be used.
        /// Structure is documented below.
        /// </summary>
        [Input("nodeConfig")]
        public Input<Inputs.ClusterNodePoolNodeConfigGetArgs>? NodeConfig { get; set; }

        /// <summary>
        /// The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.
        /// </summary>
        [Input("nodeCount")]
        public Input<int>? NodeCount { get; set; }

        [Input("nodeLocations")]
        private InputList<string>? _nodeLocations;

        /// <summary>
        /// The list of zones in which the cluster's nodes
        /// are located. Nodes must be in the region of their regional cluster or in the
        /// same region as their cluster's zone for zonal clusters. If this is specified for
        /// a zonal cluster, omit the cluster's zone.
        /// 
        /// &gt; A "multi-zonal" cluster is a zonal cluster with at least one additional zone
        /// defined; in a multi-zonal cluster, the cluster master is only present in a
        /// single zone while nodes are present in each of the primary zone and the node
        /// locations. In contrast, in a regional cluster, cluster master nodes are present
        /// in multiple zones in the region. For that reason, regional clusters should be
        /// preferred.
        /// </summary>
        public InputList<string> NodeLocations
        {
            get => _nodeLocations ?? (_nodeLocations = new InputList<string>());
            set => _nodeLocations = value;
        }

        /// <summary>
        /// Specifies the node placement policy
        /// </summary>
        [Input("placementPolicy")]
        public Input<Inputs.ClusterNodePoolPlacementPolicyGetArgs>? PlacementPolicy { get; set; }

        /// <summary>
        /// Specifies the configuration of queued provisioning
        /// </summary>
        [Input("queuedProvisioning")]
        public Input<Inputs.ClusterNodePoolQueuedProvisioningGetArgs>? QueuedProvisioning { get; set; }

        /// <summary>
        /// Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of MaxSurge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.
        /// </summary>
        [Input("upgradeSettings")]
        public Input<Inputs.ClusterNodePoolUpgradeSettingsGetArgs>? UpgradeSettings { get; set; }

        [Input("version")]
        public Input<string>? Version { get; set; }

        public ClusterNodePoolGetArgs()
        {
        }
        public static new ClusterNodePoolGetArgs Empty => new ClusterNodePoolGetArgs();
    }
}
