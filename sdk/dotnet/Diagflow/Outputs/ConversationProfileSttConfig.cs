// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Gcp.Diagflow.Outputs
{

    [OutputType]
    public sealed class ConversationProfileSttConfig
    {
        /// <summary>
        /// Audio encoding of the audio content to process.
        /// Possible values are: `AUDIO_ENCODING_UNSPECIFIED`, `AUDIO_ENCODING_LINEAR_16`, `AUDIO_ENCODING_FLAC`, `AUDIO_ENCODING_MULAW`, `AUDIO_ENCODING_AMR`, `AUDIO_ENCODING_AMR_WB`, `AUDIO_ENCODING_OGG_OPUS`, `AUDIOENCODING_SPEEX_WITH_HEADER_BYTE`.
        /// </summary>
        public readonly string? AudioEncoding;
        /// <summary>
        /// If true, Dialogflow returns SpeechWordInfo in StreamingRecognitionResult with information about the recognized speech words.
        /// </summary>
        public readonly bool? EnableWordInfo;
        /// <summary>
        /// The language of the supplied audio.
        /// </summary>
        public readonly string? LanguageCode;
        /// <summary>
        /// Which Speech model to select.
        /// Leave this field unspecified to use Agent Speech settings for model selection.
        /// </summary>
        public readonly string? Model;
        /// <summary>
        /// Sample rate (in Hertz) of the audio content sent in the query.
        /// </summary>
        public readonly int? SampleRateHertz;
        /// <summary>
        /// The speech model used in speech to text.
        /// Possible values are: `SPEECH_MODEL_VARIANT_UNSPECIFIED`, `USE_BEST_AVAILABLE`, `USE_STANDARD`, `USE_ENHANCED`.
        /// </summary>
        public readonly string? SpeechModelVariant;
        /// <summary>
        /// Use timeout based endpointing, interpreting endpointer sensitivy as seconds of timeout value.
        /// </summary>
        public readonly bool? UseTimeoutBasedEndpointing;

        [OutputConstructor]
        private ConversationProfileSttConfig(
            string? audioEncoding,

            bool? enableWordInfo,

            string? languageCode,

            string? model,

            int? sampleRateHertz,

            string? speechModelVariant,

            bool? useTimeoutBasedEndpointing)
        {
            AudioEncoding = audioEncoding;
            EnableWordInfo = enableWordInfo;
            LanguageCode = languageCode;
            Model = model;
            SampleRateHertz = sampleRateHertz;
            SpeechModelVariant = speechModelVariant;
            UseTimeoutBasedEndpointing = useTimeoutBasedEndpointing;
        }
    }
}
