// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Gcp.DataPlex
{
    /// <summary>
    /// A Dataplex task represents the work that you want Dataplex to do on a schedule. It encapsulates code, parameters, and the schedule.
    /// 
    /// To get more information about Task, see:
    /// 
    /// * [API documentation](https://cloud.google.com/dataplex/docs/reference/rest/v1/projects.locations.lakes.tasks)
    /// * How-to Guides
    ///     * [Official Documentation](https://cloud.google.com/dataplex/docs)
    /// 
    /// ## Example Usage
    /// 
    /// ### Dataplex Task Basic
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Gcp = Pulumi.Gcp;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var project = Gcp.Organizations.GetProject.Invoke();
    /// 
    ///     var example = new Gcp.DataPlex.Lake("example", new()
    ///     {
    ///         Name = "tf-test-lake_75092",
    ///         Location = "us-central1",
    ///         Project = "my-project-name",
    ///     });
    /// 
    ///     var exampleTask = new Gcp.DataPlex.Task("example", new()
    ///     {
    ///         TaskId = "tf-test-task_2605",
    ///         Location = "us-central1",
    ///         Lake = example.Name,
    ///         Description = "Test Task Basic",
    ///         DisplayName = "task-basic",
    ///         Labels = 
    ///         {
    ///             { "count", "3" },
    ///         },
    ///         TriggerSpec = new Gcp.DataPlex.Inputs.TaskTriggerSpecArgs
    ///         {
    ///             Type = "RECURRING",
    ///             Disabled = false,
    ///             MaxRetries = 3,
    ///             StartTime = "2023-10-02T15:01:23Z",
    ///             Schedule = "1 * * * *",
    ///         },
    ///         ExecutionSpec = new Gcp.DataPlex.Inputs.TaskExecutionSpecArgs
    ///         {
    ///             ServiceAccount = $"{project.Apply(getProjectResult =&gt; getProjectResult.Number)}-compute@developer.gserviceaccount.com",
    ///             Project = "my-project-name",
    ///             MaxJobExecutionLifetime = "100s",
    ///             KmsKey = "234jn2kjn42k3n423",
    ///         },
    ///         Spark = new Gcp.DataPlex.Inputs.TaskSparkArgs
    ///         {
    ///             PythonScriptFile = "gs://dataproc-examples/pyspark/hello-world/hello-world.py",
    ///         },
    ///         Project = "my-project-name",
    ///     });
    /// 
    /// });
    /// ```
    /// ### Dataplex Task Spark
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Gcp = Pulumi.Gcp;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     // VPC network
    ///     var @default = new Gcp.Compute.Network("default", new()
    ///     {
    ///         Name = "tf-test-workstation-cluster_34535",
    ///         AutoCreateSubnetworks = true,
    ///     });
    /// 
    ///     var project = Gcp.Organizations.GetProject.Invoke();
    /// 
    ///     var exampleSpark = new Gcp.DataPlex.Lake("example_spark", new()
    ///     {
    ///         Name = "tf-test-lake_22375",
    ///         Location = "us-central1",
    ///         Project = "my-project-name",
    ///     });
    /// 
    ///     var exampleSparkTask = new Gcp.DataPlex.Task("example_spark", new()
    ///     {
    ///         TaskId = "tf-test-task_29439",
    ///         Location = "us-central1",
    ///         Lake = exampleSpark.Name,
    ///         TriggerSpec = new Gcp.DataPlex.Inputs.TaskTriggerSpecArgs
    ///         {
    ///             Type = "ON_DEMAND",
    ///         },
    ///         Description = "task-spark-terraform",
    ///         ExecutionSpec = new Gcp.DataPlex.Inputs.TaskExecutionSpecArgs
    ///         {
    ///             ServiceAccount = $"{project.Apply(getProjectResult =&gt; getProjectResult.Number)}-compute@developer.gserviceaccount.com",
    ///             Args = 
    ///             {
    ///                 { "TASK_ARGS", "--output_location,gs://spark-job/task-result, --output_format, json" },
    ///             },
    ///         },
    ///         Spark = new Gcp.DataPlex.Inputs.TaskSparkArgs
    ///         {
    ///             InfrastructureSpec = new Gcp.DataPlex.Inputs.TaskSparkInfrastructureSpecArgs
    ///             {
    ///                 Batch = new Gcp.DataPlex.Inputs.TaskSparkInfrastructureSpecBatchArgs
    ///                 {
    ///                     ExecutorsCount = 2,
    ///                     MaxExecutorsCount = 100,
    ///                 },
    ///                 ContainerImage = new Gcp.DataPlex.Inputs.TaskSparkInfrastructureSpecContainerImageArgs
    ///                 {
    ///                     Image = "test-image",
    ///                     JavaJars = new[]
    ///                     {
    ///                         "test-java-jars.jar",
    ///                     },
    ///                     PythonPackages = new[]
    ///                     {
    ///                         "gs://bucket-name/my/path/to/lib.tar.gz",
    ///                     },
    ///                     Properties = 
    ///                     {
    ///                         { "name", "wrench" },
    ///                         { "mass", "1.3kg" },
    ///                         { "count", "3" },
    ///                     },
    ///                 },
    ///                 VpcNetwork = new Gcp.DataPlex.Inputs.TaskSparkInfrastructureSpecVpcNetworkArgs
    ///                 {
    ///                     NetworkTags = new[]
    ///                     {
    ///                         "test-network-tag",
    ///                     },
    ///                     SubNetwork = @default.Id,
    ///                 },
    ///             },
    ///             FileUris = new[]
    ///             {
    ///                 "gs://terrafrom-test/test.csv",
    ///             },
    ///             ArchiveUris = new[]
    ///             {
    ///                 "gs://terraform-test/test.csv",
    ///             },
    ///             SqlScript = "show databases",
    ///         },
    ///         Project = "my-project-name",
    ///     });
    /// 
    /// });
    /// ```
    /// ### Dataplex Task Notebook
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Gcp = Pulumi.Gcp;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     // VPC network
    ///     var @default = new Gcp.Compute.Network("default", new()
    ///     {
    ///         Name = "tf-test-workstation-cluster_87786",
    ///         AutoCreateSubnetworks = true,
    ///     });
    /// 
    ///     var project = Gcp.Organizations.GetProject.Invoke();
    /// 
    ///     var exampleNotebook = new Gcp.DataPlex.Lake("example_notebook", new()
    ///     {
    ///         Name = "tf-test-lake_2067",
    ///         Location = "us-central1",
    ///         Project = "my-project-name",
    ///     });
    /// 
    ///     var exampleNotebookTask = new Gcp.DataPlex.Task("example_notebook", new()
    ///     {
    ///         TaskId = "tf-test-task_40785",
    ///         Location = "us-central1",
    ///         Lake = exampleNotebook.Name,
    ///         TriggerSpec = new Gcp.DataPlex.Inputs.TaskTriggerSpecArgs
    ///         {
    ///             Type = "RECURRING",
    ///             Schedule = "1 * * * *",
    ///         },
    ///         ExecutionSpec = new Gcp.DataPlex.Inputs.TaskExecutionSpecArgs
    ///         {
    ///             ServiceAccount = $"{project.Apply(getProjectResult =&gt; getProjectResult.Number)}-compute@developer.gserviceaccount.com",
    ///             Args = 
    ///             {
    ///                 { "TASK_ARGS", "--output_location,gs://spark-job-jars-anrajitha/task-result, --output_format, json" },
    ///             },
    ///         },
    ///         Notebook = new Gcp.DataPlex.Inputs.TaskNotebookArgs
    ///         {
    ///             Notebook = "gs://terraform-test/test-notebook.ipynb",
    ///             InfrastructureSpec = new Gcp.DataPlex.Inputs.TaskNotebookInfrastructureSpecArgs
    ///             {
    ///                 Batch = new Gcp.DataPlex.Inputs.TaskNotebookInfrastructureSpecBatchArgs
    ///                 {
    ///                     ExecutorsCount = 2,
    ///                     MaxExecutorsCount = 100,
    ///                 },
    ///                 ContainerImage = new Gcp.DataPlex.Inputs.TaskNotebookInfrastructureSpecContainerImageArgs
    ///                 {
    ///                     Image = "test-image",
    ///                     JavaJars = new[]
    ///                     {
    ///                         "test-java-jars.jar",
    ///                     },
    ///                     PythonPackages = new[]
    ///                     {
    ///                         "gs://bucket-name/my/path/to/lib.tar.gz",
    ///                     },
    ///                     Properties = 
    ///                     {
    ///                         { "name", "wrench" },
    ///                         { "mass", "1.3kg" },
    ///                         { "count", "3" },
    ///                     },
    ///                 },
    ///                 VpcNetwork = new Gcp.DataPlex.Inputs.TaskNotebookInfrastructureSpecVpcNetworkArgs
    ///                 {
    ///                     NetworkTags = new[]
    ///                     {
    ///                         "test-network-tag",
    ///                     },
    ///                     Network = @default.Id,
    ///                 },
    ///             },
    ///             FileUris = new[]
    ///             {
    ///                 "gs://terraform-test/test.csv",
    ///             },
    ///             ArchiveUris = new[]
    ///             {
    ///                 "gs://terraform-test/test.csv",
    ///             },
    ///         },
    ///         Project = "my-project-name",
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Import
    /// 
    /// Task can be imported using any of these accepted formats:
    /// 
    /// * `projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}`
    /// 
    /// * `{{project}}/{{location}}/{{lake}}/{{task_id}}`
    /// 
    /// * `{{location}}/{{lake}}/{{task_id}}`
    /// 
    /// When using the `pulumi import` command, Task can be imported using one of the formats above. For example:
    /// 
    /// ```sh
    /// $ pulumi import gcp:dataplex/task:Task default projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}
    /// ```
    /// 
    /// ```sh
    /// $ pulumi import gcp:dataplex/task:Task default {{project}}/{{location}}/{{lake}}/{{task_id}}
    /// ```
    /// 
    /// ```sh
    /// $ pulumi import gcp:dataplex/task:Task default {{location}}/{{lake}}/{{task_id}}
    /// ```
    /// </summary>
    [GcpResourceType("gcp:dataplex/task:Task")]
    public partial class Task : global::Pulumi.CustomResource
    {
        /// <summary>
        /// The time when the task was created.
        /// </summary>
        [Output("createTime")]
        public Output<string> CreateTime { get; private set; } = null!;

        /// <summary>
        /// User-provided description of the task.
        /// </summary>
        [Output("description")]
        public Output<string?> Description { get; private set; } = null!;

        /// <summary>
        /// User friendly display name.
        /// </summary>
        [Output("displayName")]
        public Output<string?> DisplayName { get; private set; } = null!;

        /// <summary>
        /// All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
        /// </summary>
        [Output("effectiveLabels")]
        public Output<ImmutableDictionary<string, string>> EffectiveLabels { get; private set; } = null!;

        /// <summary>
        /// Configuration for the cluster
        /// Structure is documented below.
        /// </summary>
        [Output("executionSpec")]
        public Output<Outputs.TaskExecutionSpec> ExecutionSpec { get; private set; } = null!;

        /// <summary>
        /// Configuration for the cluster
        /// Structure is documented below.
        /// </summary>
        [Output("executionStatuses")]
        public Output<ImmutableArray<Outputs.TaskExecutionStatus>> ExecutionStatuses { get; private set; } = null!;

        /// <summary>
        /// User-defined labels for the task.
        /// 
        /// **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
        /// Please refer to the field `effective_labels` for all of the labels present on the resource.
        /// </summary>
        [Output("labels")]
        public Output<ImmutableDictionary<string, string>?> Labels { get; private set; } = null!;

        /// <summary>
        /// The lake in which the task will be created in.
        /// </summary>
        [Output("lake")]
        public Output<string?> Lake { get; private set; } = null!;

        /// <summary>
        /// The location in which the task will be created in.
        /// </summary>
        [Output("location")]
        public Output<string?> Location { get; private set; } = null!;

        /// <summary>
        /// (Output)
        /// The relative resource name of the job, of the form: projects/{project_number}/locations/{locationId}/lakes/{lakeId}/tasks/{taskId}/jobs/{jobId}.
        /// </summary>
        [Output("name")]
        public Output<string> Name { get; private set; } = null!;

        /// <summary>
        /// A service with manual scaling runs continuously, allowing you to perform complex initialization and rely on the state of its memory over time.
        /// Structure is documented below.
        /// </summary>
        [Output("notebook")]
        public Output<Outputs.TaskNotebook?> Notebook { get; private set; } = null!;

        /// <summary>
        /// The ID of the project in which the resource belongs.
        /// If it is not provided, the provider project is used.
        /// </summary>
        [Output("project")]
        public Output<string> Project { get; private set; } = null!;

        /// <summary>
        /// The combination of labels configured directly on the resource
        /// and default labels configured on the provider.
        /// </summary>
        [Output("pulumiLabels")]
        public Output<ImmutableDictionary<string, string>> PulumiLabels { get; private set; } = null!;

        /// <summary>
        /// A service with manual scaling runs continuously, allowing you to perform complex initialization and rely on the state of its memory over time.
        /// Structure is documented below.
        /// </summary>
        [Output("spark")]
        public Output<Outputs.TaskSpark?> Spark { get; private set; } = null!;

        /// <summary>
        /// (Output)
        /// Execution state for the job.
        /// </summary>
        [Output("state")]
        public Output<string> State { get; private set; } = null!;

        /// <summary>
        /// The task Id of the task.
        /// </summary>
        [Output("taskId")]
        public Output<string?> TaskId { get; private set; } = null!;

        /// <summary>
        /// Configuration for the cluster
        /// Structure is documented below.
        /// </summary>
        [Output("triggerSpec")]
        public Output<Outputs.TaskTriggerSpec> TriggerSpec { get; private set; } = null!;

        /// <summary>
        /// (Output)
        /// System generated globally unique ID for the job.
        /// </summary>
        [Output("uid")]
        public Output<string> Uid { get; private set; } = null!;

        /// <summary>
        /// (Output)
        /// Last update time of the status.
        /// </summary>
        [Output("updateTime")]
        public Output<string> UpdateTime { get; private set; } = null!;


        /// <summary>
        /// Create a Task resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public Task(string name, TaskArgs args, CustomResourceOptions? options = null)
            : base("gcp:dataplex/task:Task", name, args ?? new TaskArgs(), MakeResourceOptions(options, ""))
        {
        }

        private Task(string name, Input<string> id, TaskState? state = null, CustomResourceOptions? options = null)
            : base("gcp:dataplex/task:Task", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
                AdditionalSecretOutputs =
                {
                    "effectiveLabels",
                    "pulumiLabels",
                },
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing Task resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static Task Get(string name, Input<string> id, TaskState? state = null, CustomResourceOptions? options = null)
        {
            return new Task(name, id, state, options);
        }
    }

    public sealed class TaskArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// User-provided description of the task.
        /// </summary>
        [Input("description")]
        public Input<string>? Description { get; set; }

        /// <summary>
        /// User friendly display name.
        /// </summary>
        [Input("displayName")]
        public Input<string>? DisplayName { get; set; }

        /// <summary>
        /// Configuration for the cluster
        /// Structure is documented below.
        /// </summary>
        [Input("executionSpec", required: true)]
        public Input<Inputs.TaskExecutionSpecArgs> ExecutionSpec { get; set; } = null!;

        [Input("labels")]
        private InputMap<string>? _labels;

        /// <summary>
        /// User-defined labels for the task.
        /// 
        /// **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
        /// Please refer to the field `effective_labels` for all of the labels present on the resource.
        /// </summary>
        public InputMap<string> Labels
        {
            get => _labels ?? (_labels = new InputMap<string>());
            set => _labels = value;
        }

        /// <summary>
        /// The lake in which the task will be created in.
        /// </summary>
        [Input("lake")]
        public Input<string>? Lake { get; set; }

        /// <summary>
        /// The location in which the task will be created in.
        /// </summary>
        [Input("location")]
        public Input<string>? Location { get; set; }

        /// <summary>
        /// A service with manual scaling runs continuously, allowing you to perform complex initialization and rely on the state of its memory over time.
        /// Structure is documented below.
        /// </summary>
        [Input("notebook")]
        public Input<Inputs.TaskNotebookArgs>? Notebook { get; set; }

        /// <summary>
        /// The ID of the project in which the resource belongs.
        /// If it is not provided, the provider project is used.
        /// </summary>
        [Input("project")]
        public Input<string>? Project { get; set; }

        /// <summary>
        /// A service with manual scaling runs continuously, allowing you to perform complex initialization and rely on the state of its memory over time.
        /// Structure is documented below.
        /// </summary>
        [Input("spark")]
        public Input<Inputs.TaskSparkArgs>? Spark { get; set; }

        /// <summary>
        /// The task Id of the task.
        /// </summary>
        [Input("taskId")]
        public Input<string>? TaskId { get; set; }

        /// <summary>
        /// Configuration for the cluster
        /// Structure is documented below.
        /// </summary>
        [Input("triggerSpec", required: true)]
        public Input<Inputs.TaskTriggerSpecArgs> TriggerSpec { get; set; } = null!;

        public TaskArgs()
        {
        }
        public static new TaskArgs Empty => new TaskArgs();
    }

    public sealed class TaskState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The time when the task was created.
        /// </summary>
        [Input("createTime")]
        public Input<string>? CreateTime { get; set; }

        /// <summary>
        /// User-provided description of the task.
        /// </summary>
        [Input("description")]
        public Input<string>? Description { get; set; }

        /// <summary>
        /// User friendly display name.
        /// </summary>
        [Input("displayName")]
        public Input<string>? DisplayName { get; set; }

        [Input("effectiveLabels")]
        private InputMap<string>? _effectiveLabels;

        /// <summary>
        /// All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
        /// </summary>
        public InputMap<string> EffectiveLabels
        {
            get => _effectiveLabels ?? (_effectiveLabels = new InputMap<string>());
            set
            {
                var emptySecret = Output.CreateSecret(ImmutableDictionary.Create<string, string>());
                _effectiveLabels = Output.All(value, emptySecret).Apply(v => v[0]);
            }
        }

        /// <summary>
        /// Configuration for the cluster
        /// Structure is documented below.
        /// </summary>
        [Input("executionSpec")]
        public Input<Inputs.TaskExecutionSpecGetArgs>? ExecutionSpec { get; set; }

        [Input("executionStatuses")]
        private InputList<Inputs.TaskExecutionStatusGetArgs>? _executionStatuses;

        /// <summary>
        /// Configuration for the cluster
        /// Structure is documented below.
        /// </summary>
        public InputList<Inputs.TaskExecutionStatusGetArgs> ExecutionStatuses
        {
            get => _executionStatuses ?? (_executionStatuses = new InputList<Inputs.TaskExecutionStatusGetArgs>());
            set => _executionStatuses = value;
        }

        [Input("labels")]
        private InputMap<string>? _labels;

        /// <summary>
        /// User-defined labels for the task.
        /// 
        /// **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
        /// Please refer to the field `effective_labels` for all of the labels present on the resource.
        /// </summary>
        public InputMap<string> Labels
        {
            get => _labels ?? (_labels = new InputMap<string>());
            set => _labels = value;
        }

        /// <summary>
        /// The lake in which the task will be created in.
        /// </summary>
        [Input("lake")]
        public Input<string>? Lake { get; set; }

        /// <summary>
        /// The location in which the task will be created in.
        /// </summary>
        [Input("location")]
        public Input<string>? Location { get; set; }

        /// <summary>
        /// (Output)
        /// The relative resource name of the job, of the form: projects/{project_number}/locations/{locationId}/lakes/{lakeId}/tasks/{taskId}/jobs/{jobId}.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// A service with manual scaling runs continuously, allowing you to perform complex initialization and rely on the state of its memory over time.
        /// Structure is documented below.
        /// </summary>
        [Input("notebook")]
        public Input<Inputs.TaskNotebookGetArgs>? Notebook { get; set; }

        /// <summary>
        /// The ID of the project in which the resource belongs.
        /// If it is not provided, the provider project is used.
        /// </summary>
        [Input("project")]
        public Input<string>? Project { get; set; }

        [Input("pulumiLabels")]
        private InputMap<string>? _pulumiLabels;

        /// <summary>
        /// The combination of labels configured directly on the resource
        /// and default labels configured on the provider.
        /// </summary>
        public InputMap<string> PulumiLabels
        {
            get => _pulumiLabels ?? (_pulumiLabels = new InputMap<string>());
            set
            {
                var emptySecret = Output.CreateSecret(ImmutableDictionary.Create<string, string>());
                _pulumiLabels = Output.All(value, emptySecret).Apply(v => v[0]);
            }
        }

        /// <summary>
        /// A service with manual scaling runs continuously, allowing you to perform complex initialization and rely on the state of its memory over time.
        /// Structure is documented below.
        /// </summary>
        [Input("spark")]
        public Input<Inputs.TaskSparkGetArgs>? Spark { get; set; }

        /// <summary>
        /// (Output)
        /// Execution state for the job.
        /// </summary>
        [Input("state")]
        public Input<string>? State { get; set; }

        /// <summary>
        /// The task Id of the task.
        /// </summary>
        [Input("taskId")]
        public Input<string>? TaskId { get; set; }

        /// <summary>
        /// Configuration for the cluster
        /// Structure is documented below.
        /// </summary>
        [Input("triggerSpec")]
        public Input<Inputs.TaskTriggerSpecGetArgs>? TriggerSpec { get; set; }

        /// <summary>
        /// (Output)
        /// System generated globally unique ID for the job.
        /// </summary>
        [Input("uid")]
        public Input<string>? Uid { get; set; }

        /// <summary>
        /// (Output)
        /// Last update time of the status.
        /// </summary>
        [Input("updateTime")]
        public Input<string>? UpdateTime { get; set; }

        public TaskState()
        {
        }
        public static new TaskState Empty => new TaskState();
    }
}
