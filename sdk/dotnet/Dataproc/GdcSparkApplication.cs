// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Gcp.Dataproc
{
    /// <summary>
    /// A Spark application is a single Spark workload run on a GDC cluster.
    /// 
    /// To get more information about SparkApplication, see:
    /// 
    /// * [API documentation](https://cloud.google.com/dataproc-gdc/docs/reference/rest/v1/projects.locations.serviceInstances.sparkApplications)
    /// * How-to Guides
    ///     * [Dataproc Intro](https://cloud.google.com/dataproc/)
    /// 
    /// ## Example Usage
    /// 
    /// ### Dataprocgdc Sparkapplication Basic
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Gcp = Pulumi.Gcp;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var spark_application = new Gcp.Dataproc.GdcSparkApplication("spark-application", new()
    ///     {
    ///         SparkApplicationId = "tf-e2e-spark-app-basic",
    ///         Serviceinstance = "do-not-delete-dataproc-gdc-instance",
    ///         Project = "my-project",
    ///         Location = "us-west2",
    ///         Namespace = "default",
    ///         SparkApplicationConfig = new Gcp.Dataproc.Inputs.GdcSparkApplicationSparkApplicationConfigArgs
    ///         {
    ///             MainClass = "org.apache.spark.examples.SparkPi",
    ///             JarFileUris = new[]
    ///             {
    ///                 "file:///usr/lib/spark/examples/jars/spark-examples.jar",
    ///             },
    ///             Args = new[]
    ///             {
    ///                 "10000",
    ///             },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// ### Dataprocgdc Sparkapplication
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Gcp = Pulumi.Gcp;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var appEnv = new Gcp.Dataproc.GdcApplicationEnvironment("app_env", new()
    ///     {
    ///         ApplicationEnvironmentId = "tf-e2e-spark-app-env",
    ///         Serviceinstance = "do-not-delete-dataproc-gdc-instance",
    ///         Project = "my-project",
    ///         Location = "us-west2",
    ///         Namespace = "default",
    ///     });
    /// 
    ///     var spark_application = new Gcp.Dataproc.GdcSparkApplication("spark-application", new()
    ///     {
    ///         SparkApplicationId = "tf-e2e-spark-app",
    ///         Serviceinstance = "do-not-delete-dataproc-gdc-instance",
    ///         Project = "my-project",
    ///         Location = "us-west2",
    ///         Namespace = "default",
    ///         Labels = 
    ///         {
    ///             { "test-label", "label-value" },
    ///         },
    ///         Annotations = 
    ///         {
    ///             { "an_annotation", "annotation_value" },
    ///         },
    ///         Properties = 
    ///         {
    ///             { "spark.executor.instances", "2" },
    ///         },
    ///         ApplicationEnvironment = appEnv.Name,
    ///         Version = "1.2",
    ///         SparkApplicationConfig = new Gcp.Dataproc.Inputs.GdcSparkApplicationSparkApplicationConfigArgs
    ///         {
    ///             MainJarFileUri = "file:///usr/lib/spark/examples/jars/spark-examples.jar",
    ///             JarFileUris = new[]
    ///             {
    ///                 "file:///usr/lib/spark/examples/jars/spark-examples.jar",
    ///             },
    ///             ArchiveUris = new[]
    ///             {
    ///                 "file://usr/lib/spark/examples/spark-examples.jar",
    ///             },
    ///             FileUris = new[]
    ///             {
    ///                 "file:///usr/lib/spark/examples/jars/spark-examples.jar",
    ///             },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// ### Dataprocgdc Sparkapplication Pyspark
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Gcp = Pulumi.Gcp;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var spark_application = new Gcp.Dataproc.GdcSparkApplication("spark-application", new()
    ///     {
    ///         SparkApplicationId = "tf-e2e-pyspark-app",
    ///         Serviceinstance = "do-not-delete-dataproc-gdc-instance",
    ///         Project = "my-project",
    ///         Location = "us-west2",
    ///         Namespace = "default",
    ///         DisplayName = "A Pyspark application for a Terraform create test",
    ///         DependencyImages = new[]
    ///         {
    ///             "gcr.io/some/image",
    ///         },
    ///         PysparkApplicationConfig = new Gcp.Dataproc.Inputs.GdcSparkApplicationPysparkApplicationConfigArgs
    ///         {
    ///             MainPythonFileUri = "gs://goog-dataproc-initialization-actions-us-west2/conda/test_conda.py",
    ///             JarFileUris = new[]
    ///             {
    ///                 "file:///usr/lib/spark/examples/jars/spark-examples.jar",
    ///             },
    ///             PythonFileUris = new[]
    ///             {
    ///                 "gs://goog-dataproc-initialization-actions-us-west2/conda/get-sys-exec.py",
    ///             },
    ///             FileUris = new[]
    ///             {
    ///                 "file://usr/lib/spark/examples/spark-examples.jar",
    ///             },
    ///             ArchiveUris = new[]
    ///             {
    ///                 "file://usr/lib/spark/examples/spark-examples.jar",
    ///             },
    ///             Args = new[]
    ///             {
    ///                 "10",
    ///             },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// ### Dataprocgdc Sparkapplication Sparkr
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Gcp = Pulumi.Gcp;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var spark_application = new Gcp.Dataproc.GdcSparkApplication("spark-application", new()
    ///     {
    ///         SparkApplicationId = "tf-e2e-sparkr-app",
    ///         Serviceinstance = "do-not-delete-dataproc-gdc-instance",
    ///         Project = "my-project",
    ///         Location = "us-west2",
    ///         Namespace = "default",
    ///         DisplayName = "A SparkR application for a Terraform create test",
    ///         SparkRApplicationConfig = new Gcp.Dataproc.Inputs.GdcSparkApplicationSparkRApplicationConfigArgs
    ///         {
    ///             MainRFileUri = "gs://some-bucket/something.R",
    ///             FileUris = new[]
    ///             {
    ///                 "file://usr/lib/spark/examples/spark-examples.jar",
    ///             },
    ///             ArchiveUris = new[]
    ///             {
    ///                 "file://usr/lib/spark/examples/spark-examples.jar",
    ///             },
    ///             Args = new[]
    ///             {
    ///                 "10",
    ///             },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// ### Dataprocgdc Sparkapplication Sparksql
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Gcp = Pulumi.Gcp;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var spark_application = new Gcp.Dataproc.GdcSparkApplication("spark-application", new()
    ///     {
    ///         SparkApplicationId = "tf-e2e-sparksql-app",
    ///         Serviceinstance = "do-not-delete-dataproc-gdc-instance",
    ///         Project = "my-project",
    ///         Location = "us-west2",
    ///         Namespace = "default",
    ///         DisplayName = "A SparkSql application for a Terraform create test",
    ///         SparkSqlApplicationConfig = new Gcp.Dataproc.Inputs.GdcSparkApplicationSparkSqlApplicationConfigArgs
    ///         {
    ///             JarFileUris = new[]
    ///             {
    ///                 "file:///usr/lib/spark/examples/jars/spark-examples.jar",
    ///             },
    ///             QueryList = new Gcp.Dataproc.Inputs.GdcSparkApplicationSparkSqlApplicationConfigQueryListArgs
    ///             {
    ///                 Queries = new[]
    ///                 {
    ///                     "show tables;",
    ///                 },
    ///             },
    ///             ScriptVariables = 
    ///             {
    ///                 { "MY_VAR", "1" },
    ///             },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// ### Dataprocgdc Sparkapplication Sparksql Query File
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Gcp = Pulumi.Gcp;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var spark_application = new Gcp.Dataproc.GdcSparkApplication("spark-application", new()
    ///     {
    ///         SparkApplicationId = "tf-e2e-sparksql-app",
    ///         Serviceinstance = "do-not-delete-dataproc-gdc-instance",
    ///         Project = "my-project",
    ///         Location = "us-west2",
    ///         Namespace = "default",
    ///         DisplayName = "A SparkSql application for a Terraform create test",
    ///         SparkSqlApplicationConfig = new Gcp.Dataproc.Inputs.GdcSparkApplicationSparkSqlApplicationConfigArgs
    ///         {
    ///             JarFileUris = new[]
    ///             {
    ///                 "file:///usr/lib/spark/examples/jars/spark-examples.jar",
    ///             },
    ///             QueryFileUri = "gs://some-bucket/something.sql",
    ///             ScriptVariables = 
    ///             {
    ///                 { "MY_VAR", "1" },
    ///             },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Import
    /// 
    /// SparkApplication can be imported using any of these accepted formats:
    /// 
    /// * `projects/{{project}}/locations/{{location}}/serviceInstances/{{serviceinstance}}/sparkApplications/{{spark_application_id}}`
    /// 
    /// * `{{project}}/{{location}}/{{serviceinstance}}/{{spark_application_id}}`
    /// 
    /// * `{{location}}/{{serviceinstance}}/{{spark_application_id}}`
    /// 
    /// When using the `pulumi import` command, SparkApplication can be imported using one of the formats above. For example:
    /// 
    /// ```sh
    /// $ pulumi import gcp:dataproc/gdcSparkApplication:GdcSparkApplication default projects/{{project}}/locations/{{location}}/serviceInstances/{{serviceinstance}}/sparkApplications/{{spark_application_id}}
    /// ```
    /// 
    /// ```sh
    /// $ pulumi import gcp:dataproc/gdcSparkApplication:GdcSparkApplication default {{project}}/{{location}}/{{serviceinstance}}/{{spark_application_id}}
    /// ```
    /// 
    /// ```sh
    /// $ pulumi import gcp:dataproc/gdcSparkApplication:GdcSparkApplication default {{location}}/{{serviceinstance}}/{{spark_application_id}}
    /// ```
    /// </summary>
    [GcpResourceType("gcp:dataproc/gdcSparkApplication:GdcSparkApplication")]
    public partial class GdcSparkApplication : global::Pulumi.CustomResource
    {
        /// <summary>
        /// The annotations to associate with this application. Annotations may be used to store client information, but are not used by the server.
        /// **Note**: This field is non-authoritative, and will only manage the annotations present in your configuration.
        /// Please refer to the field `effective_annotations` for all of the annotations present on the resource.
        /// </summary>
        [Output("annotations")]
        public Output<ImmutableDictionary<string, string>?> Annotations { get; private set; } = null!;

        /// <summary>
        /// An ApplicationEnvironment from which to inherit configuration properties.
        /// </summary>
        [Output("applicationEnvironment")]
        public Output<string?> ApplicationEnvironment { get; private set; } = null!;

        /// <summary>
        /// The timestamp when the resource was created.
        /// </summary>
        [Output("createTime")]
        public Output<string> CreateTime { get; private set; } = null!;

        /// <summary>
        /// List of container image uris for additional file dependencies. Dependent files are sequentially copied from each image. If a file with the same name exists in 2 images then the file from later image is used.
        /// </summary>
        [Output("dependencyImages")]
        public Output<ImmutableArray<string>> DependencyImages { get; private set; } = null!;

        /// <summary>
        /// User-provided human-readable name to be used in user interfaces.
        /// </summary>
        [Output("displayName")]
        public Output<string?> DisplayName { get; private set; } = null!;

        [Output("effectiveAnnotations")]
        public Output<ImmutableDictionary<string, string>> EffectiveAnnotations { get; private set; } = null!;

        /// <summary>
        /// All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
        /// </summary>
        [Output("effectiveLabels")]
        public Output<ImmutableDictionary<string, string>> EffectiveLabels { get; private set; } = null!;

        /// <summary>
        /// The labels to associate with this application. Labels may be used for filtering and billing tracking.
        /// **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
        /// Please refer to the field `effective_labels` for all of the labels present on the resource.
        /// </summary>
        [Output("labels")]
        public Output<ImmutableDictionary<string, string>?> Labels { get; private set; } = null!;

        /// <summary>
        /// The location of the spark application.
        /// </summary>
        [Output("location")]
        public Output<string> Location { get; private set; } = null!;

        /// <summary>
        /// URL for a monitoring UI for this application (for eventual Spark PHS/UI support) Out of scope for private GA
        /// </summary>
        [Output("monitoringEndpoint")]
        public Output<string> MonitoringEndpoint { get; private set; } = null!;

        /// <summary>
        /// Identifier. The name of the application. Format: projects/{project}/locations/{location}/serviceInstances/{service_instance}/sparkApplications/{application}
        /// </summary>
        [Output("name")]
        public Output<string> Name { get; private set; } = null!;

        /// <summary>
        /// The Kubernetes namespace in which to create the application. This namespace must already exist on the cluster.
        /// </summary>
        [Output("namespace")]
        public Output<string?> Namespace { get; private set; } = null!;

        /// <summary>
        /// An HCFS URI pointing to the location of stdout and stdout of the application Mainly useful for Pantheon and gcloud Not in scope for private GA
        /// </summary>
        [Output("outputUri")]
        public Output<string> OutputUri { get; private set; } = null!;

        /// <summary>
        /// The ID of the project in which the resource belongs.
        /// If it is not provided, the provider project is used.
        /// </summary>
        [Output("project")]
        public Output<string> Project { get; private set; } = null!;

        /// <summary>
        /// application-specific properties.
        /// </summary>
        [Output("properties")]
        public Output<ImmutableDictionary<string, string>?> Properties { get; private set; } = null!;

        /// <summary>
        /// The combination of labels configured directly on the resource
        /// and default labels configured on the provider.
        /// </summary>
        [Output("pulumiLabels")]
        public Output<ImmutableDictionary<string, string>> PulumiLabels { get; private set; } = null!;

        /// <summary>
        /// Represents the PySparkApplicationConfig.
        /// Structure is documented below.
        /// </summary>
        [Output("pysparkApplicationConfig")]
        public Output<Outputs.GdcSparkApplicationPysparkApplicationConfig?> PysparkApplicationConfig { get; private set; } = null!;

        /// <summary>
        /// Whether the application is currently reconciling. True if the current state of the resource does not match the intended state, and the system is working to reconcile them, whether or not the change was user initiated.
        /// </summary>
        [Output("reconciling")]
        public Output<bool> Reconciling { get; private set; } = null!;

        /// <summary>
        /// The id of the service instance to which this spark application belongs.
        /// </summary>
        [Output("serviceinstance")]
        public Output<string> Serviceinstance { get; private set; } = null!;

        /// <summary>
        /// Represents the SparkApplicationConfig.
        /// Structure is documented below.
        /// </summary>
        [Output("sparkApplicationConfig")]
        public Output<Outputs.GdcSparkApplicationSparkApplicationConfig?> SparkApplicationConfig { get; private set; } = null!;

        /// <summary>
        /// The id of the application
        /// 
        /// 
        /// - - -
        /// </summary>
        [Output("sparkApplicationId")]
        public Output<string> SparkApplicationId { get; private set; } = null!;

        /// <summary>
        /// Represents the SparkRApplicationConfig.
        /// Structure is documented below.
        /// </summary>
        [Output("sparkRApplicationConfig")]
        public Output<Outputs.GdcSparkApplicationSparkRApplicationConfig?> SparkRApplicationConfig { get; private set; } = null!;

        /// <summary>
        /// Represents the SparkRApplicationConfig.
        /// Structure is documented below.
        /// </summary>
        [Output("sparkSqlApplicationConfig")]
        public Output<Outputs.GdcSparkApplicationSparkSqlApplicationConfig?> SparkSqlApplicationConfig { get; private set; } = null!;

        /// <summary>
        /// The current state.
        /// Possible values:
        /// * `STATE_UNSPECIFIED`
        /// * `PENDING`
        /// * `RUNNING`
        /// * `CANCELLING`
        /// * `CANCELLED`
        /// * `SUCCEEDED`
        /// * `FAILED`
        /// </summary>
        [Output("state")]
        public Output<string> State { get; private set; } = null!;

        /// <summary>
        /// A message explaining the current state.
        /// </summary>
        [Output("stateMessage")]
        public Output<string> StateMessage { get; private set; } = null!;

        /// <summary>
        /// System generated unique identifier for this application, formatted as UUID4.
        /// </summary>
        [Output("uid")]
        public Output<string> Uid { get; private set; } = null!;

        /// <summary>
        /// The timestamp when the resource was most recently updated.
        /// </summary>
        [Output("updateTime")]
        public Output<string> UpdateTime { get; private set; } = null!;

        /// <summary>
        /// The Dataproc version of this application.
        /// </summary>
        [Output("version")]
        public Output<string?> Version { get; private set; } = null!;


        /// <summary>
        /// Create a GdcSparkApplication resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public GdcSparkApplication(string name, GdcSparkApplicationArgs args, CustomResourceOptions? options = null)
            : base("gcp:dataproc/gdcSparkApplication:GdcSparkApplication", name, args ?? new GdcSparkApplicationArgs(), MakeResourceOptions(options, ""))
        {
        }

        private GdcSparkApplication(string name, Input<string> id, GdcSparkApplicationState? state = null, CustomResourceOptions? options = null)
            : base("gcp:dataproc/gdcSparkApplication:GdcSparkApplication", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
                AdditionalSecretOutputs =
                {
                    "effectiveLabels",
                    "pulumiLabels",
                },
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing GdcSparkApplication resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static GdcSparkApplication Get(string name, Input<string> id, GdcSparkApplicationState? state = null, CustomResourceOptions? options = null)
        {
            return new GdcSparkApplication(name, id, state, options);
        }
    }

    public sealed class GdcSparkApplicationArgs : global::Pulumi.ResourceArgs
    {
        [Input("annotations")]
        private InputMap<string>? _annotations;

        /// <summary>
        /// The annotations to associate with this application. Annotations may be used to store client information, but are not used by the server.
        /// **Note**: This field is non-authoritative, and will only manage the annotations present in your configuration.
        /// Please refer to the field `effective_annotations` for all of the annotations present on the resource.
        /// </summary>
        public InputMap<string> Annotations
        {
            get => _annotations ?? (_annotations = new InputMap<string>());
            set => _annotations = value;
        }

        /// <summary>
        /// An ApplicationEnvironment from which to inherit configuration properties.
        /// </summary>
        [Input("applicationEnvironment")]
        public Input<string>? ApplicationEnvironment { get; set; }

        [Input("dependencyImages")]
        private InputList<string>? _dependencyImages;

        /// <summary>
        /// List of container image uris for additional file dependencies. Dependent files are sequentially copied from each image. If a file with the same name exists in 2 images then the file from later image is used.
        /// </summary>
        public InputList<string> DependencyImages
        {
            get => _dependencyImages ?? (_dependencyImages = new InputList<string>());
            set => _dependencyImages = value;
        }

        /// <summary>
        /// User-provided human-readable name to be used in user interfaces.
        /// </summary>
        [Input("displayName")]
        public Input<string>? DisplayName { get; set; }

        [Input("labels")]
        private InputMap<string>? _labels;

        /// <summary>
        /// The labels to associate with this application. Labels may be used for filtering and billing tracking.
        /// **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
        /// Please refer to the field `effective_labels` for all of the labels present on the resource.
        /// </summary>
        public InputMap<string> Labels
        {
            get => _labels ?? (_labels = new InputMap<string>());
            set => _labels = value;
        }

        /// <summary>
        /// The location of the spark application.
        /// </summary>
        [Input("location", required: true)]
        public Input<string> Location { get; set; } = null!;

        /// <summary>
        /// The Kubernetes namespace in which to create the application. This namespace must already exist on the cluster.
        /// </summary>
        [Input("namespace")]
        public Input<string>? Namespace { get; set; }

        /// <summary>
        /// The ID of the project in which the resource belongs.
        /// If it is not provided, the provider project is used.
        /// </summary>
        [Input("project")]
        public Input<string>? Project { get; set; }

        [Input("properties")]
        private InputMap<string>? _properties;

        /// <summary>
        /// application-specific properties.
        /// </summary>
        public InputMap<string> Properties
        {
            get => _properties ?? (_properties = new InputMap<string>());
            set => _properties = value;
        }

        /// <summary>
        /// Represents the PySparkApplicationConfig.
        /// Structure is documented below.
        /// </summary>
        [Input("pysparkApplicationConfig")]
        public Input<Inputs.GdcSparkApplicationPysparkApplicationConfigArgs>? PysparkApplicationConfig { get; set; }

        /// <summary>
        /// The id of the service instance to which this spark application belongs.
        /// </summary>
        [Input("serviceinstance", required: true)]
        public Input<string> Serviceinstance { get; set; } = null!;

        /// <summary>
        /// Represents the SparkApplicationConfig.
        /// Structure is documented below.
        /// </summary>
        [Input("sparkApplicationConfig")]
        public Input<Inputs.GdcSparkApplicationSparkApplicationConfigArgs>? SparkApplicationConfig { get; set; }

        /// <summary>
        /// The id of the application
        /// 
        /// 
        /// - - -
        /// </summary>
        [Input("sparkApplicationId", required: true)]
        public Input<string> SparkApplicationId { get; set; } = null!;

        /// <summary>
        /// Represents the SparkRApplicationConfig.
        /// Structure is documented below.
        /// </summary>
        [Input("sparkRApplicationConfig")]
        public Input<Inputs.GdcSparkApplicationSparkRApplicationConfigArgs>? SparkRApplicationConfig { get; set; }

        /// <summary>
        /// Represents the SparkRApplicationConfig.
        /// Structure is documented below.
        /// </summary>
        [Input("sparkSqlApplicationConfig")]
        public Input<Inputs.GdcSparkApplicationSparkSqlApplicationConfigArgs>? SparkSqlApplicationConfig { get; set; }

        /// <summary>
        /// The Dataproc version of this application.
        /// </summary>
        [Input("version")]
        public Input<string>? Version { get; set; }

        public GdcSparkApplicationArgs()
        {
        }
        public static new GdcSparkApplicationArgs Empty => new GdcSparkApplicationArgs();
    }

    public sealed class GdcSparkApplicationState : global::Pulumi.ResourceArgs
    {
        [Input("annotations")]
        private InputMap<string>? _annotations;

        /// <summary>
        /// The annotations to associate with this application. Annotations may be used to store client information, but are not used by the server.
        /// **Note**: This field is non-authoritative, and will only manage the annotations present in your configuration.
        /// Please refer to the field `effective_annotations` for all of the annotations present on the resource.
        /// </summary>
        public InputMap<string> Annotations
        {
            get => _annotations ?? (_annotations = new InputMap<string>());
            set => _annotations = value;
        }

        /// <summary>
        /// An ApplicationEnvironment from which to inherit configuration properties.
        /// </summary>
        [Input("applicationEnvironment")]
        public Input<string>? ApplicationEnvironment { get; set; }

        /// <summary>
        /// The timestamp when the resource was created.
        /// </summary>
        [Input("createTime")]
        public Input<string>? CreateTime { get; set; }

        [Input("dependencyImages")]
        private InputList<string>? _dependencyImages;

        /// <summary>
        /// List of container image uris for additional file dependencies. Dependent files are sequentially copied from each image. If a file with the same name exists in 2 images then the file from later image is used.
        /// </summary>
        public InputList<string> DependencyImages
        {
            get => _dependencyImages ?? (_dependencyImages = new InputList<string>());
            set => _dependencyImages = value;
        }

        /// <summary>
        /// User-provided human-readable name to be used in user interfaces.
        /// </summary>
        [Input("displayName")]
        public Input<string>? DisplayName { get; set; }

        [Input("effectiveAnnotations")]
        private InputMap<string>? _effectiveAnnotations;
        public InputMap<string> EffectiveAnnotations
        {
            get => _effectiveAnnotations ?? (_effectiveAnnotations = new InputMap<string>());
            set => _effectiveAnnotations = value;
        }

        [Input("effectiveLabels")]
        private InputMap<string>? _effectiveLabels;

        /// <summary>
        /// All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
        /// </summary>
        public InputMap<string> EffectiveLabels
        {
            get => _effectiveLabels ?? (_effectiveLabels = new InputMap<string>());
            set
            {
                var emptySecret = Output.CreateSecret(ImmutableDictionary.Create<string, string>());
                _effectiveLabels = Output.All(value, emptySecret).Apply(v => v[0]);
            }
        }

        [Input("labels")]
        private InputMap<string>? _labels;

        /// <summary>
        /// The labels to associate with this application. Labels may be used for filtering and billing tracking.
        /// **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
        /// Please refer to the field `effective_labels` for all of the labels present on the resource.
        /// </summary>
        public InputMap<string> Labels
        {
            get => _labels ?? (_labels = new InputMap<string>());
            set => _labels = value;
        }

        /// <summary>
        /// The location of the spark application.
        /// </summary>
        [Input("location")]
        public Input<string>? Location { get; set; }

        /// <summary>
        /// URL for a monitoring UI for this application (for eventual Spark PHS/UI support) Out of scope for private GA
        /// </summary>
        [Input("monitoringEndpoint")]
        public Input<string>? MonitoringEndpoint { get; set; }

        /// <summary>
        /// Identifier. The name of the application. Format: projects/{project}/locations/{location}/serviceInstances/{service_instance}/sparkApplications/{application}
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// The Kubernetes namespace in which to create the application. This namespace must already exist on the cluster.
        /// </summary>
        [Input("namespace")]
        public Input<string>? Namespace { get; set; }

        /// <summary>
        /// An HCFS URI pointing to the location of stdout and stdout of the application Mainly useful for Pantheon and gcloud Not in scope for private GA
        /// </summary>
        [Input("outputUri")]
        public Input<string>? OutputUri { get; set; }

        /// <summary>
        /// The ID of the project in which the resource belongs.
        /// If it is not provided, the provider project is used.
        /// </summary>
        [Input("project")]
        public Input<string>? Project { get; set; }

        [Input("properties")]
        private InputMap<string>? _properties;

        /// <summary>
        /// application-specific properties.
        /// </summary>
        public InputMap<string> Properties
        {
            get => _properties ?? (_properties = new InputMap<string>());
            set => _properties = value;
        }

        [Input("pulumiLabels")]
        private InputMap<string>? _pulumiLabels;

        /// <summary>
        /// The combination of labels configured directly on the resource
        /// and default labels configured on the provider.
        /// </summary>
        public InputMap<string> PulumiLabels
        {
            get => _pulumiLabels ?? (_pulumiLabels = new InputMap<string>());
            set
            {
                var emptySecret = Output.CreateSecret(ImmutableDictionary.Create<string, string>());
                _pulumiLabels = Output.All(value, emptySecret).Apply(v => v[0]);
            }
        }

        /// <summary>
        /// Represents the PySparkApplicationConfig.
        /// Structure is documented below.
        /// </summary>
        [Input("pysparkApplicationConfig")]
        public Input<Inputs.GdcSparkApplicationPysparkApplicationConfigGetArgs>? PysparkApplicationConfig { get; set; }

        /// <summary>
        /// Whether the application is currently reconciling. True if the current state of the resource does not match the intended state, and the system is working to reconcile them, whether or not the change was user initiated.
        /// </summary>
        [Input("reconciling")]
        public Input<bool>? Reconciling { get; set; }

        /// <summary>
        /// The id of the service instance to which this spark application belongs.
        /// </summary>
        [Input("serviceinstance")]
        public Input<string>? Serviceinstance { get; set; }

        /// <summary>
        /// Represents the SparkApplicationConfig.
        /// Structure is documented below.
        /// </summary>
        [Input("sparkApplicationConfig")]
        public Input<Inputs.GdcSparkApplicationSparkApplicationConfigGetArgs>? SparkApplicationConfig { get; set; }

        /// <summary>
        /// The id of the application
        /// 
        /// 
        /// - - -
        /// </summary>
        [Input("sparkApplicationId")]
        public Input<string>? SparkApplicationId { get; set; }

        /// <summary>
        /// Represents the SparkRApplicationConfig.
        /// Structure is documented below.
        /// </summary>
        [Input("sparkRApplicationConfig")]
        public Input<Inputs.GdcSparkApplicationSparkRApplicationConfigGetArgs>? SparkRApplicationConfig { get; set; }

        /// <summary>
        /// Represents the SparkRApplicationConfig.
        /// Structure is documented below.
        /// </summary>
        [Input("sparkSqlApplicationConfig")]
        public Input<Inputs.GdcSparkApplicationSparkSqlApplicationConfigGetArgs>? SparkSqlApplicationConfig { get; set; }

        /// <summary>
        /// The current state.
        /// Possible values:
        /// * `STATE_UNSPECIFIED`
        /// * `PENDING`
        /// * `RUNNING`
        /// * `CANCELLING`
        /// * `CANCELLED`
        /// * `SUCCEEDED`
        /// * `FAILED`
        /// </summary>
        [Input("state")]
        public Input<string>? State { get; set; }

        /// <summary>
        /// A message explaining the current state.
        /// </summary>
        [Input("stateMessage")]
        public Input<string>? StateMessage { get; set; }

        /// <summary>
        /// System generated unique identifier for this application, formatted as UUID4.
        /// </summary>
        [Input("uid")]
        public Input<string>? Uid { get; set; }

        /// <summary>
        /// The timestamp when the resource was most recently updated.
        /// </summary>
        [Input("updateTime")]
        public Input<string>? UpdateTime { get; set; }

        /// <summary>
        /// The Dataproc version of this application.
        /// </summary>
        [Input("version")]
        public Input<string>? Version { get; set; }

        public GdcSparkApplicationState()
        {
        }
        public static new GdcSparkApplicationState Empty => new GdcSparkApplicationState();
    }
}
