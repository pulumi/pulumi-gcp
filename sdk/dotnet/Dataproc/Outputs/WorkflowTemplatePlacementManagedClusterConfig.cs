// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Gcp.Dataproc.Outputs
{

    [OutputType]
    public sealed class WorkflowTemplatePlacementManagedClusterConfig
    {
        /// <summary>
        /// Autoscaling config for the policy associated with the cluster. Cluster does not autoscale if this field is unset.
        /// </summary>
        public readonly Outputs.WorkflowTemplatePlacementManagedClusterConfigAutoscalingConfig? AutoscalingConfig;
        /// <summary>
        /// Encryption settings for the cluster.
        /// </summary>
        public readonly Outputs.WorkflowTemplatePlacementManagedClusterConfigEncryptionConfig? EncryptionConfig;
        /// <summary>
        /// Port/endpoint configuration for this cluster
        /// </summary>
        public readonly Outputs.WorkflowTemplatePlacementManagedClusterConfigEndpointConfig? EndpointConfig;
        /// <summary>
        /// The shared Compute Engine config settings for all instances in a cluster.
        /// </summary>
        public readonly Outputs.WorkflowTemplatePlacementManagedClusterConfigGceClusterConfig? GceClusterConfig;
        /// <summary>
        /// The Kubernetes Engine config for Dataproc clusters deployed to Kubernetes. Setting this is considered mutually exclusive with Compute Engine-based options such as `GceClusterConfig`, `MasterConfig`, `WorkerConfig`, `SecondaryWorkerConfig`, and `AutoscalingConfig`.
        /// </summary>
        public readonly Outputs.WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfig? GkeClusterConfig;
        /// <summary>
        /// Commands to execute on each node after config is completed. By default, executables are run on master and all worker nodes. You can test a node's `Role` metadata to run an executable on a master or worker node, as shown below using `Curl` (you can also use `Wget`): ROLE=$(curl -H Metadata-Flavor:Google http://metadata/computeMetadata/v1/instance/attributes/dataproc-role) if ; then ... master specific actions ... else ... worker specific actions ... fi
        /// </summary>
        public readonly ImmutableArray<Outputs.WorkflowTemplatePlacementManagedClusterConfigInitializationAction> InitializationActions;
        /// <summary>
        /// Lifecycle setting for the cluster.
        /// </summary>
        public readonly Outputs.WorkflowTemplatePlacementManagedClusterConfigLifecycleConfig? LifecycleConfig;
        /// <summary>
        /// The Compute Engine config settings for additional worker instances in a cluster.
        /// </summary>
        public readonly Outputs.WorkflowTemplatePlacementManagedClusterConfigMasterConfig? MasterConfig;
        /// <summary>
        /// Metastore configuration.
        /// </summary>
        public readonly Outputs.WorkflowTemplatePlacementManagedClusterConfigMetastoreConfig? MetastoreConfig;
        /// <summary>
        /// The Compute Engine config settings for additional worker instances in a cluster.
        /// </summary>
        public readonly Outputs.WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfig? SecondaryWorkerConfig;
        /// <summary>
        /// Security settings for the cluster.
        /// </summary>
        public readonly Outputs.WorkflowTemplatePlacementManagedClusterConfigSecurityConfig? SecurityConfig;
        /// <summary>
        /// The config settings for software inside the cluster.
        /// </summary>
        public readonly Outputs.WorkflowTemplatePlacementManagedClusterConfigSoftwareConfig? SoftwareConfig;
        /// <summary>
        /// A Cloud Storage bucket used to stage job dependencies, config files, and job driver console output. If you do not specify a staging bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's staging bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket (see [Dataproc staging and temp buckets](https://docs.cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)).
        /// </summary>
        public readonly string? StagingBucket;
        /// <summary>
        /// A Cloud Storage bucket used to store ephemeral cluster and jobs data, such as Spark and MapReduce history files. If you do not specify a temp bucket, Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's temp bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket. The default bucket has a TTL of 90 days, but you can use any TTL (or none) if you specify a bucket.
        /// </summary>
        public readonly string? TempBucket;
        /// <summary>
        /// The Compute Engine config settings for additional worker instances in a cluster.
        /// 
        /// - - -
        /// </summary>
        public readonly Outputs.WorkflowTemplatePlacementManagedClusterConfigWorkerConfig? WorkerConfig;

        [OutputConstructor]
        private WorkflowTemplatePlacementManagedClusterConfig(
            Outputs.WorkflowTemplatePlacementManagedClusterConfigAutoscalingConfig? autoscalingConfig,

            Outputs.WorkflowTemplatePlacementManagedClusterConfigEncryptionConfig? encryptionConfig,

            Outputs.WorkflowTemplatePlacementManagedClusterConfigEndpointConfig? endpointConfig,

            Outputs.WorkflowTemplatePlacementManagedClusterConfigGceClusterConfig? gceClusterConfig,

            Outputs.WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfig? gkeClusterConfig,

            ImmutableArray<Outputs.WorkflowTemplatePlacementManagedClusterConfigInitializationAction> initializationActions,

            Outputs.WorkflowTemplatePlacementManagedClusterConfigLifecycleConfig? lifecycleConfig,

            Outputs.WorkflowTemplatePlacementManagedClusterConfigMasterConfig? masterConfig,

            Outputs.WorkflowTemplatePlacementManagedClusterConfigMetastoreConfig? metastoreConfig,

            Outputs.WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfig? secondaryWorkerConfig,

            Outputs.WorkflowTemplatePlacementManagedClusterConfigSecurityConfig? securityConfig,

            Outputs.WorkflowTemplatePlacementManagedClusterConfigSoftwareConfig? softwareConfig,

            string? stagingBucket,

            string? tempBucket,

            Outputs.WorkflowTemplatePlacementManagedClusterConfigWorkerConfig? workerConfig)
        {
            AutoscalingConfig = autoscalingConfig;
            EncryptionConfig = encryptionConfig;
            EndpointConfig = endpointConfig;
            GceClusterConfig = gceClusterConfig;
            GkeClusterConfig = gkeClusterConfig;
            InitializationActions = initializationActions;
            LifecycleConfig = lifecycleConfig;
            MasterConfig = masterConfig;
            MetastoreConfig = metastoreConfig;
            SecondaryWorkerConfig = secondaryWorkerConfig;
            SecurityConfig = securityConfig;
            SoftwareConfig = softwareConfig;
            StagingBucket = stagingBucket;
            TempBucket = tempBucket;
            WorkerConfig = workerConfig;
        }
    }
}
