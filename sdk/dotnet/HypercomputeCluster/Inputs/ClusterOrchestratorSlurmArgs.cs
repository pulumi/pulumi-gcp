// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Gcp.HypercomputeCluster.Inputs
{

    public sealed class ClusterOrchestratorSlurmArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Default partition to use for submitted jobs that do not explicitly specify
        /// a partition. Required if and only if there is more than one partition, in
        /// which case it must match the id of one of the partitions.
        /// </summary>
        [Input("defaultPartition")]
        public Input<string>? DefaultPartition { get; set; }

        [Input("epilogBashScripts")]
        private InputList<string>? _epilogBashScripts;

        /// <summary>
        /// Slurm [epilog scripts](https://slurm.schedmd.com/prolog_epilog.html), which
        /// will be executed by compute nodes whenever a node finishes running a job.
        /// Values must not be empty.
        /// </summary>
        public InputList<string> EpilogBashScripts
        {
            get => _epilogBashScripts ?? (_epilogBashScripts = new InputList<string>());
            set => _epilogBashScripts = value;
        }

        /// <summary>
        /// Configuration for Slurm [login
        /// nodes](https://slurm.schedmd.com/quickstart_admin.html#login) in the cluster.
        /// Login nodes are Compute Engine VM instances that allow users to access the
        /// cluster over SSH.
        /// Structure is documented below.
        /// </summary>
        [Input("loginNodes", required: true)]
        public Input<Inputs.ClusterOrchestratorSlurmLoginNodesArgs> LoginNodes { get; set; } = null!;

        [Input("nodeSets", required: true)]
        private InputList<Inputs.ClusterOrchestratorSlurmNodeSetArgs>? _nodeSets;

        /// <summary>
        /// Configuration of Slurm nodesets, which define groups of compute resources
        /// that can be used by Slurm. At least one compute node is required.
        /// Structure is documented below.
        /// </summary>
        public InputList<Inputs.ClusterOrchestratorSlurmNodeSetArgs> NodeSets
        {
            get => _nodeSets ?? (_nodeSets = new InputList<Inputs.ClusterOrchestratorSlurmNodeSetArgs>());
            set => _nodeSets = value;
        }

        [Input("partitions", required: true)]
        private InputList<Inputs.ClusterOrchestratorSlurmPartitionArgs>? _partitions;

        /// <summary>
        /// Configuration of Slurm partitions, which group one or more nodesets. Acts
        /// as a queue against which jobs can be submitted. At least one partition is
        /// required.
        /// Structure is documented below.
        /// </summary>
        public InputList<Inputs.ClusterOrchestratorSlurmPartitionArgs> Partitions
        {
            get => _partitions ?? (_partitions = new InputList<Inputs.ClusterOrchestratorSlurmPartitionArgs>());
            set => _partitions = value;
        }

        [Input("prologBashScripts")]
        private InputList<string>? _prologBashScripts;

        /// <summary>
        /// Slurm [prolog scripts](https://slurm.schedmd.com/prolog_epilog.html), which
        /// will be executed by compute nodes before a node begins running a new job.
        /// Values must not be empty.
        /// </summary>
        public InputList<string> PrologBashScripts
        {
            get => _prologBashScripts ?? (_prologBashScripts = new InputList<string>());
            set => _prologBashScripts = value;
        }

        public ClusterOrchestratorSlurmArgs()
        {
        }
        public static new ClusterOrchestratorSlurmArgs Empty => new ClusterOrchestratorSlurmArgs();
    }
}
