// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Gcp.Dataflow.Inputs
{

    public sealed class PipelineWorkloadDataflowLaunchTemplateRequestArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// A Cloud Storage path to the template from which to create the job. Must be a valid Cloud Storage URL, beginning with 'gs://'.
        /// </summary>
        [Input("gcsPath")]
        public Input<string>? GcsPath { get; set; }

        /// <summary>
        /// The parameters of the template to launch. This should be part of the body of the POST request.
        /// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchtemplateparameters
        /// Structure is documented below.
        /// </summary>
        [Input("launchParameters")]
        public Input<Inputs.PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersArgs>? LaunchParameters { get; set; }

        /// <summary>
        /// The regional endpoint to which to direct the request.
        /// </summary>
        [Input("location")]
        public Input<string>? Location { get; set; }

        /// <summary>
        /// The ID of the Cloud Platform project that the job belongs to.
        /// </summary>
        [Input("projectId", required: true)]
        public Input<string> ProjectId { get; set; } = null!;

        /// <summary>
        /// (Optional)
        /// </summary>
        [Input("validateOnly")]
        public Input<bool>? ValidateOnly { get; set; }

        public PipelineWorkloadDataflowLaunchTemplateRequestArgs()
        {
        }
        public static new PipelineWorkloadDataflowLaunchTemplateRequestArgs Empty => new PipelineWorkloadDataflowLaunchTemplateRequestArgs();
    }
}
