// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Gcp.BigQuery
{
    /// <summary>
    /// Represents a data transfer configuration. A transfer configuration
    /// contains all metadata needed to perform a data transfer.
    /// 
    /// To get more information about Config, see:
    /// 
    /// * [API documentation](https://cloud.google.com/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs/create)
    /// * How-to Guides
    ///     * [Official Documentation](https://cloud.google.com/bigquery/docs/reference/datatransfer/rest/)
    /// 
    /// &gt; **Note:**  All arguments marked as write-only values will not be stored in the state: `sensitive_params.secret_access_key_wo`.
    /// Read more about Write-only Attributes.
    /// 
    /// ## Example Usage
    /// 
    /// ### Bigquerydatatransfer Config Scheduled Query
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Gcp = Pulumi.Gcp;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var project = Gcp.Organizations.GetProject.Invoke();
    /// 
    ///     var permissions = new Gcp.Projects.IAMMember("permissions", new()
    ///     {
    ///         Project = project.Apply(getProjectResult =&gt; getProjectResult.ProjectId),
    ///         Role = "roles/iam.serviceAccountTokenCreator",
    ///         Member = $"serviceAccount:service-{project.Apply(getProjectResult =&gt; getProjectResult.Number)}@gcp-sa-bigquerydatatransfer.iam.gserviceaccount.com",
    ///     });
    /// 
    ///     var myDataset = new Gcp.BigQuery.Dataset("my_dataset", new()
    ///     {
    ///         DatasetId = "my_dataset",
    ///         FriendlyName = "foo",
    ///         Description = "bar",
    ///         Location = "asia-northeast1",
    ///     }, new CustomResourceOptions
    ///     {
    ///         DependsOn =
    ///         {
    ///             permissions,
    ///         },
    ///     });
    /// 
    ///     var queryConfig = new Gcp.BigQuery.DataTransferConfig("query_config", new()
    ///     {
    ///         DisplayName = "my-query",
    ///         Location = "asia-northeast1",
    ///         DataSourceId = "scheduled_query",
    ///         Schedule = "first sunday of quarter 00:00",
    ///         DestinationDatasetId = myDataset.DatasetId,
    ///         Params = 
    ///         {
    ///             { "destination_table_name_template", "my_table" },
    ///             { "write_disposition", "WRITE_APPEND" },
    ///             { "query", "SELECT name FROM tabl WHERE x = 'y'" },
    ///         },
    ///     }, new CustomResourceOptions
    ///     {
    ///         DependsOn =
    ///         {
    ///             permissions,
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// ### Bigquerydatatransfer Config Cmek
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Gcp = Pulumi.Gcp;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var project = Gcp.Organizations.GetProject.Invoke();
    /// 
    ///     var permissions = new Gcp.Projects.IAMMember("permissions", new()
    ///     {
    ///         Project = project.Apply(getProjectResult =&gt; getProjectResult.ProjectId),
    ///         Role = "roles/iam.serviceAccountTokenCreator",
    ///         Member = $"serviceAccount:service-{project.Apply(getProjectResult =&gt; getProjectResult.Number)}@gcp-sa-bigquerydatatransfer.iam.gserviceaccount.com",
    ///     });
    /// 
    ///     var myDataset = new Gcp.BigQuery.Dataset("my_dataset", new()
    ///     {
    ///         DatasetId = "example_dataset",
    ///         FriendlyName = "foo",
    ///         Description = "bar",
    ///         Location = "asia-northeast1",
    ///     }, new CustomResourceOptions
    ///     {
    ///         DependsOn =
    ///         {
    ///             permissions,
    ///         },
    ///     });
    /// 
    ///     var keyRing = new Gcp.Kms.KeyRing("key_ring", new()
    ///     {
    ///         Name = "example-keyring",
    ///         Location = "us",
    ///     });
    /// 
    ///     var cryptoKey = new Gcp.Kms.CryptoKey("crypto_key", new()
    ///     {
    ///         Name = "example-key",
    ///         KeyRing = keyRing.Id,
    ///     });
    /// 
    ///     var queryConfigCmek = new Gcp.BigQuery.DataTransferConfig("query_config_cmek", new()
    ///     {
    ///         DisplayName = "display-name",
    ///         Location = "asia-northeast1",
    ///         DataSourceId = "scheduled_query",
    ///         Schedule = "first sunday of quarter 00:00",
    ///         DestinationDatasetId = myDataset.DatasetId,
    ///         Params = 
    ///         {
    ///             { "destination_table_name_template", "my_table" },
    ///             { "write_disposition", "WRITE_APPEND" },
    ///             { "query", "SELECT name FROM tabl WHERE x = 'y'" },
    ///         },
    ///         EncryptionConfiguration = new Gcp.BigQuery.Inputs.DataTransferConfigEncryptionConfigurationArgs
    ///         {
    ///             KmsKeyName = cryptoKey.Id,
    ///         },
    ///     }, new CustomResourceOptions
    ///     {
    ///         DependsOn =
    ///         {
    ///             permissions,
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// ### Bigquerydatatransfer Config Salesforce
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Gcp = Pulumi.Gcp;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var project = Gcp.Organizations.GetProject.Invoke();
    /// 
    ///     var myDataset = new Gcp.BigQuery.Dataset("my_dataset", new()
    ///     {
    ///         DatasetId = "my_dataset",
    ///         Description = "My dataset",
    ///         Location = "asia-northeast1",
    ///     });
    /// 
    ///     var salesforceConfig = new Gcp.BigQuery.DataTransferConfig("salesforce_config", new()
    ///     {
    ///         DisplayName = "my-salesforce-config",
    ///         Location = "asia-northeast1",
    ///         DataSourceId = "salesforce",
    ///         Schedule = "first sunday of quarter 00:00",
    ///         DestinationDatasetId = myDataset.DatasetId,
    ///         Params = 
    ///         {
    ///             { "connector.authentication.oauth.clientId", "client-id" },
    ///             { "connector.authentication.oauth.clientSecret", "client-secret" },
    ///             { "connector.authentication.oauth.myDomain", "MyDomainName" },
    ///             { "assets", "[\"asset-a\",\"asset-b\"]" },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Ephemeral Attributes Reference
    /// 
    /// The following write-only attributes are supported:
    /// 
    /// &lt;a name="nested_sensitive_params"&gt;&lt;/a&gt;The `sensitive_params` block supports:
    /// 
    /// * `secret_access_key_wo` -
    ///   (Optional)
    ///   The Secret Access Key of the AWS account transferring data from.
    ///   **Note**: This property is write-only and will not be read from the API.
    /// 
    /// ## Import
    /// 
    /// Config can be imported using any of these accepted formats:
    /// 
    /// * `{{project}}/{{name}}`
    /// 
    /// * `{{project}} {{name}}`
    /// 
    /// * `{{name}}`
    /// 
    /// When using the `pulumi import` command, Config can be imported using one of the formats above. For example:
    /// 
    /// ```sh
    /// $ pulumi import gcp:bigquery/dataTransferConfig:DataTransferConfig default {{project}}/{{name}}
    /// ```
    /// 
    /// ```sh
    /// $ pulumi import gcp:bigquery/dataTransferConfig:DataTransferConfig default "{{project}} {{name}}"
    /// ```
    /// 
    /// ```sh
    /// $ pulumi import gcp:bigquery/dataTransferConfig:DataTransferConfig default {{name}}
    /// ```
    /// </summary>
    [GcpResourceType("gcp:bigquery/dataTransferConfig:DataTransferConfig")]
    public partial class DataTransferConfig : global::Pulumi.CustomResource
    {
        /// <summary>
        /// The number of days to look back to automatically refresh the data.
        /// For example, if dataRefreshWindowDays = 10, then every day BigQuery
        /// reingests data for [today-10, today-1], rather than ingesting data for
        /// just [today-1]. Only valid if the data source supports the feature.
        /// Set the value to 0 to use the default value.
        /// </summary>
        [Output("dataRefreshWindowDays")]
        public Output<int?> DataRefreshWindowDays { get; private set; } = null!;

        /// <summary>
        /// The data source id. Cannot be changed once the transfer config is created.
        /// </summary>
        [Output("dataSourceId")]
        public Output<string> DataSourceId { get; private set; } = null!;

        /// <summary>
        /// The BigQuery target dataset id.
        /// </summary>
        [Output("destinationDatasetId")]
        public Output<string?> DestinationDatasetId { get; private set; } = null!;

        /// <summary>
        /// When set to true, no runs are scheduled for a given transfer.
        /// </summary>
        [Output("disabled")]
        public Output<bool?> Disabled { get; private set; } = null!;

        /// <summary>
        /// The user specified display name for the transfer config.
        /// </summary>
        [Output("displayName")]
        public Output<string> DisplayName { get; private set; } = null!;

        /// <summary>
        /// Email notifications will be sent according to these preferences to the
        /// email address of the user who owns this transfer config.
        /// Structure is documented below.
        /// </summary>
        [Output("emailPreferences")]
        public Output<Outputs.DataTransferConfigEmailPreferences?> EmailPreferences { get; private set; } = null!;

        /// <summary>
        /// Represents the encryption configuration for a transfer.
        /// Structure is documented below.
        /// </summary>
        [Output("encryptionConfiguration")]
        public Output<Outputs.DataTransferConfigEncryptionConfiguration?> EncryptionConfiguration { get; private set; } = null!;

        /// <summary>
        /// The geographic location where the transfer config should reside.
        /// Examples: US, EU, asia-northeast1. The default value is US.
        /// </summary>
        [Output("location")]
        public Output<string?> Location { get; private set; } = null!;

        /// <summary>
        /// The resource name of the transfer config. Transfer config names have the
        /// form projects/{projectId}/locations/{location}/transferConfigs/{configId}
        /// or projects/{projectId}/transferConfigs/{configId},
        /// where configId is usually a uuid, but this is not required.
        /// The name is ignored when creating a transfer config.
        /// </summary>
        [Output("name")]
        public Output<string> Name { get; private set; } = null!;

        /// <summary>
        /// Pub/Sub topic where notifications will be sent after transfer runs
        /// associated with this transfer config finish.
        /// </summary>
        [Output("notificationPubsubTopic")]
        public Output<string?> NotificationPubsubTopic { get; private set; } = null!;

        /// <summary>
        /// Parameters specific to each data source. For more information see the bq tab in the 'Setting up a data transfer'
        /// section for each data source. For example the parameters for Cloud Storage transfers are listed here:
        /// https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
        /// **NOTE** : If you are attempting to update a parameter that cannot be updated (due to api limitations) please force recreation of the resource.
        /// 
        /// 
        /// - - -
        /// </summary>
        [Output("params")]
        public Output<ImmutableDictionary<string, string>> Params { get; private set; } = null!;

        /// <summary>
        /// The ID of the project in which the resource belongs.
        /// If it is not provided, the provider project is used.
        /// </summary>
        [Output("project")]
        public Output<string> Project { get; private set; } = null!;

        /// <summary>
        /// Data transfer schedule. If the data source does not support a custom
        /// schedule, this should be empty. If it is empty, the default value for
        /// the data source will be used. The specified times are in UTC. Examples
        /// of valid format: 1st,3rd monday of month 15:30, every wed,fri of jan,
        /// jun 13:15, and first sunday of quarter 00:00. See more explanation
        /// about the format here:
        /// https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format
        /// NOTE: The minimum interval time between recurring transfers depends
        /// on the data source; refer to the documentation for your data source.
        /// </summary>
        [Output("schedule")]
        public Output<string?> Schedule { get; private set; } = null!;

        /// <summary>
        /// Options customizing the data transfer schedule.
        /// Structure is documented below.
        /// </summary>
        [Output("scheduleOptions")]
        public Output<Outputs.DataTransferConfigScheduleOptions?> ScheduleOptions { get; private set; } = null!;

        /// <summary>
        /// Different parameters are configured primarily using the the `params` field on this
        /// resource. This block contains the parameters which contain secrets or passwords so that they can be marked
        /// sensitive and hidden from plan output. The name of the field, eg: secret_access_key, will be the key
        /// in the `params` map in the api request.
        /// Credentials may not be specified in both locations and will cause an error. Changing from one location
        /// to a different credential configuration in the config will require an apply to update state.
        /// Structure is documented below.
        /// </summary>
        [Output("sensitiveParams")]
        public Output<Outputs.DataTransferConfigSensitiveParams?> SensitiveParams { get; private set; } = null!;

        /// <summary>
        /// Service account email. If this field is set, transfer config will
        /// be created with this service account credentials. It requires that
        /// requesting user calling this API has permissions to act as this service account.
        /// </summary>
        [Output("serviceAccountName")]
        public Output<string?> ServiceAccountName { get; private set; } = null!;


        /// <summary>
        /// Create a DataTransferConfig resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public DataTransferConfig(string name, DataTransferConfigArgs args, CustomResourceOptions? options = null)
            : base("gcp:bigquery/dataTransferConfig:DataTransferConfig", name, args ?? new DataTransferConfigArgs(), MakeResourceOptions(options, ""))
        {
        }

        private DataTransferConfig(string name, Input<string> id, DataTransferConfigState? state = null, CustomResourceOptions? options = null)
            : base("gcp:bigquery/dataTransferConfig:DataTransferConfig", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing DataTransferConfig resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static DataTransferConfig Get(string name, Input<string> id, DataTransferConfigState? state = null, CustomResourceOptions? options = null)
        {
            return new DataTransferConfig(name, id, state, options);
        }
    }

    public sealed class DataTransferConfigArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The number of days to look back to automatically refresh the data.
        /// For example, if dataRefreshWindowDays = 10, then every day BigQuery
        /// reingests data for [today-10, today-1], rather than ingesting data for
        /// just [today-1]. Only valid if the data source supports the feature.
        /// Set the value to 0 to use the default value.
        /// </summary>
        [Input("dataRefreshWindowDays")]
        public Input<int>? DataRefreshWindowDays { get; set; }

        /// <summary>
        /// The data source id. Cannot be changed once the transfer config is created.
        /// </summary>
        [Input("dataSourceId", required: true)]
        public Input<string> DataSourceId { get; set; } = null!;

        /// <summary>
        /// The BigQuery target dataset id.
        /// </summary>
        [Input("destinationDatasetId")]
        public Input<string>? DestinationDatasetId { get; set; }

        /// <summary>
        /// When set to true, no runs are scheduled for a given transfer.
        /// </summary>
        [Input("disabled")]
        public Input<bool>? Disabled { get; set; }

        /// <summary>
        /// The user specified display name for the transfer config.
        /// </summary>
        [Input("displayName", required: true)]
        public Input<string> DisplayName { get; set; } = null!;

        /// <summary>
        /// Email notifications will be sent according to these preferences to the
        /// email address of the user who owns this transfer config.
        /// Structure is documented below.
        /// </summary>
        [Input("emailPreferences")]
        public Input<Inputs.DataTransferConfigEmailPreferencesArgs>? EmailPreferences { get; set; }

        /// <summary>
        /// Represents the encryption configuration for a transfer.
        /// Structure is documented below.
        /// </summary>
        [Input("encryptionConfiguration")]
        public Input<Inputs.DataTransferConfigEncryptionConfigurationArgs>? EncryptionConfiguration { get; set; }

        /// <summary>
        /// The geographic location where the transfer config should reside.
        /// Examples: US, EU, asia-northeast1. The default value is US.
        /// </summary>
        [Input("location")]
        public Input<string>? Location { get; set; }

        /// <summary>
        /// Pub/Sub topic where notifications will be sent after transfer runs
        /// associated with this transfer config finish.
        /// </summary>
        [Input("notificationPubsubTopic")]
        public Input<string>? NotificationPubsubTopic { get; set; }

        [Input("params", required: true)]
        private InputMap<string>? _params;

        /// <summary>
        /// Parameters specific to each data source. For more information see the bq tab in the 'Setting up a data transfer'
        /// section for each data source. For example the parameters for Cloud Storage transfers are listed here:
        /// https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
        /// **NOTE** : If you are attempting to update a parameter that cannot be updated (due to api limitations) please force recreation of the resource.
        /// 
        /// 
        /// - - -
        /// </summary>
        public InputMap<string> Params
        {
            get => _params ?? (_params = new InputMap<string>());
            set => _params = value;
        }

        /// <summary>
        /// The ID of the project in which the resource belongs.
        /// If it is not provided, the provider project is used.
        /// </summary>
        [Input("project")]
        public Input<string>? Project { get; set; }

        /// <summary>
        /// Data transfer schedule. If the data source does not support a custom
        /// schedule, this should be empty. If it is empty, the default value for
        /// the data source will be used. The specified times are in UTC. Examples
        /// of valid format: 1st,3rd monday of month 15:30, every wed,fri of jan,
        /// jun 13:15, and first sunday of quarter 00:00. See more explanation
        /// about the format here:
        /// https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format
        /// NOTE: The minimum interval time between recurring transfers depends
        /// on the data source; refer to the documentation for your data source.
        /// </summary>
        [Input("schedule")]
        public Input<string>? Schedule { get; set; }

        /// <summary>
        /// Options customizing the data transfer schedule.
        /// Structure is documented below.
        /// </summary>
        [Input("scheduleOptions")]
        public Input<Inputs.DataTransferConfigScheduleOptionsArgs>? ScheduleOptions { get; set; }

        /// <summary>
        /// Different parameters are configured primarily using the the `params` field on this
        /// resource. This block contains the parameters which contain secrets or passwords so that they can be marked
        /// sensitive and hidden from plan output. The name of the field, eg: secret_access_key, will be the key
        /// in the `params` map in the api request.
        /// Credentials may not be specified in both locations and will cause an error. Changing from one location
        /// to a different credential configuration in the config will require an apply to update state.
        /// Structure is documented below.
        /// </summary>
        [Input("sensitiveParams")]
        public Input<Inputs.DataTransferConfigSensitiveParamsArgs>? SensitiveParams { get; set; }

        /// <summary>
        /// Service account email. If this field is set, transfer config will
        /// be created with this service account credentials. It requires that
        /// requesting user calling this API has permissions to act as this service account.
        /// </summary>
        [Input("serviceAccountName")]
        public Input<string>? ServiceAccountName { get; set; }

        public DataTransferConfigArgs()
        {
        }
        public static new DataTransferConfigArgs Empty => new DataTransferConfigArgs();
    }

    public sealed class DataTransferConfigState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The number of days to look back to automatically refresh the data.
        /// For example, if dataRefreshWindowDays = 10, then every day BigQuery
        /// reingests data for [today-10, today-1], rather than ingesting data for
        /// just [today-1]. Only valid if the data source supports the feature.
        /// Set the value to 0 to use the default value.
        /// </summary>
        [Input("dataRefreshWindowDays")]
        public Input<int>? DataRefreshWindowDays { get; set; }

        /// <summary>
        /// The data source id. Cannot be changed once the transfer config is created.
        /// </summary>
        [Input("dataSourceId")]
        public Input<string>? DataSourceId { get; set; }

        /// <summary>
        /// The BigQuery target dataset id.
        /// </summary>
        [Input("destinationDatasetId")]
        public Input<string>? DestinationDatasetId { get; set; }

        /// <summary>
        /// When set to true, no runs are scheduled for a given transfer.
        /// </summary>
        [Input("disabled")]
        public Input<bool>? Disabled { get; set; }

        /// <summary>
        /// The user specified display name for the transfer config.
        /// </summary>
        [Input("displayName")]
        public Input<string>? DisplayName { get; set; }

        /// <summary>
        /// Email notifications will be sent according to these preferences to the
        /// email address of the user who owns this transfer config.
        /// Structure is documented below.
        /// </summary>
        [Input("emailPreferences")]
        public Input<Inputs.DataTransferConfigEmailPreferencesGetArgs>? EmailPreferences { get; set; }

        /// <summary>
        /// Represents the encryption configuration for a transfer.
        /// Structure is documented below.
        /// </summary>
        [Input("encryptionConfiguration")]
        public Input<Inputs.DataTransferConfigEncryptionConfigurationGetArgs>? EncryptionConfiguration { get; set; }

        /// <summary>
        /// The geographic location where the transfer config should reside.
        /// Examples: US, EU, asia-northeast1. The default value is US.
        /// </summary>
        [Input("location")]
        public Input<string>? Location { get; set; }

        /// <summary>
        /// The resource name of the transfer config. Transfer config names have the
        /// form projects/{projectId}/locations/{location}/transferConfigs/{configId}
        /// or projects/{projectId}/transferConfigs/{configId},
        /// where configId is usually a uuid, but this is not required.
        /// The name is ignored when creating a transfer config.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// Pub/Sub topic where notifications will be sent after transfer runs
        /// associated with this transfer config finish.
        /// </summary>
        [Input("notificationPubsubTopic")]
        public Input<string>? NotificationPubsubTopic { get; set; }

        [Input("params")]
        private InputMap<string>? _params;

        /// <summary>
        /// Parameters specific to each data source. For more information see the bq tab in the 'Setting up a data transfer'
        /// section for each data source. For example the parameters for Cloud Storage transfers are listed here:
        /// https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
        /// **NOTE** : If you are attempting to update a parameter that cannot be updated (due to api limitations) please force recreation of the resource.
        /// 
        /// 
        /// - - -
        /// </summary>
        public InputMap<string> Params
        {
            get => _params ?? (_params = new InputMap<string>());
            set => _params = value;
        }

        /// <summary>
        /// The ID of the project in which the resource belongs.
        /// If it is not provided, the provider project is used.
        /// </summary>
        [Input("project")]
        public Input<string>? Project { get; set; }

        /// <summary>
        /// Data transfer schedule. If the data source does not support a custom
        /// schedule, this should be empty. If it is empty, the default value for
        /// the data source will be used. The specified times are in UTC. Examples
        /// of valid format: 1st,3rd monday of month 15:30, every wed,fri of jan,
        /// jun 13:15, and first sunday of quarter 00:00. See more explanation
        /// about the format here:
        /// https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format
        /// NOTE: The minimum interval time between recurring transfers depends
        /// on the data source; refer to the documentation for your data source.
        /// </summary>
        [Input("schedule")]
        public Input<string>? Schedule { get; set; }

        /// <summary>
        /// Options customizing the data transfer schedule.
        /// Structure is documented below.
        /// </summary>
        [Input("scheduleOptions")]
        public Input<Inputs.DataTransferConfigScheduleOptionsGetArgs>? ScheduleOptions { get; set; }

        /// <summary>
        /// Different parameters are configured primarily using the the `params` field on this
        /// resource. This block contains the parameters which contain secrets or passwords so that they can be marked
        /// sensitive and hidden from plan output. The name of the field, eg: secret_access_key, will be the key
        /// in the `params` map in the api request.
        /// Credentials may not be specified in both locations and will cause an error. Changing from one location
        /// to a different credential configuration in the config will require an apply to update state.
        /// Structure is documented below.
        /// </summary>
        [Input("sensitiveParams")]
        public Input<Inputs.DataTransferConfigSensitiveParamsGetArgs>? SensitiveParams { get; set; }

        /// <summary>
        /// Service account email. If this field is set, transfer config will
        /// be created with this service account credentials. It requires that
        /// requesting user calling this API has permissions to act as this service account.
        /// </summary>
        [Input("serviceAccountName")]
        public Input<string>? ServiceAccountName { get; set; }

        public DataTransferConfigState()
        {
        }
        public static new DataTransferConfigState Empty => new DataTransferConfigState();
    }
}
