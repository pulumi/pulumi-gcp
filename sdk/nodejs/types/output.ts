// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import { input as inputs, output as outputs } from "../types";

export namespace accesscontextmanager {
    export interface AccessLevelBasic {
        /**
         * How the conditions list should be combined to determine if a request
         * is granted this AccessLevel. If AND is used, each Condition in
         * conditions must be satisfied for the AccessLevel to be applied. If
         * OR is used, at least one Condition in conditions must be satisfied
         * for the AccessLevel to be applied.
         * Default value is `AND`.
         * Possible values are `AND` and `OR`.
         */
        combiningFunction?: string;
        /**
         * A set of requirements for the AccessLevel to be granted.
         * Structure is documented below.
         */
        conditions: outputs.accesscontextmanager.AccessLevelBasicCondition[];
    }

    export interface AccessLevelBasicCondition {
        /**
         * Device specific restrictions, all restrictions must hold for
         * the Condition to be true. If not specified, all devices are
         * allowed.
         * Structure is documented below.
         */
        devicePolicy?: outputs.accesscontextmanager.AccessLevelBasicConditionDevicePolicy;
        /**
         * A list of CIDR block IP subnetwork specification. May be IPv4
         * or IPv6.
         * Note that for a CIDR IP address block, the specified IP address
         * portion must be properly truncated (i.e. all the host bits must
         * be zero) or the input is considered malformed. For example,
         * "192.0.2.0/24" is accepted but "192.0.2.1/24" is not. Similarly,
         * for IPv6, "2001:db8::/32" is accepted whereas "2001:db8::1/32"
         * is not. The originating IP of a request must be in one of the
         * listed subnets in order for this Condition to be true.
         * If empty, all IP addresses are allowed.
         */
        ipSubnetworks?: string[];
        /**
         * An allowed list of members (users, service accounts).
         * Using groups is not supported yet.
         * The signed-in user originating the request must be a part of one
         * of the provided members. If not specified, a request may come
         * from any user (logged in/not logged in, not present in any
         * groups, etc.).
         * Formats: `user:{emailid}`, `serviceAccount:{emailid}`
         */
        members?: string[];
        /**
         * Whether to negate the Condition. If true, the Condition becomes
         * a NAND over its non-empty fields, each field must be false for
         * the Condition overall to be satisfied. Defaults to false.
         */
        negate?: boolean;
        /**
         * The request must originate from one of the provided
         * countries/regions.
         * Format: A valid ISO 3166-1 alpha-2 code.
         */
        regions?: string[];
        /**
         * A list of other access levels defined in the same Policy,
         * referenced by resource name. Referencing an AccessLevel which
         * does not exist is an error. All access levels listed must be
         * granted for the Condition to be true.
         * Format: accessPolicies/{policy_id}/accessLevels/{short_name}
         */
        requiredAccessLevels?: string[];
    }

    export interface AccessLevelBasicConditionDevicePolicy {
        /**
         * A list of allowed device management levels.
         * An empty list allows all management levels.
         * Each value may be one of `MANAGEMENT_UNSPECIFIED`, `NONE`, `BASIC`, and `COMPLETE`.
         */
        allowedDeviceManagementLevels?: string[];
        /**
         * A list of allowed encryptions statuses.
         * An empty list allows all statuses.
         * Each value may be one of `ENCRYPTION_UNSPECIFIED`, `ENCRYPTION_UNSUPPORTED`, `UNENCRYPTED`, and `ENCRYPTED`.
         */
        allowedEncryptionStatuses?: string[];
        /**
         * A list of allowed OS versions.
         * An empty list allows all types and all versions.
         * Structure is documented below.
         */
        osConstraints?: outputs.accesscontextmanager.AccessLevelBasicConditionDevicePolicyOsConstraint[];
        /**
         * Whether the device needs to be approved by the customer admin.
         */
        requireAdminApproval?: boolean;
        /**
         * Whether the device needs to be corp owned.
         */
        requireCorpOwned?: boolean;
        /**
         * Whether or not screenlock is required for the DevicePolicy
         * to be true. Defaults to false.
         */
        requireScreenLock?: boolean;
    }

    export interface AccessLevelBasicConditionDevicePolicyOsConstraint {
        /**
         * The minimum allowed OS version. If not set, any version
         * of this OS satisfies the constraint.
         * Format: "major.minor.patch" such as "10.5.301", "9.2.1".
         */
        minimumVersion?: string;
        /**
         * The operating system type of the device.
         * Possible values are `OS_UNSPECIFIED`, `DESKTOP_MAC`, `DESKTOP_WINDOWS`, `DESKTOP_LINUX`, `DESKTOP_CHROME_OS`, `ANDROID`, and `IOS`.
         */
        osType: string;
        /**
         * If you specify DESKTOP_CHROME_OS for osType, you can optionally include requireVerifiedChromeOs to require Chrome Verified Access.
         */
        requireVerifiedChromeOs?: boolean;
    }

    export interface AccessLevelConditionDevicePolicy {
        /**
         * A list of allowed device management levels.
         * An empty list allows all management levels.
         * Each value may be one of `MANAGEMENT_UNSPECIFIED`, `NONE`, `BASIC`, and `COMPLETE`.
         */
        allowedDeviceManagementLevels?: string[];
        /**
         * A list of allowed encryptions statuses.
         * An empty list allows all statuses.
         * Each value may be one of `ENCRYPTION_UNSPECIFIED`, `ENCRYPTION_UNSUPPORTED`, `UNENCRYPTED`, and `ENCRYPTED`.
         */
        allowedEncryptionStatuses?: string[];
        /**
         * A list of allowed OS versions.
         * An empty list allows all types and all versions.
         * Structure is documented below.
         */
        osConstraints?: outputs.accesscontextmanager.AccessLevelConditionDevicePolicyOsConstraint[];
        /**
         * Whether the device needs to be approved by the customer admin.
         */
        requireAdminApproval?: boolean;
        /**
         * Whether the device needs to be corp owned.
         */
        requireCorpOwned?: boolean;
        /**
         * Whether or not screenlock is required for the DevicePolicy
         * to be true. Defaults to false.
         */
        requireScreenLock?: boolean;
    }

    export interface AccessLevelConditionDevicePolicyOsConstraint {
        /**
         * The minimum allowed OS version. If not set, any version
         * of this OS satisfies the constraint.
         * Format: "major.minor.patch" such as "10.5.301", "9.2.1".
         */
        minimumVersion?: string;
        /**
         * The operating system type of the device.
         * Possible values are `OS_UNSPECIFIED`, `DESKTOP_MAC`, `DESKTOP_WINDOWS`, `DESKTOP_LINUX`, `DESKTOP_CHROME_OS`, `ANDROID`, and `IOS`.
         */
        osType: string;
    }

    export interface AccessLevelCustom {
        /**
         * Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language.
         * This page details the objects and attributes that are used to the build the CEL expressions for
         * custom access levels - https://cloud.google.com/access-context-manager/docs/custom-access-level-spec.
         * Structure is documented below.
         */
        expr: outputs.accesscontextmanager.AccessLevelCustomExpr;
    }

    export interface AccessLevelCustomExpr {
        /**
         * Description of the expression
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * String indicating the location of the expression for error reporting, e.g. a file name and a position in the file
         */
        location?: string;
        /**
         * Title for the expression, i.e. a short string describing its purpose.
         */
        title?: string;
    }

    export interface AccessLevelsAccessLevel {
        /**
         * A set of predefined conditions for the access level and a combining function.
         * Structure is documented below.
         */
        basic?: outputs.accesscontextmanager.AccessLevelsAccessLevelBasic;
        /**
         * Custom access level conditions are set using the Cloud Common Expression Language to represent the necessary conditions for the level to apply to a request.
         * See CEL spec at: https://github.com/google/cel-spec.
         * Structure is documented below.
         */
        custom?: outputs.accesscontextmanager.AccessLevelsAccessLevelCustom;
        /**
         * Description of the expression
         */
        description?: string;
        /**
         * Resource name for the Access Level. The shortName component must begin
         * with a letter and only include alphanumeric and '_'.
         * Format: accessPolicies/{policy_id}/accessLevels/{short_name}
         */
        name: string;
        /**
         * Title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface AccessLevelsAccessLevelBasic {
        /**
         * How the conditions list should be combined to determine if a request
         * is granted this AccessLevel. If AND is used, each Condition in
         * conditions must be satisfied for the AccessLevel to be applied. If
         * OR is used, at least one Condition in conditions must be satisfied
         * for the AccessLevel to be applied.
         * Default value is `AND`.
         * Possible values are `AND` and `OR`.
         */
        combiningFunction?: string;
        /**
         * A set of requirements for the AccessLevel to be granted.
         * Structure is documented below.
         */
        conditions: outputs.accesscontextmanager.AccessLevelsAccessLevelBasicCondition[];
    }

    export interface AccessLevelsAccessLevelBasicCondition {
        /**
         * Device specific restrictions, all restrictions must hold for
         * the Condition to be true. If not specified, all devices are
         * allowed.
         * Structure is documented below.
         */
        devicePolicy?: outputs.accesscontextmanager.AccessLevelsAccessLevelBasicConditionDevicePolicy;
        /**
         * A list of CIDR block IP subnetwork specification. May be IPv4
         * or IPv6.
         * Note that for a CIDR IP address block, the specified IP address
         * portion must be properly truncated (i.e. all the host bits must
         * be zero) or the input is considered malformed. For example,
         * "192.0.2.0/24" is accepted but "192.0.2.1/24" is not. Similarly,
         * for IPv6, "2001:db8::/32" is accepted whereas "2001:db8::1/32"
         * is not. The originating IP of a request must be in one of the
         * listed subnets in order for this Condition to be true.
         * If empty, all IP addresses are allowed.
         */
        ipSubnetworks?: string[];
        /**
         * An allowed list of members (users, service accounts).
         * Using groups is not supported yet.
         * The signed-in user originating the request must be a part of one
         * of the provided members. If not specified, a request may come
         * from any user (logged in/not logged in, not present in any
         * groups, etc.).
         * Formats: `user:{emailid}`, `serviceAccount:{emailid}`
         */
        members?: string[];
        /**
         * Whether to negate the Condition. If true, the Condition becomes
         * a NAND over its non-empty fields, each field must be false for
         * the Condition overall to be satisfied. Defaults to false.
         */
        negate?: boolean;
        /**
         * The request must originate from one of the provided
         * countries/regions.
         * Format: A valid ISO 3166-1 alpha-2 code.
         */
        regions?: string[];
        /**
         * A list of other access levels defined in the same Policy,
         * referenced by resource name. Referencing an AccessLevel which
         * does not exist is an error. All access levels listed must be
         * granted for the Condition to be true.
         * Format: accessPolicies/{policy_id}/accessLevels/{short_name}
         */
        requiredAccessLevels?: string[];
    }

    export interface AccessLevelsAccessLevelBasicConditionDevicePolicy {
        /**
         * A list of allowed device management levels.
         * An empty list allows all management levels.
         * Each value may be one of `MANAGEMENT_UNSPECIFIED`, `NONE`, `BASIC`, and `COMPLETE`.
         */
        allowedDeviceManagementLevels?: string[];
        /**
         * A list of allowed encryptions statuses.
         * An empty list allows all statuses.
         * Each value may be one of `ENCRYPTION_UNSPECIFIED`, `ENCRYPTION_UNSUPPORTED`, `UNENCRYPTED`, and `ENCRYPTED`.
         */
        allowedEncryptionStatuses?: string[];
        /**
         * A list of allowed OS versions.
         * An empty list allows all types and all versions.
         * Structure is documented below.
         */
        osConstraints?: outputs.accesscontextmanager.AccessLevelsAccessLevelBasicConditionDevicePolicyOsConstraint[];
        /**
         * Whether the device needs to be approved by the customer admin.
         */
        requireAdminApproval?: boolean;
        /**
         * Whether the device needs to be corp owned.
         */
        requireCorpOwned?: boolean;
        /**
         * Whether or not screenlock is required for the DevicePolicy
         * to be true. Defaults to false.
         */
        requireScreenLock?: boolean;
    }

    export interface AccessLevelsAccessLevelBasicConditionDevicePolicyOsConstraint {
        /**
         * The minimum allowed OS version. If not set, any version
         * of this OS satisfies the constraint.
         * Format: "major.minor.patch" such as "10.5.301", "9.2.1".
         */
        minimumVersion?: string;
        /**
         * The operating system type of the device.
         * Possible values are `OS_UNSPECIFIED`, `DESKTOP_MAC`, `DESKTOP_WINDOWS`, `DESKTOP_LINUX`, `DESKTOP_CHROME_OS`, `ANDROID`, and `IOS`.
         */
        osType: string;
    }

    export interface AccessLevelsAccessLevelCustom {
        /**
         * Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language.
         * This page details the objects and attributes that are used to the build the CEL expressions for
         * custom access levels - https://cloud.google.com/access-context-manager/docs/custom-access-level-spec.
         * Structure is documented below.
         */
        expr: outputs.accesscontextmanager.AccessLevelsAccessLevelCustomExpr;
    }

    export interface AccessLevelsAccessLevelCustomExpr {
        /**
         * Description of the expression
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * String indicating the location of the expression for error reporting, e.g. a file name and a position in the file
         */
        location?: string;
        /**
         * Title for the expression, i.e. a short string describing its purpose.
         */
        title?: string;
    }

    export interface AccessPolicyIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface AccessPolicyIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ServicePerimeterSpec {
        /**
         * A list of AccessLevel resource names that allow resources within
         * the ServicePerimeter to be accessed from the internet.
         * AccessLevels listed must be in the same policy as this
         * ServicePerimeter. Referencing a nonexistent AccessLevel is a
         * syntax error. If no AccessLevel names are listed, resources within
         * the perimeter can only be accessed via GCP calls with request
         * origins within the perimeter. For Service Perimeter Bridge, must
         * be empty.
         * Format: accessPolicies/{policy_id}/accessLevels/{access_level_name}
         */
        accessLevels?: string[];
        /**
         * List of EgressPolicies to apply to the perimeter. A perimeter may
         * have multiple EgressPolicies, each of which is evaluated separately.
         * Access is granted if any EgressPolicy grants it. Must be empty for
         * a perimeter bridge.
         * Structure is documented below.
         */
        egressPolicies?: outputs.accesscontextmanager.ServicePerimeterSpecEgressPolicy[];
        /**
         * List of `IngressPolicies` to apply to the perimeter. A perimeter may
         * have multiple `IngressPolicies`, each of which is evaluated
         * separately. Access is granted if any `Ingress Policy` grants it.
         * Must be empty for a perimeter bridge.
         * Structure is documented below.
         */
        ingressPolicies?: outputs.accesscontextmanager.ServicePerimeterSpecIngressPolicy[];
        /**
         * A list of resources, currently only projects in the form
         * `projects/<projectnumber>`, that match this to stanza. A request matches
         * if it contains a resource in this list. If * is specified for resources,
         * then this `EgressTo` rule will authorize access to all resources outside
         * the perimeter.
         */
        resources?: string[];
        /**
         * GCP services that are subject to the Service Perimeter
         * restrictions. Must contain a list of services. For example, if
         * `storage.googleapis.com` is specified, access to the storage
         * buckets inside the perimeter must meet the perimeter's access
         * restrictions.
         */
        restrictedServices?: string[];
        /**
         * Specifies how APIs are allowed to communicate within the Service
         * Perimeter.
         * Structure is documented below.
         */
        vpcAccessibleServices?: outputs.accesscontextmanager.ServicePerimeterSpecVpcAccessibleServices;
    }

    export interface ServicePerimeterSpecEgressPolicy {
        /**
         * Defines conditions on the source of a request causing this `EgressPolicy` to apply.
         * Structure is documented below.
         */
        egressFrom?: outputs.accesscontextmanager.ServicePerimeterSpecEgressPolicyEgressFrom;
        /**
         * Defines the conditions on the `ApiOperation` and destination resources that
         * cause this `EgressPolicy` to apply.
         * Structure is documented below.
         */
        egressTo?: outputs.accesscontextmanager.ServicePerimeterSpecEgressPolicyEgressTo;
    }

    export interface ServicePerimeterSpecEgressPolicyEgressFrom {
        /**
         * A list of identities that are allowed access through this `EgressPolicy`.
         * Should be in the format of email address. The email address should
         * represent individual user or service account only.
         */
        identities?: string[];
        /**
         * Specifies the type of identities that are allowed access to outside the
         * perimeter. If left unspecified, then members of `identities` field will
         * be allowed access.
         * Possible values are `IDENTITY_TYPE_UNSPECIFIED`, `ANY_IDENTITY`, `ANY_USER_ACCOUNT`, and `ANY_SERVICE_ACCOUNT`.
         */
        identityType?: string;
    }

    export interface ServicePerimeterSpecEgressPolicyEgressTo {
        /**
         * A list of `ApiOperations` that this egress rule applies to. A request matches
         * if it contains an operation/service in this list.
         * Structure is documented below.
         */
        operations?: outputs.accesscontextmanager.ServicePerimeterSpecEgressPolicyEgressToOperation[];
        /**
         * A list of resources, currently only projects in the form
         * `projects/<projectnumber>`, that match this to stanza. A request matches
         * if it contains a resource in this list. If * is specified for resources,
         * then this `EgressTo` rule will authorize access to all resources outside
         * the perimeter.
         */
        resources?: string[];
    }

    export interface ServicePerimeterSpecEgressPolicyEgressToOperation {
        /**
         * API methods or permissions to allow. Method or permission must belong
         * to the service specified by `serviceName` field. A single MethodSelector
         * entry with `*` specified for the `method` field will allow all methods
         * AND permissions for the service specified in `serviceName`.
         * Structure is documented below.
         */
        methodSelectors?: outputs.accesscontextmanager.ServicePerimeterSpecEgressPolicyEgressToOperationMethodSelector[];
        /**
         * The name of the API whose methods or permissions the `IngressPolicy` or
         * `EgressPolicy` want to allow. A single `ApiOperation` with serviceName
         * field set to `*` will allow all methods AND permissions for all services.
         */
        serviceName?: string;
    }

    export interface ServicePerimeterSpecEgressPolicyEgressToOperationMethodSelector {
        /**
         * Value for `method` should be a valid method name for the corresponding
         * `serviceName` in `ApiOperation`. If `*` used as value for method,
         * then ALL methods and permissions are allowed.
         */
        method?: string;
        /**
         * Value for permission should be a valid Cloud IAM permission for the
         * corresponding `serviceName` in `ApiOperation`.
         */
        permission?: string;
    }

    export interface ServicePerimeterSpecIngressPolicy {
        /**
         * Defines the conditions on the source of a request causing this `IngressPolicy`
         * to apply.
         * Structure is documented below.
         */
        ingressFrom?: outputs.accesscontextmanager.ServicePerimeterSpecIngressPolicyIngressFrom;
        /**
         * Defines the conditions on the `ApiOperation` and request destination that cause
         * this `IngressPolicy` to apply.
         * Structure is documented below.
         */
        ingressTo?: outputs.accesscontextmanager.ServicePerimeterSpecIngressPolicyIngressTo;
    }

    export interface ServicePerimeterSpecIngressPolicyIngressFrom {
        /**
         * A list of identities that are allowed access through this `EgressPolicy`.
         * Should be in the format of email address. The email address should
         * represent individual user or service account only.
         */
        identities?: string[];
        /**
         * Specifies the type of identities that are allowed access to outside the
         * perimeter. If left unspecified, then members of `identities` field will
         * be allowed access.
         * Possible values are `IDENTITY_TYPE_UNSPECIFIED`, `ANY_IDENTITY`, `ANY_USER_ACCOUNT`, and `ANY_SERVICE_ACCOUNT`.
         */
        identityType?: string;
        /**
         * Sources that this `IngressPolicy` authorizes access from.
         * Structure is documented below.
         */
        sources?: outputs.accesscontextmanager.ServicePerimeterSpecIngressPolicyIngressFromSource[];
    }

    export interface ServicePerimeterSpecIngressPolicyIngressFromSource {
        /**
         * An `AccessLevel` resource name that allow resources within the
         * `ServicePerimeters` to be accessed from the internet. `AccessLevels` listed
         * must be in the same policy as this `ServicePerimeter`. Referencing a nonexistent
         * `AccessLevel` will cause an error. If no `AccessLevel` names are listed,
         * resources within the perimeter can only be accessed via Google Cloud calls
         * with request origins within the perimeter.
         * Example `accessPolicies/MY_POLICY/accessLevels/MY_LEVEL.`
         * If * is specified, then all IngressSources will be allowed.
         */
        accessLevel?: string;
        /**
         * A Google Cloud resource that is allowed to ingress the perimeter.
         * Requests from these resources will be allowed to access perimeter data.
         * Currently only projects are allowed. Format `projects/{project_number}`
         * The project may be in any Google Cloud organization, not just the
         * organization that the perimeter is defined in. `*` is not allowed, the case
         * of allowing all Google Cloud resources only is not supported.
         */
        resource?: string;
    }

    export interface ServicePerimeterSpecIngressPolicyIngressTo {
        /**
         * A list of `ApiOperations` that this egress rule applies to. A request matches
         * if it contains an operation/service in this list.
         * Structure is documented below.
         */
        operations?: outputs.accesscontextmanager.ServicePerimeterSpecIngressPolicyIngressToOperation[];
        /**
         * A list of resources, currently only projects in the form
         * `projects/<projectnumber>`, that match this to stanza. A request matches
         * if it contains a resource in this list. If * is specified for resources,
         * then this `EgressTo` rule will authorize access to all resources outside
         * the perimeter.
         */
        resources?: string[];
    }

    export interface ServicePerimeterSpecIngressPolicyIngressToOperation {
        /**
         * API methods or permissions to allow. Method or permission must belong
         * to the service specified by `serviceName` field. A single MethodSelector
         * entry with `*` specified for the `method` field will allow all methods
         * AND permissions for the service specified in `serviceName`.
         * Structure is documented below.
         */
        methodSelectors?: outputs.accesscontextmanager.ServicePerimeterSpecIngressPolicyIngressToOperationMethodSelector[];
        /**
         * The name of the API whose methods or permissions the `IngressPolicy` or
         * `EgressPolicy` want to allow. A single `ApiOperation` with serviceName
         * field set to `*` will allow all methods AND permissions for all services.
         */
        serviceName?: string;
    }

    export interface ServicePerimeterSpecIngressPolicyIngressToOperationMethodSelector {
        /**
         * Value for `method` should be a valid method name for the corresponding
         * `serviceName` in `ApiOperation`. If `*` used as value for method,
         * then ALL methods and permissions are allowed.
         */
        method?: string;
        /**
         * Value for permission should be a valid Cloud IAM permission for the
         * corresponding `serviceName` in `ApiOperation`.
         */
        permission?: string;
    }

    export interface ServicePerimeterSpecVpcAccessibleServices {
        /**
         * The list of APIs usable within the Service Perimeter.
         * Must be empty unless `enableRestriction` is True.
         */
        allowedServices?: string[];
        /**
         * Whether to restrict API calls within the Service Perimeter to the
         * list of APIs specified in 'allowedServices'.
         */
        enableRestriction?: boolean;
    }

    export interface ServicePerimeterStatus {
        /**
         * A list of AccessLevel resource names that allow resources within
         * the ServicePerimeter to be accessed from the internet.
         * AccessLevels listed must be in the same policy as this
         * ServicePerimeter. Referencing a nonexistent AccessLevel is a
         * syntax error. If no AccessLevel names are listed, resources within
         * the perimeter can only be accessed via GCP calls with request
         * origins within the perimeter. For Service Perimeter Bridge, must
         * be empty.
         * Format: accessPolicies/{policy_id}/accessLevels/{access_level_name}
         */
        accessLevels?: string[];
        /**
         * List of EgressPolicies to apply to the perimeter. A perimeter may
         * have multiple EgressPolicies, each of which is evaluated separately.
         * Access is granted if any EgressPolicy grants it. Must be empty for
         * a perimeter bridge.
         * Structure is documented below.
         */
        egressPolicies?: outputs.accesscontextmanager.ServicePerimeterStatusEgressPolicy[];
        /**
         * List of `IngressPolicies` to apply to the perimeter. A perimeter may
         * have multiple `IngressPolicies`, each of which is evaluated
         * separately. Access is granted if any `Ingress Policy` grants it.
         * Must be empty for a perimeter bridge.
         * Structure is documented below.
         */
        ingressPolicies?: outputs.accesscontextmanager.ServicePerimeterStatusIngressPolicy[];
        /**
         * A list of resources, currently only projects in the form
         * `projects/<projectnumber>`, that match this to stanza. A request matches
         * if it contains a resource in this list. If * is specified for resources,
         * then this `EgressTo` rule will authorize access to all resources outside
         * the perimeter.
         */
        resources?: string[];
        /**
         * GCP services that are subject to the Service Perimeter
         * restrictions. Must contain a list of services. For example, if
         * `storage.googleapis.com` is specified, access to the storage
         * buckets inside the perimeter must meet the perimeter's access
         * restrictions.
         */
        restrictedServices?: string[];
        /**
         * Specifies how APIs are allowed to communicate within the Service
         * Perimeter.
         * Structure is documented below.
         */
        vpcAccessibleServices?: outputs.accesscontextmanager.ServicePerimeterStatusVpcAccessibleServices;
    }

    export interface ServicePerimeterStatusEgressPolicy {
        /**
         * Defines conditions on the source of a request causing this `EgressPolicy` to apply.
         * Structure is documented below.
         */
        egressFrom?: outputs.accesscontextmanager.ServicePerimeterStatusEgressPolicyEgressFrom;
        /**
         * Defines the conditions on the `ApiOperation` and destination resources that
         * cause this `EgressPolicy` to apply.
         * Structure is documented below.
         */
        egressTo?: outputs.accesscontextmanager.ServicePerimeterStatusEgressPolicyEgressTo;
    }

    export interface ServicePerimeterStatusEgressPolicyEgressFrom {
        /**
         * A list of identities that are allowed access through this `EgressPolicy`.
         * Should be in the format of email address. The email address should
         * represent individual user or service account only.
         */
        identities?: string[];
        /**
         * Specifies the type of identities that are allowed access to outside the
         * perimeter. If left unspecified, then members of `identities` field will
         * be allowed access.
         * Possible values are `IDENTITY_TYPE_UNSPECIFIED`, `ANY_IDENTITY`, `ANY_USER_ACCOUNT`, and `ANY_SERVICE_ACCOUNT`.
         */
        identityType?: string;
    }

    export interface ServicePerimeterStatusEgressPolicyEgressTo {
        /**
         * A list of `ApiOperations` that this egress rule applies to. A request matches
         * if it contains an operation/service in this list.
         * Structure is documented below.
         */
        operations?: outputs.accesscontextmanager.ServicePerimeterStatusEgressPolicyEgressToOperation[];
        /**
         * A list of resources, currently only projects in the form
         * `projects/<projectnumber>`, that match this to stanza. A request matches
         * if it contains a resource in this list. If * is specified for resources,
         * then this `EgressTo` rule will authorize access to all resources outside
         * the perimeter.
         */
        resources?: string[];
    }

    export interface ServicePerimeterStatusEgressPolicyEgressToOperation {
        /**
         * API methods or permissions to allow. Method or permission must belong
         * to the service specified by `serviceName` field. A single MethodSelector
         * entry with `*` specified for the `method` field will allow all methods
         * AND permissions for the service specified in `serviceName`.
         * Structure is documented below.
         */
        methodSelectors?: outputs.accesscontextmanager.ServicePerimeterStatusEgressPolicyEgressToOperationMethodSelector[];
        /**
         * The name of the API whose methods or permissions the `IngressPolicy` or
         * `EgressPolicy` want to allow. A single `ApiOperation` with serviceName
         * field set to `*` will allow all methods AND permissions for all services.
         */
        serviceName?: string;
    }

    export interface ServicePerimeterStatusEgressPolicyEgressToOperationMethodSelector {
        /**
         * Value for `method` should be a valid method name for the corresponding
         * `serviceName` in `ApiOperation`. If `*` used as value for method,
         * then ALL methods and permissions are allowed.
         */
        method?: string;
        /**
         * Value for permission should be a valid Cloud IAM permission for the
         * corresponding `serviceName` in `ApiOperation`.
         */
        permission?: string;
    }

    export interface ServicePerimeterStatusIngressPolicy {
        /**
         * Defines the conditions on the source of a request causing this `IngressPolicy`
         * to apply.
         * Structure is documented below.
         */
        ingressFrom?: outputs.accesscontextmanager.ServicePerimeterStatusIngressPolicyIngressFrom;
        /**
         * Defines the conditions on the `ApiOperation` and request destination that cause
         * this `IngressPolicy` to apply.
         * Structure is documented below.
         */
        ingressTo?: outputs.accesscontextmanager.ServicePerimeterStatusIngressPolicyIngressTo;
    }

    export interface ServicePerimeterStatusIngressPolicyIngressFrom {
        /**
         * A list of identities that are allowed access through this `EgressPolicy`.
         * Should be in the format of email address. The email address should
         * represent individual user or service account only.
         */
        identities?: string[];
        /**
         * Specifies the type of identities that are allowed access to outside the
         * perimeter. If left unspecified, then members of `identities` field will
         * be allowed access.
         * Possible values are `IDENTITY_TYPE_UNSPECIFIED`, `ANY_IDENTITY`, `ANY_USER_ACCOUNT`, and `ANY_SERVICE_ACCOUNT`.
         */
        identityType?: string;
        /**
         * Sources that this `IngressPolicy` authorizes access from.
         * Structure is documented below.
         */
        sources?: outputs.accesscontextmanager.ServicePerimeterStatusIngressPolicyIngressFromSource[];
    }

    export interface ServicePerimeterStatusIngressPolicyIngressFromSource {
        /**
         * An `AccessLevel` resource name that allow resources within the
         * `ServicePerimeters` to be accessed from the internet. `AccessLevels` listed
         * must be in the same policy as this `ServicePerimeter`. Referencing a nonexistent
         * `AccessLevel` will cause an error. If no `AccessLevel` names are listed,
         * resources within the perimeter can only be accessed via Google Cloud calls
         * with request origins within the perimeter.
         * Example `accessPolicies/MY_POLICY/accessLevels/MY_LEVEL.`
         * If * is specified, then all IngressSources will be allowed.
         */
        accessLevel?: string;
        /**
         * A Google Cloud resource that is allowed to ingress the perimeter.
         * Requests from these resources will be allowed to access perimeter data.
         * Currently only projects are allowed. Format `projects/{project_number}`
         * The project may be in any Google Cloud organization, not just the
         * organization that the perimeter is defined in. `*` is not allowed, the case
         * of allowing all Google Cloud resources only is not supported.
         */
        resource?: string;
    }

    export interface ServicePerimeterStatusIngressPolicyIngressTo {
        /**
         * A list of `ApiOperations` that this egress rule applies to. A request matches
         * if it contains an operation/service in this list.
         * Structure is documented below.
         */
        operations?: outputs.accesscontextmanager.ServicePerimeterStatusIngressPolicyIngressToOperation[];
        /**
         * A list of resources, currently only projects in the form
         * `projects/<projectnumber>`, that match this to stanza. A request matches
         * if it contains a resource in this list. If * is specified for resources,
         * then this `EgressTo` rule will authorize access to all resources outside
         * the perimeter.
         */
        resources?: string[];
    }

    export interface ServicePerimeterStatusIngressPolicyIngressToOperation {
        /**
         * API methods or permissions to allow. Method or permission must belong
         * to the service specified by `serviceName` field. A single MethodSelector
         * entry with `*` specified for the `method` field will allow all methods
         * AND permissions for the service specified in `serviceName`.
         * Structure is documented below.
         */
        methodSelectors?: outputs.accesscontextmanager.ServicePerimeterStatusIngressPolicyIngressToOperationMethodSelector[];
        /**
         * The name of the API whose methods or permissions the `IngressPolicy` or
         * `EgressPolicy` want to allow. A single `ApiOperation` with serviceName
         * field set to `*` will allow all methods AND permissions for all services.
         */
        serviceName?: string;
    }

    export interface ServicePerimeterStatusIngressPolicyIngressToOperationMethodSelector {
        /**
         * Value for `method` should be a valid method name for the corresponding
         * `serviceName` in `ApiOperation`. If `*` used as value for method,
         * then ALL methods and permissions are allowed.
         */
        method?: string;
        /**
         * Value for permission should be a valid Cloud IAM permission for the
         * corresponding `serviceName` in `ApiOperation`.
         */
        permission?: string;
    }

    export interface ServicePerimeterStatusVpcAccessibleServices {
        /**
         * The list of APIs usable within the Service Perimeter.
         * Must be empty unless `enableRestriction` is True.
         */
        allowedServices?: string[];
        /**
         * Whether to restrict API calls within the Service Perimeter to the
         * list of APIs specified in 'allowedServices'.
         */
        enableRestriction?: boolean;
    }

    export interface ServicePerimetersServicePerimeter {
        /**
         * -
         * Time the AccessPolicy was created in UTC.
         */
        createTime: string;
        /**
         * Description of the ServicePerimeter and its use. Does not affect
         * behavior.
         */
        description?: string;
        /**
         * Resource name for the ServicePerimeter. The shortName component must
         * begin with a letter and only include alphanumeric and '_'.
         * Format: accessPolicies/{policy_id}/servicePerimeters/{short_name}
         */
        name: string;
        /**
         * Specifies the type of the Perimeter. There are two types: regular and
         * bridge. Regular Service Perimeter contains resources, access levels,
         * and restricted services. Every resource can be in at most
         * ONE regular Service Perimeter.
         * In addition to being in a regular service perimeter, a resource can also
         * be in zero or more perimeter bridges. A perimeter bridge only contains
         * resources. Cross project operations are permitted if all effected
         * resources share some perimeter (whether bridge or regular). Perimeter
         * Bridge does not contain access levels or services: those are governed
         * entirely by the regular perimeter that resource is in.
         * Perimeter Bridges are typically useful when building more complex
         * topologies with many independent perimeters that need to share some data
         * with a common perimeter, but should not be able to share data among
         * themselves.
         * Default value is `PERIMETER_TYPE_REGULAR`.
         * Possible values are `PERIMETER_TYPE_REGULAR` and `PERIMETER_TYPE_BRIDGE`.
         */
        perimeterType?: string;
        /**
         * Proposed (or dry run) ServicePerimeter configuration.
         * This configuration allows to specify and test ServicePerimeter configuration
         * without enforcing actual access restrictions. Only allowed to be set when
         * the `useExplicitDryRunSpec` flag is set.
         * Structure is documented below.
         */
        spec?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpec;
        /**
         * ServicePerimeter configuration. Specifies sets of resources,
         * restricted services and access levels that determine
         * perimeter content and boundaries.
         * Structure is documented below.
         */
        status?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatus;
        /**
         * Human readable title. Must be unique within the Policy.
         */
        title: string;
        /**
         * -
         * Time the AccessPolicy was updated in UTC.
         */
        updateTime: string;
        /**
         * Use explicit dry run spec flag. Ordinarily, a dry-run spec implicitly exists
         * for all Service Perimeters, and that spec is identical to the status for those
         * Service Perimeters. When this flag is set, it inhibits the generation of the
         * implicit spec, thereby allowing the user to explicitly provide a
         * configuration ("spec") to use in a dry-run version of the Service Perimeter.
         * This allows the user to test changes to the enforced config ("status") without
         * actually enforcing them. This testing is done through analyzing the differences
         * between currently enforced and suggested restrictions. useExplicitDryRunSpec must
         * bet set to True if any of the fields in the spec are set to non-default values.
         */
        useExplicitDryRunSpec?: boolean;
    }

    export interface ServicePerimetersServicePerimeterSpec {
        /**
         * A list of AccessLevel resource names that allow resources within
         * the ServicePerimeter to be accessed from the internet.
         * AccessLevels listed must be in the same policy as this
         * ServicePerimeter. Referencing a nonexistent AccessLevel is a
         * syntax error. If no AccessLevel names are listed, resources within
         * the perimeter can only be accessed via GCP calls with request
         * origins within the perimeter. For Service Perimeter Bridge, must
         * be empty.
         * Format: accessPolicies/{policy_id}/accessLevels/{access_level_name}
         */
        accessLevels?: string[];
        /**
         * List of EgressPolicies to apply to the perimeter. A perimeter may
         * have multiple EgressPolicies, each of which is evaluated separately.
         * Access is granted if any EgressPolicy grants it. Must be empty for
         * a perimeter bridge.
         * Structure is documented below.
         */
        egressPolicies?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpecEgressPolicy[];
        /**
         * List of `IngressPolicies` to apply to the perimeter. A perimeter may
         * have multiple `IngressPolicies`, each of which is evaluated
         * separately. Access is granted if any `Ingress Policy` grants it.
         * Must be empty for a perimeter bridge.
         * Structure is documented below.
         */
        ingressPolicies?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpecIngressPolicy[];
        /**
         * A list of resources, currently only projects in the form
         * `projects/<projectnumber>`, that match this to stanza. A request matches
         * if it contains a resource in this list. If * is specified for resources,
         * then this `EgressTo` rule will authorize access to all resources outside
         * the perimeter.
         */
        resources?: string[];
        /**
         * GCP services that are subject to the Service Perimeter
         * restrictions. Must contain a list of services. For example, if
         * `storage.googleapis.com` is specified, access to the storage
         * buckets inside the perimeter must meet the perimeter's access
         * restrictions.
         */
        restrictedServices?: string[];
        /**
         * Specifies how APIs are allowed to communicate within the Service
         * Perimeter.
         * Structure is documented below.
         */
        vpcAccessibleServices?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpecVpcAccessibleServices;
    }

    export interface ServicePerimetersServicePerimeterSpecEgressPolicy {
        /**
         * Defines conditions on the source of a request causing this `EgressPolicy` to apply.
         * Structure is documented below.
         */
        egressFrom?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpecEgressPolicyEgressFrom;
        /**
         * Defines the conditions on the `ApiOperation` and destination resources that
         * cause this `EgressPolicy` to apply.
         * Structure is documented below.
         */
        egressTo?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpecEgressPolicyEgressTo;
    }

    export interface ServicePerimetersServicePerimeterSpecEgressPolicyEgressFrom {
        /**
         * A list of identities that are allowed access through this `EgressPolicy`.
         * Should be in the format of email address. The email address should
         * represent individual user or service account only.
         */
        identities?: string[];
        /**
         * Specifies the type of identities that are allowed access to outside the
         * perimeter. If left unspecified, then members of `identities` field will
         * be allowed access.
         * Possible values are `IDENTITY_TYPE_UNSPECIFIED`, `ANY_IDENTITY`, `ANY_USER_ACCOUNT`, and `ANY_SERVICE_ACCOUNT`.
         */
        identityType?: string;
    }

    export interface ServicePerimetersServicePerimeterSpecEgressPolicyEgressTo {
        /**
         * A list of `ApiOperations` that this egress rule applies to. A request matches
         * if it contains an operation/service in this list.
         * Structure is documented below.
         */
        operations?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpecEgressPolicyEgressToOperation[];
        /**
         * A list of resources, currently only projects in the form
         * `projects/<projectnumber>`, that match this to stanza. A request matches
         * if it contains a resource in this list. If * is specified for resources,
         * then this `EgressTo` rule will authorize access to all resources outside
         * the perimeter.
         */
        resources?: string[];
    }

    export interface ServicePerimetersServicePerimeterSpecEgressPolicyEgressToOperation {
        /**
         * API methods or permissions to allow. Method or permission must belong
         * to the service specified by `serviceName` field. A single MethodSelector
         * entry with `*` specified for the `method` field will allow all methods
         * AND permissions for the service specified in `serviceName`.
         * Structure is documented below.
         */
        methodSelectors?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpecEgressPolicyEgressToOperationMethodSelector[];
        /**
         * The name of the API whose methods or permissions the `IngressPolicy` or
         * `EgressPolicy` want to allow. A single `ApiOperation` with serviceName
         * field set to `*` will allow all methods AND permissions for all services.
         */
        serviceName?: string;
    }

    export interface ServicePerimetersServicePerimeterSpecEgressPolicyEgressToOperationMethodSelector {
        /**
         * Value for `method` should be a valid method name for the corresponding
         * `serviceName` in `ApiOperation`. If `*` used as value for method,
         * then ALL methods and permissions are allowed.
         */
        method?: string;
        /**
         * Value for permission should be a valid Cloud IAM permission for the
         * corresponding `serviceName` in `ApiOperation`.
         */
        permission?: string;
    }

    export interface ServicePerimetersServicePerimeterSpecIngressPolicy {
        /**
         * Defines the conditions on the source of a request causing this `IngressPolicy`
         * to apply.
         * Structure is documented below.
         */
        ingressFrom?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpecIngressPolicyIngressFrom;
        /**
         * Defines the conditions on the `ApiOperation` and request destination that cause
         * this `IngressPolicy` to apply.
         * Structure is documented below.
         */
        ingressTo?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpecIngressPolicyIngressTo;
    }

    export interface ServicePerimetersServicePerimeterSpecIngressPolicyIngressFrom {
        /**
         * A list of identities that are allowed access through this `EgressPolicy`.
         * Should be in the format of email address. The email address should
         * represent individual user or service account only.
         */
        identities?: string[];
        /**
         * Specifies the type of identities that are allowed access to outside the
         * perimeter. If left unspecified, then members of `identities` field will
         * be allowed access.
         * Possible values are `IDENTITY_TYPE_UNSPECIFIED`, `ANY_IDENTITY`, `ANY_USER_ACCOUNT`, and `ANY_SERVICE_ACCOUNT`.
         */
        identityType?: string;
        /**
         * Sources that this `IngressPolicy` authorizes access from.
         * Structure is documented below.
         */
        sources?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpecIngressPolicyIngressFromSource[];
    }

    export interface ServicePerimetersServicePerimeterSpecIngressPolicyIngressFromSource {
        /**
         * An `AccessLevel` resource name that allow resources within the
         * `ServicePerimeters` to be accessed from the internet. `AccessLevels` listed
         * must be in the same policy as this `ServicePerimeter`. Referencing a nonexistent
         * `AccessLevel` will cause an error. If no `AccessLevel` names are listed,
         * resources within the perimeter can only be accessed via Google Cloud calls
         * with request origins within the perimeter.
         * Example `accessPolicies/MY_POLICY/accessLevels/MY_LEVEL.`
         * If * is specified, then all IngressSources will be allowed.
         */
        accessLevel?: string;
        /**
         * A Google Cloud resource that is allowed to ingress the perimeter.
         * Requests from these resources will be allowed to access perimeter data.
         * Currently only projects are allowed. Format `projects/{project_number}`
         * The project may be in any Google Cloud organization, not just the
         * organization that the perimeter is defined in. `*` is not allowed, the case
         * of allowing all Google Cloud resources only is not supported.
         */
        resource?: string;
    }

    export interface ServicePerimetersServicePerimeterSpecIngressPolicyIngressTo {
        /**
         * A list of `ApiOperations` that this egress rule applies to. A request matches
         * if it contains an operation/service in this list.
         * Structure is documented below.
         */
        operations?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpecIngressPolicyIngressToOperation[];
        /**
         * A list of resources, currently only projects in the form
         * `projects/<projectnumber>`, that match this to stanza. A request matches
         * if it contains a resource in this list. If * is specified for resources,
         * then this `EgressTo` rule will authorize access to all resources outside
         * the perimeter.
         */
        resources?: string[];
    }

    export interface ServicePerimetersServicePerimeterSpecIngressPolicyIngressToOperation {
        /**
         * API methods or permissions to allow. Method or permission must belong
         * to the service specified by `serviceName` field. A single MethodSelector
         * entry with `*` specified for the `method` field will allow all methods
         * AND permissions for the service specified in `serviceName`.
         * Structure is documented below.
         */
        methodSelectors?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterSpecIngressPolicyIngressToOperationMethodSelector[];
        /**
         * The name of the API whose methods or permissions the `IngressPolicy` or
         * `EgressPolicy` want to allow. A single `ApiOperation` with serviceName
         * field set to `*` will allow all methods AND permissions for all services.
         */
        serviceName?: string;
    }

    export interface ServicePerimetersServicePerimeterSpecIngressPolicyIngressToOperationMethodSelector {
        /**
         * Value for `method` should be a valid method name for the corresponding
         * `serviceName` in `ApiOperation`. If `*` used as value for method,
         * then ALL methods and permissions are allowed.
         */
        method?: string;
        /**
         * Value for permission should be a valid Cloud IAM permission for the
         * corresponding `serviceName` in `ApiOperation`.
         */
        permission?: string;
    }

    export interface ServicePerimetersServicePerimeterSpecVpcAccessibleServices {
        /**
         * The list of APIs usable within the Service Perimeter.
         * Must be empty unless `enableRestriction` is True.
         */
        allowedServices?: string[];
        /**
         * Whether to restrict API calls within the Service Perimeter to the
         * list of APIs specified in 'allowedServices'.
         */
        enableRestriction?: boolean;
    }

    export interface ServicePerimetersServicePerimeterStatus {
        /**
         * A list of AccessLevel resource names that allow resources within
         * the ServicePerimeter to be accessed from the internet.
         * AccessLevels listed must be in the same policy as this
         * ServicePerimeter. Referencing a nonexistent AccessLevel is a
         * syntax error. If no AccessLevel names are listed, resources within
         * the perimeter can only be accessed via GCP calls with request
         * origins within the perimeter. For Service Perimeter Bridge, must
         * be empty.
         * Format: accessPolicies/{policy_id}/accessLevels/{access_level_name}
         */
        accessLevels?: string[];
        /**
         * List of EgressPolicies to apply to the perimeter. A perimeter may
         * have multiple EgressPolicies, each of which is evaluated separately.
         * Access is granted if any EgressPolicy grants it. Must be empty for
         * a perimeter bridge.
         * Structure is documented below.
         */
        egressPolicies?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatusEgressPolicy[];
        /**
         * List of `IngressPolicies` to apply to the perimeter. A perimeter may
         * have multiple `IngressPolicies`, each of which is evaluated
         * separately. Access is granted if any `Ingress Policy` grants it.
         * Must be empty for a perimeter bridge.
         * Structure is documented below.
         */
        ingressPolicies?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatusIngressPolicy[];
        /**
         * A list of resources, currently only projects in the form
         * `projects/<projectnumber>`, that match this to stanza. A request matches
         * if it contains a resource in this list. If * is specified for resources,
         * then this `EgressTo` rule will authorize access to all resources outside
         * the perimeter.
         */
        resources?: string[];
        /**
         * GCP services that are subject to the Service Perimeter
         * restrictions. Must contain a list of services. For example, if
         * `storage.googleapis.com` is specified, access to the storage
         * buckets inside the perimeter must meet the perimeter's access
         * restrictions.
         */
        restrictedServices?: string[];
        /**
         * Specifies how APIs are allowed to communicate within the Service
         * Perimeter.
         * Structure is documented below.
         */
        vpcAccessibleServices?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatusVpcAccessibleServices;
    }

    export interface ServicePerimetersServicePerimeterStatusEgressPolicy {
        /**
         * Defines conditions on the source of a request causing this `EgressPolicy` to apply.
         * Structure is documented below.
         */
        egressFrom?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatusEgressPolicyEgressFrom;
        /**
         * Defines the conditions on the `ApiOperation` and destination resources that
         * cause this `EgressPolicy` to apply.
         * Structure is documented below.
         */
        egressTo?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatusEgressPolicyEgressTo;
    }

    export interface ServicePerimetersServicePerimeterStatusEgressPolicyEgressFrom {
        /**
         * A list of identities that are allowed access through this `EgressPolicy`.
         * Should be in the format of email address. The email address should
         * represent individual user or service account only.
         */
        identities?: string[];
        /**
         * Specifies the type of identities that are allowed access to outside the
         * perimeter. If left unspecified, then members of `identities` field will
         * be allowed access.
         * Possible values are `IDENTITY_TYPE_UNSPECIFIED`, `ANY_IDENTITY`, `ANY_USER_ACCOUNT`, and `ANY_SERVICE_ACCOUNT`.
         */
        identityType?: string;
    }

    export interface ServicePerimetersServicePerimeterStatusEgressPolicyEgressTo {
        /**
         * A list of `ApiOperations` that this egress rule applies to. A request matches
         * if it contains an operation/service in this list.
         * Structure is documented below.
         */
        operations?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatusEgressPolicyEgressToOperation[];
        /**
         * A list of resources, currently only projects in the form
         * `projects/<projectnumber>`, that match this to stanza. A request matches
         * if it contains a resource in this list. If * is specified for resources,
         * then this `EgressTo` rule will authorize access to all resources outside
         * the perimeter.
         */
        resources?: string[];
    }

    export interface ServicePerimetersServicePerimeterStatusEgressPolicyEgressToOperation {
        /**
         * API methods or permissions to allow. Method or permission must belong
         * to the service specified by `serviceName` field. A single MethodSelector
         * entry with `*` specified for the `method` field will allow all methods
         * AND permissions for the service specified in `serviceName`.
         * Structure is documented below.
         */
        methodSelectors?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatusEgressPolicyEgressToOperationMethodSelector[];
        /**
         * The name of the API whose methods or permissions the `IngressPolicy` or
         * `EgressPolicy` want to allow. A single `ApiOperation` with serviceName
         * field set to `*` will allow all methods AND permissions for all services.
         */
        serviceName?: string;
    }

    export interface ServicePerimetersServicePerimeterStatusEgressPolicyEgressToOperationMethodSelector {
        /**
         * Value for `method` should be a valid method name for the corresponding
         * `serviceName` in `ApiOperation`. If `*` used as value for method,
         * then ALL methods and permissions are allowed.
         */
        method?: string;
        /**
         * Value for permission should be a valid Cloud IAM permission for the
         * corresponding `serviceName` in `ApiOperation`.
         */
        permission?: string;
    }

    export interface ServicePerimetersServicePerimeterStatusIngressPolicy {
        /**
         * Defines the conditions on the source of a request causing this `IngressPolicy`
         * to apply.
         * Structure is documented below.
         */
        ingressFrom?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatusIngressPolicyIngressFrom;
        /**
         * Defines the conditions on the `ApiOperation` and request destination that cause
         * this `IngressPolicy` to apply.
         * Structure is documented below.
         */
        ingressTo?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatusIngressPolicyIngressTo;
    }

    export interface ServicePerimetersServicePerimeterStatusIngressPolicyIngressFrom {
        /**
         * A list of identities that are allowed access through this `EgressPolicy`.
         * Should be in the format of email address. The email address should
         * represent individual user or service account only.
         */
        identities?: string[];
        /**
         * Specifies the type of identities that are allowed access to outside the
         * perimeter. If left unspecified, then members of `identities` field will
         * be allowed access.
         * Possible values are `IDENTITY_TYPE_UNSPECIFIED`, `ANY_IDENTITY`, `ANY_USER_ACCOUNT`, and `ANY_SERVICE_ACCOUNT`.
         */
        identityType?: string;
        /**
         * Sources that this `IngressPolicy` authorizes access from.
         * Structure is documented below.
         */
        sources?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatusIngressPolicyIngressFromSource[];
    }

    export interface ServicePerimetersServicePerimeterStatusIngressPolicyIngressFromSource {
        /**
         * An `AccessLevel` resource name that allow resources within the
         * `ServicePerimeters` to be accessed from the internet. `AccessLevels` listed
         * must be in the same policy as this `ServicePerimeter`. Referencing a nonexistent
         * `AccessLevel` will cause an error. If no `AccessLevel` names are listed,
         * resources within the perimeter can only be accessed via Google Cloud calls
         * with request origins within the perimeter.
         * Example `accessPolicies/MY_POLICY/accessLevels/MY_LEVEL.`
         * If * is specified, then all IngressSources will be allowed.
         */
        accessLevel?: string;
        /**
         * A Google Cloud resource that is allowed to ingress the perimeter.
         * Requests from these resources will be allowed to access perimeter data.
         * Currently only projects are allowed. Format `projects/{project_number}`
         * The project may be in any Google Cloud organization, not just the
         * organization that the perimeter is defined in. `*` is not allowed, the case
         * of allowing all Google Cloud resources only is not supported.
         */
        resource?: string;
    }

    export interface ServicePerimetersServicePerimeterStatusIngressPolicyIngressTo {
        /**
         * A list of `ApiOperations` that this egress rule applies to. A request matches
         * if it contains an operation/service in this list.
         * Structure is documented below.
         */
        operations?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatusIngressPolicyIngressToOperation[];
        /**
         * A list of resources, currently only projects in the form
         * `projects/<projectnumber>`, that match this to stanza. A request matches
         * if it contains a resource in this list. If * is specified for resources,
         * then this `EgressTo` rule will authorize access to all resources outside
         * the perimeter.
         */
        resources?: string[];
    }

    export interface ServicePerimetersServicePerimeterStatusIngressPolicyIngressToOperation {
        /**
         * API methods or permissions to allow. Method or permission must belong
         * to the service specified by `serviceName` field. A single MethodSelector
         * entry with `*` specified for the `method` field will allow all methods
         * AND permissions for the service specified in `serviceName`.
         * Structure is documented below.
         */
        methodSelectors?: outputs.accesscontextmanager.ServicePerimetersServicePerimeterStatusIngressPolicyIngressToOperationMethodSelector[];
        /**
         * The name of the API whose methods or permissions the `IngressPolicy` or
         * `EgressPolicy` want to allow. A single `ApiOperation` with serviceName
         * field set to `*` will allow all methods AND permissions for all services.
         */
        serviceName?: string;
    }

    export interface ServicePerimetersServicePerimeterStatusIngressPolicyIngressToOperationMethodSelector {
        /**
         * Value for `method` should be a valid method name for the corresponding
         * `serviceName` in `ApiOperation`. If `*` used as value for method,
         * then ALL methods and permissions are allowed.
         */
        method?: string;
        /**
         * Value for permission should be a valid Cloud IAM permission for the
         * corresponding `serviceName` in `ApiOperation`.
         */
        permission?: string;
    }

    export interface ServicePerimetersServicePerimeterStatusVpcAccessibleServices {
        /**
         * The list of APIs usable within the Service Perimeter.
         * Must be empty unless `enableRestriction` is True.
         */
        allowedServices?: string[];
        /**
         * Whether to restrict API calls within the Service Perimeter to the
         * list of APIs specified in 'allowedServices'.
         */
        enableRestriction?: boolean;
    }

}

export namespace apigateway {
    export interface ApiConfigGatewayConfig {
        /**
         * Backend settings that are applied to all backends of the Gateway.
         * Structure is documented below.
         */
        backendConfig: outputs.apigateway.ApiConfigGatewayConfigBackendConfig;
    }

    export interface ApiConfigGatewayConfigBackendConfig {
        /**
         * Google Cloud IAM service account used to sign OIDC tokens for backends that have authentication configured
         * (https://cloud.google.com/service-infrastructure/docs/service-management/reference/rest/v1/services.configs#backend).
         */
        googleServiceAccount: string;
    }

    export interface ApiConfigIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ApiConfigIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ApiConfigOpenapiDocument {
        /**
         * The OpenAPI Specification document file.
         * Structure is documented below.
         */
        document: outputs.apigateway.ApiConfigOpenapiDocumentDocument;
    }

    export interface ApiConfigOpenapiDocumentDocument {
        /**
         * Base64 encoded content of the file.
         */
        contents: string;
        /**
         * The file path (full or relative path). This is typically the path of the file when it is uploaded.
         */
        path: string;
    }

    export interface ApiIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ApiIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface GatewayIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface GatewayIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

}

export namespace apigee {
    export interface EnvironmentIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface EnvironmentIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

}

export namespace appengine {
    export interface ApplicationFeatureSettings {
        /**
         * Set to false to use the legacy health check instead of the readiness
         * and liveness checks.
         */
        splitHealthChecks: boolean;
    }

    export interface ApplicationIap {
        /**
         * (Optional) Whether the serving infrastructure will authenticate and authorize all incoming requests. 
         * (default is false)
         */
        enabled?: boolean;
        /**
         * OAuth2 client ID to use for the authentication flow.
         */
        oauth2ClientId: string;
        /**
         * OAuth2 client secret to use for the authentication flow.
         * The SHA-256 hash of the value is returned in the oauth2ClientSecretSha256 field.
         */
        oauth2ClientSecret: string;
        /**
         * Hex-encoded SHA-256 hash of the client secret.
         */
        oauth2ClientSecretSha256: string;
    }

    export interface ApplicationUrlDispatchRule {
        domain: string;
        path: string;
        service: string;
    }

    export interface ApplicationUrlDispatchRulesDispatchRule {
        /**
         * Domain name to match against. The wildcard "*" is supported if specified before a period: "*.".
         * Defaults to matching all domains: "*".
         */
        domain?: string;
        /**
         * Pathname within the host. Must start with a "/". A single "*" can be included at the end of the path.
         * The sum of the lengths of the domain and path may not exceed 100 characters.
         */
        path: string;
        /**
         * Pathname within the host. Must start with a "/". A single "*" can be included at the end of the path.
         * The sum of the lengths of the domain and path may not exceed 100 characters.
         */
        service: string;
    }

    export interface DomainMappingResourceRecord {
        name?: string;
        rrdata?: string;
        type?: string;
    }

    export interface DomainMappingSslSettings {
        /**
         * ID of the AuthorizedCertificate resource configuring SSL for the application. Clearing this field will
         * remove SSL support.
         * By default, a managed certificate is automatically created for every domain mapping. To omit SSL support
         * or to configure SSL manually, specify `SslManagementType.MANUAL` on a `CREATE` or `UPDATE` request. You must be
         * authorized to administer the `AuthorizedCertificate` resource to manually map it to a DomainMapping resource.
         * Example: 12345.
         */
        certificateId: string;
        /**
         * -
         * ID of the managed `AuthorizedCertificate` resource currently being provisioned, if applicable. Until the new
         * managed certificate has been successfully provisioned, the previous SSL state will be preserved. Once the
         * provisioning process completes, the `certificateId` field will reflect the new managed certificate and this
         * field will be left empty. To remove SSL support while there is still a pending managed certificate, clear the
         * `certificateId` field with an update request.
         */
        pendingManagedCertificateId: string;
        /**
         * SSL management type for this domain. If `AUTOMATIC`, a managed certificate is automatically provisioned.
         * If `MANUAL`, `certificateId` must be manually specified in order to configure SSL for this domain.
         * Possible values are `AUTOMATIC` and `MANUAL`.
         */
        sslManagementType: string;
    }

    export interface EngineSplitTrafficSplit {
        /**
         * Mapping from version IDs within the service to fractional (0.000, 1] allocations of traffic for that version. Each version can be specified only once, but some versions in the service may not have any traffic allocation. Services that have traffic allocated cannot be deleted until either the service is deleted or their traffic allocation is removed. Allocations must sum to 1. Up to two decimal place precision is supported for IP-based splits and up to three decimal places is supported for cookie-based splits.
         */
        allocations: {[key: string]: string};
        /**
         * Mechanism used to determine which version a request is sent to. The traffic selection algorithm will be stable for either type until allocations are changed.
         * Possible values are `UNSPECIFIED`, `COOKIE`, `IP`, and `RANDOM`.
         */
        shardBy?: string;
    }

    export interface FlexibleAppVersionApiConfig {
        /**
         * Action to take when users access resources that require authentication.
         * Default value is `AUTH_FAIL_ACTION_REDIRECT`.
         * Possible values are `AUTH_FAIL_ACTION_REDIRECT` and `AUTH_FAIL_ACTION_UNAUTHORIZED`.
         */
        authFailAction?: string;
        /**
         * Level of login required to access this resource.
         * Default value is `LOGIN_OPTIONAL`.
         * Possible values are `LOGIN_OPTIONAL`, `LOGIN_ADMIN`, and `LOGIN_REQUIRED`.
         */
        login?: string;
        /**
         * Path to the script from the application root directory.
         */
        script: string;
        /**
         * Security (HTTPS) enforcement for this URL.
         * Possible values are `SECURE_DEFAULT`, `SECURE_NEVER`, `SECURE_OPTIONAL`, and `SECURE_ALWAYS`.
         */
        securityLevel?: string;
        /**
         * URL to serve the endpoint at.
         */
        url?: string;
    }

    export interface FlexibleAppVersionAutomaticScaling {
        /**
         * The time period that the Autoscaler should wait before it starts collecting information from a new instance.
         * This prevents the autoscaler from collecting information when the instance is initializing,
         * during which the collected usage would not be reliable. Default: 120s
         */
        coolDownPeriod?: string;
        /**
         * Target scaling by CPU usage.
         * Structure is documented below.
         */
        cpuUtilization: outputs.appengine.FlexibleAppVersionAutomaticScalingCpuUtilization;
        /**
         * Target scaling by disk usage.
         * Structure is documented below.
         */
        diskUtilization?: outputs.appengine.FlexibleAppVersionAutomaticScalingDiskUtilization;
        /**
         * Number of concurrent requests an automatic scaling instance can accept before the scheduler spawns a new instance.
         * Defaults to a runtime-specific value.
         */
        maxConcurrentRequests: number;
        /**
         * Maximum number of idle instances that should be maintained for this version.
         */
        maxIdleInstances?: number;
        /**
         * Maximum amount of time that a request should wait in the pending queue before starting a new instance to handle it.
         */
        maxPendingLatency?: string;
        /**
         * Maximum number of instances that should be started to handle requests for this version. Default: 20
         */
        maxTotalInstances?: number;
        /**
         * Minimum number of idle instances that should be maintained for this version. Only applicable for the default version of a service.
         */
        minIdleInstances?: number;
        /**
         * Minimum amount of time a request should wait in the pending queue before starting a new instance to handle it.
         */
        minPendingLatency?: string;
        /**
         * Minimum number of running instances that should be maintained for this version. Default: 2
         */
        minTotalInstances?: number;
        /**
         * Target scaling by network usage.
         * Structure is documented below.
         */
        networkUtilization?: outputs.appengine.FlexibleAppVersionAutomaticScalingNetworkUtilization;
        /**
         * Target scaling by request utilization.
         * Structure is documented below.
         */
        requestUtilization?: outputs.appengine.FlexibleAppVersionAutomaticScalingRequestUtilization;
    }

    export interface FlexibleAppVersionAutomaticScalingCpuUtilization {
        /**
         * Period of time over which CPU utilization is calculated.
         */
        aggregationWindowLength?: string;
        /**
         * Target CPU utilization ratio to maintain when scaling. Must be between 0 and 1.
         */
        targetUtilization: number;
    }

    export interface FlexibleAppVersionAutomaticScalingDiskUtilization {
        /**
         * Target bytes read per second.
         */
        targetReadBytesPerSecond?: number;
        /**
         * Target ops read per seconds.
         */
        targetReadOpsPerSecond?: number;
        /**
         * Target bytes written per second.
         */
        targetWriteBytesPerSecond?: number;
        /**
         * Target ops written per second.
         */
        targetWriteOpsPerSecond?: number;
    }

    export interface FlexibleAppVersionAutomaticScalingNetworkUtilization {
        /**
         * Target bytes received per second.
         */
        targetReceivedBytesPerSecond?: number;
        /**
         * Target packets received per second.
         */
        targetReceivedPacketsPerSecond?: number;
        /**
         * Target bytes sent per second.
         */
        targetSentBytesPerSecond?: number;
        /**
         * Target packets sent per second.
         */
        targetSentPacketsPerSecond?: number;
    }

    export interface FlexibleAppVersionAutomaticScalingRequestUtilization {
        /**
         * Target number of concurrent requests.
         */
        targetConcurrentRequests?: number;
        /**
         * Target requests per second.
         */
        targetRequestCountPerSecond?: string;
    }

    export interface FlexibleAppVersionDeployment {
        /**
         * Options for the build operations performed as a part of the version deployment. Only applicable when creating a version using source code directly.
         * Structure is documented below.
         */
        cloudBuildOptions?: outputs.appengine.FlexibleAppVersionDeploymentCloudBuildOptions;
        /**
         * The Docker image for the container that runs the version.
         * Structure is documented below.
         */
        container: outputs.appengine.FlexibleAppVersionDeploymentContainer;
        /**
         * Manifest of the files stored in Google Cloud Storage that are included as part of this version.
         * All files must be readable using the credentials supplied with this call.
         * Structure is documented below.
         */
        files?: outputs.appengine.FlexibleAppVersionDeploymentFile[];
        /**
         * Zip File
         * Structure is documented below.
         */
        zip?: outputs.appengine.FlexibleAppVersionDeploymentZip;
    }

    export interface FlexibleAppVersionDeploymentCloudBuildOptions {
        /**
         * Path to the yaml file used in deployment, used to determine runtime configuration details.
         */
        appYamlPath: string;
        /**
         * The Cloud Build timeout used as part of any dependent builds performed by version creation. Defaults to 10 minutes.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        cloudBuildTimeout?: string;
    }

    export interface FlexibleAppVersionDeploymentContainer {
        /**
         * URI to the hosted container image in Google Container Registry. The URI must be fully qualified and include a tag or digest.
         * Examples: "gcr.io/my-project/image:tag" or "gcr.io/my-project/image@digest"
         */
        image: string;
    }

    export interface FlexibleAppVersionDeploymentFile {
        /**
         * Full Serverless VPC Access Connector name e.g. /projects/my-project/locations/us-central1/connectors/c1.
         */
        name: string;
        /**
         * SHA1 checksum of the file
         */
        sha1Sum?: string;
        /**
         * Source URL
         */
        sourceUrl: string;
    }

    export interface FlexibleAppVersionDeploymentZip {
        /**
         * files count
         */
        filesCount?: number;
        /**
         * Source URL
         */
        sourceUrl: string;
    }

    export interface FlexibleAppVersionEndpointsApiService {
        /**
         * Endpoints service configuration ID as specified by the Service Management API. For example "2016-09-19r1".
         * By default, the rollout strategy for Endpoints is "FIXED". This means that Endpoints starts up with a particular configuration ID.
         * When a new configuration is rolled out, Endpoints must be given the new configuration ID. The configId field is used to give the configuration ID
         * and is required in this case.
         * Endpoints also has a rollout strategy called "MANAGED". When using this, Endpoints fetches the latest configuration and does not need
         * the configuration ID. In this case, configId must be omitted.
         */
        configId?: string;
        /**
         * Enable or disable trace sampling. By default, this is set to false for enabled.
         */
        disableTraceSampling?: boolean;
        /**
         * Full Serverless VPC Access Connector name e.g. /projects/my-project/locations/us-central1/connectors/c1.
         */
        name: string;
        /**
         * Endpoints rollout strategy. If FIXED, configId must be specified. If MANAGED, configId must be omitted.
         * Default value is `FIXED`.
         * Possible values are `FIXED` and `MANAGED`.
         */
        rolloutStrategy?: string;
    }

    export interface FlexibleAppVersionEntrypoint {
        /**
         * The format should be a shell command that can be fed to bash -c.
         */
        shell: string;
    }

    export interface FlexibleAppVersionHandler {
        /**
         * Action to take when users access resources that require authentication.
         * Default value is `AUTH_FAIL_ACTION_REDIRECT`.
         * Possible values are `AUTH_FAIL_ACTION_REDIRECT` and `AUTH_FAIL_ACTION_UNAUTHORIZED`.
         */
        authFailAction?: string;
        /**
         * Level of login required to access this resource.
         * Default value is `LOGIN_OPTIONAL`.
         * Possible values are `LOGIN_OPTIONAL`, `LOGIN_ADMIN`, and `LOGIN_REQUIRED`.
         */
        login?: string;
        /**
         * 30x code to use when performing redirects for the secure field.
         * Possible values are `REDIRECT_HTTP_RESPONSE_CODE_301`, `REDIRECT_HTTP_RESPONSE_CODE_302`, `REDIRECT_HTTP_RESPONSE_CODE_303`, and `REDIRECT_HTTP_RESPONSE_CODE_307`.
         */
        redirectHttpResponseCode?: string;
        /**
         * Path to the script from the application root directory.
         */
        script?: outputs.appengine.FlexibleAppVersionHandlerScript;
        /**
         * Security (HTTPS) enforcement for this URL.
         * Possible values are `SECURE_DEFAULT`, `SECURE_NEVER`, `SECURE_OPTIONAL`, and `SECURE_ALWAYS`.
         */
        securityLevel?: string;
        /**
         * Files served directly to the user for a given URL, such as images, CSS stylesheets, or JavaScript source files.
         * Static file handlers describe which files in the application directory are static files, and which URLs serve them.
         * Structure is documented below.
         */
        staticFiles?: outputs.appengine.FlexibleAppVersionHandlerStaticFiles;
        /**
         * URL prefix. Uses regular expression syntax, which means regexp special characters must be escaped, but should not contain groupings.
         * All URLs that begin with this prefix are handled by this handler, using the portion of the URL after the prefix as part of the file path.
         */
        urlRegex?: string;
    }

    export interface FlexibleAppVersionHandlerScript {
        /**
         * Path to the script from the application root directory.
         */
        scriptPath: string;
    }

    export interface FlexibleAppVersionHandlerStaticFiles {
        /**
         * Whether files should also be uploaded as code data. By default, files declared in static file handlers are
         * uploaded as static data and are only served to end users; they cannot be read by the application. If enabled,
         * uploads are charged against both your code and static data storage resource quotas.
         */
        applicationReadable?: boolean;
        /**
         * Time a static file served by this handler should be cached by web proxies and browsers.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example "3.5s".
         * Default is '0s'
         */
        expiration?: string;
        /**
         * HTTP headers to use for all responses from these URLs.
         * An object containing a list of "key:value" value pairs.".
         */
        httpHeaders?: {[key: string]: string};
        /**
         * MIME type used to serve all files served by this handler.
         * Defaults to file-specific MIME types, which are derived from each file's filename extension.
         */
        mimeType?: string;
        /**
         * Path to the static files matched by the URL pattern, from the application root directory.
         * The path can refer to text matched in groupings in the URL pattern.
         */
        path?: string;
        /**
         * Whether this handler should match the request if the file referenced by the handler does not exist.
         */
        requireMatchingFile?: boolean;
        /**
         * Regular expression that matches the file paths for all files that should be referenced by this handler.
         */
        uploadPathRegex?: string;
    }

    export interface FlexibleAppVersionLivenessCheck {
        /**
         * Interval between health checks.
         */
        checkInterval?: string;
        /**
         * Number of consecutive failed checks required before considering the VM unhealthy. Default: 4.
         */
        failureThreshold?: number;
        /**
         * Host header to send when performing a HTTP Readiness check. Example: "myapp.appspot.com"
         */
        host?: string;
        /**
         * The initial delay before starting to execute the checks. Default: "300s"
         */
        initialDelay?: string;
        /**
         * Path to the static files matched by the URL pattern, from the application root directory.
         * The path can refer to text matched in groupings in the URL pattern.
         */
        path: string;
        /**
         * Number of consecutive successful checks required before considering the VM healthy. Default: 2.
         */
        successThreshold?: number;
        /**
         * Time before the check is considered failed. Default: "4s"
         */
        timeout?: string;
    }

    export interface FlexibleAppVersionManualScaling {
        /**
         * Number of instances to assign to the service at the start.
         * **Note:** When managing the number of instances at runtime through the App Engine Admin API or the (now deprecated) Python 2
         * Modules API set_num_instances() you must use `lifecycle.ignore_changes = ["manualScaling"[0].instances]` to prevent drift detection.
         */
        instances: number;
    }

    export interface FlexibleAppVersionNetwork {
        /**
         * List of ports, or port pairs, to forward from the virtual machine to the application container.
         */
        forwardedPorts?: string[];
        /**
         * Tag to apply to the instance during creation.
         */
        instanceTag?: string;
        /**
         * Full Serverless VPC Access Connector name e.g. /projects/my-project/locations/us-central1/connectors/c1.
         */
        name: string;
        /**
         * Enable session affinity.
         */
        sessionAffinity?: boolean;
        /**
         * Google Cloud Platform sub-network where the virtual machines are created. Specify the short name, not the resource path.
         * If the network that the instance is being created in is a Legacy network, then the IP address is allocated from the IPv4Range.
         * If the network that the instance is being created in is an auto Subnet Mode Network, then only network name should be specified (not the subnetworkName) and the IP address is created from the IPCidrRange of the subnetwork that exists in that zone for that network.
         * If the network that the instance is being created in is a custom Subnet Mode Network, then the subnetworkName must be specified and the IP address is created from the IPCidrRange of the subnetwork.
         * If specified, the subnetwork must exist in the same region as the App Engine flexible environment application.
         */
        subnetwork?: string;
    }

    export interface FlexibleAppVersionReadinessCheck {
        /**
         * A maximum time limit on application initialization, measured from moment the application successfully
         * replies to a healthcheck until it is ready to serve traffic. Default: "300s"
         */
        appStartTimeout?: string;
        /**
         * Interval between health checks.
         */
        checkInterval?: string;
        /**
         * Number of consecutive failed checks required before considering the VM unhealthy. Default: 4.
         */
        failureThreshold?: number;
        /**
         * Host header to send when performing a HTTP Readiness check. Example: "myapp.appspot.com"
         */
        host?: string;
        /**
         * Path to the static files matched by the URL pattern, from the application root directory.
         * The path can refer to text matched in groupings in the URL pattern.
         */
        path: string;
        /**
         * Number of consecutive successful checks required before considering the VM healthy. Default: 2.
         */
        successThreshold?: number;
        /**
         * Time before the check is considered failed. Default: "4s"
         */
        timeout?: string;
    }

    export interface FlexibleAppVersionResources {
        /**
         * Number of CPU cores needed.
         */
        cpu?: number;
        /**
         * Disk size (GB) needed.
         */
        diskGb?: number;
        /**
         * Memory (GB) needed.
         */
        memoryGb?: number;
        /**
         * List of ports, or port pairs, to forward from the virtual machine to the application container.
         * Structure is documented below.
         */
        volumes?: outputs.appengine.FlexibleAppVersionResourcesVolume[];
    }

    export interface FlexibleAppVersionResourcesVolume {
        /**
         * Full Serverless VPC Access Connector name e.g. /projects/my-project/locations/us-central1/connectors/c1.
         */
        name: string;
        /**
         * Volume size in gigabytes.
         */
        sizeGb: number;
        /**
         * Underlying volume type, e.g. 'tmpfs'.
         */
        volumeType: string;
    }

    export interface FlexibleAppVersionVpcAccessConnector {
        /**
         * Full Serverless VPC Access Connector name e.g. /projects/my-project/locations/us-central1/connectors/c1.
         */
        name: string;
    }

    export interface ServiceNetworkSettingsNetworkSettings {
        /**
         * The ingress settings for version or service.
         * Default value is `INGRESS_TRAFFIC_ALLOWED_UNSPECIFIED`.
         * Possible values are `INGRESS_TRAFFIC_ALLOWED_UNSPECIFIED`, `INGRESS_TRAFFIC_ALLOWED_ALL`, `INGRESS_TRAFFIC_ALLOWED_INTERNAL_ONLY`, and `INGRESS_TRAFFIC_ALLOWED_INTERNAL_AND_LB`.
         */
        ingressTrafficAllowed?: string;
    }

    export interface StandardAppVersionAutomaticScaling {
        /**
         * Number of concurrent requests an automatic scaling instance can accept before the scheduler spawns a new instance.
         * Defaults to a runtime-specific value.
         */
        maxConcurrentRequests?: number;
        /**
         * Maximum number of idle instances that should be maintained for this version.
         */
        maxIdleInstances?: number;
        /**
         * Maximum amount of time that a request should wait in the pending queue before starting a new instance to handle it.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        maxPendingLatency?: string;
        /**
         * Minimum number of idle instances that should be maintained for this version. Only applicable for the default version of a service.
         */
        minIdleInstances?: number;
        /**
         * Minimum amount of time a request should wait in the pending queue before starting a new instance to handle it.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        minPendingLatency?: string;
        /**
         * Scheduler settings for standard environment.
         * Structure is documented below.
         */
        standardSchedulerSettings?: outputs.appengine.StandardAppVersionAutomaticScalingStandardSchedulerSettings;
    }

    export interface StandardAppVersionAutomaticScalingStandardSchedulerSettings {
        /**
         * Maximum number of instances to create for this version. Must be in the range [1.0, 200.0].
         */
        maxInstances?: number;
        /**
         * Minimum number of instances to run for this version. Set to zero to disable minInstances configuration.
         */
        minInstances?: number;
        /**
         * Target CPU utilization ratio to maintain when scaling. Should be a value in the range [0.50, 0.95], zero, or a negative value.
         */
        targetCpuUtilization?: number;
        /**
         * Target throughput utilization ratio to maintain when scaling. Should be a value in the range [0.50, 0.95], zero, or a negative value.
         */
        targetThroughputUtilization?: number;
    }

    export interface StandardAppVersionBasicScaling {
        /**
         * Duration of time after the last request that an instance must wait before the instance is shut down.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s". Defaults to 900s.
         */
        idleTimeout?: string;
        /**
         * Maximum number of instances to create for this version. Must be in the range [1.0, 200.0].
         */
        maxInstances: number;
    }

    export interface StandardAppVersionDeployment {
        /**
         * Manifest of the files stored in Google Cloud Storage that are included as part of this version.
         * All files must be readable using the credentials supplied with this call.
         * Structure is documented below.
         */
        files?: outputs.appengine.StandardAppVersionDeploymentFile[];
        /**
         * Zip File
         * Structure is documented below.
         */
        zip?: outputs.appengine.StandardAppVersionDeploymentZip;
    }

    export interface StandardAppVersionDeploymentFile {
        /**
         * Full Serverless VPC Access Connector name e.g. /projects/my-project/locations/us-central1/connectors/c1.
         */
        name: string;
        /**
         * SHA1 checksum of the file
         */
        sha1Sum?: string;
        /**
         * Source URL
         */
        sourceUrl: string;
    }

    export interface StandardAppVersionDeploymentZip {
        /**
         * files count
         */
        filesCount?: number;
        /**
         * Source URL
         */
        sourceUrl: string;
    }

    export interface StandardAppVersionEntrypoint {
        /**
         * The format should be a shell command that can be fed to bash -c.
         */
        shell: string;
    }

    export interface StandardAppVersionHandler {
        /**
         * Actions to take when the user is not logged in.
         * Possible values are `AUTH_FAIL_ACTION_REDIRECT` and `AUTH_FAIL_ACTION_UNAUTHORIZED`.
         */
        authFailAction?: string;
        /**
         * Methods to restrict access to a URL based on login status.
         * Possible values are `LOGIN_OPTIONAL`, `LOGIN_ADMIN`, and `LOGIN_REQUIRED`.
         */
        login?: string;
        /**
         * 30x code to use when performing redirects for the secure field.
         * Possible values are `REDIRECT_HTTP_RESPONSE_CODE_301`, `REDIRECT_HTTP_RESPONSE_CODE_302`, `REDIRECT_HTTP_RESPONSE_CODE_303`, and `REDIRECT_HTTP_RESPONSE_CODE_307`.
         */
        redirectHttpResponseCode?: string;
        /**
         * Executes a script to handle the requests that match this URL pattern.
         * Only the auto value is supported for Node.js in the App Engine standard environment, for example "script:" "auto".
         * Structure is documented below.
         */
        script?: outputs.appengine.StandardAppVersionHandlerScript;
        /**
         * Security (HTTPS) enforcement for this URL.
         * Possible values are `SECURE_DEFAULT`, `SECURE_NEVER`, `SECURE_OPTIONAL`, and `SECURE_ALWAYS`.
         */
        securityLevel?: string;
        /**
         * Files served directly to the user for a given URL, such as images, CSS stylesheets, or JavaScript source files. Static file handlers describe which files in the application directory are static files, and which URLs serve them.
         * Structure is documented below.
         */
        staticFiles?: outputs.appengine.StandardAppVersionHandlerStaticFiles;
        /**
         * URL prefix. Uses regular expression syntax, which means regexp special characters must be escaped, but should not contain groupings.
         * All URLs that begin with this prefix are handled by this handler, using the portion of the URL after the prefix as part of the file path.
         */
        urlRegex?: string;
    }

    export interface StandardAppVersionHandlerScript {
        /**
         * Path to the script from the application root directory.
         */
        scriptPath: string;
    }

    export interface StandardAppVersionHandlerStaticFiles {
        /**
         * Whether files should also be uploaded as code data. By default, files declared in static file handlers are uploaded as
         * static data and are only served to end users; they cannot be read by the application. If enabled, uploads are charged
         * against both your code and static data storage resource quotas.
         */
        applicationReadable?: boolean;
        /**
         * Time a static file served by this handler should be cached by web proxies and browsers.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example "3.5s".
         */
        expiration?: string;
        /**
         * HTTP headers to use for all responses from these URLs.
         * An object containing a list of "key:value" value pairs.".
         */
        httpHeaders?: {[key: string]: string};
        /**
         * MIME type used to serve all files served by this handler.
         * Defaults to file-specific MIME types, which are derived from each file's filename extension.
         */
        mimeType?: string;
        /**
         * Path to the static files matched by the URL pattern, from the application root directory. The path can refer to text matched in groupings in the URL pattern.
         */
        path?: string;
        /**
         * Whether this handler should match the request if the file referenced by the handler does not exist.
         */
        requireMatchingFile?: boolean;
        /**
         * Regular expression that matches the file paths for all files that should be referenced by this handler.
         */
        uploadPathRegex?: string;
    }

    export interface StandardAppVersionLibrary {
        /**
         * Full Serverless VPC Access Connector name e.g. /projects/my-project/locations/us-central1/connectors/c1.
         */
        name?: string;
        /**
         * Version of the library to select, or "latest".
         */
        version?: string;
    }

    export interface StandardAppVersionManualScaling {
        /**
         * Number of instances to assign to the service at the start.
         * **Note:** When managing the number of instances at runtime through the App Engine Admin API or the (now deprecated) Python 2
         * Modules API set_num_instances() you must use `lifecycle.ignore_changes = ["manualScaling"[0].instances]` to prevent drift detection.
         */
        instances: number;
    }

    export interface StandardAppVersionVpcAccessConnector {
        /**
         * Full Serverless VPC Access Connector name e.g. /projects/my-project/locations/us-central1/connectors/c1.
         */
        name: string;
    }

}

export namespace artifactregistry {
    export interface RepositoryIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface RepositoryIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface RepositoryMavenConfig {
        /**
         * The repository with this flag will allow publishing the same
         * snapshot versions.
         */
        allowSnapshotOverwrites?: boolean;
        /**
         * Version policy defines the versions that the registry will accept.
         * Default value is `VERSION_POLICY_UNSPECIFIED`.
         * Possible values are `VERSION_POLICY_UNSPECIFIED`, `RELEASE`, and `SNAPSHOT`.
         */
        versionPolicy?: string;
    }

}

export namespace assuredworkloads {
    export interface WorkloadKmsSettings {
        /**
         * Required. Input only. Immutable. The time at which the Key Management Service will automatically create a new version of the crypto key and mark it as the primary.
         */
        nextRotationTime: string;
        /**
         * Required. Input only. Immutable. will be advanced by this period when the Key Management Service automatically rotates a key. Must be at least 24 hours and at most 876,000 hours.
         */
        rotationPeriod: string;
    }

    export interface WorkloadResource {
        /**
         * Resource identifier. For a project this represents project_number. If the project is already taken, the workload creation will fail.
         */
        resourceId: number;
        /**
         * Indicates the type of resource. This field should be specified to correspond the id to the right project type (CONSUMER_PROJECT or ENCRYPTION_KEYS_PROJECT) Possible values: RESOURCE_TYPE_UNSPECIFIED, CONSUMER_PROJECT, ENCRYPTION_KEYS_PROJECT, KEYRING, CONSUMER_FOLDER
         */
        resourceType: string;
    }

    export interface WorkloadResourceSetting {
        /**
         * Resource identifier. For a project this represents project_number. If the project is already taken, the workload creation will fail.
         */
        resourceId?: string;
        /**
         * Indicates the type of resource. This field should be specified to correspond the id to the right project type (CONSUMER_PROJECT or ENCRYPTION_KEYS_PROJECT) Possible values: RESOURCE_TYPE_UNSPECIFIED, CONSUMER_PROJECT, ENCRYPTION_KEYS_PROJECT, KEYRING, CONSUMER_FOLDER
         */
        resourceType?: string;
    }

}

export namespace bigquery {
    export interface AppProfileSingleClusterRouting {
        /**
         * If true, CheckAndMutateRow and ReadModifyWriteRow requests are allowed by this app profile.
         * It is unsafe to send these requests to the same table/row/column in multiple clusters.
         */
        allowTransactionalWrites?: boolean;
        /**
         * The cluster to which read/write requests should be routed.
         */
        clusterId: string;
    }

    export interface ConnectionAws {
        /**
         * Authentication using Google owned service account to assume into customer's AWS IAM Role.
         * Structure is documented below.
         */
        accessRole: outputs.bigquery.ConnectionAwsAccessRole;
    }

    export interface ConnectionAwsAccessRole {
        /**
         * The users AWS IAM Role that trusts the Google-owned AWS IAM user Connection.
         */
        iamRoleId: string;
        /**
         * -
         * A unique Google-owned and Google-generated identity for the Connection. This identity will be used to access the user's AWS IAM Role.
         */
        identity: string;
    }

    export interface ConnectionAzure {
        /**
         * -
         * The name of the Azure Active Directory Application.
         */
        application: string;
        /**
         * -
         * The client id of the Azure Active Directory Application.
         */
        clientId: string;
        /**
         * The id of customer's directory that host the data.
         */
        customerTenantId: string;
        /**
         * -
         * The object id of the Azure Active Directory Application.
         */
        objectId: string;
        /**
         * -
         * The URL user will be redirected to after granting consent during connection setup.
         */
        redirectUri: string;
    }

    export interface ConnectionCloudResource {
        /**
         * -
         * The account ID of the service created for the purpose of this connection.
         */
        serviceAccountId: string;
    }

    export interface ConnectionCloudSpanner {
        /**
         * Cloud Spanner database in the form `project/instance/database'
         */
        database: string;
        /**
         * If parallelism should be used when reading from Cloud Spanner
         */
        useParallelism?: boolean;
    }

    export interface ConnectionCloudSql {
        /**
         * Cloud SQL properties.
         * Structure is documented below.
         */
        credential: outputs.bigquery.ConnectionCloudSqlCredential;
        /**
         * Cloud Spanner database in the form `project/instance/database'
         */
        database: string;
        /**
         * Cloud SQL instance ID in the form project:location:instance.
         */
        instanceId: string;
        /**
         * Type of the Cloud SQL database.
         * Possible values are `DATABASE_TYPE_UNSPECIFIED`, `POSTGRES`, and `MYSQL`.
         */
        type: string;
    }

    export interface ConnectionCloudSqlCredential {
        /**
         * Password for database.
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        password: string;
        /**
         * Username for database.
         */
        username: string;
    }

    export interface DataTransferConfigEmailPreferences {
        /**
         * If true, email notifications will be sent on transfer run failures.
         */
        enableFailureEmail: boolean;
    }

    export interface DataTransferConfigScheduleOptions {
        /**
         * If true, automatic scheduling of data transfer runs for this
         * configuration will be disabled. The runs can be started on ad-hoc
         * basis using transferConfigs.startManualRuns API. When automatic
         * scheduling is disabled, the TransferConfig.schedule field will
         * be ignored.
         */
        disableAutoScheduling?: boolean;
        /**
         * Defines time to stop scheduling transfer runs. A transfer run cannot be
         * scheduled at or after the end time. The end time can be changed at any
         * moment. The time when a data transfer can be triggered manually is not
         * limited by this option.
         */
        endTime?: string;
        /**
         * Specifies time to start scheduling transfer runs. The first run will be
         * scheduled at or after the start time according to a recurrence pattern
         * defined in the schedule string. The start time can be changed at any
         * moment. The time when a data transfer can be triggered manually is not
         * limited by this option.
         */
        startTime?: string;
    }

    export interface DataTransferConfigSensitiveParams {
        /**
         * The Secret Access Key of the AWS account transferring data from.
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        secretAccessKey: string;
    }

    export interface DatasetAccess {
        /**
         * The dataset this entry applies to
         * Structure is documented below.
         */
        dataset?: outputs.bigquery.DatasetAccessDataset;
        /**
         * A domain to grant access to. Any users signed in with the
         * domain specified will be granted the specified access
         */
        domain?: string;
        /**
         * An email address of a Google Group to grant access to.
         */
        groupByEmail?: string;
        /**
         * Describes the rights granted to the user specified by the other
         * member of the access object. Basic, predefined, and custom roles
         * are supported. Predefined roles that have equivalent basic roles
         * are swapped by the API to their basic counterparts. See
         * [official docs](https://cloud.google.com/bigquery/docs/access-control).
         */
        role?: string;
        /**
         * A special group to grant access to. Possible values include:
         */
        specialGroup?: string;
        /**
         * An email address of a user to grant access to. For example:
         * fred@example.com
         */
        userByEmail?: string;
        /**
         * A view from a different dataset to grant access to. Queries
         * executed against that view will have read access to tables in
         * this dataset. The role field is not required when this field is
         * set. If that view is updated by any user, access to the view
         * needs to be granted again via an update operation.
         * Structure is documented below.
         */
        view?: outputs.bigquery.DatasetAccessView;
    }

    export interface DatasetAccessAuthorizedDataset {
        /**
         * The dataset this entry applies to
         * Structure is documented below.
         */
        dataset: outputs.bigquery.DatasetAccessAuthorizedDatasetDataset;
        /**
         * Which resources in the dataset this entry applies to. Currently, only views are supported,
         * but additional target types may be added in the future. Possible values: VIEWS
         */
        targetTypes: string[];
    }

    export interface DatasetAccessAuthorizedDatasetDataset {
        /**
         * The ID of the dataset containing this table.
         */
        datasetId: string;
        /**
         * The ID of the project containing this table.
         */
        projectId: string;
    }

    export interface DatasetAccessDataset {
        /**
         * The dataset this entry applies to
         * Structure is documented below.
         */
        dataset: outputs.bigquery.DatasetAccessDatasetDataset;
        /**
         * Which resources in the dataset this entry applies to. Currently, only views are supported,
         * but additional target types may be added in the future. Possible values: VIEWS
         */
        targetTypes: string[];
    }

    export interface DatasetAccessDatasetDataset {
        /**
         * The ID of the dataset containing this table.
         */
        datasetId: string;
        /**
         * The ID of the project containing this table.
         */
        projectId: string;
    }

    export interface DatasetAccessView {
        /**
         * The ID of the dataset containing this table.
         */
        datasetId: string;
        /**
         * The ID of the project containing this table.
         */
        projectId: string;
        /**
         * The ID of the table. The ID must contain only letters (a-z,
         * A-Z), numbers (0-9), or underscores (_). The maximum length
         * is 1,024 characters.
         */
        tableId: string;
    }

    export interface DatasetDefaultEncryptionConfiguration {
        /**
         * Describes the Cloud KMS encryption key that will be used to protect destination
         * BigQuery table. The BigQuery Service Account associated with your project requires
         * access to this encryption key.
         */
        kmsKeyName: string;
    }

    export interface DatasetIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface DatasetIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface IamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface IamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface JobCopy {
        /**
         * Specifies whether the job is allowed to create new tables. The following values are supported:
         * CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
         * CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
         * Creation, truncation and append actions occur as one atomic update upon job completion
         * Default value is `CREATE_IF_NEEDED`.
         * Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
         */
        createDisposition?: string;
        /**
         * Custom encryption configuration (e.g., Cloud KMS keys)
         * Structure is documented below.
         */
        destinationEncryptionConfiguration?: outputs.bigquery.JobCopyDestinationEncryptionConfiguration;
        /**
         * The destination table.
         * Structure is documented below.
         */
        destinationTable?: outputs.bigquery.JobCopyDestinationTable;
        /**
         * Source tables to copy.
         * Structure is documented below.
         */
        sourceTables: outputs.bigquery.JobCopySourceTable[];
        /**
         * Specifies the action that occurs if the destination table already exists. The following values are supported:
         * WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
         * WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
         * WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
         * Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
         * Creation, truncation and append actions occur as one atomic update upon job completion.
         * Default value is `WRITE_EMPTY`.
         * Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
         */
        writeDisposition?: string;
    }

    export interface JobCopyDestinationEncryptionConfiguration {
        /**
         * Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
         * The BigQuery Service Account associated with your project requires access to this encryption key.
         */
        kmsKeyName: string;
        /**
         * -
         * Describes the Cloud KMS encryption key version used to protect destination BigQuery table.
         */
        kmsKeyVersion: string;
    }

    export interface JobCopyDestinationTable {
        /**
         * The ID of the dataset containing this model.
         */
        datasetId: string;
        /**
         * The ID of the project containing this model.
         */
        projectId: string;
        /**
         * The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
         * or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
         */
        tableId: string;
    }

    export interface JobCopySourceTable {
        /**
         * The ID of the dataset containing this model.
         */
        datasetId: string;
        /**
         * The ID of the project containing this model.
         */
        projectId: string;
        /**
         * The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
         * or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
         */
        tableId: string;
    }

    export interface JobExtract {
        /**
         * The compression type to use for exported files. Possible values include GZIP, DEFLATE, SNAPPY, and NONE.
         * The default value is NONE. DEFLATE and SNAPPY are only supported for Avro.
         */
        compression?: string;
        /**
         * The exported file format. Possible values include CSV, NEWLINE_DELIMITED_JSON and AVRO for tables and SAVED_MODEL for models.
         * The default value for tables is CSV. Tables with nested or repeated fields cannot be exported as CSV.
         * The default value for models is SAVED_MODEL.
         */
        destinationFormat: string;
        /**
         * A list of fully-qualified Google Cloud Storage URIs where the extracted table should be written.
         */
        destinationUris: string[];
        /**
         * When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
         * Default is ','
         */
        fieldDelimiter: string;
        /**
         * Whether to print out a header row in the results. Default is true.
         */
        printHeader?: boolean;
        /**
         * A reference to the model being exported.
         * Structure is documented below.
         */
        sourceModel?: outputs.bigquery.JobExtractSourceModel;
        /**
         * A reference to the table being exported.
         * Structure is documented below.
         */
        sourceTable?: outputs.bigquery.JobExtractSourceTable;
        /**
         * Whether to use logical types when extracting to AVRO format.
         */
        useAvroLogicalTypes?: boolean;
    }

    export interface JobExtractSourceModel {
        /**
         * The ID of the dataset containing this model.
         */
        datasetId: string;
        /**
         * The ID of the model.
         */
        modelId: string;
        /**
         * The ID of the project containing this model.
         */
        projectId: string;
    }

    export interface JobExtractSourceTable {
        /**
         * The ID of the dataset containing this model.
         */
        datasetId: string;
        /**
         * The ID of the project containing this model.
         */
        projectId: string;
        /**
         * The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
         * or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
         */
        tableId: string;
    }

    export interface JobLoad {
        /**
         * Accept rows that are missing trailing optional columns. The missing values are treated as nulls.
         * If false, records with missing trailing columns are treated as bad records, and if there are too many bad records,
         * an invalid error is returned in the job result. The default value is false. Only applicable to CSV, ignored for other formats.
         */
        allowJaggedRows?: boolean;
        /**
         * Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file.
         * The default value is false.
         */
        allowQuotedNewlines?: boolean;
        /**
         * Indicates if we should automatically infer the options and schema for CSV and JSON sources.
         */
        autodetect?: boolean;
        /**
         * Specifies whether the job is allowed to create new tables. The following values are supported:
         * CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
         * CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
         * Creation, truncation and append actions occur as one atomic update upon job completion
         * Default value is `CREATE_IF_NEEDED`.
         * Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
         */
        createDisposition?: string;
        /**
         * Custom encryption configuration (e.g., Cloud KMS keys)
         * Structure is documented below.
         */
        destinationEncryptionConfiguration?: outputs.bigquery.JobLoadDestinationEncryptionConfiguration;
        /**
         * The destination table.
         * Structure is documented below.
         */
        destinationTable: outputs.bigquery.JobLoadDestinationTable;
        /**
         * The character encoding of the data. The supported values are UTF-8 or ISO-8859-1.
         * The default value is UTF-8. BigQuery decodes the data after the raw, binary data
         * has been split using the values of the quote and fieldDelimiter properties.
         */
        encoding?: string;
        /**
         * When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
         * Default is ','
         */
        fieldDelimiter: string;
        /**
         * Indicates if BigQuery should allow extra values that are not represented in the table schema.
         * If true, the extra values are ignored. If false, records with extra columns are treated as bad records,
         * and if there are too many bad records, an invalid error is returned in the job result.
         * The default value is false. The sourceFormat property determines what BigQuery treats as an extra value:
         * CSV: Trailing columns
         * JSON: Named values that don't match any column names
         */
        ignoreUnknownValues?: boolean;
        /**
         * The maximum number of bad records that BigQuery can ignore when running the job. If the number of bad records exceeds this value,
         * an invalid error is returned in the job result. The default value is 0, which requires that all records are valid.
         */
        maxBadRecords?: number;
        /**
         * Specifies a string that represents a null value in a CSV file. The default value is the empty string. If you set this
         * property to a custom value, BigQuery throws an error if an
         * empty string is present for all data types except for STRING and BYTE. For STRING and BYTE columns, BigQuery interprets the empty string as
         * an empty value.
         */
        nullMarker?: string;
        /**
         * If sourceFormat is set to "DATASTORE_BACKUP", indicates which entity properties to load into BigQuery from a Cloud Datastore backup.
         * Property names are case sensitive and must be top-level properties. If no properties are specified, BigQuery loads all properties.
         * If any named property isn't found in the Cloud Datastore backup, an invalid error is returned in the job result.
         */
        projectionFields?: string[];
        /**
         * The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding,
         * and then uses the first byte of the encoded string to split the data in its raw, binary state.
         * The default value is a double-quote ('"'). If your data does not contain quoted sections, set the property value to an empty string.
         * If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true.
         */
        quote: string;
        /**
         * Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
         * supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
         * when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
         * For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
         * ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
         * ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
         */
        schemaUpdateOptions?: string[];
        /**
         * The number of rows at the top of a CSV file that BigQuery will skip when loading the data.
         * The default value is 0. This property is useful if you have header rows in the file that should be skipped.
         * When autodetect is on, the behavior is the following:
         * skipLeadingRows unspecified - Autodetect tries to detect headers in the first row. If they are not detected,
         * the row is read as data. Otherwise data is read starting from the second row.
         * skipLeadingRows is 0 - Instructs autodetect that there are no headers and data should be read starting from the first row.
         * skipLeadingRows = N > 0 - Autodetect skips N-1 rows and tries to detect headers in row N. If headers are not detected,
         * row N is just skipped. Otherwise row N is used to extract column names for the detected schema.
         */
        skipLeadingRows?: number;
        /**
         * The format of the data files. For CSV files, specify "CSV". For datastore backups, specify "DATASTORE_BACKUP".
         * For newline-delimited JSON, specify "NEWLINE_DELIMITED_JSON". For Avro, specify "AVRO". For parquet, specify "PARQUET".
         * For orc, specify "ORC". [Beta] For Bigtable, specify "BIGTABLE".
         * The default value is CSV.
         */
        sourceFormat?: string;
        /**
         * The fully-qualified URIs that point to your data in Google Cloud.
         * For Google Cloud Storage URIs: Each URI can contain one '*' wildcard character
         * and it must come after the 'bucket' name. Size limits related to load jobs apply
         * to external data sources. For Google Cloud Bigtable URIs: Exactly one URI can be
         * specified and it has be a fully specified and valid HTTPS URL for a Google Cloud Bigtable table.
         * For Google Cloud Datastore backups: Exactly one URI can be specified. Also, the '*' wildcard character is not allowed.
         */
        sourceUris: string[];
        /**
         * Time-based partitioning specification for the destination table.
         * Structure is documented below.
         */
        timePartitioning?: outputs.bigquery.JobLoadTimePartitioning;
        /**
         * Specifies the action that occurs if the destination table already exists. The following values are supported:
         * WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
         * WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
         * WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
         * Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
         * Creation, truncation and append actions occur as one atomic update upon job completion.
         * Default value is `WRITE_EMPTY`.
         * Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
         */
        writeDisposition?: string;
    }

    export interface JobLoadDestinationEncryptionConfiguration {
        /**
         * Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
         * The BigQuery Service Account associated with your project requires access to this encryption key.
         */
        kmsKeyName: string;
        /**
         * -
         * Describes the Cloud KMS encryption key version used to protect destination BigQuery table.
         */
        kmsKeyVersion: string;
    }

    export interface JobLoadDestinationTable {
        /**
         * The ID of the dataset containing this model.
         */
        datasetId: string;
        /**
         * The ID of the project containing this model.
         */
        projectId: string;
        /**
         * The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
         * or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
         */
        tableId: string;
    }

    export interface JobLoadTimePartitioning {
        /**
         * Number of milliseconds for which to keep the storage for a partition. A wrapper is used here because 0 is an invalid value.
         */
        expirationMs?: string;
        /**
         * If not set, the table is partitioned by pseudo column '_PARTITIONTIME'; if set, the table is partitioned by this field.
         * The field must be a top-level TIMESTAMP or DATE field. Its mode must be NULLABLE or REQUIRED.
         * A wrapper is used here because an empty string is an invalid value.
         */
        field?: string;
        /**
         * The only type supported is DAY, which will generate one partition per day. Providing an empty string used to cause an error,
         * but in OnePlatform the field will be treated as unset.
         */
        type: string;
    }

    export interface JobQuery {
        /**
         * If true and query uses legacy SQL dialect, allows the query to produce arbitrarily large result tables at a slight cost in performance.
         * Requires destinationTable to be set. For standard SQL queries, this flag is ignored and large results are always allowed.
         * However, you must still set destinationTable when result size exceeds the allowed maximum response size.
         */
        allowLargeResults?: boolean;
        /**
         * Specifies whether the job is allowed to create new tables. The following values are supported:
         * CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
         * CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
         * Creation, truncation and append actions occur as one atomic update upon job completion
         * Default value is `CREATE_IF_NEEDED`.
         * Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
         */
        createDisposition?: string;
        /**
         * Specifies the default dataset to use for unqualified table names in the query. Note that this does not alter behavior of unqualified dataset names.
         * Structure is documented below.
         */
        defaultDataset?: outputs.bigquery.JobQueryDefaultDataset;
        /**
         * Custom encryption configuration (e.g., Cloud KMS keys)
         * Structure is documented below.
         */
        destinationEncryptionConfiguration?: outputs.bigquery.JobQueryDestinationEncryptionConfiguration;
        /**
         * The destination table.
         * Structure is documented below.
         */
        destinationTable?: outputs.bigquery.JobQueryDestinationTable;
        /**
         * If true and query uses legacy SQL dialect, flattens all nested and repeated fields in the query results.
         * allowLargeResults must be true if this is set to false. For standard SQL queries, this flag is ignored and results are never flattened.
         */
        flattenResults?: boolean;
        /**
         * Limits the billing tier for this job. Queries that have resource usage beyond this tier will fail (without incurring a charge).
         * If unspecified, this will be set to your project default.
         */
        maximumBillingTier?: number;
        /**
         * Limits the bytes billed for this job. Queries that will have bytes billed beyond this limit will fail (without incurring a charge).
         * If unspecified, this will be set to your project default.
         */
        maximumBytesBilled?: string;
        /**
         * Standard SQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query.
         */
        parameterMode?: string;
        /**
         * Specifies a priority for the query.
         * Default value is `INTERACTIVE`.
         * Possible values are `INTERACTIVE` and `BATCH`.
         */
        priority?: string;
        /**
         * Configures a query job.
         * Structure is documented below.
         */
        query: string;
        /**
         * Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
         * supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
         * when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
         * For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
         * ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
         * ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
         */
        schemaUpdateOptions?: string[];
        /**
         * Options controlling the execution of scripts.
         * Structure is documented below.
         */
        scriptOptions?: outputs.bigquery.JobQueryScriptOptions;
        /**
         * Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true.
         * If set to false, the query will use BigQuery's standard SQL.
         */
        useLegacySql?: boolean;
        /**
         * Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever
         * tables in the query are modified. Moreover, the query cache is only available when a query does not have a destination table specified.
         * The default value is true.
         */
        useQueryCache?: boolean;
        /**
         * Describes user-defined function resources used in the query.
         * Structure is documented below.
         */
        userDefinedFunctionResources?: outputs.bigquery.JobQueryUserDefinedFunctionResource[];
        /**
         * Specifies the action that occurs if the destination table already exists. The following values are supported:
         * WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
         * WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
         * WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
         * Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
         * Creation, truncation and append actions occur as one atomic update upon job completion.
         * Default value is `WRITE_EMPTY`.
         * Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
         */
        writeDisposition?: string;
    }

    export interface JobQueryDefaultDataset {
        /**
         * The ID of the dataset containing this model.
         */
        datasetId: string;
        /**
         * The ID of the project containing this model.
         */
        projectId: string;
    }

    export interface JobQueryDestinationEncryptionConfiguration {
        /**
         * Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
         * The BigQuery Service Account associated with your project requires access to this encryption key.
         */
        kmsKeyName: string;
        /**
         * -
         * Describes the Cloud KMS encryption key version used to protect destination BigQuery table.
         */
        kmsKeyVersion: string;
    }

    export interface JobQueryDestinationTable {
        /**
         * The ID of the dataset containing this model.
         */
        datasetId: string;
        /**
         * The ID of the project containing this model.
         */
        projectId: string;
        /**
         * The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
         * or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
         */
        tableId: string;
    }

    export interface JobQueryScriptOptions {
        /**
         * Determines which statement in the script represents the "key result",
         * used to populate the schema and query results of the script job.
         * Possible values are `LAST` and `FIRST_SELECT`.
         */
        keyResultStatement?: string;
        /**
         * Limit on the number of bytes billed per statement. Exceeding this budget results in an error.
         */
        statementByteBudget?: string;
        /**
         * Timeout period for each statement in a script.
         */
        statementTimeoutMs?: string;
    }

    export interface JobQueryUserDefinedFunctionResource {
        /**
         * An inline resource that contains code for a user-defined function (UDF).
         * Providing a inline code resource is equivalent to providing a URI for a file containing the same code.
         */
        inlineCode?: string;
        /**
         * A code resource to load from a Google Cloud Storage URI (gs://bucket/path).
         */
        resourceUri?: string;
    }

    export interface JobStatus {
        errorResults: outputs.bigquery.JobStatusErrorResult[];
        errors: outputs.bigquery.JobStatusError[];
        state: string;
    }

    export interface JobStatusError {
        /**
         * The geographic location of the job. The default value is US.
         */
        location?: string;
        message?: string;
        reason?: string;
    }

    export interface JobStatusErrorResult {
        /**
         * The geographic location of the job. The default value is US.
         */
        location?: string;
        message?: string;
        reason?: string;
    }

    export interface RoutineArgument {
        /**
         * Defaults to FIXED_TYPE.
         * Default value is `FIXED_TYPE`.
         * Possible values are `FIXED_TYPE` and `ANY_TYPE`.
         */
        argumentKind?: string;
        /**
         * A JSON schema for the data type. Required unless argumentKind = ANY_TYPE.
         * ~>**NOTE**: Because this field expects a JSON string, any changes to the string
         * will create a diff, even if the JSON itself hasn't changed. If the API returns
         * a different value for the same schema, e.g. it switched the order of values
         * or replaced STRUCT field type with RECORD field type, we currently cannot
         * suppress the recurring diff this causes. As a workaround, we recommend using
         * the schema as returned by the API.
         */
        dataType?: string;
        /**
         * Specifies whether the argument is input or output. Can be set for procedures only.
         * Possible values are `IN`, `OUT`, and `INOUT`.
         */
        mode?: string;
        /**
         * The name of this argument. Can be absent for function return argument.
         */
        name?: string;
    }

    export interface TableEncryptionConfiguration {
        /**
         * The self link or full name of a key which should be used to
         * encrypt this table.  Note that the default bigquery service account will need to have
         * encrypt/decrypt permissions on this key - you may want to see the
         * `gcp.bigquery.getDefaultServiceAccount` datasource and the
         * `gcp.kms.CryptoKeyIAMBinding` resource.
         */
        kmsKeyName: string;
        /**
         * The self link or full name of the kms key version used to encrypt this table.
         */
        kmsKeyVersion: string;
    }

    export interface TableExternalDataConfiguration {
        /**
         * - Let BigQuery try to autodetect the schema
         * and format of the table.
         */
        autodetect: boolean;
        /**
         * The compression type of the data source.
         * Valid values are "NONE" or "GZIP".
         */
        compression?: string;
        /**
         * Additional properties to set if
         * `sourceFormat` is set to "CSV". Structure is documented below.
         */
        csvOptions?: outputs.bigquery.TableExternalDataConfigurationCsvOptions;
        /**
         * Additional options if
         * `sourceFormat` is set to "GOOGLE_SHEETS". Structure is
         * documented below.
         */
        googleSheetsOptions?: outputs.bigquery.TableExternalDataConfigurationGoogleSheetsOptions;
        /**
         * When set, configures hive partitioning
         * support. Not all storage formats support hive partitioning -- requesting hive
         * partitioning on an unsupported format will lead to an error, as will providing
         * an invalid specification. Structure is documented below.
         */
        hivePartitioningOptions?: outputs.bigquery.TableExternalDataConfigurationHivePartitioningOptions;
        /**
         * Indicates if BigQuery should
         * allow extra values that are not represented in the table schema.
         * If true, the extra values are ignored. If false, records with
         * extra columns are treated as bad records, and if there are too
         * many bad records, an invalid error is returned in the job result.
         * The default value is false.
         */
        ignoreUnknownValues?: boolean;
        /**
         * The maximum number of bad records that
         * BigQuery can ignore when reading data.
         */
        maxBadRecords?: number;
        /**
         * A JSON schema for the external table. Schema is required
         * for CSV and JSON formats if autodetect is not on. Schema is disallowed
         * for Google Cloud Bigtable, Cloud Datastore backups, Avro, ORC and Parquet formats.
         * ~>**NOTE:** Because this field expects a JSON string, any changes to the
         * string will create a diff, even if the JSON itself hasn't changed.
         * Furthermore drift for this field cannot not be detected because BigQuery
         * only uses this schema to compute the effective schema for the table, therefore
         * any changes on the configured value will force the table to be recreated.
         * This schema is effectively only applied when creating a table from an external
         * datasource, after creation the computed schema will be stored in
         * `google_bigquery_table.schema`
         */
        schema: string;
        /**
         * The data format. Supported values are:
         * "CSV", "GOOGLE_SHEETS", "NEWLINE_DELIMITED_JSON", "AVRO", "PARQUET", "ORC",
         * "DATSTORE_BACKUP", and "BIGTABLE". To use "GOOGLE_SHEETS"
         * the `scopes` must include
         * "https://www.googleapis.com/auth/drive.readonly".
         */
        sourceFormat: string;
        /**
         * A list of the fully-qualified URIs that point to
         * your data in Google Cloud.
         */
        sourceUris: string[];
    }

    export interface TableExternalDataConfigurationCsvOptions {
        /**
         * Indicates if BigQuery should accept rows
         * that are missing trailing optional columns.
         */
        allowJaggedRows?: boolean;
        /**
         * Indicates if BigQuery should allow
         * quoted data sections that contain newline characters in a CSV file.
         * The default value is false.
         */
        allowQuotedNewlines?: boolean;
        /**
         * The character encoding of the data. The supported
         * values are UTF-8 or ISO-8859-1.
         */
        encoding?: string;
        /**
         * The separator for fields in a CSV file.
         */
        fieldDelimiter?: string;
        /**
         * The value that is used to quote data sections in a
         * CSV file. If your data does not contain quoted sections, set the
         * property value to an empty string. If your data contains quoted newline
         * characters, you must also set the `allowQuotedNewlines` property to true.
         * The API-side default is `"`, specified in the provider escaped as `\"`. Due to
         * limitations with default values, this value is required to be
         * explicitly set.
         */
        quote: string;
        /**
         * The number of rows at the top of the sheet
         * that BigQuery will skip when reading the data. At least one of `range` or
         * `skipLeadingRows` must be set.
         */
        skipLeadingRows?: number;
    }

    export interface TableExternalDataConfigurationGoogleSheetsOptions {
        /**
         * Information required to partition based on ranges.
         * Structure is documented below.
         */
        range?: string;
        /**
         * The number of rows at the top of the sheet
         * that BigQuery will skip when reading the data. At least one of `range` or
         * `skipLeadingRows` must be set.
         */
        skipLeadingRows?: number;
    }

    export interface TableExternalDataConfigurationHivePartitioningOptions {
        /**
         * When set, what mode of hive partitioning to use when
         * reading data. The following modes are supported.
         * * AUTO: automatically infer partition key name(s) and type(s).
         * * STRINGS: automatically infer partition key name(s). All types are
         * Not all storage formats support hive partitioning. Requesting hive
         * partitioning on an unsupported format will lead to an error.
         * Currently supported formats are: JSON, CSV, ORC, Avro and Parquet.
         * * CUSTOM: when set to `CUSTOM`, you must encode the partition key schema within the `sourceUriPrefix` by setting `sourceUriPrefix` to `gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}`.
         */
        mode?: string;
        /**
         * If set to true, queries over this table
         * require a partition filter that can be used for partition elimination to be
         * specified.
         */
        requirePartitionFilter?: boolean;
        /**
         * When hive partition detection is requested,
         * a common for all source uris must be required. The prefix must end immediately
         * before the partition key encoding begins. For example, consider files following
         * this data layout. `gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro`
         * `gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro` When hive
         * partitioning is requested with either AUTO or STRINGS detection, the common prefix
         * can be either of `gs://bucket/path_to_table` or `gs://bucket/path_to_table/`.
         * Note that when `mode` is set to `CUSTOM`, you must encode the partition key schema within the `sourceUriPrefix` by setting `sourceUriPrefix` to `gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}`.
         */
        sourceUriPrefix?: string;
    }

    export interface TableMaterializedView {
        /**
         * Specifies whether to use BigQuery's automatic refresh for this materialized view when the base table is updated.
         * The default value is true.
         */
        enableRefresh?: boolean;
        /**
         * A query whose result is persisted.
         */
        query: string;
        /**
         * The maximum frequency at which this materialized view will be refreshed.
         * The default value is 1800000
         */
        refreshIntervalMs?: number;
    }

    export interface TableRangePartitioning {
        /**
         * The field used to determine how to create a range-based
         * partition.
         */
        field: string;
        /**
         * Information required to partition based on ranges.
         * Structure is documented below.
         */
        range: outputs.bigquery.TableRangePartitioningRange;
    }

    export interface TableRangePartitioningRange {
        /**
         * End of the range partitioning, exclusive.
         */
        end: number;
        /**
         * The width of each range within the partition.
         */
        interval: number;
        /**
         * Start of the range partitioning, inclusive.
         */
        start: number;
    }

    export interface TableTimePartitioning {
        /**
         * Number of milliseconds for which to keep the
         * storage for a partition.
         */
        expirationMs: number;
        /**
         * The field used to determine how to create a range-based
         * partition.
         */
        field?: string;
        /**
         * If set to true, queries over this table
         * require a partition filter that can be used for partition elimination to be
         * specified.
         */
        requirePartitionFilter?: boolean;
        /**
         * The supported types are DAY, HOUR, MONTH, and YEAR,
         * which will generate one partition per day, hour, month, and year, respectively.
         */
        type: string;
    }

    export interface TableView {
        /**
         * A query whose result is persisted.
         */
        query: string;
        /**
         * Specifies whether to use BigQuery's legacy SQL for this view.
         * The default value is true. If set to false, the view will use BigQuery's standard SQL.
         */
        useLegacySql?: boolean;
    }

}

export namespace bigtable {
    export interface GCPolicyMaxAge {
        /**
         * Number of days before applying GC policy.
         *
         * @deprecated Deprecated in favor of duration
         */
        days: number;
        /**
         * Duration before applying GC policy (ex. "8h"). This is required when `days` isn't set
         */
        duration: string;
    }

    export interface GCPolicyMaxVersion {
        /**
         * Number of version before applying the GC policy.
         */
        number: number;
    }

    export interface InstanceCluster {
        /**
         * Autoscaling config for the cluster, contains the following arguments:
         */
        autoscalingConfig?: outputs.bigtable.InstanceClusterAutoscalingConfig;
        /**
         * The ID of the Cloud Bigtable cluster.
         */
        clusterId: string;
        /**
         * Describes the Cloud KMS encryption key that will be used to protect the destination Bigtable cluster. The requirements for this key are: 1) The Cloud Bigtable service account associated with the project that contains this cluster must be granted the `cloudkms.cryptoKeyEncrypterDecrypter` role on the CMEK key. 2) Only regional keys can be used and the region of the CMEK key must match the region of the cluster.
         */
        kmsKeyName: string;
        /**
         * The number of nodes in your Cloud Bigtable cluster.
         * Required, with a minimum of `1` for a `PRODUCTION` instance. Must be left unset
         * for a `DEVELOPMENT` instance.
         */
        numNodes: number;
        /**
         * The storage type to use. One of `"SSD"` or
         * `"HDD"`. Defaults to `"SSD"`.
         */
        storageType?: string;
        /**
         * The zone to create the Cloud Bigtable cluster in. If it not
         * specified, the provider zone is used. Each cluster must have a different zone in the same region. Zones that support
         * Bigtable instances are noted on the [Cloud Bigtable locations page](https://cloud.google.com/bigtable/docs/locations).
         */
        zone: string;
    }

    export interface InstanceClusterAutoscalingConfig {
        /**
         * The CPU utilization target in percentage. Must be between 10 and 80.
         */
        cpuTarget: number;
        /**
         * The maximum number of nodes for autoscaling.
         */
        maxNodes: number;
        /**
         * The minimum number of nodes for autoscaling.
         */
        minNodes: number;
    }

    export interface InstanceIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface InstanceIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface TableColumnFamily {
        /**
         * The name of the column family.
         */
        family: string;
    }

    export interface TableIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface TableIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

}

export namespace billing {
    export interface AccountIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface AccountIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface BudgetAllUpdatesRule {
        /**
         * Boolean. When set to true, disables default notifications sent
         * when a threshold is exceeded. Default recipients are
         * those with Billing Account Administrators and Billing
         * Account Users IAM roles for the target account.
         */
        disableDefaultIamRecipients?: boolean;
        /**
         * The full resource name of a monitoring notification
         * channel in the form
         * projects/{project_id}/notificationChannels/{channel_id}.
         * A maximum of 5 channels are allowed.
         */
        monitoringNotificationChannels?: string[];
        /**
         * The name of the Cloud Pub/Sub topic where budget related
         * messages will be published, in the form
         * projects/{project_id}/topics/{topic_id}. Updates are sent
         * at regular intervals to the topic.
         */
        pubsubTopic?: string;
        /**
         * The schema version of the notification. Only "1.0" is
         * accepted. It represents the JSON schema as defined in
         * https://cloud.google.com/billing/docs/how-to/budgets#notification_format.
         */
        schemaVersion?: string;
    }

    export interface BudgetAmount {
        /**
         * Configures a budget amount that is automatically set to 100% of
         * last period's spend.
         * Boolean. Set value to true to use. Do not set to false, instead
         * use the `specifiedAmount` block.
         */
        lastPeriodAmount?: boolean;
        /**
         * A specified amount to use as the budget. currencyCode is
         * optional. If specified, it must match the currency of the
         * billing account. The currencyCode is provided on output.
         * Structure is documented below.
         */
        specifiedAmount?: outputs.billing.BudgetAmountSpecifiedAmount;
    }

    export interface BudgetAmountSpecifiedAmount {
        /**
         * The 3-letter currency code defined in ISO 4217.
         */
        currencyCode: string;
        /**
         * Number of nano (10^-9) units of the amount.
         * The value must be between -999,999,999 and +999,999,999
         * inclusive. If units is positive, nanos must be positive or
         * zero. If units is zero, nanos can be positive, zero, or
         * negative. If units is negative, nanos must be negative or
         * zero. For example $-1.75 is represented as units=-1 and
         * nanos=-750,000,000.
         */
        nanos?: number;
        /**
         * The whole units of the amount. For example if currencyCode
         * is "USD", then 1 unit is one US dollar.
         */
        units?: string;
    }

    export interface BudgetBudgetFilter {
        /**
         * A set of subaccounts of the form billingAccounts/{account_id},
         * specifying that usage from only this set of subaccounts should
         * be included in the budget. If a subaccount is set to the name of
         * the parent account, usage from the parent account will be included.
         * If the field is omitted, the report will include usage from the parent
         * account and all subaccounts, if they exist.
         */
        creditTypes: string[];
        /**
         * Specifies how credits should be treated when determining spend
         * for threshold calculations.
         * Default value is `INCLUDE_ALL_CREDITS`.
         * Possible values are `INCLUDE_ALL_CREDITS`, `EXCLUDE_ALL_CREDITS`, and `INCLUDE_SPECIFIED_CREDITS`.
         */
        creditTypesTreatment?: string;
        /**
         * A single label and value pair specifying that usage from only
         * this set of labeled resources should be included in the budget.
         */
        labels: {[key: string]: string};
        /**
         * A set of projects of the form projects/{project_number},
         * specifying that usage from only this set of projects should be
         * included in the budget. If omitted, the report will include
         * all usage for the billing account, regardless of which project
         * the usage occurred on.
         */
        projects?: string[];
        /**
         * A set of services of the form services/{service_id},
         * specifying that usage from only this set of services should be
         * included in the budget. If omitted, the report will include
         * usage for all the services. The service names are available
         * through the Catalog API:
         * https://cloud.google.com/billing/v1/how-tos/catalog-api.
         */
        services: string[];
        /**
         * A set of subaccounts of the form billingAccounts/{account_id},
         * specifying that usage from only this set of subaccounts should
         * be included in the budget. If a subaccount is set to the name of
         * the parent account, usage from the parent account will be included.
         * If the field is omitted, the report will include usage from the parent
         * account and all subaccounts, if they exist.
         */
        subaccounts: string[];
    }

    export interface BudgetThresholdRule {
        /**
         * The type of basis used to determine if spend has passed
         * the threshold.
         * Default value is `CURRENT_SPEND`.
         * Possible values are `CURRENT_SPEND` and `FORECASTED_SPEND`.
         */
        spendBasis?: string;
        /**
         * Send an alert when this threshold is exceeded. This is a
         * 1.0-based percentage, so 0.5 = 50%. Must be >= 0.
         */
        thresholdPercent: number;
    }

}

export namespace binaryauthorization {
    export interface AttestorAttestationAuthorityNote {
        /**
         * -
         * This field will contain the service account email address that
         * this Attestor will use as the principal when querying Container
         * Analysis. Attestor administrators must grant this service account
         * the IAM role needed to read attestations from the noteReference in
         * Container Analysis (containeranalysis.notes.occurrences.viewer).
         * This email address is fixed for the lifetime of the Attestor, but
         * callers should not make any other assumptions about the service
         * account email; future versions may use an email based on a
         * different naming pattern.
         */
        delegationServiceAccountEmail: string;
        /**
         * The resource name of a ATTESTATION_AUTHORITY Note, created by the
         * user. If the Note is in a different project from the Attestor, it
         * should be specified in the format `projects/*&#47;notes/*` (or the legacy
         * `providers/*&#47;notes/*`). This field may not be updated.
         * An attestation by this attestor is stored as a Container Analysis
         * ATTESTATION_AUTHORITY Occurrence that names a container image
         * and that links to this Note.
         */
        noteReference: string;
        /**
         * Public keys that verify attestations signed by this attestor. This
         * field may be updated.
         * If this field is non-empty, one of the specified public keys must
         * verify that an attestation was signed by this attestor for the
         * image specified in the admission request.
         * If this field is empty, this attestor always returns that no valid
         * attestations exist.
         * Structure is documented below.
         */
        publicKeys?: outputs.binaryauthorization.AttestorAttestationAuthorityNotePublicKey[];
    }

    export interface AttestorAttestationAuthorityNotePublicKey {
        /**
         * ASCII-armored representation of a PGP public key, as the
         * entire output by the command
         * `gpg --export --armor foo@example.com` (either LF or CRLF
         * line endings). When using this field, id should be left
         * blank. The BinAuthz API handlers will calculate the ID
         * and fill it in automatically. BinAuthz computes this ID
         * as the OpenPGP RFC4880 V4 fingerprint, represented as
         * upper-case hex. If id is provided by the caller, it will
         * be overwritten by the API-calculated ID.
         */
        asciiArmoredPgpPublicKey?: string;
        /**
         * A descriptive comment. This field may be updated.
         */
        comment?: string;
        /**
         * The ID of this public key. Signatures verified by BinAuthz
         * must include the ID of the public key that can be used to
         * verify them, and that ID must match the contents of this
         * field exactly. Additional restrictions on this field can
         * be imposed based on which public key type is encapsulated.
         * See the documentation on publicKey cases below for details.
         */
        id: string;
        /**
         * A raw PKIX SubjectPublicKeyInfo format public key.
         * NOTE: id may be explicitly provided by the caller when using this
         * type of public key, but it MUST be a valid RFC3986 URI. If id is left
         * blank, a default one will be computed based on the digest of the DER
         * encoding of the public key.
         * Structure is documented below.
         */
        pkixPublicKey?: outputs.binaryauthorization.AttestorAttestationAuthorityNotePublicKeyPkixPublicKey;
    }

    export interface AttestorAttestationAuthorityNotePublicKeyPkixPublicKey {
        /**
         * A PEM-encoded public key, as described in
         * `https://tools.ietf.org/html/rfc7468#section-13`
         */
        publicKeyPem?: string;
        /**
         * The signature algorithm used to verify a message against
         * a signature using this key. These signature algorithm must
         * match the structure and any object identifiers encoded in
         * publicKeyPem (i.e. this algorithm must match that of the
         * public key).
         */
        signatureAlgorithm?: string;
    }

    export interface AttestorIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface AttestorIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface PolicyAdmissionWhitelistPattern {
        /**
         * An image name pattern to whitelist, in the form
         * `registry/path/to/image`. This supports a trailing * as a
         * wildcard, but this is allowed only in text after the registry/
         * part.
         */
        namePattern: string;
    }

    export interface PolicyClusterAdmissionRule {
        /**
         * The identifier for this object. Format specified above.
         */
        cluster: string;
        /**
         * The action when a pod creation is denied by the admission rule.
         * Possible values are `ENFORCED_BLOCK_AND_AUDIT_LOG` and `DRYRUN_AUDIT_LOG_ONLY`.
         */
        enforcementMode: string;
        /**
         * How this admission rule will be evaluated.
         * Possible values are `ALWAYS_ALLOW`, `REQUIRE_ATTESTATION`, and `ALWAYS_DENY`.
         */
        evaluationMode: string;
        /**
         * The resource names of the attestors that must attest to a
         * container image. If the attestor is in a different project from the
         * policy, it should be specified in the format `projects/*&#47;attestors/*`.
         * Each attestor must exist before a policy can reference it. To add an
         * attestor to a policy the principal issuing the policy change
         * request must be able to read the attestor resource.
         * Note: this field must be non-empty when the evaluationMode field
         * specifies REQUIRE_ATTESTATION, otherwise it must be empty.
         */
        requireAttestationsBies?: string[];
    }

    export interface PolicyDefaultAdmissionRule {
        /**
         * The action when a pod creation is denied by the admission rule.
         * Possible values are `ENFORCED_BLOCK_AND_AUDIT_LOG` and `DRYRUN_AUDIT_LOG_ONLY`.
         */
        enforcementMode: string;
        /**
         * How this admission rule will be evaluated.
         * Possible values are `ALWAYS_ALLOW`, `REQUIRE_ATTESTATION`, and `ALWAYS_DENY`.
         */
        evaluationMode: string;
        /**
         * The resource names of the attestors that must attest to a
         * container image. If the attestor is in a different project from the
         * policy, it should be specified in the format `projects/*&#47;attestors/*`.
         * Each attestor must exist before a policy can reference it. To add an
         * attestor to a policy the principal issuing the policy change
         * request must be able to read the attestor resource.
         * Note: this field must be non-empty when the evaluationMode field
         * specifies REQUIRE_ATTESTATION, otherwise it must be empty.
         */
        requireAttestationsBies?: string[];
    }

}

export namespace certificateauthority {
    export interface AuthorityAccessUrl {
        caCertificateAccessUrl: string;
        crlAccessUrls: string[];
    }

    export interface AuthorityConfig {
        /**
         * Specifies some of the values in a certificate that are related to the subject.
         * Structure is documented below.
         */
        subjectConfig: outputs.certificateauthority.AuthorityConfigSubjectConfig;
        /**
         * Describes how some of the technical X.509 fields in a certificate should be populated.
         * Structure is documented below.
         */
        x509Config: outputs.certificateauthority.AuthorityConfigX509Config;
    }

    export interface AuthorityConfigSubjectConfig {
        /**
         * Contains distinguished name fields such as the location and organization.
         * Structure is documented below.
         */
        subject: outputs.certificateauthority.AuthorityConfigSubjectConfigSubject;
        /**
         * The subject alternative name fields.
         * Structure is documented below.
         */
        subjectAltName?: outputs.certificateauthority.AuthorityConfigSubjectConfigSubjectAltName;
    }

    export interface AuthorityConfigSubjectConfigSubject {
        /**
         * The common name of the distinguished name.
         */
        commonName: string;
        /**
         * The country code of the subject.
         */
        countryCode?: string;
        /**
         * The locality or city of the subject.
         */
        locality?: string;
        /**
         * The organization of the subject.
         */
        organization: string;
        /**
         * The organizational unit of the subject.
         */
        organizationalUnit?: string;
        /**
         * The postal code of the subject.
         */
        postalCode?: string;
        /**
         * The province, territory, or regional state of the subject.
         */
        province?: string;
        /**
         * The street address of the subject.
         */
        streetAddress?: string;
    }

    export interface AuthorityConfigSubjectConfigSubjectAltName {
        /**
         * Contains only valid, fully-qualified host names.
         */
        dnsNames?: string[];
        /**
         * Contains only valid RFC 2822 E-mail addresses.
         */
        emailAddresses?: string[];
        /**
         * Contains only valid 32-bit IPv4 addresses or RFC 4291 IPv6 addresses.
         */
        ipAddresses?: string[];
        /**
         * Contains only valid RFC 3986 URIs.
         */
        uris?: string[];
    }

    export interface AuthorityConfigX509Config {
        /**
         * Specifies an X.509 extension, which may be used in different parts of X.509 objects like certificates, CSRs, and CRLs.
         * Structure is documented below.
         */
        additionalExtensions?: outputs.certificateauthority.AuthorityConfigX509ConfigAdditionalExtension[];
        /**
         * Describes Online Certificate Status Protocol (OCSP) endpoint addresses that appear in the
         * "Authority Information Access" extension in the certificate.
         */
        aiaOcspServers?: string[];
        /**
         * Describes values that are relevant in a CA certificate.
         * Structure is documented below.
         */
        caOptions: outputs.certificateauthority.AuthorityConfigX509ConfigCaOptions;
        /**
         * Indicates the intended use for keys that correspond to a certificate.
         * Structure is documented below.
         */
        keyUsage: outputs.certificateauthority.AuthorityConfigX509ConfigKeyUsage;
        /**
         * Describes the X.509 certificate policy object identifiers, per https://tools.ietf.org/html/rfc5280#section-4.2.1.4.
         * Structure is documented below.
         */
        policyIds?: outputs.certificateauthority.AuthorityConfigX509ConfigPolicyId[];
    }

    export interface AuthorityConfigX509ConfigAdditionalExtension {
        /**
         * Indicates whether or not this extension is critical (i.e., if the client does not know how to
         * handle this extension, the client should consider this to be an error).
         */
        critical: boolean;
        /**
         * Describes values that are relevant in a CA certificate.
         * Structure is documented below.
         */
        objectId: outputs.certificateauthority.AuthorityConfigX509ConfigAdditionalExtensionObjectId;
        /**
         * The value of this X.509 extension. A base64-encoded string.
         */
        value: string;
    }

    export interface AuthorityConfigX509ConfigAdditionalExtensionObjectId {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface AuthorityConfigX509ConfigCaOptions {
        /**
         * When true, the "CA" in Basic Constraints extension will be set to true.
         */
        isCa: boolean;
        /**
         * Refers to the "path length constraint" in Basic Constraints extension. For a CA certificate, this value describes the depth of
         * subordinate CA certificates that are allowed. If this value is less than 0, the request will fail.
         */
        maxIssuerPathLength?: number;
        /**
         * When true, the "CA" in Basic Constraints extension will be set to false.
         * If both `isCa` and `nonCa` are unset, the extension will be omitted from the CA certificate.
         */
        nonCa?: boolean;
        /**
         * When true, the "path length constraint" in Basic Constraints extension will be set to 0.
         * if both `maxIssuerPathLength` and `zeroMaxIssuerPathLength` are unset,
         * the max path length will be omitted from the CA certificate.
         */
        zeroMaxIssuerPathLength?: boolean;
    }

    export interface AuthorityConfigX509ConfigKeyUsage {
        /**
         * Describes high-level ways in which a key may be used.
         * Structure is documented below.
         */
        baseKeyUsage: outputs.certificateauthority.AuthorityConfigX509ConfigKeyUsageBaseKeyUsage;
        /**
         * Describes high-level ways in which a key may be used.
         * Structure is documented below.
         */
        extendedKeyUsage: outputs.certificateauthority.AuthorityConfigX509ConfigKeyUsageExtendedKeyUsage;
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         * Structure is documented below.
         */
        unknownExtendedKeyUsages?: outputs.certificateauthority.AuthorityConfigX509ConfigKeyUsageUnknownExtendedKeyUsage[];
    }

    export interface AuthorityConfigX509ConfigKeyUsageBaseKeyUsage {
        /**
         * The key may be used to sign certificates.
         */
        certSign?: boolean;
        /**
         * The key may be used for cryptographic commitments. Note that this may also be referred to as "non-repudiation".
         */
        contentCommitment?: boolean;
        /**
         * The key may be used sign certificate revocation lists.
         */
        crlSign?: boolean;
        /**
         * The key may be used to encipher data.
         */
        dataEncipherment?: boolean;
        /**
         * The key may be used to decipher only.
         */
        decipherOnly?: boolean;
        /**
         * The key may be used for digital signatures.
         */
        digitalSignature?: boolean;
        /**
         * The key may be used to encipher only.
         */
        encipherOnly?: boolean;
        /**
         * The key may be used in a key agreement protocol.
         */
        keyAgreement?: boolean;
        /**
         * The key may be used to encipher other keys.
         */
        keyEncipherment?: boolean;
    }

    export interface AuthorityConfigX509ConfigKeyUsageExtendedKeyUsage {
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.2. Officially described as "TLS WWW client authentication", though regularly used for non-WWW TLS.
         */
        clientAuth?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.3. Officially described as "Signing of downloadable executable code client authentication".
         */
        codeSigning?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.4. Officially described as "Email protection".
         */
        emailProtection?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.9. Officially described as "Signing OCSP responses".
         */
        ocspSigning?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.1. Officially described as "TLS WWW server authentication", though regularly used for non-WWW TLS.
         */
        serverAuth?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.8. Officially described as "Binding the hash of an object to a time".
         */
        timeStamping?: boolean;
    }

    export interface AuthorityConfigX509ConfigKeyUsageUnknownExtendedKeyUsage {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface AuthorityConfigX509ConfigPolicyId {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface AuthorityKeySpec {
        /**
         * The algorithm to use for creating a managed Cloud KMS key for a for a simplified
         * experience. All managed keys will be have their ProtectionLevel as HSM.
         * Possible values are `SIGN_HASH_ALGORITHM_UNSPECIFIED`, `RSA_PSS_2048_SHA256`, `RSA_PSS_3072_SHA256`, `RSA_PSS_4096_SHA256`, `RSA_PKCS1_2048_SHA256`, `RSA_PKCS1_3072_SHA256`, `RSA_PKCS1_4096_SHA256`, `EC_P256_SHA256`, and `EC_P384_SHA384`.
         */
        algorithm?: string;
        /**
         * The resource name for an existing Cloud KMS CryptoKeyVersion in the format
         * `projects/*&#47;locations/*&#47;keyRings/*&#47;cryptoKeys/*&#47;cryptoKeyVersions/*`.
         */
        cloudKmsKeyVersion?: string;
    }

    export interface CaPoolIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface CaPoolIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface CaPoolIssuancePolicy {
        /**
         * IssuanceModes specifies the allowed ways in which Certificates may be requested from this CaPool.
         * Structure is documented below.
         */
        allowedIssuanceModes?: outputs.certificateauthority.CaPoolIssuancePolicyAllowedIssuanceModes;
        /**
         * If any AllowedKeyType is specified, then the certificate request's public key must match one of the key types listed here.
         * Otherwise, any key may be used.
         * Structure is documented below.
         */
        allowedKeyTypes?: outputs.certificateauthority.CaPoolIssuancePolicyAllowedKeyType[];
        /**
         * A set of X.509 values that will be applied to all certificates issued through this CaPool. If a certificate request
         * includes conflicting values for the same properties, they will be overwritten by the values defined here. If a certificate
         * request uses a CertificateTemplate that defines conflicting predefinedValues for the same properties, the certificate
         * issuance request will fail.
         * Structure is documented below.
         */
        baselineValues?: outputs.certificateauthority.CaPoolIssuancePolicyBaselineValues;
        /**
         * Describes constraints on identities that may appear in Certificates issued through this CaPool.
         * If this is omitted, then this CaPool will not add restrictions on a certificate's identity.
         * Structure is documented below.
         */
        identityConstraints?: outputs.certificateauthority.CaPoolIssuancePolicyIdentityConstraints;
        /**
         * The maximum lifetime allowed for issued Certificates. Note that if the issuing CertificateAuthority
         * expires before a Certificate's requested maximumLifetime, the effective lifetime will be explicitly truncated to match it.
         */
        maximumLifetime?: string;
    }

    export interface CaPoolIssuancePolicyAllowedIssuanceModes {
        /**
         * When true, allows callers to create Certificates by specifying a CertificateConfig.
         */
        allowConfigBasedIssuance: boolean;
        /**
         * When true, allows callers to create Certificates by specifying a CSR.
         */
        allowCsrBasedIssuance: boolean;
    }

    export interface CaPoolIssuancePolicyAllowedKeyType {
        /**
         * Represents an allowed Elliptic Curve key type.
         * Structure is documented below.
         */
        ellipticCurve?: outputs.certificateauthority.CaPoolIssuancePolicyAllowedKeyTypeEllipticCurve;
        /**
         * Describes an RSA key that may be used in a Certificate issued from a CaPool.
         * Structure is documented below.
         */
        rsa?: outputs.certificateauthority.CaPoolIssuancePolicyAllowedKeyTypeRsa;
    }

    export interface CaPoolIssuancePolicyAllowedKeyTypeEllipticCurve {
        /**
         * The algorithm used.
         * Possible values are `ECDSA_P256`, `ECDSA_P384`, and `EDDSA_25519`.
         */
        signatureAlgorithm: string;
    }

    export interface CaPoolIssuancePolicyAllowedKeyTypeRsa {
        /**
         * The maximum allowed RSA modulus size, in bits. If this is not set, or if set to zero, the
         * service will not enforce an explicit upper bound on RSA modulus sizes.
         */
        maxModulusSize?: string;
        /**
         * The minimum allowed RSA modulus size, in bits. If this is not set, or if set to zero, the
         * service-level min RSA modulus size will continue to apply.
         */
        minModulusSize?: string;
    }

    export interface CaPoolIssuancePolicyBaselineValues {
        /**
         * Specifies an X.509 extension, which may be used in different parts of X.509 objects like certificates, CSRs, and CRLs.
         * Structure is documented below.
         */
        additionalExtensions?: outputs.certificateauthority.CaPoolIssuancePolicyBaselineValuesAdditionalExtension[];
        /**
         * Describes Online Certificate Status Protocol (OCSP) endpoint addresses that appear in the
         * "Authority Information Access" extension in the certificate.
         */
        aiaOcspServers?: string[];
        /**
         * Describes values that are relevant in a CA certificate.
         * Structure is documented below.
         */
        caOptions: outputs.certificateauthority.CaPoolIssuancePolicyBaselineValuesCaOptions;
        /**
         * Indicates the intended use for keys that correspond to a certificate.
         * Structure is documented below.
         */
        keyUsage: outputs.certificateauthority.CaPoolIssuancePolicyBaselineValuesKeyUsage;
        /**
         * Describes the X.509 certificate policy object identifiers, per https://tools.ietf.org/html/rfc5280#section-4.2.1.4.
         * Structure is documented below.
         */
        policyIds?: outputs.certificateauthority.CaPoolIssuancePolicyBaselineValuesPolicyId[];
    }

    export interface CaPoolIssuancePolicyBaselineValuesAdditionalExtension {
        /**
         * Indicates whether or not this extension is critical (i.e., if the client does not know how to
         * handle this extension, the client should consider this to be an error).
         */
        critical: boolean;
        /**
         * Describes values that are relevant in a CA certificate.
         * Structure is documented below.
         */
        objectId: outputs.certificateauthority.CaPoolIssuancePolicyBaselineValuesAdditionalExtensionObjectId;
        /**
         * The value of this X.509 extension. A base64-encoded string.
         */
        value: string;
    }

    export interface CaPoolIssuancePolicyBaselineValuesAdditionalExtensionObjectId {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface CaPoolIssuancePolicyBaselineValuesCaOptions {
        /**
         * When true, the "CA" in Basic Constraints extension will be set to true.
         */
        isCa?: boolean;
        /**
         * Refers to the "path length constraint" in Basic Constraints extension. For a CA certificate, this value describes the depth of
         * subordinate CA certificates that are allowed. If this value is less than 0, the request will fail.
         */
        maxIssuerPathLength?: number;
        /**
         * When true, the "CA" in Basic Constraints extension will be set to false.
         * If both `isCa` and `nonCa` are unset, the extension will be omitted from the CA certificate.
         */
        nonCa?: boolean;
        /**
         * When true, the "path length constraint" in Basic Constraints extension will be set to 0.
         * if both `maxIssuerPathLength` and `zeroMaxIssuerPathLength` are unset,
         * the max path length will be omitted from the CA certificate.
         */
        zeroMaxIssuerPathLength?: boolean;
    }

    export interface CaPoolIssuancePolicyBaselineValuesKeyUsage {
        /**
         * Describes high-level ways in which a key may be used.
         * Structure is documented below.
         */
        baseKeyUsage: outputs.certificateauthority.CaPoolIssuancePolicyBaselineValuesKeyUsageBaseKeyUsage;
        /**
         * Describes high-level ways in which a key may be used.
         * Structure is documented below.
         */
        extendedKeyUsage: outputs.certificateauthority.CaPoolIssuancePolicyBaselineValuesKeyUsageExtendedKeyUsage;
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         * Structure is documented below.
         */
        unknownExtendedKeyUsages?: outputs.certificateauthority.CaPoolIssuancePolicyBaselineValuesKeyUsageUnknownExtendedKeyUsage[];
    }

    export interface CaPoolIssuancePolicyBaselineValuesKeyUsageBaseKeyUsage {
        /**
         * The key may be used to sign certificates.
         */
        certSign?: boolean;
        /**
         * The key may be used for cryptographic commitments. Note that this may also be referred to as "non-repudiation".
         */
        contentCommitment?: boolean;
        /**
         * The key may be used sign certificate revocation lists.
         */
        crlSign?: boolean;
        /**
         * The key may be used to encipher data.
         */
        dataEncipherment?: boolean;
        /**
         * The key may be used to decipher only.
         */
        decipherOnly?: boolean;
        /**
         * The key may be used for digital signatures.
         */
        digitalSignature?: boolean;
        /**
         * The key may be used to encipher only.
         */
        encipherOnly?: boolean;
        /**
         * The key may be used in a key agreement protocol.
         */
        keyAgreement?: boolean;
        /**
         * The key may be used to encipher other keys.
         */
        keyEncipherment?: boolean;
    }

    export interface CaPoolIssuancePolicyBaselineValuesKeyUsageExtendedKeyUsage {
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.2. Officially described as "TLS WWW client authentication", though regularly used for non-WWW TLS.
         */
        clientAuth?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.3. Officially described as "Signing of downloadable executable code client authentication".
         */
        codeSigning?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.4. Officially described as "Email protection".
         */
        emailProtection?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.9. Officially described as "Signing OCSP responses".
         */
        ocspSigning?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.1. Officially described as "TLS WWW server authentication", though regularly used for non-WWW TLS.
         */
        serverAuth?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.8. Officially described as "Binding the hash of an object to a time".
         */
        timeStamping?: boolean;
    }

    export interface CaPoolIssuancePolicyBaselineValuesKeyUsageUnknownExtendedKeyUsage {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface CaPoolIssuancePolicyBaselineValuesPolicyId {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface CaPoolIssuancePolicyIdentityConstraints {
        /**
         * If this is set, the SubjectAltNames extension may be copied from a certificate request into the signed certificate.
         * Otherwise, the requested SubjectAltNames will be discarded.
         */
        allowSubjectAltNamesPassthrough: boolean;
        /**
         * If this is set, the Subject field may be copied from a certificate request into the signed certificate.
         * Otherwise, the requested Subject will be discarded.
         */
        allowSubjectPassthrough: boolean;
        /**
         * A CEL expression that may be used to validate the resolved X.509 Subject and/or Subject Alternative Name before a
         * certificate is signed. To see the full allowed syntax and some examples,
         * see https://cloud.google.com/certificate-authority-service/docs/cel-guide
         * Structure is documented below.
         */
        celExpression?: outputs.certificateauthority.CaPoolIssuancePolicyIdentityConstraintsCelExpression;
    }

    export interface CaPoolIssuancePolicyIdentityConstraintsCelExpression {
        /**
         * Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
         */
        location?: string;
        /**
         * Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
         */
        title?: string;
    }

    export interface CaPoolPublishingOptions {
        /**
         * When true, publishes each CertificateAuthority's CA certificate and includes its URL in the "Authority Information Access"
         * X.509 extension in all issued Certificates. If this is false, the CA certificate will not be published and the corresponding
         * X.509 extension will not be written in issued certificates.
         */
        publishCaCert: boolean;
        /**
         * When true, publishes each CertificateAuthority's CRL and includes its URL in the "CRL Distribution Points" X.509 extension
         * in all issued Certificates. If this is false, CRLs will not be published and the corresponding X.509 extension will not
         * be written in issued certificates. CRLs will expire 7 days from their creation. However, we will rebuild daily. CRLs are
         * also rebuilt shortly after a certificate is revoked.
         */
        publishCrl: boolean;
    }

    export interface CertificateCertificateDescription {
        aiaIssuingCertificateUrls: string[];
        authorityKeyIds: outputs.certificateauthority.CertificateCertificateDescriptionAuthorityKeyId[];
        certFingerprints: outputs.certificateauthority.CertificateCertificateDescriptionCertFingerprint[];
        /**
         * @deprecated Deprecated in favor of `x509_description`.
         */
        configValues: outputs.certificateauthority.CertificateCertificateDescriptionConfigValue[];
        crlDistributionPoints: string[];
        /**
         * A PublicKey describes a public key.
         * Structure is documented below.
         */
        publicKeys: outputs.certificateauthority.CertificateCertificateDescriptionPublicKey[];
        subjectDescriptions: outputs.certificateauthority.CertificateCertificateDescriptionSubjectDescription[];
        subjectKeyIds: outputs.certificateauthority.CertificateCertificateDescriptionSubjectKeyId[];
        x509Descriptions: outputs.certificateauthority.CertificateCertificateDescriptionX509Description[];
    }

    export interface CertificateCertificateDescriptionAuthorityKeyId {
        keyId: string;
    }

    export interface CertificateCertificateDescriptionCertFingerprint {
        sha256Hash: string;
    }

    export interface CertificateCertificateDescriptionConfigValue {
        /**
         * Indicates the intended use for keys that correspond to a certificate.
         * Structure is documented below.
         */
        keyUsages: outputs.certificateauthority.CertificateCertificateDescriptionConfigValueKeyUsage[];
    }

    export interface CertificateCertificateDescriptionConfigValueKeyUsage {
        /**
         * Describes high-level ways in which a key may be used.
         * Structure is documented below.
         */
        baseKeyUsages: outputs.certificateauthority.CertificateCertificateDescriptionConfigValueKeyUsageBaseKeyUsage[];
        /**
         * Describes high-level ways in which a key may be used.
         * Structure is documented below.
         */
        extendedKeyUsages: outputs.certificateauthority.CertificateCertificateDescriptionConfigValueKeyUsageExtendedKeyUsage[];
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         * Structure is documented below.
         */
        unknownExtendedKeyUsages: outputs.certificateauthority.CertificateCertificateDescriptionConfigValueKeyUsageUnknownExtendedKeyUsage[];
    }

    export interface CertificateCertificateDescriptionConfigValueKeyUsageBaseKeyUsage {
        keyUsageOptions: outputs.certificateauthority.CertificateCertificateDescriptionConfigValueKeyUsageBaseKeyUsageKeyUsageOption[];
    }

    export interface CertificateCertificateDescriptionConfigValueKeyUsageBaseKeyUsageKeyUsageOption {
        /**
         * The key may be used to sign certificates.
         */
        certSign: boolean;
        /**
         * The key may be used for cryptographic commitments. Note that this may also be referred to as "non-repudiation".
         */
        contentCommitment: boolean;
        /**
         * The key may be used sign certificate revocation lists.
         */
        crlSign: boolean;
        /**
         * The key may be used to encipher data.
         */
        dataEncipherment: boolean;
        /**
         * The key may be used to decipher only.
         */
        decipherOnly: boolean;
        /**
         * The key may be used for digital signatures.
         */
        digitalSignature: boolean;
        /**
         * The key may be used to encipher only.
         */
        encipherOnly: boolean;
        /**
         * The key may be used in a key agreement protocol.
         */
        keyAgreement: boolean;
        /**
         * The key may be used to encipher other keys.
         */
        keyEncipherment: boolean;
    }

    export interface CertificateCertificateDescriptionConfigValueKeyUsageExtendedKeyUsage {
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.2. Officially described as "TLS WWW client authentication", though regularly used for non-WWW TLS.
         */
        clientAuth: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.3. Officially described as "Signing of downloadable executable code client authentication".
         */
        codeSigning: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.4. Officially described as "Email protection".
         */
        emailProtection: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.9. Officially described as "Signing OCSP responses".
         */
        ocspSigning: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.1. Officially described as "TLS WWW server authentication", though regularly used for non-WWW TLS.
         */
        serverAuth: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.8. Officially described as "Binding the hash of an object to a time".
         */
        timeStamping: boolean;
    }

    export interface CertificateCertificateDescriptionConfigValueKeyUsageUnknownExtendedKeyUsage {
        obectIds: outputs.certificateauthority.CertificateCertificateDescriptionConfigValueKeyUsageUnknownExtendedKeyUsageObectId[];
    }

    export interface CertificateCertificateDescriptionConfigValueKeyUsageUnknownExtendedKeyUsageObectId {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface CertificateCertificateDescriptionPublicKey {
        /**
         * The format of the public key. Currently, only PEM format is supported.
         * Possible values are `KEY_TYPE_UNSPECIFIED` and `PEM`.
         */
        format: string;
        /**
         * Required. A public key. When this is specified in a request, the padding and encoding can be any of the options described by the respective 'KeyType' value. When this is generated by the service, it will always be an RFC 5280 SubjectPublicKeyInfo structure containing an algorithm identifier and a key. A base64-encoded string.
         */
        key: string;
    }

    export interface CertificateCertificateDescriptionSubjectDescription {
        hexSerialNumber: string;
        /**
         * The desired lifetime of the CA certificate. Used to create the "notBeforeTime" and
         * "notAfterTime" fields inside an X.509 certificate. A duration in seconds with up to nine
         * fractional digits, terminated by 's'. Example: "3.5s".
         */
        lifetime: string;
        notAfterTime: string;
        notBeforeTime: string;
        /**
         * The subject alternative name fields.
         * Structure is documented below.
         */
        subjectAltNames: outputs.certificateauthority.CertificateCertificateDescriptionSubjectDescriptionSubjectAltName[];
        /**
         * Contains distinguished name fields such as the location and organization.
         * Structure is documented below.
         */
        subjects: outputs.certificateauthority.CertificateCertificateDescriptionSubjectDescriptionSubject[];
    }

    export interface CertificateCertificateDescriptionSubjectDescriptionSubject {
        /**
         * The common name of the distinguished name.
         */
        commonName: string;
        /**
         * The country code of the subject.
         */
        countryCode: string;
        /**
         * The locality or city of the subject.
         */
        locality: string;
        /**
         * The organization of the subject.
         */
        organization: string;
        /**
         * The organizational unit of the subject.
         */
        organizationalUnit: string;
        /**
         * The postal code of the subject.
         */
        postalCode: string;
        /**
         * The province, territory, or regional state of the subject.
         */
        province: string;
        /**
         * The street address of the subject.
         */
        streetAddress: string;
    }

    export interface CertificateCertificateDescriptionSubjectDescriptionSubjectAltName {
        customSans: outputs.certificateauthority.CertificateCertificateDescriptionSubjectDescriptionSubjectAltNameCustomSan[];
        /**
         * Contains only valid, fully-qualified host names.
         */
        dnsNames: string[];
        /**
         * Contains only valid RFC 2822 E-mail addresses.
         */
        emailAddresses: string[];
        /**
         * Contains only valid 32-bit IPv4 addresses or RFC 4291 IPv6 addresses.
         */
        ipAddresses: string[];
        /**
         * Contains only valid RFC 3986 URIs.
         */
        uris: string[];
    }

    export interface CertificateCertificateDescriptionSubjectDescriptionSubjectAltNameCustomSan {
        /**
         * Indicates whether or not this extension is critical (i.e., if the client does not know how to
         * handle this extension, the client should consider this to be an error).
         */
        critical: boolean;
        obectIds: outputs.certificateauthority.CertificateCertificateDescriptionSubjectDescriptionSubjectAltNameCustomSanObectId[];
        /**
         * The value of this X.509 extension. A base64-encoded string.
         */
        value: string;
    }

    export interface CertificateCertificateDescriptionSubjectDescriptionSubjectAltNameCustomSanObectId {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface CertificateCertificateDescriptionSubjectKeyId {
        keyId: string;
    }

    export interface CertificateCertificateDescriptionX509Description {
        /**
         * Specifies an X.509 extension, which may be used in different parts of X.509 objects like certificates, CSRs, and CRLs.
         * Structure is documented below.
         */
        additionalExtensions: outputs.certificateauthority.CertificateCertificateDescriptionX509DescriptionAdditionalExtension[];
        /**
         * Describes Online Certificate Status Protocol (OCSP) endpoint addresses that appear in the
         * "Authority Information Access" extension in the certificate.
         */
        aiaOcspServers: string[];
        /**
         * Describes values that are relevant in a CA certificate.
         * Structure is documented below.
         */
        caOptions: outputs.certificateauthority.CertificateCertificateDescriptionX509DescriptionCaOption[];
        /**
         * Indicates the intended use for keys that correspond to a certificate.
         * Structure is documented below.
         */
        keyUsages: outputs.certificateauthority.CertificateCertificateDescriptionX509DescriptionKeyUsage[];
        /**
         * Describes the X.509 certificate policy object identifiers, per https://tools.ietf.org/html/rfc5280#section-4.2.1.4.
         * Structure is documented below.
         */
        policyIds: outputs.certificateauthority.CertificateCertificateDescriptionX509DescriptionPolicyId[];
    }

    export interface CertificateCertificateDescriptionX509DescriptionAdditionalExtension {
        /**
         * Indicates whether or not this extension is critical (i.e., if the client does not know how to
         * handle this extension, the client should consider this to be an error).
         */
        critical: boolean;
        /**
         * Describes values that are relevant in a CA certificate.
         * Structure is documented below.
         */
        objectIds: outputs.certificateauthority.CertificateCertificateDescriptionX509DescriptionAdditionalExtensionObjectId[];
        /**
         * The value of this X.509 extension. A base64-encoded string.
         */
        value?: string;
    }

    export interface CertificateCertificateDescriptionX509DescriptionAdditionalExtensionObjectId {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface CertificateCertificateDescriptionX509DescriptionCaOption {
        /**
         * When true, the "CA" in Basic Constraints extension will be set to true.
         */
        isCa: boolean;
        /**
         * Refers to the "path length constraint" in Basic Constraints extension. For a CA certificate, this value describes the depth of
         * subordinate CA certificates that are allowed. If this value is less than 0, the request will fail.
         */
        maxIssuerPathLength: number;
    }

    export interface CertificateCertificateDescriptionX509DescriptionKeyUsage {
        /**
         * Describes high-level ways in which a key may be used.
         * Structure is documented below.
         */
        baseKeyUsages: outputs.certificateauthority.CertificateCertificateDescriptionX509DescriptionKeyUsageBaseKeyUsage[];
        /**
         * Describes high-level ways in which a key may be used.
         * Structure is documented below.
         */
        extendedKeyUsages: outputs.certificateauthority.CertificateCertificateDescriptionX509DescriptionKeyUsageExtendedKeyUsage[];
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         * Structure is documented below.
         */
        unknownExtendedKeyUsages: outputs.certificateauthority.CertificateCertificateDescriptionX509DescriptionKeyUsageUnknownExtendedKeyUsage[];
    }

    export interface CertificateCertificateDescriptionX509DescriptionKeyUsageBaseKeyUsage {
        /**
         * The key may be used to sign certificates.
         */
        certSign: boolean;
        /**
         * The key may be used for cryptographic commitments. Note that this may also be referred to as "non-repudiation".
         */
        contentCommitment: boolean;
        /**
         * The key may be used sign certificate revocation lists.
         */
        crlSign: boolean;
        /**
         * The key may be used to encipher data.
         */
        dataEncipherment: boolean;
        /**
         * The key may be used to decipher only.
         */
        decipherOnly: boolean;
        /**
         * The key may be used for digital signatures.
         */
        digitalSignature: boolean;
        /**
         * The key may be used to encipher only.
         */
        encipherOnly: boolean;
        /**
         * The key may be used in a key agreement protocol.
         */
        keyAgreement: boolean;
        /**
         * The key may be used to encipher other keys.
         */
        keyEncipherment: boolean;
    }

    export interface CertificateCertificateDescriptionX509DescriptionKeyUsageExtendedKeyUsage {
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.2. Officially described as "TLS WWW client authentication", though regularly used for non-WWW TLS.
         */
        clientAuth: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.3. Officially described as "Signing of downloadable executable code client authentication".
         */
        codeSigning: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.4. Officially described as "Email protection".
         */
        emailProtection: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.9. Officially described as "Signing OCSP responses".
         */
        ocspSigning: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.1. Officially described as "TLS WWW server authentication", though regularly used for non-WWW TLS.
         */
        serverAuth: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.8. Officially described as "Binding the hash of an object to a time".
         */
        timeStamping: boolean;
    }

    export interface CertificateCertificateDescriptionX509DescriptionKeyUsageUnknownExtendedKeyUsage {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface CertificateCertificateDescriptionX509DescriptionPolicyId {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface CertificateConfig {
        /**
         * A PublicKey describes a public key.
         * Structure is documented below.
         */
        publicKey: outputs.certificateauthority.CertificateConfigPublicKey;
        /**
         * Specifies some of the values in a certificate that are related to the subject.
         * Structure is documented below.
         */
        subjectConfig: outputs.certificateauthority.CertificateConfigSubjectConfig;
        /**
         * Describes how some of the technical X.509 fields in a certificate should be populated.
         * Structure is documented below.
         */
        x509Config: outputs.certificateauthority.CertificateConfigX509Config;
    }

    export interface CertificateConfigPublicKey {
        /**
         * The format of the public key. Currently, only PEM format is supported.
         * Possible values are `KEY_TYPE_UNSPECIFIED` and `PEM`.
         */
        format: string;
        /**
         * Required. A public key. When this is specified in a request, the padding and encoding can be any of the options described by the respective 'KeyType' value. When this is generated by the service, it will always be an RFC 5280 SubjectPublicKeyInfo structure containing an algorithm identifier and a key. A base64-encoded string.
         */
        key?: string;
    }

    export interface CertificateConfigSubjectConfig {
        /**
         * Contains distinguished name fields such as the location and organization.
         * Structure is documented below.
         */
        subject: outputs.certificateauthority.CertificateConfigSubjectConfigSubject;
        /**
         * The subject alternative name fields.
         * Structure is documented below.
         */
        subjectAltName?: outputs.certificateauthority.CertificateConfigSubjectConfigSubjectAltName;
    }

    export interface CertificateConfigSubjectConfigSubject {
        /**
         * The common name of the distinguished name.
         */
        commonName: string;
        /**
         * The country code of the subject.
         */
        countryCode?: string;
        /**
         * The locality or city of the subject.
         */
        locality?: string;
        /**
         * The organization of the subject.
         */
        organization: string;
        /**
         * The organizational unit of the subject.
         */
        organizationalUnit?: string;
        /**
         * The postal code of the subject.
         */
        postalCode?: string;
        /**
         * The province, territory, or regional state of the subject.
         */
        province?: string;
        /**
         * The street address of the subject.
         */
        streetAddress?: string;
    }

    export interface CertificateConfigSubjectConfigSubjectAltName {
        /**
         * Contains only valid, fully-qualified host names.
         */
        dnsNames?: string[];
        /**
         * Contains only valid RFC 2822 E-mail addresses.
         */
        emailAddresses?: string[];
        /**
         * Contains only valid 32-bit IPv4 addresses or RFC 4291 IPv6 addresses.
         */
        ipAddresses?: string[];
        /**
         * Contains only valid RFC 3986 URIs.
         */
        uris?: string[];
    }

    export interface CertificateConfigX509Config {
        /**
         * Specifies an X.509 extension, which may be used in different parts of X.509 objects like certificates, CSRs, and CRLs.
         * Structure is documented below.
         */
        additionalExtensions?: outputs.certificateauthority.CertificateConfigX509ConfigAdditionalExtension[];
        /**
         * Describes Online Certificate Status Protocol (OCSP) endpoint addresses that appear in the
         * "Authority Information Access" extension in the certificate.
         */
        aiaOcspServers?: string[];
        /**
         * Describes values that are relevant in a CA certificate.
         * Structure is documented below.
         */
        caOptions?: outputs.certificateauthority.CertificateConfigX509ConfigCaOptions;
        /**
         * Indicates the intended use for keys that correspond to a certificate.
         * Structure is documented below.
         */
        keyUsage: outputs.certificateauthority.CertificateConfigX509ConfigKeyUsage;
        /**
         * Describes the X.509 certificate policy object identifiers, per https://tools.ietf.org/html/rfc5280#section-4.2.1.4.
         * Structure is documented below.
         */
        policyIds?: outputs.certificateauthority.CertificateConfigX509ConfigPolicyId[];
    }

    export interface CertificateConfigX509ConfigAdditionalExtension {
        /**
         * Indicates whether or not this extension is critical (i.e., if the client does not know how to
         * handle this extension, the client should consider this to be an error).
         */
        critical: boolean;
        /**
         * Describes values that are relevant in a CA certificate.
         * Structure is documented below.
         */
        objectId: outputs.certificateauthority.CertificateConfigX509ConfigAdditionalExtensionObjectId;
        /**
         * The value of this X.509 extension. A base64-encoded string.
         */
        value: string;
    }

    export interface CertificateConfigX509ConfigAdditionalExtensionObjectId {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface CertificateConfigX509ConfigCaOptions {
        /**
         * When true, the "CA" in Basic Constraints extension will be set to true.
         */
        isCa?: boolean;
        /**
         * Refers to the "path length constraint" in Basic Constraints extension. For a CA certificate, this value describes the depth of
         * subordinate CA certificates that are allowed. If this value is less than 0, the request will fail.
         */
        maxIssuerPathLength?: number;
        /**
         * When true, the "CA" in Basic Constraints extension will be set to false.
         * If both `isCa` and `nonCa` are unset, the extension will be omitted from the CA certificate.
         */
        nonCa?: boolean;
        /**
         * When true, the "path length constraint" in Basic Constraints extension will be set to 0.
         * if both `maxIssuerPathLength` and `zeroMaxIssuerPathLength` are unset,
         * the max path length will be omitted from the CA certificate.
         */
        zeroMaxIssuerPathLength?: boolean;
    }

    export interface CertificateConfigX509ConfigKeyUsage {
        /**
         * Describes high-level ways in which a key may be used.
         * Structure is documented below.
         */
        baseKeyUsage: outputs.certificateauthority.CertificateConfigX509ConfigKeyUsageBaseKeyUsage;
        /**
         * Describes high-level ways in which a key may be used.
         * Structure is documented below.
         */
        extendedKeyUsage: outputs.certificateauthority.CertificateConfigX509ConfigKeyUsageExtendedKeyUsage;
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         * Structure is documented below.
         */
        unknownExtendedKeyUsages?: outputs.certificateauthority.CertificateConfigX509ConfigKeyUsageUnknownExtendedKeyUsage[];
    }

    export interface CertificateConfigX509ConfigKeyUsageBaseKeyUsage {
        /**
         * The key may be used to sign certificates.
         */
        certSign?: boolean;
        /**
         * The key may be used for cryptographic commitments. Note that this may also be referred to as "non-repudiation".
         */
        contentCommitment?: boolean;
        /**
         * The key may be used sign certificate revocation lists.
         */
        crlSign?: boolean;
        /**
         * The key may be used to encipher data.
         */
        dataEncipherment?: boolean;
        /**
         * The key may be used to decipher only.
         */
        decipherOnly?: boolean;
        /**
         * The key may be used for digital signatures.
         */
        digitalSignature?: boolean;
        /**
         * The key may be used to encipher only.
         */
        encipherOnly?: boolean;
        /**
         * The key may be used in a key agreement protocol.
         */
        keyAgreement?: boolean;
        /**
         * The key may be used to encipher other keys.
         */
        keyEncipherment?: boolean;
    }

    export interface CertificateConfigX509ConfigKeyUsageExtendedKeyUsage {
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.2. Officially described as "TLS WWW client authentication", though regularly used for non-WWW TLS.
         */
        clientAuth?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.3. Officially described as "Signing of downloadable executable code client authentication".
         */
        codeSigning?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.4. Officially described as "Email protection".
         */
        emailProtection?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.9. Officially described as "Signing OCSP responses".
         */
        ocspSigning?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.1. Officially described as "TLS WWW server authentication", though regularly used for non-WWW TLS.
         */
        serverAuth?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.8. Officially described as "Binding the hash of an object to a time".
         */
        timeStamping?: boolean;
    }

    export interface CertificateConfigX509ConfigKeyUsageUnknownExtendedKeyUsage {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface CertificateConfigX509ConfigPolicyId {
        /**
         * An ObjectId specifies an object identifier (OID). These provide context and describe types in ASN.1 messages.
         */
        objectIdPaths: number[];
    }

    export interface CertificateRevocationDetail {
        revocationState: string;
        revocationTime: string;
    }

    export interface CertificateTemplateIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface CertificateTemplateIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface CertificateTemplateIdentityConstraints {
        /**
         * Required. If this is true, the SubjectAltNames extension may be copied from a certificate request into the signed certificate. Otherwise, the requested SubjectAltNames will be discarded.
         */
        allowSubjectAltNamesPassthrough: boolean;
        /**
         * Required. If this is true, the Subject field may be copied from a certificate request into the signed certificate. Otherwise, the requested Subject will be discarded.
         */
        allowSubjectPassthrough: boolean;
        /**
         * Optional. A CEL expression that may be used to validate the resolved X.509 Subject and/or Subject Alternative Name before a certificate is signed. To see the full allowed syntax and some examples, see https://cloud.google.com/certificate-authority-service/docs/using-cel
         */
        celExpression?: outputs.certificateauthority.CertificateTemplateIdentityConstraintsCelExpression;
    }

    export interface CertificateTemplateIdentityConstraintsCelExpression {
        /**
         * Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression?: string;
        /**
         * Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
         */
        location?: string;
        /**
         * Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
         */
        title?: string;
    }

    export interface CertificateTemplatePassthroughExtensions {
        /**
         * Optional. Describes custom X.509 extensions.
         */
        additionalExtensions?: outputs.certificateauthority.CertificateTemplatePassthroughExtensionsAdditionalExtension[];
        /**
         * Optional. A set of named X.509 extensions. Will be combined with additionalExtensions to determine the full set of X.509 extensions.
         */
        knownExtensions?: string[];
    }

    export interface CertificateTemplatePassthroughExtensionsAdditionalExtension {
        /**
         * Required. The parts of an OID path. The most significant parts of the path come first.
         */
        objectIdPaths: number[];
    }

    export interface CertificateTemplatePredefinedValues {
        /**
         * Optional. Describes custom X.509 extensions.
         */
        additionalExtensions?: outputs.certificateauthority.CertificateTemplatePredefinedValuesAdditionalExtension[];
        /**
         * Optional. Describes Online Certificate Status Protocol (OCSP) endpoint addresses that appear in the "Authority Information Access" extension in the certificate.
         */
        aiaOcspServers?: string[];
        /**
         * Optional. Describes options in this X509Parameters that are relevant in a CA certificate.
         */
        caOptions?: outputs.certificateauthority.CertificateTemplatePredefinedValuesCaOptions;
        /**
         * Optional. Indicates the intended use for keys that correspond to a certificate.
         */
        keyUsage?: outputs.certificateauthority.CertificateTemplatePredefinedValuesKeyUsage;
        /**
         * Optional. Describes the X.509 certificate policy object identifiers, per https://tools.ietf.org/html/rfc5280#section-4.2.1.4.
         */
        policyIds?: outputs.certificateauthority.CertificateTemplatePredefinedValuesPolicyId[];
    }

    export interface CertificateTemplatePredefinedValuesAdditionalExtension {
        /**
         * Optional. Indicates whether or not this extension is critical (i.e., if the client does not know how to handle this extension, the client should consider this to be an error).
         */
        critical?: boolean;
        /**
         * Required. The OID for this X.509 extension.
         */
        objectId: outputs.certificateauthority.CertificateTemplatePredefinedValuesAdditionalExtensionObjectId;
        /**
         * Required. The value of this X.509 extension.
         */
        value: string;
    }

    export interface CertificateTemplatePredefinedValuesAdditionalExtensionObjectId {
        /**
         * Required. The parts of an OID path. The most significant parts of the path come first.
         */
        objectIdPaths: number[];
    }

    export interface CertificateTemplatePredefinedValuesCaOptions {
        /**
         * Optional. Refers to the "CA" X.509 extension, which is a boolean value. When this value is missing, the extension will be omitted from the CA certificate.
         */
        isCa?: boolean;
        /**
         * Optional. Refers to the path length restriction X.509 extension. For a CA certificate, this value describes the depth of subordinate CA certificates that are allowed. If this value is less than 0, the request will fail. If this value is missing, the max path length will be omitted from the CA certificate.
         */
        maxIssuerPathLength?: number;
    }

    export interface CertificateTemplatePredefinedValuesKeyUsage {
        /**
         * Describes high-level ways in which a key may be used.
         */
        baseKeyUsage?: outputs.certificateauthority.CertificateTemplatePredefinedValuesKeyUsageBaseKeyUsage;
        /**
         * Detailed scenarios in which a key may be used.
         */
        extendedKeyUsage?: outputs.certificateauthority.CertificateTemplatePredefinedValuesKeyUsageExtendedKeyUsage;
        /**
         * Used to describe extended key usages that are not listed in the KeyUsage.ExtendedKeyUsageOptions message.
         */
        unknownExtendedKeyUsages?: outputs.certificateauthority.CertificateTemplatePredefinedValuesKeyUsageUnknownExtendedKeyUsage[];
    }

    export interface CertificateTemplatePredefinedValuesKeyUsageBaseKeyUsage {
        /**
         * The key may be used to sign certificates.
         */
        certSign?: boolean;
        /**
         * The key may be used for cryptographic commitments. Note that this may also be referred to as "non-repudiation".
         */
        contentCommitment?: boolean;
        /**
         * The key may be used sign certificate revocation lists.
         */
        crlSign?: boolean;
        /**
         * The key may be used to encipher data.
         */
        dataEncipherment?: boolean;
        /**
         * The key may be used to decipher only.
         */
        decipherOnly?: boolean;
        /**
         * The key may be used for digital signatures.
         */
        digitalSignature?: boolean;
        /**
         * The key may be used to encipher only.
         */
        encipherOnly?: boolean;
        /**
         * The key may be used in a key agreement protocol.
         */
        keyAgreement?: boolean;
        /**
         * The key may be used to encipher other keys.
         */
        keyEncipherment?: boolean;
    }

    export interface CertificateTemplatePredefinedValuesKeyUsageExtendedKeyUsage {
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.2. Officially described as "TLS WWW client authentication", though regularly used for non-WWW TLS.
         */
        clientAuth?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.3. Officially described as "Signing of downloadable executable code client authentication".
         */
        codeSigning?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.4. Officially described as "Email protection".
         */
        emailProtection?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.9. Officially described as "Signing OCSP responses".
         */
        ocspSigning?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.1. Officially described as "TLS WWW server authentication", though regularly used for non-WWW TLS.
         */
        serverAuth?: boolean;
        /**
         * Corresponds to OID 1.3.6.1.5.5.7.3.8. Officially described as "Binding the hash of an object to a time".
         */
        timeStamping?: boolean;
    }

    export interface CertificateTemplatePredefinedValuesKeyUsageUnknownExtendedKeyUsage {
        /**
         * Required. The parts of an OID path. The most significant parts of the path come first.
         */
        objectIdPaths: number[];
    }

    export interface CertificateTemplatePredefinedValuesPolicyId {
        /**
         * Required. The parts of an OID path. The most significant parts of the path come first.
         */
        objectIdPaths: number[];
    }

    export interface GetAuthorityAccessUrl {
        caCertificateAccessUrl: string;
        crlAccessUrls: string[];
    }

    export interface GetAuthorityConfig {
        subjectConfigs: outputs.certificateauthority.GetAuthorityConfigSubjectConfig[];
        x509Configs: outputs.certificateauthority.GetAuthorityConfigX509Config[];
    }

    export interface GetAuthorityConfigSubjectConfig {
        subjectAltNames: outputs.certificateauthority.GetAuthorityConfigSubjectConfigSubjectAltName[];
        subjects: outputs.certificateauthority.GetAuthorityConfigSubjectConfigSubject[];
    }

    export interface GetAuthorityConfigSubjectConfigSubject {
        commonName: string;
        countryCode: string;
        locality: string;
        organization: string;
        organizationalUnit: string;
        postalCode: string;
        province: string;
        streetAddress: string;
    }

    export interface GetAuthorityConfigSubjectConfigSubjectAltName {
        dnsNames: string[];
        emailAddresses: string[];
        ipAddresses: string[];
        uris: string[];
    }

    export interface GetAuthorityConfigX509Config {
        additionalExtensions: outputs.certificateauthority.GetAuthorityConfigX509ConfigAdditionalExtension[];
        aiaOcspServers: string[];
        caOptions: outputs.certificateauthority.GetAuthorityConfigX509ConfigCaOption[];
        keyUsages: outputs.certificateauthority.GetAuthorityConfigX509ConfigKeyUsage[];
        policyIds: outputs.certificateauthority.GetAuthorityConfigX509ConfigPolicyId[];
    }

    export interface GetAuthorityConfigX509ConfigAdditionalExtension {
        critical: boolean;
        objectIds: outputs.certificateauthority.GetAuthorityConfigX509ConfigAdditionalExtensionObjectId[];
        value: string;
    }

    export interface GetAuthorityConfigX509ConfigAdditionalExtensionObjectId {
        objectIdPaths: number[];
    }

    export interface GetAuthorityConfigX509ConfigCaOption {
        isCa: boolean;
        maxIssuerPathLength: number;
        nonCa: boolean;
        zeroMaxIssuerPathLength: boolean;
    }

    export interface GetAuthorityConfigX509ConfigKeyUsage {
        baseKeyUsages: outputs.certificateauthority.GetAuthorityConfigX509ConfigKeyUsageBaseKeyUsage[];
        extendedKeyUsages: outputs.certificateauthority.GetAuthorityConfigX509ConfigKeyUsageExtendedKeyUsage[];
        unknownExtendedKeyUsages: outputs.certificateauthority.GetAuthorityConfigX509ConfigKeyUsageUnknownExtendedKeyUsage[];
    }

    export interface GetAuthorityConfigX509ConfigKeyUsageBaseKeyUsage {
        certSign: boolean;
        contentCommitment: boolean;
        crlSign: boolean;
        dataEncipherment: boolean;
        decipherOnly: boolean;
        digitalSignature: boolean;
        encipherOnly: boolean;
        keyAgreement: boolean;
        keyEncipherment: boolean;
    }

    export interface GetAuthorityConfigX509ConfigKeyUsageExtendedKeyUsage {
        clientAuth: boolean;
        codeSigning: boolean;
        emailProtection: boolean;
        ocspSigning: boolean;
        serverAuth: boolean;
        timeStamping: boolean;
    }

    export interface GetAuthorityConfigX509ConfigKeyUsageUnknownExtendedKeyUsage {
        objectIdPaths: number[];
    }

    export interface GetAuthorityConfigX509ConfigPolicyId {
        objectIdPaths: number[];
    }

    export interface GetAuthorityKeySpec {
        algorithm: string;
        cloudKmsKeyVersion: string;
    }

}

export namespace certificatemanager {
    export interface CertificateManaged {
        /**
         * Authorizations that will be used for performing domain authorization
         */
        dnsAuthorizations?: string[];
        /**
         * The domains for which a managed SSL certificate will be generated.
         * Wildcard domains are only supported with DNS challenge resolution
         */
        domains?: string[];
        /**
         * -
         * State of the managed certificate resource.
         */
        state: string;
    }

    export interface CertificateSelfManaged {
        /**
         * The certificate chain in PEM-encoded form.
         * Leaf certificate comes first, followed by intermediate ones if any.
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        certificatePem: string;
        /**
         * The private key of the leaf certificate in PEM-encoded form.
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        privateKeyPem: string;
    }

    export interface DnsAuthorizationDnsResourceRecord {
        data: string;
        /**
         * Name of the resource; provided by the client when the resource is created.
         * The name must be 1-64 characters long, and match the regular expression [a-zA-Z][a-zA-Z0-9_-]* which means the first character must be a letter,
         * and all following characters must be a dash, underscore, letter or digit.
         */
        name: string;
        type: string;
    }

}

export namespace cloudasset {
    export interface FolderFeedCondition {
        /**
         * Description of the expression. This is a longer text which describes the expression,
         * e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * String indicating the location of the expression for error reporting, e.g. a file
         * name and a position in the file.
         */
        location?: string;
        /**
         * Title for the expression, i.e. a short string describing its purpose.
         * This can be used e.g. in UIs which allow to enter the expression.
         */
        title?: string;
    }

    export interface FolderFeedFeedOutputConfig {
        /**
         * Destination on Cloud Pubsub.
         * Structure is documented below.
         */
        pubsubDestination: outputs.cloudasset.FolderFeedFeedOutputConfigPubsubDestination;
    }

    export interface FolderFeedFeedOutputConfigPubsubDestination {
        /**
         * Destination on Cloud Pubsub topic.
         */
        topic: string;
    }

    export interface OrganizationFeedCondition {
        /**
         * Description of the expression. This is a longer text which describes the expression,
         * e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * String indicating the location of the expression for error reporting, e.g. a file
         * name and a position in the file.
         */
        location?: string;
        /**
         * Title for the expression, i.e. a short string describing its purpose.
         * This can be used e.g. in UIs which allow to enter the expression.
         */
        title?: string;
    }

    export interface OrganizationFeedFeedOutputConfig {
        /**
         * Destination on Cloud Pubsub.
         * Structure is documented below.
         */
        pubsubDestination: outputs.cloudasset.OrganizationFeedFeedOutputConfigPubsubDestination;
    }

    export interface OrganizationFeedFeedOutputConfigPubsubDestination {
        /**
         * Destination on Cloud Pubsub topic.
         */
        topic: string;
    }

    export interface ProjectFeedCondition {
        /**
         * Description of the expression. This is a longer text which describes the expression,
         * e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * String indicating the location of the expression for error reporting, e.g. a file
         * name and a position in the file.
         */
        location?: string;
        /**
         * Title for the expression, i.e. a short string describing its purpose.
         * This can be used e.g. in UIs which allow to enter the expression.
         */
        title?: string;
    }

    export interface ProjectFeedFeedOutputConfig {
        /**
         * Destination on Cloud Pubsub.
         * Structure is documented below.
         */
        pubsubDestination: outputs.cloudasset.ProjectFeedFeedOutputConfigPubsubDestination;
    }

    export interface ProjectFeedFeedOutputConfigPubsubDestination {
        /**
         * Destination on Cloud Pubsub topic.
         */
        topic: string;
    }

}

export namespace cloudbuild {
    export interface TriggerApprovalConfig {
        /**
         * Whether or not approval is needed. If this is set on a build, it will become pending when run,
         * and will need to be explicitly approved to start.
         */
        approvalRequired?: boolean;
    }

    export interface TriggerBuild {
        /**
         * Artifacts produced by the build that should be uploaded upon successful completion of all build steps.
         * Structure is documented below.
         */
        artifacts?: outputs.cloudbuild.TriggerBuildArtifacts;
        /**
         * Secrets and secret environment variables.
         * Structure is documented below.
         */
        availableSecrets?: outputs.cloudbuild.TriggerBuildAvailableSecrets;
        /**
         * A list of images to be pushed upon the successful completion of all build steps.
         * The images will be pushed using the builder service account's credentials.
         * The digests of the pushed images will be stored in the Build resource's results field.
         * If any of the images fail to be pushed, the build is marked FAILURE.
         */
        images?: string[];
        /**
         * Google Cloud Storage bucket where logs should be written.
         * Logs file names will be of the format ${logsBucket}/log-${build_id}.txt.
         */
        logsBucket?: string;
        /**
         * Special options for this build.
         * Structure is documented below.
         */
        options?: outputs.cloudbuild.TriggerBuildOptions;
        /**
         * TTL in queue for this build. If provided and the build is enqueued longer than this value,
         * the build will expire and the build status will be EXPIRED.
         * The TTL starts ticking from createTime.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        queueTtl?: string;
        /**
         * Secrets to decrypt using Cloud Key Management Service.
         * Structure is documented below.
         */
        secrets?: outputs.cloudbuild.TriggerBuildSecret[];
        /**
         * The location of the source files to build.
         * One of `storageSource` or `repoSource` must be provided.
         * Structure is documented below.
         */
        source?: outputs.cloudbuild.TriggerBuildSource;
        /**
         * The operations to be performed on the workspace.
         * Structure is documented below.
         */
        steps: outputs.cloudbuild.TriggerBuildStep[];
        /**
         * Substitutions to use in a triggered build. Should only be used with triggers.run
         */
        substitutions?: {[key: string]: string};
        /**
         * Tags for annotation of a Build. These are not docker tags.
         */
        tags?: string[];
        /**
         * Time limit for executing this build step. If not defined,
         * the step has no
         * time limit and will be allowed to continue to run until either it
         * completes or the build itself times out.
         */
        timeout?: string;
    }

    export interface TriggerBuildArtifacts {
        /**
         * A list of images to be pushed upon the successful completion of all build steps.
         * The images will be pushed using the builder service account's credentials.
         * The digests of the pushed images will be stored in the Build resource's results field.
         * If any of the images fail to be pushed, the build is marked FAILURE.
         */
        images?: string[];
        /**
         * A list of objects to be uploaded to Cloud Storage upon successful completion of all build steps.
         * Files in the workspace matching specified paths globs will be uploaded to the
         * Cloud Storage location using the builder service account's credentials.
         * The location and generation of the uploaded objects will be stored in the Build resource's results field.
         * If any objects fail to be pushed, the build is marked FAILURE.
         * Structure is documented below.
         */
        objects?: outputs.cloudbuild.TriggerBuildArtifactsObjects;
    }

    export interface TriggerBuildArtifactsObjects {
        /**
         * Cloud Storage bucket and optional object path, in the form "gs://bucket/path/to/somewhere/".
         * Files in the workspace matching any path pattern will be uploaded to Cloud Storage with
         * this location as a prefix.
         */
        location?: string;
        /**
         * Path globs used to match files in the build's workspace.
         */
        paths?: string[];
        /**
         * -
         * Output only. Stores timing information for pushing all artifact objects.
         * Structure is documented below.
         */
        timings: outputs.cloudbuild.TriggerBuildArtifactsObjectsTiming[];
    }

    export interface TriggerBuildArtifactsObjectsTiming {
        /**
         * End of time span.
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to
         * nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
         */
        endTime?: string;
        /**
         * Start of time span.
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to
         * nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
         */
        startTime?: string;
    }

    export interface TriggerBuildAvailableSecrets {
        /**
         * Pairs a secret environment variable with a SecretVersion in Secret Manager.
         * Structure is documented below.
         */
        secretManagers: outputs.cloudbuild.TriggerBuildAvailableSecretsSecretManager[];
    }

    export interface TriggerBuildAvailableSecretsSecretManager {
        /**
         * A list of global environment variable definitions that will exist for all build steps
         * in this build. If a variable is defined in both globally and in a build step,
         * the variable will use the build step value.
         * The elements are of the form "KEY=VALUE" for the environment variable "KEY" being given the value "VALUE".
         */
        env: string;
        /**
         * Resource name of the SecretVersion. In format: projects/*&#47;secrets/*&#47;versions/*
         */
        versionName: string;
    }

    export interface TriggerBuildOptions {
        /**
         * Requested disk size for the VM that runs the build. Note that this is NOT "disk free";
         * some of the space will be used by the operating system and build utilities.
         * Also note that this is the minimum disk size that will be allocated for the build --
         * the build may run with a larger disk than requested. At present, the maximum disk size
         * is 1000GB; builds that request more than the maximum are rejected with an error.
         */
        diskSizeGb?: number;
        /**
         * Option to specify whether or not to apply bash style string operations to the substitutions.
         * NOTE this is always enabled for triggered builds and cannot be overridden in the build configuration file.
         */
        dynamicSubstitutions?: boolean;
        /**
         * A list of global environment variable definitions that will exist for all build steps
         * in this build. If a variable is defined in both globally and in a build step,
         * the variable will use the build step value.
         * The elements are of the form "KEY=VALUE" for the environment variable "KEY" being given the value "VALUE".
         */
        envs?: string[];
        /**
         * Option to define build log streaming behavior to Google Cloud Storage.
         * Possible values are `STREAM_DEFAULT`, `STREAM_ON`, and `STREAM_OFF`.
         */
        logStreamingOption?: string;
        /**
         * Option to specify the logging mode, which determines if and where build logs are stored.
         * Possible values are `LOGGING_UNSPECIFIED`, `LEGACY`, `GCS_ONLY`, `STACKDRIVER_ONLY`, `CLOUD_LOGGING_ONLY`, and `NONE`.
         */
        logging?: string;
        /**
         * Compute Engine machine type on which to run the build.
         * Possible values are `UNSPECIFIED`, `N1_HIGHCPU_8`, `N1_HIGHCPU_32`, `E2_HIGHCPU_8`, and `E2_HIGHCPU_32`.
         */
        machineType?: string;
        /**
         * Requested verifiability options.
         * Possible values are `NOT_VERIFIED` and `VERIFIED`.
         */
        requestedVerifyOption?: string;
        /**
         * A list of global environment variables, which are encrypted using a Cloud Key Management
         * Service crypto key. These values must be specified in the build's Secret. These variables
         * will be available to all build steps in this build.
         */
        secretEnvs?: string[];
        /**
         * Requested hash for SourceProvenance.
         * Each value may be one of `NONE`, `SHA256`, and `MD5`.
         */
        sourceProvenanceHashes?: string[];
        /**
         * Option to specify behavior when there is an error in the substitution checks.
         * NOTE this is always set to ALLOW_LOOSE for triggered builds and cannot be overridden
         * in the build configuration file.
         * Possible values are `MUST_MATCH` and `ALLOW_LOOSE`.
         */
        substitutionOption?: string;
        /**
         * Global list of volumes to mount for ALL build steps
         * Each volume is created as an empty volume prior to starting the build process.
         * Upon completion of the build, volumes and their contents are discarded. Global
         * volume names and paths cannot conflict with the volumes defined a build step.
         * Using a global volume in a build with only one step is not valid as it is indicative
         * of a build request with an incorrect configuration.
         * Structure is documented below.
         */
        volumes?: outputs.cloudbuild.TriggerBuildOptionsVolume[];
        /**
         * Option to specify a WorkerPool for the build. Format projects/{project}/workerPools/{workerPool}
         * This field is experimental.
         */
        workerPool?: string;
    }

    export interface TriggerBuildOptionsVolume {
        /**
         * Name of the volume to mount.
         * Volume names must be unique per build step and must be valid names for Docker volumes.
         * Each named volume must be used by at least two build steps.
         */
        name?: string;
        /**
         * Path at which to mount the volume.
         * Paths must be absolute and cannot conflict with other volume paths on the same
         * build step or with certain reserved volume paths.
         */
        path?: string;
    }

    export interface TriggerBuildSecret {
        /**
         * Cloud KMS key name to use to decrypt these envs.
         */
        kmsKeyName: string;
        /**
         * A list of global environment variables, which are encrypted using a Cloud Key Management
         * Service crypto key. These values must be specified in the build's Secret. These variables
         * will be available to all build steps in this build.
         */
        secretEnv?: {[key: string]: string};
    }

    export interface TriggerBuildSource {
        /**
         * Location of the source in a Google Cloud Source Repository.
         * Structure is documented below.
         */
        repoSource?: outputs.cloudbuild.TriggerBuildSourceRepoSource;
        /**
         * Location of the source in an archive file in Google Cloud Storage.
         * Structure is documented below.
         */
        storageSource?: outputs.cloudbuild.TriggerBuildSourceStorageSource;
    }

    export interface TriggerBuildSourceRepoSource {
        /**
         * Regex matching branches to build. Exactly one a of branch name, tag, or commit SHA must be provided.
         * The syntax of the regular expressions accepted is the syntax accepted by RE2 and
         * described at https://github.com/google/re2/wiki/Syntax
         */
        branchName?: string;
        /**
         * Explicit commit SHA to build. Exactly one a of branch name, tag, or commit SHA must be provided.
         */
        commitSha?: string;
        /**
         * Working directory to use when running this step's container.
         * If this value is a relative path, it is relative to the build's working
         * directory. If this value is absolute, it may be outside the build's working
         * directory, in which case the contents of the path may not be persisted
         * across build step executions, unless a `volume` for that path is specified.
         * If the build specifies a `RepoSource` with `dir` and a step with a
         * `dir`,
         * which specifies an absolute path, the `RepoSource` `dir` is ignored
         * for the step's execution.
         */
        dir?: string;
        /**
         * Only trigger a build if the revision regex does NOT match the revision regex.
         */
        invertRegex?: boolean;
        /**
         * ID of the project that owns the Cloud Source Repository.
         * If omitted, the project ID requesting the build is assumed.
         */
        projectId?: string;
        /**
         * Name of the Cloud Source Repository.
         */
        repoName: string;
        /**
         * Substitutions to use in a triggered build. Should only be used with triggers.run
         */
        substitutions?: {[key: string]: string};
        /**
         * Regex matching tags to build. Exactly one a of branch name, tag, or commit SHA must be provided.
         * The syntax of the regular expressions accepted is the syntax accepted by RE2 and
         * described at https://github.com/google/re2/wiki/Syntax
         */
        tagName?: string;
    }

    export interface TriggerBuildSourceStorageSource {
        /**
         * Google Cloud Storage bucket containing the source.
         */
        bucket: string;
        /**
         * Google Cloud Storage generation for the object.
         * If the generation is omitted, the latest generation will be used
         */
        generation?: string;
        /**
         * Google Cloud Storage object containing the source.
         * This object must be a gzipped archive file (.tar.gz) containing source to build.
         */
        object: string;
    }

    export interface TriggerBuildStep {
        /**
         * A list of arguments that will be presented to the step when it is started.
         * If the image used to run the step's container has an entrypoint, the args
         * are used as arguments to that entrypoint. If the image does not define an
         * entrypoint, the first element in args is used as the entrypoint, and the
         * remainder will be used as arguments.
         */
        args?: string[];
        /**
         * Working directory to use when running this step's container.
         * If this value is a relative path, it is relative to the build's working
         * directory. If this value is absolute, it may be outside the build's working
         * directory, in which case the contents of the path may not be persisted
         * across build step executions, unless a `volume` for that path is specified.
         * If the build specifies a `RepoSource` with `dir` and a step with a
         * `dir`,
         * which specifies an absolute path, the `RepoSource` `dir` is ignored
         * for the step's execution.
         */
        dir?: string;
        /**
         * Entrypoint to be used instead of the build step image's
         * default entrypoint.
         * If unset, the image's default entrypoint is used
         */
        entrypoint?: string;
        /**
         * A list of global environment variable definitions that will exist for all build steps
         * in this build. If a variable is defined in both globally and in a build step,
         * the variable will use the build step value.
         * The elements are of the form "KEY=VALUE" for the environment variable "KEY" being given the value "VALUE".
         */
        envs?: string[];
        /**
         * Unique identifier for this build step, used in `waitFor` to
         * reference this build step as a dependency.
         */
        id?: string;
        /**
         * Name of the volume to mount.
         * Volume names must be unique per build step and must be valid names for Docker volumes.
         * Each named volume must be used by at least two build steps.
         */
        name: string;
        /**
         * A list of global environment variables, which are encrypted using a Cloud Key Management
         * Service crypto key. These values must be specified in the build's Secret. These variables
         * will be available to all build steps in this build.
         */
        secretEnvs?: string[];
        /**
         * Time limit for executing this build step. If not defined,
         * the step has no
         * time limit and will be allowed to continue to run until either it
         * completes or the build itself times out.
         */
        timeout?: string;
        /**
         * -
         * Output only. Stores timing information for pushing all artifact objects.
         * Structure is documented below.
         */
        timing?: string;
        /**
         * Global list of volumes to mount for ALL build steps
         * Each volume is created as an empty volume prior to starting the build process.
         * Upon completion of the build, volumes and their contents are discarded. Global
         * volume names and paths cannot conflict with the volumes defined a build step.
         * Using a global volume in a build with only one step is not valid as it is indicative
         * of a build request with an incorrect configuration.
         * Structure is documented below.
         */
        volumes?: outputs.cloudbuild.TriggerBuildStepVolume[];
        /**
         * The ID(s) of the step(s) that this build step depends on.
         * This build step will not start until all the build steps in `waitFor`
         * have completed successfully. If `waitFor` is empty, this build step
         * will start when all previous build steps in the `Build.Steps` list
         * have completed successfully.
         */
        waitFors?: string[];
    }

    export interface TriggerBuildStepVolume {
        /**
         * Name of the volume to mount.
         * Volume names must be unique per build step and must be valid names for Docker volumes.
         * Each named volume must be used by at least two build steps.
         */
        name: string;
        /**
         * Path at which to mount the volume.
         * Paths must be absolute and cannot conflict with other volume paths on the same
         * build step or with certain reserved volume paths.
         */
        path: string;
    }

    export interface TriggerGitFileSource {
        /**
         * Path at which to mount the volume.
         * Paths must be absolute and cannot conflict with other volume paths on the same
         * build step or with certain reserved volume paths.
         */
        path: string;
        /**
         * The type of the repo, since it may not be explicit from the repo field (e.g from a URL).
         * Values can be UNKNOWN, CLOUD_SOURCE_REPOSITORIES, GITHUB
         * Possible values are `UNKNOWN`, `CLOUD_SOURCE_REPOSITORIES`, and `GITHUB`.
         */
        repoType: string;
        /**
         * The branch, tag, arbitrary ref, or SHA version of the repo to use when resolving the
         * filename (optional). This field respects the same syntax/resolution as described here: https://git-scm.com/docs/gitrevisions
         * If unspecified, the revision from which the trigger invocation originated is assumed to be the revision from which to read the specified path.
         */
        revision?: string;
        /**
         * The URI of the repo (required).
         */
        uri?: string;
    }

    export interface TriggerGithub {
        /**
         * Name of the volume to mount.
         * Volume names must be unique per build step and must be valid names for Docker volumes.
         * Each named volume must be used by at least two build steps.
         */
        name?: string;
        /**
         * Owner of the repository. For example: The owner for
         * https://github.com/googlecloudplatform/cloud-builders is "googlecloudplatform".
         */
        owner?: string;
        /**
         * filter to match changes in pull requests. Specify only one of `pullRequest` or `push`.
         * Structure is documented below.
         */
        pullRequest?: outputs.cloudbuild.TriggerGithubPullRequest;
        /**
         * filter to match changes in refs, like branches or tags. Specify only one of `pullRequest` or `push`.
         * Structure is documented below.
         */
        push?: outputs.cloudbuild.TriggerGithubPush;
    }

    export interface TriggerGithubPullRequest {
        /**
         * Regex of branches to match.  Specify only one of branch or tag.
         */
        branch: string;
        /**
         * Whether to block builds on a "/gcbrun" comment from a repository owner or collaborator.
         * Possible values are `COMMENTS_DISABLED`, `COMMENTS_ENABLED`, and `COMMENTS_ENABLED_FOR_EXTERNAL_CONTRIBUTORS_ONLY`.
         */
        commentControl?: string;
        /**
         * Only trigger a build if the revision regex does NOT match the revision regex.
         */
        invertRegex?: boolean;
    }

    export interface TriggerGithubPush {
        /**
         * Regex of branches to match.  Specify only one of branch or tag.
         */
        branch?: string;
        /**
         * Only trigger a build if the revision regex does NOT match the revision regex.
         */
        invertRegex?: boolean;
        /**
         * Regex of tags to match.  Specify only one of branch or tag.
         */
        tag?: string;
    }

    export interface TriggerPubsubConfig {
        /**
         * Service account that will make the push request.
         */
        serviceAccountEmail?: string;
        /**
         * -
         * Potential issues with the underlying Pub/Sub subscription configuration.
         * Only populated on get requests.
         */
        state: string;
        /**
         * -
         * Output only. Name of the subscription.
         */
        subscription: string;
        /**
         * The name of the topic from which this subscription is receiving messages.
         */
        topic: string;
    }

    export interface TriggerSourceToBuild {
        /**
         * The branch or tag to use. Must start with "refs/" (required).
         */
        ref: string;
        /**
         * The type of the repo, since it may not be explicit from the repo field (e.g from a URL).
         * Values can be UNKNOWN, CLOUD_SOURCE_REPOSITORIES, GITHUB
         * Possible values are `UNKNOWN`, `CLOUD_SOURCE_REPOSITORIES`, and `GITHUB`.
         */
        repoType: string;
        /**
         * The URI of the repo (required).
         */
        uri: string;
    }

    export interface TriggerTriggerTemplate {
        /**
         * Regex matching branches to build. Exactly one a of branch name, tag, or commit SHA must be provided.
         * The syntax of the regular expressions accepted is the syntax accepted by RE2 and
         * described at https://github.com/google/re2/wiki/Syntax
         */
        branchName?: string;
        /**
         * Explicit commit SHA to build. Exactly one a of branch name, tag, or commit SHA must be provided.
         */
        commitSha?: string;
        /**
         * Working directory to use when running this step's container.
         * If this value is a relative path, it is relative to the build's working
         * directory. If this value is absolute, it may be outside the build's working
         * directory, in which case the contents of the path may not be persisted
         * across build step executions, unless a `volume` for that path is specified.
         * If the build specifies a `RepoSource` with `dir` and a step with a
         * `dir`,
         * which specifies an absolute path, the `RepoSource` `dir` is ignored
         * for the step's execution.
         */
        dir?: string;
        /**
         * Only trigger a build if the revision regex does NOT match the revision regex.
         */
        invertRegex?: boolean;
        /**
         * ID of the project that owns the Cloud Source Repository.
         * If omitted, the project ID requesting the build is assumed.
         */
        projectId: string;
        /**
         * Name of the Cloud Source Repository.
         */
        repoName?: string;
        /**
         * Regex matching tags to build. Exactly one a of branch name, tag, or commit SHA must be provided.
         * The syntax of the regular expressions accepted is the syntax accepted by RE2 and
         * described at https://github.com/google/re2/wiki/Syntax
         */
        tagName?: string;
    }

    export interface TriggerWebhookConfig {
        /**
         * Secrets to decrypt using Cloud Key Management Service.
         * Structure is documented below.
         */
        secret: string;
        /**
         * -
         * Potential issues with the underlying Pub/Sub subscription configuration.
         * Only populated on get requests.
         */
        state: string;
    }

    export interface WorkerPoolNetworkConfig {
        /**
         * Immutable. The network definition that the workers are peered to. If this section is left empty, the workers will be peered to `WorkerPool.project_id` on the service producer network. Must be in the format `projects/{project}/global/networks/{network}`, where `{project}` is a project number, such as `12345`, and `{network}` is the name of a VPC network in the project. See (https://cloud.google.com/cloud-build/docs/custom-workers/set-up-custom-worker-pool-environment#understanding_the_network_configuration_options)
         */
        peeredNetwork: string;
    }

    export interface WorkerPoolWorkerConfig {
        /**
         * Size of the disk attached to the worker, in GB. See (https://cloud.google.com/cloud-build/docs/custom-workers/worker-pool-config-file). Specify a value of up to 1000. If `0` is specified, Cloud Build will use a standard disk size.
         */
        diskSizeGb?: number;
        /**
         * Machine type of a worker, such as `n1-standard-1`. See (https://cloud.google.com/cloud-build/docs/custom-workers/worker-pool-config-file). If left blank, Cloud Build will use `n1-standard-1`.
         */
        machineType?: string;
        /**
         * If true, workers are created without any public address, which prevents network egress to public IPs.
         */
        noExternalIp: boolean;
    }

}

export namespace clouddeploy {
    export interface DeliveryPipelineCondition {
        pipelineReadyConditions: outputs.clouddeploy.DeliveryPipelineConditionPipelineReadyCondition[];
        targetsPresentConditions: outputs.clouddeploy.DeliveryPipelineConditionTargetsPresentCondition[];
    }

    export interface DeliveryPipelineConditionPipelineReadyCondition {
        status: boolean;
        updateTime: string;
    }

    export interface DeliveryPipelineConditionTargetsPresentCondition {
        missingTargets: string[];
        status: boolean;
        updateTime: string;
    }

    export interface DeliveryPipelineSerialPipeline {
        /**
         * Each stage specifies configuration for a `Target`. The ordering of this list defines the promotion flow.
         */
        stages?: outputs.clouddeploy.DeliveryPipelineSerialPipelineStage[];
    }

    export interface DeliveryPipelineSerialPipelineStage {
        /**
         * Skaffold profiles to use when rendering the manifest for this stage's `Target`.
         */
        profiles?: string[];
        /**
         * The targetId to which this stage points. This field refers exclusively to the last segment of a target name. For example, this field would just be `my-target` (rather than `projects/project/locations/location/targets/my-target`). The location of the `Target` is inferred to be the same as the location of the `DeliveryPipeline` that contains this `Stage`.
         */
        targetId?: string;
    }

    export interface TargetAnthosCluster {
        /**
         * Membership of the GKE Hub-registered cluster to which to apply the Skaffold configuration. Format is `projects/{project}/locations/{location}/memberships/{membership_name}`.
         */
        membership?: string;
    }

    export interface TargetExecutionConfig {
        /**
         * Optional. Cloud Storage location in which to store execution outputs. This can either be a bucket ("gs://my-bucket") or a path within a bucket ("gs://my-bucket/my-dir"). If unspecified, a default bucket located in the same region will be used.
         */
        artifactStorage?: string;
        /**
         * Optional. Google service account to use for execution. If unspecified, the project execution service account (-compute@developer.gserviceaccount.com) is used.
         */
        serviceAccount?: string;
        /**
         * Required. Usages when this configuration should be applied.
         */
        usages: string[];
        /**
         * Optional. The resource name of the `WorkerPool`, with the format `projects/{project}/locations/{location}/workerPools/{worker_pool}`. If this optional field is unspecified, the default Cloud Build pool will be used.
         */
        workerPool?: string;
    }

    export interface TargetGke {
        /**
         * Information specifying a GKE Cluster. Format is `projects/{project_id}/locations/{location_id}/clusters/{cluster_id}.
         */
        cluster?: string;
        /**
         * Optional. If true, `cluster` is accessed using the private IP address of the control plane endpoint. Otherwise, the default IP address of the control plane endpoint is used. The default IP address is the private IP address for clusters with private control-plane endpoints and the public IP address otherwise. Only specify this option when `cluster` is a [private GKE cluster](https://cloud.google.com/kubernetes-engine/docs/concepts/private-cluster-concept).
         */
        internalIp?: boolean;
    }

}

export namespace cloudfunctions {
    export interface FunctionEventTrigger {
        /**
         * The type of event to observe. For example: `"google.storage.object.finalize"`.
         * See the documentation on [calling Cloud Functions](https://cloud.google.com/functions/docs/calling/) for a
         * full reference of accepted triggers.
         */
        eventType: string;
        /**
         * Specifies policy for failed executions. Structure is documented below.
         */
        failurePolicy: outputs.cloudfunctions.FunctionEventTriggerFailurePolicy;
        /**
         * Required. The name or partial URI of the resource from
         * which to observe events. For example, `"myBucket"` or `"projects/my-project/topics/my-topic"`
         */
        resource: string;
    }

    export interface FunctionEventTriggerFailurePolicy {
        /**
         * Whether the function should be retried on failure. Defaults to `false`.
         */
        retry: boolean;
    }

    export interface FunctionIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface FunctionIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface FunctionSecretEnvironmentVariable {
        /**
         * Name of the environment variable.
         */
        key: string;
        /**
         * Project identifier (due to a known limitation, only project number is supported by this field) of the project that contains the secret. If not set, it will be populated with the function's project, assuming that the secret exists in the same project as of the function.
         */
        projectId: string;
        /**
         * ID of the secret in secret manager (not the full resource name).
         */
        secret: string;
        /**
         * Version of the secret (version number or the string "latest"). It is preferable to use "latest" version with secret volumes as secret value changes are reflected immediately.
         */
        version: string;
    }

    export interface FunctionSecretVolume {
        /**
         * The path within the container to mount the secret volume. For example, setting the mountPath as "/etc/secrets" would mount the secret value files under the "/etc/secrets" directory. This directory will also be completely shadowed and unavailable to mount any other secrets. Recommended mount paths: "/etc/secrets" Restricted mount paths: "/cloudsql", "/dev/log", "/pod", "/proc", "/var/log".
         */
        mountPath: string;
        /**
         * Project identifier (due to a known limitation, only project number is supported by this field) of the project that contains the secret. If not set, it will be populated with the function's project, assuming that the secret exists in the same project as of the function.
         */
        projectId: string;
        /**
         * ID of the secret in secret manager (not the full resource name).
         */
        secret: string;
        /**
         * List of secret versions to mount for this secret. If empty, the "latest" version of the secret will be made available in a file named after the secret under the mount point. Structure is documented below.
         */
        versions?: outputs.cloudfunctions.FunctionSecretVolumeVersion[];
    }

    export interface FunctionSecretVolumeVersion {
        /**
         * Relative path of the file under the mount path where the secret value for this version will be fetched and made available. For example, setting the mountPath as "/etc/secrets" and path as "/secret_foo" would mount the secret value file at "/etc/secrets/secret_foo".
         */
        path: string;
        /**
         * Version of the secret (version number or the string "latest"). It is preferable to use "latest" version with secret volumes as secret value changes are reflected immediately.
         */
        version: string;
    }

    export interface FunctionSourceRepository {
        deployedUrl: string;
        /**
         * The URL pointing to the hosted repository where the function is defined. There are supported Cloud Source Repository URLs in the following formats:
         */
        url: string;
    }

    export interface GetFunctionEventTrigger {
        /**
         * The type of event to observe. For example: `"google.storage.object.finalize"`.
         * See the documentation on [calling Cloud Functions](https://cloud.google.com/functions/docs/calling/)
         * for a full reference of accepted triggers.
         */
        eventType: string;
        /**
         * Policy for failed executions. Structure is documented below.
         */
        failurePolicies: outputs.cloudfunctions.GetFunctionEventTriggerFailurePolicy[];
        /**
         * The name of the resource whose events are being observed, for example, `"myBucket"`
         */
        resource: string;
    }

    export interface GetFunctionEventTriggerFailurePolicy {
        /**
         * Whether the function should be retried on failure.
         */
        retry: boolean;
    }

    export interface GetFunctionSecretEnvironmentVariable {
        key: string;
        projectId: string;
        secret: string;
        version: string;
    }

    export interface GetFunctionSecretVolume {
        mountPath: string;
        projectId: string;
        secret: string;
        versions: outputs.cloudfunctions.GetFunctionSecretVolumeVersion[];
    }

    export interface GetFunctionSecretVolumeVersion {
        path: string;
        version: string;
    }

    export interface GetFunctionSourceRepository {
        deployedUrl: string;
        /**
         * The URL pointing to the hosted repository where the function is defined.
         */
        url: string;
    }

}

export namespace cloudfunctionsv2 {
    export interface FunctionBuildConfig {
        /**
         * -
         * The Cloud Build name of the latest successful
         * deployment of the function.
         */
        build: string;
        /**
         * User managed repository created in Artifact Registry optionally with a customer managed encryption key.
         */
        dockerRepository?: string;
        /**
         * The name of the function (as defined in source code) that will be executed.
         * Defaults to the resource name suffix, if not specified. For backward
         * compatibility, if function with given name is not found, then the system
         * will try to use function named "function". For Node.js this is name of a
         * function exported by the module specified in source_location.
         */
        entryPoint?: string;
        /**
         * Environment variables that shall be available during function execution.
         */
        environmentVariables: {[key: string]: string};
        /**
         * The runtime in which to run the function. Required when deploying a new
         * function, optional when updating an existing function.
         */
        runtime?: string;
        /**
         * The location of the function source code.
         * Structure is documented below.
         */
        source?: outputs.cloudfunctionsv2.FunctionBuildConfigSource;
        /**
         * Name of the Cloud Build Custom Worker Pool that should be used to build the function.
         */
        workerPool?: string;
    }

    export interface FunctionBuildConfigSource {
        /**
         * If provided, get the source from this location in a Cloud Source Repository.
         * Structure is documented below.
         */
        repoSource?: outputs.cloudfunctionsv2.FunctionBuildConfigSourceRepoSource;
        /**
         * If provided, get the source from this location in Google Cloud Storage.
         * Structure is documented below.
         */
        storageSource?: outputs.cloudfunctionsv2.FunctionBuildConfigSourceStorageSource;
    }

    export interface FunctionBuildConfigSourceRepoSource {
        /**
         * Regex matching branches to build.
         */
        branchName?: string;
        /**
         * Regex matching tags to build.
         */
        commitSha?: string;
        /**
         * Directory, relative to the source root, in which to run the build.
         */
        dir?: string;
        /**
         * Only trigger a build if the revision regex does
         * NOT match the revision regex.
         */
        invertRegex?: boolean;
        /**
         * ID of the project that owns the Cloud Source Repository. If omitted, the
         * project ID requesting the build is assumed.
         */
        projectId?: string;
        /**
         * Name of the Cloud Source Repository.
         */
        repoName?: string;
        /**
         * Regex matching tags to build.
         */
        tagName?: string;
    }

    export interface FunctionBuildConfigSourceStorageSource {
        /**
         * Google Cloud Storage bucket containing the source
         */
        bucket?: string;
        /**
         * Google Cloud Storage generation for the object. If the generation
         * is omitted, the latest generation will be used.
         */
        generation?: number;
        /**
         * Google Cloud Storage object containing the source.
         */
        object?: string;
    }

    export interface FunctionEventTrigger {
        /**
         * Required. The type of event to observe.
         */
        eventType?: string;
        /**
         * The name of a Pub/Sub topic in the same project that will be used
         * as the transport topic for the event delivery.
         */
        pubsubTopic?: string;
        /**
         * Describes the retry policy in case of function's execution failure.
         * Retried execution is charged as any other execution.
         * Possible values are `RETRY_POLICY_UNSPECIFIED`, `RETRY_POLICY_DO_NOT_RETRY`, and `RETRY_POLICY_RETRY`.
         */
        retryPolicy?: string;
        /**
         * -
         * The email of the service account for this function.
         */
        serviceAccountEmail: string;
        /**
         * -
         * The resource name of the Eventarc trigger.
         */
        trigger: string;
        /**
         * The region that the trigger will be in. The trigger will only receive
         * events originating in this region. It can be the same
         * region as the function, a different region or multi-region, or the global
         * region. If not provided, defaults to the same region as the function.
         */
        triggerRegion?: string;
    }

    export interface FunctionServiceConfig {
        /**
         * Whether 100% of traffic is routed to the latest revision. Defaults to true.
         */
        allTrafficOnLatestRevision?: boolean;
        /**
         * The amount of memory available for a function.
         * Defaults to 256M. Supported units are k, M, G, Mi, Gi. If no unit is
         * supplied the value is interpreted as bytes.
         */
        availableMemory?: string;
        /**
         * Environment variables that shall be available during function execution.
         */
        environmentVariables?: {[key: string]: string};
        /**
         * -
         * URIs of the Service deployed
         */
        gcfUri: string;
        /**
         * Available ingress settings. Defaults to "ALLOW_ALL" if unspecified.
         * Default value is `ALLOW_ALL`.
         * Possible values are `ALLOW_ALL`, `ALLOW_INTERNAL_ONLY`, and `ALLOW_INTERNAL_AND_GCLB`.
         */
        ingressSettings?: string;
        /**
         * The limit on the maximum number of function instances that may coexist at a
         * given time.
         */
        maxInstanceCount?: number;
        /**
         * The limit on the minimum number of function instances that may coexist at a
         * given time.
         */
        minInstanceCount?: number;
        /**
         * Name of the service associated with a Function.
         */
        service: string;
        /**
         * -
         * The email of the service account for this function.
         */
        serviceAccountEmail: string;
        /**
         * The function execution timeout. Execution is considered failed and
         * can be terminated if the function is not completed at the end of the
         * timeout period. Defaults to 60 seconds.
         */
        timeoutSeconds?: number;
        /**
         * -
         * URI of the Service deployed.
         */
        uri: string;
        /**
         * The Serverless VPC Access connector that this cloud function can connect to.
         */
        vpcConnector?: string;
        /**
         * Available egress settings.
         * Possible values are `VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED`, `PRIVATE_RANGES_ONLY`, and `ALL_TRAFFIC`.
         */
        vpcConnectorEgressSettings?: string;
    }

}

export namespace cloudidentity {
    export interface GetGroupMembershipsMembership {
        createTime: string;
        /**
         * The parent Group resource under which to lookup the Membership names. Must be of the form groups/{group_id}.
         */
        group: string;
        memberKeys: outputs.cloudidentity.GetGroupMembershipsMembershipMemberKey[];
        /**
         * The name of the MembershipRole. One of OWNER, MANAGER, MEMBER.
         */
        name: string;
        preferredMemberKeys: outputs.cloudidentity.GetGroupMembershipsMembershipPreferredMemberKey[];
        /**
         * The MembershipRoles that apply to the Membership. Structure is documented below.
         */
        roles: outputs.cloudidentity.GetGroupMembershipsMembershipRole[];
        type: string;
        updateTime: string;
    }

    export interface GetGroupMembershipsMembershipMemberKey {
        /**
         * The ID of the entity. For Google-managed entities, the id is the email address of an existing
         * group or user. For external-identity-mapped entities, the id is a string conforming
         * to the Identity Source's requirements.
         */
        id: string;
        /**
         * The namespace in which the entity exists.
         * If not populated, the EntityKey represents a Google-managed entity
         * such as a Google user or a Google Group.
         * If populated, the EntityKey represents an external-identity-mapped group.
         */
        namespace: string;
    }

    export interface GetGroupMembershipsMembershipPreferredMemberKey {
        /**
         * The ID of the entity. For Google-managed entities, the id is the email address of an existing
         * group or user. For external-identity-mapped entities, the id is a string conforming
         * to the Identity Source's requirements.
         */
        id: string;
        /**
         * The namespace in which the entity exists.
         * If not populated, the EntityKey represents a Google-managed entity
         * such as a Google user or a Google Group.
         * If populated, the EntityKey represents an external-identity-mapped group.
         */
        namespace: string;
    }

    export interface GetGroupMembershipsMembershipRole {
        /**
         * The name of the MembershipRole. One of OWNER, MANAGER, MEMBER.
         */
        name: string;
    }

    export interface GetGroupsGroup {
        createTime: string;
        description: string;
        displayName: string;
        groupKeys: outputs.cloudidentity.GetGroupsGroupGroupKey[];
        initialGroupConfig: string;
        labels: {[key: string]: string};
        name: string;
        /**
         * The parent resource under which to list all Groups. Must be of the form identitysources/{identity_source_id} for external- identity-mapped groups or customers/{customer_id} for Google Groups.
         */
        parent: string;
        updateTime: string;
    }

    export interface GetGroupsGroupGroupKey {
        id: string;
        namespace: string;
    }

    export interface GroupGroupKey {
        /**
         * The ID of the entity.
         * For Google-managed entities, the id must be the email address of an existing
         * group or user.
         * For external-identity-mapped entities, the id must be a string conforming
         * to the Identity Source's requirements.
         * Must be unique within a namespace.
         */
        id: string;
        /**
         * The namespace in which the entity exists.
         * If not specified, the EntityKey represents a Google-managed entity
         * such as a Google user or a Google Group.
         * If specified, the EntityKey represents an external-identity-mapped group.
         * The namespace must correspond to an identity source created in Admin Console
         * and must be in the form of `identitysources/{identity_source_id}`.
         */
        namespace?: string;
    }

    export interface GroupMembershipMemberKey {
        /**
         * The ID of the entity.
         * For Google-managed entities, the id must be the email address of an existing
         * group or user.
         * For external-identity-mapped entities, the id must be a string conforming
         * to the Identity Source's requirements.
         * Must be unique within a namespace.
         */
        id: string;
        /**
         * The namespace in which the entity exists.
         * If not specified, the EntityKey represents a Google-managed entity
         * such as a Google user or a Google Group.
         * If specified, the EntityKey represents an external-identity-mapped group.
         * The namespace must correspond to an identity source created in Admin Console
         * and must be in the form of `identitysources/{identity_source_id}`.
         */
        namespace?: string;
    }

    export interface GroupMembershipPreferredMemberKey {
        /**
         * The ID of the entity.
         * For Google-managed entities, the id must be the email address of an existing
         * group or user.
         * For external-identity-mapped entities, the id must be a string conforming
         * to the Identity Source's requirements.
         * Must be unique within a namespace.
         */
        id: string;
        /**
         * The namespace in which the entity exists.
         * If not specified, the EntityKey represents a Google-managed entity
         * such as a Google user or a Google Group.
         * If specified, the EntityKey represents an external-identity-mapped group.
         * The namespace must correspond to an identity source created in Admin Console
         * and must be in the form of `identitysources/{identity_source_id}`.
         */
        namespace?: string;
    }

    export interface GroupMembershipRole {
        /**
         * The name of the MembershipRole. Must be one of OWNER, MANAGER, MEMBER.
         * Possible values are `OWNER`, `MANAGER`, and `MEMBER`.
         */
        name: string;
    }
}

export namespace cloudrun {
    export interface DomainMappingMetadata {
        /**
         * Annotations is a key value map stored with a resource that
         * may be set by external tools to store and retrieve arbitrary metadata. More
         * info: http://kubernetes.io/docs/user-guide/annotations
         * **Note**: The Cloud Run API may add additional annotations that were not provided in your config.
         * If the provider plan shows a diff where a server-side annotation is added, you can add it to your config
         * or apply the lifecycle.ignore_changes rule to the metadata.0.annotations field.
         */
        annotations: {[key: string]: string};
        /**
         * -
         * A sequence number representing a specific generation of the desired state.
         */
        generation: number;
        /**
         * Map of string keys and values that can be used to organize and categorize
         * (scope and select) objects. May match selectors of replication controllers
         * and routes.
         * More info: http://kubernetes.io/docs/user-guide/labels
         */
        labels: {[key: string]: string};
        /**
         * In Cloud Run the namespace must be equal to either the
         * project ID or project number.
         */
        namespace: string;
        /**
         * -
         * An opaque value that represents the internal version of this object that
         * can be used by clients to determine when objects have changed. May be used
         * for optimistic concurrency, change detection, and the watch operation on a
         * resource or set of resources. They may only be valid for a
         * particular resource or set of resources.
         * More info:
         * https://git.k8s.io/community/contributors/devel/api-conventions.md#concurrency-control-and-consistency
         */
        resourceVersion: string;
        /**
         * -
         * SelfLink is a URL representing this object.
         */
        selfLink: string;
        /**
         * -
         * UID is a unique id generated by the server on successful creation of a resource and is not
         * allowed to change on PUT operations.
         * More info: http://kubernetes.io/docs/user-guide/identifiers#uids
         */
        uid: string;
    }

    export interface DomainMappingSpec {
        /**
         * The mode of the certificate.
         * Default value is `AUTOMATIC`.
         * Possible values are `NONE` and `AUTOMATIC`.
         */
        certificateMode?: string;
        /**
         * If set, the mapping will override any mapping set before this spec was set.
         * It is recommended that the user leaves this empty to receive an error
         * warning about a potential conflict and only set it once the respective UI
         * has given such a warning.
         */
        forceOverride?: boolean;
        /**
         * The name of the Cloud Run Service that this DomainMapping applies to.
         * The route must exist.
         */
        routeName: string;
    }

    export interface DomainMappingStatus {
        conditions: outputs.cloudrun.DomainMappingStatusCondition[];
        mappedRouteName: string;
        observedGeneration: number;
        resourceRecords?: outputs.cloudrun.DomainMappingStatusResourceRecord[];
    }

    export interface DomainMappingStatusCondition {
        message: string;
        reason: string;
        status: string;
        type: string;
    }

    export interface DomainMappingStatusResourceRecord {
        /**
         * Name should be a [verified](https://support.google.com/webmasters/answer/9008080) domain
         */
        name: string;
        rrdata: string;
        type?: string;
    }

    export interface GetServiceMetadata {
        annotations: {[key: string]: string};
        generation: number;
        labels: {[key: string]: string};
        namespace: string;
        resourceVersion: string;
        selfLink: string;
        uid: string;
    }

    export interface GetServiceStatus {
        conditions: outputs.cloudrun.GetServiceStatusCondition[];
        latestCreatedRevisionName: string;
        latestReadyRevisionName: string;
        observedGeneration: number;
        url: string;
    }

    export interface GetServiceStatusCondition {
        message: string;
        reason: string;
        status: string;
        type: string;
    }

    export interface GetServiceTemplate {
        metadatas: outputs.cloudrun.GetServiceTemplateMetadata[];
        specs: outputs.cloudrun.GetServiceTemplateSpec[];
    }

    export interface GetServiceTemplateMetadata {
        annotations: {[key: string]: string};
        generation: number;
        labels: {[key: string]: string};
        /**
         * The name of the Cloud Run Service.
         */
        name: string;
        namespace: string;
        resourceVersion: string;
        selfLink: string;
        uid: string;
    }

    export interface GetServiceTemplateSpec {
        containerConcurrency: number;
        containers: outputs.cloudrun.GetServiceTemplateSpecContainer[];
        serviceAccountName: string;
        servingState: string;
        timeoutSeconds: number;
        volumes: outputs.cloudrun.GetServiceTemplateSpecVolume[];
    }

    export interface GetServiceTemplateSpecContainer {
        args: string[];
        commands: string[];
        envFroms: outputs.cloudrun.GetServiceTemplateSpecContainerEnvFrom[];
        envs: outputs.cloudrun.GetServiceTemplateSpecContainerEnv[];
        image: string;
        ports: outputs.cloudrun.GetServiceTemplateSpecContainerPort[];
        resources: outputs.cloudrun.GetServiceTemplateSpecContainerResource[];
        volumeMounts: outputs.cloudrun.GetServiceTemplateSpecContainerVolumeMount[];
        workingDir: string;
    }

    export interface GetServiceTemplateSpecContainerEnv {
        /**
         * The name of the Cloud Run Service.
         */
        name: string;
        value: string;
        valueFroms: outputs.cloudrun.GetServiceTemplateSpecContainerEnvValueFrom[];
    }

    export interface GetServiceTemplateSpecContainerEnvFrom {
        configMapReves: outputs.cloudrun.GetServiceTemplateSpecContainerEnvFromConfigMapRef[];
        prefix: string;
        secretReves: outputs.cloudrun.GetServiceTemplateSpecContainerEnvFromSecretRef[];
    }

    export interface GetServiceTemplateSpecContainerEnvFromConfigMapRef {
        localObjectReferences: outputs.cloudrun.GetServiceTemplateSpecContainerEnvFromConfigMapRefLocalObjectReference[];
        optional: boolean;
    }

    export interface GetServiceTemplateSpecContainerEnvFromConfigMapRefLocalObjectReference {
        /**
         * The name of the Cloud Run Service.
         */
        name: string;
    }

    export interface GetServiceTemplateSpecContainerEnvFromSecretRef {
        localObjectReferences: outputs.cloudrun.GetServiceTemplateSpecContainerEnvFromSecretRefLocalObjectReference[];
        optional: boolean;
    }

    export interface GetServiceTemplateSpecContainerEnvFromSecretRefLocalObjectReference {
        /**
         * The name of the Cloud Run Service.
         */
        name: string;
    }

    export interface GetServiceTemplateSpecContainerEnvValueFrom {
        secretKeyReves: outputs.cloudrun.GetServiceTemplateSpecContainerEnvValueFromSecretKeyRef[];
    }

    export interface GetServiceTemplateSpecContainerEnvValueFromSecretKeyRef {
        key: string;
        /**
         * The name of the Cloud Run Service.
         */
        name: string;
    }

    export interface GetServiceTemplateSpecContainerPort {
        containerPort: number;
        /**
         * The name of the Cloud Run Service.
         */
        name: string;
        protocol: string;
    }

    export interface GetServiceTemplateSpecContainerResource {
        limits: {[key: string]: string};
        requests: {[key: string]: string};
    }

    export interface GetServiceTemplateSpecContainerVolumeMount {
        mountPath: string;
        /**
         * The name of the Cloud Run Service.
         */
        name: string;
    }

    export interface GetServiceTemplateSpecVolume {
        /**
         * The name of the Cloud Run Service.
         */
        name: string;
        secrets: outputs.cloudrun.GetServiceTemplateSpecVolumeSecret[];
    }

    export interface GetServiceTemplateSpecVolumeSecret {
        defaultMode: number;
        items: outputs.cloudrun.GetServiceTemplateSpecVolumeSecretItem[];
        secretName: string;
    }

    export interface GetServiceTemplateSpecVolumeSecretItem {
        key: string;
        mode: number;
        path: string;
    }

    export interface GetServiceTraffic {
        latestRevision: boolean;
        percent: number;
        revisionName: string;
        tag: string;
        url: string;
    }

    export interface IamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface IamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ServiceMetadata {
        /**
         * Annotations is a key value map stored with a resource that
         * may be set by external tools to store and retrieve arbitrary metadata. More
         * info: http://kubernetes.io/docs/user-guide/annotations
         * **Note**: The Cloud Run API may add additional annotations that were not provided in your config.
         * If the provider plan shows a diff where a server-side annotation is added, you can add it to your config
         * or apply the lifecycle.ignore_changes rule to the metadata.0.annotations field.
         * Cloud Run (fully managed) uses the following annotation keys to configure features on a Service:
         * - `run.googleapis.com/ingress` sets the [ingress settings](https://cloud.google.com/sdk/gcloud/reference/run/deploy#--ingress)
         * for the Service. For example, `"run.googleapis.com/ingress" = "all"`.
         */
        annotations: {[key: string]: string};
        /**
         * -
         * A sequence number representing a specific generation of the desired state.
         */
        generation: number;
        /**
         * Map of string keys and values that can be used to organize and categorize
         * (scope and select) objects. May match selectors of replication controllers
         * and routes.
         * More info: http://kubernetes.io/docs/user-guide/labels
         */
        labels: {[key: string]: string};
        /**
         * In Cloud Run the namespace must be equal to either the
         * project ID or project number.
         */
        namespace: string;
        /**
         * -
         * An opaque value that represents the internal version of this object that
         * can be used by clients to determine when objects have changed. May be used
         * for optimistic concurrency, change detection, and the watch operation on a
         * resource or set of resources. They may only be valid for a
         * particular resource or set of resources.
         * More info:
         * https://git.k8s.io/community/contributors/devel/api-conventions.md#concurrency-control-and-consistency
         */
        resourceVersion: string;
        /**
         * -
         * SelfLink is a URL representing this object.
         */
        selfLink: string;
        /**
         * -
         * UID is a unique id generated by the server on successful creation of a resource and is not
         * allowed to change on PUT operations.
         * More info: http://kubernetes.io/docs/user-guide/identifiers#uids
         */
        uid: string;
    }

    export interface ServiceStatus {
        conditions: outputs.cloudrun.ServiceStatusCondition[];
        latestCreatedRevisionName: string;
        latestReadyRevisionName: string;
        observedGeneration: number;
        /**
         * -
         * URL displays the URL for accessing tagged traffic targets. URL is displayed in status,
         * and is disallowed on spec. URL must contain a scheme (e.g. http://) and a hostname,
         * but may not contain anything else (e.g. basic auth, url path, etc.)
         */
        url: string;
    }

    export interface ServiceStatusCondition {
        message: string;
        reason: string;
        status: string;
        type: string;
    }

    export interface ServiceTemplate {
        /**
         * Metadata associated with this Service, including name, namespace, labels,
         * and annotations.
         * Structure is documented below.
         */
        metadata: outputs.cloudrun.ServiceTemplateMetadata;
        /**
         * RevisionSpec holds the desired state of the Revision (from the client).
         * Structure is documented below.
         */
        spec: outputs.cloudrun.ServiceTemplateSpec;
    }

    export interface ServiceTemplateMetadata {
        /**
         * Annotations is a key value map stored with a resource that
         * may be set by external tools to store and retrieve arbitrary metadata. More
         * info: http://kubernetes.io/docs/user-guide/annotations
         * **Note**: The Cloud Run API may add additional annotations that were not provided in your config.
         * If the provider plan shows a diff where a server-side annotation is added, you can add it to your config
         * or apply the lifecycle.ignore_changes rule to the metadata.0.annotations field.
         * Cloud Run (fully managed) uses the following annotation keys to configure features on a Service:
         * - `run.googleapis.com/ingress` sets the [ingress settings](https://cloud.google.com/sdk/gcloud/reference/run/deploy#--ingress)
         * for the Service. For example, `"run.googleapis.com/ingress" = "all"`.
         */
        annotations: {[key: string]: string};
        /**
         * -
         * A sequence number representing a specific generation of the desired state.
         */
        generation: number;
        /**
         * Map of string keys and values that can be used to organize and categorize
         * (scope and select) objects. May match selectors of replication controllers
         * and routes.
         * More info: http://kubernetes.io/docs/user-guide/labels
         */
        labels?: {[key: string]: string};
        /**
         * Volume's name.
         */
        name: string;
        /**
         * In Cloud Run the namespace must be equal to either the
         * project ID or project number.
         */
        namespace: string;
        /**
         * -
         * An opaque value that represents the internal version of this object that
         * can be used by clients to determine when objects have changed. May be used
         * for optimistic concurrency, change detection, and the watch operation on a
         * resource or set of resources. They may only be valid for a
         * particular resource or set of resources.
         * More info:
         * https://git.k8s.io/community/contributors/devel/api-conventions.md#concurrency-control-and-consistency
         */
        resourceVersion: string;
        /**
         * -
         * SelfLink is a URL representing this object.
         */
        selfLink: string;
        /**
         * -
         * UID is a unique id generated by the server on successful creation of a resource and is not
         * allowed to change on PUT operations.
         * More info: http://kubernetes.io/docs/user-guide/identifiers#uids
         */
        uid: string;
    }

    export interface ServiceTemplateSpec {
        /**
         * ContainerConcurrency specifies the maximum allowed in-flight (concurrent)
         * requests per container of the Revision. Values are:
         */
        containerConcurrency: number;
        /**
         * Container defines the unit of execution for this Revision.
         * In the context of a Revision, we disallow a number of the fields of
         * this Container, including: name, ports, and volumeMounts.
         * The runtime contract is documented here:
         * https://github.com/knative/serving/blob/main/docs/runtime-contract.md
         * Structure is documented below.
         */
        containers: outputs.cloudrun.ServiceTemplateSpecContainer[];
        /**
         * Email address of the IAM service account associated with the revision of the
         * service. The service account represents the identity of the running revision,
         * and determines what permissions the revision has. If not provided, the revision
         * will use the project's default service account.
         */
        serviceAccountName: string;
        /**
         * -
         * (Deprecated)
         * ServingState holds a value describing the state the resources
         * are in for this Revision.
         * It is expected
         * that the system will manipulate this based on routability and load.
         *
         * @deprecated Not supported by Cloud Run fully managed
         */
        servingState: string;
        /**
         * TimeoutSeconds holds the max duration the instance is allowed for responding to a request.
         */
        timeoutSeconds: number;
        /**
         * Volume represents a named volume in a container.
         * Structure is documented below.
         */
        volumes?: outputs.cloudrun.ServiceTemplateSpecVolume[];
    }

    export interface ServiceTemplateSpecContainer {
        /**
         * Arguments to the entrypoint.
         * The docker image's CMD is used if this is not provided.
         * Variable references $(VAR_NAME) are expanded using the container's
         * environment. If a variable cannot be resolved, the reference in the input
         * string will be unchanged. The $(VAR_NAME) syntax can be escaped with a
         * double $$, ie: $$(VAR_NAME). Escaped references will never be expanded,
         * regardless of whether the variable exists or not.
         * More info:
         * https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
         */
        args?: string[];
        /**
         * Entrypoint array. Not executed within a shell.
         * The docker image's ENTRYPOINT is used if this is not provided.
         * Variable references $(VAR_NAME) are expanded using the container's
         * environment. If a variable cannot be resolved, the reference in the input
         * string will be unchanged. The $(VAR_NAME) syntax can be escaped with a
         * double $$, ie: $$(VAR_NAME). Escaped references will never be expanded,
         * regardless of whether the variable exists or not.
         * More info:
         * https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
         */
        commands?: string[];
        /**
         * -
         * (Optional, Deprecated)
         * List of sources to populate environment variables in the container.
         * All invalid keys will be reported as an event when the container is starting.
         * When a key exists in multiple sources, the value associated with the last source will
         * take precedence. Values defined by an Env with a duplicate key will take
         * precedence.
         * Structure is documented below.
         *
         * @deprecated Not supported by Cloud Run fully managed
         */
        envFroms?: outputs.cloudrun.ServiceTemplateSpecContainerEnvFrom[];
        /**
         * List of environment variables to set in the container.
         * Structure is documented below.
         */
        envs?: outputs.cloudrun.ServiceTemplateSpecContainerEnv[];
        /**
         * Docker image name. This is most often a reference to a container located
         * in the container registry, such as gcr.io/cloudrun/hello
         * More info: https://kubernetes.io/docs/concepts/containers/images
         */
        image: string;
        /**
         * List of open ports in the container.
         * More Info:
         * https://cloud.google.com/run/docs/reference/rest/v1/RevisionSpec#ContainerPort
         * Structure is documented below.
         */
        ports: outputs.cloudrun.ServiceTemplateSpecContainerPort[];
        /**
         * Compute Resources required by this container. Used to set values such as max memory
         * More info:
         * https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits
         * Structure is documented below.
         */
        resources: outputs.cloudrun.ServiceTemplateSpecContainerResources;
        /**
         * Volume to mount into the container's filesystem.
         * Only supports SecretVolumeSources.
         * Structure is documented below.
         */
        volumeMounts?: outputs.cloudrun.ServiceTemplateSpecContainerVolumeMount[];
        /**
         * -
         * (Optional, Deprecated)
         * Container's working directory.
         * If not specified, the container runtime's default will be used, which
         * might be configured in the container image.
         *
         * @deprecated Not supported by Cloud Run fully managed
         */
        workingDir?: string;
    }

    export interface ServiceTemplateSpecContainerEnv {
        /**
         * Volume's name.
         */
        name?: string;
        /**
         * Variable references $(VAR_NAME) are expanded
         * using the previous defined environment variables in the container and
         * any route environment variables. If a variable cannot be resolved,
         * the reference in the input string will be unchanged. The $(VAR_NAME)
         * syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped
         * references will never be expanded, regardless of whether the variable
         * exists or not.
         * Defaults to "".
         */
        value?: string;
        /**
         * Source for the environment variable's value. Only supports secret_key_ref.
         * Structure is documented below.
         */
        valueFrom?: outputs.cloudrun.ServiceTemplateSpecContainerEnvValueFrom;
    }

    export interface ServiceTemplateSpecContainerEnvFrom {
        /**
         * The ConfigMap to select from.
         * Structure is documented below.
         */
        configMapRef?: outputs.cloudrun.ServiceTemplateSpecContainerEnvFromConfigMapRef;
        /**
         * An optional identifier to prepend to each key in the ConfigMap.
         */
        prefix?: string;
        /**
         * The Secret to select from.
         * Structure is documented below.
         */
        secretRef?: outputs.cloudrun.ServiceTemplateSpecContainerEnvFromSecretRef;
    }

    export interface ServiceTemplateSpecContainerEnvFromConfigMapRef {
        /**
         * The Secret to select from.
         * Structure is documented below.
         */
        localObjectReference?: outputs.cloudrun.ServiceTemplateSpecContainerEnvFromConfigMapRefLocalObjectReference;
        /**
         * Specify whether the Secret must be defined
         */
        optional?: boolean;
    }

    export interface ServiceTemplateSpecContainerEnvFromConfigMapRefLocalObjectReference {
        /**
         * Volume's name.
         */
        name: string;
    }

    export interface ServiceTemplateSpecContainerEnvFromSecretRef {
        /**
         * The Secret to select from.
         * Structure is documented below.
         */
        localObjectReference?: outputs.cloudrun.ServiceTemplateSpecContainerEnvFromSecretRefLocalObjectReference;
        /**
         * Specify whether the Secret must be defined
         */
        optional?: boolean;
    }

    export interface ServiceTemplateSpecContainerEnvFromSecretRefLocalObjectReference {
        /**
         * Volume's name.
         */
        name: string;
    }

    export interface ServiceTemplateSpecContainerEnvValueFrom {
        /**
         * Selects a key (version) of a secret in Secret Manager.
         * Structure is documented below.
         */
        secretKeyRef: outputs.cloudrun.ServiceTemplateSpecContainerEnvValueFromSecretKeyRef;
    }

    export interface ServiceTemplateSpecContainerEnvValueFromSecretKeyRef {
        /**
         * The Cloud Secret Manager secret version.
         * Can be 'latest' for the latest value or an integer for a specific version.
         */
        key: string;
        /**
         * Volume's name.
         */
        name: string;
    }

    export interface ServiceTemplateSpecContainerPort {
        /**
         * Port number the container listens on. This must be a valid port number, 0 < x < 65536.
         */
        containerPort?: number;
        /**
         * Volume's name.
         */
        name: string;
        /**
         * Protocol for port. Must be "TCP". Defaults to "TCP".
         */
        protocol?: string;
    }

    export interface ServiceTemplateSpecContainerResources {
        /**
         * Limits describes the maximum amount of compute resources allowed.
         * The values of the map is string form of the 'quantity' k8s type:
         * https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apimachinery/pkg/api/resource/quantity.go
         */
        limits: {[key: string]: string};
        /**
         * Requests describes the minimum amount of compute resources required.
         * If Requests is omitted for a container, it defaults to Limits if that is
         * explicitly specified, otherwise to an implementation-defined value.
         * The values of the map is string form of the 'quantity' k8s type:
         * https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apimachinery/pkg/api/resource/quantity.go
         */
        requests?: {[key: string]: string};
    }

    export interface ServiceTemplateSpecContainerVolumeMount {
        /**
         * Path within the container at which the volume should be mounted.  Must
         * not contain ':'.
         */
        mountPath: string;
        /**
         * Volume's name.
         */
        name: string;
    }

    export interface ServiceTemplateSpecVolume {
        /**
         * Volume's name.
         */
        name: string;
        /**
         * The secret's value will be presented as the content of a file whose
         * name is defined in the item path. If no items are defined, the name of
         * the file is the secret_name.
         * Structure is documented below.
         */
        secret: outputs.cloudrun.ServiceTemplateSpecVolumeSecret;
    }

    export interface ServiceTemplateSpecVolumeSecret {
        /**
         * Mode bits to use on created files by default. Must be a value between 0000
         * and 0777. Defaults to 0644. Directories within the path are not affected by
         * this setting. This might be in conflict with other options that affect the
         * file mode, like fsGroup, and the result can be other mode bits set.
         */
        defaultMode?: number;
        /**
         * If unspecified, the volume will expose a file whose name is the
         * secret_name.
         * If specified, the key will be used as the version to fetch from Cloud
         * Secret Manager and the path will be the name of the file exposed in the
         * volume. When items are defined, they must specify a key and a path.
         * Structure is documented below.
         */
        items?: outputs.cloudrun.ServiceTemplateSpecVolumeSecretItem[];
        /**
         * The name of the secret in Cloud Secret Manager. By default, the secret
         * is assumed to be in the same project.
         * If the secret is in another project, you must define an alias.
         * An alias definition has the form:
         * <alias>:projects/<project-id|project-number>/secrets/<secret-name>.
         * If multiple alias definitions are needed, they must be separated by
         * commas.
         * The alias definitions must be set on the run.googleapis.com/secrets
         * annotation.
         */
        secretName: string;
    }

    export interface ServiceTemplateSpecVolumeSecretItem {
        /**
         * The Cloud Secret Manager secret version.
         * Can be 'latest' for the latest value or an integer for a specific version.
         */
        key: string;
        /**
         * Mode bits to use on this file, must be a value between 0000 and 0777. If
         * not specified, the volume defaultMode will be used. This might be in
         * conflict with other options that affect the file mode, like fsGroup, and
         * the result can be other mode bits set.
         */
        mode?: number;
        /**
         * The relative path of the file to map the key to.
         * May not be an absolute path.
         * May not contain the path element '..'.
         * May not start with the string '..'.
         */
        path: string;
    }

    export interface ServiceTraffic {
        /**
         * LatestRevision may be optionally provided to indicate that the latest ready
         * Revision of the Configuration should be used for this traffic target. When
         * provided LatestRevision must be true if RevisionName is empty; it must be
         * false when RevisionName is non-empty.
         */
        latestRevision?: boolean;
        /**
         * Percent specifies percent of the traffic to this Revision or Configuration.
         */
        percent: number;
        /**
         * RevisionName of a specific revision to which to send this portion of traffic.
         */
        revisionName?: string;
        /**
         * Tag is optionally used to expose a dedicated url for referencing this target exclusively.
         */
        tag?: string;
        /**
         * -
         * URL displays the URL for accessing tagged traffic targets. URL is displayed in status,
         * and is disallowed on spec. URL must contain a scheme (e.g. http://) and a hostname,
         * but may not contain anything else (e.g. basic auth, url path, etc.)
         */
        url: string;
    }
}

export namespace cloudscheduler {
    export interface JobAppEngineHttpTarget {
        /**
         * App Engine Routing setting for the job.
         * Structure is documented below.
         */
        appEngineRouting?: outputs.cloudscheduler.JobAppEngineHttpTargetAppEngineRouting;
        /**
         * HTTP request body.
         * A request body is allowed only if the HTTP method is POST, PUT, or PATCH.
         * It is an error to set body on a job with an incompatible HttpMethod.
         * A base64-encoded string.
         */
        body?: string;
        /**
         * This map contains the header field names and values.
         * Repeated headers are not supported, but a header value can contain commas.
         */
        headers?: {[key: string]: string};
        /**
         * Which HTTP method to use for the request.
         */
        httpMethod?: string;
        /**
         * The relative URI.
         * The relative URL must begin with "/" and must be a valid HTTP relative URL.
         * It can contain a path, query string arguments, and \# fragments.
         * If the relative URL is empty, then the root path "/" will be used.
         * No spaces are allowed, and the maximum length allowed is 2083 characters
         */
        relativeUri: string;
    }

    export interface JobAppEngineHttpTargetAppEngineRouting {
        /**
         * App instance.
         * By default, the job is sent to an instance which is available when the job is attempted.
         */
        instance?: string;
        /**
         * App service.
         * By default, the job is sent to the service which is the default service when the job is attempted.
         */
        service?: string;
        /**
         * App version.
         * By default, the job is sent to the version which is the default version when the job is attempted.
         */
        version?: string;
    }

    export interface JobHttpTarget {
        /**
         * HTTP request body.
         * A request body is allowed only if the HTTP method is POST, PUT, or PATCH.
         * It is an error to set body on a job with an incompatible HttpMethod.
         * A base64-encoded string.
         */
        body?: string;
        /**
         * This map contains the header field names and values.
         * Repeated headers are not supported, but a header value can contain commas.
         */
        headers?: {[key: string]: string};
        /**
         * Which HTTP method to use for the request.
         */
        httpMethod?: string;
        /**
         * Contains information needed for generating an OAuth token.
         * This type of authorization should be used when sending requests to a GCP endpoint.
         * Structure is documented below.
         */
        oauthToken?: outputs.cloudscheduler.JobHttpTargetOauthToken;
        /**
         * Contains information needed for generating an OpenID Connect token.
         * This type of authorization should be used when sending requests to third party endpoints or Cloud Run.
         * Structure is documented below.
         */
        oidcToken?: outputs.cloudscheduler.JobHttpTargetOidcToken;
        /**
         * The full URI path that the request will be sent to.
         */
        uri: string;
    }

    export interface JobHttpTargetOauthToken {
        /**
         * OAuth scope to be used for generating OAuth access token. If not specified,
         * "https://www.googleapis.com/auth/cloud-platform" will be used.
         */
        scope?: string;
        /**
         * Service account email to be used for generating OAuth token.
         * The service account must be within the same project as the job.
         */
        serviceAccountEmail: string;
    }

    export interface JobHttpTargetOidcToken {
        /**
         * Audience to be used when generating OIDC token. If not specified,
         * the URI specified in target will be used.
         */
        audience?: string;
        /**
         * Service account email to be used for generating OAuth token.
         * The service account must be within the same project as the job.
         */
        serviceAccountEmail: string;
    }

    export interface JobPubsubTarget {
        /**
         * Attributes for PubsubMessage.
         * Pubsub message must contain either non-empty data, or at least one attribute.
         */
        attributes?: {[key: string]: string};
        /**
         * The message payload for PubsubMessage.
         * Pubsub message must contain either non-empty data, or at least one attribute.
         * A base64-encoded string.
         */
        data?: string;
        /**
         * The full resource name for the Cloud Pub/Sub topic to which
         * messages will be published when a job is delivered. ~>**NOTE:**
         * The topic name must be in the same format as required by PubSub's
         * PublishRequest.name, e.g. `projects/my-project/topics/my-topic`.
         */
        topicName: string;
    }

    export interface JobRetryConfig {
        /**
         * The maximum amount of time to wait before retrying a job after it fails.
         * A duration in seconds with up to nine fractional digits, terminated by 's'.
         */
        maxBackoffDuration: string;
        /**
         * The time between retries will double maxDoublings times.
         * A job's retry interval starts at minBackoffDuration,
         * then doubles maxDoublings times, then increases linearly,
         * and finally retries retries at intervals of maxBackoffDuration up to retryCount times.
         */
        maxDoublings: number;
        /**
         * The time limit for retrying a failed job, measured from time when an execution was first attempted.
         * If specified with retryCount, the job will be retried until both limits are reached.
         * A duration in seconds with up to nine fractional digits, terminated by 's'.
         */
        maxRetryDuration: string;
        /**
         * The minimum amount of time to wait before retrying a job after it fails.
         * A duration in seconds with up to nine fractional digits, terminated by 's'.
         */
        minBackoffDuration: string;
        /**
         * The number of attempts that the system will make to run a
         * job using the exponential backoff procedure described by maxDoublings.
         * Values greater than 5 and negative values are not allowed.
         */
        retryCount: number;
    }

}

export namespace cloudtasks {
    export interface QueueAppEngineRoutingOverride {
        /**
         * -
         * The host that the task is sent to.
         */
        host: string;
        /**
         * App instance.
         * By default, the task is sent to an instance which is available when the task is attempted.
         */
        instance?: string;
        /**
         * App service.
         * By default, the task is sent to the service which is the default service when the task is attempted.
         */
        service?: string;
        /**
         * App version.
         * By default, the task is sent to the version which is the default version when the task is attempted.
         */
        version?: string;
    }

    export interface QueueRateLimits {
        /**
         * -
         * The max burst size.
         * Max burst size limits how fast tasks in queue are processed when many tasks are
         * in the queue and the rate is high. This field allows the queue to have a high
         * rate so processing starts shortly after a task is enqueued, but still limits
         * resource usage when many tasks are enqueued in a short period of time.
         */
        maxBurstSize: number;
        /**
         * The maximum number of concurrent tasks that Cloud Tasks allows to
         * be dispatched for this queue. After this threshold has been
         * reached, Cloud Tasks stops dispatching tasks until the number of
         * concurrent requests decreases.
         */
        maxConcurrentDispatches: number;
        /**
         * The maximum rate at which tasks are dispatched from this queue.
         * If unspecified when the queue is created, Cloud Tasks will pick the default.
         */
        maxDispatchesPerSecond: number;
    }

    export interface QueueRetryConfig {
        /**
         * Number of attempts per task.
         * Cloud Tasks will attempt the task maxAttempts times (that is, if
         * the first attempt fails, then there will be maxAttempts - 1
         * retries). Must be >= -1.
         * If unspecified when the queue is created, Cloud Tasks will pick
         * the default.
         * -1 indicates unlimited attempts.
         */
        maxAttempts: number;
        /**
         * A task will be scheduled for retry between minBackoff and
         * maxBackoff duration after it fails, if the queue's RetryConfig
         * specifies that the task should be retried.
         */
        maxBackoff: string;
        /**
         * The time between retries will double maxDoublings times.
         * A task's retry interval starts at minBackoff, then doubles maxDoublings times,
         * then increases linearly, and finally retries retries at intervals of maxBackoff
         * up to maxAttempts times.
         */
        maxDoublings: number;
        /**
         * If positive, maxRetryDuration specifies the time limit for
         * retrying a failed task, measured from when the task was first
         * attempted. Once maxRetryDuration time has passed and the task has
         * been attempted maxAttempts times, no further attempts will be
         * made and the task will be deleted.
         * If zero, then the task age is unlimited.
         */
        maxRetryDuration: string;
        /**
         * A task will be scheduled for retry between minBackoff and
         * maxBackoff duration after it fails, if the queue's RetryConfig
         * specifies that the task should be retried.
         */
        minBackoff: string;
    }

    export interface QueueStackdriverLoggingConfig {
        /**
         * Specifies the fraction of operations to write to Stackdriver Logging.
         * This field may contain any value between 0.0 and 1.0, inclusive. 0.0 is the
         * default and means that no operations are logged.
         */
        samplingRatio: number;
    }

}

export namespace composer {
    export interface EnvironmentConfig {
        airflowUri: string;
        dagGcsPrefix: string;
        databaseConfig: outputs.composer.EnvironmentConfigDatabaseConfig;
        encryptionConfig: outputs.composer.EnvironmentConfigEncryptionConfig;
        environmentSize: string;
        gkeCluster: string;
        maintenanceWindow: outputs.composer.EnvironmentConfigMaintenanceWindow;
        masterAuthorizedNetworksConfig?: outputs.composer.EnvironmentConfigMasterAuthorizedNetworksConfig;
        nodeConfig: outputs.composer.EnvironmentConfigNodeConfig;
        nodeCount: number;
        privateEnvironmentConfig: outputs.composer.EnvironmentConfigPrivateEnvironmentConfig;
        softwareConfig: outputs.composer.EnvironmentConfigSoftwareConfig;
        webServerConfig: outputs.composer.EnvironmentConfigWebServerConfig;
        webServerNetworkAccessControl: outputs.composer.EnvironmentConfigWebServerNetworkAccessControl;
        workloadsConfig: outputs.composer.EnvironmentConfigWorkloadsConfig;
    }

    export interface EnvironmentConfigDatabaseConfig {
        machineType: string;
    }

    export interface EnvironmentConfigEncryptionConfig {
        kmsKeyName: string;
    }

    export interface EnvironmentConfigMaintenanceWindow {
        endTime: string;
        recurrence: string;
        startTime: string;
    }

    export interface EnvironmentConfigMasterAuthorizedNetworksConfig {
        cidrBlocks?: outputs.composer.EnvironmentConfigMasterAuthorizedNetworksConfigCidrBlock[];
        enabled: boolean;
    }

    export interface EnvironmentConfigMasterAuthorizedNetworksConfigCidrBlock {
        cidrBlock: string;
        displayName?: string;
    }

    export interface EnvironmentConfigNodeConfig {
        diskSizeGb: number;
        enableIpMasqAgent: boolean;
        ipAllocationPolicy: outputs.composer.EnvironmentConfigNodeConfigIpAllocationPolicy;
        machineType: string;
        maxPodsPerNode: number;
        network: string;
        oauthScopes: string[];
        serviceAccount: string;
        subnetwork?: string;
        tags?: string[];
        zone: string;
    }

    export interface EnvironmentConfigNodeConfigIpAllocationPolicy {
        clusterIpv4CidrBlock?: string;
        clusterSecondaryRangeName?: string;
        servicesIpv4CidrBlock?: string;
        servicesSecondaryRangeName?: string;
        useIpAliases?: boolean;
    }

    export interface EnvironmentConfigPrivateEnvironmentConfig {
        cloudComposerConnectionSubnetwork: string;
        cloudComposerNetworkIpv4CidrBlock: string;
        cloudSqlIpv4CidrBlock: string;
        enablePrivateEndpoint?: boolean;
        enablePrivatelyUsedPublicIps: boolean;
        masterIpv4CidrBlock: string;
        webServerIpv4CidrBlock: string;
    }

    export interface EnvironmentConfigSoftwareConfig {
        airflowConfigOverrides?: {[key: string]: string};
        envVariables?: {[key: string]: string};
        imageVersion: string;
        pypiPackages?: {[key: string]: string};
        pythonVersion: string;
        schedulerCount: number;
    }

    export interface EnvironmentConfigWebServerConfig {
        machineType: string;
    }

    export interface EnvironmentConfigWebServerNetworkAccessControl {
        allowedIpRanges: outputs.composer.EnvironmentConfigWebServerNetworkAccessControlAllowedIpRange[];
    }

    export interface EnvironmentConfigWebServerNetworkAccessControlAllowedIpRange {
        description?: string;
        value: string;
    }

    export interface EnvironmentConfigWorkloadsConfig {
        scheduler?: outputs.composer.EnvironmentConfigWorkloadsConfigScheduler;
        webServer?: outputs.composer.EnvironmentConfigWorkloadsConfigWebServer;
        worker?: outputs.composer.EnvironmentConfigWorkloadsConfigWorker;
    }

    export interface EnvironmentConfigWorkloadsConfigScheduler {
        count?: number;
        cpu?: number;
        memoryGb?: number;
        storageGb?: number;
    }

    export interface EnvironmentConfigWorkloadsConfigWebServer {
        cpu?: number;
        memoryGb?: number;
        storageGb?: number;
    }

    export interface EnvironmentConfigWorkloadsConfigWorker {
        cpu?: number;
        maxCount?: number;
        memoryGb?: number;
        minCount?: number;
        storageGb?: number;
    }

    export interface GetEnvironmentConfig {
        airflowUri: string;
        dagGcsPrefix: string;
        databaseConfigs: outputs.composer.GetEnvironmentConfigDatabaseConfig[];
        encryptionConfigs: outputs.composer.GetEnvironmentConfigEncryptionConfig[];
        environmentSize: string;
        gkeCluster: string;
        maintenanceWindows: outputs.composer.GetEnvironmentConfigMaintenanceWindow[];
        masterAuthorizedNetworksConfigs: outputs.composer.GetEnvironmentConfigMasterAuthorizedNetworksConfig[];
        nodeConfigs: outputs.composer.GetEnvironmentConfigNodeConfig[];
        nodeCount: number;
        privateEnvironmentConfigs: outputs.composer.GetEnvironmentConfigPrivateEnvironmentConfig[];
        softwareConfigs: outputs.composer.GetEnvironmentConfigSoftwareConfig[];
        webServerConfigs: outputs.composer.GetEnvironmentConfigWebServerConfig[];
        webServerNetworkAccessControls: outputs.composer.GetEnvironmentConfigWebServerNetworkAccessControl[];
        workloadsConfigs: outputs.composer.GetEnvironmentConfigWorkloadsConfig[];
    }

    export interface GetEnvironmentConfigDatabaseConfig {
        machineType: string;
    }

    export interface GetEnvironmentConfigEncryptionConfig {
        kmsKeyName: string;
    }

    export interface GetEnvironmentConfigMaintenanceWindow {
        endTime: string;
        recurrence: string;
        startTime: string;
    }

    export interface GetEnvironmentConfigMasterAuthorizedNetworksConfig {
        cidrBlocks: outputs.composer.GetEnvironmentConfigMasterAuthorizedNetworksConfigCidrBlock[];
        enabled: boolean;
    }

    export interface GetEnvironmentConfigMasterAuthorizedNetworksConfigCidrBlock {
        cidrBlock: string;
        displayName: string;
    }

    export interface GetEnvironmentConfigNodeConfig {
        diskSizeGb: number;
        enableIpMasqAgent: boolean;
        ipAllocationPolicies: outputs.composer.GetEnvironmentConfigNodeConfigIpAllocationPolicy[];
        machineType: string;
        maxPodsPerNode: number;
        network: string;
        oauthScopes: string[];
        serviceAccount: string;
        subnetwork: string;
        tags: string[];
        zone: string;
    }

    export interface GetEnvironmentConfigNodeConfigIpAllocationPolicy {
        clusterIpv4CidrBlock: string;
        clusterSecondaryRangeName: string;
        servicesIpv4CidrBlock: string;
        servicesSecondaryRangeName: string;
        useIpAliases: boolean;
    }

    export interface GetEnvironmentConfigPrivateEnvironmentConfig {
        cloudComposerConnectionSubnetwork: string;
        cloudComposerNetworkIpv4CidrBlock: string;
        cloudSqlIpv4CidrBlock: string;
        enablePrivateEndpoint: boolean;
        enablePrivatelyUsedPublicIps: boolean;
        masterIpv4CidrBlock: string;
        webServerIpv4CidrBlock: string;
    }

    export interface GetEnvironmentConfigSoftwareConfig {
        airflowConfigOverrides: {[key: string]: string};
        envVariables: {[key: string]: string};
        imageVersion: string;
        pypiPackages: {[key: string]: string};
        pythonVersion: string;
        schedulerCount: number;
    }

    export interface GetEnvironmentConfigWebServerConfig {
        machineType: string;
    }

    export interface GetEnvironmentConfigWebServerNetworkAccessControl {
        allowedIpRanges: outputs.composer.GetEnvironmentConfigWebServerNetworkAccessControlAllowedIpRange[];
    }

    export interface GetEnvironmentConfigWebServerNetworkAccessControlAllowedIpRange {
        description: string;
        value: string;
    }

    export interface GetEnvironmentConfigWorkloadsConfig {
        schedulers: outputs.composer.GetEnvironmentConfigWorkloadsConfigScheduler[];
        webServers: outputs.composer.GetEnvironmentConfigWorkloadsConfigWebServer[];
        workers: outputs.composer.GetEnvironmentConfigWorkloadsConfigWorker[];
    }

    export interface GetEnvironmentConfigWorkloadsConfigScheduler {
        count: number;
        cpu: number;
        memoryGb: number;
        storageGb: number;
    }

    export interface GetEnvironmentConfigWorkloadsConfigWebServer {
        cpu: number;
        memoryGb: number;
        storageGb: number;
    }

    export interface GetEnvironmentConfigWorkloadsConfigWorker {
        cpu: number;
        maxCount: number;
        memoryGb: number;
        minCount: number;
        storageGb: number;
    }

    export interface GetImageVersionsImageVersion {
        /**
         * The string identifier of the image version, in the form: "composer-x.y.z-airflow-a.b.c"
         */
        imageVersionId: string;
        /**
         * Supported python versions for this image version
         */
        supportedPythonVersions: string[];
    }

}

export namespace compute {
    export interface AutoscalarAutoscalingPolicy {
        /**
         * The number of seconds that the autoscaler should wait before it
         * starts collecting information from a new instance. This prevents
         * the autoscaler from collecting information when the instance is
         * initializing, during which the collected usage would not be
         * reliable. The default time autoscaler waits is 60 seconds.
         * Virtual machine initialization times might vary because of
         * numerous factors. We recommend that you test how long an
         * instance may take to initialize. To do this, create an instance
         * and time the startup process.
         */
        cooldownPeriod?: number;
        /**
         * Defines the CPU utilization policy that allows the autoscaler to
         * scale based on the average CPU utilization of a managed instance
         * group.
         * Structure is documented below.
         */
        cpuUtilization: outputs.compute.AutoscalarAutoscalingPolicyCpuUtilization;
        /**
         * Configuration parameters of autoscaling based on a load balancer.
         * Structure is documented below.
         */
        loadBalancingUtilization?: outputs.compute.AutoscalarAutoscalingPolicyLoadBalancingUtilization;
        /**
         * The maximum number of instances that the autoscaler can scale up
         * to. This is required when creating or updating an autoscaler. The
         * maximum number of replicas should not be lower than minimal number
         * of replicas.
         */
        maxReplicas: number;
        /**
         * Configuration parameters of autoscaling based on a custom metric.
         * Structure is documented below.
         */
        metrics?: outputs.compute.AutoscalarAutoscalingPolicyMetric[];
        /**
         * The minimum number of replicas that the autoscaler can scale down
         * to. This cannot be less than 0. If not provided, autoscaler will
         * choose a default value depending on maximum number of instances
         * allowed.
         */
        minReplicas: number;
        /**
         * Defines operating mode for this policy.
         * Default value is `ON`.
         * Possible values are `OFF`, `ONLY_UP`, and `ON`.
         */
        mode?: string;
        /**
         * Defines scale down controls to reduce the risk of response latency
         * and outages due to abrupt scale-in events
         * Structure is documented below.
         */
        scaleDownControl: outputs.compute.AutoscalarAutoscalingPolicyScaleDownControl;
        /**
         * Defines scale in controls to reduce the risk of response latency
         * and outages due to abrupt scale-in events
         * Structure is documented below.
         */
        scaleInControl?: outputs.compute.AutoscalarAutoscalingPolicyScaleInControl;
        /**
         * Scaling schedules defined for an autoscaler. Multiple schedules can be set on an autoscaler and they can overlap.
         * Structure is documented below.
         */
        scalingSchedules?: outputs.compute.AutoscalarAutoscalingPolicyScalingSchedule[];
    }

    export interface AutoscalarAutoscalingPolicyCpuUtilization {
        /**
         * Indicates whether predictive autoscaling based on CPU metric is enabled. Valid values are:
         * - NONE (default). No predictive method is used. The autoscaler scales the group to meet current demand based on real-time metrics.
         * - OPTIMIZE_AVAILABILITY. Predictive autoscaling improves availability by monitoring daily and weekly load patterns and scaling out ahead of anticipated demand.
         */
        predictiveMethod?: string;
        /**
         * Fraction of backend capacity utilization (set in HTTP(s) load
         * balancing configuration) that autoscaler should maintain. Must
         * be a positive float value. If not defined, the default is 0.8.
         */
        target: number;
    }

    export interface AutoscalarAutoscalingPolicyLoadBalancingUtilization {
        /**
         * Fraction of backend capacity utilization (set in HTTP(s) load
         * balancing configuration) that autoscaler should maintain. Must
         * be a positive float value. If not defined, the default is 0.8.
         */
        target: number;
    }

    export interface AutoscalarAutoscalingPolicyMetric {
        /**
         * A filter string to be used as the filter string for
         * a Stackdriver Monitoring TimeSeries.list API call.
         * This filter is used to select a specific TimeSeries for
         * the purpose of autoscaling and to determine whether the metric
         * is exporting per-instance or per-group data.
         * You can only use the AND operator for joining selectors.
         * You can only use direct equality comparison operator (=) without
         * any functions for each selector.
         * You can specify the metric in both the filter string and in the
         * metric field. However, if specified in both places, the metric must
         * be identical.
         * The monitored resource type determines what kind of values are
         * expected for the metric. If it is a gce_instance, the autoscaler
         * expects the metric to include a separate TimeSeries for each
         * instance in a group. In such a case, you cannot filter on resource
         * labels.
         * If the resource type is any other value, the autoscaler expects
         * this metric to contain values that apply to the entire autoscaled
         * instance group and resource label filtering can be performed to
         * point autoscaler at the correct TimeSeries to scale upon.
         * This is called a per-group metric for the purpose of autoscaling.
         * If not specified, the type defaults to gce_instance.
         * You should provide a filter that is selective enough to pick just
         * one TimeSeries for the autoscaled group or for each of the instances
         * (if you are using gceInstance resource type). If multiple
         * TimeSeries are returned upon the query execution, the autoscaler
         * will sum their respective values to obtain its scaling value.
         */
        filter?: string;
        /**
         * The identifier for this object. Format specified above.
         */
        name: string;
        /**
         * If scaling is based on a per-group metric value that represents the
         * total amount of work to be done or resource usage, set this value to
         * an amount assigned for a single instance of the scaled group.
         * The autoscaler will keep the number of instances proportional to the
         * value of this metric, the metric itself should not change value due
         * to group resizing.
         * For example, a good metric to use with the target is
         * `pubsub.googleapis.com/subscription/num_undelivered_messages`
         * or a custom metric exporting the total number of requests coming to
         * your instances.
         * A bad example would be a metric exporting an average or median
         * latency, since this value can't include a chunk assignable to a
         * single instance, it could be better used with utilizationTarget
         * instead.
         */
        singleInstanceAssignment?: number;
        /**
         * Fraction of backend capacity utilization (set in HTTP(s) load
         * balancing configuration) that autoscaler should maintain. Must
         * be a positive float value. If not defined, the default is 0.8.
         */
        target?: number;
        /**
         * Defines how target utilization value is expressed for a
         * Stackdriver Monitoring metric.
         * Possible values are `GAUGE`, `DELTA_PER_SECOND`, and `DELTA_PER_MINUTE`.
         */
        type?: string;
    }

    export interface AutoscalarAutoscalingPolicyScaleDownControl {
        /**
         * A nested object resource
         * Structure is documented below.
         */
        maxScaledDownReplicas?: outputs.compute.AutoscalarAutoscalingPolicyScaleDownControlMaxScaledDownReplicas;
        /**
         * How long back autoscaling should look when computing recommendations
         * to include directives regarding slower scale down, as described above.
         */
        timeWindowSec?: number;
    }

    export interface AutoscalarAutoscalingPolicyScaleDownControlMaxScaledDownReplicas {
        /**
         * Specifies a fixed number of VM instances. This must be a positive
         * integer.
         */
        fixed?: number;
        /**
         * Specifies a percentage of instances between 0 to 100%, inclusive.
         * For example, specify 80 for 80%.
         */
        percent?: number;
    }

    export interface AutoscalarAutoscalingPolicyScaleInControl {
        /**
         * A nested object resource
         * Structure is documented below.
         */
        maxScaledInReplicas?: outputs.compute.AutoscalarAutoscalingPolicyScaleInControlMaxScaledInReplicas;
        /**
         * How long back autoscaling should look when computing recommendations
         * to include directives regarding slower scale down, as described above.
         */
        timeWindowSec?: number;
    }

    export interface AutoscalarAutoscalingPolicyScaleInControlMaxScaledInReplicas {
        /**
         * Specifies a fixed number of VM instances. This must be a positive
         * integer.
         */
        fixed?: number;
        /**
         * Specifies a percentage of instances between 0 to 100%, inclusive.
         * For example, specify 80 for 80%.
         */
        percent?: number;
    }

    export interface AutoscalarAutoscalingPolicyScalingSchedule {
        /**
         * An optional description of this resource.
         */
        description?: string;
        /**
         * A boolean value that specifies if a scaling schedule can influence autoscaler recommendations. If set to true, then a scaling schedule has no effect.
         */
        disabled?: boolean;
        /**
         * The duration of time intervals (in seconds) for which this scaling schedule will be running. The minimum allowed value is 300.
         */
        durationSec: number;
        /**
         * Minimum number of VM instances that autoscaler will recommend in time intervals starting according to schedule.
         */
        minRequiredReplicas: number;
        /**
         * The identifier for this object. Format specified above.
         */
        name: string;
        /**
         * The start timestamps of time intervals when this scaling schedule should provide a scaling signal. This field uses the extended cron format (with an optional year field).
         */
        schedule: string;
        /**
         * The time zone to be used when interpreting the schedule. The value of this field must be a time zone name from the tz database: http://en.wikipedia.org/wiki/Tz_database.
         */
        timeZone?: string;
    }

    export interface AutoscalerAutoscalingPolicy {
        /**
         * The number of seconds that the autoscaler should wait before it
         * starts collecting information from a new instance. This prevents
         * the autoscaler from collecting information when the instance is
         * initializing, during which the collected usage would not be
         * reliable. The default time autoscaler waits is 60 seconds.
         * Virtual machine initialization times might vary because of
         * numerous factors. We recommend that you test how long an
         * instance may take to initialize. To do this, create an instance
         * and time the startup process.
         */
        cooldownPeriod?: number;
        /**
         * Defines the CPU utilization policy that allows the autoscaler to
         * scale based on the average CPU utilization of a managed instance
         * group.
         * Structure is documented below.
         */
        cpuUtilization: outputs.compute.AutoscalerAutoscalingPolicyCpuUtilization;
        /**
         * Configuration parameters of autoscaling based on a load balancer.
         * Structure is documented below.
         */
        loadBalancingUtilization?: outputs.compute.AutoscalerAutoscalingPolicyLoadBalancingUtilization;
        /**
         * The maximum number of instances that the autoscaler can scale up
         * to. This is required when creating or updating an autoscaler. The
         * maximum number of replicas should not be lower than minimal number
         * of replicas.
         */
        maxReplicas: number;
        /**
         * Configuration parameters of autoscaling based on a custom metric.
         * Structure is documented below.
         */
        metrics?: outputs.compute.AutoscalerAutoscalingPolicyMetric[];
        /**
         * The minimum number of replicas that the autoscaler can scale down
         * to. This cannot be less than 0. If not provided, autoscaler will
         * choose a default value depending on maximum number of instances
         * allowed.
         */
        minReplicas: number;
        /**
         * Defines operating mode for this policy.
         * Default value is `ON`.
         * Possible values are `OFF`, `ONLY_UP`, and `ON`.
         */
        mode?: string;
        /**
         * Defines scale down controls to reduce the risk of response latency
         * and outages due to abrupt scale-in events
         * Structure is documented below.
         */
        scaleDownControl: outputs.compute.AutoscalerAutoscalingPolicyScaleDownControl;
        /**
         * Defines scale in controls to reduce the risk of response latency
         * and outages due to abrupt scale-in events
         * Structure is documented below.
         */
        scaleInControl?: outputs.compute.AutoscalerAutoscalingPolicyScaleInControl;
        /**
         * Scaling schedules defined for an autoscaler. Multiple schedules can be set on an autoscaler and they can overlap.
         * Structure is documented below.
         */
        scalingSchedules?: outputs.compute.AutoscalerAutoscalingPolicyScalingSchedule[];
    }

    export interface AutoscalerAutoscalingPolicyCpuUtilization {
        /**
         * Indicates whether predictive autoscaling based on CPU metric is enabled. Valid values are:
         * - NONE (default). No predictive method is used. The autoscaler scales the group to meet current demand based on real-time metrics.
         * - OPTIMIZE_AVAILABILITY. Predictive autoscaling improves availability by monitoring daily and weekly load patterns and scaling out ahead of anticipated demand.
         */
        predictiveMethod?: string;
        /**
         * Fraction of backend capacity utilization (set in HTTP(s) load
         * balancing configuration) that autoscaler should maintain. Must
         * be a positive float value. If not defined, the default is 0.8.
         */
        target: number;
    }

    export interface AutoscalerAutoscalingPolicyLoadBalancingUtilization {
        /**
         * Fraction of backend capacity utilization (set in HTTP(s) load
         * balancing configuration) that autoscaler should maintain. Must
         * be a positive float value. If not defined, the default is 0.8.
         */
        target: number;
    }

    export interface AutoscalerAutoscalingPolicyMetric {
        /**
         * A filter string to be used as the filter string for
         * a Stackdriver Monitoring TimeSeries.list API call.
         * This filter is used to select a specific TimeSeries for
         * the purpose of autoscaling and to determine whether the metric
         * is exporting per-instance or per-group data.
         * You can only use the AND operator for joining selectors.
         * You can only use direct equality comparison operator (=) without
         * any functions for each selector.
         * You can specify the metric in both the filter string and in the
         * metric field. However, if specified in both places, the metric must
         * be identical.
         * The monitored resource type determines what kind of values are
         * expected for the metric. If it is a gce_instance, the autoscaler
         * expects the metric to include a separate TimeSeries for each
         * instance in a group. In such a case, you cannot filter on resource
         * labels.
         * If the resource type is any other value, the autoscaler expects
         * this metric to contain values that apply to the entire autoscaled
         * instance group and resource label filtering can be performed to
         * point autoscaler at the correct TimeSeries to scale upon.
         * This is called a per-group metric for the purpose of autoscaling.
         * If not specified, the type defaults to gce_instance.
         * You should provide a filter that is selective enough to pick just
         * one TimeSeries for the autoscaled group or for each of the instances
         * (if you are using gceInstance resource type). If multiple
         * TimeSeries are returned upon the query execution, the autoscaler
         * will sum their respective values to obtain its scaling value.
         */
        filter?: string;
        /**
         * The identifier for this object. Format specified above.
         */
        name: string;
        /**
         * If scaling is based on a per-group metric value that represents the
         * total amount of work to be done or resource usage, set this value to
         * an amount assigned for a single instance of the scaled group.
         * The autoscaler will keep the number of instances proportional to the
         * value of this metric, the metric itself should not change value due
         * to group resizing.
         * For example, a good metric to use with the target is
         * `pubsub.googleapis.com/subscription/num_undelivered_messages`
         * or a custom metric exporting the total number of requests coming to
         * your instances.
         * A bad example would be a metric exporting an average or median
         * latency, since this value can't include a chunk assignable to a
         * single instance, it could be better used with utilizationTarget
         * instead.
         */
        singleInstanceAssignment?: number;
        /**
         * Fraction of backend capacity utilization (set in HTTP(s) load
         * balancing configuration) that autoscaler should maintain. Must
         * be a positive float value. If not defined, the default is 0.8.
         */
        target?: number;
        /**
         * Defines how target utilization value is expressed for a
         * Stackdriver Monitoring metric.
         * Possible values are `GAUGE`, `DELTA_PER_SECOND`, and `DELTA_PER_MINUTE`.
         */
        type?: string;
    }

    export interface AutoscalerAutoscalingPolicyScaleDownControl {
        /**
         * A nested object resource
         * Structure is documented below.
         */
        maxScaledDownReplicas?: outputs.compute.AutoscalerAutoscalingPolicyScaleDownControlMaxScaledDownReplicas;
        /**
         * How long back autoscaling should look when computing recommendations
         * to include directives regarding slower scale down, as described above.
         */
        timeWindowSec?: number;
    }

    export interface AutoscalerAutoscalingPolicyScaleDownControlMaxScaledDownReplicas {
        /**
         * Specifies a fixed number of VM instances. This must be a positive
         * integer.
         */
        fixed?: number;
        /**
         * Specifies a percentage of instances between 0 to 100%, inclusive.
         * For example, specify 80 for 80%.
         */
        percent?: number;
    }

    export interface AutoscalerAutoscalingPolicyScaleInControl {
        /**
         * A nested object resource
         * Structure is documented below.
         */
        maxScaledInReplicas?: outputs.compute.AutoscalerAutoscalingPolicyScaleInControlMaxScaledInReplicas;
        /**
         * How long back autoscaling should look when computing recommendations
         * to include directives regarding slower scale down, as described above.
         */
        timeWindowSec?: number;
    }

    export interface AutoscalerAutoscalingPolicyScaleInControlMaxScaledInReplicas {
        /**
         * Specifies a fixed number of VM instances. This must be a positive
         * integer.
         */
        fixed?: number;
        /**
         * Specifies a percentage of instances between 0 to 100%, inclusive.
         * For example, specify 80 for 80%.
         */
        percent?: number;
    }

    export interface AutoscalerAutoscalingPolicyScalingSchedule {
        /**
         * An optional description of this resource.
         */
        description?: string;
        /**
         * A boolean value that specifies if a scaling schedule can influence autoscaler recommendations. If set to true, then a scaling schedule has no effect.
         */
        disabled?: boolean;
        /**
         * The duration of time intervals (in seconds) for which this scaling schedule will be running. The minimum allowed value is 300.
         */
        durationSec: number;
        /**
         * Minimum number of VM instances that autoscaler will recommend in time intervals starting according to schedule.
         */
        minRequiredReplicas: number;
        /**
         * The identifier for this object. Format specified above.
         */
        name: string;
        /**
         * The start timestamps of time intervals when this scaling schedule should provide a scaling signal. This field uses the extended cron format (with an optional year field).
         */
        schedule: string;
        /**
         * The time zone to be used when interpreting the schedule. The value of this field must be a time zone name from the tz database: http://en.wikipedia.org/wiki/Tz_database.
         */
        timeZone?: string;
    }

    export interface BackendBucketCdnPolicy {
        /**
         * Specifies the cache setting for all responses from this backend.
         * The possible values are: USE_ORIGIN_HEADERS, FORCE_CACHE_ALL and CACHE_ALL_STATIC
         * Possible values are `USE_ORIGIN_HEADERS`, `FORCE_CACHE_ALL`, and `CACHE_ALL_STATIC`.
         */
        cacheMode: string;
        /**
         * Specifies the maximum allowed TTL for cached content served by this origin.
         */
        clientTtl: number;
        /**
         * Specifies the default TTL for cached content served by this origin for responses
         * that do not have an existing valid TTL (max-age or s-max-age).
         */
        defaultTtl: number;
        /**
         * Specifies the maximum allowed TTL for cached content served by this origin.
         */
        maxTtl: number;
        /**
         * Negative caching allows per-status code TTLs to be set, in order to apply fine-grained caching for common errors or redirects.
         */
        negativeCaching: boolean;
        /**
         * Sets a cache TTL for the specified HTTP status code. negativeCaching must be enabled to configure negativeCachingPolicy.
         * Omitting the policy and leaving negativeCaching enabled will use Cloud CDN's default cache TTLs.
         * Structure is documented below.
         */
        negativeCachingPolicies?: outputs.compute.BackendBucketCdnPolicyNegativeCachingPolicy[];
        /**
         * Serve existing content from the cache (if available) when revalidating content with the origin, or when an error is encountered when refreshing the cache.
         */
        serveWhileStale: number;
        /**
         * Maximum number of seconds the response to a signed URL request will
         * be considered fresh. After this time period,
         * the response will be revalidated before being served.
         * When serving responses to signed URL requests,
         * Cloud CDN will internally behave as though
         * all responses from this backend had a "Cache-Control: public,
         * max-age=[TTL]" header, regardless of any existing Cache-Control
         * header. The actual headers served in responses will not be altered.
         */
        signedUrlCacheMaxAgeSec?: number;
    }

    export interface BackendBucketCdnPolicyNegativeCachingPolicy {
        /**
         * The HTTP status code to define a TTL against. Only HTTP status codes 300, 301, 308, 404, 405, 410, 421, 451 and 501
         * can be specified as values, and you cannot specify a status code more than once.
         */
        code?: number;
        /**
         * The TTL (in seconds) for which to cache responses with the corresponding status code. The maximum allowed value is 1800s
         * (30 minutes), noting that infrequently accessed objects may be evicted from the cache before the defined TTL.
         */
        ttl?: number;
    }

    export interface BackendServiceBackend {
        /**
         * Specifies the balancing mode for this backend.
         * For global HTTP(S) or TCP/SSL load balancing, the default is
         * UTILIZATION. Valid values are UTILIZATION, RATE (for HTTP(S))
         * and CONNECTION (for TCP/SSL).
         * Default value is `UTILIZATION`.
         * Possible values are `UTILIZATION`, `RATE`, and `CONNECTION`.
         */
        balancingMode?: string;
        /**
         * A multiplier applied to the group's maximum servicing capacity
         * (based on UTILIZATION, RATE or CONNECTION).
         * Default value is 1, which means the group will serve up to 100%
         * of its configured capacity (depending on balancingMode). A
         * setting of 0 means the group is completely drained, offering
         * 0% of its available Capacity. Valid range is [0.0,1.0].
         */
        capacityScaler?: number;
        /**
         * An optional description of this resource.
         * Provide this property when you create the resource.
         */
        description?: string;
        /**
         * The fully-qualified URL of an Instance Group or Network Endpoint
         * Group resource. In case of instance group this defines the list
         * of instances that serve traffic. Member virtual machine
         * instances from each instance group must live in the same zone as
         * the instance group itself. No two backends in a backend service
         * are allowed to use same Instance Group resource.
         * For Network Endpoint Groups this defines list of endpoints. All
         * endpoints of Network Endpoint Group must be hosted on instances
         * located in the same zone as the Network Endpoint Group.
         * Backend services cannot mix Instance Group and
         * Network Endpoint Group backends.
         * Note that you must specify an Instance Group or Network Endpoint
         * Group resource using the fully-qualified URL, rather than a
         * partial URL.
         */
        group: string;
        /**
         * The maximum number of connections to the backend cluster.
         * Defaults to 1024.
         */
        maxConnections: number;
        /**
         * The max number of simultaneous connections that a single backend
         * network endpoint can handle. This is used to calculate the
         * capacity of the group. Can be used in either CONNECTION or
         * UTILIZATION balancing modes.
         * For CONNECTION mode, either
         * maxConnections or maxConnectionsPerEndpoint must be set.
         */
        maxConnectionsPerEndpoint: number;
        /**
         * The max number of simultaneous connections that a single
         * backend instance can handle. This is used to calculate the
         * capacity of the group. Can be used in either CONNECTION or
         * UTILIZATION balancing modes.
         * For CONNECTION mode, either maxConnections or
         * maxConnectionsPerInstance must be set.
         */
        maxConnectionsPerInstance: number;
        /**
         * The max requests per second (RPS) of the group.
         * Can be used with either RATE or UTILIZATION balancing modes,
         * but required if RATE mode. For RATE mode, either maxRate or one
         * of maxRatePerInstance or maxRatePerEndpoint, as appropriate for
         * group type, must be set.
         */
        maxRate: number;
        /**
         * The max requests per second (RPS) that a single backend network
         * endpoint can handle. This is used to calculate the capacity of
         * the group. Can be used in either balancing mode. For RATE mode,
         * either maxRate or maxRatePerEndpoint must be set.
         */
        maxRatePerEndpoint: number;
        /**
         * The max requests per second (RPS) that a single backend
         * instance can handle. This is used to calculate the capacity of
         * the group. Can be used in either balancing mode. For RATE mode,
         * either maxRate or maxRatePerInstance must be set.
         */
        maxRatePerInstance: number;
        /**
         * Used when balancingMode is UTILIZATION. This ratio defines the
         * CPU utilization target for the group. Valid range is [0.0, 1.0].
         */
        maxUtilization: number;
    }

    export interface BackendServiceCdnPolicy {
        /**
         * The CacheKeyPolicy for this CdnPolicy.
         * Structure is documented below.
         */
        cacheKeyPolicy?: outputs.compute.BackendServiceCdnPolicyCacheKeyPolicy;
        /**
         * Specifies the cache setting for all responses from this backend.
         * The possible values are: USE_ORIGIN_HEADERS, FORCE_CACHE_ALL and CACHE_ALL_STATIC
         * Possible values are `USE_ORIGIN_HEADERS`, `FORCE_CACHE_ALL`, and `CACHE_ALL_STATIC`.
         */
        cacheMode: string;
        /**
         * Specifies the maximum allowed TTL for cached content served by this origin.
         */
        clientTtl: number;
        /**
         * Specifies the default TTL for cached content served by this origin for responses
         * that do not have an existing valid TTL (max-age or s-max-age).
         */
        defaultTtl: number;
        /**
         * Specifies the maximum allowed TTL for cached content served by this origin.
         */
        maxTtl: number;
        /**
         * Negative caching allows per-status code TTLs to be set, in order to apply fine-grained caching for common errors or redirects.
         */
        negativeCaching: boolean;
        /**
         * Sets a cache TTL for the specified HTTP status code. negativeCaching must be enabled to configure negativeCachingPolicy.
         * Omitting the policy and leaving negativeCaching enabled will use Cloud CDN's default cache TTLs.
         * Structure is documented below.
         */
        negativeCachingPolicies?: outputs.compute.BackendServiceCdnPolicyNegativeCachingPolicy[];
        /**
         * Serve existing content from the cache (if available) when revalidating content with the origin, or when an error is encountered when refreshing the cache.
         */
        serveWhileStale: number;
        /**
         * Maximum number of seconds the response to a signed URL request
         * will be considered fresh, defaults to 1hr (3600s). After this
         * time period, the response will be revalidated before
         * being served.
         * When serving responses to signed URL requests, Cloud CDN will
         * internally behave as though all responses from this backend had a
         * "Cache-Control: public, max-age=[TTL]" header, regardless of any
         * existing Cache-Control header. The actual headers served in
         * responses will not be altered.
         */
        signedUrlCacheMaxAgeSec?: number;
    }

    export interface BackendServiceCdnPolicyCacheKeyPolicy {
        /**
         * If true requests to different hosts will be cached separately.
         */
        includeHost?: boolean;
        /**
         * If true, http and https requests will be cached separately.
         */
        includeProtocol?: boolean;
        /**
         * If true, include query string parameters in the cache key
         * according to queryStringWhitelist and
         * query_string_blacklist. If neither is set, the entire query
         * string will be included.
         * If false, the query string will be excluded from the cache
         * key entirely.
         */
        includeQueryString?: boolean;
        /**
         * Names of query string parameters to exclude in cache keys.
         * All other parameters will be included. Either specify
         * queryStringWhitelist or query_string_blacklist, not both.
         * '&' and '=' will be percent encoded and not treated as
         * delimiters.
         */
        queryStringBlacklists?: string[];
        /**
         * Names of query string parameters to include in cache keys.
         * All other parameters will be excluded. Either specify
         * queryStringWhitelist or query_string_blacklist, not both.
         * '&' and '=' will be percent encoded and not treated as
         * delimiters.
         */
        queryStringWhitelists?: string[];
    }

    export interface BackendServiceCdnPolicyNegativeCachingPolicy {
        /**
         * The HTTP status code to define a TTL against. Only HTTP status codes 300, 301, 308, 404, 405, 410, 421, 451 and 501
         * can be specified as values, and you cannot specify a status code more than once.
         */
        code?: number;
        /**
         * The TTL (in seconds) for which to cache responses with the corresponding status code. The maximum allowed value is 1800s
         * (30 minutes), noting that infrequently accessed objects may be evicted from the cache before the defined TTL.
         */
        ttl?: number;
    }

    export interface BackendServiceCircuitBreakers {
        /**
         * The timeout for new network connections to hosts.
         * Structure is documented below.
         */
        connectTimeout?: outputs.compute.BackendServiceCircuitBreakersConnectTimeout;
        /**
         * The maximum number of connections to the backend cluster.
         * Defaults to 1024.
         */
        maxConnections?: number;
        /**
         * The maximum number of pending requests to the backend cluster.
         * Defaults to 1024.
         */
        maxPendingRequests?: number;
        /**
         * The maximum number of parallel requests to the backend cluster.
         * Defaults to 1024.
         */
        maxRequests?: number;
        /**
         * Maximum requests for a single backend connection. This parameter
         * is respected by both the HTTP/1.1 and HTTP/2 implementations. If
         * not specified, there is no limit. Setting this parameter to 1
         * will effectively disable keep alive.
         */
        maxRequestsPerConnection?: number;
        /**
         * The maximum number of parallel retries to the backend cluster.
         * Defaults to 3.
         */
        maxRetries?: number;
    }

    export interface BackendServiceCircuitBreakersConnectTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: number;
    }

    export interface BackendServiceConsistentHash {
        /**
         * Hash is based on HTTP Cookie. This field describes a HTTP cookie
         * that will be used as the hash key for the consistent hash load
         * balancer. If the cookie is not present, it will be generated.
         * This field is applicable if the sessionAffinity is set to HTTP_COOKIE.
         * Structure is documented below.
         */
        httpCookie?: outputs.compute.BackendServiceConsistentHashHttpCookie;
        /**
         * The hash based on the value of the specified header field.
         * This field is applicable if the sessionAffinity is set to HEADER_FIELD.
         */
        httpHeaderName?: string;
        /**
         * The minimum number of virtual nodes to use for the hash ring.
         * Larger ring sizes result in more granular load
         * distributions. If the number of hosts in the load balancing pool
         * is larger than the ring size, each host will be assigned a single
         * virtual node.
         * Defaults to 1024.
         */
        minimumRingSize?: number;
    }

    export interface BackendServiceConsistentHashHttpCookie {
        /**
         * Name of the cookie.
         */
        name?: string;
        /**
         * Path to set for the cookie.
         */
        path?: string;
        /**
         * The TTL (in seconds) for which to cache responses with the corresponding status code. The maximum allowed value is 1800s
         * (30 minutes), noting that infrequently accessed objects may be evicted from the cache before the defined TTL.
         */
        ttl?: outputs.compute.BackendServiceConsistentHashHttpCookieTtl;
    }

    export interface BackendServiceConsistentHashHttpCookieTtl {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: number;
    }

    export interface BackendServiceIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface BackendServiceIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface BackendServiceIap {
        /**
         * OAuth2 Client ID for IAP
         */
        oauth2ClientId: string;
        /**
         * OAuth2 Client Secret for IAP
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        oauth2ClientSecret: string;
        /**
         * -
         * OAuth2 Client Secret SHA-256 for IAP
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        oauth2ClientSecretSha256: string;
    }

    export interface BackendServiceLogConfig {
        /**
         * Whether to enable logging for the load balancer traffic served by this backend service.
         */
        enable?: boolean;
        /**
         * This field can only be specified if logging is enabled for this backend service. The value of
         * the field must be in [0, 1]. This configures the sampling rate of requests to the load balancer
         * where 1.0 means all logged requests are reported and 0.0 means no logged requests are reported.
         * The default value is 1.0.
         */
        sampleRate?: number;
    }

    export interface BackendServiceOutlierDetection {
        /**
         * The base time that a host is ejected for. The real time is equal to the base
         * time multiplied by the number of times the host has been ejected. Defaults to
         * 30000ms or 30s.
         * Structure is documented below.
         */
        baseEjectionTime?: outputs.compute.BackendServiceOutlierDetectionBaseEjectionTime;
        /**
         * Number of errors before a host is ejected from the connection pool. When the
         * backend host is accessed over HTTP, a 5xx return code qualifies as an error.
         * Defaults to 5.
         */
        consecutiveErrors?: number;
        /**
         * The number of consecutive gateway failures (502, 503, 504 status or connection
         * errors that are mapped to one of those status codes) before a consecutive
         * gateway failure ejection occurs. Defaults to 5.
         */
        consecutiveGatewayFailure?: number;
        /**
         * The percentage chance that a host will be actually ejected when an outlier
         * status is detected through consecutive 5xx. This setting can be used to disable
         * ejection or to ramp it up slowly. Defaults to 100.
         */
        enforcingConsecutiveErrors?: number;
        /**
         * The percentage chance that a host will be actually ejected when an outlier
         * status is detected through consecutive gateway failures. This setting can be
         * used to disable ejection or to ramp it up slowly. Defaults to 0.
         */
        enforcingConsecutiveGatewayFailure?: number;
        /**
         * The percentage chance that a host will be actually ejected when an outlier
         * status is detected through success rate statistics. This setting can be used to
         * disable ejection or to ramp it up slowly. Defaults to 100.
         */
        enforcingSuccessRate?: number;
        /**
         * Time interval between ejection sweep analysis. This can result in both new
         * ejections as well as hosts being returned to service. Defaults to 10 seconds.
         * Structure is documented below.
         */
        interval?: outputs.compute.BackendServiceOutlierDetectionInterval;
        /**
         * Maximum percentage of hosts in the load balancing pool for the backend service
         * that can be ejected. Defaults to 10%.
         */
        maxEjectionPercent?: number;
        /**
         * The number of hosts in a cluster that must have enough request volume to detect
         * success rate outliers. If the number of hosts is less than this setting, outlier
         * detection via success rate statistics is not performed for any host in the
         * cluster. Defaults to 5.
         */
        successRateMinimumHosts?: number;
        /**
         * The minimum number of total requests that must be collected in one interval (as
         * defined by the interval duration above) to include this host in success rate
         * based outlier detection. If the volume is lower than this setting, outlier
         * detection via success rate statistics is not performed for that host. Defaults
         * to 100.
         */
        successRateRequestVolume?: number;
        /**
         * This factor is used to determine the ejection threshold for success rate outlier
         * ejection. The ejection threshold is the difference between the mean success
         * rate, and the product of this factor and the standard deviation of the mean
         * success rate: mean - (stdev * success_rate_stdev_factor). This factor is divided
         * by a thousand to get a double. That is, if the desired factor is 1.9, the
         * runtime value should be 1900. Defaults to 1900.
         */
        successRateStdevFactor?: number;
    }

    export interface BackendServiceOutlierDetectionBaseEjectionTime {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: number;
    }

    export interface BackendServiceOutlierDetectionInterval {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: number;
    }

    export interface BackendServiceSecuritySettings {
        /**
         * ClientTlsPolicy is a resource that specifies how a client should authenticate
         * connections to backends of a service. This resource itself does not affect
         * configuration unless it is attached to a backend service resource.
         */
        clientTlsPolicy: string;
        /**
         * A list of alternate names to verify the subject identity in the certificate.
         * If specified, the client will verify that the server certificate's subject
         * alt name matches one of the specified values.
         */
        subjectAltNames: string[];
    }

    export interface DiskDiskEncryptionKey {
        /**
         * The self link of the encryption key used to encrypt the disk. Also called KmsKeyName
         * in the cloud console. Your project's Compute Engine System service account
         * (`service-{{PROJECT_NUMBER}}@compute-system.iam.gserviceaccount.com`) must have
         * `roles/cloudkms.cryptoKeyEncrypterDecrypter` to use this feature.
         * See https://cloud.google.com/compute/docs/disks/customer-managed-encryption#encrypt_a_new_persistent_disk_with_your_own_keys
         */
        kmsKeySelfLink?: string;
        /**
         * The service account used for the encryption request for the given KMS key.
         * If absent, the Compute Engine Service Agent service account is used.
         */
        kmsKeyServiceAccount?: string;
        /**
         * Specifies a 256-bit customer-supplied encryption key, encoded in
         * RFC 4648 base64 to either encrypt or decrypt this resource.
         */
        rawKey?: string;
        /**
         * -
         * The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied
         * encryption key that protects this resource.
         */
        sha256: string;
    }

    export interface DiskIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface DiskIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface DiskSourceImageEncryptionKey {
        /**
         * The self link of the encryption key used to encrypt the disk. Also called KmsKeyName
         * in the cloud console. Your project's Compute Engine System service account
         * (`service-{{PROJECT_NUMBER}}@compute-system.iam.gserviceaccount.com`) must have
         * `roles/cloudkms.cryptoKeyEncrypterDecrypter` to use this feature.
         * See https://cloud.google.com/compute/docs/disks/customer-managed-encryption#encrypt_a_new_persistent_disk_with_your_own_keys
         */
        kmsKeySelfLink?: string;
        /**
         * The service account used for the encryption request for the given KMS key.
         * If absent, the Compute Engine Service Agent service account is used.
         */
        kmsKeyServiceAccount?: string;
        /**
         * Specifies a 256-bit customer-supplied encryption key, encoded in
         * RFC 4648 base64 to either encrypt or decrypt this resource.
         */
        rawKey?: string;
        /**
         * -
         * The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied
         * encryption key that protects this resource.
         */
        sha256: string;
    }

    export interface DiskSourceSnapshotEncryptionKey {
        /**
         * The self link of the encryption key used to encrypt the disk. Also called KmsKeyName
         * in the cloud console. Your project's Compute Engine System service account
         * (`service-{{PROJECT_NUMBER}}@compute-system.iam.gserviceaccount.com`) must have
         * `roles/cloudkms.cryptoKeyEncrypterDecrypter` to use this feature.
         * See https://cloud.google.com/compute/docs/disks/customer-managed-encryption#encrypt_a_new_persistent_disk_with_your_own_keys
         */
        kmsKeySelfLink?: string;
        /**
         * The service account used for the encryption request for the given KMS key.
         * If absent, the Compute Engine Service Agent service account is used.
         */
        kmsKeyServiceAccount?: string;
        /**
         * Specifies a 256-bit customer-supplied encryption key, encoded in
         * RFC 4648 base64 to either encrypt or decrypt this resource.
         */
        rawKey?: string;
        /**
         * -
         * The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied
         * encryption key that protects this resource.
         */
        sha256: string;
    }

    export interface ExternalVpnGatewayInterface {
        /**
         * The numeric ID for this interface. Allowed values are based on the redundancy type
         * of this external VPN gateway
         * * `0 - SINGLE_IP_INTERNALLY_REDUNDANT`
         * * `0, 1 - TWO_IPS_REDUNDANCY`
         * * `0, 1, 2, 3 - FOUR_IPS_REDUNDANCY`
         */
        id?: number;
        /**
         * IP address of the interface in the external VPN gateway.
         * Only IPv4 is supported. This IP address can be either from
         * your on-premise gateway or another Cloud provider's VPN gateway,
         * it cannot be an IP address from Google Compute Engine.
         */
        ipAddress?: string;
    }

    export interface FirewallAllow {
        /**
         * An optional list of ports to which this rule applies. This field
         * is only applicable for UDP or TCP protocol. Each entry must be
         * either an integer or a range. If not specified, this rule
         * applies to connections through any port.
         * Example inputs include: ["22"], ["80","443"], and
         * ["12345-12349"].
         */
        ports?: string[];
        /**
         * The IP protocol to which this rule applies. The protocol type is
         * required when creating a firewall rule. This value can either be
         * one of the following well known protocol strings (tcp, udp,
         * icmp, esp, ah, sctp, ipip, all), or the IP protocol number.
         */
        protocol: string;
    }

    export interface FirewallDeny {
        /**
         * An optional list of ports to which this rule applies. This field
         * is only applicable for UDP or TCP protocol. Each entry must be
         * either an integer or a range. If not specified, this rule
         * applies to connections through any port.
         * Example inputs include: ["22"], ["80","443"], and
         * ["12345-12349"].
         */
        ports?: string[];
        /**
         * The IP protocol to which this rule applies. The protocol type is
         * required when creating a firewall rule. This value can either be
         * one of the following well known protocol strings (tcp, udp,
         * icmp, esp, ah, sctp, ipip, all), or the IP protocol number.
         */
        protocol: string;
    }

    export interface FirewallLogConfig {
        /**
         * This field denotes whether to include or exclude metadata for firewall logs.
         * Possible values are `EXCLUDE_ALL_METADATA` and `INCLUDE_ALL_METADATA`.
         */
        metadata: string;
    }

    export interface FirewallPolicyRuleMatch {
        /**
         * CIDR IP address range. Maximum number of destination CIDR IP ranges allowed is 256.
         */
        destIpRanges?: string[];
        /**
         * Pairs of IP protocols and ports that the rule should match. Structure is documented below.
         */
        layer4Configs: outputs.compute.FirewallPolicyRuleMatchLayer4Config[];
        /**
         * CIDR IP address range. Maximum number of source CIDR IP ranges allowed is 256.
         */
        srcIpRanges?: string[];
    }

    export interface FirewallPolicyRuleMatchLayer4Config {
        /**
         * The IP protocol to which this rule applies. The protocol type is required when creating a firewall rule. This value can either be one of the following well known protocol strings (`tcp`, `udp`, `icmp`, `esp`, `ah`, `ipip`, `sctp`), or the IP protocol number.
         */
        ipProtocol: string;
        /**
         * An optional list of ports to which this rule applies. This field is only applicable for UDP or TCP protocol. Each entry must be either an integer or a range. If not specified, this rule applies to connections through any port. Example inputs include: ``.
         */
        ports?: string[];
    }

    export interface ForwardingRuleServiceDirectoryRegistration {
        /**
         * Service Directory namespace to register the forwarding rule under.
         */
        namespace: string;
        /**
         * Service Directory service to register the forwarding rule under.
         */
        service?: string;
    }

    export interface GetBackendBucketCdnPolicy {
        cacheMode: string;
        clientTtl: number;
        defaultTtl: number;
        maxTtl: number;
        negativeCaching: boolean;
        negativeCachingPolicies: outputs.compute.GetBackendBucketCdnPolicyNegativeCachingPolicy[];
        serveWhileStale: number;
        signedUrlCacheMaxAgeSec: number;
    }

    export interface GetBackendBucketCdnPolicyNegativeCachingPolicy {
        code: number;
        ttl: number;
    }

    export interface GetBackendServiceBackend {
        balancingMode: string;
        capacityScaler: number;
        /**
         * Textual description for the Backend Service.
         */
        description: string;
        group: string;
        maxConnections: number;
        maxConnectionsPerEndpoint: number;
        maxConnectionsPerInstance: number;
        maxRate: number;
        maxRatePerEndpoint: number;
        maxRatePerInstance: number;
        maxUtilization: number;
    }

    export interface GetBackendServiceCdnPolicy {
        cacheKeyPolicies: outputs.compute.GetBackendServiceCdnPolicyCacheKeyPolicy[];
        cacheMode: string;
        clientTtl: number;
        defaultTtl: number;
        maxTtl: number;
        negativeCaching: boolean;
        negativeCachingPolicies: outputs.compute.GetBackendServiceCdnPolicyNegativeCachingPolicy[];
        serveWhileStale: number;
        signedUrlCacheMaxAgeSec: number;
    }

    export interface GetBackendServiceCdnPolicyCacheKeyPolicy {
        includeHost: boolean;
        includeProtocol: boolean;
        includeQueryString: boolean;
        queryStringBlacklists: string[];
        queryStringWhitelists: string[];
    }

    export interface GetBackendServiceCdnPolicyNegativeCachingPolicy {
        code: number;
        ttl: number;
    }

    export interface GetBackendServiceCircuitBreaker {
        connectTimeouts: outputs.compute.GetBackendServiceCircuitBreakerConnectTimeout[];
        maxConnections: number;
        maxPendingRequests: number;
        maxRequests: number;
        maxRequestsPerConnection: number;
        maxRetries: number;
    }

    export interface GetBackendServiceCircuitBreakerConnectTimeout {
        nanos: number;
        seconds: number;
    }

    export interface GetBackendServiceConsistentHash {
        httpCookies: outputs.compute.GetBackendServiceConsistentHashHttpCooky[];
        httpHeaderName: string;
        minimumRingSize: number;
    }

    export interface GetBackendServiceConsistentHashHttpCooky {
        /**
         * The name of the Backend Service.
         */
        name: string;
        path: string;
        ttls: outputs.compute.GetBackendServiceConsistentHashHttpCookyTtl[];
    }

    export interface GetBackendServiceConsistentHashHttpCookyTtl {
        nanos: number;
        seconds: number;
    }

    export interface GetBackendServiceIap {
        oauth2ClientId: string;
        oauth2ClientSecret: string;
        oauth2ClientSecretSha256: string;
    }

    export interface GetBackendServiceLogConfig {
        enable: boolean;
        sampleRate: number;
    }

    export interface GetBackendServiceOutlierDetection {
        baseEjectionTimes: outputs.compute.GetBackendServiceOutlierDetectionBaseEjectionTime[];
        consecutiveErrors: number;
        consecutiveGatewayFailure: number;
        enforcingConsecutiveErrors: number;
        enforcingConsecutiveGatewayFailure: number;
        enforcingSuccessRate: number;
        intervals: outputs.compute.GetBackendServiceOutlierDetectionInterval[];
        maxEjectionPercent: number;
        successRateMinimumHosts: number;
        successRateRequestVolume: number;
        successRateStdevFactor: number;
    }

    export interface GetBackendServiceOutlierDetectionBaseEjectionTime {
        nanos: number;
        seconds: number;
    }

    export interface GetBackendServiceOutlierDetectionInterval {
        nanos: number;
        seconds: number;
    }

    export interface GetBackendServiceSecuritySetting {
        clientTlsPolicy: string;
        subjectAltNames: string[];
    }

    export interface GetDiskDiskEncryptionKey {
        kmsKeySelfLink: string;
        kmsKeyServiceAccount: string;
        rawKey: string;
        sha256: string;
    }

    export interface GetDiskSourceImageEncryptionKey {
        kmsKeySelfLink: string;
        kmsKeyServiceAccount: string;
        rawKey: string;
        sha256: string;
    }

    export interface GetDiskSourceSnapshotEncryptionKey {
        kmsKeySelfLink: string;
        kmsKeyServiceAccount: string;
        rawKey: string;
        sha256: string;
    }

    export interface GetForwardingRuleServiceDirectoryRegistration {
        namespace: string;
        service: string;
    }

    export interface GetGlobalForwardingRuleMetadataFilter {
        filterLabels: outputs.compute.GetGlobalForwardingRuleMetadataFilterFilterLabel[];
        filterMatchCriteria: string;
    }

    export interface GetGlobalForwardingRuleMetadataFilterFilterLabel {
        /**
         * The name of the global forwarding rule.
         */
        name: string;
        value: string;
    }

    export interface GetHcVpnGatewayVpnInterface {
        id: number;
        interconnectAttachment: string;
        ipAddress: string;
    }

    export interface GetHealthCheckGrpcHealthCheck {
        grpcServiceName: string;
        port: number;
        portName: string;
        portSpecification: string;
    }

    export interface GetHealthCheckHttp2HealthCheck {
        host: string;
        port: number;
        portName: string;
        portSpecification: string;
        proxyHeader: string;
        requestPath: string;
        response: string;
    }

    export interface GetHealthCheckHttpHealthCheck {
        host: string;
        port: number;
        portName: string;
        portSpecification: string;
        proxyHeader: string;
        requestPath: string;
        response: string;
    }

    export interface GetHealthCheckHttpsHealthCheck {
        host: string;
        port: number;
        portName: string;
        portSpecification: string;
        proxyHeader: string;
        requestPath: string;
        response: string;
    }

    export interface GetHealthCheckLogConfig {
        enable: boolean;
    }

    export interface GetHealthCheckSslHealthCheck {
        port: number;
        portName: string;
        portSpecification: string;
        proxyHeader: string;
        request: string;
        response: string;
    }

    export interface GetHealthCheckTcpHealthCheck {
        port: number;
        portName: string;
        portSpecification: string;
        proxyHeader: string;
        request: string;
        response: string;
    }

    export interface GetInstanceAdvancedMachineFeature {
        enableNestedVirtualization: boolean;
        threadsPerCore: number;
    }

    export interface GetInstanceAttachedDisk {
        /**
         * Name with which the attached disk is accessible
         * under `/dev/disk/by-id/`
         */
        deviceName: string;
        diskEncryptionKeyRaw: string;
        diskEncryptionKeySha256: string;
        kmsKeySelfLink: string;
        /**
         * Read/write mode for the disk. One of `"READ_ONLY"` or `"READ_WRITE"`.
         */
        mode: string;
        /**
         * The name or selfLink of the disk attached to this instance.
         */
        source: string;
    }

    export interface GetInstanceBootDisk {
        /**
         * Whether the disk will be auto-deleted when the instance is deleted.
         */
        autoDelete: boolean;
        /**
         * Name with which the attached disk is accessible
         * under `/dev/disk/by-id/`
         */
        deviceName: string;
        diskEncryptionKeyRaw: string;
        diskEncryptionKeySha256: string;
        /**
         * Parameters with which a disk was created alongside the instance.
         * Structure is documented below.
         */
        initializeParams: outputs.compute.GetInstanceBootDiskInitializeParam[];
        kmsKeySelfLink: string;
        /**
         * Read/write mode for the disk. One of `"READ_ONLY"` or `"READ_WRITE"`.
         */
        mode: string;
        /**
         * The name or selfLink of the disk attached to this instance.
         */
        source: string;
    }

    export interface GetInstanceBootDiskInitializeParam {
        /**
         * The image from which this disk was initialised.
         */
        image: string;
        /**
         * A set of key/value label pairs assigned to the instance.
         */
        labels: {[key: string]: any};
        /**
         * The size of the image in gigabytes.
         */
        size: number;
        /**
         * The accelerator type resource exposed to this instance. E.g. `nvidia-tesla-k80`.
         */
        type: string;
    }

    export interface GetInstanceConfidentialInstanceConfig {
        enableConfidentialCompute: boolean;
    }

    export interface GetInstanceGroupNamedPort {
        /**
         * The name of the instance group. Either `name` or `selfLink` must be provided.
         */
        name: string;
        port: number;
    }

    export interface GetInstanceGuestAccelerator {
        /**
         * The number of the guest accelerator cards exposed to this instance.
         */
        count: number;
        /**
         * The accelerator type resource exposed to this instance. E.g. `nvidia-tesla-k80`.
         */
        type: string;
    }

    export interface GetInstanceNetworkInterface {
        /**
         * Access configurations, i.e. IPs via which this
         * instance can be accessed via the Internet. Structure documented below.
         */
        accessConfigs: outputs.compute.GetInstanceNetworkInterfaceAccessConfig[];
        /**
         * An array of alias IP ranges for this network interface. Structure documented below.
         */
        aliasIpRanges: outputs.compute.GetInstanceNetworkInterfaceAliasIpRange[];
        ipv6AccessConfigs: outputs.compute.GetInstanceNetworkInterfaceIpv6AccessConfig[];
        ipv6AccessType: string;
        /**
         * The name of the instance. One of `name` or `selfLink` must be provided.
         */
        name: string;
        /**
         * The name or selfLink of the network attached to this interface.
         */
        network: string;
        /**
         * The private IP address assigned to the instance.
         */
        networkIp: string;
        nicType: string;
        queueCount: number;
        stackType: string;
        /**
         * The name or selfLink of the subnetwork attached to this interface.
         */
        subnetwork: string;
        /**
         * The project in which the subnetwork belongs.
         */
        subnetworkProject: string;
    }

    export interface GetInstanceNetworkInterfaceAccessConfig {
        /**
         * The IP address that is be 1:1 mapped to the instance's
         * network ip.
         */
        natIp: string;
        /**
         * The [networking tier][network-tier] used for configuring this instance. One of `PREMIUM` or `STANDARD`.
         */
        networkTier: string;
        /**
         * The DNS domain name for the public PTR record.
         */
        publicPtrDomainName: string;
    }

    export interface GetInstanceNetworkInterfaceAliasIpRange {
        /**
         * The IP CIDR range represented by this alias IP range.
         */
        ipCidrRange: string;
        /**
         * The subnetwork secondary range name specifying
         * the secondary range from which to allocate the IP CIDR range for this alias IP
         * range.
         */
        subnetworkRangeName: string;
    }

    export interface GetInstanceNetworkInterfaceIpv6AccessConfig {
        externalIpv6: string;
        externalIpv6PrefixLength: string;
        /**
         * The [networking tier][network-tier] used for configuring this instance. One of `PREMIUM` or `STANDARD`.
         */
        networkTier: string;
        /**
         * The DNS domain name for the public PTR record.
         */
        publicPtrDomainName: string;
    }

    export interface GetInstanceNetworkPerformanceConfig {
        /**
         * The egress bandwidth tier for the instance.
         */
        totalEgressBandwidthTier: string;
    }

    export interface GetInstanceReservationAffinity {
        specificReservations: outputs.compute.GetInstanceReservationAffinitySpecificReservation[];
        /**
         * The accelerator type resource exposed to this instance. E.g. `nvidia-tesla-k80`.
         */
        type: string;
    }

    export interface GetInstanceReservationAffinitySpecificReservation {
        key: string;
        values: string[];
    }

    export interface GetInstanceScheduling {
        /**
         * Specifies if the instance should be
         * restarted if it was terminated by Compute Engine (not a user).
         */
        automaticRestart: boolean;
        minNodeCpus: number;
        nodeAffinities: outputs.compute.GetInstanceSchedulingNodeAffinity[];
        /**
         * Describes maintenance behavior for the
         * instance. One of `MIGRATE` or `TERMINATE`, for more info, read
         * [here](https://cloud.google.com/compute/docs/instances/setting-instance-scheduling-options)
         */
        onHostMaintenance: string;
        /**
         * Whether the instance is preemptible.
         */
        preemptible: boolean;
        /**
         * (Beta) Describe the type of preemptible VM.
         */
        provisioningModel: string;
    }

    export interface GetInstanceSchedulingNodeAffinity {
        key: string;
        operator: string;
        values: string[];
    }

    export interface GetInstanceScratchDisk {
        /**
         * The disk interface used for attaching this disk. One of `SCSI` or `NVME`.
         */
        interface: string;
    }

    export interface GetInstanceServiceAccount {
        /**
         * The service account e-mail address.
         */
        email: string;
        /**
         * A list of service scopes.
         */
        scopes: string[];
    }

    export interface GetInstanceShieldedInstanceConfig {
        enableIntegrityMonitoring: boolean;
        enableSecureBoot: boolean;
        enableVtpm: boolean;
    }

    export interface GetInstanceTemplateAdvancedMachineFeature {
        enableNestedVirtualization: boolean;
        threadsPerCore: number;
    }

    export interface GetInstanceTemplateConfidentialInstanceConfig {
        enableConfidentialCompute: boolean;
    }

    export interface GetInstanceTemplateDisk {
        /**
         * Whether or not the disk should be auto-deleted.
         * This defaults to true.
         */
        autoDelete: boolean;
        /**
         * Indicates that this is a boot disk.
         */
        boot: boolean;
        /**
         * A unique device name that is reflected into the
         * /dev/  tree of a Linux operating system running within the instance. If not
         * specified, the server chooses a default device name to apply to this disk.
         */
        deviceName: string;
        /**
         * Encrypts or decrypts a disk using a customer-supplied encryption key.
         */
        diskEncryptionKeys: outputs.compute.GetInstanceTemplateDiskDiskEncryptionKey[];
        /**
         * Name of the disk. When not provided, this defaults
         * to the name of the instance.
         */
        diskName: string;
        /**
         * The size of the image in gigabytes. If not
         * specified, it will inherit the size of its base image. For SCRATCH disks,
         * the size must be exactly 375GB.
         */
        diskSizeGb: number;
        /**
         * The GCE disk type. Such as `"pd-ssd"`, `"local-ssd"`,
         * `"pd-balanced"` or `"pd-standard"`.
         */
        diskType: string;
        /**
         * Specifies the disk interface to use for attaching this disk,
         * which is either SCSI or NVME. The default is SCSI. Persistent disks must always use SCSI
         * and the request will fail if you attempt to attach a persistent disk in any other format
         * than SCSI. Local SSDs can use either NVME or SCSI.
         */
        interface: string;
        /**
         * (Optional) A set of ket/value label pairs to assign to disk created from
         * this template
         */
        labels: {[key: string]: string};
        /**
         * The mode in which to attach this disk, either READ_WRITE
         * or READ_ONLY. If you are attaching or creating a boot disk, this must
         * read-write mode.
         */
        mode: string;
        resourcePolicies: string[];
        /**
         * The name (**not self_link**)
         * of the disk (such as those managed by `gcp.compute.Disk`) to attach.
         * > **Note:** Either `source` or `sourceImage` is **required** in a disk block unless the disk type is `local-ssd`. Check the API [docs](https://cloud.google.com/compute/docs/reference/rest/v1/instanceTemplates/insert) for details.
         */
        source: string;
        /**
         * The image from which to
         * initialize this disk. This can be one of: the image's `selfLink`,
         * `projects/{project}/global/images/{image}`,
         * `projects/{project}/global/images/family/{family}`, `global/images/{image}`,
         * `global/images/family/{family}`, `family/{family}`, `{project}/{family}`,
         * `{project}/{image}`, `{family}`, or `{image}`.
         * > **Note:** Either `source` or `sourceImage` is **required** in a disk block unless the disk type is `local-ssd`. Check the API [docs](https://cloud.google.com/compute/docs/reference/rest/v1/instanceTemplates/insert) for details.
         */
        sourceImage: string;
        /**
         * The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
         */
        type: string;
    }

    export interface GetInstanceTemplateDiskDiskEncryptionKey {
        /**
         * The self link of the encryption key that is stored in Google Cloud KMS
         */
        kmsKeySelfLink: string;
    }

    export interface GetInstanceTemplateGuestAccelerator {
        /**
         * The number of the guest accelerator cards exposed to this instance.
         */
        count: number;
        /**
         * The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
         */
        type: string;
    }

    export interface GetInstanceTemplateNetworkInterface {
        /**
         * Access configurations, i.e. IPs via which this
         * instance can be accessed via the Internet. Omit to ensure that the instance
         * is not accessible from the Internet (this means that ssh provisioners will
         * not work unless you are running the prvovider can send traffic to the instance's
         * network (e.g. via tunnel or because it is running on another cloud instance
         * on that network). This block can be repeated multiple times. Structure documented below.
         */
        accessConfigs: outputs.compute.GetInstanceTemplateNetworkInterfaceAccessConfig[];
        /**
         * An
         * array of alias IP ranges for this network interface. Can only be specified for network
         * interfaces on subnet-mode networks. Structure documented below.
         */
        aliasIpRanges: outputs.compute.GetInstanceTemplateNetworkInterfaceAliasIpRange[];
        ipv6AccessConfigs: outputs.compute.GetInstanceTemplateNetworkInterfaceIpv6AccessConfig[];
        ipv6AccessType: string;
        /**
         * The name of the instance template. One of `name` or `filter` must be provided.
         */
        name: string;
        /**
         * The name or selfLink of the network to attach this interface to.
         * Use `network` attribute for Legacy or Auto subnetted networks and
         * `subnetwork` for custom subnetted networks.
         */
        network: string;
        /**
         * The private IP address to assign to the instance. If
         * empty, the address will be automatically assigned.
         */
        networkIp: string;
        nicType: string;
        queueCount: number;
        stackType: string;
        /**
         * the name of the subnetwork to attach this interface
         * to. The subnetwork must exist in the same `region` this instance will be
         * created in. Either `network` or `subnetwork` must be provided.
         */
        subnetwork: string;
        /**
         * The ID of the project in which the subnetwork belongs.
         * If it is not provided, the provider project is used.
         */
        subnetworkProject: string;
    }

    export interface GetInstanceTemplateNetworkInterfaceAccessConfig {
        /**
         * The IP address that will be 1:1 mapped to the instance's
         * network ip. If not given, one will be generated.
         */
        natIp: string;
        /**
         * The [networking tier][network-tier] used for configuring
         * this instance template. This field can take the following values: PREMIUM or
         * STANDARD. If this field is not specified, it is assumed to be PREMIUM.
         */
        networkTier: string;
        publicPtrDomainName: string;
    }

    export interface GetInstanceTemplateNetworkInterfaceAliasIpRange {
        /**
         * The IP CIDR range represented by this alias IP range. This IP CIDR range
         * must belong to the specified subnetwork and cannot contain IP addresses reserved by
         * system or used by other network interfaces. At the time of writing only a
         * netmask (e.g. /24) may be supplied, with a CIDR format resulting in an API
         * error.
         */
        ipCidrRange: string;
        /**
         * The subnetwork secondary range name specifying
         * the secondary range from which to allocate the IP CIDR range for this alias IP
         * range. If left unspecified, the primary range of the subnetwork will be used.
         */
        subnetworkRangeName: string;
    }

    export interface GetInstanceTemplateNetworkInterfaceIpv6AccessConfig {
        externalIpv6: string;
        externalIpv6PrefixLength: string;
        /**
         * The [networking tier][network-tier] used for configuring
         * this instance template. This field can take the following values: PREMIUM or
         * STANDARD. If this field is not specified, it is assumed to be PREMIUM.
         */
        networkTier: string;
        publicPtrDomainName: string;
    }

    export interface GetInstanceTemplateNetworkPerformanceConfig {
        /**
         * The egress bandwidth tier for the instance.
         */
        totalEgressBandwidthTier: string;
    }

    export interface GetInstanceTemplateReservationAffinity {
        specificReservations: outputs.compute.GetInstanceTemplateReservationAffinitySpecificReservation[];
        /**
         * The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
         */
        type: string;
    }

    export interface GetInstanceTemplateReservationAffinitySpecificReservation {
        /**
         * The key for the node affinity label.
         */
        key: string;
        values: string[];
    }

    export interface GetInstanceTemplateScheduling {
        /**
         * Specifies whether the instance should be
         * automatically restarted if it is terminated by Compute Engine (not
         * terminated by a user). This defaults to true.
         */
        automaticRestart: boolean;
        minNodeCpus: number;
        /**
         * Specifies node affinities or anti-affinities
         * to determine which sole-tenant nodes your instances and managed instance
         * groups will use as host systems. Read more on sole-tenant node creation
         * [here](https://cloud.google.com/compute/docs/nodes/create-nodes).
         * Structure documented below.
         */
        nodeAffinities: outputs.compute.GetInstanceTemplateSchedulingNodeAffinity[];
        /**
         * Defines the maintenance behavior for this
         * instance.
         */
        onHostMaintenance: string;
        /**
         * Allows instance to be preempted. This defaults to
         * false. Read more on this
         * [here](https://cloud.google.com/compute/docs/instances/preemptible).
         */
        preemptible: boolean;
        /**
         * (Beta) Describe the type of preemptible VM.
         */
        provisioningModel: string;
    }

    export interface GetInstanceTemplateSchedulingNodeAffinity {
        /**
         * The key for the node affinity label.
         */
        key: string;
        /**
         * The operator. Can be `IN` for node-affinities
         * or `NOT_IN` for anti-affinities.
         */
        operator: string;
        values: string[];
    }

    export interface GetInstanceTemplateServiceAccount {
        /**
         * The service account e-mail address. If not given, the
         * default Google Compute Engine service account is used.
         */
        email: string;
        /**
         * A list of service scopes. Both OAuth2 URLs and gcloud
         * short names are supported. To allow full access to all Cloud APIs, use the
         * `cloud-platform` scope. See a complete list of scopes [here](https://cloud.google.com/sdk/gcloud/reference/alpha/compute/instances/set-scopes#--scopes).
         */
        scopes: string[];
    }

    export interface GetInstanceTemplateShieldedInstanceConfig {
        enableIntegrityMonitoring: boolean;
        enableSecureBoot: boolean;
        enableVtpm: boolean;
    }

    export interface GetRegionInstanceGroupInstance {
        /**
         * URL to the instance.
         */
        instance: string;
        /**
         * List of named ports in the group, as a list of resources, each containing:
         */
        namedPorts: outputs.compute.GetRegionInstanceGroupInstanceNamedPort[];
        /**
         * String description of current state of the instance.
         */
        status: string;
    }

    export interface GetRegionInstanceGroupInstanceNamedPort {
        /**
         * The name of the instance group.  One of `name` or `selfLink` must be provided.
         */
        name: string;
        /**
         * Integer port number
         */
        port: number;
    }

    export interface GetResourcePolicyGroupPlacementPolicy {
        availabilityDomainCount: number;
        collocation: string;
        vmCount: number;
    }

    export interface GetResourcePolicyInstanceSchedulePolicy {
        expirationTime: string;
        startTime: string;
        timeZone: string;
        vmStartSchedules: outputs.compute.GetResourcePolicyInstanceSchedulePolicyVmStartSchedule[];
        vmStopSchedules: outputs.compute.GetResourcePolicyInstanceSchedulePolicyVmStopSchedule[];
    }

    export interface GetResourcePolicyInstanceSchedulePolicyVmStartSchedule {
        schedule: string;
    }

    export interface GetResourcePolicyInstanceSchedulePolicyVmStopSchedule {
        schedule: string;
    }

    export interface GetResourcePolicySnapshotSchedulePolicy {
        retentionPolicies: outputs.compute.GetResourcePolicySnapshotSchedulePolicyRetentionPolicy[];
        schedules: outputs.compute.GetResourcePolicySnapshotSchedulePolicySchedule[];
        snapshotProperties: outputs.compute.GetResourcePolicySnapshotSchedulePolicySnapshotProperty[];
    }

    export interface GetResourcePolicySnapshotSchedulePolicyRetentionPolicy {
        maxRetentionDays: number;
        onSourceDiskDelete: string;
    }

    export interface GetResourcePolicySnapshotSchedulePolicySchedule {
        dailySchedules: outputs.compute.GetResourcePolicySnapshotSchedulePolicyScheduleDailySchedule[];
        hourlySchedules: outputs.compute.GetResourcePolicySnapshotSchedulePolicyScheduleHourlySchedule[];
        weeklySchedules: outputs.compute.GetResourcePolicySnapshotSchedulePolicyScheduleWeeklySchedule[];
    }

    export interface GetResourcePolicySnapshotSchedulePolicyScheduleDailySchedule {
        daysInCycle: number;
        startTime: string;
    }

    export interface GetResourcePolicySnapshotSchedulePolicyScheduleHourlySchedule {
        hoursInCycle: number;
        startTime: string;
    }

    export interface GetResourcePolicySnapshotSchedulePolicyScheduleWeeklySchedule {
        dayOfWeeks: outputs.compute.GetResourcePolicySnapshotSchedulePolicyScheduleWeeklyScheduleDayOfWeek[];
    }

    export interface GetResourcePolicySnapshotSchedulePolicyScheduleWeeklyScheduleDayOfWeek {
        day: string;
        startTime: string;
    }

    export interface GetResourcePolicySnapshotSchedulePolicySnapshotProperty {
        guestFlush: boolean;
        labels: {[key: string]: string};
        storageLocations: string[];
    }

    export interface GetRouterBgp {
        advertiseMode: string;
        advertisedGroups: string[];
        advertisedIpRanges: outputs.compute.GetRouterBgpAdvertisedIpRange[];
        asn: number;
        keepaliveInterval: number;
    }

    export interface GetRouterBgpAdvertisedIpRange {
        description: string;
        range: string;
    }

    export interface GetRouterStatusBestRoute {
        description: string;
        destRange: string;
        /**
         * The name of the router.
         */
        name: string;
        /**
         * The network name or resource link to the parent
         * network of this subnetwork.
         */
        network: string;
        nextHopGateway: string;
        nextHopIlb: string;
        nextHopInstance: string;
        nextHopInstanceZone: string;
        nextHopIp: string;
        nextHopNetwork: string;
        nextHopVpnTunnel: string;
        priority: number;
        /**
         * The ID of the project in which the resource
         * belongs. If it is not provided, the provider project is used.
         */
        project: string;
        selfLink: string;
        tags: string[];
    }

    export interface GetRouterStatusBestRoutesForRouter {
        description: string;
        destRange: string;
        /**
         * The name of the router.
         */
        name: string;
        /**
         * The network name or resource link to the parent
         * network of this subnetwork.
         */
        network: string;
        nextHopGateway: string;
        nextHopIlb: string;
        nextHopInstance: string;
        nextHopInstanceZone: string;
        nextHopIp: string;
        nextHopNetwork: string;
        nextHopVpnTunnel: string;
        priority: number;
        /**
         * The ID of the project in which the resource
         * belongs. If it is not provided, the provider project is used.
         */
        project: string;
        selfLink: string;
        tags: string[];
    }

    export interface GetSubnetworkSecondaryIpRange {
        /**
         * The range of IP addresses belonging to this subnetwork
         * secondary range.
         */
        ipCidrRange: string;
        /**
         * The name associated with this subnetwork secondary range, used
         * when adding an alias IP range to a VM instance.
         */
        rangeName: string;
    }

    export interface GlobalForwardingRuleMetadataFilter {
        /**
         * The list of label value pairs that must match labels in the
         * provided metadata based on filterMatchCriteria
         * This list must not be empty and can have at the most 64 entries.
         * Structure is documented below.
         */
        filterLabels: outputs.compute.GlobalForwardingRuleMetadataFilterFilterLabel[];
        /**
         * Specifies how individual filterLabel matches within the list of
         * filterLabels contribute towards the overall metadataFilter match.
         * MATCH_ANY - At least one of the filterLabels must have a matching
         * label in the provided metadata.
         * MATCH_ALL - All filterLabels must have matching labels in the
         * provided metadata.
         * Possible values are `MATCH_ANY` and `MATCH_ALL`.
         */
        filterMatchCriteria: string;
    }

    export interface GlobalForwardingRuleMetadataFilterFilterLabel {
        /**
         * Name of the metadata label. The length must be between
         * 1 and 1024 characters, inclusive.
         */
        name: string;
        /**
         * The value that the label must match. The value has a maximum
         * length of 1024 characters.
         */
        value: string;
    }

    export interface HaVpnGatewayVpnInterface {
        /**
         * The numeric ID of this VPN gateway interface.
         */
        id?: number;
        /**
         * URL of the interconnect attachment resource. When the value
         * of this field is present, the VPN Gateway will be used for
         * IPsec-encrypted Cloud Interconnect; all Egress or Ingress
         * traffic for this VPN Gateway interface will go through the
         * specified interconnect attachment resource.
         * Not currently available publicly.
         */
        interconnectAttachment?: string;
        /**
         * -
         * The external IP address for this VPN gateway interface.
         */
        ipAddress: string;
    }

    export interface HealthCheckGrpcHealthCheck {
        /**
         * The gRPC service name for the health check.
         * The value of grpcServiceName has the following meanings by convention:
         * - Empty serviceName means the overall status of all services at the backend.
         * - Non-empty serviceName means the health of that gRPC service, as defined by the owner of the service.
         * The grpcServiceName can only be ASCII.
         */
        grpcServiceName?: string;
        /**
         * The port number for the health check request.
         * Must be specified if portName and portSpecification are not set
         * or if portSpecification is USE_FIXED_PORT. Valid values are 1 through 65535.
         */
        port?: number;
        /**
         * Port name as defined in InstanceGroup#NamedPort#name. If both port and
         * portName are defined, port takes precedence.
         */
        portName?: string;
        /**
         * Specifies how port is selected for health checking, can be one of the
         * following values:
         * * `USE_FIXED_PORT`: The port number in `port` is used for health checking.
         * * `USE_NAMED_PORT`: The `portName` is used for health checking.
         * * `USE_SERVING_PORT`: For NetworkEndpointGroup, the port specified for each
         * network endpoint is used for health checking. For other backends, the
         * port or named port specified in the Backend Service is used for health
         * checking.
         * If not specified, gRPC health check follows behavior specified in `port` and
         * `portName` fields.
         * Possible values are `USE_FIXED_PORT`, `USE_NAMED_PORT`, and `USE_SERVING_PORT`.
         */
        portSpecification?: string;
    }

    export interface HealthCheckHttp2HealthCheck {
        /**
         * The value of the host header in the HTTP2 health check request.
         * If left empty (default value), the public IP on behalf of which this health
         * check is performed will be used.
         */
        host?: string;
        /**
         * The port number for the health check request.
         * Must be specified if portName and portSpecification are not set
         * or if portSpecification is USE_FIXED_PORT. Valid values are 1 through 65535.
         */
        port?: number;
        /**
         * Port name as defined in InstanceGroup#NamedPort#name. If both port and
         * portName are defined, port takes precedence.
         */
        portName?: string;
        /**
         * Specifies how port is selected for health checking, can be one of the
         * following values:
         * * `USE_FIXED_PORT`: The port number in `port` is used for health checking.
         * * `USE_NAMED_PORT`: The `portName` is used for health checking.
         * * `USE_SERVING_PORT`: For NetworkEndpointGroup, the port specified for each
         * network endpoint is used for health checking. For other backends, the
         * port or named port specified in the Backend Service is used for health
         * checking.
         * If not specified, gRPC health check follows behavior specified in `port` and
         * `portName` fields.
         * Possible values are `USE_FIXED_PORT`, `USE_NAMED_PORT`, and `USE_SERVING_PORT`.
         */
        portSpecification?: string;
        /**
         * Specifies the type of proxy header to append before sending data to the
         * backend.
         * Default value is `NONE`.
         * Possible values are `NONE` and `PROXY_V1`.
         */
        proxyHeader?: string;
        /**
         * The request path of the HTTP2 health check request.
         * The default value is /.
         */
        requestPath?: string;
        /**
         * The bytes to match against the beginning of the response data. If left empty
         * (the default value), any response will indicate health. The response data
         * can only be ASCII.
         */
        response?: string;
    }

    export interface HealthCheckHttpHealthCheck {
        /**
         * The value of the host header in the HTTP2 health check request.
         * If left empty (default value), the public IP on behalf of which this health
         * check is performed will be used.
         */
        host?: string;
        /**
         * The port number for the health check request.
         * Must be specified if portName and portSpecification are not set
         * or if portSpecification is USE_FIXED_PORT. Valid values are 1 through 65535.
         */
        port?: number;
        /**
         * Port name as defined in InstanceGroup#NamedPort#name. If both port and
         * portName are defined, port takes precedence.
         */
        portName?: string;
        /**
         * Specifies how port is selected for health checking, can be one of the
         * following values:
         * * `USE_FIXED_PORT`: The port number in `port` is used for health checking.
         * * `USE_NAMED_PORT`: The `portName` is used for health checking.
         * * `USE_SERVING_PORT`: For NetworkEndpointGroup, the port specified for each
         * network endpoint is used for health checking. For other backends, the
         * port or named port specified in the Backend Service is used for health
         * checking.
         * If not specified, gRPC health check follows behavior specified in `port` and
         * `portName` fields.
         * Possible values are `USE_FIXED_PORT`, `USE_NAMED_PORT`, and `USE_SERVING_PORT`.
         */
        portSpecification?: string;
        /**
         * Specifies the type of proxy header to append before sending data to the
         * backend.
         * Default value is `NONE`.
         * Possible values are `NONE` and `PROXY_V1`.
         */
        proxyHeader?: string;
        /**
         * The request path of the HTTP2 health check request.
         * The default value is /.
         */
        requestPath?: string;
        /**
         * The bytes to match against the beginning of the response data. If left empty
         * (the default value), any response will indicate health. The response data
         * can only be ASCII.
         */
        response?: string;
    }

    export interface HealthCheckHttpsHealthCheck {
        /**
         * The value of the host header in the HTTP2 health check request.
         * If left empty (default value), the public IP on behalf of which this health
         * check is performed will be used.
         */
        host?: string;
        /**
         * The port number for the health check request.
         * Must be specified if portName and portSpecification are not set
         * or if portSpecification is USE_FIXED_PORT. Valid values are 1 through 65535.
         */
        port?: number;
        /**
         * Port name as defined in InstanceGroup#NamedPort#name. If both port and
         * portName are defined, port takes precedence.
         */
        portName?: string;
        /**
         * Specifies how port is selected for health checking, can be one of the
         * following values:
         * * `USE_FIXED_PORT`: The port number in `port` is used for health checking.
         * * `USE_NAMED_PORT`: The `portName` is used for health checking.
         * * `USE_SERVING_PORT`: For NetworkEndpointGroup, the port specified for each
         * network endpoint is used for health checking. For other backends, the
         * port or named port specified in the Backend Service is used for health
         * checking.
         * If not specified, gRPC health check follows behavior specified in `port` and
         * `portName` fields.
         * Possible values are `USE_FIXED_PORT`, `USE_NAMED_PORT`, and `USE_SERVING_PORT`.
         */
        portSpecification?: string;
        /**
         * Specifies the type of proxy header to append before sending data to the
         * backend.
         * Default value is `NONE`.
         * Possible values are `NONE` and `PROXY_V1`.
         */
        proxyHeader?: string;
        /**
         * The request path of the HTTP2 health check request.
         * The default value is /.
         */
        requestPath?: string;
        /**
         * The bytes to match against the beginning of the response data. If left empty
         * (the default value), any response will indicate health. The response data
         * can only be ASCII.
         */
        response?: string;
    }

    export interface HealthCheckLogConfig {
        /**
         * Indicates whether or not to export logs. This is false by default,
         * which means no health check logging will be done.
         */
        enable?: boolean;
    }

    export interface HealthCheckSslHealthCheck {
        /**
         * The port number for the health check request.
         * Must be specified if portName and portSpecification are not set
         * or if portSpecification is USE_FIXED_PORT. Valid values are 1 through 65535.
         */
        port?: number;
        /**
         * Port name as defined in InstanceGroup#NamedPort#name. If both port and
         * portName are defined, port takes precedence.
         */
        portName?: string;
        /**
         * Specifies how port is selected for health checking, can be one of the
         * following values:
         * * `USE_FIXED_PORT`: The port number in `port` is used for health checking.
         * * `USE_NAMED_PORT`: The `portName` is used for health checking.
         * * `USE_SERVING_PORT`: For NetworkEndpointGroup, the port specified for each
         * network endpoint is used for health checking. For other backends, the
         * port or named port specified in the Backend Service is used for health
         * checking.
         * If not specified, gRPC health check follows behavior specified in `port` and
         * `portName` fields.
         * Possible values are `USE_FIXED_PORT`, `USE_NAMED_PORT`, and `USE_SERVING_PORT`.
         */
        portSpecification?: string;
        /**
         * Specifies the type of proxy header to append before sending data to the
         * backend.
         * Default value is `NONE`.
         * Possible values are `NONE` and `PROXY_V1`.
         */
        proxyHeader?: string;
        /**
         * The application data to send once the SSL connection has been
         * established (default value is empty). If both request and response are
         * empty, the connection establishment alone will indicate health. The request
         * data can only be ASCII.
         */
        request?: string;
        /**
         * The bytes to match against the beginning of the response data. If left empty
         * (the default value), any response will indicate health. The response data
         * can only be ASCII.
         */
        response?: string;
    }

    export interface HealthCheckTcpHealthCheck {
        /**
         * The port number for the health check request.
         * Must be specified if portName and portSpecification are not set
         * or if portSpecification is USE_FIXED_PORT. Valid values are 1 through 65535.
         */
        port?: number;
        /**
         * Port name as defined in InstanceGroup#NamedPort#name. If both port and
         * portName are defined, port takes precedence.
         */
        portName?: string;
        /**
         * Specifies how port is selected for health checking, can be one of the
         * following values:
         * * `USE_FIXED_PORT`: The port number in `port` is used for health checking.
         * * `USE_NAMED_PORT`: The `portName` is used for health checking.
         * * `USE_SERVING_PORT`: For NetworkEndpointGroup, the port specified for each
         * network endpoint is used for health checking. For other backends, the
         * port or named port specified in the Backend Service is used for health
         * checking.
         * If not specified, gRPC health check follows behavior specified in `port` and
         * `portName` fields.
         * Possible values are `USE_FIXED_PORT`, `USE_NAMED_PORT`, and `USE_SERVING_PORT`.
         */
        portSpecification?: string;
        /**
         * Specifies the type of proxy header to append before sending data to the
         * backend.
         * Default value is `NONE`.
         * Possible values are `NONE` and `PROXY_V1`.
         */
        proxyHeader?: string;
        /**
         * The application data to send once the SSL connection has been
         * established (default value is empty). If both request and response are
         * empty, the connection establishment alone will indicate health. The request
         * data can only be ASCII.
         */
        request?: string;
        /**
         * The bytes to match against the beginning of the response data. If left empty
         * (the default value), any response will indicate health. The response data
         * can only be ASCII.
         */
        response?: string;
    }

    export interface ImageGuestOsFeature {
        /**
         * The type of supported feature. Read [Enabling guest operating system features](https://cloud.google.com/compute/docs/images/create-delete-deprecate-private-images#guest-os-features) to see a list of available options.
         * Possible values are `MULTI_IP_SUBNET`, `SECURE_BOOT`, `SEV_CAPABLE`, `UEFI_COMPATIBLE`, `VIRTIO_SCSI_MULTIQUEUE`, `WINDOWS`, and `GVNIC`.
         */
        type: string;
    }

    export interface ImageIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface ImageIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface ImageRawDisk {
        /**
         * The format used to encode and transmit the block device, which
         * should be TAR. This is just a container and transmission format
         * and not a runtime format. Provided by the client when the disk
         * image is created.
         * Default value is `TAR`.
         * Possible values are `TAR`.
         */
        containerType?: string;
        /**
         * An optional SHA1 checksum of the disk image before unpackaging.
         * This is provided by the client when the disk image is created.
         */
        sha1?: string;
        /**
         * The full Google Cloud Storage URL where disk storage is stored
         * You must provide either this property or the sourceDisk property
         * but not both.
         */
        source: string;
    }

    export interface InstanceAdvancedMachineFeatures {
        /**
         * Defines whether the instance should have nested virtualization  enabled. Defaults to false.
         */
        enableNestedVirtualization?: boolean;
        /**
         * he number of threads per physical core. To disable [simultaneous multithreading (SMT)](https://cloud.google.com/compute/docs/instances/disabling-smt) set this to 1.
         */
        threadsPerCore?: number;
    }

    export interface InstanceAttachedDisk {
        /**
         * Name with which the attached disk will be accessible
         * under `/dev/disk/by-id/google-*`
         */
        deviceName: string;
        /**
         * A 256-bit [customer-supplied encryption key]
         * (<https://cloud.google.com/compute/docs/disks/customer-supplied-encryption>),
         * encoded in [RFC 4648 base64](https://tools.ietf.org/html/rfc4648#section-4)
         * to encrypt this disk. Only one of `kmsKeySelfLink` and `diskEncryptionKeyRaw` may be set.
         */
        diskEncryptionKeyRaw?: string;
        diskEncryptionKeySha256: string;
        /**
         * The selfLink of the encryption key that is
         * stored in Google Cloud KMS to encrypt this disk. Only one of `kmsKeySelfLink`
         * and `diskEncryptionKeyRaw` may be set.
         */
        kmsKeySelfLink: string;
        /**
         * Either "READ_ONLY" or "READ_WRITE", defaults to "READ_WRITE"
         * If you have a persistent disk with data that you want to share
         * between multiple instances, detach it from any read-write instances and
         * attach it to one or more instances in read-only mode.
         */
        mode?: string;
        /**
         * The name or selfLink of the disk to attach to this instance.
         */
        source: string;
    }

    export interface InstanceBootDisk {
        /**
         * Whether the disk will be auto-deleted when the instance
         * is deleted. Defaults to true.
         */
        autoDelete?: boolean;
        /**
         * Name with which the attached disk will be accessible
         * under `/dev/disk/by-id/google-*`
         */
        deviceName: string;
        /**
         * A 256-bit [customer-supplied encryption key]
         * (<https://cloud.google.com/compute/docs/disks/customer-supplied-encryption>),
         * encoded in [RFC 4648 base64](https://tools.ietf.org/html/rfc4648#section-4)
         * to encrypt this disk. Only one of `kmsKeySelfLink` and `diskEncryptionKeyRaw` may be set.
         */
        diskEncryptionKeyRaw?: string;
        diskEncryptionKeySha256: string;
        /**
         * Parameters for a new disk that will be created
         * alongside the new instance. Either `initializeParams` or `source` must be set.
         * Structure is documented below.
         */
        initializeParams: outputs.compute.InstanceBootDiskInitializeParams;
        /**
         * The selfLink of the encryption key that is
         * stored in Google Cloud KMS to encrypt this disk. Only one of `kmsKeySelfLink`
         * and `diskEncryptionKeyRaw` may be set.
         */
        kmsKeySelfLink: string;
        /**
         * Either "READ_ONLY" or "READ_WRITE", defaults to "READ_WRITE"
         * If you have a persistent disk with data that you want to share
         * between multiple instances, detach it from any read-write instances and
         * attach it to one or more instances in read-only mode.
         */
        mode?: string;
        /**
         * The name or selfLink of the disk to attach to this instance.
         */
        source: string;
    }

    export interface InstanceBootDiskInitializeParams {
        /**
         * The image from which to initialize this disk. This can be
         * one of: the image's `selfLink`, `projects/{project}/global/images/{image}`,
         * `projects/{project}/global/images/family/{family}`, `global/images/{image}`,
         * `global/images/family/{family}`, `family/{family}`, `{project}/{family}`,
         * `{project}/{image}`, `{family}`, or `{image}`. If referred by family, the
         * images names must include the family name. If they don't, use the
         * [gcp.compute.Image data source](https://www.terraform.io/docs/providers/google/d/compute_image.html).
         * For instance, the image `centos-6-v20180104` includes its family name `centos-6`.
         * These images can be referred by family name here.
         */
        image: string;
        /**
         * A map of key/value label pairs to assign to the instance.
         */
        labels: {[key: string]: any};
        /**
         * The size of the image in gigabytes. If not specified, it
         * will inherit the size of its base image.
         */
        size: number;
        /**
         * The type of reservation from which this instance can consume resources.
         */
        type: string;
    }

    export interface InstanceConfidentialInstanceConfig {
        /**
         * Defines whether the instance should have confidential compute enabled. `onHostMaintenance` has to be set to TERMINATE or this will fail to create the VM.
         */
        enableConfidentialCompute: boolean;
    }

    export interface InstanceFromMachineImageAdvancedMachineFeatures {
        enableNestedVirtualization: boolean;
        threadsPerCore: number;
    }

    export interface InstanceFromMachineImageAttachedDisk {
        deviceName: string;
        diskEncryptionKeyRaw: string;
        diskEncryptionKeySha256: string;
        kmsKeySelfLink: string;
        mode: string;
        source: string;
    }

    export interface InstanceFromMachineImageBootDisk {
        autoDelete: boolean;
        deviceName: string;
        diskEncryptionKeyRaw: string;
        diskEncryptionKeySha256: string;
        initializeParams: outputs.compute.InstanceFromMachineImageBootDiskInitializeParams;
        kmsKeySelfLink: string;
        mode: string;
        source: string;
    }

    export interface InstanceFromMachineImageBootDiskInitializeParams {
        image: string;
        labels: {[key: string]: any};
        size: number;
        type: string;
    }

    export interface InstanceFromMachineImageConfidentialInstanceConfig {
        enableConfidentialCompute: boolean;
    }

    export interface InstanceFromMachineImageGuestAccelerator {
        count: number;
        type: string;
    }

    export interface InstanceFromMachineImageNetworkInterface {
        accessConfigs: outputs.compute.InstanceFromMachineImageNetworkInterfaceAccessConfig[];
        aliasIpRanges: outputs.compute.InstanceFromMachineImageNetworkInterfaceAliasIpRange[];
        ipv6AccessConfigs: outputs.compute.InstanceFromMachineImageNetworkInterfaceIpv6AccessConfig[];
        ipv6AccessType: string;
        /**
         * A unique name for the resource, required by GCE.
         * Changing this forces a new resource to be created.
         */
        name: string;
        network: string;
        networkIp: string;
        nicType: string;
        queueCount: number;
        stackType: string;
        subnetwork: string;
        subnetworkProject: string;
    }

    export interface InstanceFromMachineImageNetworkInterfaceAccessConfig {
        natIp: string;
        networkTier: string;
        publicPtrDomainName: string;
    }

    export interface InstanceFromMachineImageNetworkInterfaceAliasIpRange {
        ipCidrRange: string;
        subnetworkRangeName: string;
    }

    export interface InstanceFromMachineImageNetworkInterfaceIpv6AccessConfig {
        externalIpv6: string;
        externalIpv6PrefixLength: string;
        networkTier: string;
        publicPtrDomainName: string;
    }

    export interface InstanceFromMachineImageNetworkPerformanceConfig {
        totalEgressBandwidthTier: string;
    }

    export interface InstanceFromMachineImageReservationAffinity {
        specificReservation: outputs.compute.InstanceFromMachineImageReservationAffinitySpecificReservation;
        type: string;
    }

    export interface InstanceFromMachineImageReservationAffinitySpecificReservation {
        key: string;
        values: string[];
    }

    export interface InstanceFromMachineImageScheduling {
        automaticRestart: boolean;
        minNodeCpus: number;
        nodeAffinities: outputs.compute.InstanceFromMachineImageSchedulingNodeAffinity[];
        onHostMaintenance: string;
        preemptible: boolean;
        provisioningModel: string;
    }

    export interface InstanceFromMachineImageSchedulingNodeAffinity {
        key: string;
        operator: string;
        values: string[];
    }

    export interface InstanceFromMachineImageScratchDisk {
        interface: string;
    }

    export interface InstanceFromMachineImageServiceAccount {
        email: string;
        scopes: string[];
    }

    export interface InstanceFromMachineImageShieldedInstanceConfig {
        enableIntegrityMonitoring: boolean;
        enableSecureBoot: boolean;
        enableVtpm: boolean;
    }

    export interface InstanceFromTemplateAdvancedMachineFeatures {
        enableNestedVirtualization: boolean;
        threadsPerCore: number;
    }

    export interface InstanceFromTemplateAttachedDisk {
        deviceName: string;
        diskEncryptionKeyRaw: string;
        diskEncryptionKeySha256: string;
        kmsKeySelfLink: string;
        mode: string;
        source: string;
    }

    export interface InstanceFromTemplateBootDisk {
        autoDelete: boolean;
        deviceName: string;
        diskEncryptionKeyRaw: string;
        diskEncryptionKeySha256: string;
        initializeParams: outputs.compute.InstanceFromTemplateBootDiskInitializeParams;
        kmsKeySelfLink: string;
        mode: string;
        source: string;
    }

    export interface InstanceFromTemplateBootDiskInitializeParams {
        image: string;
        labels: {[key: string]: any};
        size: number;
        type: string;
    }

    export interface InstanceFromTemplateConfidentialInstanceConfig {
        enableConfidentialCompute: boolean;
    }

    export interface InstanceFromTemplateGuestAccelerator {
        count: number;
        type: string;
    }

    export interface InstanceFromTemplateNetworkInterface {
        accessConfigs: outputs.compute.InstanceFromTemplateNetworkInterfaceAccessConfig[];
        aliasIpRanges: outputs.compute.InstanceFromTemplateNetworkInterfaceAliasIpRange[];
        ipv6AccessConfigs: outputs.compute.InstanceFromTemplateNetworkInterfaceIpv6AccessConfig[];
        ipv6AccessType: string;
        /**
         * A unique name for the resource, required by GCE.
         * Changing this forces a new resource to be created.
         */
        name: string;
        network: string;
        networkIp: string;
        nicType: string;
        queueCount: number;
        stackType: string;
        subnetwork: string;
        subnetworkProject: string;
    }

    export interface InstanceFromTemplateNetworkInterfaceAccessConfig {
        natIp: string;
        networkTier: string;
        publicPtrDomainName: string;
    }

    export interface InstanceFromTemplateNetworkInterfaceAliasIpRange {
        ipCidrRange: string;
        subnetworkRangeName: string;
    }

    export interface InstanceFromTemplateNetworkInterfaceIpv6AccessConfig {
        externalIpv6: string;
        externalIpv6PrefixLength: string;
        networkTier: string;
        publicPtrDomainName: string;
    }

    export interface InstanceFromTemplateNetworkPerformanceConfig {
        totalEgressBandwidthTier: string;
    }

    export interface InstanceFromTemplateReservationAffinity {
        specificReservation: outputs.compute.InstanceFromTemplateReservationAffinitySpecificReservation;
        type: string;
    }

    export interface InstanceFromTemplateReservationAffinitySpecificReservation {
        key: string;
        values: string[];
    }

    export interface InstanceFromTemplateScheduling {
        automaticRestart: boolean;
        minNodeCpus: number;
        nodeAffinities: outputs.compute.InstanceFromTemplateSchedulingNodeAffinity[];
        onHostMaintenance: string;
        preemptible: boolean;
        provisioningModel: string;
    }

    export interface InstanceFromTemplateSchedulingNodeAffinity {
        key: string;
        operator: string;
        values: string[];
    }

    export interface InstanceFromTemplateScratchDisk {
        interface: string;
    }

    export interface InstanceFromTemplateServiceAccount {
        email: string;
        scopes: string[];
    }

    export interface InstanceFromTemplateShieldedInstanceConfig {
        enableIntegrityMonitoring: boolean;
        enableSecureBoot: boolean;
        enableVtpm: boolean;
    }

    export interface InstanceGroupManagerAutoHealingPolicies {
        /**
         * The health check resource that signals autohealing.
         */
        healthCheck: string;
        /**
         * The number of seconds that the managed instance group waits before
         * it applies autohealing policies to new instances or recently recreated instances. Between 0 and 3600.
         */
        initialDelaySec: number;
    }

    export interface InstanceGroupManagerNamedPort {
        /**
         * - Version name.
         */
        name: string;
        /**
         * The port number.
         * - - -
         */
        port: number;
    }

    export interface InstanceGroupManagerStatefulDisk {
        /**
         * , A value that prescribes what should happen to the stateful disk when the VM instance is deleted. The available options are `NEVER` and `ON_PERMANENT_INSTANCE_DELETION`. `NEVER` - detach the disk when the VM is deleted, but do not delete the disk. `ON_PERMANENT_INSTANCE_DELETION` will delete the stateful disk when the VM is permanently deleted from the instance group. The default is `NEVER`.
         */
        deleteRule?: string;
        /**
         * , The device name of the disk to be attached.
         */
        deviceName: string;
    }

    export interface InstanceGroupManagerStatus {
        /**
         * A bit indicating whether the managed instance group is in a stable state. A stable state means that: none of the instances in the managed instance group is currently undergoing any type of change (for example, creation, restart, or deletion); no future changes are scheduled for instances in the managed instance group; and the managed instance group itself is not being modified.
         */
        isStable: boolean;
        /**
         * Stateful status of the given Instance Group Manager.
         */
        statefuls: outputs.compute.InstanceGroupManagerStatusStateful[];
        /**
         * A bit indicating whether version target has been reached in this managed instance group, i.e. all instances are in their target version. Instances' target version are specified by version field on Instance Group Manager.
         */
        versionTargets: outputs.compute.InstanceGroupManagerStatusVersionTarget[];
    }

    export interface InstanceGroupManagerStatusStateful {
        /**
         * A bit indicating whether the managed instance group has stateful configuration, that is, if you have configured any items in a stateful policy or in per-instance configs. The group might report that it has no stateful config even when there is still some preserved state on a managed instance, for example, if you have deleted all PICs but not yet applied those deletions.
         */
        hasStatefulConfig: boolean;
        /**
         * Status of per-instance configs on the instance.
         */
        perInstanceConfigs: outputs.compute.InstanceGroupManagerStatusStatefulPerInstanceConfig[];
    }

    export interface InstanceGroupManagerStatusStatefulPerInstanceConfig {
        /**
         * A bit indicating if all of the group's per-instance configs (listed in the output of a listPerInstanceConfigs API call) have status `EFFECTIVE` or there are no per-instance-configs.
         */
        allEffective: boolean;
    }

    export interface InstanceGroupManagerStatusVersionTarget {
        isReached: boolean;
    }

    export interface InstanceGroupManagerUpdatePolicy {
        /**
         * , The maximum number of instances that can be created above the specified targetSize during the update process. Conflicts with `maxSurgePercent`. If neither is set, defaults to 1
         */
        maxSurgeFixed: number;
        /**
         * , The maximum number of instances(calculated as percentage) that can be created above the specified targetSize during the update process. Conflicts with `maxSurgeFixed`.
         */
        maxSurgePercent?: number;
        /**
         * , The maximum number of instances that can be unavailable during the update process. Conflicts with `maxUnavailablePercent`. If neither is set, defaults to 1
         */
        maxUnavailableFixed: number;
        /**
         * , The maximum number of instances(calculated as percentage) that can be unavailable during the update process. Conflicts with `maxUnavailableFixed`.
         */
        maxUnavailablePercent?: number;
        /**
         * ), Minimum number of seconds to wait for after a newly created instance becomes available. This value must be from range [0, 3600]
         */
        minReadySec?: number;
        /**
         * - Minimal action to be taken on an instance. You can specify either `REFRESH` to update without stopping instances, `RESTART` to restart existing instances or `REPLACE` to delete and create new instances from the target template. If you specify a `REFRESH`, the Updater will attempt to perform that action only. However, if the Updater determines that the minimal action you specify is not enough to perform the update, it might perform a more disruptive action.
         */
        minimalAction: string;
        /**
         * - Most disruptive action that is allowed to be taken on an instance. You can specify either NONE to forbid any actions, REFRESH to allow actions that do not need instance restart, RESTART to allow actions that can be applied without instance replacing or REPLACE to allow all possible actions. If the Updater determines that the minimal update action needed is more disruptive than most disruptive allowed action you specify it will not perform the update at all.
         */
        mostDisruptiveAllowedAction?: string;
        /**
         * , The instance replacement method for managed instance groups. Valid values are: "RECREATE", "SUBSTITUTE". If SUBSTITUTE (default), the group replaces VM instances with new instances that have randomly generated names. If RECREATE, instance names are preserved.  You must also set maxUnavailableFixed or maxUnavailablePercent to be greater than 0.
         * - - -
         */
        replacementMethod?: string;
        /**
         * - The type of update process. You can specify either `PROACTIVE` so that the instance group manager proactively executes actions in order to bring instances to their target versions or `OPPORTUNISTIC` so that no action is proactively executed but the update will be performed as part of other actions (for example, resizes or recreateInstances calls).
         */
        type: string;
    }

    export interface InstanceGroupManagerVersion {
        /**
         * - The full URL to an instance template from which all new instances of this version will be created.
         */
        instanceTemplate: string;
        /**
         * - Version name.
         */
        name?: string;
        /**
         * - The number of instances calculated as a fixed number or a percentage depending on the settings. Structure is documented below.
         */
        targetSize?: outputs.compute.InstanceGroupManagerVersionTargetSize;
    }

    export interface InstanceGroupManagerVersionTargetSize {
        /**
         * , The number of instances which are managed for this version. Conflicts with `percent`.
         */
        fixed?: number;
        /**
         * , The number of instances (calculated as percentage) which are managed for this version. Conflicts with `fixed`.
         * Note that when using `percent`, rounding will be in favor of explicitly set `targetSize` values; a managed instance group with 2 instances and 2 `version`s,
         * one of which has a `target_size.percent` of `60` will create 2 instances of that `version`.
         */
        percent?: number;
    }

    export interface InstanceGroupNamedPort {
        /**
         * The name which the port will be mapped to.
         */
        name: string;
        /**
         * The port number to map the name to.
         */
        port: number;
    }

    export interface InstanceGuestAccelerator {
        /**
         * The number of the guest accelerator cards exposed to this instance.
         */
        count: number;
        /**
         * The type of reservation from which this instance can consume resources.
         */
        type: string;
    }

    export interface InstanceIAMBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface InstanceIAMMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface InstanceNetworkInterface {
        /**
         * Access configurations, i.e. IPs via which this
         * instance can be accessed via the Internet. Omit to ensure that the instance
         * is not accessible from the Internet. If omitted, ssh will not
         * work unless this provider can send traffic to the instance's network (e.g. via
         * tunnel or because it is running on another cloud instance on that network).
         * This block can be repeated multiple times. Structure documented below.
         */
        accessConfigs?: outputs.compute.InstanceNetworkInterfaceAccessConfig[];
        /**
         * An
         * array of alias IP ranges for this network interface. Can only be specified for network
         * interfaces on subnet-mode networks. Structure documented below.
         */
        aliasIpRanges?: outputs.compute.InstanceNetworkInterfaceAliasIpRange[];
        /**
         * An array of IPv6 access configurations for this interface.
         * Currently, only one IPv6 access config, DIRECT_IPV6, is supported. If there is no ipv6AccessConfig
         * specified, then this instance will have no external IPv6 Internet access. Structure documented below.
         */
        ipv6AccessConfigs?: outputs.compute.InstanceNetworkInterfaceIpv6AccessConfig[];
        /**
         * One of EXTERNAL, INTERNAL to indicate whether the IP can be accessed from the Internet.
         * This field is always inherited from its subnetwork.
         */
        ipv6AccessType: string;
        /**
         * A unique name for the resource, required by GCE.
         * Changing this forces a new resource to be created.
         */
        name: string;
        /**
         * The name or selfLink of the network to attach this interface to.
         * Either `network` or `subnetwork` must be provided. If network isn't provided it will
         * be inferred from the subnetwork.
         */
        network: string;
        /**
         * The private IP address to assign to the instance. If
         * empty, the address will be automatically assigned.
         */
        networkIp: string;
        /**
         * The type of vNIC to be used on this interface. Possible values: GVNIC, VIRTIO_NET.
         */
        nicType?: string;
        /**
         * The networking queue count that's specified by users for the network interface. Both Rx and Tx queues will be set to this number. It will be empty if not specified.
         */
        queueCount?: number;
        /**
         * The stack type for this network interface to identify whether the IPv6 feature is enabled or not. Values are IPV4_IPV6 or IPV4_ONLY. If not specified, IPV4_ONLY will be used.
         */
        stackType: string;
        /**
         * The name or selfLink of the subnetwork to attach this
         * interface to. Either `network` or `subnetwork` must be provided. If network isn't provided
         * it will be inferred from the subnetwork. The subnetwork must exist in the same region this
         * instance will be created in. If the network resource is in
         * [legacy](https://cloud.google.com/vpc/docs/legacy) mode, do not specify this field. If the
         * network is in auto subnet mode, specifying the subnetwork is optional. If the network is
         * in custom subnet mode, specifying the subnetwork is required.
         */
        subnetwork: string;
        /**
         * The project in which the subnetwork belongs.
         * If the `subnetwork` is a self_link, this field is ignored in favor of the project
         * defined in the subnetwork self_link. If the `subnetwork` is a name and this
         * field is not provided, the provider project is used.
         */
        subnetworkProject: string;
    }

    export interface InstanceNetworkInterfaceAccessConfig {
        /**
         * The IP address that will be 1:1 mapped to the instance's
         * network ip. If not given, one will be generated.
         */
        natIp: string;
        /**
         * The service-level to be provided for IPv6 traffic when the
         * subnet has an external subnet. Only PREMIUM or STANDARD tier is valid for IPv6.
         */
        networkTier: string;
        /**
         * The domain name to be used when creating DNSv6
         * records for the external IPv6 ranges..
         */
        publicPtrDomainName?: string;
    }

    export interface InstanceNetworkInterfaceAliasIpRange {
        /**
         * The IP CIDR range represented by this alias IP range. This IP CIDR range
         * must belong to the specified subnetwork and cannot contain IP addresses reserved by
         * system or used by other network interfaces. This range may be a single IP address
         * (e.g. 10.2.3.4), a netmask (e.g. /24) or a CIDR format string (e.g. 10.1.2.0/24).
         */
        ipCidrRange: string;
        /**
         * The subnetwork secondary range name specifying
         * the secondary range from which to allocate the IP CIDR range for this alias IP
         * range. If left unspecified, the primary range of the subnetwork will be used.
         */
        subnetworkRangeName?: string;
    }

    export interface InstanceNetworkInterfaceIpv6AccessConfig {
        externalIpv6: string;
        externalIpv6PrefixLength: string;
        /**
         * The service-level to be provided for IPv6 traffic when the
         * subnet has an external subnet. Only PREMIUM or STANDARD tier is valid for IPv6.
         */
        networkTier: string;
        /**
         * The domain name to be used when creating DNSv6
         * records for the external IPv6 ranges..
         */
        publicPtrDomainName?: string;
    }

    export interface InstanceNetworkPerformanceConfig {
        /**
         * The egress bandwidth tier to enable.
         * Possible values: TIER_1, DEFAULT
         */
        totalEgressBandwidthTier: string;
    }

    export interface InstanceReservationAffinity {
        /**
         * Specifies the label selector for the reservation to use..
         * Structure is documented below.
         */
        specificReservation?: outputs.compute.InstanceReservationAffinitySpecificReservation;
        /**
         * The type of reservation from which this instance can consume resources.
         */
        type: string;
    }

    export interface InstanceReservationAffinitySpecificReservation {
        /**
         * Corresponds to the label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify compute.googleapis.com/reservation-name as the key and specify the name of your reservation as the only value.
         */
        key: string;
        /**
         * Corresponds to the label values of a reservation resource.
         */
        values: string[];
    }

    export interface InstanceScheduling {
        /**
         * Specifies if the instance should be
         * restarted if it was terminated by Compute Engine (not a user).
         * Defaults to true.
         */
        automaticRestart?: boolean;
        /**
         * The minimum number of virtual CPUs this instance will consume when running on a sole-tenant node.
         */
        minNodeCpus?: number;
        /**
         * Specifies node affinities or anti-affinities
         * to determine which sole-tenant nodes your instances and managed instance
         * groups will use as host systems. Read more on sole-tenant node creation
         * [here](https://cloud.google.com/compute/docs/nodes/create-nodes).
         * Structure documented below.
         */
        nodeAffinities?: outputs.compute.InstanceSchedulingNodeAffinity[];
        /**
         * Describes maintenance behavior for the
         * instance. Can be MIGRATE or TERMINATE, for more info, read
         * [here](https://cloud.google.com/compute/docs/instances/setting-instance-scheduling-options).
         */
        onHostMaintenance: string;
        /**
         * Specifies if the instance is preemptible.
         * If this field is set to true, then `automaticRestart` must be
         * set to false.  Defaults to false.
         */
        preemptible?: boolean;
        /**
         * Describe the type of preemptible VM. This field accepts the value `STANDARD` or `SPOT`. If the value is `STANDARD`, there will be no discount. If this   is set to `SPOT`,
         * `preemptible` should be `true` and `autoRestart` should be
         * `false`. For more info about
         * `SPOT`, read [here](https://cloud.google.com/compute/docs/instances/spot)
         */
        provisioningModel: string;
    }

    export interface InstanceSchedulingNodeAffinity {
        /**
         * Corresponds to the label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify compute.googleapis.com/reservation-name as the key and specify the name of your reservation as the only value.
         */
        key: string;
        /**
         * The operator. Can be `IN` for node-affinities
         * or `NOT_IN` for anti-affinities.
         */
        operator: string;
        /**
         * Corresponds to the label values of a reservation resource.
         */
        values: string[];
    }

    export interface InstanceScratchDisk {
        /**
         * The disk interface to use for attaching this disk; either SCSI or NVME.
         */
        interface: string;
    }

    export interface InstanceServiceAccount {
        /**
         * The service account e-mail address. If not given, the
         * default Google Compute Engine service account is used.
         * **Note**: `allowStoppingForUpdate` must be set to true or your instance must have a `desiredStatus` of `TERMINATED` in order to update this field.
         */
        email: string;
        /**
         * A list of service scopes. Both OAuth2 URLs and gcloud
         * short names are supported. To allow full access to all Cloud APIs, use the
         * `cloud-platform` scope. See a complete list of scopes [here](https://cloud.google.com/sdk/gcloud/reference/alpha/compute/instances/set-scopes#--scopes).
         * **Note**: `allowStoppingForUpdate` must be set to true or your instance must have a `desiredStatus` of `TERMINATED` in order to update this field.
         */
        scopes: string[];
    }

    export interface InstanceShieldedInstanceConfig {
        /**
         * -- Compare the most recent boot measurements to the integrity policy baseline and return a pair of pass/fail results depending on whether they match or not. Defaults to true.
         * **Note**: `allowStoppingForUpdate` must be set to true or your instance must have a `desiredStatus` of `TERMINATED` in order to update this field.
         */
        enableIntegrityMonitoring?: boolean;
        /**
         * -- Verify the digital signature of all boot components, and halt the boot process if signature verification fails. Defaults to false.
         * **Note**: `allowStoppingForUpdate` must be set to true or your instance must have a `desiredStatus` of `TERMINATED` in order to update this field.
         */
        enableSecureBoot?: boolean;
        /**
         * -- Use a virtualized trusted platform module, which is a specialized computer chip you can use to encrypt objects like keys and certificates. Defaults to true.
         * **Note**: `allowStoppingForUpdate` must be set to true or your instance must have a `desiredStatus` of `TERMINATED` in order to update this field.
         */
        enableVtpm?: boolean;
    }

    export interface InstanceTemplateAdvancedMachineFeatures {
        /**
         * Defines whether the instance should have nested virtualization enabled. Defaults to false.
         */
        enableNestedVirtualization?: boolean;
        /**
         * he number of threads per physical core. To disable [simultaneous multithreading (SMT)](https://cloud.google.com/compute/docs/instances/disabling-smt) set this to 1.
         */
        threadsPerCore?: number;
    }

    export interface InstanceTemplateConfidentialInstanceConfig {
        /**
         * Defines whether the instance should have confidential compute enabled. `onHostMaintenance` has to be set to TERMINATE or this will fail to create the VM.
         */
        enableConfidentialCompute: boolean;
    }

    export interface InstanceTemplateDisk {
        /**
         * Whether or not the disk should be auto-deleted.
         * This defaults to true.
         */
        autoDelete?: boolean;
        /**
         * Indicates that this is a boot disk.
         */
        boot: boolean;
        /**
         * A unique device name that is reflected into the
         * /dev/  tree of a Linux operating system running within the instance. If not
         * specified, the server chooses a default device name to apply to this disk.
         */
        deviceName: string;
        /**
         * Encrypts or decrypts a disk using a customer-supplied encryption key.
         */
        diskEncryptionKey?: outputs.compute.InstanceTemplateDiskDiskEncryptionKey;
        /**
         * Name of the disk. When not provided, this defaults
         * to the name of the instance.
         */
        diskName?: string;
        /**
         * The size of the image in gigabytes. If not
         * specified, it will inherit the size of its base image. For SCRATCH disks,
         * the size must be exactly 375GB.
         */
        diskSizeGb: number;
        /**
         * The GCE disk type. Such as `"pd-ssd"`, `"local-ssd"`,
         * `"pd-balanced"` or `"pd-standard"`.
         */
        diskType: string;
        /**
         * Specifies the disk interface to use for attaching this disk,
         * which is either SCSI or NVME. The default is SCSI. Persistent disks must always use SCSI
         * and the request will fail if you attempt to attach a persistent disk in any other format
         * than SCSI. Local SSDs can use either NVME or SCSI.
         */
        interface: string;
        /**
         * A set of ket/value label pairs to assign to disk created from
         * this template
         */
        labels?: {[key: string]: string};
        /**
         * The mode in which to attach this disk, either READ_WRITE
         * or READ_ONLY. If you are attaching or creating a boot disk, this must
         * read-write mode.
         */
        mode: string;
        /**
         * -- A list (short name or id) of resource policies to attach to this disk for automatic snapshot creations. Currently a max of 1 resource policy is supported.
         */
        resourcePolicies?: string;
        /**
         * The name (**not self_link**)
         * of the disk (such as those managed by `gcp.compute.Disk`) to attach.
         * > **Note:** Either `source` or `sourceImage` is **required** in a disk block unless the disk type is `local-ssd`. Check the API [docs](https://cloud.google.com/compute/docs/reference/rest/v1/instanceTemplates/insert) for details.
         */
        source?: string;
        /**
         * The image from which to
         * initialize this disk. This can be one of: the image's `selfLink`,
         * `projects/{project}/global/images/{image}`,
         * `projects/{project}/global/images/family/{family}`, `global/images/{image}`,
         * `global/images/family/{family}`, `family/{family}`, `{project}/{family}`,
         * `{project}/{image}`, `{family}`, or `{image}`.
         * > **Note:** Either `source` or `sourceImage` is **required** in a disk block unless the disk type is `local-ssd`. Check the API [docs](https://cloud.google.com/compute/docs/reference/rest/v1/instanceTemplates/insert) for details.
         */
        sourceImage: string;
        /**
         * The type of reservation from which this instance can consume resources.
         */
        type: string;
    }

    export interface InstanceTemplateDiskDiskEncryptionKey {
        /**
         * The self link of the encryption key that is stored in Google Cloud KMS
         */
        kmsKeySelfLink: string;
    }

    export interface InstanceTemplateGuestAccelerator {
        /**
         * The number of the guest accelerator cards exposed to this instance.
         */
        count: number;
        /**
         * The type of reservation from which this instance can consume resources.
         */
        type: string;
    }

    export interface InstanceTemplateNetworkInterface {
        /**
         * Access configurations, i.e. IPs via which this
         * instance can be accessed via the Internet. Omit to ensure that the instance
         * is not accessible from the Internet (this means that ssh provisioners will
         * not work unless you can send traffic to the instance's
         * network (e.g. via tunnel or because it is running on another cloud instance
         * on that network). This block can be repeated multiple times. Structure documented below.
         */
        accessConfigs?: outputs.compute.InstanceTemplateNetworkInterfaceAccessConfig[];
        /**
         * An
         * array of alias IP ranges for this network interface. Can only be specified for network
         * interfaces on subnet-mode networks. Structure documented below.
         */
        aliasIpRanges?: outputs.compute.InstanceTemplateNetworkInterfaceAliasIpRange[];
        /**
         * An array of IPv6 access configurations for this interface.
         * Currently, only one IPv6 access config, DIRECT_IPV6, is supported. If there is no ipv6AccessConfig
         * specified, then this instance will have no external IPv6 Internet access. Structure documented below.
         */
        ipv6AccessConfigs?: outputs.compute.InstanceTemplateNetworkInterfaceIpv6AccessConfig[];
        ipv6AccessType: string;
        /**
         * The name of the instance template. If you leave
         * this blank, the provider will auto-generate a unique name.
         */
        name: string;
        /**
         * The name or selfLink of the network to attach this interface to.
         * Use `network` attribute for Legacy or Auto subnetted networks and
         * `subnetwork` for custom subnetted networks.
         */
        network: string;
        /**
         * The private IP address to assign to the instance. If
         * empty, the address will be automatically assigned.
         */
        networkIp?: string;
        /**
         * The type of vNIC to be used on this interface. Possible values: GVNIC, VIRTIO_NET.
         */
        nicType?: string;
        /**
         * The networking queue count that's specified by users for the network interface. Both Rx and Tx queues will be set to this number. It will be empty if not specified.
         */
        queueCount?: number;
        /**
         * The stack type for this network interface to identify whether the IPv6 feature is enabled or not. Values are IPV4_IPV6 or IPV4_ONLY. If not specified, IPV4_ONLY will be used.
         */
        stackType: string;
        /**
         * the name of the subnetwork to attach this interface
         * to. The subnetwork must exist in the same `region` this instance will be
         * created in. Either `network` or `subnetwork` must be provided.
         */
        subnetwork: string;
        /**
         * The ID of the project in which the subnetwork belongs.
         * If it is not provided, the provider project is used.
         */
        subnetworkProject: string;
    }

    export interface InstanceTemplateNetworkInterfaceAccessConfig {
        /**
         * The IP address that will be 1:1 mapped to the instance's
         * network ip. If not given, one will be generated.
         */
        natIp: string;
        /**
         * The service-level to be provided for IPv6 traffic when the
         * subnet has an external subnet. Only PREMIUM and STANDARD tier is valid for IPv6.
         */
        networkTier: string;
        publicPtrDomainName: string;
    }

    export interface InstanceTemplateNetworkInterfaceAliasIpRange {
        /**
         * The IP CIDR range represented by this alias IP range. This IP CIDR range
         * must belong to the specified subnetwork and cannot contain IP addresses reserved by
         * system or used by other network interfaces. At the time of writing only a
         * netmask (e.g. /24) may be supplied, with a CIDR format resulting in an API
         * error.
         */
        ipCidrRange: string;
        /**
         * The subnetwork secondary range name specifying
         * the secondary range from which to allocate the IP CIDR range for this alias IP
         * range. If left unspecified, the primary range of the subnetwork will be used.
         */
        subnetworkRangeName?: string;
    }

    export interface InstanceTemplateNetworkInterfaceIpv6AccessConfig {
        externalIpv6: string;
        externalIpv6PrefixLength: string;
        /**
         * The service-level to be provided for IPv6 traffic when the
         * subnet has an external subnet. Only PREMIUM and STANDARD tier is valid for IPv6.
         */
        networkTier: string;
        publicPtrDomainName: string;
    }

    export interface InstanceTemplateNetworkPerformanceConfig {
        /**
         * The egress bandwidth tier to enable. Possible values: TIER_1, DEFAULT
         */
        totalEgressBandwidthTier: string;
    }

    export interface InstanceTemplateReservationAffinity {
        /**
         * Specifies the label selector for the reservation to use..
         * Structure is documented below.
         */
        specificReservation?: outputs.compute.InstanceTemplateReservationAffinitySpecificReservation;
        /**
         * The type of reservation from which this instance can consume resources.
         */
        type: string;
    }

    export interface InstanceTemplateReservationAffinitySpecificReservation {
        /**
         * Corresponds to the label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify compute.googleapis.com/reservation-name as the key and specify the name of your reservation as the only value.
         */
        key: string;
        /**
         * Corresponds to the label values of a reservation resource.
         */
        values: string[];
    }

    export interface InstanceTemplateScheduling {
        /**
         * Specifies whether the instance should be
         * automatically restarted if it is terminated by Compute Engine (not
         * terminated by a user). This defaults to true.
         */
        automaticRestart?: boolean;
        minNodeCpus?: number;
        /**
         * Specifies node affinities or anti-affinities
         * to determine which sole-tenant nodes your instances and managed instance
         * groups will use as host systems. Read more on sole-tenant node creation
         * [here](https://cloud.google.com/compute/docs/nodes/create-nodes).
         * Structure documented below.
         */
        nodeAffinities?: outputs.compute.InstanceTemplateSchedulingNodeAffinity[];
        /**
         * Defines the maintenance behavior for this
         * instance.
         */
        onHostMaintenance: string;
        /**
         * Allows instance to be preempted. This defaults to
         * false. Read more on this
         * [here](https://cloud.google.com/compute/docs/instances/preemptible).
         */
        preemptible?: boolean;
        /**
         * Describe the type of preemptible VM. This field accepts the value `STANDARD` or `SPOT`. If the value is `STANDARD`, there will be no discount. If this   is set to `SPOT`,
         * `preemptible` should be `true` and `autoRestart` should be
         * `false`. For more info about
         * `SPOT`, read [here](https://cloud.google.com/compute/docs/instances/spot)
         */
        provisioningModel: string;
    }

    export interface InstanceTemplateSchedulingNodeAffinity {
        /**
         * Corresponds to the label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify compute.googleapis.com/reservation-name as the key and specify the name of your reservation as the only value.
         */
        key: string;
        /**
         * The operator. Can be `IN` for node-affinities
         * or `NOT_IN` for anti-affinities.
         */
        operator: string;
        /**
         * Corresponds to the label values of a reservation resource.
         */
        values: string[];
    }

    export interface InstanceTemplateServiceAccount {
        /**
         * The service account e-mail address. If not given, the
         * default Google Compute Engine service account is used.
         */
        email: string;
        /**
         * A list of service scopes. Both OAuth2 URLs and gcloud
         * short names are supported. To allow full access to all Cloud APIs, use the
         * `cloud-platform` scope. See a complete list of scopes [here](https://cloud.google.com/sdk/gcloud/reference/alpha/compute/instances/set-scopes#--scopes).
         */
        scopes: string[];
    }

    export interface InstanceTemplateShieldedInstanceConfig {
        /**
         * -- Compare the most recent boot measurements to the integrity policy baseline and return a pair of pass/fail results depending on whether they match or not. Defaults to true.
         */
        enableIntegrityMonitoring?: boolean;
        /**
         * -- Verify the digital signature of all boot components, and halt the boot process if signature verification fails. Defaults to false.
         */
        enableSecureBoot?: boolean;
        /**
         * -- Use a virtualized trusted platform module, which is a specialized computer chip you can use to encrypt objects like keys and certificates. Defaults to true.
         */
        enableVtpm?: boolean;
    }

    export interface InterconnectAttachmentPrivateInterconnectInfo {
        tag8021q: number;
    }

    export interface MachineImageIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface MachineImageIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface MachineImageMachineImageEncryptionKey {
        /**
         * The name of the encryption key that is stored in Google Cloud KMS.
         */
        kmsKeyName?: string;
        /**
         * The service account used for the encryption request for the given KMS key.
         * If absent, the Compute Engine Service Agent service account is used.
         */
        kmsKeyServiceAccount?: string;
        /**
         * Specifies a 256-bit customer-supplied encryption key, encoded in
         * RFC 4648 base64 to either encrypt or decrypt this resource.
         */
        rawKey?: string;
        /**
         * -
         * The RFC 4648 base64 encoded SHA-256 hash of the
         * customer-supplied encryption key that protects this resource.
         */
        sha256: string;
    }

    export interface ManagedSslCertificateManaged {
        /**
         * Domains for which a managed SSL certificate will be valid.  Currently,
         * there can be up to 100 domains in this list.
         */
        domains: string[];
    }

    export interface MangedSslCertificateManaged {
        /**
         * Domains for which a managed SSL certificate will be valid.  Currently,
         * there can be up to 100 domains in this list.
         */
        domains: string[];
    }

    export interface NodeGroupAutoscalingPolicy {
        /**
         * Maximum size of the node group. Set to a value less than or equal
         * to 100 and greater than or equal to min-nodes.
         */
        maxNodes: number;
        /**
         * Minimum size of the node group. Must be less
         * than or equal to max-nodes. The default value is 0.
         */
        minNodes: number;
        /**
         * The autoscaling mode. Set to one of the following:
         * - OFF: Disables the autoscaler.
         * - ON: Enables scaling in and scaling out.
         * - ONLY_SCALE_OUT: Enables only scaling out.
         * You must use this mode if your node groups are configured to
         * restart their hosted VMs on minimal servers.
         * Possible values are `OFF`, `ON`, and `ONLY_SCALE_OUT`.
         */
        mode: string;
    }

    export interface NodeGroupMaintenanceWindow {
        /**
         * instances.start time of the window. This must be in UTC format that resolves to one of 00:00, 04:00, 08:00, 12:00, 16:00, or 20:00. For example, both 13:00-5 and 08:00 are valid.
         */
        startTime: string;
    }

    export interface NodeTemplateNodeTypeFlexibility {
        /**
         * Number of virtual CPUs to use.
         */
        cpus?: string;
        /**
         * -
         * Use local SSD
         */
        localSsd: string;
        /**
         * Physical memory available to the node, defined in MB.
         */
        memory?: string;
    }

    export interface NodeTemplateServerBinding {
        /**
         * Type of server binding policy. If `RESTART_NODE_ON_ANY_SERVER`,
         * nodes using this template will restart on any physical server
         * following a maintenance event.
         * If `RESTART_NODE_ON_MINIMAL_SERVER`, nodes using this template
         * will restart on the same physical server following a maintenance
         * event, instead of being live migrated to or restarted on a new
         * physical server. This option may be useful if you are using
         * software licenses tied to the underlying server characteristics
         * such as physical sockets or cores, to avoid the need for
         * additional licenses when maintenance occurs. However, VMs on such
         * nodes will experience outages while maintenance is applied.
         * Possible values are `RESTART_NODE_ON_ANY_SERVER` and `RESTART_NODE_ON_MINIMAL_SERVERS`.
         */
        type: string;
    }

    export interface OrganizationSecurityPolicyRuleMatch {
        /**
         * The configuration options for matching the rule.
         * Structure is documented below.
         */
        config: outputs.compute.OrganizationSecurityPolicyRuleMatchConfig;
        /**
         * A description of the rule.
         */
        description?: string;
        /**
         * Preconfigured versioned expression. For organization security policy rules,
         * the only supported type is "FIREWALL".
         * Default value is `FIREWALL`.
         * Possible values are `FIREWALL`.
         */
        versionedExpr?: string;
    }

    export interface OrganizationSecurityPolicyRuleMatchConfig {
        /**
         * Destination IP address range in CIDR format. Required for
         * EGRESS rules.
         */
        destIpRanges?: string[];
        /**
         * Pairs of IP protocols and ports that the rule should match.
         * Structure is documented below.
         */
        layer4Configs: outputs.compute.OrganizationSecurityPolicyRuleMatchConfigLayer4Config[];
        /**
         * Source IP address range in CIDR format. Required for
         * INGRESS rules.
         */
        srcIpRanges?: string[];
    }

    export interface OrganizationSecurityPolicyRuleMatchConfigLayer4Config {
        /**
         * The IP protocol to which this rule applies. The protocol
         * type is required when creating a firewall rule.
         * This value can either be one of the following well
         * known protocol strings (tcp, udp, icmp, esp, ah, ipip, sctp),
         * or the IP protocol number.
         */
        ipProtocol: string;
        /**
         * An optional list of ports to which this rule applies. This field
         * is only applicable for UDP or TCP protocol. Each entry must be
         * either an integer or a range. If not specified, this rule
         * applies to connections through any port.
         * Example inputs include: ["22"], ["80","443"], and
         * ["12345-12349"].
         */
        ports?: string[];
    }

    export interface PacketMirroringCollectorIlb {
        /**
         * The URL of the instances where this rule should be active.
         */
        url: string;
    }

    export interface PacketMirroringFilter {
        /**
         * IP CIDR ranges that apply as a filter on the source (ingress) or
         * destination (egress) IP in the IP header. Only IPv4 is supported.
         */
        cidrRanges?: string[];
        /**
         * Direction of traffic to mirror.
         * Default value is `BOTH`.
         * Possible values are `INGRESS`, `EGRESS`, and `BOTH`.
         */
        direction?: string;
        /**
         * Protocols that apply as a filter on mirrored traffic.
         * Each value may be one of `tcp`, `udp`, and `icmp`.
         */
        ipProtocols?: string[];
    }

    export interface PacketMirroringMirroredResources {
        /**
         * All the listed instances will be mirrored.  Specify at most 50.
         * Structure is documented below.
         */
        instances?: outputs.compute.PacketMirroringMirroredResourcesInstance[];
        /**
         * All instances in one of these subnetworks will be mirrored.
         * Structure is documented below.
         */
        subnetworks?: outputs.compute.PacketMirroringMirroredResourcesSubnetwork[];
        /**
         * All instances with these tags will be mirrored.
         */
        tags?: string[];
    }

    export interface PacketMirroringMirroredResourcesInstance {
        /**
         * The URL of the instances where this rule should be active.
         */
        url: string;
    }

    export interface PacketMirroringMirroredResourcesSubnetwork {
        /**
         * The URL of the instances where this rule should be active.
         */
        url: string;
    }

    export interface PacketMirroringNetwork {
        /**
         * The URL of the instances where this rule should be active.
         */
        url: string;
    }

    export interface PerInstanceConfigPreservedState {
        /**
         * Stateful disks for the instance.
         * Structure is documented below.
         */
        disks?: outputs.compute.PerInstanceConfigPreservedStateDisk[];
        /**
         * Preserved metadata defined for this instance. This is a list of key->value pairs.
         */
        metadata?: {[key: string]: string};
    }

    export interface PerInstanceConfigPreservedStateDisk {
        /**
         * A value that prescribes what should happen to the stateful disk when the VM instance is deleted.
         * The available options are `NEVER` and `ON_PERMANENT_INSTANCE_DELETION`.
         * `NEVER` - detach the disk when the VM is deleted, but do not delete the disk.
         * `ON_PERMANENT_INSTANCE_DELETION` will delete the stateful disk when the VM is permanently
         * deleted from the instance group.
         * Default value is `NEVER`.
         * Possible values are `NEVER` and `ON_PERMANENT_INSTANCE_DELETION`.
         */
        deleteRule?: string;
        /**
         * A unique device name that is reflected into the /dev/ tree of a Linux operating system running within the instance.
         */
        deviceName: string;
        /**
         * The mode of the disk.
         * Default value is `READ_WRITE`.
         * Possible values are `READ_ONLY` and `READ_WRITE`.
         */
        mode?: string;
        /**
         * The URI of an existing persistent disk to attach under the specified device-name in the format
         * `projects/project-id/zones/zone/disks/disk-name`.
         */
        source: string;
    }

    export interface RegionAutoscalerAutoscalingPolicy {
        /**
         * The number of seconds that the autoscaler should wait before it
         * starts collecting information from a new instance. This prevents
         * the autoscaler from collecting information when the instance is
         * initializing, during which the collected usage would not be
         * reliable. The default time autoscaler waits is 60 seconds.
         * Virtual machine initialization times might vary because of
         * numerous factors. We recommend that you test how long an
         * instance may take to initialize. To do this, create an instance
         * and time the startup process.
         */
        cooldownPeriod?: number;
        /**
         * Defines the CPU utilization policy that allows the autoscaler to
         * scale based on the average CPU utilization of a managed instance
         * group.
         * Structure is documented below.
         */
        cpuUtilization: outputs.compute.RegionAutoscalerAutoscalingPolicyCpuUtilization;
        /**
         * Configuration parameters of autoscaling based on a load balancer.
         * Structure is documented below.
         */
        loadBalancingUtilization?: outputs.compute.RegionAutoscalerAutoscalingPolicyLoadBalancingUtilization;
        /**
         * The maximum number of instances that the autoscaler can scale up
         * to. This is required when creating or updating an autoscaler. The
         * maximum number of replicas should not be lower than minimal number
         * of replicas.
         */
        maxReplicas: number;
        /**
         * Configuration parameters of autoscaling based on a custom metric.
         * Structure is documented below.
         */
        metrics?: outputs.compute.RegionAutoscalerAutoscalingPolicyMetric[];
        /**
         * The minimum number of replicas that the autoscaler can scale down
         * to. This cannot be less than 0. If not provided, autoscaler will
         * choose a default value depending on maximum number of instances
         * allowed.
         */
        minReplicas: number;
        /**
         * Defines operating mode for this policy.
         * Default value is `ON`.
         * Possible values are `OFF`, `ONLY_UP`, and `ON`.
         */
        mode?: string;
        /**
         * Defines scale down controls to reduce the risk of response latency
         * and outages due to abrupt scale-in events
         * Structure is documented below.
         */
        scaleDownControl?: outputs.compute.RegionAutoscalerAutoscalingPolicyScaleDownControl;
        /**
         * Defines scale in controls to reduce the risk of response latency
         * and outages due to abrupt scale-in events
         * Structure is documented below.
         */
        scaleInControl?: outputs.compute.RegionAutoscalerAutoscalingPolicyScaleInControl;
        /**
         * Scaling schedules defined for an autoscaler. Multiple schedules can be set on an autoscaler and they can overlap.
         * Structure is documented below.
         */
        scalingSchedules?: outputs.compute.RegionAutoscalerAutoscalingPolicyScalingSchedule[];
    }

    export interface RegionAutoscalerAutoscalingPolicyCpuUtilization {
        /**
         * Indicates whether predictive autoscaling based on CPU metric is enabled. Valid values are:
         * - NONE (default). No predictive method is used. The autoscaler scales the group to meet current demand based on real-time metrics.
         * - OPTIMIZE_AVAILABILITY. Predictive autoscaling improves availability by monitoring daily and weekly load patterns and scaling out ahead of anticipated demand.
         */
        predictiveMethod?: string;
        /**
         * Fraction of backend capacity utilization (set in HTTP(s) load
         * balancing configuration) that autoscaler should maintain. Must
         * be a positive float value. If not defined, the default is 0.8.
         */
        target: number;
    }

    export interface RegionAutoscalerAutoscalingPolicyLoadBalancingUtilization {
        /**
         * Fraction of backend capacity utilization (set in HTTP(s) load
         * balancing configuration) that autoscaler should maintain. Must
         * be a positive float value. If not defined, the default is 0.8.
         */
        target: number;
    }

    export interface RegionAutoscalerAutoscalingPolicyMetric {
        /**
         * A filter string to be used as the filter string for
         * a Stackdriver Monitoring TimeSeries.list API call.
         * This filter is used to select a specific TimeSeries for
         * the purpose of autoscaling and to determine whether the metric
         * is exporting per-instance or per-group data.
         * You can only use the AND operator for joining selectors.
         * You can only use direct equality comparison operator (=) without
         * any functions for each selector.
         * You can specify the metric in both the filter string and in the
         * metric field. However, if specified in both places, the metric must
         * be identical.
         * The monitored resource type determines what kind of values are
         * expected for the metric. If it is a gce_instance, the autoscaler
         * expects the metric to include a separate TimeSeries for each
         * instance in a group. In such a case, you cannot filter on resource
         * labels.
         * If the resource type is any other value, the autoscaler expects
         * this metric to contain values that apply to the entire autoscaled
         * instance group and resource label filtering can be performed to
         * point autoscaler at the correct TimeSeries to scale upon.
         * This is called a per-group metric for the purpose of autoscaling.
         * If not specified, the type defaults to gce_instance.
         * You should provide a filter that is selective enough to pick just
         * one TimeSeries for the autoscaled group or for each of the instances
         * (if you are using gceInstance resource type). If multiple
         * TimeSeries are returned upon the query execution, the autoscaler
         * will sum their respective values to obtain its scaling value.
         */
        filter?: string;
        /**
         * The identifier for this object. Format specified above.
         */
        name: string;
        /**
         * If scaling is based on a per-group metric value that represents the
         * total amount of work to be done or resource usage, set this value to
         * an amount assigned for a single instance of the scaled group.
         * The autoscaler will keep the number of instances proportional to the
         * value of this metric, the metric itself should not change value due
         * to group resizing.
         * For example, a good metric to use with the target is
         * `pubsub.googleapis.com/subscription/num_undelivered_messages`
         * or a custom metric exporting the total number of requests coming to
         * your instances.
         * A bad example would be a metric exporting an average or median
         * latency, since this value can't include a chunk assignable to a
         * single instance, it could be better used with utilizationTarget
         * instead.
         */
        singleInstanceAssignment?: number;
        /**
         * Fraction of backend capacity utilization (set in HTTP(s) load
         * balancing configuration) that autoscaler should maintain. Must
         * be a positive float value. If not defined, the default is 0.8.
         */
        target?: number;
        /**
         * Defines how target utilization value is expressed for a
         * Stackdriver Monitoring metric.
         * Possible values are `GAUGE`, `DELTA_PER_SECOND`, and `DELTA_PER_MINUTE`.
         */
        type?: string;
    }

    export interface RegionAutoscalerAutoscalingPolicyScaleDownControl {
        /**
         * A nested object resource
         * Structure is documented below.
         */
        maxScaledDownReplicas?: outputs.compute.RegionAutoscalerAutoscalingPolicyScaleDownControlMaxScaledDownReplicas;
        /**
         * How long back autoscaling should look when computing recommendations
         * to include directives regarding slower scale down, as described above.
         */
        timeWindowSec?: number;
    }

    export interface RegionAutoscalerAutoscalingPolicyScaleDownControlMaxScaledDownReplicas {
        /**
         * Specifies a fixed number of VM instances. This must be a positive
         * integer.
         */
        fixed?: number;
        /**
         * Specifies a percentage of instances between 0 to 100%, inclusive.
         * For example, specify 80 for 80%.
         */
        percent?: number;
    }

    export interface RegionAutoscalerAutoscalingPolicyScaleInControl {
        /**
         * A nested object resource
         * Structure is documented below.
         */
        maxScaledInReplicas?: outputs.compute.RegionAutoscalerAutoscalingPolicyScaleInControlMaxScaledInReplicas;
        /**
         * How long back autoscaling should look when computing recommendations
         * to include directives regarding slower scale down, as described above.
         */
        timeWindowSec?: number;
    }

    export interface RegionAutoscalerAutoscalingPolicyScaleInControlMaxScaledInReplicas {
        /**
         * Specifies a fixed number of VM instances. This must be a positive
         * integer.
         */
        fixed?: number;
        /**
         * Specifies a percentage of instances between 0 to 100%, inclusive.
         * For example, specify 80 for 80%.
         */
        percent?: number;
    }

    export interface RegionAutoscalerAutoscalingPolicyScalingSchedule {
        /**
         * An optional description of this resource.
         */
        description?: string;
        /**
         * A boolean value that specifies if a scaling schedule can influence autoscaler recommendations. If set to true, then a scaling schedule has no effect.
         */
        disabled?: boolean;
        /**
         * The duration of time intervals (in seconds) for which this scaling schedule will be running. The minimum allowed value is 300.
         */
        durationSec: number;
        /**
         * Minimum number of VM instances that autoscaler will recommend in time intervals starting according to schedule.
         */
        minRequiredReplicas: number;
        /**
         * The identifier for this object. Format specified above.
         */
        name: string;
        /**
         * The start timestamps of time intervals when this scaling schedule should provide a scaling signal. This field uses the extended cron format (with an optional year field).
         */
        schedule: string;
        /**
         * The time zone to be used when interpreting the schedule. The value of this field must be a time zone name from the tz database: http://en.wikipedia.org/wiki/Tz_database.
         */
        timeZone?: string;
    }

    export interface RegionBackendServiceBackend {
        /**
         * Specifies the balancing mode for this backend.
         * Default value is `CONNECTION`.
         * Possible values are `UTILIZATION`, `RATE`, and `CONNECTION`.
         */
        balancingMode?: string;
        /**
         * A multiplier applied to the group's maximum servicing capacity
         * (based on UTILIZATION, RATE or CONNECTION).
         * ~>**NOTE**: This field cannot be set for
         * INTERNAL region backend services (default loadBalancingScheme),
         * but is required for non-INTERNAL backend service. The total
         * capacityScaler for all backends must be non-zero.
         * A setting of 0 means the group is completely drained, offering
         * 0% of its available Capacity. Valid range is [0.0,1.0].
         */
        capacityScaler?: number;
        /**
         * An optional description of this resource.
         * Provide this property when you create the resource.
         */
        description?: string;
        /**
         * This field designates whether this is a failover backend. More
         * than one failover backend can be configured for a given RegionBackendService.
         */
        failover: boolean;
        /**
         * The fully-qualified URL of an Instance Group or Network Endpoint
         * Group resource. In case of instance group this defines the list
         * of instances that serve traffic. Member virtual machine
         * instances from each instance group must live in the same zone as
         * the instance group itself. No two backends in a backend service
         * are allowed to use same Instance Group resource.
         * For Network Endpoint Groups this defines list of endpoints. All
         * endpoints of Network Endpoint Group must be hosted on instances
         * located in the same zone as the Network Endpoint Group.
         * Backend services cannot mix Instance Group and
         * Network Endpoint Group backends.
         * When the `loadBalancingScheme` is INTERNAL, only instance groups
         * are supported.
         * Note that you must specify an Instance Group or Network Endpoint
         * Group resource using the fully-qualified URL, rather than a
         * partial URL.
         */
        group: string;
        /**
         * The maximum number of connections to the backend cluster.
         * Defaults to 1024.
         */
        maxConnections?: number;
        /**
         * The max number of simultaneous connections that a single backend
         * network endpoint can handle. Cannot be set
         * for INTERNAL backend services.
         * This is used to calculate the capacity of the group. Can be
         * used in either CONNECTION or UTILIZATION balancing modes. For
         * CONNECTION mode, either maxConnections or
         * maxConnectionsPerEndpoint must be set.
         */
        maxConnectionsPerEndpoint?: number;
        /**
         * The max number of simultaneous connections that a single
         * backend instance can handle. Cannot be set for INTERNAL backend
         * services.
         * This is used to calculate the capacity of the group.
         * Can be used in either CONNECTION or UTILIZATION balancing modes.
         * For CONNECTION mode, either maxConnections or
         * maxConnectionsPerInstance must be set.
         */
        maxConnectionsPerInstance?: number;
        /**
         * The max requests per second (RPS) of the group. Cannot be set
         * for INTERNAL backend services.
         * Can be used with either RATE or UTILIZATION balancing modes,
         * but required if RATE mode. Either maxRate or one
         * of maxRatePerInstance or maxRatePerEndpoint, as appropriate for
         * group type, must be set.
         */
        maxRate?: number;
        /**
         * The max requests per second (RPS) that a single backend network
         * endpoint can handle. This is used to calculate the capacity of
         * the group. Can be used in either balancing mode. For RATE mode,
         * either maxRate or maxRatePerEndpoint must be set. Cannot be set
         * for INTERNAL backend services.
         */
        maxRatePerEndpoint?: number;
        /**
         * The max requests per second (RPS) that a single backend
         * instance can handle. This is used to calculate the capacity of
         * the group. Can be used in either balancing mode. For RATE mode,
         * either maxRate or maxRatePerInstance must be set. Cannot be set
         * for INTERNAL backend services.
         */
        maxRatePerInstance?: number;
        /**
         * Used when balancingMode is UTILIZATION. This ratio defines the
         * CPU utilization target for the group. Valid range is [0.0, 1.0].
         * Cannot be set for INTERNAL backend services.
         */
        maxUtilization?: number;
    }

    export interface RegionBackendServiceCdnPolicy {
        /**
         * The CacheKeyPolicy for this CdnPolicy.
         * Structure is documented below.
         */
        cacheKeyPolicy?: outputs.compute.RegionBackendServiceCdnPolicyCacheKeyPolicy;
        /**
         * Specifies the cache setting for all responses from this backend.
         * The possible values are: USE_ORIGIN_HEADERS, FORCE_CACHE_ALL and CACHE_ALL_STATIC
         * Possible values are `USE_ORIGIN_HEADERS`, `FORCE_CACHE_ALL`, and `CACHE_ALL_STATIC`.
         */
        cacheMode: string;
        /**
         * Specifies the maximum allowed TTL for cached content served by this origin.
         */
        clientTtl: number;
        /**
         * Specifies the default TTL for cached content served by this origin for responses
         * that do not have an existing valid TTL (max-age or s-max-age).
         */
        defaultTtl: number;
        /**
         * Specifies the maximum allowed TTL for cached content served by this origin.
         */
        maxTtl: number;
        /**
         * Negative caching allows per-status code TTLs to be set, in order to apply fine-grained caching for common errors or redirects.
         */
        negativeCaching: boolean;
        /**
         * Sets a cache TTL for the specified HTTP status code. negativeCaching must be enabled to configure negativeCachingPolicy.
         * Omitting the policy and leaving negativeCaching enabled will use Cloud CDN's default cache TTLs.
         * Structure is documented below.
         */
        negativeCachingPolicies?: outputs.compute.RegionBackendServiceCdnPolicyNegativeCachingPolicy[];
        /**
         * Serve existing content from the cache (if available) when revalidating content with the origin, or when an error is encountered when refreshing the cache.
         */
        serveWhileStale: number;
        /**
         * Maximum number of seconds the response to a signed URL request
         * will be considered fresh, defaults to 1hr (3600s). After this
         * time period, the response will be revalidated before
         * being served.
         * When serving responses to signed URL requests, Cloud CDN will
         * internally behave as though all responses from this backend had a
         * "Cache-Control: public, max-age=[TTL]" header, regardless of any
         * existing Cache-Control header. The actual headers served in
         * responses will not be altered.
         */
        signedUrlCacheMaxAgeSec?: number;
    }

    export interface RegionBackendServiceCdnPolicyCacheKeyPolicy {
        /**
         * If true requests to different hosts will be cached separately.
         */
        includeHost?: boolean;
        /**
         * If true, http and https requests will be cached separately.
         */
        includeProtocol?: boolean;
        /**
         * If true, include query string parameters in the cache key
         * according to queryStringWhitelist and
         * query_string_blacklist. If neither is set, the entire query
         * string will be included.
         * If false, the query string will be excluded from the cache
         * key entirely.
         */
        includeQueryString?: boolean;
        /**
         * Names of query string parameters to exclude in cache keys.
         * All other parameters will be included. Either specify
         * queryStringWhitelist or query_string_blacklist, not both.
         * '&' and '=' will be percent encoded and not treated as
         * delimiters.
         */
        queryStringBlacklists?: string[];
        /**
         * Names of query string parameters to include in cache keys.
         * All other parameters will be excluded. Either specify
         * queryStringWhitelist or query_string_blacklist, not both.
         * '&' and '=' will be percent encoded and not treated as
         * delimiters.
         */
        queryStringWhitelists?: string[];
    }

    export interface RegionBackendServiceCdnPolicyNegativeCachingPolicy {
        /**
         * The HTTP status code to define a TTL against. Only HTTP status codes 300, 301, 308, 404, 405, 410, 421, 451 and 501
         * can be specified as values, and you cannot specify a status code more than once.
         */
        code?: number;
        /**
         * The TTL (in seconds) for which to cache responses with the corresponding status code. The maximum allowed value is 1800s
         * (30 minutes), noting that infrequently accessed objects may be evicted from the cache before the defined TTL.
         */
        ttl?: number;
    }

    export interface RegionBackendServiceCircuitBreakers {
        /**
         * The timeout for new network connections to hosts.
         * Structure is documented below.
         */
        connectTimeout?: outputs.compute.RegionBackendServiceCircuitBreakersConnectTimeout;
        /**
         * The maximum number of connections to the backend cluster.
         * Defaults to 1024.
         */
        maxConnections?: number;
        /**
         * The maximum number of pending requests to the backend cluster.
         * Defaults to 1024.
         */
        maxPendingRequests?: number;
        /**
         * The maximum number of parallel requests to the backend cluster.
         * Defaults to 1024.
         */
        maxRequests?: number;
        /**
         * Maximum requests for a single backend connection. This parameter
         * is respected by both the HTTP/1.1 and HTTP/2 implementations. If
         * not specified, there is no limit. Setting this parameter to 1
         * will effectively disable keep alive.
         */
        maxRequestsPerConnection?: number;
        /**
         * The maximum number of parallel retries to the backend cluster.
         * Defaults to 3.
         */
        maxRetries?: number;
    }

    export interface RegionBackendServiceCircuitBreakersConnectTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: number;
    }

    export interface RegionBackendServiceConnectionTrackingPolicy {
        /**
         * Specifies connection persistence when backends are unhealthy.
         * If set to `DEFAULT_FOR_PROTOCOL`, the existing connections persist on
         * unhealthy backends only for connection-oriented protocols (TCP and SCTP)
         * and only if the Tracking Mode is PER_CONNECTION (default tracking mode)
         * or the Session Affinity is configured for 5-tuple. They do not persist
         * for UDP.
         * If set to `NEVER_PERSIST`, after a backend becomes unhealthy, the existing
         * connections on the unhealthy backend are never persisted on the unhealthy
         * backend. They are always diverted to newly selected healthy backends
         * (unless all backends are unhealthy).
         * If set to `ALWAYS_PERSIST`, existing connections always persist on
         * unhealthy backends regardless of protocol and session affinity. It is
         * generally not recommended to use this mode overriding the default.
         * Default value is `DEFAULT_FOR_PROTOCOL`.
         * Possible values are `DEFAULT_FOR_PROTOCOL`, `NEVER_PERSIST`, and `ALWAYS_PERSIST`.
         */
        connectionPersistenceOnUnhealthyBackends?: string;
        /**
         * Specifies how long to keep a Connection Tracking entry while there is
         * no matching traffic (in seconds).
         * For L4 ILB the minimum(default) is 10 minutes and maximum is 16 hours.
         * For NLB the minimum(default) is 60 seconds and the maximum is 16 hours.
         */
        idleTimeoutSec: number;
        /**
         * Specifies the key used for connection tracking. There are two options:
         * `PER_CONNECTION`: The Connection Tracking is performed as per the
         * Connection Key (default Hash Method) for the specific protocol.
         * `PER_SESSION`: The Connection Tracking is performed as per the
         * configured Session Affinity. It matches the configured Session Affinity.
         * Default value is `PER_CONNECTION`.
         * Possible values are `PER_CONNECTION` and `PER_SESSION`.
         */
        trackingMode?: string;
    }

    export interface RegionBackendServiceConsistentHash {
        /**
         * Hash is based on HTTP Cookie. This field describes a HTTP cookie
         * that will be used as the hash key for the consistent hash load
         * balancer. If the cookie is not present, it will be generated.
         * This field is applicable if the sessionAffinity is set to HTTP_COOKIE.
         * Structure is documented below.
         */
        httpCookie?: outputs.compute.RegionBackendServiceConsistentHashHttpCookie;
        /**
         * The hash based on the value of the specified header field.
         * This field is applicable if the sessionAffinity is set to HEADER_FIELD.
         */
        httpHeaderName?: string;
        /**
         * The minimum number of virtual nodes to use for the hash ring.
         * Larger ring sizes result in more granular load
         * distributions. If the number of hosts in the load balancing pool
         * is larger than the ring size, each host will be assigned a single
         * virtual node.
         * Defaults to 1024.
         */
        minimumRingSize?: number;
    }

    export interface RegionBackendServiceConsistentHashHttpCookie {
        /**
         * Name of the cookie.
         */
        name?: string;
        /**
         * Path to set for the cookie.
         */
        path?: string;
        /**
         * The TTL (in seconds) for which to cache responses with the corresponding status code. The maximum allowed value is 1800s
         * (30 minutes), noting that infrequently accessed objects may be evicted from the cache before the defined TTL.
         */
        ttl?: outputs.compute.RegionBackendServiceConsistentHashHttpCookieTtl;
    }

    export interface RegionBackendServiceConsistentHashHttpCookieTtl {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: number;
    }

    export interface RegionBackendServiceFailoverPolicy {
        /**
         * On failover or failback, this field indicates whether connection drain
         * will be honored. Setting this to true has the following effect: connections
         * to the old active pool are not drained. Connections to the new active pool
         * use the timeout of 10 min (currently fixed). Setting to false has the
         * following effect: both old and new connections will have a drain timeout
         * of 10 min.
         * This can be set to true only if the protocol is TCP.
         * The default is false.
         */
        disableConnectionDrainOnFailover?: boolean;
        /**
         * This option is used only when no healthy VMs are detected in the primary
         * and backup instance groups. When set to true, traffic is dropped. When
         * set to false, new connections are sent across all VMs in the primary group.
         * The default is false.
         */
        dropTrafficIfUnhealthy?: boolean;
        /**
         * The value of the field must be in [0, 1]. If the ratio of the healthy
         * VMs in the primary backend is at or below this number, traffic arriving
         * at the load-balanced IP will be directed to the failover backend.
         * In case where 'failoverRatio' is not set or all the VMs in the backup
         * backend are unhealthy, the traffic will be directed back to the primary
         * backend in the "force" mode, where traffic will be spread to the healthy
         * VMs with the best effort, or to all VMs when no VM is healthy.
         * This field is only used with l4 load balancing.
         */
        failoverRatio?: number;
    }

    export interface RegionBackendServiceIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface RegionBackendServiceIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface RegionBackendServiceIap {
        /**
         * OAuth2 Client ID for IAP
         */
        oauth2ClientId: string;
        /**
         * OAuth2 Client Secret for IAP
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        oauth2ClientSecret: string;
        /**
         * -
         * OAuth2 Client Secret SHA-256 for IAP
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        oauth2ClientSecretSha256: string;
    }

    export interface RegionBackendServiceLogConfig {
        /**
         * Whether to enable logging for the load balancer traffic served by this backend service.
         */
        enable?: boolean;
        /**
         * This field can only be specified if logging is enabled for this backend service. The value of
         * the field must be in [0, 1]. This configures the sampling rate of requests to the load balancer
         * where 1.0 means all logged requests are reported and 0.0 means no logged requests are reported.
         * The default value is 1.0.
         */
        sampleRate?: number;
    }

    export interface RegionBackendServiceOutlierDetection {
        /**
         * The base time that a host is ejected for. The real time is equal to the base
         * time multiplied by the number of times the host has been ejected. Defaults to
         * 30000ms or 30s.
         * Structure is documented below.
         */
        baseEjectionTime?: outputs.compute.RegionBackendServiceOutlierDetectionBaseEjectionTime;
        /**
         * Number of errors before a host is ejected from the connection pool. When the
         * backend host is accessed over HTTP, a 5xx return code qualifies as an error.
         * Defaults to 5.
         */
        consecutiveErrors?: number;
        /**
         * The number of consecutive gateway failures (502, 503, 504 status or connection
         * errors that are mapped to one of those status codes) before a consecutive
         * gateway failure ejection occurs. Defaults to 5.
         */
        consecutiveGatewayFailure?: number;
        /**
         * The percentage chance that a host will be actually ejected when an outlier
         * status is detected through consecutive 5xx. This setting can be used to disable
         * ejection or to ramp it up slowly. Defaults to 100.
         */
        enforcingConsecutiveErrors?: number;
        /**
         * The percentage chance that a host will be actually ejected when an outlier
         * status is detected through consecutive gateway failures. This setting can be
         * used to disable ejection or to ramp it up slowly. Defaults to 0.
         */
        enforcingConsecutiveGatewayFailure?: number;
        /**
         * The percentage chance that a host will be actually ejected when an outlier
         * status is detected through success rate statistics. This setting can be used to
         * disable ejection or to ramp it up slowly. Defaults to 100.
         */
        enforcingSuccessRate?: number;
        /**
         * Time interval between ejection sweep analysis. This can result in both new
         * ejections as well as hosts being returned to service. Defaults to 10 seconds.
         * Structure is documented below.
         */
        interval?: outputs.compute.RegionBackendServiceOutlierDetectionInterval;
        /**
         * Maximum percentage of hosts in the load balancing pool for the backend service
         * that can be ejected. Defaults to 10%.
         */
        maxEjectionPercent?: number;
        /**
         * The number of hosts in a cluster that must have enough request volume to detect
         * success rate outliers. If the number of hosts is less than this setting, outlier
         * detection via success rate statistics is not performed for any host in the
         * cluster. Defaults to 5.
         */
        successRateMinimumHosts?: number;
        /**
         * The minimum number of total requests that must be collected in one interval (as
         * defined by the interval duration above) to include this host in success rate
         * based outlier detection. If the volume is lower than this setting, outlier
         * detection via success rate statistics is not performed for that host. Defaults
         * to 100.
         */
        successRateRequestVolume?: number;
        /**
         * This factor is used to determine the ejection threshold for success rate outlier
         * ejection. The ejection threshold is the difference between the mean success
         * rate, and the product of this factor and the standard deviation of the mean
         * success rate: mean - (stdev * success_rate_stdev_factor). This factor is divided
         * by a thousand to get a double. That is, if the desired factor is 1.9, the
         * runtime value should be 1900. Defaults to 1900.
         */
        successRateStdevFactor?: number;
    }

    export interface RegionBackendServiceOutlierDetectionBaseEjectionTime {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: number;
    }

    export interface RegionBackendServiceOutlierDetectionInterval {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: number;
    }

    export interface RegionBackendServiceSubsetting {
        /**
         * The algorithm used for subsetting.
         * Possible values are `CONSISTENT_HASH_SUBSETTING`.
         */
        policy: string;
    }

    export interface RegionDiskDiskEncryptionKey {
        /**
         * The name of the encryption key that is stored in Google Cloud KMS.
         */
        kmsKeyName?: string;
        /**
         * Specifies a 256-bit customer-supplied encryption key, encoded in
         * RFC 4648 base64 to either encrypt or decrypt this resource.
         */
        rawKey?: string;
        /**
         * -
         * The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied
         * encryption key that protects this resource.
         */
        sha256: string;
    }

    export interface RegionDiskIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface RegionDiskIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface RegionDiskSourceSnapshotEncryptionKey {
        /**
         * The name of the encryption key that is stored in Google Cloud KMS.
         */
        kmsKeyName?: string;
        /**
         * Specifies a 256-bit customer-supplied encryption key, encoded in
         * RFC 4648 base64 to either encrypt or decrypt this resource.
         */
        rawKey?: string;
        /**
         * -
         * The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied
         * encryption key that protects this resource.
         */
        sha256: string;
    }

    export interface RegionHealthCheckGrpcHealthCheck {
        /**
         * The gRPC service name for the health check.
         * The value of grpcServiceName has the following meanings by convention:
         * * Empty serviceName means the overall status of all services at the backend.
         * * Non-empty serviceName means the health of that gRPC service, as defined by the owner of the service.
         * The grpcServiceName can only be ASCII.
         */
        grpcServiceName?: string;
        /**
         * The port number for the health check request.
         * Must be specified if portName and portSpecification are not set
         * or if portSpecification is USE_FIXED_PORT. Valid values are 1 through 65535.
         */
        port?: number;
        /**
         * Port name as defined in InstanceGroup#NamedPort#name. If both port and
         * portName are defined, port takes precedence.
         */
        portName?: string;
        /**
         * Specifies how port is selected for health checking, can be one of the
         * following values:
         * * `USE_FIXED_PORT`: The port number in `port` is used for health checking.
         * * `USE_NAMED_PORT`: The `portName` is used for health checking.
         * * `USE_SERVING_PORT`: For NetworkEndpointGroup, the port specified for each
         * network endpoint is used for health checking. For other backends, the
         * port or named port specified in the Backend Service is used for health
         * checking.
         * If not specified, gRPC health check follows behavior specified in `port` and
         * `portName` fields.
         * Possible values are `USE_FIXED_PORT`, `USE_NAMED_PORT`, and `USE_SERVING_PORT`.
         */
        portSpecification?: string;
    }

    export interface RegionHealthCheckHttp2HealthCheck {
        /**
         * The value of the host header in the HTTP2 health check request.
         * If left empty (default value), the public IP on behalf of which this health
         * check is performed will be used.
         */
        host?: string;
        /**
         * The port number for the health check request.
         * Must be specified if portName and portSpecification are not set
         * or if portSpecification is USE_FIXED_PORT. Valid values are 1 through 65535.
         */
        port?: number;
        /**
         * Port name as defined in InstanceGroup#NamedPort#name. If both port and
         * portName are defined, port takes precedence.
         */
        portName?: string;
        /**
         * Specifies how port is selected for health checking, can be one of the
         * following values:
         * * `USE_FIXED_PORT`: The port number in `port` is used for health checking.
         * * `USE_NAMED_PORT`: The `portName` is used for health checking.
         * * `USE_SERVING_PORT`: For NetworkEndpointGroup, the port specified for each
         * network endpoint is used for health checking. For other backends, the
         * port or named port specified in the Backend Service is used for health
         * checking.
         * If not specified, gRPC health check follows behavior specified in `port` and
         * `portName` fields.
         * Possible values are `USE_FIXED_PORT`, `USE_NAMED_PORT`, and `USE_SERVING_PORT`.
         */
        portSpecification?: string;
        /**
         * Specifies the type of proxy header to append before sending data to the
         * backend.
         * Default value is `NONE`.
         * Possible values are `NONE` and `PROXY_V1`.
         */
        proxyHeader?: string;
        /**
         * The request path of the HTTP2 health check request.
         * The default value is /.
         */
        requestPath?: string;
        /**
         * The bytes to match against the beginning of the response data. If left empty
         * (the default value), any response will indicate health. The response data
         * can only be ASCII.
         */
        response?: string;
    }

    export interface RegionHealthCheckHttpHealthCheck {
        /**
         * The value of the host header in the HTTP2 health check request.
         * If left empty (default value), the public IP on behalf of which this health
         * check is performed will be used.
         */
        host?: string;
        /**
         * The port number for the health check request.
         * Must be specified if portName and portSpecification are not set
         * or if portSpecification is USE_FIXED_PORT. Valid values are 1 through 65535.
         */
        port?: number;
        /**
         * Port name as defined in InstanceGroup#NamedPort#name. If both port and
         * portName are defined, port takes precedence.
         */
        portName?: string;
        /**
         * Specifies how port is selected for health checking, can be one of the
         * following values:
         * * `USE_FIXED_PORT`: The port number in `port` is used for health checking.
         * * `USE_NAMED_PORT`: The `portName` is used for health checking.
         * * `USE_SERVING_PORT`: For NetworkEndpointGroup, the port specified for each
         * network endpoint is used for health checking. For other backends, the
         * port or named port specified in the Backend Service is used for health
         * checking.
         * If not specified, gRPC health check follows behavior specified in `port` and
         * `portName` fields.
         * Possible values are `USE_FIXED_PORT`, `USE_NAMED_PORT`, and `USE_SERVING_PORT`.
         */
        portSpecification?: string;
        /**
         * Specifies the type of proxy header to append before sending data to the
         * backend.
         * Default value is `NONE`.
         * Possible values are `NONE` and `PROXY_V1`.
         */
        proxyHeader?: string;
        /**
         * The request path of the HTTP2 health check request.
         * The default value is /.
         */
        requestPath?: string;
        /**
         * The bytes to match against the beginning of the response data. If left empty
         * (the default value), any response will indicate health. The response data
         * can only be ASCII.
         */
        response?: string;
    }

    export interface RegionHealthCheckHttpsHealthCheck {
        /**
         * The value of the host header in the HTTP2 health check request.
         * If left empty (default value), the public IP on behalf of which this health
         * check is performed will be used.
         */
        host?: string;
        /**
         * The port number for the health check request.
         * Must be specified if portName and portSpecification are not set
         * or if portSpecification is USE_FIXED_PORT. Valid values are 1 through 65535.
         */
        port?: number;
        /**
         * Port name as defined in InstanceGroup#NamedPort#name. If both port and
         * portName are defined, port takes precedence.
         */
        portName?: string;
        /**
         * Specifies how port is selected for health checking, can be one of the
         * following values:
         * * `USE_FIXED_PORT`: The port number in `port` is used for health checking.
         * * `USE_NAMED_PORT`: The `portName` is used for health checking.
         * * `USE_SERVING_PORT`: For NetworkEndpointGroup, the port specified for each
         * network endpoint is used for health checking. For other backends, the
         * port or named port specified in the Backend Service is used for health
         * checking.
         * If not specified, gRPC health check follows behavior specified in `port` and
         * `portName` fields.
         * Possible values are `USE_FIXED_PORT`, `USE_NAMED_PORT`, and `USE_SERVING_PORT`.
         */
        portSpecification?: string;
        /**
         * Specifies the type of proxy header to append before sending data to the
         * backend.
         * Default value is `NONE`.
         * Possible values are `NONE` and `PROXY_V1`.
         */
        proxyHeader?: string;
        /**
         * The request path of the HTTP2 health check request.
         * The default value is /.
         */
        requestPath?: string;
        /**
         * The bytes to match against the beginning of the response data. If left empty
         * (the default value), any response will indicate health. The response data
         * can only be ASCII.
         */
        response?: string;
    }

    export interface RegionHealthCheckLogConfig {
        /**
         * Indicates whether or not to export logs. This is false by default,
         * which means no health check logging will be done.
         */
        enable?: boolean;
    }

    export interface RegionHealthCheckSslHealthCheck {
        /**
         * The port number for the health check request.
         * Must be specified if portName and portSpecification are not set
         * or if portSpecification is USE_FIXED_PORT. Valid values are 1 through 65535.
         */
        port?: number;
        /**
         * Port name as defined in InstanceGroup#NamedPort#name. If both port and
         * portName are defined, port takes precedence.
         */
        portName?: string;
        /**
         * Specifies how port is selected for health checking, can be one of the
         * following values:
         * * `USE_FIXED_PORT`: The port number in `port` is used for health checking.
         * * `USE_NAMED_PORT`: The `portName` is used for health checking.
         * * `USE_SERVING_PORT`: For NetworkEndpointGroup, the port specified for each
         * network endpoint is used for health checking. For other backends, the
         * port or named port specified in the Backend Service is used for health
         * checking.
         * If not specified, gRPC health check follows behavior specified in `port` and
         * `portName` fields.
         * Possible values are `USE_FIXED_PORT`, `USE_NAMED_PORT`, and `USE_SERVING_PORT`.
         */
        portSpecification?: string;
        /**
         * Specifies the type of proxy header to append before sending data to the
         * backend.
         * Default value is `NONE`.
         * Possible values are `NONE` and `PROXY_V1`.
         */
        proxyHeader?: string;
        /**
         * The application data to send once the SSL connection has been
         * established (default value is empty). If both request and response are
         * empty, the connection establishment alone will indicate health. The request
         * data can only be ASCII.
         */
        request?: string;
        /**
         * The bytes to match against the beginning of the response data. If left empty
         * (the default value), any response will indicate health. The response data
         * can only be ASCII.
         */
        response?: string;
    }

    export interface RegionHealthCheckTcpHealthCheck {
        /**
         * The port number for the health check request.
         * Must be specified if portName and portSpecification are not set
         * or if portSpecification is USE_FIXED_PORT. Valid values are 1 through 65535.
         */
        port?: number;
        /**
         * Port name as defined in InstanceGroup#NamedPort#name. If both port and
         * portName are defined, port takes precedence.
         */
        portName?: string;
        /**
         * Specifies how port is selected for health checking, can be one of the
         * following values:
         * * `USE_FIXED_PORT`: The port number in `port` is used for health checking.
         * * `USE_NAMED_PORT`: The `portName` is used for health checking.
         * * `USE_SERVING_PORT`: For NetworkEndpointGroup, the port specified for each
         * network endpoint is used for health checking. For other backends, the
         * port or named port specified in the Backend Service is used for health
         * checking.
         * If not specified, gRPC health check follows behavior specified in `port` and
         * `portName` fields.
         * Possible values are `USE_FIXED_PORT`, `USE_NAMED_PORT`, and `USE_SERVING_PORT`.
         */
        portSpecification?: string;
        /**
         * Specifies the type of proxy header to append before sending data to the
         * backend.
         * Default value is `NONE`.
         * Possible values are `NONE` and `PROXY_V1`.
         */
        proxyHeader?: string;
        /**
         * The application data to send once the SSL connection has been
         * established (default value is empty). If both request and response are
         * empty, the connection establishment alone will indicate health. The request
         * data can only be ASCII.
         */
        request?: string;
        /**
         * The bytes to match against the beginning of the response data. If left empty
         * (the default value), any response will indicate health. The response data
         * can only be ASCII.
         */
        response?: string;
    }

    export interface RegionInstanceGroupManagerAutoHealingPolicies {
        /**
         * The health check resource that signals autohealing.
         */
        healthCheck: string;
        /**
         * The number of seconds that the managed instance group waits before
         * it applies autohealing policies to new instances or recently recreated instances. Between 0 and 3600.
         */
        initialDelaySec: number;
    }

    export interface RegionInstanceGroupManagerNamedPort {
        /**
         * - Version name.
         */
        name: string;
        /**
         * The port number.
         * - - -
         */
        port: number;
    }

    export interface RegionInstanceGroupManagerStatefulDisk {
        /**
         * , A value that prescribes what should happen to the stateful disk when the VM instance is deleted. The available options are `NEVER` and `ON_PERMANENT_INSTANCE_DELETION`. `NEVER` - detach the disk when the VM is deleted, but do not delete the disk. `ON_PERMANENT_INSTANCE_DELETION` will delete the stateful disk when the VM is permanently deleted from the instance group. The default is `NEVER`.
         */
        deleteRule?: string;
        /**
         * , The device name of the disk to be attached.
         */
        deviceName: string;
    }

    export interface RegionInstanceGroupManagerStatus {
        /**
         * A bit indicating whether the managed instance group is in a stable state. A stable state means that: none of the instances in the managed instance group is currently undergoing any type of change (for example, creation, restart, or deletion); no future changes are scheduled for instances in the managed instance group; and the managed instance group itself is not being modified.
         */
        isStable: boolean;
        /**
         * Stateful status of the given Instance Group Manager.
         */
        statefuls: outputs.compute.RegionInstanceGroupManagerStatusStateful[];
        /**
         * A bit indicating whether version target has been reached in this managed instance group, i.e. all instances are in their target version. Instances' target version are specified by version field on Instance Group Manager.
         */
        versionTargets: outputs.compute.RegionInstanceGroupManagerStatusVersionTarget[];
    }

    export interface RegionInstanceGroupManagerStatusStateful {
        /**
         * A bit indicating whether the managed instance group has stateful configuration, that is, if you have configured any items in a stateful policy or in per-instance configs. The group might report that it has no stateful config even when there is still some preserved state on a managed instance, for example, if you have deleted all PICs but not yet applied those deletions.
         */
        hasStatefulConfig: boolean;
        /**
         * Status of per-instance configs on the instance.
         */
        perInstanceConfigs: outputs.compute.RegionInstanceGroupManagerStatusStatefulPerInstanceConfig[];
    }

    export interface RegionInstanceGroupManagerStatusStatefulPerInstanceConfig {
        /**
         * A bit indicating if all of the group's per-instance configs (listed in the output of a listPerInstanceConfigs API call) have status `EFFECTIVE` or there are no per-instance-configs.
         */
        allEffective: boolean;
    }

    export interface RegionInstanceGroupManagerStatusVersionTarget {
        isReached: boolean;
    }

    export interface RegionInstanceGroupManagerUpdatePolicy {
        /**
         * - The instance redistribution policy for regional managed instance groups. Valid values are: `"PROACTIVE"`, `"NONE"`. If `PROACTIVE` (default), the group attempts to maintain an even distribution of VM instances across zones in the region. If `NONE`, proactive redistribution is disabled.
         */
        instanceRedistributionType?: string;
        /**
         * , The maximum number of instances that can be created above the specified targetSize during the update process. Conflicts with `maxSurgePercent`. It has to be either 0 or at least equal to the number of zones.  If fixed values are used, at least one of `maxUnavailableFixed` or `maxSurgeFixed` must be greater than 0.
         */
        maxSurgeFixed: number;
        /**
         * , The maximum number of instances(calculated as percentage) that can be created above the specified targetSize during the update process. Conflicts with `maxSurgeFixed`. Percent value is only allowed for regional managed instance groups with size at least 10.
         */
        maxSurgePercent?: number;
        /**
         * , The maximum number of instances that can be unavailable during the update process. Conflicts with `maxUnavailablePercent`. It has to be either 0 or at least equal to the number of zones. If fixed values are used, at least one of `maxUnavailableFixed` or `maxSurgeFixed` must be greater than 0.
         */
        maxUnavailableFixed: number;
        /**
         * , The maximum number of instances(calculated as percentage) that can be unavailable during the update process. Conflicts with `maxUnavailableFixed`. Percent value is only allowed for regional managed instance groups with size at least 10.
         */
        maxUnavailablePercent?: number;
        /**
         * ), Minimum number of seconds to wait for after a newly created instance becomes available. This value must be from range [0, 3600]
         */
        minReadySec?: number;
        /**
         * - Minimal action to be taken on an instance. You can specify either `REFRESH` to update without stopping instances, `RESTART` to restart existing instances or `REPLACE` to delete and create new instances from the target template. If you specify a `REFRESH`, the Updater will attempt to perform that action only. However, if the Updater determines that the minimal action you specify is not enough to perform the update, it might perform a more disruptive action.
         */
        minimalAction: string;
        /**
         * - Most disruptive action that is allowed to be taken on an instance. You can specify either NONE to forbid any actions, REFRESH to allow actions that do not need instance restart, RESTART to allow actions that can be applied without instance replacing or REPLACE to allow all possible actions. If the Updater determines that the minimal update action needed is more disruptive than most disruptive allowed action you specify it will not perform the update at all.
         */
        mostDisruptiveAllowedAction?: string;
        /**
         * , The instance replacement method for managed instance groups. Valid values are: "RECREATE", "SUBSTITUTE". If SUBSTITUTE (default), the group replaces VM instances with new instances that have randomly generated names. If RECREATE, instance names are preserved.  You must also set maxUnavailableFixed or maxUnavailablePercent to be greater than 0.
         * - - -
         */
        replacementMethod?: string;
        /**
         * - The type of update process. You can specify either `PROACTIVE` so that the instance group manager proactively executes actions in order to bring instances to their target versions or `OPPORTUNISTIC` so that no action is proactively executed but the update will be performed as part of other actions (for example, resizes or recreateInstances calls).
         */
        type: string;
    }

    export interface RegionInstanceGroupManagerVersion {
        /**
         * - The full URL to an instance template from which all new instances of this version will be created.
         */
        instanceTemplate: string;
        /**
         * - Version name.
         */
        name?: string;
        /**
         * - The number of instances calculated as a fixed number or a percentage depending on the settings. Structure is documented below.
         */
        targetSize?: outputs.compute.RegionInstanceGroupManagerVersionTargetSize;
    }

    export interface RegionInstanceGroupManagerVersionTargetSize {
        /**
         * , The number of instances which are managed for this version. Conflicts with `percent`.
         */
        fixed?: number;
        /**
         * , The number of instances (calculated as percentage) which are managed for this version. Conflicts with `fixed`.
         * Note that when using `percent`, rounding will be in favor of explicitly set `targetSize` values; a managed instance group with 2 instances and 2 `version`s,
         * one of which has a `target_size.percent` of `60` will create 2 instances of that `version`.
         */
        percent?: number;
    }

    export interface RegionNetworkEndpointGroupAppEngine {
        /**
         * Optional serving service.
         * The service name must be 1-63 characters long, and comply with RFC1035.
         * Example value: "default", "my-service".
         */
        service?: string;
        /**
         * A template to parse platform-specific fields from a request URL. URL mask allows for routing to multiple resources
         * on the same serverless platform without having to create multiple Network Endpoint Groups and backend resources.
         * The fields parsed by this template are platform-specific and are as follows: API Gateway: The gateway ID,
         * App Engine: The service and version, Cloud Functions: The function name, Cloud Run: The service and tag
         */
        urlMask?: string;
        /**
         * The optional resource version. The version identified by this value is platform-specific and is follows:
         * API Gateway: Unused, App Engine: The service version, Cloud Functions: Unused, Cloud Run: The service tag
         */
        version?: string;
    }

    export interface RegionNetworkEndpointGroupCloudFunction {
        /**
         * A user-defined name of the Cloud Function.
         * The function name is case-sensitive and must be 1-63 characters long.
         * Example value: "func1".
         */
        function?: string;
        /**
         * A template to parse platform-specific fields from a request URL. URL mask allows for routing to multiple resources
         * on the same serverless platform without having to create multiple Network Endpoint Groups and backend resources.
         * The fields parsed by this template are platform-specific and are as follows: API Gateway: The gateway ID,
         * App Engine: The service and version, Cloud Functions: The function name, Cloud Run: The service and tag
         */
        urlMask?: string;
    }

    export interface RegionNetworkEndpointGroupCloudRun {
        /**
         * Optional serving service.
         * The service name must be 1-63 characters long, and comply with RFC1035.
         * Example value: "default", "my-service".
         */
        service?: string;
        /**
         * Cloud Run tag represents the "named-revision" to provide
         * additional fine-grained traffic routing information.
         * The tag must be 1-63 characters long, and comply with RFC1035.
         * Example value: "revision-0010".
         */
        tag?: string;
        /**
         * A template to parse platform-specific fields from a request URL. URL mask allows for routing to multiple resources
         * on the same serverless platform without having to create multiple Network Endpoint Groups and backend resources.
         * The fields parsed by this template are platform-specific and are as follows: API Gateway: The gateway ID,
         * App Engine: The service and version, Cloud Functions: The function name, Cloud Run: The service and tag
         */
        urlMask?: string;
    }

    export interface RegionNetworkEndpointGroupServerlessDeployment {
        /**
         * The platform of the NEG backend target(s). Possible values:
         * API Gateway: apigateway.googleapis.com
         */
        platform: string;
        /**
         * The user-defined name of the workload/instance. This value must be provided explicitly or in the urlMask.
         * The resource identified by this value is platform-specific and is as follows: API Gateway: The gateway ID, App Engine: The service name,
         * Cloud Functions: The function name, Cloud Run: The service name
         */
        resource?: string;
        /**
         * A template to parse platform-specific fields from a request URL. URL mask allows for routing to multiple resources
         * on the same serverless platform without having to create multiple Network Endpoint Groups and backend resources.
         * The fields parsed by this template are platform-specific and are as follows: API Gateway: The gateway ID,
         * App Engine: The service and version, Cloud Functions: The function name, Cloud Run: The service and tag
         */
        urlMask?: string;
        /**
         * The optional resource version. The version identified by this value is platform-specific and is follows:
         * API Gateway: Unused, App Engine: The service version, Cloud Functions: Unused, Cloud Run: The service tag
         */
        version?: string;
    }

    export interface RegionPerInstanceConfigPreservedState {
        /**
         * Stateful disks for the instance.
         * Structure is documented below.
         */
        disks?: outputs.compute.RegionPerInstanceConfigPreservedStateDisk[];
        /**
         * Preserved metadata defined for this instance. This is a list of key->value pairs.
         */
        metadata?: {[key: string]: string};
    }

    export interface RegionPerInstanceConfigPreservedStateDisk {
        /**
         * A value that prescribes what should happen to the stateful disk when the VM instance is deleted.
         * The available options are `NEVER` and `ON_PERMANENT_INSTANCE_DELETION`.
         * `NEVER` - detach the disk when the VM is deleted, but do not delete the disk.
         * `ON_PERMANENT_INSTANCE_DELETION` will delete the stateful disk when the VM is permanently
         * deleted from the instance group.
         * Default value is `NEVER`.
         * Possible values are `NEVER` and `ON_PERMANENT_INSTANCE_DELETION`.
         */
        deleteRule?: string;
        /**
         * A unique device name that is reflected into the /dev/ tree of a Linux operating system running within the instance.
         */
        deviceName: string;
        /**
         * The mode of the disk.
         * Default value is `READ_WRITE`.
         * Possible values are `READ_ONLY` and `READ_WRITE`.
         */
        mode?: string;
        /**
         * The URI of an existing persistent disk to attach under the specified device-name in the format
         * `projects/project-id/zones/zone/disks/disk-name`.
         */
        source: string;
    }

    export interface RegionUrlMapDefaultUrlRedirect {
        /**
         * The host that will be used in the redirect response instead of the one that was
         * supplied in the request. The value must be between 1 and 255 characters.
         */
        hostRedirect?: string;
        /**
         * If set to true, the URL scheme in the redirected request is set to https. If set to
         * false, the URL scheme of the redirected request will remain the same as that of the
         * request. This must only be set for UrlMaps used in TargetHttpProxys. Setting this
         * true for TargetHttpsProxy is not permitted. The default is set to false.
         */
        httpsRedirect?: boolean;
        /**
         * The path that will be used in the redirect response instead of the one that was
         * supplied in the request. pathRedirect cannot be supplied together with
         * prefixRedirect. Supply one alone or neither. If neither is supplied, the path of the
         * original request will be used for the redirect. The value must be between 1 and 1024
         * characters.
         */
        pathRedirect?: string;
        /**
         * The prefix that replaces the prefixMatch specified in the HttpRouteRuleMatch,
         * retaining the remaining portion of the URL before redirecting the request.
         * prefixRedirect cannot be supplied together with pathRedirect. Supply one alone or
         * neither. If neither is supplied, the path of the original request will be used for
         * the redirect. The value must be between 1 and 1024 characters.
         */
        prefixRedirect?: string;
        /**
         * The HTTP Status code to use for this RedirectAction. Supported values are:
         * * MOVED_PERMANENTLY_DEFAULT, which is the default value and corresponds to 301.
         * * FOUND, which corresponds to 302.
         * * SEE_OTHER which corresponds to 303.
         * * TEMPORARY_REDIRECT, which corresponds to 307. In this case, the request method
         * will be retained.
         * * PERMANENT_REDIRECT, which corresponds to 308. In this case,
         * the request method will be retained.
         */
        redirectResponseCode?: string;
        /**
         * If set to true, any accompanying query portion of the original URL is removed prior
         * to redirecting the request. If set to false, the query portion of the original URL is
         * retained.
         * This field is required to ensure an empty block is not set. The normal default value is false.
         */
        stripQuery: boolean;
    }

    export interface RegionUrlMapHostRule {
        /**
         * Description of this test case.
         */
        description?: string;
        /**
         * The list of host patterns to match. They must be valid
         * hostnames, except * will match any string of ([a-z0-9-.]*). In
         * that case, * must be the first character and must be followed in
         * the pattern by either - or ..
         */
        hosts: string[];
        /**
         * The name of the PathMatcher to use to match the path portion of
         * the URL if the hostRule matches the URL's host portion.
         */
        pathMatcher: string;
    }

    export interface RegionUrlMapPathMatcher {
        /**
         * A reference to a RegionBackendService resource. This will be used if
         * none of the pathRules defined by this PathMatcher is matched by
         * the URL's path portion.
         */
        defaultService?: string;
        /**
         * When none of the specified hostRules match, the request is redirected to a URL specified
         * by defaultUrlRedirect. If defaultUrlRedirect is specified, defaultService or
         * defaultRouteAction must not be set.
         * Structure is documented below.
         */
        defaultUrlRedirect?: outputs.compute.RegionUrlMapPathMatcherDefaultUrlRedirect;
        /**
         * Description of this test case.
         */
        description?: string;
        /**
         * The name of the query parameter to match. The query parameter must exist in the
         * request, in the absence of which the request match fails.
         */
        name: string;
        /**
         * The list of path rules. Use this list instead of routeRules when routing based
         * on simple path matching is all that's required. The order by which path rules
         * are specified does not matter. Matches are always done on the longest-path-first
         * basis. For example: a pathRule with a path /a/b/c/* will match before /a/b/*
         * irrespective of the order in which those paths appear in this list. Within a
         * given pathMatcher, only one of pathRules or routeRules must be set.
         * Structure is documented below.
         */
        pathRules?: outputs.compute.RegionUrlMapPathMatcherPathRule[];
        /**
         * The list of ordered HTTP route rules. Use this list instead of pathRules when
         * advanced route matching and routing actions are desired. The order of specifying
         * routeRules matters: the first rule that matches will cause its specified routing
         * action to take effect. Within a given pathMatcher, only one of pathRules or
         * routeRules must be set. routeRules are not supported in UrlMaps intended for
         * External load balancers.
         * Structure is documented below.
         */
        routeRules?: outputs.compute.RegionUrlMapPathMatcherRouteRule[];
    }

    export interface RegionUrlMapPathMatcherDefaultUrlRedirect {
        /**
         * The host that will be used in the redirect response instead of the one that was
         * supplied in the request. The value must be between 1 and 255 characters.
         */
        hostRedirect?: string;
        /**
         * If set to true, the URL scheme in the redirected request is set to https. If set to
         * false, the URL scheme of the redirected request will remain the same as that of the
         * request. This must only be set for UrlMaps used in TargetHttpProxys. Setting this
         * true for TargetHttpsProxy is not permitted. The default is set to false.
         */
        httpsRedirect?: boolean;
        /**
         * The path that will be used in the redirect response instead of the one that was
         * supplied in the request. pathRedirect cannot be supplied together with
         * prefixRedirect. Supply one alone or neither. If neither is supplied, the path of the
         * original request will be used for the redirect. The value must be between 1 and 1024
         * characters.
         */
        pathRedirect?: string;
        /**
         * The prefix that replaces the prefixMatch specified in the HttpRouteRuleMatch,
         * retaining the remaining portion of the URL before redirecting the request.
         * prefixRedirect cannot be supplied together with pathRedirect. Supply one alone or
         * neither. If neither is supplied, the path of the original request will be used for
         * the redirect. The value must be between 1 and 1024 characters.
         */
        prefixRedirect?: string;
        /**
         * The HTTP Status code to use for this RedirectAction. Supported values are:
         * * MOVED_PERMANENTLY_DEFAULT, which is the default value and corresponds to 301.
         * * FOUND, which corresponds to 302.
         * * SEE_OTHER which corresponds to 303.
         * * TEMPORARY_REDIRECT, which corresponds to 307. In this case, the request method
         * will be retained.
         * * PERMANENT_REDIRECT, which corresponds to 308. In this case,
         * the request method will be retained.
         */
        redirectResponseCode?: string;
        /**
         * If set to true, any accompanying query portion of the original URL is removed prior
         * to redirecting the request. If set to false, the query portion of the original URL is
         * retained.
         * This field is required to ensure an empty block is not set. The normal default value is false.
         */
        stripQuery: boolean;
    }

    export interface RegionUrlMapPathMatcherPathRule {
        /**
         * The list of path patterns to match. Each must start with / and the only place a
         * \* is allowed is at the end following a /. The string fed to the path matcher
         * does not include any text after the first ? or #, and those chars are not
         * allowed here.
         */
        paths: string[];
        /**
         * In response to a matching path, the load balancer performs advanced routing
         * actions like URL rewrites, header transformations, etc. prior to forwarding the
         * request to the selected backend. If routeAction specifies any
         * weightedBackendServices, service must not be set. Conversely if service is set,
         * routeAction cannot contain any  weightedBackendServices. Only one of routeAction
         * or urlRedirect must be set.
         * Structure is documented below.
         */
        routeAction?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteAction;
        /**
         * A reference to expected RegionBackendService resource the given URL should be mapped to.
         */
        service?: string;
        /**
         * When a path pattern is matched, the request is redirected to a URL specified
         * by urlRedirect. If urlRedirect is specified, service or routeAction must not
         * be set.
         * Structure is documented below.
         */
        urlRedirect?: outputs.compute.RegionUrlMapPathMatcherPathRuleUrlRedirect;
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteAction {
        /**
         * The specification for allowing client side cross-origin requests. Please see W3C
         * Recommendation for Cross Origin Resource Sharing
         * Structure is documented below.
         */
        corsPolicy?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionCorsPolicy;
        /**
         * The specification for fault injection introduced into traffic to test the
         * resiliency of clients to backend service failure. As part of fault injection,
         * when clients send requests to a backend service, delays can be introduced by
         * Loadbalancer on a percentage of requests before sending those request to the
         * backend service. Similarly requests from clients can be aborted by the
         * Loadbalancer for a percentage of requests. timeout and retryPolicy will be
         * ignored by clients that are configured with a fault_injection_policy.
         * Structure is documented below.
         */
        faultInjectionPolicy?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionFaultInjectionPolicy;
        /**
         * Specifies the policy on how requests intended for the route's backends are
         * shadowed to a separate mirrored backend service. Loadbalancer does not wait for
         * responses from the shadow service. Prior to sending traffic to the shadow
         * service, the host / authority header is suffixed with -shadow.
         * Structure is documented below.
         */
        requestMirrorPolicy?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionRequestMirrorPolicy;
        /**
         * Specifies the retry policy associated with this route.
         * Structure is documented below.
         */
        retryPolicy?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionRetryPolicy;
        /**
         * Specifies the timeout for the selected route. Timeout is computed from the time
         * the request is has been fully processed (i.e. end-of-stream) up until the
         * response has been completely processed. Timeout includes all retries. If not
         * specified, the default value is 15 seconds.
         * Structure is documented below.
         */
        timeout?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionTimeout;
        /**
         * The spec to modify the URL of the request, prior to forwarding the request to
         * the matched service
         * Structure is documented below.
         */
        urlRewrite?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionUrlRewrite;
        /**
         * A list of weighted backend services to send traffic to when a route match
         * occurs. The weights determine the fraction of traffic that flows to their
         * corresponding backend service. If all traffic needs to go to a single backend
         * service, there must be one  weightedBackendService with weight set to a non 0
         * number. Once a backendService is identified and before forwarding the request to
         * the backend service, advanced routing actions like Url rewrites and header
         * transformations are applied depending on additional settings specified in this
         * HttpRouteAction.
         * Structure is documented below.
         */
        weightedBackendServices?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionWeightedBackendService[];
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionCorsPolicy {
        /**
         * In response to a preflight request, setting this to true indicates that the
         * actual request can include user credentials. This translates to the Access-
         * Control-Allow-Credentials header. Defaults to false.
         */
        allowCredentials?: boolean;
        /**
         * Specifies the content for the Access-Control-Allow-Headers header.
         */
        allowHeaders?: string[];
        /**
         * Specifies the content for the Access-Control-Allow-Methods header.
         */
        allowMethods?: string[];
        /**
         * Specifies the regular expression patterns that match allowed origins. For
         * regular expression grammar please see en.cppreference.com/w/cpp/regex/ecmascript
         * An origin is allowed if it matches either allowOrigins or allow_origin_regex.
         */
        allowOriginRegexes?: string[];
        /**
         * Specifies the list of origins that will be allowed to do CORS requests. An
         * origin is allowed if it matches either allowOrigins or allow_origin_regex.
         */
        allowOrigins?: string[];
        /**
         * If true, specifies the CORS policy is disabled.
         */
        disabled: boolean;
        /**
         * Specifies the content for the Access-Control-Expose-Headers header.
         */
        exposeHeaders?: string[];
        /**
         * Specifies how long the results of a preflight request can be cached. This
         * translates to the content for the Access-Control-Max-Age header.
         */
        maxAge?: number;
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionFaultInjectionPolicy {
        /**
         * The specification for how client requests are aborted as part of fault
         * injection.
         * Structure is documented below.
         */
        abort?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionFaultInjectionPolicyAbort;
        /**
         * The specification for how client requests are delayed as part of fault
         * injection, before being sent to a backend service.
         * Structure is documented below.
         */
        delay?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionFaultInjectionPolicyDelay;
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionFaultInjectionPolicyAbort {
        /**
         * The HTTP status code used to abort the request. The value must be between 200
         * and 599 inclusive.
         */
        httpStatus: number;
        /**
         * The percentage of traffic (connections/operations/requests) on which delay will
         * be introduced as part of fault injection. The value must be between 0.0 and
         * 100.0 inclusive.
         */
        percentage: number;
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionFaultInjectionPolicyDelay {
        /**
         * Specifies the value of the fixed delay interval.
         * Structure is documented below.
         */
        fixedDelay: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionFaultInjectionPolicyDelayFixedDelay;
        /**
         * The percentage of traffic (connections/operations/requests) on which delay will
         * be introduced as part of fault injection. The value must be between 0.0 and
         * 100.0 inclusive.
         */
        percentage: number;
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionFaultInjectionPolicyDelayFixedDelay {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: string;
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionRequestMirrorPolicy {
        /**
         * The default RegionBackendService resource. Before
         * forwarding the request to backendService, the loadbalancer applies any relevant
         * headerActions specified as part of this backendServiceWeight.
         */
        backendService: string;
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionRetryPolicy {
        /**
         * Specifies the allowed number retries. This number must be > 0.
         */
        numRetries?: number;
        /**
         * Specifies a non-zero timeout per retry attempt.
         * Structure is documented below.
         */
        perTryTimeout?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionRetryPolicyPerTryTimeout;
        /**
         * Specifies one or more conditions when this retry rule applies. Valid values are:
         * - 5xx: Loadbalancer will attempt a retry if the backend service responds with
         * any 5xx response code, or if the backend service does not respond at all,
         * example: disconnects, reset, read timeout, connection failure, and refused
         * streams.
         * - gateway-error: Similar to 5xx, but only applies to response codes
         * 502, 503 or 504.
         * - connect-failure: Loadbalancer will retry on failures
         * connecting to backend services, for example due to connection timeouts.
         * - retriable-4xx: Loadbalancer will retry for retriable 4xx response codes.
         * Currently the only retriable error supported is 409.
         * - refused-stream: Loadbalancer will retry if the backend service resets the stream with a
         * REFUSED_STREAM error code. This reset type indicates that it is safe to retry.
         * - cancelled: Loadbalancer will retry if the gRPC status code in the response
         * header is set to cancelled
         * - deadline-exceeded: Loadbalancer will retry if the
         * gRPC status code in the response header is set to deadline-exceeded
         * - resource-exhausted: Loadbalancer will retry if the gRPC status code in the response
         * header is set to resource-exhausted
         * - unavailable: Loadbalancer will retry if
         * the gRPC status code in the response header is set to unavailable
         */
        retryConditions?: string[];
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionRetryPolicyPerTryTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: string;
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: string;
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionUrlRewrite {
        /**
         * Prior to forwarding the request to the selected service, the request's host
         * header is replaced with contents of hostRewrite. The value must be between 1 and
         * 255 characters.
         */
        hostRewrite?: string;
        /**
         * Prior to forwarding the request to the selected backend service, the matching
         * portion of the request's path is replaced by pathPrefixRewrite. The value must
         * be between 1 and 1024 characters.
         */
        pathPrefixRewrite?: string;
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionWeightedBackendService {
        /**
         * The default RegionBackendService resource. Before
         * forwarding the request to backendService, the loadbalancer applies any relevant
         * headerActions specified as part of this backendServiceWeight.
         */
        backendService: string;
        /**
         * Specifies changes to request and response headers that need to take effect for
         * the selected backendService. headerAction specified here take effect before
         * headerAction in the enclosing HttpRouteRule, PathMatcher and UrlMap.
         * Structure is documented below.
         */
        headerAction?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionWeightedBackendServiceHeaderAction;
        /**
         * Specifies the fraction of traffic sent to backendService, computed as weight /
         * (sum of all weightedBackendService weights in routeAction) . The selection of a
         * backend service is determined only for new traffic. Once a user's request has
         * been directed to a backendService, subsequent requests will be sent to the same
         * backendService as determined by the BackendService's session affinity policy.
         * The value must be between 0 and 1000
         */
        weight: number;
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionWeightedBackendServiceHeaderAction {
        /**
         * Headers to add to a matching request prior to forwarding the request to the
         * backendService.
         * Structure is documented below.
         */
        requestHeadersToAdds?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionWeightedBackendServiceHeaderActionRequestHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the request
         * prior to forwarding the request to the backendService.
         */
        requestHeadersToRemoves?: string[];
        /**
         * Headers to add the response prior to sending the response back to the client.
         * Structure is documented below.
         */
        responseHeadersToAdds?: outputs.compute.RegionUrlMapPathMatcherPathRuleRouteActionWeightedBackendServiceHeaderActionResponseHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the response
         * prior to sending the response back to the client.
         */
        responseHeadersToRemoves?: string[];
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionWeightedBackendServiceHeaderActionRequestHeadersToAdd {
        /**
         * The name of the header.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the
         * header. If true, headerValue is set for the header, discarding any values that
         * were set for that header.
         */
        replace: boolean;
    }

    export interface RegionUrlMapPathMatcherPathRuleRouteActionWeightedBackendServiceHeaderActionResponseHeadersToAdd {
        /**
         * The name of the header.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the
         * header. If true, headerValue is set for the header, discarding any values that
         * were set for that header.
         */
        replace: boolean;
    }

    export interface RegionUrlMapPathMatcherPathRuleUrlRedirect {
        /**
         * The host that will be used in the redirect response instead of the one that was
         * supplied in the request. The value must be between 1 and 255 characters.
         */
        hostRedirect?: string;
        /**
         * If set to true, the URL scheme in the redirected request is set to https. If set to
         * false, the URL scheme of the redirected request will remain the same as that of the
         * request. This must only be set for UrlMaps used in TargetHttpProxys. Setting this
         * true for TargetHttpsProxy is not permitted. The default is set to false.
         */
        httpsRedirect?: boolean;
        /**
         * The path that will be used in the redirect response instead of the one that was
         * supplied in the request. pathRedirect cannot be supplied together with
         * prefixRedirect. Supply one alone or neither. If neither is supplied, the path of the
         * original request will be used for the redirect. The value must be between 1 and 1024
         * characters.
         */
        pathRedirect?: string;
        /**
         * The prefix that replaces the prefixMatch specified in the HttpRouteRuleMatch,
         * retaining the remaining portion of the URL before redirecting the request.
         * prefixRedirect cannot be supplied together with pathRedirect. Supply one alone or
         * neither. If neither is supplied, the path of the original request will be used for
         * the redirect. The value must be between 1 and 1024 characters.
         */
        prefixRedirect?: string;
        /**
         * The HTTP Status code to use for this RedirectAction. Supported values are:
         * * MOVED_PERMANENTLY_DEFAULT, which is the default value and corresponds to 301.
         * * FOUND, which corresponds to 302.
         * * SEE_OTHER which corresponds to 303.
         * * TEMPORARY_REDIRECT, which corresponds to 307. In this case, the request method
         * will be retained.
         * * PERMANENT_REDIRECT, which corresponds to 308. In this case,
         * the request method will be retained.
         */
        redirectResponseCode?: string;
        /**
         * If set to true, any accompanying query portion of the original URL is removed prior
         * to redirecting the request. If set to false, the query portion of the original URL is
         * retained.
         * This field is required to ensure an empty block is not set. The normal default value is false.
         */
        stripQuery: boolean;
    }

    export interface RegionUrlMapPathMatcherRouteRule {
        /**
         * Specifies changes to request and response headers that need to take effect for
         * the selected backendService. headerAction specified here take effect before
         * headerAction in the enclosing HttpRouteRule, PathMatcher and UrlMap.
         * Structure is documented below.
         */
        headerAction?: outputs.compute.RegionUrlMapPathMatcherRouteRuleHeaderAction;
        /**
         * The rules for determining a match.
         * Structure is documented below.
         */
        matchRules?: outputs.compute.RegionUrlMapPathMatcherRouteRuleMatchRule[];
        /**
         * For routeRules within a given pathMatcher, priority determines the order
         * in which load balancer will interpret routeRules. RouteRules are evaluated
         * in order of priority, from the lowest to highest number. The priority of
         * a rule decreases as its number increases (1, 2, 3, N+1). The first rule
         * that matches the request is applied.
         * You cannot configure two or more routeRules with the same priority.
         * Priority for each rule must be set to a number between 0 and
         * 2147483647 inclusive.
         * Priority numbers can have gaps, which enable you to add or remove rules
         * in the future without affecting the rest of the rules. For example,
         * 1, 2, 3, 4, 5, 9, 12, 16 is a valid series of priority numbers to which
         * you could add rules numbered from 6 to 8, 10 to 11, and 13 to 15 in the
         * future without any impact on existing rules.
         */
        priority: number;
        /**
         * In response to a matching path, the load balancer performs advanced routing
         * actions like URL rewrites, header transformations, etc. prior to forwarding the
         * request to the selected backend. If routeAction specifies any
         * weightedBackendServices, service must not be set. Conversely if service is set,
         * routeAction cannot contain any  weightedBackendServices. Only one of routeAction
         * or urlRedirect must be set.
         * Structure is documented below.
         */
        routeAction?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteAction;
        /**
         * A reference to expected RegionBackendService resource the given URL should be mapped to.
         */
        service?: string;
        /**
         * When a path pattern is matched, the request is redirected to a URL specified
         * by urlRedirect. If urlRedirect is specified, service or routeAction must not
         * be set.
         * Structure is documented below.
         */
        urlRedirect?: outputs.compute.RegionUrlMapPathMatcherRouteRuleUrlRedirect;
    }

    export interface RegionUrlMapPathMatcherRouteRuleHeaderAction {
        /**
         * Headers to add to a matching request prior to forwarding the request to the
         * backendService.
         * Structure is documented below.
         */
        requestHeadersToAdds?: outputs.compute.RegionUrlMapPathMatcherRouteRuleHeaderActionRequestHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the request
         * prior to forwarding the request to the backendService.
         */
        requestHeadersToRemoves?: string[];
        /**
         * Headers to add the response prior to sending the response back to the client.
         * Structure is documented below.
         */
        responseHeadersToAdds?: outputs.compute.RegionUrlMapPathMatcherRouteRuleHeaderActionResponseHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the response
         * prior to sending the response back to the client.
         */
        responseHeadersToRemoves?: string[];
    }

    export interface RegionUrlMapPathMatcherRouteRuleHeaderActionRequestHeadersToAdd {
        /**
         * The name of the header.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the
         * header. If true, headerValue is set for the header, discarding any values that
         * were set for that header.
         */
        replace: boolean;
    }

    export interface RegionUrlMapPathMatcherRouteRuleHeaderActionResponseHeadersToAdd {
        /**
         * The name of the header.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the
         * header. If true, headerValue is set for the header, discarding any values that
         * were set for that header.
         */
        replace: boolean;
    }

    export interface RegionUrlMapPathMatcherRouteRuleMatchRule {
        /**
         * For satisfying the matchRule condition, the path of the request must exactly
         * match the value specified in fullPathMatch after removing any query parameters
         * and anchor that may be part of the original URL. FullPathMatch must be between 1
         * and 1024 characters. Only one of prefixMatch, fullPathMatch or regexMatch must
         * be specified.
         */
        fullPathMatch?: string;
        /**
         * Specifies a list of header match criteria, all of which must match corresponding
         * headers in the request.
         * Structure is documented below.
         */
        headerMatches?: outputs.compute.RegionUrlMapPathMatcherRouteRuleMatchRuleHeaderMatch[];
        /**
         * Specifies that prefixMatch and fullPathMatch matches are case sensitive.
         * Defaults to false.
         */
        ignoreCase?: boolean;
        /**
         * Opaque filter criteria used by Loadbalancer to restrict routing configuration to
         * a limited set xDS compliant clients. In their xDS requests to Loadbalancer, xDS
         * clients present node metadata. If a match takes place, the relevant routing
         * configuration is made available to those proxies. For each metadataFilter in
         * this list, if its filterMatchCriteria is set to MATCH_ANY, at least one of the
         * filterLabels must match the corresponding label provided in the metadata. If its
         * filterMatchCriteria is set to MATCH_ALL, then all of its filterLabels must match
         * with corresponding labels in the provided metadata. metadataFilters specified
         * here can be overrides those specified in ForwardingRule that refers to this
         * UrlMap. metadataFilters only applies to Loadbalancers that have their
         * loadBalancingScheme set to INTERNAL_SELF_MANAGED.
         * Structure is documented below.
         */
        metadataFilters?: outputs.compute.RegionUrlMapPathMatcherRouteRuleMatchRuleMetadataFilter[];
        /**
         * The value of the header must start with the contents of prefixMatch. Only one of
         * exactMatch, prefixMatch, suffixMatch, regexMatch, presentMatch or rangeMatch
         * must be set.
         */
        prefixMatch?: string;
        /**
         * Specifies a list of query parameter match criteria, all of which must match
         * corresponding query parameters in the request.
         * Structure is documented below.
         */
        queryParameterMatches?: outputs.compute.RegionUrlMapPathMatcherRouteRuleMatchRuleQueryParameterMatch[];
        /**
         * The queryParameterMatch matches if the value of the parameter matches the
         * regular expression specified by regexMatch. For the regular expression grammar,
         * please see en.cppreference.com/w/cpp/regex/ecmascript  Only one of presentMatch,
         * exactMatch and regexMatch must be set.
         */
        regexMatch?: string;
    }

    export interface RegionUrlMapPathMatcherRouteRuleMatchRuleHeaderMatch {
        /**
         * The queryParameterMatch matches if the value of the parameter exactly matches
         * the contents of exactMatch. Only one of presentMatch, exactMatch and regexMatch
         * must be set.
         */
        exactMatch?: string;
        /**
         * The name of the header.
         */
        headerName: string;
        /**
         * If set to false, the headerMatch is considered a match if the match criteria
         * above are met. If set to true, the headerMatch is considered a match if the
         * match criteria above are NOT met. Defaults to false.
         */
        invertMatch?: boolean;
        /**
         * The value of the header must start with the contents of prefixMatch. Only one of
         * exactMatch, prefixMatch, suffixMatch, regexMatch, presentMatch or rangeMatch
         * must be set.
         */
        prefixMatch?: string;
        /**
         * Specifies that the queryParameterMatch matches if the request contains the query
         * parameter, irrespective of whether the parameter has a value or not. Only one of
         * presentMatch, exactMatch and regexMatch must be set.
         */
        presentMatch?: boolean;
        /**
         * The header value must be an integer and its value must be in the range specified
         * in rangeMatch. If the header does not contain an integer, number or is empty,
         * the match fails. For example for a range [-5, 0]
         * * -3 will match
         * * 0 will not match
         * * 0.25 will not match
         * * -3someString will not match.
         * Only one of exactMatch, prefixMatch, suffixMatch, regexMatch, presentMatch or
         * rangeMatch must be set.
         * Structure is documented below.
         */
        rangeMatch?: outputs.compute.RegionUrlMapPathMatcherRouteRuleMatchRuleHeaderMatchRangeMatch;
        /**
         * The queryParameterMatch matches if the value of the parameter matches the
         * regular expression specified by regexMatch. For the regular expression grammar,
         * please see en.cppreference.com/w/cpp/regex/ecmascript  Only one of presentMatch,
         * exactMatch and regexMatch must be set.
         */
        regexMatch?: string;
        /**
         * The value of the header must end with the contents of suffixMatch. Only one of
         * exactMatch, prefixMatch, suffixMatch, regexMatch, presentMatch or rangeMatch
         * must be set.
         */
        suffixMatch?: string;
    }

    export interface RegionUrlMapPathMatcherRouteRuleMatchRuleHeaderMatchRangeMatch {
        /**
         * The end of the range (exclusive).
         */
        rangeEnd: number;
        /**
         * The start of the range (inclusive).
         */
        rangeStart: number;
    }

    export interface RegionUrlMapPathMatcherRouteRuleMatchRuleMetadataFilter {
        /**
         * The list of label value pairs that must match labels in the provided metadata
         * based on filterMatchCriteria  This list must not be empty and can have at the
         * most 64 entries.
         * Structure is documented below.
         */
        filterLabels: outputs.compute.RegionUrlMapPathMatcherRouteRuleMatchRuleMetadataFilterFilterLabel[];
        /**
         * Specifies how individual filterLabel matches within the list of filterLabels
         * contribute towards the overall metadataFilter match. Supported values are:
         * * MATCH_ANY: At least one of the filterLabels must have a matching label in the
         * provided metadata.
         * * MATCH_ALL: All filterLabels must have matching labels in
         * the provided metadata.
         * Possible values are `MATCH_ALL` and `MATCH_ANY`.
         */
        filterMatchCriteria: string;
    }

    export interface RegionUrlMapPathMatcherRouteRuleMatchRuleMetadataFilterFilterLabel {
        /**
         * The name of the query parameter to match. The query parameter must exist in the
         * request, in the absence of which the request match fails.
         */
        name: string;
        /**
         * The value of the label must match the specified value. value can have a maximum
         * length of 1024 characters.
         */
        value: string;
    }

    export interface RegionUrlMapPathMatcherRouteRuleMatchRuleQueryParameterMatch {
        /**
         * The queryParameterMatch matches if the value of the parameter exactly matches
         * the contents of exactMatch. Only one of presentMatch, exactMatch and regexMatch
         * must be set.
         */
        exactMatch?: string;
        /**
         * The name of the query parameter to match. The query parameter must exist in the
         * request, in the absence of which the request match fails.
         */
        name: string;
        /**
         * Specifies that the queryParameterMatch matches if the request contains the query
         * parameter, irrespective of whether the parameter has a value or not. Only one of
         * presentMatch, exactMatch and regexMatch must be set.
         */
        presentMatch?: boolean;
        /**
         * The queryParameterMatch matches if the value of the parameter matches the
         * regular expression specified by regexMatch. For the regular expression grammar,
         * please see en.cppreference.com/w/cpp/regex/ecmascript  Only one of presentMatch,
         * exactMatch and regexMatch must be set.
         */
        regexMatch?: string;
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteAction {
        /**
         * The specification for allowing client side cross-origin requests. Please see W3C
         * Recommendation for Cross Origin Resource Sharing
         * Structure is documented below.
         */
        corsPolicy?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionCorsPolicy;
        /**
         * The specification for fault injection introduced into traffic to test the
         * resiliency of clients to backend service failure. As part of fault injection,
         * when clients send requests to a backend service, delays can be introduced by
         * Loadbalancer on a percentage of requests before sending those request to the
         * backend service. Similarly requests from clients can be aborted by the
         * Loadbalancer for a percentage of requests. timeout and retryPolicy will be
         * ignored by clients that are configured with a fault_injection_policy.
         * Structure is documented below.
         */
        faultInjectionPolicy?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionFaultInjectionPolicy;
        /**
         * Specifies the policy on how requests intended for the route's backends are
         * shadowed to a separate mirrored backend service. Loadbalancer does not wait for
         * responses from the shadow service. Prior to sending traffic to the shadow
         * service, the host / authority header is suffixed with -shadow.
         * Structure is documented below.
         */
        requestMirrorPolicy?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionRequestMirrorPolicy;
        /**
         * Specifies the retry policy associated with this route.
         * Structure is documented below.
         */
        retryPolicy?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionRetryPolicy;
        /**
         * Specifies the timeout for the selected route. Timeout is computed from the time
         * the request is has been fully processed (i.e. end-of-stream) up until the
         * response has been completely processed. Timeout includes all retries. If not
         * specified, the default value is 15 seconds.
         * Structure is documented below.
         */
        timeout?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionTimeout;
        /**
         * The spec to modify the URL of the request, prior to forwarding the request to
         * the matched service
         * Structure is documented below.
         */
        urlRewrite?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionUrlRewrite;
        /**
         * A list of weighted backend services to send traffic to when a route match
         * occurs. The weights determine the fraction of traffic that flows to their
         * corresponding backend service. If all traffic needs to go to a single backend
         * service, there must be one  weightedBackendService with weight set to a non 0
         * number. Once a backendService is identified and before forwarding the request to
         * the backend service, advanced routing actions like Url rewrites and header
         * transformations are applied depending on additional settings specified in this
         * HttpRouteAction.
         * Structure is documented below.
         */
        weightedBackendServices?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionWeightedBackendService[];
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionCorsPolicy {
        /**
         * In response to a preflight request, setting this to true indicates that the
         * actual request can include user credentials. This translates to the Access-
         * Control-Allow-Credentials header. Defaults to false.
         */
        allowCredentials?: boolean;
        /**
         * Specifies the content for the Access-Control-Allow-Headers header.
         */
        allowHeaders?: string[];
        /**
         * Specifies the content for the Access-Control-Allow-Methods header.
         */
        allowMethods?: string[];
        /**
         * Specifies the regular expression patterns that match allowed origins. For
         * regular expression grammar please see en.cppreference.com/w/cpp/regex/ecmascript
         * An origin is allowed if it matches either allowOrigins or allow_origin_regex.
         */
        allowOriginRegexes?: string[];
        /**
         * Specifies the list of origins that will be allowed to do CORS requests. An
         * origin is allowed if it matches either allowOrigins or allow_origin_regex.
         */
        allowOrigins?: string[];
        /**
         * If true, specifies the CORS policy is disabled.
         */
        disabled?: boolean;
        /**
         * Specifies the content for the Access-Control-Expose-Headers header.
         */
        exposeHeaders?: string[];
        /**
         * Specifies how long the results of a preflight request can be cached. This
         * translates to the content for the Access-Control-Max-Age header.
         */
        maxAge?: number;
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionFaultInjectionPolicy {
        /**
         * The specification for how client requests are aborted as part of fault
         * injection.
         * Structure is documented below.
         */
        abort?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionFaultInjectionPolicyAbort;
        /**
         * The specification for how client requests are delayed as part of fault
         * injection, before being sent to a backend service.
         * Structure is documented below.
         */
        delay?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionFaultInjectionPolicyDelay;
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionFaultInjectionPolicyAbort {
        /**
         * The HTTP status code used to abort the request. The value must be between 200
         * and 599 inclusive.
         */
        httpStatus?: number;
        /**
         * The percentage of traffic (connections/operations/requests) on which delay will
         * be introduced as part of fault injection. The value must be between 0.0 and
         * 100.0 inclusive.
         */
        percentage?: number;
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionFaultInjectionPolicyDelay {
        /**
         * Specifies the value of the fixed delay interval.
         * Structure is documented below.
         */
        fixedDelay?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionFaultInjectionPolicyDelayFixedDelay;
        /**
         * The percentage of traffic (connections/operations/requests) on which delay will
         * be introduced as part of fault injection. The value must be between 0.0 and
         * 100.0 inclusive.
         */
        percentage?: number;
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionFaultInjectionPolicyDelayFixedDelay {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: string;
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionRequestMirrorPolicy {
        /**
         * The default RegionBackendService resource. Before
         * forwarding the request to backendService, the loadbalancer applies any relevant
         * headerActions specified as part of this backendServiceWeight.
         */
        backendService: string;
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionRetryPolicy {
        /**
         * Specifies the allowed number retries. This number must be > 0.
         */
        numRetries: number;
        /**
         * Specifies a non-zero timeout per retry attempt.
         * Structure is documented below.
         */
        perTryTimeout?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionRetryPolicyPerTryTimeout;
        /**
         * Specifies one or more conditions when this retry rule applies. Valid values are:
         * - 5xx: Loadbalancer will attempt a retry if the backend service responds with
         * any 5xx response code, or if the backend service does not respond at all,
         * example: disconnects, reset, read timeout, connection failure, and refused
         * streams.
         * - gateway-error: Similar to 5xx, but only applies to response codes
         * 502, 503 or 504.
         * - connect-failure: Loadbalancer will retry on failures
         * connecting to backend services, for example due to connection timeouts.
         * - retriable-4xx: Loadbalancer will retry for retriable 4xx response codes.
         * Currently the only retriable error supported is 409.
         * - refused-stream: Loadbalancer will retry if the backend service resets the stream with a
         * REFUSED_STREAM error code. This reset type indicates that it is safe to retry.
         * - cancelled: Loadbalancer will retry if the gRPC status code in the response
         * header is set to cancelled
         * - deadline-exceeded: Loadbalancer will retry if the
         * gRPC status code in the response header is set to deadline-exceeded
         * - resource-exhausted: Loadbalancer will retry if the gRPC status code in the response
         * header is set to resource-exhausted
         * - unavailable: Loadbalancer will retry if
         * the gRPC status code in the response header is set to unavailable
         */
        retryConditions?: string[];
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionRetryPolicyPerTryTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: string;
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations
         * less than one second are represented with a 0 `seconds` field and a positive
         * `nanos` field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000
         * inclusive.
         */
        seconds: string;
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionUrlRewrite {
        /**
         * Prior to forwarding the request to the selected service, the request's host
         * header is replaced with contents of hostRewrite. The value must be between 1 and
         * 255 characters.
         */
        hostRewrite?: string;
        /**
         * Prior to forwarding the request to the selected backend service, the matching
         * portion of the request's path is replaced by pathPrefixRewrite. The value must
         * be between 1 and 1024 characters.
         */
        pathPrefixRewrite?: string;
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionWeightedBackendService {
        /**
         * The default RegionBackendService resource. Before
         * forwarding the request to backendService, the loadbalancer applies any relevant
         * headerActions specified as part of this backendServiceWeight.
         */
        backendService: string;
        /**
         * Specifies changes to request and response headers that need to take effect for
         * the selected backendService. headerAction specified here take effect before
         * headerAction in the enclosing HttpRouteRule, PathMatcher and UrlMap.
         * Structure is documented below.
         */
        headerAction?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionWeightedBackendServiceHeaderAction;
        /**
         * Specifies the fraction of traffic sent to backendService, computed as weight /
         * (sum of all weightedBackendService weights in routeAction) . The selection of a
         * backend service is determined only for new traffic. Once a user's request has
         * been directed to a backendService, subsequent requests will be sent to the same
         * backendService as determined by the BackendService's session affinity policy.
         * The value must be between 0 and 1000
         */
        weight: number;
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionWeightedBackendServiceHeaderAction {
        /**
         * Headers to add to a matching request prior to forwarding the request to the
         * backendService.
         * Structure is documented below.
         */
        requestHeadersToAdds?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionWeightedBackendServiceHeaderActionRequestHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the request
         * prior to forwarding the request to the backendService.
         */
        requestHeadersToRemoves?: string[];
        /**
         * Headers to add the response prior to sending the response back to the client.
         * Structure is documented below.
         */
        responseHeadersToAdds?: outputs.compute.RegionUrlMapPathMatcherRouteRuleRouteActionWeightedBackendServiceHeaderActionResponseHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the response
         * prior to sending the response back to the client.
         */
        responseHeadersToRemoves?: string[];
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionWeightedBackendServiceHeaderActionRequestHeadersToAdd {
        /**
         * The name of the header.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the
         * header. If true, headerValue is set for the header, discarding any values that
         * were set for that header.
         */
        replace: boolean;
    }

    export interface RegionUrlMapPathMatcherRouteRuleRouteActionWeightedBackendServiceHeaderActionResponseHeadersToAdd {
        /**
         * The name of the header.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the
         * header. If true, headerValue is set for the header, discarding any values that
         * were set for that header.
         */
        replace: boolean;
    }

    export interface RegionUrlMapPathMatcherRouteRuleUrlRedirect {
        /**
         * The host that will be used in the redirect response instead of the one that was
         * supplied in the request. The value must be between 1 and 255 characters.
         */
        hostRedirect?: string;
        /**
         * If set to true, the URL scheme in the redirected request is set to https. If set to
         * false, the URL scheme of the redirected request will remain the same as that of the
         * request. This must only be set for UrlMaps used in TargetHttpProxys. Setting this
         * true for TargetHttpsProxy is not permitted. The default is set to false.
         */
        httpsRedirect?: boolean;
        /**
         * The path that will be used in the redirect response instead of the one that was
         * supplied in the request. pathRedirect cannot be supplied together with
         * prefixRedirect. Supply one alone or neither. If neither is supplied, the path of the
         * original request will be used for the redirect. The value must be between 1 and 1024
         * characters.
         */
        pathRedirect?: string;
        /**
         * The prefix that replaces the prefixMatch specified in the HttpRouteRuleMatch,
         * retaining the remaining portion of the URL before redirecting the request.
         * prefixRedirect cannot be supplied together with pathRedirect. Supply one alone or
         * neither. If neither is supplied, the path of the original request will be used for
         * the redirect. The value must be between 1 and 1024 characters.
         */
        prefixRedirect?: string;
        /**
         * The HTTP Status code to use for this RedirectAction. Supported values are:
         * * MOVED_PERMANENTLY_DEFAULT, which is the default value and corresponds to 301.
         * * FOUND, which corresponds to 302.
         * * SEE_OTHER which corresponds to 303.
         * * TEMPORARY_REDIRECT, which corresponds to 307. In this case, the request method
         * will be retained.
         * * PERMANENT_REDIRECT, which corresponds to 308. In this case,
         * the request method will be retained.
         */
        redirectResponseCode?: string;
        /**
         * If set to true, any accompanying query portion of the original URL is removed prior
         * to redirecting the request. If set to false, the query portion of the original URL is
         * retained.
         * This field is required to ensure an empty block is not set. The normal default value is false.
         */
        stripQuery?: boolean;
    }

    export interface RegionUrlMapTest {
        /**
         * Description of this test case.
         */
        description?: string;
        /**
         * Host portion of the URL.
         */
        host: string;
        /**
         * Path portion of the URL.
         */
        path: string;
        /**
         * A reference to expected RegionBackendService resource the given URL should be mapped to.
         */
        service: string;
    }

    export interface ReservationShareSettings {
        /**
         * A map of project number and project config. This is only valid when shareType's value is SPECIFIC_PROJECTS.
         * Structure is documented below.
         */
        projectMaps?: outputs.compute.ReservationShareSettingsProjectMap[];
        /**
         * Type of sharing for this shared-reservation
         * Possible values are `LOCAL` and `SPECIFIC_PROJECTS`.
         */
        shareType: string;
    }

    export interface ReservationShareSettingsProjectMap {
        /**
         * The identifier for this object. Format specified above.
         */
        id: string;
        /**
         * The project id/number, should be same as the key of this project config in the project map.
         */
        projectId?: string;
    }

    export interface ReservationSpecificReservation {
        /**
         * The number of resources that are allocated.
         */
        count: number;
        /**
         * -
         * How many instances are in use.
         */
        inUseCount: number;
        /**
         * The instance properties for the reservation.
         * Structure is documented below.
         */
        instanceProperties: outputs.compute.ReservationSpecificReservationInstanceProperties;
    }

    export interface ReservationSpecificReservationInstanceProperties {
        /**
         * Guest accelerator type and count.
         * Structure is documented below.
         */
        guestAccelerators?: outputs.compute.ReservationSpecificReservationInstancePropertiesGuestAccelerator[];
        /**
         * The amount of local ssd to reserve with each instance. This
         * reserves disks of type `local-ssd`.
         * Structure is documented below.
         */
        localSsds?: outputs.compute.ReservationSpecificReservationInstancePropertiesLocalSsd[];
        /**
         * The name of the machine type to reserve.
         */
        machineType: string;
        /**
         * The minimum CPU platform for the reservation. For example,
         * `"Intel Skylake"`. See
         * the CPU platform availability reference](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform#availablezones)
         * for information on available CPU platforms.
         */
        minCpuPlatform: string;
    }

    export interface ReservationSpecificReservationInstancePropertiesGuestAccelerator {
        /**
         * The number of the guest accelerator cards exposed to
         * this instance.
         */
        acceleratorCount: number;
        /**
         * The full or partial URL of the accelerator type to
         * attach to this instance. For example:
         * `projects/my-project/zones/us-central1-c/acceleratorTypes/nvidia-tesla-p100`
         * If you are creating an instance template, specify only the accelerator name.
         */
        acceleratorType: string;
    }

    export interface ReservationSpecificReservationInstancePropertiesLocalSsd {
        /**
         * The size of the disk in base-2 GB.
         */
        diskSizeGb: number;
        /**
         * The disk interface to use for attaching this disk.
         * Default value is `SCSI`.
         * Possible values are `SCSI` and `NVME`.
         */
        interface?: string;
    }

    export interface ResourcePolicyGroupPlacementPolicy {
        /**
         * The number of availability domains instances will be spread across. If two instances are in different
         * availability domain, they will not be put in the same low latency network
         */
        availabilityDomainCount?: number;
        /**
         * Collocation specifies whether to place VMs inside the same availability domain on the same low-latency network.
         * Specify `COLLOCATED` to enable collocation. Can only be specified with `vmCount`. If compute instances are created
         * with a COLLOCATED policy, then exactly `vmCount` instances must be created at the same time with the resource policy
         * attached.
         * Possible values are `COLLOCATED`.
         */
        collocation?: string;
        /**
         * Number of VMs in this placement group. Google does not recommend that you use this field
         * unless you use a compact policy and you want your policy to work only if it contains this
         * exact number of VMs.
         */
        vmCount?: number;
    }

    export interface ResourcePolicyInstanceSchedulePolicy {
        /**
         * The expiration time of the schedule. The timestamp is an RFC3339 string.
         */
        expirationTime?: string;
        /**
         * The start time of the schedule. The timestamp is an RFC3339 string.
         */
        startTime?: string;
        /**
         * Specifies the time zone to be used in interpreting the schedule. The value of this field must be a time zone name
         * from the tz database: http://en.wikipedia.org/wiki/Tz_database.
         */
        timeZone: string;
        /**
         * Specifies the schedule for starting instances.
         * Structure is documented below.
         */
        vmStartSchedule?: outputs.compute.ResourcePolicyInstanceSchedulePolicyVmStartSchedule;
        /**
         * Specifies the schedule for stopping instances.
         * Structure is documented below.
         */
        vmStopSchedule?: outputs.compute.ResourcePolicyInstanceSchedulePolicyVmStopSchedule;
    }

    export interface ResourcePolicyInstanceSchedulePolicyVmStartSchedule {
        /**
         * Specifies the frequency for the operation, using the unix-cron format.
         */
        schedule: string;
    }

    export interface ResourcePolicyInstanceSchedulePolicyVmStopSchedule {
        /**
         * Specifies the frequency for the operation, using the unix-cron format.
         */
        schedule: string;
    }

    export interface ResourcePolicySnapshotSchedulePolicy {
        /**
         * Retention policy applied to snapshots created by this resource policy.
         * Structure is documented below.
         */
        retentionPolicy?: outputs.compute.ResourcePolicySnapshotSchedulePolicyRetentionPolicy;
        /**
         * Specifies the frequency for the operation, using the unix-cron format.
         */
        schedule: outputs.compute.ResourcePolicySnapshotSchedulePolicySchedule;
        /**
         * Properties with which the snapshots are created, such as labels.
         * Structure is documented below.
         */
        snapshotProperties?: outputs.compute.ResourcePolicySnapshotSchedulePolicySnapshotProperties;
    }

    export interface ResourcePolicySnapshotSchedulePolicyRetentionPolicy {
        /**
         * Maximum age of the snapshot that is allowed to be kept.
         */
        maxRetentionDays: number;
        /**
         * Specifies the behavior to apply to scheduled snapshots when
         * the source disk is deleted.
         * Default value is `KEEP_AUTO_SNAPSHOTS`.
         * Possible values are `KEEP_AUTO_SNAPSHOTS` and `APPLY_RETENTION_POLICY`.
         */
        onSourceDiskDelete?: string;
    }

    export interface ResourcePolicySnapshotSchedulePolicySchedule {
        /**
         * The policy will execute every nth day at the specified time.
         * Structure is documented below.
         */
        dailySchedule?: outputs.compute.ResourcePolicySnapshotSchedulePolicyScheduleDailySchedule;
        /**
         * The policy will execute every nth hour starting at the specified time.
         * Structure is documented below.
         */
        hourlySchedule?: outputs.compute.ResourcePolicySnapshotSchedulePolicyScheduleHourlySchedule;
        /**
         * Allows specifying a snapshot time for each day of the week.
         * Structure is documented below.
         */
        weeklySchedule?: outputs.compute.ResourcePolicySnapshotSchedulePolicyScheduleWeeklySchedule;
    }

    export interface ResourcePolicySnapshotSchedulePolicyScheduleDailySchedule {
        /**
         * The number of days between snapshots.
         */
        daysInCycle: number;
        /**
         * The start time of the schedule. The timestamp is an RFC3339 string.
         */
        startTime: string;
    }

    export interface ResourcePolicySnapshotSchedulePolicyScheduleHourlySchedule {
        /**
         * The number of hours between snapshots.
         */
        hoursInCycle: number;
        /**
         * The start time of the schedule. The timestamp is an RFC3339 string.
         */
        startTime: string;
    }

    export interface ResourcePolicySnapshotSchedulePolicyScheduleWeeklySchedule {
        /**
         * May contain up to seven (one for each day of the week) snapshot times.
         * Structure is documented below.
         */
        dayOfWeeks: outputs.compute.ResourcePolicySnapshotSchedulePolicyScheduleWeeklyScheduleDayOfWeek[];
    }

    export interface ResourcePolicySnapshotSchedulePolicyScheduleWeeklyScheduleDayOfWeek {
        /**
         * The day of the week to create the snapshot. e.g. MONDAY
         * Possible values are `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, and `SUNDAY`.
         */
        day: string;
        /**
         * The start time of the schedule. The timestamp is an RFC3339 string.
         */
        startTime: string;
    }

    export interface ResourcePolicySnapshotSchedulePolicySnapshotProperties {
        /**
         * Whether to perform a 'guest aware' snapshot.
         */
        guestFlush?: boolean;
        /**
         * A set of key-value pairs.
         */
        labels?: {[key: string]: string};
        /**
         * Cloud Storage bucket location to store the auto snapshot
         * (regional or multi-regional)
         */
        storageLocations?: string;
    }

    export interface RouterBgp {
        /**
         * User-specified flag to indicate which mode to use for advertisement.
         * Default value is `DEFAULT`.
         * Possible values are `DEFAULT` and `CUSTOM`.
         */
        advertiseMode?: string;
        /**
         * User-specified list of prefix groups to advertise in custom mode.
         * This field can only be populated if advertiseMode is CUSTOM and
         * is advertised to all peers of the router. These groups will be
         * advertised in addition to any specified prefixes. Leave this field
         * blank to advertise no custom groups.
         * This enum field has the one valid value: ALL_SUBNETS
         */
        advertisedGroups?: string[];
        /**
         * User-specified list of individual IP ranges to advertise in
         * custom mode. This field can only be populated if advertiseMode
         * is CUSTOM and is advertised to all peers of the router. These IP
         * ranges will be advertised in addition to any specified groups.
         * Leave this field blank to advertise no custom IP ranges.
         * Structure is documented below.
         */
        advertisedIpRanges?: outputs.compute.RouterBgpAdvertisedIpRange[];
        /**
         * Local BGP Autonomous System Number (ASN). Must be an RFC6996
         * private ASN, either 16-bit or 32-bit. The value will be fixed for
         * this router resource. All VPN tunnels that link to this router
         * will have the same local ASN.
         */
        asn: number;
        /**
         * The interval in seconds between BGP keepalive messages that are sent to the peer.
         * Hold time is three times the interval at which keepalive messages are sent, and the hold time is the
         * maximum number of seconds allowed to elapse between successive keepalive messages that BGP receives from a peer.
         * BGP will use the smaller of either the local hold time value or the peer's hold time value as the hold time for
         * the BGP connection between the two peers. If set, this value must be between 20 and 60. The default is 20.
         */
        keepaliveInterval?: number;
    }

    export interface RouterBgpAdvertisedIpRange {
        /**
         * User-specified description for the IP range.
         */
        description?: string;
        /**
         * The IP range to advertise. The value must be a
         * CIDR-formatted string.
         */
        range: string;
    }

    export interface RouterNatLogConfig {
        /**
         * Indicates whether or not to export logs.
         */
        enable: boolean;
        /**
         * Specifies the desired filtering of logs on this NAT.
         * Possible values are `ERRORS_ONLY`, `TRANSLATIONS_ONLY`, and `ALL`.
         */
        filter: string;
    }

    export interface RouterNatSubnetwork {
        /**
         * Self-link of subnetwork to NAT
         */
        name: string;
        /**
         * List of the secondary ranges of the subnetwork that are allowed
         * to use NAT. This can be populated only if
         * `LIST_OF_SECONDARY_IP_RANGES` is one of the values in
         * sourceIpRangesToNat
         */
        secondaryIpRangeNames?: string[];
        /**
         * List of options for which source IPs in the subnetwork
         * should have NAT enabled. Supported values include:
         * `ALL_IP_RANGES`, `LIST_OF_SECONDARY_IP_RANGES`,
         * `PRIMARY_IP_RANGE`.
         */
        sourceIpRangesToNats: string[];
    }

    export interface RouterPeerAdvertisedIpRange {
        /**
         * User-specified description for the IP range.
         */
        description?: string;
        /**
         * The IP range to advertise. The value must be a
         * CIDR-formatted string.
         */
        range: string;
    }

    export interface RouterPeerBfd {
        /**
         * The minimum interval, in milliseconds, between BFD control packets
         * received from the peer router. The actual value is negotiated
         * between the two routers and is equal to the greater of this value
         * and the transmit interval of the other router. If set, this value
         * must be between 1000 and 30000.
         */
        minReceiveInterval?: number;
        /**
         * The minimum interval, in milliseconds, between BFD control packets
         * transmitted to the peer router. The actual value is negotiated
         * between the two routers and is equal to the greater of this value
         * and the corresponding receive interval of the other router. If set,
         * this value must be between 1000 and 30000.
         */
        minTransmitInterval?: number;
        /**
         * The number of consecutive BFD packets that must be missed before
         * BFD declares that a peer is unavailable. If set, the value must
         * be a value between 5 and 16.
         */
        multiplier?: number;
        /**
         * The BFD session initialization mode for this BGP peer.
         * If set to `ACTIVE`, the Cloud Router will initiate the BFD session
         * for this BGP peer. If set to `PASSIVE`, the Cloud Router will wait
         * for the peer router to initiate the BFD session for this BGP peer.
         * If set to `DISABLED`, BFD is disabled for this BGP peer.
         * Possible values are `ACTIVE`, `DISABLED`, and `PASSIVE`.
         */
        sessionInitializationMode: string;
    }

    export interface RouterStatusBestRoute {
        description: string;
        destRange: string;
        /**
         * The name of the router.
         */
        name: string;
        /**
         * The network name or resource link to the parent
         * network of this subnetwork.
         */
        network: string;
        nextHopGateway: string;
        nextHopIlb: string;
        nextHopInstance: string;
        nextHopInstanceZone: string;
        nextHopIp: string;
        nextHopNetwork: string;
        nextHopVpnTunnel: string;
        priority: number;
        /**
         * The ID of the project in which the resource
         * belongs. If it is not provided, the provider project is used.
         */
        project: string;
        selfLink: string;
        tags: string[];
    }

    export interface RouterStatusBestRoutesForRouter {
        description: string;
        destRange: string;
        /**
         * The name of the router.
         */
        name: string;
        /**
         * The network name or resource link to the parent
         * network of this subnetwork.
         */
        network: string;
        nextHopGateway: string;
        nextHopIlb: string;
        nextHopInstance: string;
        nextHopInstanceZone: string;
        nextHopIp: string;
        nextHopNetwork: string;
        nextHopVpnTunnel: string;
        priority: number;
        /**
         * The ID of the project in which the resource
         * belongs. If it is not provided, the provider project is used.
         */
        project: string;
        selfLink: string;
        tags: string[];
    }

    export interface SecurityPolicyAdaptiveProtectionConfig {
        /**
         * Configuration for [Google Cloud Armor Adaptive Protection Layer 7 DDoS Defense](https://cloud.google.com/armor/docs/adaptive-protection-overview?hl=en). Structure is documented below.
         */
        layer7DdosDefenseConfig?: outputs.compute.SecurityPolicyAdaptiveProtectionConfigLayer7DdosDefenseConfig;
    }

    export interface SecurityPolicyAdaptiveProtectionConfigLayer7DdosDefenseConfig {
        /**
         * If set to true, enables CAAP for L7 DDoS detection.
         */
        enable?: boolean;
        /**
         * Rule visibility can be one of the following: STANDARD - opaque rules. (default) PREMIUM - transparent rules.
         */
        ruleVisibility?: string;
    }

    export interface SecurityPolicyRule {
        /**
         * Action to take when `match` matches the request. Valid values:
         * * allow: allow access to target.
         * * deny(): deny access to target, returns the HTTP response code specified (valid values are 403, 404, and 502).
         * * rate_based_ban: limit client traffic to the configured threshold and ban the client if the traffic exceeds the threshold. Configure parameters for this action in RateLimitOptions. Requires rateLimitOptions to be set.
         * * redirect: redirect to a different target. This can either be an internal reCAPTCHA redirect, or an external URL-based redirect via a 302 response. Parameters for this action can be configured via redirectOptions.
         * * throttle: limit client traffic to the configured threshold. Configure parameters for this action in rateLimitOptions. Requires rateLimitOptions to be set for this.
         */
        action: string;
        /**
         * An optional description of this rule. Max size is 64.
         */
        description?: string;
        /**
         * A match condition that incoming traffic is evaluated against.
         * If it evaluates to true, the corresponding `action` is enforced. Structure is documented below.
         */
        match: outputs.compute.SecurityPolicyRuleMatch;
        /**
         * When set to true, the `action` specified above is not enforced.
         * Stackdriver logs for requests that trigger a preview action are annotated as such.
         */
        preview: boolean;
        /**
         * An unique positive integer indicating the priority of evaluation for a rule.
         * Rules are evaluated from highest priority (lowest numerically) to lowest priority (highest numerically) in order.
         */
        priority: number;
        /**
         * )
         * Must be specified if the `action` is "rateBasedBad" or "throttle". Cannot be specified for other actions. Structure is documented below.
         */
        rateLimitOptions?: outputs.compute.SecurityPolicyRuleRateLimitOptions;
        /**
         * )
         * Can be specified if the `action` is "redirect". Cannot be specified for other actions. Structure is documented below.
         */
        redirectOptions?: outputs.compute.SecurityPolicyRuleRedirectOptions;
    }

    export interface SecurityPolicyRuleMatch {
        /**
         * The configuration options available when specifying `versionedExpr`.
         * This field must be specified if `versionedExpr` is specified and cannot be specified if `versionedExpr` is not specified.
         * Structure is documented below.
         */
        config?: outputs.compute.SecurityPolicyRuleMatchConfig;
        /**
         * User defined CEVAL expression. A CEVAL expression is used to specify match criteria
         * such as origin.ip, source.region_code and contents in the request header.
         * Structure is documented below.
         */
        expr?: outputs.compute.SecurityPolicyRuleMatchExpr;
        /**
         * Predefined rule expression. If this field is specified, `config` must also be specified.
         * Available options:
         * * SRC_IPS_V1: Must specify the corresponding `srcIpRanges` field in `config`.
         */
        versionedExpr?: string;
    }

    export interface SecurityPolicyRuleMatchConfig {
        /**
         * Set of IP addresses or ranges (IPV4 or IPV6) in CIDR notation
         * to match against inbound traffic. There is a limit of 10 IP ranges per rule. A value of '\*' matches all IPs
         * (can be used to override the default behavior).
         */
        srcIpRanges: string[];
    }

    export interface SecurityPolicyRuleMatchExpr {
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         * The application context of the containing message determines which well-known feature set of CEL is supported.
         */
        expression: string;
    }

    export interface SecurityPolicyRuleRateLimitOptions {
        /**
         * Can only be specified if the `action` for the rule is "rateBasedBan".
         * If specified, determines the time (in seconds) the traffic will continue to be banned by the rate limit after the rate falls below the threshold.
         */
        banDurationSec?: number;
        /**
         * Can only be specified if the `action` for the rule is "rateBasedBan".
         * If specified, the key will be banned for the configured 'ban_duration_sec' when the number of requests that exceed the 'rate_limit_threshold' also
         * exceed this 'ban_threshold'. Structure is documented below.
         */
        banThreshold?: outputs.compute.SecurityPolicyRuleRateLimitOptionsBanThreshold;
        /**
         * Action to take for requests that are under the configured rate limit threshold. Valid option is "allow" only.
         */
        conformAction: string;
        /**
         * Determines the key to enforce the rateLimitThreshold on. If not specified, defaults to "ALL".
         */
        enforceOnKey?: string;
        /**
         * Rate limit key name applicable only for the following key types: HTTP_HEADER -- Name of the HTTP header whose value is taken as the key value. HTTP_COOKIE -- Name of the HTTP cookie whose value is taken as the key value.
         */
        enforceOnKeyName?: string;
        /**
         * When a request is denied, returns the HTTP response code specified.
         * Valid options are "deny()" where valid values for status are 403, 404, 429, and 502.
         */
        exceedAction: string;
        exceedRedirectOptions?: outputs.compute.SecurityPolicyRuleRateLimitOptionsExceedRedirectOptions;
        /**
         * Threshold at which to begin ratelimiting. Structure is documented below.
         */
        rateLimitThreshold: outputs.compute.SecurityPolicyRuleRateLimitOptionsRateLimitThreshold;
    }

    export interface SecurityPolicyRuleRateLimitOptionsBanThreshold {
        /**
         * Number of HTTP(S) requests for calculating the threshold.
         */
        count: number;
        /**
         * Interval over which the threshold is computed.
         */
        intervalSec: number;
    }

    export interface SecurityPolicyRuleRateLimitOptionsExceedRedirectOptions {
        /**
         * External redirection target when "EXTERNAL_302" is set in 'type'.
         */
        target?: string;
        /**
         * Type of redirect action.
         */
        type: string;
    }

    export interface SecurityPolicyRuleRateLimitOptionsRateLimitThreshold {
        /**
         * Number of HTTP(S) requests for calculating the threshold.
         */
        count: number;
        /**
         * Interval over which the threshold is computed.
         */
        intervalSec: number;
    }

    export interface SecurityPolicyRuleRedirectOptions {
        /**
         * External redirection target when "EXTERNAL_302" is set in 'type'.
         */
        target?: string;
        /**
         * Type of redirect action.
         */
        type: string;
    }

    export interface SecurityScanConfigAuthentication {
        /**
         * Describes authentication configuration that uses a custom account.
         * Structure is documented below.
         */
        customAccount?: outputs.compute.SecurityScanConfigAuthenticationCustomAccount;
        /**
         * Describes authentication configuration that uses a Google account.
         * Structure is documented below.
         */
        googleAccount?: outputs.compute.SecurityScanConfigAuthenticationGoogleAccount;
    }

    export interface SecurityScanConfigAuthenticationCustomAccount {
        /**
         * The login form URL of the website.
         */
        loginUrl: string;
        /**
         * The password of the custom account. The credential is stored encrypted
         * in GCP.
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        password: string;
        /**
         * The user name of the custom account.
         */
        username: string;
    }

    export interface SecurityScanConfigAuthenticationGoogleAccount {
        /**
         * The password of the custom account. The credential is stored encrypted
         * in GCP.
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        password: string;
        /**
         * The user name of the custom account.
         */
        username: string;
    }

    export interface SecurityScanConfigSchedule {
        /**
         * The duration of time between executions in days
         */
        intervalDurationDays: number;
        /**
         * A timestamp indicates when the next run will be scheduled. The value is refreshed
         * by the server after each run. If unspecified, it will default to current server time,
         * which means the scan will be scheduled to start immediately.
         */
        scheduleTime?: string;
    }

    export interface ServiceAttachmentConnectedEndpoint {
        endpoint: string;
        status: string;
    }

    export interface ServiceAttachmentConsumerAcceptList {
        /**
         * The number of consumer forwarding rules the consumer project can
         * create.
         */
        connectionLimit: number;
        /**
         * A project that is allowed to connect to this service attachment.
         */
        projectIdOrNum: string;
    }

    export interface SnapshotSnapshotEncryptionKey {
        /**
         * The name of the encryption key that is stored in Google Cloud KMS.
         */
        kmsKeySelfLink?: string;
        /**
         * The service account used for the encryption request for the given KMS key.
         * If absent, the Compute Engine Service Agent service account is used.
         */
        kmsKeyServiceAccount?: string;
        /**
         * Specifies a 256-bit customer-supplied encryption key, encoded in
         * RFC 4648 base64 to either encrypt or decrypt this resource.
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        rawKey?: string;
        /**
         * -
         * The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied
         * encryption key that protects this resource.
         */
        sha256: string;
    }

    export interface SnapshotSourceDiskEncryptionKey {
        /**
         * The service account used for the encryption request for the given KMS key.
         * If absent, the Compute Engine Service Agent service account is used.
         */
        kmsKeyServiceAccount?: string;
        /**
         * Specifies a 256-bit customer-supplied encryption key, encoded in
         * RFC 4648 base64 to either encrypt or decrypt this resource.
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        rawKey?: string;
    }

    export interface SubnetworkIAMBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface SubnetworkIAMMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface SubnetworkLogConfig {
        /**
         * Can only be specified if VPC flow logging for this subnetwork is enabled.
         * Toggles the aggregation interval for collecting flow logs. Increasing the
         * interval time will reduce the amount of generated flow logs for long
         * lasting connections. Default is an interval of 5 seconds per connection.
         * Default value is `INTERVAL_5_SEC`.
         * Possible values are `INTERVAL_5_SEC`, `INTERVAL_30_SEC`, `INTERVAL_1_MIN`, `INTERVAL_5_MIN`, `INTERVAL_10_MIN`, and `INTERVAL_15_MIN`.
         */
        aggregationInterval?: string;
        /**
         * Export filter used to define which VPC flow logs should be logged, as as CEL expression. See
         * https://cloud.google.com/vpc/docs/flow-logs#filtering for details on how to format this field.
         * The default value is 'true', which evaluates to include everything.
         */
        filterExpr?: string;
        /**
         * Can only be specified if VPC flow logging for this subnetwork is enabled.
         * The value of the field must be in [0, 1]. Set the sampling rate of VPC
         * flow logs within the subnetwork where 1.0 means all collected logs are
         * reported and 0.0 means no logs are reported. Default is 0.5 which means
         * half of all collected logs are reported.
         */
        flowSampling?: number;
        /**
         * Can only be specified if VPC flow logging for this subnetwork is enabled.
         * Configures whether metadata fields should be added to the reported VPC
         * flow logs.
         * Default value is `INCLUDE_ALL_METADATA`.
         * Possible values are `EXCLUDE_ALL_METADATA`, `INCLUDE_ALL_METADATA`, and `CUSTOM_METADATA`.
         */
        metadata?: string;
        /**
         * List of metadata fields that should be added to reported logs.
         * Can only be specified if VPC flow logs for this subnetwork is enabled and "metadata" is set to CUSTOM_METADATA.
         */
        metadataFields?: string[];
    }

    export interface SubnetworkSecondaryIpRange {
        /**
         * The range of IP addresses belonging to this subnetwork secondary
         * range. Provide this property when you create the subnetwork.
         * Ranges must be unique and non-overlapping with all primary and
         * secondary IP ranges within a network. Only IPv4 is supported.
         */
        ipCidrRange: string;
        /**
         * The name associated with this subnetwork secondary range, used
         * when adding an alias IP range to a VM instance. The name must
         * be 1-63 characters long, and comply with RFC1035. The name
         * must be unique within the subnetwork.
         */
        rangeName: string;
    }

    export interface URLMapDefaultRouteAction {
        /**
         * The specification for allowing client side cross-origin requests. Please see
         * [W3C Recommendation for Cross Origin Resource Sharing](https://www.w3.org/TR/cors/)
         * Structure is documented below.
         */
        corsPolicy?: outputs.compute.URLMapDefaultRouteActionCorsPolicy;
        /**
         * The specification for fault injection introduced into traffic to test the resiliency of clients to backend service failure.
         * As part of fault injection, when clients send requests to a backend service, delays can be introduced by Loadbalancer on a
         * percentage of requests before sending those request to the backend service. Similarly requests from clients can be aborted
         * by the Loadbalancer for a percentage of requests.
         * timeout and retryPolicy will be ignored by clients that are configured with a faultInjectionPolicy.
         * Structure is documented below.
         */
        faultInjectionPolicy?: outputs.compute.URLMapDefaultRouteActionFaultInjectionPolicy;
        /**
         * Specifies the policy on how requests intended for the route's backends are shadowed to a separate mirrored backend service.
         * Loadbalancer does not wait for responses from the shadow service. Prior to sending traffic to the shadow service,
         * the host / authority header is suffixed with -shadow.
         * Structure is documented below.
         */
        requestMirrorPolicy?: outputs.compute.URLMapDefaultRouteActionRequestMirrorPolicy;
        /**
         * Specifies the retry policy associated with this route.
         * Structure is documented below.
         */
        retryPolicy?: outputs.compute.URLMapDefaultRouteActionRetryPolicy;
        /**
         * Specifies the timeout for the selected route. Timeout is computed from the time the request has been
         * fully processed (i.e. end-of-stream) up until the response has been completely processed. Timeout includes all retries.
         * If not specified, will use the largest timeout among all backend services associated with the route.
         * Structure is documented below.
         */
        timeout: outputs.compute.URLMapDefaultRouteActionTimeout;
        /**
         * The spec to modify the URL of the request, prior to forwarding the request to the matched service.
         * Structure is documented below.
         */
        urlRewrite?: outputs.compute.URLMapDefaultRouteActionUrlRewrite;
        /**
         * A list of weighted backend services to send traffic to when a route match occurs.
         * The weights determine the fraction of traffic that flows to their corresponding backend service.
         * If all traffic needs to go to a single backend service, there must be one weightedBackendService
         * with weight set to a non 0 number.
         * Once a backendService is identified and before forwarding the request to the backend service,
         * advanced routing actions like Url rewrites and header transformations are applied depending on
         * additional settings specified in this HttpRouteAction.
         * Structure is documented below.
         */
        weightedBackendServices?: outputs.compute.URLMapDefaultRouteActionWeightedBackendService[];
    }

    export interface URLMapDefaultRouteActionCorsPolicy {
        /**
         * In response to a preflight request, setting this to true indicates that the actual request can include user credentials.
         * This translates to the Access-Control-Allow-Credentials header.
         */
        allowCredentials?: boolean;
        /**
         * Specifies the content for the Access-Control-Allow-Headers header.
         */
        allowHeaders?: string[];
        /**
         * Specifies the content for the Access-Control-Allow-Methods header.
         */
        allowMethods?: string[];
        /**
         * Specifies the regular expression patterns that match allowed origins. For regular expression grammar
         * please see en.cppreference.com/w/cpp/regex/ecmascript
         * An origin is allowed if it matches either an item in allowOrigins or an item in allowOriginRegexes.
         */
        allowOriginRegexes?: string[];
        /**
         * Specifies the list of origins that will be allowed to do CORS requests.
         * An origin is allowed if it matches either an item in allowOrigins or an item in allowOriginRegexes.
         */
        allowOrigins?: string[];
        /**
         * If true, specifies the CORS policy is disabled. The default value is false, which indicates that the CORS policy is in effect.
         */
        disabled?: boolean;
        /**
         * Specifies the content for the Access-Control-Expose-Headers header.
         */
        exposeHeaders?: string[];
        /**
         * Specifies how long results of a preflight request can be cached in seconds.
         * This translates to the Access-Control-Max-Age header.
         */
        maxAge?: number;
    }

    export interface URLMapDefaultRouteActionFaultInjectionPolicy {
        /**
         * The specification for how client requests are aborted as part of fault injection.
         * Structure is documented below.
         */
        abort?: outputs.compute.URLMapDefaultRouteActionFaultInjectionPolicyAbort;
        /**
         * The specification for how client requests are delayed as part of fault injection, before being sent to a backend service.
         * Structure is documented below.
         */
        delay?: outputs.compute.URLMapDefaultRouteActionFaultInjectionPolicyDelay;
    }

    export interface URLMapDefaultRouteActionFaultInjectionPolicyAbort {
        /**
         * The HTTP status code used to abort the request.
         * The value must be between 200 and 599 inclusive.
         */
        httpStatus?: number;
        /**
         * The percentage of traffic (connections/operations/requests) which will be aborted as part of fault injection.
         * The value must be between 0.0 and 100.0 inclusive.
         */
        percentage?: number;
    }

    export interface URLMapDefaultRouteActionFaultInjectionPolicyDelay {
        /**
         * Specifies the value of the fixed delay interval.
         * Structure is documented below.
         */
        fixedDelay?: outputs.compute.URLMapDefaultRouteActionFaultInjectionPolicyDelayFixedDelay;
        /**
         * The percentage of traffic (connections/operations/requests) which will be aborted as part of fault injection.
         * The value must be between 0.0 and 100.0 inclusive.
         */
        percentage?: number;
    }

    export interface URLMapDefaultRouteActionFaultInjectionPolicyDelayFixedDelay {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are
         * represented with a 0 seconds field and a positive nanos field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive.
         * Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
         */
        seconds?: string;
    }

    export interface URLMapDefaultRouteActionRequestMirrorPolicy {
        /**
         * The full or partial URL to the BackendService resource being mirrored to.
         */
        backendService: string;
    }

    export interface URLMapDefaultRouteActionRetryPolicy {
        /**
         * Specifies the allowed number retries. This number must be > 0. If not specified, defaults to 1.
         */
        numRetries?: number;
        /**
         * Specifies a non-zero timeout per retry attempt.
         * If not specified, will use the timeout set in HttpRouteAction. If timeout in HttpRouteAction is not set,
         * will use the largest timeout among all backend services associated with the route.
         * Structure is documented below.
         */
        perTryTimeout?: outputs.compute.URLMapDefaultRouteActionRetryPolicyPerTryTimeout;
        /**
         * Specfies one or more conditions when this retry rule applies. Valid values are:
         * * 5xx: Loadbalancer will attempt a retry if the backend service responds with any 5xx response code,
         * or if the backend service does not respond at all, example: disconnects, reset, read timeout,
         * * connection failure, and refused streams.
         * * gateway-error: Similar to 5xx, but only applies to response codes 502, 503 or 504.
         * * connect-failure: Loadbalancer will retry on failures connecting to backend services,
         * for example due to connection timeouts.
         * * retriable-4xx: Loadbalancer will retry for retriable 4xx response codes.
         * Currently the only retriable error supported is 409.
         * * refused-stream:Loadbalancer will retry if the backend service resets the stream with a REFUSED_STREAM error code.
         * This reset type indicates that it is safe to retry.
         * * cancelled: Loadbalancer will retry if the gRPC status code in the response header is set to cancelled
         * * deadline-exceeded: Loadbalancer will retry if the gRPC status code in the response header is set to deadline-exceeded
         * * resource-exhausted: Loadbalancer will retry if the gRPC status code in the response header is set to resource-exhausted
         * * unavailable: Loadbalancer will retry if the gRPC status code in the response header is set to unavailable
         */
        retryConditions?: string[];
    }

    export interface URLMapDefaultRouteActionRetryPolicyPerTryTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are
         * represented with a 0 seconds field and a positive nanos field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive.
         * Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
         */
        seconds?: string;
    }

    export interface URLMapDefaultRouteActionTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are
         * represented with a 0 seconds field and a positive nanos field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive.
         * Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
         */
        seconds?: string;
    }

    export interface URLMapDefaultRouteActionUrlRewrite {
        /**
         * Prior to forwarding the request to the selected service, the request's host header is replaced
         * with contents of hostRewrite.
         * The value must be between 1 and 255 characters.
         */
        hostRewrite?: string;
        /**
         * Prior to forwarding the request to the selected backend service, the matching portion of the
         * request's path is replaced by pathPrefixRewrite.
         * The value must be between 1 and 1024 characters.
         */
        pathPrefixRewrite?: string;
    }

    export interface URLMapDefaultRouteActionWeightedBackendService {
        /**
         * The full or partial URL to the BackendService resource being mirrored to.
         */
        backendService?: string;
        /**
         * Specifies changes to request and response headers that need to take effect for
         * the selected backendService.
         * headerAction specified here take effect before headerAction in the enclosing
         * HttpRouteRule, PathMatcher and UrlMap.
         * Structure is documented below.
         */
        headerAction?: outputs.compute.URLMapDefaultRouteActionWeightedBackendServiceHeaderAction;
        /**
         * Specifies the fraction of traffic sent to backendService, computed as
         * weight / (sum of all weightedBackendService weights in routeAction) .
         * The selection of a backend service is determined only for new traffic. Once a user's request
         * has been directed to a backendService, subsequent requests will be sent to the same backendService
         * as determined by the BackendService's session affinity policy.
         * The value must be between 0 and 1000
         */
        weight?: number;
    }

    export interface URLMapDefaultRouteActionWeightedBackendServiceHeaderAction {
        /**
         * Headers to add to a matching request prior to forwarding the request to the backendService.
         * Structure is documented below.
         */
        requestHeadersToAdds?: outputs.compute.URLMapDefaultRouteActionWeightedBackendServiceHeaderActionRequestHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the request prior to
         * forwarding the request to the backendService.
         */
        requestHeadersToRemoves?: string[];
        /**
         * Headers to add the response prior to sending the response back to the client.
         * Structure is documented below.
         */
        responseHeadersToAdds?: outputs.compute.URLMapDefaultRouteActionWeightedBackendServiceHeaderActionResponseHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the response prior to sending the
         * response back to the client.
         */
        responseHeadersToRemoves?: string[];
    }

    export interface URLMapDefaultRouteActionWeightedBackendServiceHeaderActionRequestHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName?: string;
        /**
         * The value of the header to add.
         */
        headerValue?: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace?: boolean;
    }

    export interface URLMapDefaultRouteActionWeightedBackendServiceHeaderActionResponseHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName?: string;
        /**
         * The value of the header to add.
         */
        headerValue?: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace?: boolean;
    }

    export interface URLMapDefaultUrlRedirect {
        /**
         * The host that will be used in the redirect response instead of the one that was
         * supplied in the request. The value must be between 1 and 255 characters.
         */
        hostRedirect?: string;
        /**
         * If set to true, the URL scheme in the redirected request is set to https. If set to
         * false, the URL scheme of the redirected request will remain the same as that of the
         * request. This must only be set for UrlMaps used in TargetHttpProxys. Setting this
         * true for TargetHttpsProxy is not permitted. The default is set to false.
         */
        httpsRedirect?: boolean;
        /**
         * The path that will be used in the redirect response instead of the one that was
         * supplied in the request. pathRedirect cannot be supplied together with
         * prefixRedirect. Supply one alone or neither. If neither is supplied, the path of the
         * original request will be used for the redirect. The value must be between 1 and 1024
         * characters.
         */
        pathRedirect?: string;
        /**
         * The prefix that replaces the prefixMatch specified in the HttpRouteRuleMatch,
         * retaining the remaining portion of the URL before redirecting the request.
         * prefixRedirect cannot be supplied together with pathRedirect. Supply one alone or
         * neither. If neither is supplied, the path of the original request will be used for
         * the redirect. The value must be between 1 and 1024 characters.
         */
        prefixRedirect?: string;
        /**
         * The HTTP Status code to use for this RedirectAction. Supported values are:
         * * MOVED_PERMANENTLY_DEFAULT, which is the default value and corresponds to 301.
         * * FOUND, which corresponds to 302.
         * * SEE_OTHER which corresponds to 303.
         * * TEMPORARY_REDIRECT, which corresponds to 307. In this case, the request method
         * will be retained.
         * * PERMANENT_REDIRECT, which corresponds to 308. In this case,
         * the request method will be retained.
         */
        redirectResponseCode?: string;
        /**
         * If set to true, any accompanying query portion of the original URL is removed prior
         * to redirecting the request. If set to false, the query portion of the original URL is
         * retained. The default is set to false.
         * This field is required to ensure an empty block is not set. The normal default value is false.
         */
        stripQuery: boolean;
    }

    export interface URLMapHeaderAction {
        /**
         * Headers to add to a matching request prior to forwarding the request to the backendService.
         * Structure is documented below.
         */
        requestHeadersToAdds?: outputs.compute.URLMapHeaderActionRequestHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the request prior to
         * forwarding the request to the backendService.
         */
        requestHeadersToRemoves?: string[];
        /**
         * Headers to add the response prior to sending the response back to the client.
         * Structure is documented below.
         */
        responseHeadersToAdds?: outputs.compute.URLMapHeaderActionResponseHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the response prior to sending the
         * response back to the client.
         */
        responseHeadersToRemoves?: string[];
    }

    export interface URLMapHeaderActionRequestHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace: boolean;
    }

    export interface URLMapHeaderActionResponseHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace: boolean;
    }

    export interface URLMapHostRule {
        /**
         * Description of this test case.
         */
        description?: string;
        /**
         * The list of host patterns to match. They must be valid hostnames, except * will
         * match any string of ([a-z0-9-.]*). In that case, * must be the first character
         * and must be followed in the pattern by either - or ..
         */
        hosts: string[];
        /**
         * The name of the PathMatcher to use to match the path portion of the URL if the
         * hostRule matches the URL's host portion.
         */
        pathMatcher: string;
    }

    export interface URLMapPathMatcher {
        /**
         * defaultRouteAction takes effect when none of the pathRules or routeRules match. The load balancer performs
         * advanced routing actions like URL rewrites, header transformations, etc. prior to forwarding the request
         * to the selected backend. If defaultRouteAction specifies any weightedBackendServices, defaultService must not be set.
         * Conversely if defaultService is set, defaultRouteAction cannot contain any weightedBackendServices.
         * Only one of defaultRouteAction or defaultUrlRedirect must be set.
         * Structure is documented below.
         */
        defaultRouteAction?: outputs.compute.URLMapPathMatcherDefaultRouteAction;
        /**
         * The backend service or backend bucket to use when none of the given paths match.
         */
        defaultService?: string;
        /**
         * When none of the specified hostRules match, the request is redirected to a URL specified
         * by defaultUrlRedirect. If defaultUrlRedirect is specified, defaultService or
         * defaultRouteAction must not be set.
         * Structure is documented below.
         */
        defaultUrlRedirect?: outputs.compute.URLMapPathMatcherDefaultUrlRedirect;
        /**
         * Description of this test case.
         */
        description?: string;
        /**
         * Specifies changes to request and response headers that need to take effect for
         * the selected backendService.
         * headerAction specified here take effect before headerAction in the enclosing
         * HttpRouteRule, PathMatcher and UrlMap.
         * Structure is documented below.
         */
        headerAction?: outputs.compute.URLMapPathMatcherHeaderAction;
        /**
         * The name of the query parameter to match. The query parameter must exist in the
         * request, in the absence of which the request match fails.
         */
        name: string;
        /**
         * The list of path rules. Use this list instead of routeRules when routing based
         * on simple path matching is all that's required. The order by which path rules
         * are specified does not matter. Matches are always done on the longest-path-first
         * basis. For example: a pathRule with a path /a/b/c/* will match before /a/b/*
         * irrespective of the order in which those paths appear in this list. Within a
         * given pathMatcher, only one of pathRules or routeRules must be set.
         * Structure is documented below.
         */
        pathRules?: outputs.compute.URLMapPathMatcherPathRule[];
        /**
         * The list of ordered HTTP route rules. Use this list instead of pathRules when
         * advanced route matching and routing actions are desired. The order of specifying
         * routeRules matters: the first rule that matches will cause its specified routing
         * action to take effect. Within a given pathMatcher, only one of pathRules or
         * routeRules must be set. routeRules are not supported in UrlMaps intended for
         * External load balancers.
         * Structure is documented below.
         */
        routeRules?: outputs.compute.URLMapPathMatcherRouteRule[];
    }

    export interface URLMapPathMatcherDefaultRouteAction {
        /**
         * The specification for allowing client side cross-origin requests. Please see
         * [W3C Recommendation for Cross Origin Resource Sharing](https://www.w3.org/TR/cors/)
         * Structure is documented below.
         */
        corsPolicy?: outputs.compute.URLMapPathMatcherDefaultRouteActionCorsPolicy;
        /**
         * The specification for fault injection introduced into traffic to test the resiliency of clients to backend service failure.
         * As part of fault injection, when clients send requests to a backend service, delays can be introduced by Loadbalancer on a
         * percentage of requests before sending those request to the backend service. Similarly requests from clients can be aborted
         * by the Loadbalancer for a percentage of requests.
         * timeout and retryPolicy will be ignored by clients that are configured with a faultInjectionPolicy.
         * Structure is documented below.
         */
        faultInjectionPolicy?: outputs.compute.URLMapPathMatcherDefaultRouteActionFaultInjectionPolicy;
        /**
         * Specifies the policy on how requests intended for the route's backends are shadowed to a separate mirrored backend service.
         * Loadbalancer does not wait for responses from the shadow service. Prior to sending traffic to the shadow service,
         * the host / authority header is suffixed with -shadow.
         * Structure is documented below.
         */
        requestMirrorPolicy?: outputs.compute.URLMapPathMatcherDefaultRouteActionRequestMirrorPolicy;
        /**
         * Specifies the retry policy associated with this route.
         * Structure is documented below.
         */
        retryPolicy?: outputs.compute.URLMapPathMatcherDefaultRouteActionRetryPolicy;
        /**
         * Specifies the timeout for the selected route. Timeout is computed from the time the request has been
         * fully processed (i.e. end-of-stream) up until the response has been completely processed. Timeout includes all retries.
         * If not specified, will use the largest timeout among all backend services associated with the route.
         * Structure is documented below.
         */
        timeout: outputs.compute.URLMapPathMatcherDefaultRouteActionTimeout;
        /**
         * The spec to modify the URL of the request, prior to forwarding the request to the matched service.
         * Structure is documented below.
         */
        urlRewrite?: outputs.compute.URLMapPathMatcherDefaultRouteActionUrlRewrite;
        /**
         * A list of weighted backend services to send traffic to when a route match occurs.
         * The weights determine the fraction of traffic that flows to their corresponding backend service.
         * If all traffic needs to go to a single backend service, there must be one weightedBackendService
         * with weight set to a non 0 number.
         * Once a backendService is identified and before forwarding the request to the backend service,
         * advanced routing actions like Url rewrites and header transformations are applied depending on
         * additional settings specified in this HttpRouteAction.
         * Structure is documented below.
         */
        weightedBackendServices?: outputs.compute.URLMapPathMatcherDefaultRouteActionWeightedBackendService[];
    }

    export interface URLMapPathMatcherDefaultRouteActionCorsPolicy {
        /**
         * In response to a preflight request, setting this to true indicates that the actual request can include user credentials.
         * This translates to the Access-Control-Allow-Credentials header.
         */
        allowCredentials?: boolean;
        /**
         * Specifies the content for the Access-Control-Allow-Headers header.
         */
        allowHeaders?: string[];
        /**
         * Specifies the content for the Access-Control-Allow-Methods header.
         */
        allowMethods?: string[];
        /**
         * Specifies the regular expression patterns that match allowed origins. For regular expression grammar
         * please see en.cppreference.com/w/cpp/regex/ecmascript
         * An origin is allowed if it matches either an item in allowOrigins or an item in allowOriginRegexes.
         */
        allowOriginRegexes?: string[];
        /**
         * Specifies the list of origins that will be allowed to do CORS requests.
         * An origin is allowed if it matches either an item in allowOrigins or an item in allowOriginRegexes.
         */
        allowOrigins?: string[];
        /**
         * If true, specifies the CORS policy is disabled. The default value is false, which indicates that the CORS policy is in effect.
         */
        disabled?: boolean;
        /**
         * Specifies the content for the Access-Control-Expose-Headers header.
         */
        exposeHeaders?: string[];
        /**
         * Specifies how long results of a preflight request can be cached in seconds.
         * This translates to the Access-Control-Max-Age header.
         */
        maxAge?: number;
    }

    export interface URLMapPathMatcherDefaultRouteActionFaultInjectionPolicy {
        /**
         * The specification for how client requests are aborted as part of fault injection.
         * Structure is documented below.
         */
        abort?: outputs.compute.URLMapPathMatcherDefaultRouteActionFaultInjectionPolicyAbort;
        /**
         * The specification for how client requests are delayed as part of fault injection, before being sent to a backend service.
         * Structure is documented below.
         */
        delay?: outputs.compute.URLMapPathMatcherDefaultRouteActionFaultInjectionPolicyDelay;
    }

    export interface URLMapPathMatcherDefaultRouteActionFaultInjectionPolicyAbort {
        /**
         * The HTTP status code used to abort the request.
         * The value must be between 200 and 599 inclusive.
         */
        httpStatus?: number;
        /**
         * The percentage of traffic (connections/operations/requests) which will be aborted as part of fault injection.
         * The value must be between 0.0 and 100.0 inclusive.
         */
        percentage?: number;
    }

    export interface URLMapPathMatcherDefaultRouteActionFaultInjectionPolicyDelay {
        /**
         * Specifies the value of the fixed delay interval.
         * Structure is documented below.
         */
        fixedDelay?: outputs.compute.URLMapPathMatcherDefaultRouteActionFaultInjectionPolicyDelayFixedDelay;
        /**
         * The percentage of traffic (connections/operations/requests) which will be aborted as part of fault injection.
         * The value must be between 0.0 and 100.0 inclusive.
         */
        percentage?: number;
    }

    export interface URLMapPathMatcherDefaultRouteActionFaultInjectionPolicyDelayFixedDelay {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are
         * represented with a 0 seconds field and a positive nanos field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive.
         * Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
         */
        seconds?: string;
    }

    export interface URLMapPathMatcherDefaultRouteActionRequestMirrorPolicy {
        /**
         * The full or partial URL to the BackendService resource being mirrored to.
         */
        backendService: string;
    }

    export interface URLMapPathMatcherDefaultRouteActionRetryPolicy {
        /**
         * Specifies the allowed number retries. This number must be > 0. If not specified, defaults to 1.
         */
        numRetries?: number;
        /**
         * Specifies a non-zero timeout per retry attempt.
         * If not specified, will use the timeout set in HttpRouteAction. If timeout in HttpRouteAction is not set,
         * will use the largest timeout among all backend services associated with the route.
         * Structure is documented below.
         */
        perTryTimeout?: outputs.compute.URLMapPathMatcherDefaultRouteActionRetryPolicyPerTryTimeout;
        /**
         * Specfies one or more conditions when this retry rule applies. Valid values are:
         * * 5xx: Loadbalancer will attempt a retry if the backend service responds with any 5xx response code,
         * or if the backend service does not respond at all, example: disconnects, reset, read timeout,
         * * connection failure, and refused streams.
         * * gateway-error: Similar to 5xx, but only applies to response codes 502, 503 or 504.
         * * connect-failure: Loadbalancer will retry on failures connecting to backend services,
         * for example due to connection timeouts.
         * * retriable-4xx: Loadbalancer will retry for retriable 4xx response codes.
         * Currently the only retriable error supported is 409.
         * * refused-stream:Loadbalancer will retry if the backend service resets the stream with a REFUSED_STREAM error code.
         * This reset type indicates that it is safe to retry.
         * * cancelled: Loadbalancer will retry if the gRPC status code in the response header is set to cancelled
         * * deadline-exceeded: Loadbalancer will retry if the gRPC status code in the response header is set to deadline-exceeded
         * * resource-exhausted: Loadbalancer will retry if the gRPC status code in the response header is set to resource-exhausted
         * * unavailable: Loadbalancer will retry if the gRPC status code in the response header is set to unavailable
         */
        retryConditions?: string[];
    }

    export interface URLMapPathMatcherDefaultRouteActionRetryPolicyPerTryTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are
         * represented with a 0 seconds field and a positive nanos field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive.
         * Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
         */
        seconds?: string;
    }

    export interface URLMapPathMatcherDefaultRouteActionTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are
         * represented with a 0 seconds field and a positive nanos field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive.
         * Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
         */
        seconds?: string;
    }

    export interface URLMapPathMatcherDefaultRouteActionUrlRewrite {
        /**
         * Prior to forwarding the request to the selected service, the request's host header is replaced
         * with contents of hostRewrite.
         * The value must be between 1 and 255 characters.
         */
        hostRewrite?: string;
        /**
         * Prior to forwarding the request to the selected backend service, the matching portion of the
         * request's path is replaced by pathPrefixRewrite.
         * The value must be between 1 and 1024 characters.
         */
        pathPrefixRewrite?: string;
    }

    export interface URLMapPathMatcherDefaultRouteActionWeightedBackendService {
        /**
         * The full or partial URL to the BackendService resource being mirrored to.
         */
        backendService?: string;
        /**
         * Specifies changes to request and response headers that need to take effect for
         * the selected backendService.
         * headerAction specified here take effect before headerAction in the enclosing
         * HttpRouteRule, PathMatcher and UrlMap.
         * Structure is documented below.
         */
        headerAction?: outputs.compute.URLMapPathMatcherDefaultRouteActionWeightedBackendServiceHeaderAction;
        /**
         * Specifies the fraction of traffic sent to backendService, computed as
         * weight / (sum of all weightedBackendService weights in routeAction) .
         * The selection of a backend service is determined only for new traffic. Once a user's request
         * has been directed to a backendService, subsequent requests will be sent to the same backendService
         * as determined by the BackendService's session affinity policy.
         * The value must be between 0 and 1000
         */
        weight?: number;
    }

    export interface URLMapPathMatcherDefaultRouteActionWeightedBackendServiceHeaderAction {
        /**
         * Headers to add to a matching request prior to forwarding the request to the backendService.
         * Structure is documented below.
         */
        requestHeadersToAdds?: outputs.compute.URLMapPathMatcherDefaultRouteActionWeightedBackendServiceHeaderActionRequestHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the request prior to
         * forwarding the request to the backendService.
         */
        requestHeadersToRemoves?: string[];
        /**
         * Headers to add the response prior to sending the response back to the client.
         * Structure is documented below.
         */
        responseHeadersToAdds?: outputs.compute.URLMapPathMatcherDefaultRouteActionWeightedBackendServiceHeaderActionResponseHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the response prior to sending the
         * response back to the client.
         */
        responseHeadersToRemoves?: string[];
    }

    export interface URLMapPathMatcherDefaultRouteActionWeightedBackendServiceHeaderActionRequestHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName?: string;
        /**
         * The value of the header to add.
         */
        headerValue?: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace?: boolean;
    }

    export interface URLMapPathMatcherDefaultRouteActionWeightedBackendServiceHeaderActionResponseHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName?: string;
        /**
         * The value of the header to add.
         */
        headerValue?: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace?: boolean;
    }

    export interface URLMapPathMatcherDefaultUrlRedirect {
        /**
         * The host that will be used in the redirect response instead of the one that was
         * supplied in the request. The value must be between 1 and 255 characters.
         */
        hostRedirect?: string;
        /**
         * If set to true, the URL scheme in the redirected request is set to https. If set to
         * false, the URL scheme of the redirected request will remain the same as that of the
         * request. This must only be set for UrlMaps used in TargetHttpProxys. Setting this
         * true for TargetHttpsProxy is not permitted. The default is set to false.
         */
        httpsRedirect?: boolean;
        /**
         * The path that will be used in the redirect response instead of the one that was
         * supplied in the request. pathRedirect cannot be supplied together with
         * prefixRedirect. Supply one alone or neither. If neither is supplied, the path of the
         * original request will be used for the redirect. The value must be between 1 and 1024
         * characters.
         */
        pathRedirect?: string;
        /**
         * The prefix that replaces the prefixMatch specified in the HttpRouteRuleMatch,
         * retaining the remaining portion of the URL before redirecting the request.
         * prefixRedirect cannot be supplied together with pathRedirect. Supply one alone or
         * neither. If neither is supplied, the path of the original request will be used for
         * the redirect. The value must be between 1 and 1024 characters.
         */
        prefixRedirect?: string;
        /**
         * The HTTP Status code to use for this RedirectAction. Supported values are:
         * * MOVED_PERMANENTLY_DEFAULT, which is the default value and corresponds to 301.
         * * FOUND, which corresponds to 302.
         * * SEE_OTHER which corresponds to 303.
         * * TEMPORARY_REDIRECT, which corresponds to 307. In this case, the request method
         * will be retained.
         * * PERMANENT_REDIRECT, which corresponds to 308. In this case,
         * the request method will be retained.
         */
        redirectResponseCode?: string;
        /**
         * If set to true, any accompanying query portion of the original URL is removed prior
         * to redirecting the request. If set to false, the query portion of the original URL is
         * retained. The default is set to false.
         * This field is required to ensure an empty block is not set. The normal default value is false.
         */
        stripQuery: boolean;
    }

    export interface URLMapPathMatcherHeaderAction {
        /**
         * Headers to add to a matching request prior to forwarding the request to the backendService.
         * Structure is documented below.
         */
        requestHeadersToAdds?: outputs.compute.URLMapPathMatcherHeaderActionRequestHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the request prior to
         * forwarding the request to the backendService.
         */
        requestHeadersToRemoves?: string[];
        /**
         * Headers to add the response prior to sending the response back to the client.
         * Structure is documented below.
         */
        responseHeadersToAdds?: outputs.compute.URLMapPathMatcherHeaderActionResponseHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the response prior to sending the
         * response back to the client.
         */
        responseHeadersToRemoves?: string[];
    }

    export interface URLMapPathMatcherHeaderActionRequestHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace: boolean;
    }

    export interface URLMapPathMatcherHeaderActionResponseHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace: boolean;
    }

    export interface URLMapPathMatcherPathRule {
        /**
         * The list of path patterns to match. Each must start with / and the only place a
         * \* is allowed is at the end following a /. The string fed to the path matcher
         * does not include any text after the first ? or #, and those chars are not
         * allowed here.
         */
        paths: string[];
        /**
         * In response to a matching matchRule, the load balancer performs advanced routing
         * actions like URL rewrites, header transformations, etc. prior to forwarding the
         * request to the selected backend. If  routeAction specifies any
         * weightedBackendServices, service must not be set. Conversely if service is set,
         * routeAction cannot contain any  weightedBackendServices. Only one of routeAction
         * or urlRedirect must be set.
         * Structure is documented below.
         */
        routeAction?: outputs.compute.URLMapPathMatcherPathRuleRouteAction;
        /**
         * The backend service or backend bucket link that should be matched by this test.
         */
        service?: string;
        /**
         * When this rule is matched, the request is redirected to a URL specified by
         * urlRedirect. If urlRedirect is specified, service or routeAction must not be
         * set.
         * Structure is documented below.
         */
        urlRedirect?: outputs.compute.URLMapPathMatcherPathRuleUrlRedirect;
    }

    export interface URLMapPathMatcherPathRuleRouteAction {
        /**
         * The specification for allowing client side cross-origin requests. Please see
         * [W3C Recommendation for Cross Origin Resource Sharing](https://www.w3.org/TR/cors/)
         * Structure is documented below.
         */
        corsPolicy?: outputs.compute.URLMapPathMatcherPathRuleRouteActionCorsPolicy;
        /**
         * The specification for fault injection introduced into traffic to test the resiliency of clients to backend service failure.
         * As part of fault injection, when clients send requests to a backend service, delays can be introduced by Loadbalancer on a
         * percentage of requests before sending those request to the backend service. Similarly requests from clients can be aborted
         * by the Loadbalancer for a percentage of requests.
         * timeout and retryPolicy will be ignored by clients that are configured with a faultInjectionPolicy.
         * Structure is documented below.
         */
        faultInjectionPolicy?: outputs.compute.URLMapPathMatcherPathRuleRouteActionFaultInjectionPolicy;
        /**
         * Specifies the policy on how requests intended for the route's backends are shadowed to a separate mirrored backend service.
         * Loadbalancer does not wait for responses from the shadow service. Prior to sending traffic to the shadow service,
         * the host / authority header is suffixed with -shadow.
         * Structure is documented below.
         */
        requestMirrorPolicy?: outputs.compute.URLMapPathMatcherPathRuleRouteActionRequestMirrorPolicy;
        /**
         * Specifies the retry policy associated with this route.
         * Structure is documented below.
         */
        retryPolicy?: outputs.compute.URLMapPathMatcherPathRuleRouteActionRetryPolicy;
        /**
         * Specifies the timeout for the selected route. Timeout is computed from the time the request has been
         * fully processed (i.e. end-of-stream) up until the response has been completely processed. Timeout includes all retries.
         * If not specified, will use the largest timeout among all backend services associated with the route.
         * Structure is documented below.
         */
        timeout?: outputs.compute.URLMapPathMatcherPathRuleRouteActionTimeout;
        /**
         * The spec to modify the URL of the request, prior to forwarding the request to the matched service.
         * Structure is documented below.
         */
        urlRewrite?: outputs.compute.URLMapPathMatcherPathRuleRouteActionUrlRewrite;
        /**
         * A list of weighted backend services to send traffic to when a route match occurs.
         * The weights determine the fraction of traffic that flows to their corresponding backend service.
         * If all traffic needs to go to a single backend service, there must be one weightedBackendService
         * with weight set to a non 0 number.
         * Once a backendService is identified and before forwarding the request to the backend service,
         * advanced routing actions like Url rewrites and header transformations are applied depending on
         * additional settings specified in this HttpRouteAction.
         * Structure is documented below.
         */
        weightedBackendServices?: outputs.compute.URLMapPathMatcherPathRuleRouteActionWeightedBackendService[];
    }

    export interface URLMapPathMatcherPathRuleRouteActionCorsPolicy {
        /**
         * In response to a preflight request, setting this to true indicates that the actual request can include user credentials.
         * This translates to the Access-Control-Allow-Credentials header.
         */
        allowCredentials?: boolean;
        /**
         * Specifies the content for the Access-Control-Allow-Headers header.
         */
        allowHeaders?: string[];
        /**
         * Specifies the content for the Access-Control-Allow-Methods header.
         */
        allowMethods?: string[];
        /**
         * Specifies the regular expression patterns that match allowed origins. For regular expression grammar
         * please see en.cppreference.com/w/cpp/regex/ecmascript
         * An origin is allowed if it matches either an item in allowOrigins or an item in allowOriginRegexes.
         */
        allowOriginRegexes?: string[];
        /**
         * Specifies the list of origins that will be allowed to do CORS requests.
         * An origin is allowed if it matches either an item in allowOrigins or an item in allowOriginRegexes.
         */
        allowOrigins?: string[];
        /**
         * If true, specifies the CORS policy is disabled. The default value is false, which indicates that the CORS policy is in effect.
         */
        disabled: boolean;
        /**
         * Specifies the content for the Access-Control-Expose-Headers header.
         */
        exposeHeaders?: string[];
        /**
         * Specifies how long results of a preflight request can be cached in seconds.
         * This translates to the Access-Control-Max-Age header.
         */
        maxAge?: number;
    }

    export interface URLMapPathMatcherPathRuleRouteActionFaultInjectionPolicy {
        /**
         * The specification for how client requests are aborted as part of fault injection.
         * Structure is documented below.
         */
        abort?: outputs.compute.URLMapPathMatcherPathRuleRouteActionFaultInjectionPolicyAbort;
        /**
         * The specification for how client requests are delayed as part of fault injection, before being sent to a backend service.
         * Structure is documented below.
         */
        delay?: outputs.compute.URLMapPathMatcherPathRuleRouteActionFaultInjectionPolicyDelay;
    }

    export interface URLMapPathMatcherPathRuleRouteActionFaultInjectionPolicyAbort {
        /**
         * The HTTP status code used to abort the request.
         * The value must be between 200 and 599 inclusive.
         */
        httpStatus: number;
        /**
         * The percentage of traffic (connections/operations/requests) which will be aborted as part of fault injection.
         * The value must be between 0.0 and 100.0 inclusive.
         */
        percentage: number;
    }

    export interface URLMapPathMatcherPathRuleRouteActionFaultInjectionPolicyDelay {
        /**
         * Specifies the value of the fixed delay interval.
         * Structure is documented below.
         */
        fixedDelay: outputs.compute.URLMapPathMatcherPathRuleRouteActionFaultInjectionPolicyDelayFixedDelay;
        /**
         * The percentage of traffic (connections/operations/requests) which will be aborted as part of fault injection.
         * The value must be between 0.0 and 100.0 inclusive.
         */
        percentage: number;
    }

    export interface URLMapPathMatcherPathRuleRouteActionFaultInjectionPolicyDelayFixedDelay {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are
         * represented with a 0 seconds field and a positive nanos field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive.
         * Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
         */
        seconds: string;
    }

    export interface URLMapPathMatcherPathRuleRouteActionRequestMirrorPolicy {
        /**
         * The full or partial URL to the BackendService resource being mirrored to.
         */
        backendService: string;
    }

    export interface URLMapPathMatcherPathRuleRouteActionRetryPolicy {
        /**
         * Specifies the allowed number retries. This number must be > 0. If not specified, defaults to 1.
         */
        numRetries?: number;
        /**
         * Specifies a non-zero timeout per retry attempt.
         * If not specified, will use the timeout set in HttpRouteAction. If timeout in HttpRouteAction is not set,
         * will use the largest timeout among all backend services associated with the route.
         * Structure is documented below.
         */
        perTryTimeout?: outputs.compute.URLMapPathMatcherPathRuleRouteActionRetryPolicyPerTryTimeout;
        /**
         * Specfies one or more conditions when this retry rule applies. Valid values are:
         * * 5xx: Loadbalancer will attempt a retry if the backend service responds with any 5xx response code,
         * or if the backend service does not respond at all, example: disconnects, reset, read timeout,
         * * connection failure, and refused streams.
         * * gateway-error: Similar to 5xx, but only applies to response codes 502, 503 or 504.
         * * connect-failure: Loadbalancer will retry on failures connecting to backend services,
         * for example due to connection timeouts.
         * * retriable-4xx: Loadbalancer will retry for retriable 4xx response codes.
         * Currently the only retriable error supported is 409.
         * * refused-stream:Loadbalancer will retry if the backend service resets the stream with a REFUSED_STREAM error code.
         * This reset type indicates that it is safe to retry.
         * * cancelled: Loadbalancer will retry if the gRPC status code in the response header is set to cancelled
         * * deadline-exceeded: Loadbalancer will retry if the gRPC status code in the response header is set to deadline-exceeded
         * * resource-exhausted: Loadbalancer will retry if the gRPC status code in the response header is set to resource-exhausted
         * * unavailable: Loadbalancer will retry if the gRPC status code in the response header is set to unavailable
         */
        retryConditions?: string[];
    }

    export interface URLMapPathMatcherPathRuleRouteActionRetryPolicyPerTryTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are
         * represented with a 0 seconds field and a positive nanos field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive.
         * Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
         */
        seconds: string;
    }

    export interface URLMapPathMatcherPathRuleRouteActionTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are
         * represented with a 0 seconds field and a positive nanos field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive.
         * Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
         */
        seconds: string;
    }

    export interface URLMapPathMatcherPathRuleRouteActionUrlRewrite {
        /**
         * Prior to forwarding the request to the selected service, the request's host header is replaced
         * with contents of hostRewrite.
         * The value must be between 1 and 255 characters.
         */
        hostRewrite?: string;
        /**
         * Prior to forwarding the request to the selected backend service, the matching portion of the
         * request's path is replaced by pathPrefixRewrite.
         * The value must be between 1 and 1024 characters.
         */
        pathPrefixRewrite?: string;
    }

    export interface URLMapPathMatcherPathRuleRouteActionWeightedBackendService {
        /**
         * The full or partial URL to the BackendService resource being mirrored to.
         */
        backendService: string;
        /**
         * Specifies changes to request and response headers that need to take effect for
         * the selected backendService.
         * headerAction specified here take effect before headerAction in the enclosing
         * HttpRouteRule, PathMatcher and UrlMap.
         * Structure is documented below.
         */
        headerAction?: outputs.compute.URLMapPathMatcherPathRuleRouteActionWeightedBackendServiceHeaderAction;
        /**
         * Specifies the fraction of traffic sent to backendService, computed as
         * weight / (sum of all weightedBackendService weights in routeAction) .
         * The selection of a backend service is determined only for new traffic. Once a user's request
         * has been directed to a backendService, subsequent requests will be sent to the same backendService
         * as determined by the BackendService's session affinity policy.
         * The value must be between 0 and 1000
         */
        weight: number;
    }

    export interface URLMapPathMatcherPathRuleRouteActionWeightedBackendServiceHeaderAction {
        /**
         * Headers to add to a matching request prior to forwarding the request to the backendService.
         * Structure is documented below.
         */
        requestHeadersToAdds?: outputs.compute.URLMapPathMatcherPathRuleRouteActionWeightedBackendServiceHeaderActionRequestHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the request prior to
         * forwarding the request to the backendService.
         */
        requestHeadersToRemoves?: string[];
        /**
         * Headers to add the response prior to sending the response back to the client.
         * Structure is documented below.
         */
        responseHeadersToAdds?: outputs.compute.URLMapPathMatcherPathRuleRouteActionWeightedBackendServiceHeaderActionResponseHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the response prior to sending the
         * response back to the client.
         */
        responseHeadersToRemoves?: string[];
    }

    export interface URLMapPathMatcherPathRuleRouteActionWeightedBackendServiceHeaderActionRequestHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace: boolean;
    }

    export interface URLMapPathMatcherPathRuleRouteActionWeightedBackendServiceHeaderActionResponseHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace: boolean;
    }

    export interface URLMapPathMatcherPathRuleUrlRedirect {
        /**
         * The host that will be used in the redirect response instead of the one that was
         * supplied in the request. The value must be between 1 and 255 characters.
         */
        hostRedirect?: string;
        /**
         * If set to true, the URL scheme in the redirected request is set to https. If set to
         * false, the URL scheme of the redirected request will remain the same as that of the
         * request. This must only be set for UrlMaps used in TargetHttpProxys. Setting this
         * true for TargetHttpsProxy is not permitted. The default is set to false.
         */
        httpsRedirect?: boolean;
        /**
         * The path that will be used in the redirect response instead of the one that was
         * supplied in the request. pathRedirect cannot be supplied together with
         * prefixRedirect. Supply one alone or neither. If neither is supplied, the path of the
         * original request will be used for the redirect. The value must be between 1 and 1024
         * characters.
         */
        pathRedirect?: string;
        /**
         * The prefix that replaces the prefixMatch specified in the HttpRouteRuleMatch,
         * retaining the remaining portion of the URL before redirecting the request.
         * prefixRedirect cannot be supplied together with pathRedirect. Supply one alone or
         * neither. If neither is supplied, the path of the original request will be used for
         * the redirect. The value must be between 1 and 1024 characters.
         */
        prefixRedirect?: string;
        /**
         * The HTTP Status code to use for this RedirectAction. Supported values are:
         * * MOVED_PERMANENTLY_DEFAULT, which is the default value and corresponds to 301.
         * * FOUND, which corresponds to 302.
         * * SEE_OTHER which corresponds to 303.
         * * TEMPORARY_REDIRECT, which corresponds to 307. In this case, the request method
         * will be retained.
         * * PERMANENT_REDIRECT, which corresponds to 308. In this case,
         * the request method will be retained.
         */
        redirectResponseCode?: string;
        /**
         * If set to true, any accompanying query portion of the original URL is removed prior
         * to redirecting the request. If set to false, the query portion of the original URL is
         * retained. The default is set to false.
         * This field is required to ensure an empty block is not set. The normal default value is false.
         */
        stripQuery: boolean;
    }

    export interface URLMapPathMatcherRouteRule {
        /**
         * Specifies changes to request and response headers that need to take effect for
         * the selected backendService.
         * headerAction specified here take effect before headerAction in the enclosing
         * HttpRouteRule, PathMatcher and UrlMap.
         * Structure is documented below.
         */
        headerAction?: outputs.compute.URLMapPathMatcherRouteRuleHeaderAction;
        /**
         * The rules for determining a match.
         * Structure is documented below.
         */
        matchRules?: outputs.compute.URLMapPathMatcherRouteRuleMatchRule[];
        /**
         * For routeRules within a given pathMatcher, priority determines the order
         * in which load balancer will interpret routeRules. RouteRules are evaluated
         * in order of priority, from the lowest to highest number. The priority of
         * a rule decreases as its number increases (1, 2, 3, N+1). The first rule
         * that matches the request is applied.
         * You cannot configure two or more routeRules with the same priority.
         * Priority for each rule must be set to a number between 0 and
         * 2147483647 inclusive.
         * Priority numbers can have gaps, which enable you to add or remove rules
         * in the future without affecting the rest of the rules. For example,
         * 1, 2, 3, 4, 5, 9, 12, 16 is a valid series of priority numbers to which
         * you could add rules numbered from 6 to 8, 10 to 11, and 13 to 15 in the
         * future without any impact on existing rules.
         */
        priority: number;
        /**
         * In response to a matching matchRule, the load balancer performs advanced routing
         * actions like URL rewrites, header transformations, etc. prior to forwarding the
         * request to the selected backend. If  routeAction specifies any
         * weightedBackendServices, service must not be set. Conversely if service is set,
         * routeAction cannot contain any  weightedBackendServices. Only one of routeAction
         * or urlRedirect must be set.
         * Structure is documented below.
         */
        routeAction?: outputs.compute.URLMapPathMatcherRouteRuleRouteAction;
        /**
         * The backend service or backend bucket link that should be matched by this test.
         */
        service?: string;
        /**
         * When this rule is matched, the request is redirected to a URL specified by
         * urlRedirect. If urlRedirect is specified, service or routeAction must not be
         * set.
         * Structure is documented below.
         */
        urlRedirect?: outputs.compute.URLMapPathMatcherRouteRuleUrlRedirect;
    }

    export interface URLMapPathMatcherRouteRuleHeaderAction {
        /**
         * Headers to add to a matching request prior to forwarding the request to the backendService.
         * Structure is documented below.
         */
        requestHeadersToAdds?: outputs.compute.URLMapPathMatcherRouteRuleHeaderActionRequestHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the request prior to
         * forwarding the request to the backendService.
         */
        requestHeadersToRemoves?: string[];
        /**
         * Headers to add the response prior to sending the response back to the client.
         * Structure is documented below.
         */
        responseHeadersToAdds?: outputs.compute.URLMapPathMatcherRouteRuleHeaderActionResponseHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the response prior to sending the
         * response back to the client.
         */
        responseHeadersToRemoves?: string[];
    }

    export interface URLMapPathMatcherRouteRuleHeaderActionRequestHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace: boolean;
    }

    export interface URLMapPathMatcherRouteRuleHeaderActionResponseHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace: boolean;
    }

    export interface URLMapPathMatcherRouteRuleMatchRule {
        /**
         * For satisfying the matchRule condition, the path of the request must exactly
         * match the value specified in fullPathMatch after removing any query parameters
         * and anchor that may be part of the original URL. FullPathMatch must be between 1
         * and 1024 characters. Only one of prefixMatch, fullPathMatch or regexMatch must
         * be specified.
         */
        fullPathMatch?: string;
        /**
         * Specifies a list of header match criteria, all of which must match corresponding
         * headers in the request.
         * Structure is documented below.
         */
        headerMatches?: outputs.compute.URLMapPathMatcherRouteRuleMatchRuleHeaderMatch[];
        /**
         * Specifies that prefixMatch and fullPathMatch matches are case sensitive.
         * Defaults to false.
         */
        ignoreCase?: boolean;
        /**
         * Opaque filter criteria used by Loadbalancer to restrict routing configuration to
         * a limited set xDS compliant clients. In their xDS requests to Loadbalancer, xDS
         * clients present node metadata. If a match takes place, the relevant routing
         * configuration is made available to those proxies. For each metadataFilter in
         * this list, if its filterMatchCriteria is set to MATCH_ANY, at least one of the
         * filterLabels must match the corresponding label provided in the metadata. If its
         * filterMatchCriteria is set to MATCH_ALL, then all of its filterLabels must match
         * with corresponding labels in the provided metadata. metadataFilters specified
         * here can be overrides those specified in ForwardingRule that refers to this
         * UrlMap. metadataFilters only applies to Loadbalancers that have their
         * loadBalancingScheme set to INTERNAL_SELF_MANAGED.
         * Structure is documented below.
         */
        metadataFilters?: outputs.compute.URLMapPathMatcherRouteRuleMatchRuleMetadataFilter[];
        /**
         * The value of the header must start with the contents of prefixMatch. Only one of
         * exactMatch, prefixMatch, suffixMatch, regexMatch, presentMatch or rangeMatch
         * must be set.
         */
        prefixMatch?: string;
        /**
         * Specifies a list of query parameter match criteria, all of which must match
         * corresponding query parameters in the request.
         * Structure is documented below.
         */
        queryParameterMatches?: outputs.compute.URLMapPathMatcherRouteRuleMatchRuleQueryParameterMatch[];
        /**
         * The queryParameterMatch matches if the value of the parameter matches the
         * regular expression specified by regexMatch. For the regular expression grammar,
         * please see en.cppreference.com/w/cpp/regex/ecmascript  Only one of presentMatch,
         * exactMatch and regexMatch must be set.
         */
        regexMatch?: string;
    }

    export interface URLMapPathMatcherRouteRuleMatchRuleHeaderMatch {
        /**
         * The queryParameterMatch matches if the value of the parameter exactly matches
         * the contents of exactMatch. Only one of presentMatch, exactMatch and regexMatch
         * must be set.
         */
        exactMatch?: string;
        /**
         * The name of the header to add.
         */
        headerName: string;
        /**
         * If set to false, the headerMatch is considered a match if the match criteria
         * above are met. If set to true, the headerMatch is considered a match if the
         * match criteria above are NOT met. Defaults to false.
         */
        invertMatch?: boolean;
        /**
         * The value of the header must start with the contents of prefixMatch. Only one of
         * exactMatch, prefixMatch, suffixMatch, regexMatch, presentMatch or rangeMatch
         * must be set.
         */
        prefixMatch?: string;
        /**
         * Specifies that the queryParameterMatch matches if the request contains the query
         * parameter, irrespective of whether the parameter has a value or not. Only one of
         * presentMatch, exactMatch and regexMatch must be set.
         */
        presentMatch?: boolean;
        /**
         * The header value must be an integer and its value must be in the range specified
         * in rangeMatch. If the header does not contain an integer, number or is empty,
         * the match fails. For example for a range [-5, 0]   - -3 will match.  - 0 will
         * not match.  - 0.25 will not match.  - -3someString will not match.   Only one of
         * exactMatch, prefixMatch, suffixMatch, regexMatch, presentMatch or rangeMatch
         * must be set.
         * Structure is documented below.
         */
        rangeMatch?: outputs.compute.URLMapPathMatcherRouteRuleMatchRuleHeaderMatchRangeMatch;
        /**
         * The queryParameterMatch matches if the value of the parameter matches the
         * regular expression specified by regexMatch. For the regular expression grammar,
         * please see en.cppreference.com/w/cpp/regex/ecmascript  Only one of presentMatch,
         * exactMatch and regexMatch must be set.
         */
        regexMatch?: string;
        /**
         * The value of the header must end with the contents of suffixMatch. Only one of
         * exactMatch, prefixMatch, suffixMatch, regexMatch, presentMatch or rangeMatch
         * must be set.
         */
        suffixMatch?: string;
    }

    export interface URLMapPathMatcherRouteRuleMatchRuleHeaderMatchRangeMatch {
        /**
         * The end of the range (exclusive).
         */
        rangeEnd: number;
        /**
         * The start of the range (inclusive).
         */
        rangeStart: number;
    }

    export interface URLMapPathMatcherRouteRuleMatchRuleMetadataFilter {
        /**
         * The list of label value pairs that must match labels in the provided metadata
         * based on filterMatchCriteria  This list must not be empty and can have at the
         * most 64 entries.
         * Structure is documented below.
         */
        filterLabels: outputs.compute.URLMapPathMatcherRouteRuleMatchRuleMetadataFilterFilterLabel[];
        /**
         * Specifies how individual filterLabel matches within the list of filterLabels
         * contribute towards the overall metadataFilter match. Supported values are:
         * - MATCH_ANY: At least one of the filterLabels must have a matching label in the
         * provided metadata.
         * - MATCH_ALL: All filterLabels must have matching labels in
         * the provided metadata.
         * Possible values are `MATCH_ALL` and `MATCH_ANY`.
         */
        filterMatchCriteria: string;
    }

    export interface URLMapPathMatcherRouteRuleMatchRuleMetadataFilterFilterLabel {
        /**
         * The name of the query parameter to match. The query parameter must exist in the
         * request, in the absence of which the request match fails.
         */
        name: string;
        /**
         * The value of the label must match the specified value. value can have a maximum
         * length of 1024 characters.
         */
        value: string;
    }

    export interface URLMapPathMatcherRouteRuleMatchRuleQueryParameterMatch {
        /**
         * The queryParameterMatch matches if the value of the parameter exactly matches
         * the contents of exactMatch. Only one of presentMatch, exactMatch and regexMatch
         * must be set.
         */
        exactMatch?: string;
        /**
         * The name of the query parameter to match. The query parameter must exist in the
         * request, in the absence of which the request match fails.
         */
        name: string;
        /**
         * Specifies that the queryParameterMatch matches if the request contains the query
         * parameter, irrespective of whether the parameter has a value or not. Only one of
         * presentMatch, exactMatch and regexMatch must be set.
         */
        presentMatch?: boolean;
        /**
         * The queryParameterMatch matches if the value of the parameter matches the
         * regular expression specified by regexMatch. For the regular expression grammar,
         * please see en.cppreference.com/w/cpp/regex/ecmascript  Only one of presentMatch,
         * exactMatch and regexMatch must be set.
         */
        regexMatch?: string;
    }

    export interface URLMapPathMatcherRouteRuleRouteAction {
        /**
         * The specification for allowing client side cross-origin requests. Please see
         * [W3C Recommendation for Cross Origin Resource Sharing](https://www.w3.org/TR/cors/)
         * Structure is documented below.
         */
        corsPolicy?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionCorsPolicy;
        /**
         * The specification for fault injection introduced into traffic to test the resiliency of clients to backend service failure.
         * As part of fault injection, when clients send requests to a backend service, delays can be introduced by Loadbalancer on a
         * percentage of requests before sending those request to the backend service. Similarly requests from clients can be aborted
         * by the Loadbalancer for a percentage of requests.
         * timeout and retryPolicy will be ignored by clients that are configured with a faultInjectionPolicy.
         * Structure is documented below.
         */
        faultInjectionPolicy?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionFaultInjectionPolicy;
        /**
         * Specifies the policy on how requests intended for the route's backends are shadowed to a separate mirrored backend service.
         * Loadbalancer does not wait for responses from the shadow service. Prior to sending traffic to the shadow service,
         * the host / authority header is suffixed with -shadow.
         * Structure is documented below.
         */
        requestMirrorPolicy?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionRequestMirrorPolicy;
        /**
         * Specifies the retry policy associated with this route.
         * Structure is documented below.
         */
        retryPolicy?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionRetryPolicy;
        /**
         * Specifies the timeout for the selected route. Timeout is computed from the time the request has been
         * fully processed (i.e. end-of-stream) up until the response has been completely processed. Timeout includes all retries.
         * If not specified, will use the largest timeout among all backend services associated with the route.
         * Structure is documented below.
         */
        timeout?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionTimeout;
        /**
         * The spec to modify the URL of the request, prior to forwarding the request to the matched service.
         * Structure is documented below.
         */
        urlRewrite?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionUrlRewrite;
        /**
         * A list of weighted backend services to send traffic to when a route match occurs.
         * The weights determine the fraction of traffic that flows to their corresponding backend service.
         * If all traffic needs to go to a single backend service, there must be one weightedBackendService
         * with weight set to a non 0 number.
         * Once a backendService is identified and before forwarding the request to the backend service,
         * advanced routing actions like Url rewrites and header transformations are applied depending on
         * additional settings specified in this HttpRouteAction.
         * Structure is documented below.
         */
        weightedBackendServices?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionWeightedBackendService[];
    }

    export interface URLMapPathMatcherRouteRuleRouteActionCorsPolicy {
        /**
         * In response to a preflight request, setting this to true indicates that the actual request can include user credentials.
         * This translates to the Access-Control-Allow-Credentials header.
         */
        allowCredentials?: boolean;
        /**
         * Specifies the content for the Access-Control-Allow-Headers header.
         */
        allowHeaders?: string[];
        /**
         * Specifies the content for the Access-Control-Allow-Methods header.
         */
        allowMethods?: string[];
        /**
         * Specifies the regular expression patterns that match allowed origins. For regular expression grammar
         * please see en.cppreference.com/w/cpp/regex/ecmascript
         * An origin is allowed if it matches either an item in allowOrigins or an item in allowOriginRegexes.
         */
        allowOriginRegexes?: string[];
        /**
         * Specifies the list of origins that will be allowed to do CORS requests.
         * An origin is allowed if it matches either an item in allowOrigins or an item in allowOriginRegexes.
         */
        allowOrigins?: string[];
        /**
         * If true, specifies the CORS policy is disabled. The default value is false, which indicates that the CORS policy is in effect.
         */
        disabled?: boolean;
        /**
         * Specifies the content for the Access-Control-Expose-Headers header.
         */
        exposeHeaders?: string[];
        /**
         * Specifies how long results of a preflight request can be cached in seconds.
         * This translates to the Access-Control-Max-Age header.
         */
        maxAge?: number;
    }

    export interface URLMapPathMatcherRouteRuleRouteActionFaultInjectionPolicy {
        /**
         * The specification for how client requests are aborted as part of fault injection.
         * Structure is documented below.
         */
        abort?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionFaultInjectionPolicyAbort;
        /**
         * The specification for how client requests are delayed as part of fault injection, before being sent to a backend service.
         * Structure is documented below.
         */
        delay?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionFaultInjectionPolicyDelay;
    }

    export interface URLMapPathMatcherRouteRuleRouteActionFaultInjectionPolicyAbort {
        /**
         * The HTTP status code used to abort the request.
         * The value must be between 200 and 599 inclusive.
         */
        httpStatus?: number;
        /**
         * The percentage of traffic (connections/operations/requests) which will be aborted as part of fault injection.
         * The value must be between 0.0 and 100.0 inclusive.
         */
        percentage?: number;
    }

    export interface URLMapPathMatcherRouteRuleRouteActionFaultInjectionPolicyDelay {
        /**
         * Specifies the value of the fixed delay interval.
         * Structure is documented below.
         */
        fixedDelay?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionFaultInjectionPolicyDelayFixedDelay;
        /**
         * The percentage of traffic (connections/operations/requests) which will be aborted as part of fault injection.
         * The value must be between 0.0 and 100.0 inclusive.
         */
        percentage?: number;
    }

    export interface URLMapPathMatcherRouteRuleRouteActionFaultInjectionPolicyDelayFixedDelay {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are
         * represented with a 0 seconds field and a positive nanos field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive.
         * Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
         */
        seconds: string;
    }

    export interface URLMapPathMatcherRouteRuleRouteActionRequestMirrorPolicy {
        /**
         * The full or partial URL to the BackendService resource being mirrored to.
         */
        backendService: string;
    }

    export interface URLMapPathMatcherRouteRuleRouteActionRetryPolicy {
        /**
         * Specifies the allowed number retries. This number must be > 0. If not specified, defaults to 1.
         */
        numRetries: number;
        /**
         * Specifies a non-zero timeout per retry attempt.
         * If not specified, will use the timeout set in HttpRouteAction. If timeout in HttpRouteAction is not set,
         * will use the largest timeout among all backend services associated with the route.
         * Structure is documented below.
         */
        perTryTimeout?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionRetryPolicyPerTryTimeout;
        /**
         * Specfies one or more conditions when this retry rule applies. Valid values are:
         * * 5xx: Loadbalancer will attempt a retry if the backend service responds with any 5xx response code,
         * or if the backend service does not respond at all, example: disconnects, reset, read timeout,
         * * connection failure, and refused streams.
         * * gateway-error: Similar to 5xx, but only applies to response codes 502, 503 or 504.
         * * connect-failure: Loadbalancer will retry on failures connecting to backend services,
         * for example due to connection timeouts.
         * * retriable-4xx: Loadbalancer will retry for retriable 4xx response codes.
         * Currently the only retriable error supported is 409.
         * * refused-stream:Loadbalancer will retry if the backend service resets the stream with a REFUSED_STREAM error code.
         * This reset type indicates that it is safe to retry.
         * * cancelled: Loadbalancer will retry if the gRPC status code in the response header is set to cancelled
         * * deadline-exceeded: Loadbalancer will retry if the gRPC status code in the response header is set to deadline-exceeded
         * * resource-exhausted: Loadbalancer will retry if the gRPC status code in the response header is set to resource-exhausted
         * * unavailable: Loadbalancer will retry if the gRPC status code in the response header is set to unavailable
         */
        retryConditions?: string[];
    }

    export interface URLMapPathMatcherRouteRuleRouteActionRetryPolicyPerTryTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are
         * represented with a 0 seconds field and a positive nanos field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive.
         * Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
         */
        seconds: string;
    }

    export interface URLMapPathMatcherRouteRuleRouteActionTimeout {
        /**
         * Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are
         * represented with a 0 seconds field and a positive nanos field. Must be from 0 to 999,999,999 inclusive.
         */
        nanos?: number;
        /**
         * Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive.
         * Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
         */
        seconds: string;
    }

    export interface URLMapPathMatcherRouteRuleRouteActionUrlRewrite {
        /**
         * Prior to forwarding the request to the selected service, the request's host header is replaced
         * with contents of hostRewrite.
         * The value must be between 1 and 255 characters.
         */
        hostRewrite?: string;
        /**
         * Prior to forwarding the request to the selected backend service, the matching portion of the
         * request's path is replaced by pathPrefixRewrite.
         * The value must be between 1 and 1024 characters.
         */
        pathPrefixRewrite?: string;
    }

    export interface URLMapPathMatcherRouteRuleRouteActionWeightedBackendService {
        /**
         * The full or partial URL to the BackendService resource being mirrored to.
         */
        backendService: string;
        /**
         * Specifies changes to request and response headers that need to take effect for
         * the selected backendService.
         * headerAction specified here take effect before headerAction in the enclosing
         * HttpRouteRule, PathMatcher and UrlMap.
         * Structure is documented below.
         */
        headerAction?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionWeightedBackendServiceHeaderAction;
        /**
         * Specifies the fraction of traffic sent to backendService, computed as
         * weight / (sum of all weightedBackendService weights in routeAction) .
         * The selection of a backend service is determined only for new traffic. Once a user's request
         * has been directed to a backendService, subsequent requests will be sent to the same backendService
         * as determined by the BackendService's session affinity policy.
         * The value must be between 0 and 1000
         */
        weight: number;
    }

    export interface URLMapPathMatcherRouteRuleRouteActionWeightedBackendServiceHeaderAction {
        /**
         * Headers to add to a matching request prior to forwarding the request to the backendService.
         * Structure is documented below.
         */
        requestHeadersToAdds?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionWeightedBackendServiceHeaderActionRequestHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the request prior to
         * forwarding the request to the backendService.
         */
        requestHeadersToRemoves?: string[];
        /**
         * Headers to add the response prior to sending the response back to the client.
         * Structure is documented below.
         */
        responseHeadersToAdds?: outputs.compute.URLMapPathMatcherRouteRuleRouteActionWeightedBackendServiceHeaderActionResponseHeadersToAdd[];
        /**
         * A list of header names for headers that need to be removed from the response prior to sending the
         * response back to the client.
         */
        responseHeadersToRemoves?: string[];
    }

    export interface URLMapPathMatcherRouteRuleRouteActionWeightedBackendServiceHeaderActionRequestHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace: boolean;
    }

    export interface URLMapPathMatcherRouteRuleRouteActionWeightedBackendServiceHeaderActionResponseHeadersToAdd {
        /**
         * The name of the header to add.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * If false, headerValue is appended to any values that already exist for the header.
         * If true, headerValue is set for the header, discarding any values that were set for that header.
         */
        replace: boolean;
    }

    export interface URLMapPathMatcherRouteRuleUrlRedirect {
        /**
         * The host that will be used in the redirect response instead of the one that was
         * supplied in the request. The value must be between 1 and 255 characters.
         */
        hostRedirect?: string;
        /**
         * If set to true, the URL scheme in the redirected request is set to https. If set to
         * false, the URL scheme of the redirected request will remain the same as that of the
         * request. This must only be set for UrlMaps used in TargetHttpProxys. Setting this
         * true for TargetHttpsProxy is not permitted. The default is set to false.
         */
        httpsRedirect?: boolean;
        /**
         * The path that will be used in the redirect response instead of the one that was
         * supplied in the request. pathRedirect cannot be supplied together with
         * prefixRedirect. Supply one alone or neither. If neither is supplied, the path of the
         * original request will be used for the redirect. The value must be between 1 and 1024
         * characters.
         */
        pathRedirect?: string;
        /**
         * The prefix that replaces the prefixMatch specified in the HttpRouteRuleMatch,
         * retaining the remaining portion of the URL before redirecting the request.
         * prefixRedirect cannot be supplied together with pathRedirect. Supply one alone or
         * neither. If neither is supplied, the path of the original request will be used for
         * the redirect. The value must be between 1 and 1024 characters.
         */
        prefixRedirect?: string;
        /**
         * The HTTP Status code to use for this RedirectAction. Supported values are:
         * * MOVED_PERMANENTLY_DEFAULT, which is the default value and corresponds to 301.
         * * FOUND, which corresponds to 302.
         * * SEE_OTHER which corresponds to 303.
         * * TEMPORARY_REDIRECT, which corresponds to 307. In this case, the request method
         * will be retained.
         * * PERMANENT_REDIRECT, which corresponds to 308. In this case,
         * the request method will be retained.
         */
        redirectResponseCode?: string;
        /**
         * If set to true, any accompanying query portion of the original URL is removed prior
         * to redirecting the request. If set to false, the query portion of the original URL is
         * retained. The default is set to false.
         * This field is required to ensure an empty block is not set. The normal default value is false.
         */
        stripQuery?: boolean;
    }

    export interface URLMapTest {
        /**
         * Description of this test case.
         */
        description?: string;
        /**
         * Host portion of the URL.
         */
        host: string;
        /**
         * Path portion of the URL.
         */
        path: string;
        /**
         * The backend service or backend bucket link that should be matched by this test.
         */
        service: string;
    }

}

export namespace config {
    export interface Batching {
        enableBatching?: boolean;
        sendAfter?: string;
    }

}

export namespace container {
    export interface AwsClusterAuthorization {
        /**
         * Users to perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
         */
        adminUsers: outputs.container.AwsClusterAuthorizationAdminUser[];
    }

    export interface AwsClusterAuthorizationAdminUser {
        /**
         * The name of the user, e.g. `my-gcp-id@gmail.com`.
         */
        username: string;
    }

    export interface AwsClusterControlPlane {
        /**
         * Authentication configuration for management of AWS resources.
         */
        awsServicesAuthentication: outputs.container.AwsClusterControlPlaneAwsServicesAuthentication;
        /**
         * The ARN of the AWS KMS key used to encrypt cluster configuration.
         */
        configEncryption: outputs.container.AwsClusterControlPlaneConfigEncryption;
        /**
         * The ARN of the AWS KMS key used to encrypt cluster secrets.
         */
        databaseEncryption: outputs.container.AwsClusterControlPlaneDatabaseEncryption;
        /**
         * The name of the AWS IAM instance pofile to assign to each control plane replica.
         */
        iamInstanceProfile: string;
        /**
         * (Beta only) Details of placement information for an instance.
         */
        instancePlacement: outputs.container.AwsClusterControlPlaneInstancePlacement;
        /**
         * Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
         */
        instanceType: string;
        /**
         * Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 8 GiB with the GP2 volume type.
         */
        mainVolume: outputs.container.AwsClusterControlPlaneMainVolume;
        /**
         * Proxy configuration for outbound HTTP(S) traffic.
         */
        proxyConfig?: outputs.container.AwsClusterControlPlaneProxyConfig;
        /**
         * Optional. Configuration related to the root volume provisioned for each control plane replica. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
         */
        rootVolume: outputs.container.AwsClusterControlPlaneRootVolume;
        /**
         * Optional. The IDs of additional security groups to add to control plane replicas. The Anthos Multi-Cloud API will automatically create and manage security groups with the minimum rules needed for a functioning cluster.
         */
        securityGroupIds?: string[];
        /**
         * Optional. SSH configuration for how to access the underlying control plane machines.
         */
        sshConfig?: outputs.container.AwsClusterControlPlaneSshConfig;
        /**
         * The list of subnets where control plane replicas will run. A replica will be provisioned on each subnet and up to three values can be provided. Each subnet must be in a different AWS Availability Zone (AZ).
         */
        subnetIds: string[];
        /**
         * Optional. A set of AWS resource tags to propagate to all underlying managed AWS resources. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
         */
        tags?: {[key: string]: string};
        /**
         * The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling .
         */
        version: string;
    }

    export interface AwsClusterControlPlaneAwsServicesAuthentication {
        /**
         * The Amazon Resource Name (ARN) of the role that the Anthos Multi-Cloud API will assume when managing AWS resources on your account.
         */
        roleArn: string;
        /**
         * Optional. An identifier for the assumed role session. When unspecified, it defaults to `multicloud-service-agent`.
         */
        roleSessionName: string;
    }

    export interface AwsClusterControlPlaneConfigEncryption {
        /**
         * Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
         */
        kmsKeyArn: string;
    }

    export interface AwsClusterControlPlaneDatabaseEncryption {
        /**
         * Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
         */
        kmsKeyArn: string;
    }

    export interface AwsClusterControlPlaneInstancePlacement {
        /**
         * The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
         */
        tenancy: string;
    }

    export interface AwsClusterControlPlaneMainVolume {
        /**
         * Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
         */
        iops: number;
        /**
         * Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
         */
        kmsKeyArn?: string;
        /**
         * Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
         */
        sizeGib: number;
        /**
         * Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
         */
        volumeType: string;
    }

    export interface AwsClusterControlPlaneProxyConfig {
        /**
         * The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
         */
        secretArn: string;
        /**
         * The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
         */
        secretVersion: string;
    }

    export interface AwsClusterControlPlaneRootVolume {
        /**
         * Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
         */
        iops: number;
        /**
         * Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
         */
        kmsKeyArn?: string;
        /**
         * Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
         */
        sizeGib: number;
        /**
         * Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
         */
        volumeType: string;
    }

    export interface AwsClusterControlPlaneSshConfig {
        /**
         * The name of the EC2 key pair used to login into cluster machines.
         */
        ec2KeyPair: string;
    }

    export interface AwsClusterFleet {
        /**
         * -
         * The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
         */
        membership: string;
        /**
         * The project for the resource
         */
        project: string;
    }

    export interface AwsClusterLoggingConfig {
        /**
         * Configuration of the logging components.
         */
        componentConfig: outputs.container.AwsClusterLoggingConfigComponentConfig;
    }

    export interface AwsClusterLoggingConfigComponentConfig {
        /**
         * Components of the logging configuration to be enabled.
         */
        enableComponents: string[];
    }

    export interface AwsClusterNetworking {
        /**
         * All pods in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
         */
        podAddressCidrBlocks: string[];
        /**
         * All services in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
         */
        serviceAddressCidrBlocks: string[];
        /**
         * The VPC associated with the cluster. All component clusters (i.e. control plane and node pools) run on a single VPC. This field cannot be changed after creation.
         */
        vpcId: string;
    }

    export interface AwsClusterWorkloadIdentityConfig {
        identityProvider: string;
        issuerUri: string;
        workloadPool: string;
    }

    export interface AwsNodePoolAutoscaling {
        /**
         * Maximum number of nodes in the NodePool. Must be >= min_node_count.
         */
        maxNodeCount: number;
        /**
         * Minimum number of nodes in the NodePool. Must be >= 1 and <= max_node_count.
         */
        minNodeCount: number;
    }

    export interface AwsNodePoolConfig {
        /**
         * The ARN of the AWS KMS key used to encrypt node pool configuration.
         */
        configEncryption: outputs.container.AwsNodePoolConfigConfigEncryption;
        /**
         * The name of the AWS IAM role assigned to nodes in the pool.
         */
        iamInstanceProfile: string;
        /**
         * (Beta only) The OS image type to use on node pool instances.
         */
        imageType: string;
        /**
         * (Beta only) Details of placement information for an instance.
         */
        instancePlacement: outputs.container.AwsNodePoolConfigInstancePlacement;
        /**
         * Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
         */
        instanceType: string;
        /**
         * Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
         */
        labels?: {[key: string]: string};
        /**
         * Proxy configuration for outbound HTTP(S) traffic.
         */
        proxyConfig?: outputs.container.AwsNodePoolConfigProxyConfig;
        /**
         * Optional. Template for the root volume provisioned for node pool nodes. Volumes will be provisioned in the availability zone assigned to the node pool subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
         */
        rootVolume: outputs.container.AwsNodePoolConfigRootVolume;
        /**
         * Optional. The IDs of additional security groups to add to nodes in this pool. The manager will automatically create security groups with minimum rules needed for a functioning cluster.
         */
        securityGroupIds?: string[];
        /**
         * Optional. The SSH configuration.
         */
        sshConfig?: outputs.container.AwsNodePoolConfigSshConfig;
        /**
         * Optional. Key/value metadata to assign to each underlying AWS resource. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
         */
        tags?: {[key: string]: string};
        /**
         * Optional. The initial taints assigned to nodes of this node pool.
         */
        taints?: outputs.container.AwsNodePoolConfigTaint[];
    }

    export interface AwsNodePoolConfigConfigEncryption {
        /**
         * Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
         */
        kmsKeyArn: string;
    }

    export interface AwsNodePoolConfigInstancePlacement {
        /**
         * The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
         */
        tenancy: string;
    }

    export interface AwsNodePoolConfigProxyConfig {
        /**
         * The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
         */
        secretArn: string;
        /**
         * The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
         */
        secretVersion: string;
    }

    export interface AwsNodePoolConfigRootVolume {
        /**
         * Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
         */
        iops: number;
        /**
         * Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
         */
        kmsKeyArn?: string;
        /**
         * Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
         */
        sizeGib: number;
        /**
         * Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
         */
        volumeType: string;
    }

    export interface AwsNodePoolConfigSshConfig {
        /**
         * The name of the EC2 key pair used to login into cluster machines.
         */
        ec2KeyPair: string;
    }

    export interface AwsNodePoolConfigTaint {
        /**
         * The taint effect. Possible values: EFFECT_UNSPECIFIED, NO_SCHEDULE, PREFER_NO_SCHEDULE, NO_EXECUTE
         */
        effect: string;
        /**
         * Key for the taint.
         */
        key: string;
        /**
         * Value for the taint.
         */
        value: string;
    }

    export interface AwsNodePoolMaxPodsConstraint {
        /**
         * The maximum number of pods to schedule on a single node.
         */
        maxPodsPerNode: number;
    }

    export interface AzureClusterAuthorization {
        /**
         * Users that can perform operations as a cluster admin. A new ClusterRoleBinding will be created to grant the cluster-admin ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
         */
        adminUsers: outputs.container.AzureClusterAuthorizationAdminUser[];
    }

    export interface AzureClusterAuthorizationAdminUser {
        /**
         * The name of the user, e.g. `my-gcp-id@gmail.com`.
         */
        username: string;
    }

    export interface AzureClusterControlPlane {
        /**
         * Optional. Configuration related to application-layer secrets encryption.
         */
        databaseEncryption?: outputs.container.AzureClusterControlPlaneDatabaseEncryption;
        /**
         * Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. When unspecified, it defaults to a 8-GiB Azure Disk.
         */
        mainVolume: outputs.container.AzureClusterControlPlaneMainVolume;
        /**
         * Proxy configuration for outbound HTTP(S) traffic.
         */
        proxyConfig?: outputs.container.AzureClusterControlPlaneProxyConfig;
        /**
         * Configuration for where to place the control plane replicas. Up to three replica placement instances can be specified. If replicaPlacements is set, the replica placement instances will be applied to the three control plane replicas as evenly as possible.
         */
        replicaPlacements?: outputs.container.AzureClusterControlPlaneReplicaPlacement[];
        /**
         * Optional. Configuration related to the root volume provisioned for each control plane replica. When unspecified, it defaults to 32-GiB Azure Disk.
         */
        rootVolume: outputs.container.AzureClusterControlPlaneRootVolume;
        /**
         * SSH configuration for how to access the underlying control plane machines.
         */
        sshConfig: outputs.container.AzureClusterControlPlaneSshConfig;
        /**
         * For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
         */
        subnetId: string;
        /**
         * Optional. A set of tags to apply to all underlying control plane Azure resources.
         */
        tags?: {[key: string]: string};
        /**
         * The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling GetAzureServerConfig.
         */
        version: string;
        /**
         * Optional. The Azure VM size name. Example: `Standard_DS2_v2`. For available VM sizes, see https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions. When unspecified, it defaults to `Standard_DS2_v2`.
         */
        vmSize: string;
    }

    export interface AzureClusterControlPlaneDatabaseEncryption {
        /**
         * The ARM ID of the Azure Key Vault key to encrypt / decrypt data. For example: `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>` Encryption will always take the latest version of the key and hence specific version is not supported.
         */
        keyId: string;
    }

    export interface AzureClusterControlPlaneMainVolume {
        /**
         * Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
         */
        sizeGib: number;
    }

    export interface AzureClusterControlPlaneProxyConfig {
        /**
         * The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
         */
        resourceGroupId: string;
        /**
         * The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
         */
        secretId: string;
    }

    export interface AzureClusterControlPlaneReplicaPlacement {
        /**
         * For a given replica, the Azure availability zone where to provision the control plane VM and the ETCD disk.
         */
        azureAvailabilityZone: string;
        /**
         * For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
         */
        subnetId: string;
    }

    export interface AzureClusterControlPlaneRootVolume {
        /**
         * Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
         */
        sizeGib: number;
    }

    export interface AzureClusterControlPlaneSshConfig {
        /**
         * The SSH public key data for VMs managed by Anthos. This accepts the authorizedKeys file format used in OpenSSH according to the sshd(8) manual page.
         */
        authorizedKey: string;
    }

    export interface AzureClusterFleet {
        /**
         * -
         * The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
         */
        membership: string;
        /**
         * The project for the resource
         */
        project: string;
    }

    export interface AzureClusterLoggingConfig {
        /**
         * Configuration of the logging components.
         */
        componentConfig: outputs.container.AzureClusterLoggingConfigComponentConfig;
    }

    export interface AzureClusterLoggingConfigComponentConfig {
        /**
         * Components of the logging configuration to be enabled.
         */
        enableComponents: string[];
    }

    export interface AzureClusterNetworking {
        /**
         * The IP address range of the pods in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All pods in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
         */
        podAddressCidrBlocks: string[];
        /**
         * The IP address range for services in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All services in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creating a cluster.
         */
        serviceAddressCidrBlocks: string[];
        /**
         * The Azure Resource Manager (ARM) ID of the VNet associated with your cluster. All components in the cluster (i.e. control plane and node pools) run on a single VNet. Example: `/subscriptions/*&#47;resourceGroups/*&#47;providers/Microsoft.Network/virtualNetworks/*` This field cannot be changed after creation.
         */
        virtualNetworkId: string;
    }

    export interface AzureClusterWorkloadIdentityConfig {
        identityProvider: string;
        issuerUri: string;
        workloadPool: string;
    }

    export interface AzureNodePoolAutoscaling {
        /**
         * Maximum number of nodes in the node pool. Must be >= min_node_count.
         */
        maxNodeCount: number;
        /**
         * Minimum number of nodes in the node pool. Must be >= 1 and <= max_node_count.
         */
        minNodeCount: number;
    }

    export interface AzureNodePoolConfig {
        /**
         * (Beta only) The OS image type to use on node pool instances.
         */
        imageType: string;
        /**
         * Proxy configuration for outbound HTTP(S) traffic.
         */
        proxyConfig?: outputs.container.AzureNodePoolConfigProxyConfig;
        /**
         * Optional. Configuration related to the root volume provisioned for each node pool machine. When unspecified, it defaults to a 32-GiB Azure Disk.
         */
        rootVolume: outputs.container.AzureNodePoolConfigRootVolume;
        /**
         * SSH configuration for how to access the node pool machines.
         */
        sshConfig: outputs.container.AzureNodePoolConfigSshConfig;
        /**
         * Optional. A set of tags to apply to all underlying Azure resources for this node pool. This currently only includes Virtual Machine Scale Sets. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
         */
        tags?: {[key: string]: string};
        /**
         * Optional. The Azure VM size name. Example: `Standard_DS2_v2`. See (/anthos/clusters/docs/azure/reference/supported-vms) for options. When unspecified, it defaults to `Standard_DS2_v2`.
         */
        vmSize: string;
    }

    export interface AzureNodePoolConfigProxyConfig {
        /**
         * The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
         */
        resourceGroupId: string;
        /**
         * The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
         */
        secretId: string;
    }

    export interface AzureNodePoolConfigRootVolume {
        /**
         * Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
         */
        sizeGib: number;
    }

    export interface AzureNodePoolConfigSshConfig {
        /**
         * The SSH public key data for VMs managed by Anthos. This accepts the authorizedKeys file format used in OpenSSH according to the sshd(8) manual page.
         */
        authorizedKey: string;
    }

    export interface AzureNodePoolMaxPodsConstraint {
        /**
         * The maximum number of pods to schedule on a single node.
         */
        maxPodsPerNode: number;
    }

    export interface ClusterAddonsConfig {
        /**
         * . Structure is documented below.
         */
        cloudrunConfig: outputs.container.ClusterAddonsConfigCloudrunConfig;
        /**
         * .
         * The status of the ConfigConnector addon. It is disabled by default; Set `enabled = true` to enable.
         */
        configConnectorConfig: outputs.container.ClusterAddonsConfigConfigConnectorConfig;
        /**
         * .
         * The status of the NodeLocal DNSCache addon. It is disabled by default.
         * Set `enabled = true` to enable.
         */
        dnsCacheConfig: outputs.container.ClusterAddonsConfigDnsCacheConfig;
        /**
         * .
         * Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Defaults to disabled; set `enabled = true` to enable.
         */
        gcePersistentDiskCsiDriverConfig: outputs.container.ClusterAddonsConfigGcePersistentDiskCsiDriverConfig;
        /**
         * The status of the Filestore CSI driver addon,
         * which allows the usage of filestore instance as volumes.
         * It is disabled by default; set `enabled = true` to enable.
         */
        gcpFilestoreCsiDriverConfig: outputs.container.ClusterAddonsConfigGcpFilestoreCsiDriverConfig;
        /**
         * ).
         * The status of the Backup for GKE agent addon. It is disabled by default; Set `enabled = true` to enable.
         */
        gkeBackupAgentConfig: outputs.container.ClusterAddonsConfigGkeBackupAgentConfig;
        /**
         * The status of the Horizontal Pod Autoscaling
         * addon, which increases or decreases the number of replica pods a replication controller
         * has based on the resource usage of the existing pods.
         * It is enabled by default;
         * set `disabled = true` to disable.
         */
        horizontalPodAutoscaling: outputs.container.ClusterAddonsConfigHorizontalPodAutoscaling;
        /**
         * The status of the HTTP (L7) load balancing
         * controller addon, which makes it easy to set up HTTP load balancers for services in a
         * cluster. It is enabled by default; set `disabled = true` to disable.
         */
        httpLoadBalancing: outputs.container.ClusterAddonsConfigHttpLoadBalancing;
        /**
         * .
         * Structure is documented below.
         */
        istioConfig: outputs.container.ClusterAddonsConfigIstioConfig;
        /**
         * .
         * Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set `enabled = true` to enable.
         */
        kalmConfig: outputs.container.ClusterAddonsConfigKalmConfig;
        /**
         * Whether we should enable the network policy addon
         * for the master.  This must be enabled in order to enable network policy for the nodes.
         * To enable this, you must also define a `networkPolicy` block,
         * otherwise nothing will happen.
         * It can only be disabled if the nodes already do not have network policies enabled.
         * Defaults to disabled; set `disabled = false` to enable.
         */
        networkPolicyConfig: outputs.container.ClusterAddonsConfigNetworkPolicyConfig;
    }

    export interface ClusterAddonsConfigCloudrunConfig {
        /**
         * The status of the Istio addon, which makes it easy to set up Istio for services in a
         * cluster. It is disabled by default. Set `disabled = false` to enable.
         */
        disabled: boolean;
        /**
         * The load balancer type of CloudRun ingress service. It is external load balancer by default.
         * Set `load_balancer_type=LOAD_BALANCER_TYPE_INTERNAL` to configure it as internal load balancer.
         */
        loadBalancerType?: string;
    }

    export interface ClusterAddonsConfigConfigConnectorConfig {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterAddonsConfigDnsCacheConfig {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterAddonsConfigGcePersistentDiskCsiDriverConfig {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterAddonsConfigGcpFilestoreCsiDriverConfig {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterAddonsConfigGkeBackupAgentConfig {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterAddonsConfigHorizontalPodAutoscaling {
        /**
         * The status of the Istio addon, which makes it easy to set up Istio for services in a
         * cluster. It is disabled by default. Set `disabled = false` to enable.
         */
        disabled: boolean;
    }

    export interface ClusterAddonsConfigHttpLoadBalancing {
        /**
         * The status of the Istio addon, which makes it easy to set up Istio for services in a
         * cluster. It is disabled by default. Set `disabled = false` to enable.
         */
        disabled: boolean;
    }

    export interface ClusterAddonsConfigIstioConfig {
        /**
         * The authentication type between services in Istio. Available options include `AUTH_MUTUAL_TLS`.
         */
        auth?: string;
        /**
         * The status of the Istio addon, which makes it easy to set up Istio for services in a
         * cluster. It is disabled by default. Set `disabled = false` to enable.
         */
        disabled: boolean;
    }

    export interface ClusterAddonsConfigKalmConfig {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterAddonsConfigNetworkPolicyConfig {
        /**
         * The status of the Istio addon, which makes it easy to set up Istio for services in a
         * cluster. It is disabled by default. Set `disabled = false` to enable.
         */
        disabled: boolean;
    }

    export interface ClusterAuthenticatorGroupsConfig {
        /**
         * The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format `gke-security-groups@yourdomain.com`.
         */
        securityGroup: string;
    }

    export interface ClusterClusterAutoscaling {
        /**
         * Contains defaults for a node pool created by NAP.
         * Structure is documented below.
         */
        autoProvisioningDefaults: outputs.container.ClusterClusterAutoscalingAutoProvisioningDefaults;
        /**
         * ) Configuration
         * options for the [Autoscaling profile](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler#autoscaling_profiles)
         * feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability
         * when deciding to remove nodes from a cluster. Can be `BALANCED` or `OPTIMIZE_UTILIZATION`. Defaults to `BALANCED`.
         */
        autoscalingProfile?: string;
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
        /**
         * Global constraints for machine resources in the
         * cluster. Configuring the `cpu` and `memory` types is required if node
         * auto-provisioning is enabled. These limits will apply to node pool autoscaling
         * in addition to node auto-provisioning. Structure is documented below.
         */
        resourceLimits?: outputs.container.ClusterClusterAutoscalingResourceLimit[];
    }

    export interface ClusterClusterAutoscalingAutoProvisioningDefaults {
        /**
         * The image type to use for this node. Note that changing the image type
         * will delete and recreate all nodes in the node pool.
         */
        imageType?: string;
        /**
         * Minimum CPU platform to be used by this instance.
         * The instance may be scheduled on the specified or newer CPU platform. Applicable
         * values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
         * [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
         * for more information.
         */
        minCpuPlatform?: string;
        /**
         * The set of Google API scopes to be made available
         * on all of the node VMs under the "default" service account.
         * Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `serviceAccount` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
         */
        oauthScopes: string[];
        /**
         * The service account to be used by the Node VMs.
         * If not specified, the "default" service account is used.
         */
        serviceAccount?: string;
    }

    export interface ClusterClusterAutoscalingResourceLimit {
        /**
         * Maximum amount of the resource in the cluster.
         */
        maximum?: number;
        /**
         * Minimum amount of the resource in the cluster.
         */
        minimum?: number;
        /**
         * The type of the resource. For example, `cpu` and
         * `memory`.  See the [guide to using Node Auto-Provisioning](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)
         * for a list of types.
         */
        resourceType: string;
    }

    export interface ClusterClusterTelemetry {
        /**
         * The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
         */
        type: string;
    }

    export interface ClusterConfidentialNodes {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterDatabaseEncryption {
        /**
         * the key to use to encrypt/decrypt secrets.  See the [DatabaseEncryption definition](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.DatabaseEncryption) for more information.
         */
        keyName?: string;
        /**
         * `ENCRYPTED` or `DECRYPTED`
         */
        state: string;
    }

    export interface ClusterDefaultSnatStatus {
        /**
         * The status of the Istio addon, which makes it easy to set up Istio for services in a
         * cluster. It is disabled by default. Set `disabled = false` to enable.
         */
        disabled: boolean;
    }

    export interface ClusterDnsConfig {
        /**
         * Which in-cluster DNS provider should be used. `PROVIDER_UNSPECIFIED` (default) or `PLATFORM_DEFAULT` or `CLOUD_DNS`.
         */
        clusterDns?: string;
        /**
         * The suffix used for all cluster service records.
         */
        clusterDnsDomain?: string;
        /**
         * The scope of access to cluster DNS records. `DNS_SCOPE_UNSPECIFIED` (default) or `CLUSTER_SCOPE` or `VPC_SCOPE`.
         */
        clusterDnsScope?: string;
    }

    export interface ClusterIdentityServiceConfig {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled?: boolean;
    }

    export interface ClusterIpAllocationPolicy {
        /**
         * The IP address range for the cluster pod IPs.
         * Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
         * to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
         * from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
         * pick a specific range to use.
         */
        clusterIpv4CidrBlock: string;
        /**
         * The name of the existing secondary
         * range in the cluster's subnetwork to use for pod IP addresses. Alternatively,
         * `clusterIpv4CidrBlock` can be used to automatically create a GKE-managed one.
         */
        clusterSecondaryRangeName: string;
        /**
         * The IP address range of the services IPs in this cluster.
         * Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
         * to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
         * from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
         * pick a specific range to use.
         */
        servicesIpv4CidrBlock: string;
        /**
         * The name of the existing
         * secondary range in the cluster's subnetwork to use for service `ClusterIP`s.
         * Alternatively, `servicesIpv4CidrBlock` can be used to automatically create a
         * GKE-managed one.
         */
        servicesSecondaryRangeName: string;
    }

    export interface ClusterLoggingConfig {
        /**
         * The GKE components exposing logs. `SYSTEM_COMPONENTS` and in beta provider, both `SYSTEM_COMPONENTS` and `WORKLOADS` are supported.
         */
        enableComponents: string[];
    }

    export interface ClusterMaintenancePolicy {
        /**
         * Time window specified for daily maintenance operations.
         * Specify `startTime` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM,
         * where HH : \[00-23\] and MM : \[00-59\] GMT. For example:
         */
        dailyMaintenanceWindow?: outputs.container.ClusterMaintenancePolicyDailyMaintenanceWindow;
        /**
         * Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows. A cluster can have up to three maintenance exclusions at a time [Maintenance Window and Exclusions](https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions)
         */
        maintenanceExclusions?: outputs.container.ClusterMaintenancePolicyMaintenanceExclusion[];
        /**
         * Time window for recurring maintenance operations.
         */
        recurringWindow?: outputs.container.ClusterMaintenancePolicyRecurringWindow;
    }

    export interface ClusterMaintenancePolicyDailyMaintenanceWindow {
        duration: string;
        startTime: string;
    }

    export interface ClusterMaintenancePolicyMaintenanceExclusion {
        endTime: string;
        exclusionName: string;
        /**
         * MaintenanceExclusionOptions provides maintenance exclusion related options.
         */
        exclusionOptions?: outputs.container.ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions;
        startTime: string;
    }

    export interface ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions {
        /**
         * The scope of automatic upgrades to restrict in the exclusion window. One of: **NO_UPGRADES | NO_MINOR_UPGRADES | NO_MINOR_OR_NODE_UPGRADES**
         */
        scope: string;
    }

    export interface ClusterMaintenancePolicyRecurringWindow {
        endTime: string;
        recurrence: string;
        startTime: string;
    }

    export interface ClusterMasterAuth {
        clientCertificate: string;
        /**
         * Whether client certificate authorization is enabled for this cluster.  For example:
         */
        clientCertificateConfig: outputs.container.ClusterMasterAuthClientCertificateConfig;
        clientKey: string;
        clusterCaCertificate: string;
    }

    export interface ClusterMasterAuthClientCertificateConfig {
        issueClientCertificate: boolean;
    }

    export interface ClusterMasterAuthorizedNetworksConfig {
        /**
         * External networks that can access the
         * Kubernetes cluster master through HTTPS.
         */
        cidrBlocks?: outputs.container.ClusterMasterAuthorizedNetworksConfigCidrBlock[];
    }

    export interface ClusterMasterAuthorizedNetworksConfigCidrBlock {
        /**
         * External network that can access Kubernetes master through HTTPS.
         * Must be specified in CIDR notation.
         */
        cidrBlock: string;
        /**
         * Field for users to identify CIDR blocks.
         */
        displayName?: string;
    }

    export interface ClusterMonitoringConfig {
        /**
         * The GKE components exposing logs. `SYSTEM_COMPONENTS` and in beta provider, both `SYSTEM_COMPONENTS` and `WORKLOADS` are supported.
         */
        enableComponents: string[];
    }

    export interface ClusterNetworkPolicy {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
        /**
         * The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.
         */
        provider?: string;
    }

    export interface ClusterNodeConfig {
        /**
         * The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
         */
        bootDiskKmsKey?: string;
        /**
         * Size of the disk attached to each node, specified
         * in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
         */
        diskSizeGb: number;
        /**
         * Type of the disk attached to each node
         * (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
         */
        diskType: string;
        /**
         * Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
         */
        ephemeralStorageConfig?: outputs.container.ClusterNodeConfigEphemeralStorageConfig;
        /**
         * Parameters for the Google Container Filesystem (GCFS).
         * If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `imageType = "COS_CONTAINERD"` and `nodeVersion` from GKE versions 1.19 or later to use it.
         * For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `nodeVersion` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
         * A `machineType` that has more than 16 GiB of memory is also recommended.
         * GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
         * Structure is documented below.
         */
        gcfsConfig?: outputs.container.ClusterNodeConfigGcfsConfig;
        /**
         * List of the type and count of accelerator cards attached to the instance.
         * Structure documented below.
         */
        guestAccelerators: outputs.container.ClusterNodeConfigGuestAccelerator[];
        /**
         * Google Virtual NIC (gVNIC) is a virtual network interface.
         * Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
         * gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
         * GKE node version 1.15.11-gke.15 or later
         * Structure is documented below.
         */
        gvnic?: outputs.container.ClusterNodeConfigGvnic;
        /**
         * The image type to use for this node. Note that changing the image type
         * will delete and recreate all nodes in the node pool.
         */
        imageType: string;
        /**
         * Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
         * Structure is documented below.
         */
        kubeletConfig?: outputs.container.ClusterNodeConfigKubeletConfig;
        /**
         * The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
         * reserved by Kubernetes Core components and cannot be specified.
         */
        labels: {[key: string]: string};
        /**
         * Linux node configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
         * Note that validations happen all server side. All attributes are optional.
         * Structure is documented below.
         */
        linuxNodeConfig?: outputs.container.ClusterNodeConfigLinuxNodeConfig;
        /**
         * Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
         */
        localSsdCount: number;
        /**
         * The name of a Google Compute Engine machine type.
         * Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
         * [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
         */
        machineType: string;
        /**
         * The metadata key/value pairs assigned to instances in
         * the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
         * `true` by the API; if `metadata` is set but that default value is not
         * included, the provider will attempt to unset the value. To avoid this, set the
         * value in your config.
         */
        metadata: {[key: string]: string};
        /**
         * Minimum CPU platform to be used by this instance.
         * The instance may be scheduled on the specified or newer CPU platform. Applicable
         * values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
         * [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
         * for more information.
         */
        minCpuPlatform?: string;
        /**
         * Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
         */
        nodeGroup?: string;
        /**
         * The set of Google API scopes to be made available
         * on all of the node VMs under the "default" service account.
         * Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `serviceAccount` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
         */
        oauthScopes: string[];
        /**
         * A boolean that represents whether or not the underlying node VMs
         * are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
         * for more information. Defaults to false.
         */
        preemptible?: boolean;
        /**
         * [GKE Sandbox](https://cloud.google.com/kubernetes-engine/docs/how-to/sandbox-pods) configuration. When enabling this feature you must specify `imageType = "COS_CONTAINERD"` and `nodeVersion = "1.12.7-gke.17"` or later to use it.
         * Structure is documented below.
         */
        sandboxConfig?: outputs.container.ClusterNodeConfigSandboxConfig;
        /**
         * The service account to be used by the Node VMs.
         * If not specified, the "default" service account is used.
         */
        serviceAccount: string;
        /**
         * Shielded Instance options. Structure is documented below.
         */
        shieldedInstanceConfig: outputs.container.ClusterNodeConfigShieldedInstanceConfig;
        /**
         * ) A boolean
         * that represents whether the underlying node VMs are spot. See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
         * for more information. Defaults to false.
         */
        spot?: boolean;
        /**
         * The list of instance tags applied to all nodes. Tags are used to identify
         * valid sources or targets for network firewalls.
         */
        tags?: string[];
        /**
         * A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
         * to apply to nodes. GKE's API can only set this field on cluster creation.
         * However, GKE will add taints to your nodes if you enable certain features such
         * as GPUs. If this field is set, any diffs on this field will cause the provider to
         * recreate the underlying resource. Taint values can be updated safely in
         * Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
         * this field to manage taints. If you do, `lifecycle.ignore_changes` is
         * recommended. Structure is documented below.
         */
        taints: outputs.container.ClusterNodeConfigTaint[];
        /**
         * Metadata configuration to expose to workloads on the node pool.
         * Structure is documented below.
         */
        workloadMetadataConfig: outputs.container.ClusterNodeConfigWorkloadMetadataConfig;
    }

    export interface ClusterNodeConfigEphemeralStorageConfig {
        /**
         * Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
         */
        localSsdCount: number;
    }

    export interface ClusterNodeConfigGcfsConfig {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterNodeConfigGuestAccelerator {
        /**
         * The number of the guest accelerator cards exposed to this instance.
         */
        count: number;
        /**
         * Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
         */
        gpuPartitionSize?: string;
        /**
         * The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
         */
        type: string;
    }

    export interface ClusterNodeConfigGvnic {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterNodeConfigKubeletConfig {
        /**
         * If true, enables CPU CFS quota enforcement for
         * containers that specify CPU limits.
         */
        cpuCfsQuota?: boolean;
        /**
         * The CPU CFS quota period value. Specified
         * as a sequence of decimal numbers, each with optional fraction and a unit suffix,
         * such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
         * "h". The value must be a positive duration.
         */
        cpuCfsQuotaPeriod?: string;
        /**
         * The CPU management policy on the node. See
         * [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
         * One of `"none"` or `"static"`. Defaults to `none` when `kubeletConfig` is unset.
         */
        cpuManagerPolicy: string;
    }

    export interface ClusterNodeConfigLinuxNodeConfig {
        /**
         * The Linux kernel parameters to be applied to the nodes
         * and all pods running on the nodes. Specified as a map from the key, such as
         * `net.core.wmem_max`, to a string value.
         */
        sysctls: {[key: string]: string};
    }

    export interface ClusterNodeConfigSandboxConfig {
        /**
         * Which sandbox to use for pods in the node pool.
         * Accepted values are:
         */
        sandboxType: string;
    }

    export interface ClusterNodeConfigShieldedInstanceConfig {
        /**
         * Defines if the instance has integrity monitoring enabled.
         */
        enableIntegrityMonitoring?: boolean;
        /**
         * Defines if the instance has Secure Boot enabled.
         */
        enableSecureBoot?: boolean;
    }

    export interface ClusterNodeConfigTaint {
        /**
         * Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
         */
        effect: string;
        /**
         * Key for taint.
         */
        key: string;
        /**
         * Value for taint.
         */
        value: string;
    }

    export interface ClusterNodeConfigWorkloadMetadataConfig {
        /**
         * How to expose the node metadata to the workload running on the node.
         * Accepted values are:
         * * UNSPECIFIED: Not Set
         * * GCE_METADATA: Expose all Compute Engine metadata to pods.
         * * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
         */
        mode: string;
    }

    export interface ClusterNodePool {
        autoscaling?: outputs.container.ClusterNodePoolAutoscaling;
        /**
         * The number of nodes to create in this
         * cluster's default node pool. In regional or multi-zonal clusters, this is the
         * number of nodes per zone. Must be set if `nodePool` is not set. If you're using
         * `gcp.container.NodePool` objects with no default node pool, you'll need to
         * set this to a value of at least `1`, alongside setting
         * `removeDefaultNodePool` to `true`.
         */
        initialNodeCount: number;
        instanceGroupUrls: string[];
        managedInstanceGroupUrls: string[];
        management: outputs.container.ClusterNodePoolManagement;
        maxPodsPerNode: number;
        /**
         * The name of the cluster, unique within the project and
         * location.
         */
        name: string;
        namePrefix: string;
        /**
         * Configuration for
         * [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
         */
        networkConfig: outputs.container.ClusterNodePoolNetworkConfig;
        /**
         * Parameters used in creating the default node pool.
         * Generally, this field should not be used at the same time as a
         * `gcp.container.NodePool` or a `nodePool` block; this configuration
         * manages the default node pool, which isn't recommended to be used.
         * Structure is documented below.
         */
        nodeConfig: outputs.container.ClusterNodePoolNodeConfig;
        nodeCount: number;
        /**
         * The list of zones in which the cluster's nodes
         * are located. Nodes must be in the region of their regional cluster or in the
         * same region as their cluster's zone for zonal clusters. If this is specified for
         * a zonal cluster, omit the cluster's zone.
         */
        nodeLocations: string[];
        placementPolicy?: outputs.container.ClusterNodePoolPlacementPolicy;
        upgradeSettings: outputs.container.ClusterNodePoolUpgradeSettings;
        version: string;
    }

    export interface ClusterNodePoolAutoscaling {
        maxNodeCount: number;
        minNodeCount: number;
    }

    export interface ClusterNodePoolManagement {
        autoRepair?: boolean;
        autoUpgrade?: boolean;
    }

    export interface ClusterNodePoolNetworkConfig {
        /**
         * Whether to create a new range for pod IPs in this node pool. Defaults are provided for `podRange` and `podIpv4CidrBlock` if they are not specified.
         */
        createPodRange?: boolean;
        /**
         * The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
         */
        podIpv4CidrBlock: string;
        /**
         * The ID of the secondary range for pod IPs. If `createPodRange` is true, this ID is used for the new range. If `createPodRange` is false, uses an existing secondary range with this ID.
         */
        podRange: string;
    }

    export interface ClusterNodePoolNodeConfig {
        /**
         * The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
         */
        bootDiskKmsKey?: string;
        /**
         * Size of the disk attached to each node, specified
         * in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
         */
        diskSizeGb: number;
        /**
         * Type of the disk attached to each node
         * (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
         */
        diskType: string;
        /**
         * Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
         */
        ephemeralStorageConfig?: outputs.container.ClusterNodePoolNodeConfigEphemeralStorageConfig;
        /**
         * Parameters for the Google Container Filesystem (GCFS).
         * If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `imageType = "COS_CONTAINERD"` and `nodeVersion` from GKE versions 1.19 or later to use it.
         * For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `nodeVersion` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
         * A `machineType` that has more than 16 GiB of memory is also recommended.
         * GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
         * Structure is documented below.
         */
        gcfsConfig?: outputs.container.ClusterNodePoolNodeConfigGcfsConfig;
        /**
         * List of the type and count of accelerator cards attached to the instance.
         * Structure documented below.
         */
        guestAccelerators: outputs.container.ClusterNodePoolNodeConfigGuestAccelerator[];
        /**
         * Google Virtual NIC (gVNIC) is a virtual network interface.
         * Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
         * gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
         * GKE node version 1.15.11-gke.15 or later
         * Structure is documented below.
         */
        gvnic?: outputs.container.ClusterNodePoolNodeConfigGvnic;
        /**
         * The image type to use for this node. Note that changing the image type
         * will delete and recreate all nodes in the node pool.
         */
        imageType: string;
        /**
         * Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
         * Structure is documented below.
         */
        kubeletConfig?: outputs.container.ClusterNodePoolNodeConfigKubeletConfig;
        /**
         * The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
         * reserved by Kubernetes Core components and cannot be specified.
         */
        labels: {[key: string]: string};
        /**
         * Linux node configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
         * Note that validations happen all server side. All attributes are optional.
         * Structure is documented below.
         */
        linuxNodeConfig?: outputs.container.ClusterNodePoolNodeConfigLinuxNodeConfig;
        /**
         * Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
         */
        localSsdCount: number;
        /**
         * The name of a Google Compute Engine machine type.
         * Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
         * [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
         */
        machineType: string;
        /**
         * The metadata key/value pairs assigned to instances in
         * the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
         * `true` by the API; if `metadata` is set but that default value is not
         * included, the provider will attempt to unset the value. To avoid this, set the
         * value in your config.
         */
        metadata: {[key: string]: string};
        /**
         * Minimum CPU platform to be used by this instance.
         * The instance may be scheduled on the specified or newer CPU platform. Applicable
         * values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
         * [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
         * for more information.
         */
        minCpuPlatform?: string;
        /**
         * Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
         */
        nodeGroup?: string;
        /**
         * The set of Google API scopes to be made available
         * on all of the node VMs under the "default" service account.
         * Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `serviceAccount` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
         */
        oauthScopes: string[];
        /**
         * A boolean that represents whether or not the underlying node VMs
         * are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
         * for more information. Defaults to false.
         */
        preemptible?: boolean;
        /**
         * [GKE Sandbox](https://cloud.google.com/kubernetes-engine/docs/how-to/sandbox-pods) configuration. When enabling this feature you must specify `imageType = "COS_CONTAINERD"` and `nodeVersion = "1.12.7-gke.17"` or later to use it.
         * Structure is documented below.
         */
        sandboxConfig?: outputs.container.ClusterNodePoolNodeConfigSandboxConfig;
        /**
         * The service account to be used by the Node VMs.
         * If not specified, the "default" service account is used.
         */
        serviceAccount: string;
        /**
         * Shielded Instance options. Structure is documented below.
         */
        shieldedInstanceConfig: outputs.container.ClusterNodePoolNodeConfigShieldedInstanceConfig;
        /**
         * ) A boolean
         * that represents whether the underlying node VMs are spot. See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
         * for more information. Defaults to false.
         */
        spot?: boolean;
        /**
         * The list of instance tags applied to all nodes. Tags are used to identify
         * valid sources or targets for network firewalls.
         */
        tags?: string[];
        /**
         * A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
         * to apply to nodes. GKE's API can only set this field on cluster creation.
         * However, GKE will add taints to your nodes if you enable certain features such
         * as GPUs. If this field is set, any diffs on this field will cause the provider to
         * recreate the underlying resource. Taint values can be updated safely in
         * Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
         * this field to manage taints. If you do, `lifecycle.ignore_changes` is
         * recommended. Structure is documented below.
         */
        taints: outputs.container.ClusterNodePoolNodeConfigTaint[];
        /**
         * Metadata configuration to expose to workloads on the node pool.
         * Structure is documented below.
         */
        workloadMetadataConfig: outputs.container.ClusterNodePoolNodeConfigWorkloadMetadataConfig;
    }

    export interface ClusterNodePoolNodeConfigEphemeralStorageConfig {
        /**
         * Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
         */
        localSsdCount: number;
    }

    export interface ClusterNodePoolNodeConfigGcfsConfig {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterNodePoolNodeConfigGuestAccelerator {
        /**
         * The number of the guest accelerator cards exposed to this instance.
         */
        count: number;
        /**
         * Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
         */
        gpuPartitionSize?: string;
        /**
         * The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
         */
        type: string;
    }

    export interface ClusterNodePoolNodeConfigGvnic {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterNodePoolNodeConfigKubeletConfig {
        /**
         * If true, enables CPU CFS quota enforcement for
         * containers that specify CPU limits.
         */
        cpuCfsQuota?: boolean;
        /**
         * The CPU CFS quota period value. Specified
         * as a sequence of decimal numbers, each with optional fraction and a unit suffix,
         * such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
         * "h". The value must be a positive duration.
         */
        cpuCfsQuotaPeriod?: string;
        /**
         * The CPU management policy on the node. See
         * [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
         * One of `"none"` or `"static"`. Defaults to `none` when `kubeletConfig` is unset.
         */
        cpuManagerPolicy: string;
    }

    export interface ClusterNodePoolNodeConfigLinuxNodeConfig {
        /**
         * The Linux kernel parameters to be applied to the nodes
         * and all pods running on the nodes. Specified as a map from the key, such as
         * `net.core.wmem_max`, to a string value.
         */
        sysctls: {[key: string]: string};
    }

    export interface ClusterNodePoolNodeConfigSandboxConfig {
        /**
         * Which sandbox to use for pods in the node pool.
         * Accepted values are:
         */
        sandboxType: string;
    }

    export interface ClusterNodePoolNodeConfigShieldedInstanceConfig {
        /**
         * Defines if the instance has integrity monitoring enabled.
         */
        enableIntegrityMonitoring?: boolean;
        /**
         * Defines if the instance has Secure Boot enabled.
         */
        enableSecureBoot?: boolean;
    }

    export interface ClusterNodePoolNodeConfigTaint {
        /**
         * Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
         */
        effect: string;
        /**
         * Key for taint.
         */
        key: string;
        /**
         * Value for taint.
         */
        value: string;
    }

    export interface ClusterNodePoolNodeConfigWorkloadMetadataConfig {
        /**
         * How to expose the node metadata to the workload running on the node.
         * Accepted values are:
         * * UNSPECIFIED: Not Set
         * * GCE_METADATA: Expose all Compute Engine metadata to pods.
         * * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
         */
        mode: string;
    }

    export interface ClusterNodePoolPlacementPolicy {
        /**
         * The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
         */
        type: string;
    }

    export interface ClusterNodePoolUpgradeSettings {
        maxSurge: number;
        maxUnavailable: number;
    }

    export interface ClusterNotificationConfig {
        /**
         * The pubsub config for the cluster's upgrade notifications.
         */
        pubsub: outputs.container.ClusterNotificationConfigPubsub;
    }

    export interface ClusterNotificationConfigPubsub {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
        /**
         * The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: `projects/{project}/topics/{topic}`.
         */
        topic?: string;
    }

    export interface ClusterPodSecurityPolicyConfig {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterPrivateClusterConfig {
        /**
         * When `true`, the cluster's private
         * endpoint is used as the cluster endpoint and access through the public endpoint
         * is disabled. When `false`, either endpoint can be used. This field only applies
         * to private clusters, when `enablePrivateNodes` is `true`.
         */
        enablePrivateEndpoint: boolean;
        /**
         * Enables the private cluster feature,
         * creating a private endpoint on the cluster. In a private cluster, nodes only
         * have RFC 1918 private addresses and communicate with the master's private
         * endpoint via private networking.
         */
        enablePrivateNodes?: boolean;
        /**
         * Controls cluster master global
         * access settings. If unset, the provider will no longer manage this field and will
         * not modify the previously-set value. Structure is documented below.
         */
        masterGlobalAccessConfig: outputs.container.ClusterPrivateClusterConfigMasterGlobalAccessConfig;
        /**
         * The IP range in CIDR notation to use for
         * the hosted master network. This range will be used for assigning private IP
         * addresses to the cluster master(s) and the ILB VIP. This range must not overlap
         * with any other ranges in use within the cluster's network, and it must be a /28
         * subnet. See [Private Cluster Limitations](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#req_res_lim)
         * for more details. This field only applies to private clusters, when
         * `enablePrivateNodes` is `true`.
         */
        masterIpv4CidrBlock: string;
        /**
         * The name of the peering between this cluster and the Google owned VPC.
         */
        peeringName: string;
        /**
         * The internal IP address of this cluster's master endpoint.
         */
        privateEndpoint: string;
        /**
         * The external IP address of this cluster's master endpoint.
         */
        publicEndpoint: string;
    }

    export interface ClusterPrivateClusterConfigMasterGlobalAccessConfig {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterReleaseChannel {
        /**
         * The selected release channel.
         * Accepted values are:
         * * UNSPECIFIED: Not set.
         * * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
         * * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
         * * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
         */
        channel: string;
    }

    export interface ClusterResourceUsageExportConfig {
        /**
         * Parameters for using BigQuery as the destination of resource usage export.
         */
        bigqueryDestination: outputs.container.ClusterResourceUsageExportConfigBigqueryDestination;
        /**
         * Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created
         * in the cluster to meter network egress traffic.
         */
        enableNetworkEgressMetering?: boolean;
        /**
         * Whether to enable resource
         * consumption metering on this cluster. When enabled, a table will be created in
         * the resource export BigQuery dataset to store resource consumption data. The
         * resulting table can be joined with the resource usage table or with BigQuery
         * billing export. Defaults to `true`.
         */
        enableResourceConsumptionMetering?: boolean;
    }

    export interface ClusterResourceUsageExportConfigBigqueryDestination {
        datasetId: string;
    }

    export interface ClusterVerticalPodAutoscaling {
        /**
         * Enable the PodSecurityPolicy controller for this cluster.
         * If enabled, pods must be valid under a PodSecurityPolicy to be created.
         */
        enabled: boolean;
    }

    export interface ClusterWorkloadIdentityConfig {
        /**
         * The workload pool to attach all Kubernetes service accounts to.
         */
        workloadPool?: string;
    }

    export interface GetClusterAddonsConfig {
        cloudrunConfigs: outputs.container.GetClusterAddonsConfigCloudrunConfig[];
        configConnectorConfigs: outputs.container.GetClusterAddonsConfigConfigConnectorConfig[];
        dnsCacheConfigs: outputs.container.GetClusterAddonsConfigDnsCacheConfig[];
        gcePersistentDiskCsiDriverConfigs: outputs.container.GetClusterAddonsConfigGcePersistentDiskCsiDriverConfig[];
        gcpFilestoreCsiDriverConfigs: outputs.container.GetClusterAddonsConfigGcpFilestoreCsiDriverConfig[];
        gkeBackupAgentConfigs: outputs.container.GetClusterAddonsConfigGkeBackupAgentConfig[];
        horizontalPodAutoscalings: outputs.container.GetClusterAddonsConfigHorizontalPodAutoscaling[];
        httpLoadBalancings: outputs.container.GetClusterAddonsConfigHttpLoadBalancing[];
        istioConfigs: outputs.container.GetClusterAddonsConfigIstioConfig[];
        kalmConfigs: outputs.container.GetClusterAddonsConfigKalmConfig[];
        networkPolicyConfigs: outputs.container.GetClusterAddonsConfigNetworkPolicyConfig[];
    }

    export interface GetClusterAddonsConfigCloudrunConfig {
        disabled: boolean;
        loadBalancerType: string;
    }

    export interface GetClusterAddonsConfigConfigConnectorConfig {
        enabled: boolean;
    }

    export interface GetClusterAddonsConfigDnsCacheConfig {
        enabled: boolean;
    }

    export interface GetClusterAddonsConfigGcePersistentDiskCsiDriverConfig {
        enabled: boolean;
    }

    export interface GetClusterAddonsConfigGcpFilestoreCsiDriverConfig {
        enabled: boolean;
    }

    export interface GetClusterAddonsConfigGkeBackupAgentConfig {
        enabled: boolean;
    }

    export interface GetClusterAddonsConfigHorizontalPodAutoscaling {
        disabled: boolean;
    }

    export interface GetClusterAddonsConfigHttpLoadBalancing {
        disabled: boolean;
    }

    export interface GetClusterAddonsConfigIstioConfig {
        auth: string;
        disabled: boolean;
    }

    export interface GetClusterAddonsConfigKalmConfig {
        enabled: boolean;
    }

    export interface GetClusterAddonsConfigNetworkPolicyConfig {
        disabled: boolean;
    }

    export interface GetClusterAuthenticatorGroupsConfig {
        securityGroup: string;
    }

    export interface GetClusterClusterAutoscaling {
        autoProvisioningDefaults: outputs.container.GetClusterClusterAutoscalingAutoProvisioningDefault[];
        autoscalingProfile: string;
        enabled: boolean;
        resourceLimits: outputs.container.GetClusterClusterAutoscalingResourceLimit[];
    }

    export interface GetClusterClusterAutoscalingAutoProvisioningDefault {
        imageType: string;
        minCpuPlatform: string;
        oauthScopes: string[];
        serviceAccount: string;
    }

    export interface GetClusterClusterAutoscalingResourceLimit {
        maximum: number;
        minimum: number;
        resourceType: string;
    }

    export interface GetClusterClusterTelemetry {
        type: string;
    }

    export interface GetClusterConfidentialNode {
        enabled: boolean;
    }

    export interface GetClusterDatabaseEncryption {
        keyName: string;
        state: string;
    }

    export interface GetClusterDefaultSnatStatus {
        disabled: boolean;
    }

    export interface GetClusterDnsConfig {
        clusterDns: string;
        clusterDnsDomain: string;
        clusterDnsScope: string;
    }

    export interface GetClusterIdentityServiceConfig {
        enabled: boolean;
    }

    export interface GetClusterIpAllocationPolicy {
        clusterIpv4CidrBlock: string;
        clusterSecondaryRangeName: string;
        servicesIpv4CidrBlock: string;
        servicesSecondaryRangeName: string;
    }

    export interface GetClusterLoggingConfig {
        enableComponents: string[];
    }

    export interface GetClusterMaintenancePolicy {
        dailyMaintenanceWindows: outputs.container.GetClusterMaintenancePolicyDailyMaintenanceWindow[];
        maintenanceExclusions: outputs.container.GetClusterMaintenancePolicyMaintenanceExclusion[];
        recurringWindows: outputs.container.GetClusterMaintenancePolicyRecurringWindow[];
    }

    export interface GetClusterMaintenancePolicyDailyMaintenanceWindow {
        duration: string;
        startTime: string;
    }

    export interface GetClusterMaintenancePolicyMaintenanceExclusion {
        endTime: string;
        exclusionName: string;
        exclusionOptions: outputs.container.GetClusterMaintenancePolicyMaintenanceExclusionExclusionOption[];
        startTime: string;
    }

    export interface GetClusterMaintenancePolicyMaintenanceExclusionExclusionOption {
        scope: string;
    }

    export interface GetClusterMaintenancePolicyRecurringWindow {
        endTime: string;
        recurrence: string;
        startTime: string;
    }

    export interface GetClusterMasterAuth {
        clientCertificate: string;
        clientCertificateConfigs: outputs.container.GetClusterMasterAuthClientCertificateConfig[];
        clientKey: string;
        clusterCaCertificate: string;
    }

    export interface GetClusterMasterAuthClientCertificateConfig {
        issueClientCertificate: boolean;
    }

    export interface GetClusterMasterAuthorizedNetworksConfig {
        cidrBlocks: outputs.container.GetClusterMasterAuthorizedNetworksConfigCidrBlock[];
    }

    export interface GetClusterMasterAuthorizedNetworksConfigCidrBlock {
        cidrBlock: string;
        displayName: string;
    }

    export interface GetClusterMonitoringConfig {
        enableComponents: string[];
    }

    export interface GetClusterNetworkPolicy {
        enabled: boolean;
        provider: string;
    }

    export interface GetClusterNodeConfig {
        bootDiskKmsKey: string;
        diskSizeGb: number;
        diskType: string;
        ephemeralStorageConfigs: outputs.container.GetClusterNodeConfigEphemeralStorageConfig[];
        gcfsConfigs: outputs.container.GetClusterNodeConfigGcfsConfig[];
        guestAccelerators: outputs.container.GetClusterNodeConfigGuestAccelerator[];
        gvnics: outputs.container.GetClusterNodeConfigGvnic[];
        imageType: string;
        kubeletConfigs: outputs.container.GetClusterNodeConfigKubeletConfig[];
        labels: {[key: string]: string};
        linuxNodeConfigs: outputs.container.GetClusterNodeConfigLinuxNodeConfig[];
        localSsdCount: number;
        machineType: string;
        metadata: {[key: string]: string};
        minCpuPlatform: string;
        nodeGroup: string;
        oauthScopes: string[];
        preemptible: boolean;
        sandboxConfigs: outputs.container.GetClusterNodeConfigSandboxConfig[];
        serviceAccount: string;
        shieldedInstanceConfigs: outputs.container.GetClusterNodeConfigShieldedInstanceConfig[];
        spot: boolean;
        tags: string[];
        taints: outputs.container.GetClusterNodeConfigTaint[];
        workloadMetadataConfigs: outputs.container.GetClusterNodeConfigWorkloadMetadataConfig[];
    }

    export interface GetClusterNodeConfigEphemeralStorageConfig {
        localSsdCount: number;
    }

    export interface GetClusterNodeConfigGcfsConfig {
        enabled: boolean;
    }

    export interface GetClusterNodeConfigGuestAccelerator {
        count: number;
        gpuPartitionSize: string;
        type: string;
    }

    export interface GetClusterNodeConfigGvnic {
        enabled: boolean;
    }

    export interface GetClusterNodeConfigKubeletConfig {
        cpuCfsQuota: boolean;
        cpuCfsQuotaPeriod: string;
        cpuManagerPolicy: string;
    }

    export interface GetClusterNodeConfigLinuxNodeConfig {
        sysctls: {[key: string]: string};
    }

    export interface GetClusterNodeConfigSandboxConfig {
        sandboxType: string;
    }

    export interface GetClusterNodeConfigShieldedInstanceConfig {
        enableIntegrityMonitoring: boolean;
        enableSecureBoot: boolean;
    }

    export interface GetClusterNodeConfigTaint {
        effect: string;
        key: string;
        value: string;
    }

    export interface GetClusterNodeConfigWorkloadMetadataConfig {
        mode: string;
    }

    export interface GetClusterNodePool {
        autoscalings: outputs.container.GetClusterNodePoolAutoscaling[];
        initialNodeCount: number;
        instanceGroupUrls: string[];
        managedInstanceGroupUrls: string[];
        managements: outputs.container.GetClusterNodePoolManagement[];
        maxPodsPerNode: number;
        /**
         * The name of the cluster.
         */
        name: string;
        namePrefix: string;
        networkConfigs: outputs.container.GetClusterNodePoolNetworkConfig[];
        nodeConfigs: outputs.container.GetClusterNodePoolNodeConfig[];
        nodeCount: number;
        nodeLocations: string[];
        placementPolicies: outputs.container.GetClusterNodePoolPlacementPolicy[];
        upgradeSettings: outputs.container.GetClusterNodePoolUpgradeSetting[];
        version: string;
    }

    export interface GetClusterNodePoolAutoscaling {
        maxNodeCount: number;
        minNodeCount: number;
    }

    export interface GetClusterNodePoolManagement {
        autoRepair: boolean;
        autoUpgrade: boolean;
    }

    export interface GetClusterNodePoolNetworkConfig {
        createPodRange: boolean;
        podIpv4CidrBlock: string;
        podRange: string;
    }

    export interface GetClusterNodePoolNodeConfig {
        bootDiskKmsKey: string;
        diskSizeGb: number;
        diskType: string;
        ephemeralStorageConfigs: outputs.container.GetClusterNodePoolNodeConfigEphemeralStorageConfig[];
        gcfsConfigs: outputs.container.GetClusterNodePoolNodeConfigGcfsConfig[];
        guestAccelerators: outputs.container.GetClusterNodePoolNodeConfigGuestAccelerator[];
        gvnics: outputs.container.GetClusterNodePoolNodeConfigGvnic[];
        imageType: string;
        kubeletConfigs: outputs.container.GetClusterNodePoolNodeConfigKubeletConfig[];
        labels: {[key: string]: string};
        linuxNodeConfigs: outputs.container.GetClusterNodePoolNodeConfigLinuxNodeConfig[];
        localSsdCount: number;
        machineType: string;
        metadata: {[key: string]: string};
        minCpuPlatform: string;
        nodeGroup: string;
        oauthScopes: string[];
        preemptible: boolean;
        sandboxConfigs: outputs.container.GetClusterNodePoolNodeConfigSandboxConfig[];
        serviceAccount: string;
        shieldedInstanceConfigs: outputs.container.GetClusterNodePoolNodeConfigShieldedInstanceConfig[];
        spot: boolean;
        tags: string[];
        taints: outputs.container.GetClusterNodePoolNodeConfigTaint[];
        workloadMetadataConfigs: outputs.container.GetClusterNodePoolNodeConfigWorkloadMetadataConfig[];
    }

    export interface GetClusterNodePoolNodeConfigEphemeralStorageConfig {
        localSsdCount: number;
    }

    export interface GetClusterNodePoolNodeConfigGcfsConfig {
        enabled: boolean;
    }

    export interface GetClusterNodePoolNodeConfigGuestAccelerator {
        count: number;
        gpuPartitionSize: string;
        type: string;
    }

    export interface GetClusterNodePoolNodeConfigGvnic {
        enabled: boolean;
    }

    export interface GetClusterNodePoolNodeConfigKubeletConfig {
        cpuCfsQuota: boolean;
        cpuCfsQuotaPeriod: string;
        cpuManagerPolicy: string;
    }

    export interface GetClusterNodePoolNodeConfigLinuxNodeConfig {
        sysctls: {[key: string]: string};
    }

    export interface GetClusterNodePoolNodeConfigSandboxConfig {
        sandboxType: string;
    }

    export interface GetClusterNodePoolNodeConfigShieldedInstanceConfig {
        enableIntegrityMonitoring: boolean;
        enableSecureBoot: boolean;
    }

    export interface GetClusterNodePoolNodeConfigTaint {
        effect: string;
        key: string;
        value: string;
    }

    export interface GetClusterNodePoolNodeConfigWorkloadMetadataConfig {
        mode: string;
    }

    export interface GetClusterNodePoolPlacementPolicy {
        type: string;
    }

    export interface GetClusterNodePoolUpgradeSetting {
        maxSurge: number;
        maxUnavailable: number;
    }

    export interface GetClusterNotificationConfig {
        pubsubs: outputs.container.GetClusterNotificationConfigPubsub[];
    }

    export interface GetClusterNotificationConfigPubsub {
        enabled: boolean;
        topic: string;
    }

    export interface GetClusterPodSecurityPolicyConfig {
        enabled: boolean;
    }

    export interface GetClusterPrivateClusterConfig {
        enablePrivateEndpoint: boolean;
        enablePrivateNodes: boolean;
        masterGlobalAccessConfigs: outputs.container.GetClusterPrivateClusterConfigMasterGlobalAccessConfig[];
        masterIpv4CidrBlock: string;
        peeringName: string;
        privateEndpoint: string;
        publicEndpoint: string;
    }

    export interface GetClusterPrivateClusterConfigMasterGlobalAccessConfig {
        enabled: boolean;
    }

    export interface GetClusterReleaseChannel {
        channel: string;
    }

    export interface GetClusterResourceUsageExportConfig {
        bigqueryDestinations: outputs.container.GetClusterResourceUsageExportConfigBigqueryDestination[];
        enableNetworkEgressMetering: boolean;
        enableResourceConsumptionMetering: boolean;
    }

    export interface GetClusterResourceUsageExportConfigBigqueryDestination {
        datasetId: string;
    }

    export interface GetClusterVerticalPodAutoscaling {
        enabled: boolean;
    }

    export interface GetClusterWorkloadIdentityConfig {
        workloadPool: string;
    }

    export interface NodePoolAutoscaling {
        /**
         * Maximum number of nodes in the NodePool. Must be >= min_node_count.
         */
        maxNodeCount: number;
        /**
         * Minimum number of nodes in the NodePool. Must be >=0 and
         * <= `maxNodeCount`.
         */
        minNodeCount: number;
    }

    export interface NodePoolManagement {
        /**
         * Whether the nodes will be automatically repaired.
         */
        autoRepair?: boolean;
        /**
         * Whether the nodes will be automatically upgraded.
         */
        autoUpgrade?: boolean;
    }

    export interface NodePoolNetworkConfig {
        createPodRange?: boolean;
        podIpv4CidrBlock: string;
        podRange: string;
    }

    export interface NodePoolNodeConfig {
        bootDiskKmsKey?: string;
        diskSizeGb: number;
        diskType: string;
        ephemeralStorageConfig?: outputs.container.NodePoolNodeConfigEphemeralStorageConfig;
        gcfsConfig?: outputs.container.NodePoolNodeConfigGcfsConfig;
        guestAccelerators: outputs.container.NodePoolNodeConfigGuestAccelerator[];
        gvnic?: outputs.container.NodePoolNodeConfigGvnic;
        imageType: string;
        kubeletConfig?: outputs.container.NodePoolNodeConfigKubeletConfig;
        labels: {[key: string]: string};
        linuxNodeConfig?: outputs.container.NodePoolNodeConfigLinuxNodeConfig;
        localSsdCount: number;
        machineType: string;
        metadata: {[key: string]: string};
        minCpuPlatform?: string;
        nodeGroup?: string;
        oauthScopes: string[];
        preemptible?: boolean;
        sandboxConfig?: outputs.container.NodePoolNodeConfigSandboxConfig;
        serviceAccount: string;
        shieldedInstanceConfig: outputs.container.NodePoolNodeConfigShieldedInstanceConfig;
        spot?: boolean;
        tags?: string[];
        taints: outputs.container.NodePoolNodeConfigTaint[];
        workloadMetadataConfig: outputs.container.NodePoolNodeConfigWorkloadMetadataConfig;
    }

    export interface NodePoolNodeConfigEphemeralStorageConfig {
        localSsdCount: number;
    }

    export interface NodePoolNodeConfigGcfsConfig {
        enabled: boolean;
    }

    export interface NodePoolNodeConfigGuestAccelerator {
        count: number;
        gpuPartitionSize?: string;
        /**
         * The type of the policy. Supports a single value: COMPACT.
         * Specifying COMPACT placement policy type places node pool's nodes in a closer
         * physical proximity in order to reduce network latency between nodes.
         */
        type: string;
    }

    export interface NodePoolNodeConfigGvnic {
        enabled: boolean;
    }

    export interface NodePoolNodeConfigKubeletConfig {
        cpuCfsQuota?: boolean;
        cpuCfsQuotaPeriod?: string;
        cpuManagerPolicy: string;
    }

    export interface NodePoolNodeConfigLinuxNodeConfig {
        sysctls: {[key: string]: string};
    }

    export interface NodePoolNodeConfigSandboxConfig {
        sandboxType: string;
    }

    export interface NodePoolNodeConfigShieldedInstanceConfig {
        enableIntegrityMonitoring?: boolean;
        enableSecureBoot?: boolean;
    }

    export interface NodePoolNodeConfigTaint {
        effect: string;
        key: string;
        value: string;
    }

    export interface NodePoolNodeConfigWorkloadMetadataConfig {
        mode: string;
    }

    export interface NodePoolPlacementPolicy {
        /**
         * The type of the policy. Supports a single value: COMPACT.
         * Specifying COMPACT placement policy type places node pool's nodes in a closer
         * physical proximity in order to reduce network latency between nodes.
         */
        type: string;
    }

    export interface NodePoolUpgradeSettings {
        /**
         * The number of additional nodes that can be added to the node pool during
         * an upgrade. Increasing `maxSurge` raises the number of nodes that can be upgraded simultaneously.
         * Can be set to 0 or greater.
         */
        maxSurge: number;
        /**
         * The number of nodes that can be simultaneously unavailable during
         * an upgrade. Increasing `maxUnavailable` raises the number of nodes that can be upgraded in
         * parallel. Can be set to 0 or greater.
         */
        maxUnavailable: number;
    }

}

export namespace containeranalysis {
    export interface NoteAttestationAuthority {
        /**
         * This submessage provides human-readable hints about the purpose of
         * the AttestationAuthority. Because the name of a Note acts as its
         * resource reference, it is important to disambiguate the canonical
         * name of the Note (which might be a UUID for security purposes)
         * from "readable" names more suitable for debug output. Note that
         * these hints should NOT be used to look up AttestationAuthorities
         * in security sensitive contexts, such as when looking up
         * Attestations to verify.
         * Structure is documented below.
         */
        hint: outputs.containeranalysis.NoteAttestationAuthorityHint;
    }

    export interface NoteAttestationAuthorityHint {
        /**
         * The human readable name of this Attestation Authority, for
         * example "qa".
         */
        humanReadableName: string;
    }

    export interface NoteRelatedUrl {
        /**
         * Label to describe usage of the URL
         */
        label?: string;
        /**
         * Specific URL associated with the resource.
         */
        url: string;
    }

    export interface OccurenceAttestation {
        /**
         * The serialized payload that is verified by one or
         * more signatures. A base64-encoded string.
         */
        serializedPayload: string;
        /**
         * One or more signatures over serializedPayload.
         * Verifier implementations should consider this attestation
         * message verified if at least one signature verifies
         * serializedPayload. See Signature in common.proto for more
         * details on signature structure and verification.
         * Structure is documented below.
         */
        signatures: outputs.containeranalysis.OccurenceAttestationSignature[];
    }

    export interface OccurenceAttestationSignature {
        /**
         * The identifier for the public key that verifies this
         * signature. MUST be an RFC3986 conformant
         * URI. * When possible, the key id should be an
         * immutable reference, such as a cryptographic digest.
         * Examples of valid values:
         * * OpenPGP V4 public key fingerprint. See https://www.iana.org/assignments/uri-schemes/prov/openpgp4fpr
         * for more details on this scheme.
         * * `openpgp4fpr:74FAF3B861BDA0870C7B6DEF607E48D2A663AEEA`
         * * RFC6920 digest-named SubjectPublicKeyInfo (digest of the DER serialization):
         * * "ni:///sha-256;cD9o9Cq6LG3jD0iKXqEi_vdjJGecm_iXkbqVoScViaU"
         */
        publicKeyId: string;
        /**
         * The content of the signature, an opaque bytestring.
         * The payload that this signature verifies MUST be
         * unambiguously provided with the Signature during
         * verification. A wrapper message might provide the
         * payload explicitly. Alternatively, a message might
         * have a canonical serialization that can always be
         * unambiguously computed to derive the payload.
         */
        signature?: string;
    }

}

export namespace datacatalog {
    export interface EntryBigqueryDateShardedSpec {
        dataset: string;
        shardCount: number;
        tablePrefix: string;
    }

    export interface EntryBigqueryTableSpec {
        tableSourceType: string;
        tableSpecs: outputs.datacatalog.EntryBigqueryTableSpecTableSpec[];
        viewSpecs: outputs.datacatalog.EntryBigqueryTableSpecViewSpec[];
    }

    export interface EntryBigqueryTableSpecTableSpec {
        groupedEntry: string;
    }

    export interface EntryBigqueryTableSpecViewSpec {
        viewQuery: string;
    }

    export interface EntryGcsFilesetSpec {
        /**
         * Patterns to identify a set of files in Google Cloud Storage.
         * See [Cloud Storage documentation](https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames)
         * for more information. Note that bucket wildcards are currently not supported. Examples of valid filePatterns:
         * * gs://bucket_name/dir/*: matches all files within bucket_name/dir directory.
         * * gs://bucket_name/dir/**: matches all files in bucket_name/dir spanning all subdirectories.
         * * gs://bucket_name/file*: matches files prefixed by file in bucketName
         * * gs://bucket_name/??.txt: matches files with two characters followed by .txt in bucketName
         * * gs://bucket_name/[aeiou].txt: matches files that contain a single vowel character followed by .txt in bucketName
         * * gs://bucket_name/[a-m].txt: matches files that contain a, b, ... or m followed by .txt in bucketName
         * * gs://bucket_name/a/*&#47;b: matches all files in bucketName that match a/*&#47;b pattern, such as a/c/b, a/d/b
         * * gs://another_bucket/a.txt: matches gs://another_bucket/a.txt
         */
        filePatterns: string[];
        /**
         * -
         * Sample files contained in this fileset, not all files contained in this fileset are represented here.
         * Structure is documented below.
         */
        sampleGcsFileSpecs: outputs.datacatalog.EntryGcsFilesetSpecSampleGcsFileSpec[];
    }

    export interface EntryGcsFilesetSpecSampleGcsFileSpec {
        /**
         * -
         * The full file path
         */
        filePath: string;
        /**
         * -
         * The size of the file, in bytes.
         */
        sizeBytes: number;
    }

    export interface EntryGroupIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface EntryGroupIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface PolicyTagIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface PolicyTagIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface TagField {
        /**
         * Holds the value for a tag field with boolean type.
         */
        boolValue?: boolean;
        /**
         * -
         * The display name of this field
         */
        displayName: string;
        /**
         * Holds the value for a tag field with double type.
         */
        doubleValue?: number;
        /**
         * Holds the value for a tag field with enum type. This value must be one of the allowed values in the definition of this enum.
         * Structure is documented below.
         */
        enumValue?: string;
        /**
         * The identifier for this object. Format specified above.
         */
        fieldName: string;
        /**
         * -
         * The order of this field with respect to other fields in this tag. For example, a higher value can indicate
         * a more important field. The value can be negative. Multiple fields can have the same order, and field orders
         * within a tag do not have to be sequential.
         */
        order: number;
        /**
         * Holds the value for a tag field with string type.
         */
        stringValue?: string;
        /**
         * Holds the value for a tag field with timestamp type.
         */
        timestampValue?: string;
    }

    export interface TagTemplateField {
        /**
         * A description for this field.
         */
        description?: string;
        /**
         * The display name for this template.
         */
        displayName?: string;
        /**
         * The identifier for this object. Format specified above.
         */
        fieldId: string;
        /**
         * Whether this is a required field. Defaults to false.
         */
        isRequired?: boolean;
        /**
         * -
         * The resource name of the tag template field in URL format. Example: projects/{project_id}/locations/{location}/tagTemplates/{tagTemplateId}/fields/{field}
         */
        name: string;
        /**
         * The order of this field with respect to other fields in this tag template.
         * A higher value indicates a more important field. The value can be negative.
         * Multiple fields can have the same order, and field orders within a tag do not have to be sequential.
         */
        order?: number;
        /**
         * The type of value this tag field can contain.
         * Structure is documented below.
         */
        type: outputs.datacatalog.TagTemplateFieldType;
    }

    export interface TagTemplateFieldType {
        /**
         * Represents an enum type.
         * Exactly one of `primitiveType` or `enumType` must be set
         * Structure is documented below.
         */
        enumType?: outputs.datacatalog.TagTemplateFieldTypeEnumType;
        /**
         * Represents primitive types - string, bool etc.
         * Exactly one of `primitiveType` or `enumType` must be set
         * Possible values are `DOUBLE`, `STRING`, `BOOL`, and `TIMESTAMP`.
         */
        primitiveType?: string;
    }

    export interface TagTemplateFieldTypeEnumType {
        /**
         * The set of allowed values for this enum. The display names of the
         * values must be case-insensitively unique within this set. Currently,
         * enum values can only be added to the list of allowed values. Deletion
         * and renaming of enum values are not supported.
         * Can have up to 500 allowed values.
         * Structure is documented below.
         */
        allowedValues: outputs.datacatalog.TagTemplateFieldTypeEnumTypeAllowedValue[];
    }

    export interface TagTemplateFieldTypeEnumTypeAllowedValue {
        /**
         * The display name for this template.
         */
        displayName: string;
    }

    export interface TagTemplateIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface TagTemplateIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface TaxonomyIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface TaxonomyIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

}

export namespace datafusion {
    export interface InstanceNetworkConfig {
        /**
         * The IP range in CIDR notation to use for the managed Data Fusion instance
         * nodes. This range must not overlap with any other ranges used in the Data Fusion instance network.
         */
        ipAllocation: string;
        /**
         * Name of the network in the project with which the tenant project
         * will be peered for executing pipelines. In case of shared VPC where the network resides in another host
         * project the network should specified in the form of projects/{host-project-id}/global/networks/{network}
         */
        network: string;
    }

}

export namespace dataloss {
    export interface PreventionDeidentifyTemplateDeidentifyConfig {
        /**
         * Specifies free-text based transformations to be applied to the dataset.
         * Structure is documented below.
         */
        infoTypeTransformations: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformations;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformations {
        /**
         * Transformation for each infoType. Cannot specify more than one for a given infoType.
         * Structure is documented below.
         */
        transformations: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformation[];
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformation {
        /**
         * InfoTypes to apply the transformation to. Leaving this empty will apply the transformation to apply to
         * all findings that correspond to infoTypes that were requested in InspectConfig.
         * Structure is documented below.
         */
        infoTypes?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoType[];
        /**
         * Primitive transformation to apply to the infoType.
         * Structure is documented below.
         */
        primitiveTransformation: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformation;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoType {
        /**
         * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.
         */
        name: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformation {
        /**
         * Partially mask a string by replacing a given number of characters with a fixed character.
         * Masking can start from the beginning or end of the string.
         * Structure is documented below.
         */
        characterMaskConfig?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfig;
        /**
         * Pseudonymization method that generates deterministic encryption for the given input. Outputs a base64 encoded representation of the encrypted output. Uses AES-SIV based on the RFC [https://tools.ietf.org/html/rfc5297](https://tools.ietf.org/html/rfc5297).
         * Structure is documented below.
         */
        cryptoDeterministicConfig?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfig;
        /**
         * Replaces an identifier with a surrogate using Format Preserving Encryption (FPE) with the FFX mode of operation; however when used in the `content.reidentify` API method, it serves the opposite function by reversing the surrogate back into the original identifier. The identifier must be encoded as ASCII. For a given crypto key and context, the same identifier will be replaced with the same surrogate. Identifiers must be at least two characters long. In the case that the identifier is the empty string, it will be skipped. See [https://cloud.google.com/dlp/docs/pseudonymization](https://cloud.google.com/dlp/docs/pseudonymization) to learn more.
         * Note: We recommend using CryptoDeterministicConfig for all use cases which do not require preserving the input alphabet space and size, plus warrant referential integrity.
         * Structure is documented below.
         */
        cryptoReplaceFfxFpeConfig?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfig;
        /**
         * Replace each input value with a given value.
         * Structure is documented below.
         */
        replaceConfig?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfig;
        /**
         * Replace each matching finding with the name of the info type.
         */
        replaceWithInfoTypeConfig?: boolean;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfig {
        /**
         * Characters to skip when doing de-identification of a value. These will be left alone and skipped.
         * Structure is documented below.
         */
        charactersToIgnores?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore[];
        /**
         * Character to use to mask the sensitive valuesfor example, * for an alphabetic string such as a name, or 0 for a numeric string
         * such as ZIP code or credit card number. This string must have a length of 1. If not supplied, this value defaults to * for
         * strings, and 0 for digits.
         */
        maskingCharacter?: string;
        /**
         * Number of characters to mask. If not set, all matching chars will be masked. Skipped characters do not count towards this tally.
         */
        numberToMask?: number;
        /**
         * Mask characters in reverse order. For example, if maskingCharacter is 0, numberToMask is 14, and reverseOrder is `false`, then the
         * input string `1234-5678-9012-3456` is masked as `00000000000000-3456`.
         */
        reverseOrder?: boolean;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore {
        /**
         * Characters to not transform when masking.
         */
        charactersToSkip?: string;
        /**
         * Common characters to not transform when masking. Useful to avoid removing punctuation.
         * Possible values are `NUMERIC`, `ALPHA_UPPER_CASE`, `ALPHA_LOWER_CASE`, `PUNCTUATION`, and `WHITESPACE`.
         */
        commonCharactersToIgnore?: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfig {
        /**
         * The 'tweak', a context may be used for higher security since the same identifier in two different contexts won't be given the same surrogate. If the context is not set, a default tweak will be used.
         * If the context is set but:
         * 1.  there is no record present when transforming a given value or
         * 2.  the field is not present when transforming a given value,
         * a default tweak will be used.
         * Note that case (1) is expected when an `InfoTypeTransformation` is applied to both structured and non-structured `ContentItem`s. Currently, the referenced field may be of value type integer or string.
         * The tweak is constructed as a sequence of bytes in big endian byte order such that:
         * *   a 64 bit integer is encoded followed by a single byte of value 1
         * *   a string is encoded in UTF-8 format followed by a single byte of value 2
         * Structure is documented below.
         */
        context?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContext;
        /**
         * The key used by the encryption algorithm.
         * Structure is documented below.
         */
        cryptoKey?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey;
        /**
         * The custom infoType to annotate the surrogate with. This annotation will be applied to the surrogate by prefixing it with the name of the custom infoType followed by the number of characters comprising the surrogate. The following scheme defines the format: info\_type\_name(surrogate\_character\_count):surrogate
         * For example, if the name of custom infoType is 'MY\_TOKEN\_INFO\_TYPE' and the surrogate is 'abc', the full replacement value will be: 'MY\_TOKEN\_INFO\_TYPE(3):abc'
         * This annotation identifies the surrogate when inspecting content using the custom infoType [`SurrogateType`](https://cloud.google.com/dlp/docs/reference/rest/v2/InspectConfig#surrogatetype). This facilitates reversal of the surrogate when it occurs in free text.
         * In order for inspection to work properly, the name of this infoType must not occur naturally anywhere in your data; otherwise, inspection may find a surrogate that does not correspond to an actual identifier. Therefore, choose your custom infoType name carefully after considering what your data looks like. One way to select a name that has a high chance of yielding reliable detection is to include one or more unicode characters that are highly improbable to exist in your data. For example, assuming your data is entered from a regular ASCII keyboard, the symbol with the hex code point 29DD might be used like so: MY\_TOKEN\_TYPE
         * Structure is documented below.
         */
        surrogateInfoType?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoType;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContext {
        /**
         * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.
         */
        name?: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey {
        /**
         * Kms wrapped key
         * Structure is documented below.
         */
        kmsWrapped?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped;
        /**
         * Transient crypto key
         * Structure is documented below.
         */
        transient?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransient;
        /**
         * Unwrapped crypto key
         * Structure is documented below.
         */
        unwrapped?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped {
        /**
         * The resource name of the KMS CryptoKey to use for unwrapping.
         */
        cryptoKeyName: string;
        /**
         * The wrapped data crypto key.
         * A base64-encoded string.
         */
        wrappedKey: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransient {
        /**
         * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.
         */
        name: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped {
        /**
         * A 128/192/256 bit key.
         * A base64-encoded string.
         */
        key: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoType {
        /**
         * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.
         */
        name?: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfig {
        /**
         * Common alphabets.
         * Possible values are `FFX_COMMON_NATIVE_ALPHABET_UNSPECIFIED`, `NUMERIC`, `HEXADECIMAL`, `UPPER_CASE_ALPHA_NUMERIC`, and `ALPHA_NUMERIC`.
         */
        commonAlphabet?: string;
        /**
         * The 'tweak', a context may be used for higher security since the same identifier in two different contexts won't be given the same surrogate. If the context is not set, a default tweak will be used.
         * If the context is set but:
         * 1.  there is no record present when transforming a given value or
         * 2.  the field is not present when transforming a given value,
         * a default tweak will be used.
         * Note that case (1) is expected when an `InfoTypeTransformation` is applied to both structured and non-structured `ContentItem`s. Currently, the referenced field may be of value type integer or string.
         * The tweak is constructed as a sequence of bytes in big endian byte order such that:
         * *   a 64 bit integer is encoded followed by a single byte of value 1
         * *   a string is encoded in UTF-8 format followed by a single byte of value 2
         * Structure is documented below.
         */
        context?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext;
        /**
         * The key used by the encryption algorithm.
         * Structure is documented below.
         */
        cryptoKey?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey;
        /**
         * This is supported by mapping these to the alphanumeric characters that the FFX mode natively supports. This happens before/after encryption/decryption. Each character listed must appear only once. Number of characters must be in the range \[2, 95\]. This must be encoded as ASCII. The order of characters does not matter. The full list of allowed characters is:
         * ``0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz ~`!@#$%^&*()_-+={[}]|:;"'<,>.?/``
         */
        customAlphabet?: string;
        /**
         * The native way to select the alphabet. Must be in the range \[2, 95\].
         */
        radix?: number;
        /**
         * The custom infoType to annotate the surrogate with. This annotation will be applied to the surrogate by prefixing it with the name of the custom infoType followed by the number of characters comprising the surrogate. The following scheme defines the format: info\_type\_name(surrogate\_character\_count):surrogate
         * For example, if the name of custom infoType is 'MY\_TOKEN\_INFO\_TYPE' and the surrogate is 'abc', the full replacement value will be: 'MY\_TOKEN\_INFO\_TYPE(3):abc'
         * This annotation identifies the surrogate when inspecting content using the custom infoType [`SurrogateType`](https://cloud.google.com/dlp/docs/reference/rest/v2/InspectConfig#surrogatetype). This facilitates reversal of the surrogate when it occurs in free text.
         * In order for inspection to work properly, the name of this infoType must not occur naturally anywhere in your data; otherwise, inspection may find a surrogate that does not correspond to an actual identifier. Therefore, choose your custom infoType name carefully after considering what your data looks like. One way to select a name that has a high chance of yielding reliable detection is to include one or more unicode characters that are highly improbable to exist in your data. For example, assuming your data is entered from a regular ASCII keyboard, the symbol with the hex code point 29DD might be used like so: MY\_TOKEN\_TYPE
         * Structure is documented below.
         */
        surrogateInfoType?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoType;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext {
        /**
         * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.
         */
        name?: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey {
        /**
         * Kms wrapped key
         * Structure is documented below.
         */
        kmsWrapped?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped;
        /**
         * Transient crypto key
         * Structure is documented below.
         */
        transient?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransient;
        /**
         * Unwrapped crypto key
         * Structure is documented below.
         */
        unwrapped?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped {
        /**
         * The resource name of the KMS CryptoKey to use for unwrapping.
         */
        cryptoKeyName: string;
        /**
         * The wrapped data crypto key.
         * A base64-encoded string.
         */
        wrappedKey: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransient {
        /**
         * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.
         */
        name: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped {
        /**
         * A 128/192/256 bit key.
         * A base64-encoded string.
         */
        key: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoType {
        /**
         * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.
         */
        name?: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfig {
        /**
         * Replace each input value with a given value.
         * Structure is documented below.
         */
        newValue: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValue;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValue {
        /**
         * A boolean value.
         */
        booleanValue?: boolean;
        /**
         * Represents a whole or partial calendar date.
         * Structure is documented below.
         */
        dateValue?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValue;
        /**
         * Represents a day of the week.
         * Possible values are `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, and `SUNDAY`.
         */
        dayOfWeekValue?: string;
        /**
         * A float value.
         */
        floatValue?: number;
        /**
         * An integer value.
         */
        integerValue?: number;
        /**
         * A string value.
         */
        stringValue?: string;
        /**
         * Represents a time of day.
         * Structure is documented below.
         */
        timeValue?: outputs.dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue;
        /**
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
         * Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
         */
        timestampValue?: string;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValue {
        /**
         * Day of month. Must be from 1 to 31 and valid for the year and month, or 0 if specifying a
         * year by itself or a year and month where the day is not significant.
         */
        day?: number;
        /**
         * Month of year. Must be from 1 to 12, or 0 if specifying a year without a month and day.
         */
        month?: number;
        /**
         * Year of date. Must be from 1 to 9999, or 0 if specifying a date without a year.
         */
        year?: number;
    }

    export interface PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue {
        /**
         * Hours of day in 24 hour format. Should be from 0 to 23.
         */
        hours?: number;
        /**
         * Minutes of hour of day. Must be from 0 to 59.
         */
        minutes?: number;
        /**
         * Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999.
         */
        nanos?: number;
        /**
         * Seconds of minutes of the time. Must normally be from 0 to 59.
         */
        seconds?: number;
    }

    export interface PreventionInspectTemplateInspectConfig {
        /**
         * List of options defining data content to scan. If empty, text, images, and other content will be included.
         * Each value may be one of `CONTENT_TEXT` and `CONTENT_IMAGE`.
         */
        contentOptions?: string[];
        /**
         * Custom info types to be used. See https://cloud.google.com/dlp/docs/creating-custom-infotypes to learn more.
         * Structure is documented below.
         */
        customInfoTypes?: outputs.dataloss.PreventionInspectTemplateInspectConfigCustomInfoType[];
        /**
         * Set of infoTypes for which findings would affect this rule.
         * Structure is documented below.
         */
        excludeInfoTypes?: boolean;
        /**
         * When true, a contextual quote from the data that triggered a finding is included in the response.
         */
        includeQuote?: boolean;
        /**
         * If a finding is matched by any of the infoType detectors listed here, the finding will be excluded from the scan results.
         * Structure is documented below.
         */
        infoTypes?: outputs.dataloss.PreventionInspectTemplateInspectConfigInfoType[];
        /**
         * Configuration to control the number of findings returned.
         * Structure is documented below.
         */
        limits?: outputs.dataloss.PreventionInspectTemplateInspectConfigLimits;
        /**
         * Only returns findings equal or above this threshold. See https://cloud.google.com/dlp/docs/likelihood for more info
         * Default value is `POSSIBLE`.
         * Possible values are `VERY_UNLIKELY`, `UNLIKELY`, `POSSIBLE`, `LIKELY`, and `VERY_LIKELY`.
         */
        minLikelihood?: string;
        /**
         * Set of rules to apply to the findings for this InspectConfig. Exclusion rules, contained in the set are executed in the end,
         * other rules are executed in the order they are specified for each info type.
         * Structure is documented below.
         */
        ruleSets?: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSet[];
    }

    export interface PreventionInspectTemplateInspectConfigCustomInfoType {
        /**
         * Dictionary which defines the rule.
         * Structure is documented below.
         */
        dictionary?: outputs.dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeDictionary;
        /**
         * If set to EXCLUSION_TYPE_EXCLUDE this infoType will not cause a finding to be returned. It still can be used for rules matching.
         * Possible values are `EXCLUSION_TYPE_EXCLUDE`.
         */
        exclusionType?: string;
        /**
         * CustomInfoType can either be a new infoType, or an extension of built-in infoType, when the name matches one of existing
         * infoTypes and that infoType is specified in `infoTypes` field. Specifying the latter adds findings to the
         * one detected by the system. If built-in info type is not specified in `infoTypes` list then the name is
         * treated as a custom info type.
         * Structure is documented below.
         */
        infoType: outputs.dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeInfoType;
        /**
         * Likelihood to return for this CustomInfoType. This base value can be altered by a detection rule if the finding meets the criteria
         * specified by the rule.
         * Default value is `VERY_LIKELY`.
         * Possible values are `VERY_UNLIKELY`, `UNLIKELY`, `POSSIBLE`, `LIKELY`, and `VERY_LIKELY`.
         */
        likelihood?: string;
        /**
         * Regular expression which defines the rule.
         * Structure is documented below.
         */
        regex?: outputs.dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeRegex;
        /**
         * A reference to a StoredInfoType to use with scanning.
         * Structure is documented below.
         */
        storedType?: outputs.dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeStoredType;
    }

    export interface PreventionInspectTemplateInspectConfigCustomInfoTypeDictionary {
        /**
         * Newline-delimited file of words in Cloud Storage. Only a single file is accepted.
         * Structure is documented below.
         */
        cloudStoragePath?: outputs.dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryCloudStoragePath;
        /**
         * List of words or phrases to search for.
         * Structure is documented below.
         */
        wordList?: outputs.dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryWordList;
    }

    export interface PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryCloudStoragePath {
        /**
         * A url representing a file or path (no wildcards) in Cloud Storage. Example: `gs://[BUCKET_NAME]/dictionary.txt`
         */
        path: string;
    }

    export interface PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryWordList {
        /**
         * Words or phrases defining the dictionary. The dictionary must contain at least one
         * phrase and every phrase must contain at least 2 characters that are letters or digits.
         */
        words: string[];
    }

    export interface PreventionInspectTemplateInspectConfigCustomInfoTypeInfoType {
        /**
         * Resource name of the requested StoredInfoType, for example `organizations/433245324/storedInfoTypes/432452342`
         * or `projects/project-id/storedInfoTypes/432452342`.
         */
        name: string;
    }

    export interface PreventionInspectTemplateInspectConfigCustomInfoTypeRegex {
        /**
         * The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included.
         */
        groupIndexes?: number[];
        /**
         * Pattern defining the regular expression.
         * Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
         */
        pattern: string;
    }

    export interface PreventionInspectTemplateInspectConfigCustomInfoTypeStoredType {
        /**
         * Resource name of the requested StoredInfoType, for example `organizations/433245324/storedInfoTypes/432452342`
         * or `projects/project-id/storedInfoTypes/432452342`.
         */
        name: string;
    }

    export interface PreventionInspectTemplateInspectConfigInfoType {
        /**
         * Resource name of the requested StoredInfoType, for example `organizations/433245324/storedInfoTypes/432452342`
         * or `projects/project-id/storedInfoTypes/432452342`.
         */
        name: string;
    }

    export interface PreventionInspectTemplateInspectConfigLimits {
        /**
         * Configuration of findings limit given for specified infoTypes.
         * Structure is documented below.
         */
        maxFindingsPerInfoTypes?: outputs.dataloss.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoType[];
        /**
         * Max number of findings that will be returned for each item scanned. The maximum returned is 2000.
         */
        maxFindingsPerItem: number;
        /**
         * Max number of findings that will be returned per request/job. The maximum returned is 2000.
         */
        maxFindingsPerRequest: number;
    }

    export interface PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoType {
        /**
         * CustomInfoType can either be a new infoType, or an extension of built-in infoType, when the name matches one of existing
         * infoTypes and that infoType is specified in `infoTypes` field. Specifying the latter adds findings to the
         * one detected by the system. If built-in info type is not specified in `infoTypes` list then the name is
         * treated as a custom info type.
         * Structure is documented below.
         */
        infoType: outputs.dataloss.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoType;
        /**
         * Max findings limit for the given infoType.
         */
        maxFindings: number;
    }

    export interface PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoType {
        /**
         * Resource name of the requested StoredInfoType, for example `organizations/433245324/storedInfoTypes/432452342`
         * or `projects/project-id/storedInfoTypes/432452342`.
         */
        name: string;
    }

    export interface PreventionInspectTemplateInspectConfigRuleSet {
        /**
         * If a finding is matched by any of the infoType detectors listed here, the finding will be excluded from the scan results.
         * Structure is documented below.
         */
        infoTypes: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoType[];
        /**
         * Set of rules to be applied to infoTypes. The rules are applied in order.
         * Structure is documented below.
         */
        rules: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetRule[];
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetInfoType {
        /**
         * Resource name of the requested StoredInfoType, for example `organizations/433245324/storedInfoTypes/432452342`
         * or `projects/project-id/storedInfoTypes/432452342`.
         */
        name: string;
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetRule {
        /**
         * The rule that specifies conditions when findings of infoTypes specified in InspectionRuleSet are removed from results.
         * Structure is documented below.
         */
        exclusionRule?: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRule;
        /**
         * Hotword-based detection rule.
         * Structure is documented below.
         */
        hotwordRule?: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRule;
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRule {
        /**
         * Dictionary which defines the rule.
         * Structure is documented below.
         */
        dictionary?: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionary;
        /**
         * Set of infoTypes for which findings would affect this rule.
         * Structure is documented below.
         */
        excludeInfoTypes?: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypes;
        /**
         * How the rule is applied. See the documentation for more information: https://cloud.google.com/dlp/docs/reference/rest/v2/InspectConfig#MatchingType
         * Possible values are `MATCHING_TYPE_FULL_MATCH`, `MATCHING_TYPE_PARTIAL_MATCH`, and `MATCHING_TYPE_INVERSE_MATCH`.
         */
        matchingType: string;
        /**
         * Regular expression which defines the rule.
         * Structure is documented below.
         */
        regex?: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegex;
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionary {
        /**
         * Newline-delimited file of words in Cloud Storage. Only a single file is accepted.
         * Structure is documented below.
         */
        cloudStoragePath?: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePath;
        /**
         * List of words or phrases to search for.
         * Structure is documented below.
         */
        wordList?: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryWordList;
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePath {
        /**
         * A url representing a file or path (no wildcards) in Cloud Storage. Example: `gs://[BUCKET_NAME]/dictionary.txt`
         */
        path: string;
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryWordList {
        /**
         * Words or phrases defining the dictionary. The dictionary must contain at least one
         * phrase and every phrase must contain at least 2 characters that are letters or digits.
         */
        words: string[];
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypes {
        /**
         * If a finding is matched by any of the infoType detectors listed here, the finding will be excluded from the scan results.
         * Structure is documented below.
         */
        infoTypes: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoType[];
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoType {
        /**
         * Resource name of the requested StoredInfoType, for example `organizations/433245324/storedInfoTypes/432452342`
         * or `projects/project-id/storedInfoTypes/432452342`.
         */
        name: string;
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegex {
        /**
         * The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included.
         */
        groupIndexes?: number[];
        /**
         * Pattern defining the regular expression.
         * Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
         */
        pattern: string;
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRule {
        /**
         * Regular expression pattern defining what qualifies as a hotword.
         * Structure is documented below.
         */
        hotwordRegex: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegex;
        /**
         * Likelihood adjustment to apply to all matching findings.
         * Structure is documented below.
         */
        likelihoodAdjustment: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustment;
        /**
         * Proximity of the finding within which the entire hotword must reside. The total length of the window cannot
         * exceed 1000 characters. Note that the finding itself will be included in the window, so that hotwords may be
         * used to match substrings of the finding itself. For example, the certainty of a phone number regex
         * `(\d{3}) \d{3}-\d{4}` could be adjusted upwards if the area code is known to be the local area code of a company
         * office using the hotword regex `(xxx)`, where `xxx` is the area code in question.
         * Structure is documented below.
         */
        proximity: outputs.dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximity;
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegex {
        /**
         * The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included.
         */
        groupIndexes?: number[];
        /**
         * Pattern defining the regular expression.
         * Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
         */
        pattern: string;
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustment {
        /**
         * Set the likelihood of a finding to a fixed value. Either this or relativeLikelihood can be set.
         * Possible values are `VERY_UNLIKELY`, `UNLIKELY`, `POSSIBLE`, `LIKELY`, and `VERY_LIKELY`.
         */
        fixedLikelihood?: string;
        /**
         * Increase or decrease the likelihood by the specified number of levels. For example,
         * if a finding would be POSSIBLE without the detection rule and relativeLikelihood is 1,
         * then it is upgraded to LIKELY, while a value of -1 would downgrade it to UNLIKELY.
         * Likelihood may never drop below VERY_UNLIKELY or exceed VERY_LIKELY, so applying an
         * adjustment of 1 followed by an adjustment of -1 when base likelihood is VERY_LIKELY
         * will result in a final likelihood of LIKELY. Either this or fixedLikelihood can be set.
         */
        relativeLikelihood?: number;
    }

    export interface PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximity {
        /**
         * Number of characters after the finding to consider. Either this or windowBefore must be specified
         */
        windowAfter?: number;
        /**
         * Number of characters before the finding to consider. Either this or windowAfter must be specified
         */
        windowBefore?: number;
    }

    export interface PreventionJobTriggerInspectJob {
        /**
         * A task to execute on the completion of a job.
         * Structure is documented below.
         */
        actions: outputs.dataloss.PreventionJobTriggerInspectJobAction[];
        /**
         * The name of the template to run when this job is triggered.
         */
        inspectTemplateName: string;
        /**
         * Information on where to inspect
         * Structure is documented below.
         */
        storageConfig: outputs.dataloss.PreventionJobTriggerInspectJobStorageConfig;
    }

    export interface PreventionJobTriggerInspectJobAction {
        /**
         * Schedule for triggered jobs
         * Structure is documented below.
         */
        saveFindings: outputs.dataloss.PreventionJobTriggerInspectJobActionSaveFindings;
    }

    export interface PreventionJobTriggerInspectJobActionSaveFindings {
        /**
         * Information on where to store output
         * Structure is documented below.
         */
        outputConfig: outputs.dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfig;
    }

    export interface PreventionJobTriggerInspectJobActionSaveFindingsOutputConfig {
        /**
         * Schema used for writing the findings for Inspect jobs. This field is only used for
         * Inspect and must be unspecified for Risk jobs. Columns are derived from the Finding
         * object. If appending to an existing table, any columns from the predefined schema
         * that are missing will be added. No columns in the existing table will be deleted.
         * If unspecified, then all available columns will be used for a new table or an (existing)
         * table with no schema, and no changes will be made to an existing table that has a schema.
         * Only for use with external storage.
         * Possible values are `BASIC_COLUMNS`, `GCS_COLUMNS`, `DATASTORE_COLUMNS`, `BIG_QUERY_COLUMNS`, and `ALL_COLUMNS`.
         */
        outputSchema?: string;
        /**
         * Information on the location of the target BigQuery Table.
         * Structure is documented below.
         */
        table: outputs.dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTable;
    }

    export interface PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTable {
        /**
         * Dataset ID of the table.
         */
        datasetId: string;
        /**
         * The Google Cloud Platform project ID of the project containing the table.
         */
        projectId: string;
        /**
         * Name of the table. If is not set a new one will be generated for you with the following format:
         * `dlp_googleapis_yyyy_mm_dd_[dlpJobId]`. Pacific timezone will be used for generating the date details.
         */
        tableId?: string;
    }

    export interface PreventionJobTriggerInspectJobStorageConfig {
        /**
         * Options defining BigQuery table and row identifiers.
         * Structure is documented below.
         */
        bigQueryOptions?: outputs.dataloss.PreventionJobTriggerInspectJobStorageConfigBigQueryOptions;
        /**
         * Options defining a file or a set of files within a Google Cloud Storage bucket.
         * Structure is documented below.
         */
        cloudStorageOptions?: outputs.dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptions;
        /**
         * Options defining a data set within Google Cloud Datastore.
         * Structure is documented below.
         */
        datastoreOptions?: outputs.dataloss.PreventionJobTriggerInspectJobStorageConfigDatastoreOptions;
        /**
         * Information on where to inspect
         * Structure is documented below.
         */
        timespanConfig?: outputs.dataloss.PreventionJobTriggerInspectJobStorageConfigTimespanConfig;
    }

    export interface PreventionJobTriggerInspectJobStorageConfigBigQueryOptions {
        /**
         * Set of files to scan.
         * Structure is documented below.
         */
        tableReference: outputs.dataloss.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReference;
    }

    export interface PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReference {
        /**
         * Dataset ID of the table.
         */
        datasetId: string;
        /**
         * The Google Cloud Platform project ID of the project containing the table.
         */
        projectId: string;
        /**
         * Name of the table. If is not set a new one will be generated for you with the following format:
         * `dlp_googleapis_yyyy_mm_dd_[dlpJobId]`. Pacific timezone will be used for generating the date details.
         */
        tableId: string;
    }

    export interface PreventionJobTriggerInspectJobStorageConfigCloudStorageOptions {
        /**
         * Max number of bytes to scan from a file. If a scanned file's size is bigger than this value
         * then the rest of the bytes are omitted.
         */
        bytesLimitPerFile?: number;
        /**
         * Max percentage of bytes to scan from a file. The rest are omitted. The number of bytes scanned is rounded down.
         * Must be between 0 and 100, inclusively. Both 0 and 100 means no limit.
         */
        bytesLimitPerFilePercent?: number;
        /**
         * Set of files to scan.
         * Structure is documented below.
         */
        fileSet: outputs.dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSet;
        /**
         * List of file type groups to include in the scan. If empty, all files are scanned and available data
         * format processors are applied. In addition, the binary content of the selected files is always scanned as well.
         * Images are scanned only as binary if the specified region does not support image inspection and no fileTypes were specified.
         * Each value may be one of `BINARY_FILE`, `TEXT_FILE`, `IMAGE`, `WORD`, `PDF`, `AVRO`, `CSV`, and `TSV`.
         */
        fileTypes?: string[];
        /**
         * Limits the number of files to scan to this percentage of the input FileSet. Number of files scanned is rounded down.
         * Must be between 0 and 100, inclusively. Both 0 and 100 means no limit.
         */
        filesLimitPercent?: number;
        /**
         * How to sample bytes if not all bytes are scanned. Meaningful only when used in conjunction with bytesLimitPerFile.
         * If not specified, scanning would start from the top.
         * Possible values are `TOP` and `RANDOM_START`.
         */
        sampleMethod?: string;
    }

    export interface PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSet {
        /**
         * The regex-filtered set of files to scan.
         * Structure is documented below.
         */
        regexFileSet?: outputs.dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetRegexFileSet;
        /**
         * The Cloud Storage url of the file(s) to scan, in the format `gs://<bucket>/<path>`. Trailing wildcard
         * in the path is allowed.
         * If the url ends in a trailing slash, the bucket or directory represented by the url will be scanned
         * non-recursively (content in sub-directories will not be scanned). This means that `gs://mybucket/` is
         * equivalent to `gs://mybucket/*`, and `gs://mybucket/directory/` is equivalent to `gs://mybucket/directory/*`.
         */
        url?: string;
    }

    export interface PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetRegexFileSet {
        /**
         * The name of a Cloud Storage bucket.
         */
        bucketName: string;
        /**
         * A list of regular expressions matching file paths to exclude. All files in the bucket that match at
         * least one of these regular expressions will be excluded from the scan.
         */
        excludeRegexes?: string[];
        /**
         * A list of regular expressions matching file paths to include. All files in the bucket
         * that match at least one of these regular expressions will be included in the set of files,
         * except for those that also match an item in excludeRegex. Leaving this field empty will
         * match all files by default (this is equivalent to including .* in the list)
         */
        includeRegexes?: string[];
    }

    export interface PreventionJobTriggerInspectJobStorageConfigDatastoreOptions {
        /**
         * A representation of a Datastore kind.
         * Structure is documented below.
         */
        kind: outputs.dataloss.PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsKind;
        /**
         * Datastore partition ID. A partition ID identifies a grouping of entities. The grouping
         * is always by project and namespace, however the namespace ID may be empty.
         * Structure is documented below.
         */
        partitionId: outputs.dataloss.PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsPartitionId;
    }

    export interface PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsKind {
        /**
         * The name of the Datastore kind.
         */
        name: string;
    }

    export interface PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsPartitionId {
        /**
         * If not empty, the ID of the namespace to which the entities belong.
         */
        namespaceId?: string;
        /**
         * The Google Cloud Platform project ID of the project containing the table.
         */
        projectId: string;
    }

    export interface PreventionJobTriggerInspectJobStorageConfigTimespanConfig {
        /**
         * When the job is started by a JobTrigger we will automatically figure out a valid startTime to avoid
         * scanning files that have not been modified since the last time the JobTrigger executed. This will
         * be based on the time of the execution of the last run of the JobTrigger.
         */
        enableAutoPopulationOfTimespanConfig?: boolean;
        /**
         * Exclude files or rows newer than this value. If set to zero, no upper time limit is applied.
         */
        endTime?: string;
        /**
         * Exclude files or rows older than this value.
         */
        startTime?: string;
        /**
         * Information on where to inspect
         * Structure is documented below.
         */
        timestampField: outputs.dataloss.PreventionJobTriggerInspectJobStorageConfigTimespanConfigTimestampField;
    }

    export interface PreventionJobTriggerInspectJobStorageConfigTimespanConfigTimestampField {
        /**
         * The name of the Datastore kind.
         */
        name: string;
    }

    export interface PreventionJobTriggerTrigger {
        /**
         * Schedule for triggered jobs
         * Structure is documented below.
         */
        schedule?: outputs.dataloss.PreventionJobTriggerTriggerSchedule;
    }

    export interface PreventionJobTriggerTriggerSchedule {
        /**
         * With this option a job is started a regular periodic basis. For example: every day (86400 seconds).
         * A scheduled start time will be skipped if the previous execution has not ended when its scheduled time occurs.
         * This value must be set to a time duration greater than or equal to 1 day and can be no longer than 60 days.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        recurrencePeriodDuration?: string;
    }

    export interface PreventionStoredInfoTypeDictionary {
        /**
         * Newline-delimited file of words in Cloud Storage. Only a single file is accepted.
         * Structure is documented below.
         */
        cloudStoragePath?: outputs.dataloss.PreventionStoredInfoTypeDictionaryCloudStoragePath;
        /**
         * List of words or phrases to search for.
         * Structure is documented below.
         */
        wordList?: outputs.dataloss.PreventionStoredInfoTypeDictionaryWordList;
    }

    export interface PreventionStoredInfoTypeDictionaryCloudStoragePath {
        /**
         * A url representing a file or path (no wildcards) in Cloud Storage. Example: `gs://[BUCKET_NAME]/dictionary.txt`
         */
        path: string;
    }

    export interface PreventionStoredInfoTypeDictionaryWordList {
        /**
         * Words or phrases defining the dictionary. The dictionary must contain at least one
         * phrase and every phrase must contain at least 2 characters that are letters or digits.
         */
        words: string[];
    }

    export interface PreventionStoredInfoTypeLargeCustomDictionary {
        /**
         * Field in a BigQuery table where each cell represents a dictionary phrase.
         * Structure is documented below.
         */
        bigQueryField?: outputs.dataloss.PreventionStoredInfoTypeLargeCustomDictionaryBigQueryField;
        /**
         * Set of files containing newline-delimited lists of dictionary phrases.
         * Structure is documented below.
         */
        cloudStorageFileSet?: outputs.dataloss.PreventionStoredInfoTypeLargeCustomDictionaryCloudStorageFileSet;
        /**
         * Location to store dictionary artifacts in Google Cloud Storage. These files will only be accessible by project owners and the DLP API.
         * If any of these artifacts are modified, the dictionary is considered invalid and can no longer be used.
         * Structure is documented below.
         */
        outputPath: outputs.dataloss.PreventionStoredInfoTypeLargeCustomDictionaryOutputPath;
    }

    export interface PreventionStoredInfoTypeLargeCustomDictionaryBigQueryField {
        /**
         * Designated field in the BigQuery table.
         * Structure is documented below.
         */
        field: outputs.dataloss.PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldField;
        /**
         * Field in a BigQuery table where each cell represents a dictionary phrase.
         * Structure is documented below.
         */
        table: outputs.dataloss.PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldTable;
    }

    export interface PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldField {
        /**
         * Name describing the field.
         */
        name: string;
    }

    export interface PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldTable {
        /**
         * The dataset ID of the table.
         */
        datasetId: string;
        /**
         * The Google Cloud Platform project ID of the project containing the table.
         */
        projectId: string;
        /**
         * The name of the table.
         */
        tableId: string;
    }

    export interface PreventionStoredInfoTypeLargeCustomDictionaryCloudStorageFileSet {
        /**
         * The url, in the format `gs://<bucket>/<path>`. Trailing wildcard in the path is allowed.
         */
        url: string;
    }

    export interface PreventionStoredInfoTypeLargeCustomDictionaryOutputPath {
        /**
         * A url representing a file or path (no wildcards) in Cloud Storage. Example: `gs://[BUCKET_NAME]/dictionary.txt`
         */
        path: string;
    }

    export interface PreventionStoredInfoTypeRegex {
        /**
         * The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included.
         */
        groupIndexes?: number[];
        /**
         * Pattern defining the regular expression.
         * Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
         */
        pattern: string;
    }

}

export namespace dataplex {
    export interface LakeAssetStatus {
        activeAssets: number;
        securityPolicyApplyingAssets: number;
        updateTime: string;
    }

    export interface LakeMetastore {
        /**
         * Optional. A relative reference to the Dataproc Metastore (https://cloud.google.com/dataproc-metastore/docs) service associated with the lake: `projects/{project_id}/locations/{location_id}/services/{service_id}`
         */
        service?: string;
    }

    export interface LakeMetastoreStatus {
        endpoint: string;
        message: string;
        state: string;
        updateTime: string;
    }

}

export namespace dataproc {
    export interface AutoscalingPolicyBasicAlgorithm {
        /**
         * Duration between scaling events. A scaling period starts after the
         * update operation from the previous event has completed.
         * Bounds: [2m, 1d]. Default: 2m.
         */
        cooldownPeriod?: string;
        /**
         * YARN autoscaling configuration.
         * Structure is documented below.
         */
        yarnConfig: outputs.dataproc.AutoscalingPolicyBasicAlgorithmYarnConfig;
    }

    export interface AutoscalingPolicyBasicAlgorithmYarnConfig {
        /**
         * Timeout for YARN graceful decommissioning of Node Managers. Specifies the
         * duration to wait for jobs to complete before forcefully removing workers
         * (and potentially interrupting jobs). Only applicable to downscaling operations.
         * Bounds: [0s, 1d].
         */
        gracefulDecommissionTimeout: string;
        /**
         * Fraction of average pending memory in the last cooldown period for which to
         * remove workers. A scale-down factor of 1 will result in scaling down so that there
         * is no available memory remaining after the update (more aggressive scaling).
         * A scale-down factor of 0 disables removing workers, which can be beneficial for
         * autoscaling a single job.
         * Bounds: [0.0, 1.0].
         */
        scaleDownFactor: number;
        /**
         * Minimum scale-down threshold as a fraction of total cluster size before scaling occurs.
         * For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must
         * recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0
         * means the autoscaler will scale down on any recommended change.
         * Bounds: [0.0, 1.0]. Default: 0.0.
         */
        scaleDownMinWorkerFraction?: number;
        /**
         * Fraction of average pending memory in the last cooldown period for which to
         * add workers. A scale-up factor of 1.0 will result in scaling up so that there
         * is no pending memory remaining after the update (more aggressive scaling).
         * A scale-up factor closer to 0 will result in a smaller magnitude of scaling up
         * (less aggressive scaling).
         * Bounds: [0.0, 1.0].
         */
        scaleUpFactor: number;
        /**
         * Minimum scale-up threshold as a fraction of total cluster size before scaling
         * occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler
         * must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of
         * 0 means the autoscaler will scale up on any recommended change.
         * Bounds: [0.0, 1.0]. Default: 0.0.
         */
        scaleUpMinWorkerFraction?: number;
    }

    export interface AutoscalingPolicySecondaryWorkerConfig {
        /**
         * Maximum number of instances for this group. Note that by default, clusters will not use
         * secondary workers. Required for secondary workers if the minimum secondary instances is set.
         * Bounds: [minInstances, ). Defaults to 0.
         */
        maxInstances?: number;
        /**
         * Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
         */
        minInstances?: number;
        /**
         * Weight for the instance group, which is used to determine the fraction of total workers
         * in the cluster from this instance group. For example, if primary workers have weight 2,
         * and secondary workers have weight 1, the cluster will have approximately 2 primary workers
         * for each secondary worker.
         * The cluster may not reach the specified balance if constrained by min/max bounds or other
         * autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
         * primary workers will be added. The cluster can also be out of balance when created.
         * If weight is not set on any instance group, the cluster will default to equal weight for
         * all groups: the cluster will attempt to maintain an equal number of workers in each group
         * within the configured size bounds for each group. If weight is set for one group only,
         * the cluster will default to zero weight on the unset group. For example if weight is set
         * only on primary workers, the cluster will use primary workers only and no secondary workers.
         */
        weight?: number;
    }

    export interface AutoscalingPolicyWorkerConfig {
        /**
         * Maximum number of instances for this group. Note that by default, clusters will not use
         * secondary workers. Required for secondary workers if the minimum secondary instances is set.
         * Bounds: [minInstances, ). Defaults to 0.
         */
        maxInstances: number;
        /**
         * Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
         */
        minInstances?: number;
        /**
         * Weight for the instance group, which is used to determine the fraction of total workers
         * in the cluster from this instance group. For example, if primary workers have weight 2,
         * and secondary workers have weight 1, the cluster will have approximately 2 primary workers
         * for each secondary worker.
         * The cluster may not reach the specified balance if constrained by min/max bounds or other
         * autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
         * primary workers will be added. The cluster can also be out of balance when created.
         * If weight is not set on any instance group, the cluster will default to equal weight for
         * all groups: the cluster will attempt to maintain an equal number of workers in each group
         * within the configured size bounds for each group. If weight is set for one group only,
         * the cluster will default to zero weight on the unset group. For example if weight is set
         * only on primary workers, the cluster will use primary workers only and no secondary workers.
         */
        weight?: number;
    }

    export interface ClusterClusterConfig {
        /**
         * The autoscaling policy config associated with the cluster.
         * Note that once set, if `autoscalingConfig` is the only field set in `clusterConfig`, it can
         * only be removed by setting `policyUri = ""`, rather than removing the whole block.
         * Structure defined below.
         */
        autoscalingConfig?: outputs.dataproc.ClusterClusterConfigAutoscalingConfig;
        bucket: string;
        /**
         * The Customer managed encryption keys settings for the cluster.
         * Structure defined below.
         */
        encryptionConfig?: outputs.dataproc.ClusterClusterConfigEncryptionConfig;
        /**
         * The config settings for port access on the cluster.
         * Structure defined below.
         */
        endpointConfig: outputs.dataproc.ClusterClusterConfigEndpointConfig;
        /**
         * Common config settings for resources of Google Compute Engine cluster
         * instances, applicable to all instances in the cluster. Structure defined below.
         */
        gceClusterConfig: outputs.dataproc.ClusterClusterConfigGceClusterConfig;
        /**
         * Commands to execute on each node after config is completed.
         * You can specify multiple versions of these. Structure defined below.
         */
        initializationActions?: outputs.dataproc.ClusterClusterConfigInitializationAction[];
        /**
         * The settings for auto deletion cluster schedule.
         * Structure defined below.
         */
        lifecycleConfig?: outputs.dataproc.ClusterClusterConfigLifecycleConfig;
        /**
         * The Google Compute Engine config settings for the master instances
         * in a cluster. Structure defined below.
         */
        masterConfig: outputs.dataproc.ClusterClusterConfigMasterConfig;
        /**
         * The config setting for metastore service with the cluster.
         * Structure defined below.
         * - - -
         */
        metastoreConfig?: outputs.dataproc.ClusterClusterConfigMetastoreConfig;
        /**
         * The Google Compute Engine config settings for the additional
         * instances in a cluster. Structure defined below.
         * * **NOTE** : `preemptibleWorkerConfig` is
         * an alias for the api's [secondaryWorkerConfig](https://cloud.google.com/dataproc/docs/reference/rest/v1/ClusterConfig#InstanceGroupConfig). The name doesn't necessarily mean it is preemptible and is named as
         * such for legacy/compatibility reasons.
         */
        preemptibleWorkerConfig: outputs.dataproc.ClusterClusterConfigPreemptibleWorkerConfig;
        /**
         * Security related configuration. Structure defined below.
         */
        securityConfig?: outputs.dataproc.ClusterClusterConfigSecurityConfig;
        /**
         * The config settings for software inside the cluster.
         * Structure defined below.
         */
        softwareConfig: outputs.dataproc.ClusterClusterConfigSoftwareConfig;
        /**
         * The Cloud Storage staging bucket used to stage files,
         * such as Hadoop jars, between client machines and the cluster.
         * Note: If you don't explicitly specify a `stagingBucket`
         * then GCP will auto create / assign one for you. However, you are not guaranteed
         * an auto generated bucket which is solely dedicated to your cluster; it may be shared
         * with other clusters in the same region/zone also choosing to use the auto generation
         * option.
         */
        stagingBucket?: string;
        /**
         * The Cloud Storage temp bucket used to store ephemeral cluster
         * and jobs data, such as Spark and MapReduce history files.
         * Note: If you don't explicitly specify a `tempBucket` then GCP will auto create / assign one for you.
         */
        tempBucket: string;
        /**
         * The Google Compute Engine config settings for the worker instances
         * in a cluster. Structure defined below.
         */
        workerConfig: outputs.dataproc.ClusterClusterConfigWorkerConfig;
    }

    export interface ClusterClusterConfigAutoscalingConfig {
        /**
         * The autoscaling policy used by the cluster.
         */
        policyUri: string;
    }

    export interface ClusterClusterConfigEncryptionConfig {
        /**
         * The Cloud KMS key name to use for PD disk encryption for
         * all instances in the cluster.
         */
        kmsKeyName: string;
    }

    export interface ClusterClusterConfigEndpointConfig {
        /**
         * The flag to enable http access to specific ports
         * on the cluster from external sources (aka Component Gateway). Defaults to false.
         */
        enableHttpPortAccess: boolean;
        httpPorts: {[key: string]: any};
    }

    export interface ClusterClusterConfigGceClusterConfig {
        /**
         * By default, clusters are not restricted to internal IP addresses,
         * and will have ephemeral external IP addresses assigned to each instance. If set to true, all
         * instances in the cluster will only have internal IP addresses. Note: Private Google Access
         * (also known as `privateIpGoogleAccess`) must be enabled on the subnetwork that the cluster
         * will be launched in.
         */
        internalIpOnly?: boolean;
        /**
         * A map of the Compute Engine metadata entries to add to all instances
         * (see [Project and instance metadata](https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
         */
        metadata?: {[key: string]: string};
        /**
         * The name or selfLink of the Google Compute Engine
         * network to the cluster will be part of. Conflicts with `subnetwork`.
         * If neither is specified, this defaults to the "default" network.
         */
        network: string;
        /**
         * The service account to be used by the Node VMs.
         * If not specified, the "default" service account is used.
         */
        serviceAccount?: string;
        /**
         * The set of Google API scopes
         * to be made available on all of the node VMs under the `serviceAccount`
         * specified. Both OAuth2 URLs and gcloud
         * short names are supported. To allow full access to all Cloud APIs, use the
         * `cloud-platform` scope. See a complete list of scopes [here](https://cloud.google.com/sdk/gcloud/reference/alpha/compute/instances/set-scopes#--scopes).
         */
        serviceAccountScopes: string[];
        /**
         * Shielded Instance Config for clusters using [Compute Engine Shielded VMs](https://cloud.google.com/security/shielded-cloud/shielded-vm).
         */
        shieldedInstanceConfig: outputs.dataproc.ClusterClusterConfigGceClusterConfigShieldedInstanceConfig;
        /**
         * The name or selfLink of the Google Compute Engine
         * subnetwork the cluster will be part of. Conflicts with `network`.
         */
        subnetwork?: string;
        /**
         * The list of instance tags applied to instances in the cluster.
         * Tags are used to identify valid sources or targets for network firewalls.
         */
        tags?: string[];
        /**
         * The GCP zone where your data is stored and used (i.e. where
         * the master and the worker nodes will be created in). If `region` is set to 'global' (default)
         * then `zone` is mandatory, otherwise GCP is able to make use of [Auto Zone Placement](https://cloud.google.com/dataproc/docs/concepts/auto-zone)
         * to determine this automatically for you.
         * Note: This setting additionally determines and restricts
         * which computing resources are available for use with other configs such as
         * `cluster_config.master_config.machine_type` and `cluster_config.worker_config.machine_type`.
         */
        zone: string;
    }

    export interface ClusterClusterConfigGceClusterConfigShieldedInstanceConfig {
        /**
         * Defines whether instances have integrity monitoring enabled.
         */
        enableIntegrityMonitoring?: boolean;
        /**
         * Defines whether instances have Secure Boot enabled.
         */
        enableSecureBoot?: boolean;
        /**
         * Defines whether instances have the [vTPM](https://cloud.google.com/security/shielded-cloud/shielded-vm#vtpm) enabled.
         */
        enableVtpm?: boolean;
    }

    export interface ClusterClusterConfigInitializationAction {
        /**
         * The script to be executed during initialization of the cluster.
         * The script must be a GCS file with a gs:// prefix.
         */
        script: string;
        /**
         * The maximum duration (in seconds) which `script` is
         * allowed to take to execute its action. GCP will default to a predetermined
         * computed value if not set (currently 300).
         */
        timeoutSec?: number;
    }

    export interface ClusterClusterConfigLifecycleConfig {
        /**
         * The time when cluster will be auto-deleted.
         * A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
         * Example: "2014-10-02T15:01:23.045123456Z".
         */
        autoDeleteTime?: string;
        /**
         * The duration to keep the cluster alive while idling
         * (no jobs running). After this TTL, the cluster will be deleted. Valid range: [10m, 14d].
         */
        idleDeleteTtl?: string;
        idleStartTime: string;
    }

    export interface ClusterClusterConfigMasterConfig {
        /**
         * The Compute Engine accelerator configuration for these instances. Can be specified multiple times.
         */
        accelerators?: outputs.dataproc.ClusterClusterConfigMasterConfigAccelerator[];
        /**
         * Disk Config
         */
        diskConfig: outputs.dataproc.ClusterClusterConfigMasterConfigDiskConfig;
        /**
         * The URI for the image to use for this worker.  See [the guide](https://cloud.google.com/dataproc/docs/guides/dataproc-images)
         * for more information.
         */
        imageUri: string;
        instanceNames: string[];
        /**
         * The name of a Google Compute Engine machine type
         * to create for the worker nodes. If not specified, GCP will default to a predetermined
         * computed value (currently `n1-standard-4`).
         */
        machineType: string;
        /**
         * The name of a minimum generation of CPU family
         * for the master. If not specified, GCP will default to a predetermined computed value
         * for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
         * for details about which CPU families are available (and defaulted) for each zone.
         */
        minCpuPlatform: string;
        /**
         * Specifies the number of preemptible nodes to create.
         * Defaults to 0.
         */
        numInstances: number;
    }

    export interface ClusterClusterConfigMasterConfigAccelerator {
        /**
         * The number of the accelerator cards of this type exposed to this instance. Often restricted to one of `1`, `2`, `4`, or `8`.
         */
        acceleratorCount: number;
        /**
         * The short name of the accelerator type to expose to this instance. For example, `nvidia-tesla-k80`.
         */
        acceleratorType: string;
    }

    export interface ClusterClusterConfigMasterConfigDiskConfig {
        /**
         * Size of the primary disk attached to each preemptible worker node, specified
         * in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
         * computed value if not set (currently 500GB). Note: If SSDs are not
         * attached, it also contains the HDFS data blocks and Hadoop working directories.
         */
        bootDiskSizeGb: number;
        /**
         * The disk type of the primary disk attached to each preemptible worker node.
         * One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
         */
        bootDiskType?: string;
        /**
         * The amount of local SSD disks that will be
         * attached to each preemptible worker node. Defaults to 0.
         */
        numLocalSsds: number;
    }

    export interface ClusterClusterConfigMetastoreConfig {
        /**
         * Resource name of an existing Dataproc Metastore service.
         */
        dataprocMetastoreService: string;
    }

    export interface ClusterClusterConfigPreemptibleWorkerConfig {
        /**
         * Disk Config
         */
        diskConfig: outputs.dataproc.ClusterClusterConfigPreemptibleWorkerConfigDiskConfig;
        instanceNames: string[];
        /**
         * Specifies the number of preemptible nodes to create.
         * Defaults to 0.
         */
        numInstances: number;
        /**
         * Specifies the preemptibility of the secondary workers. The default value is `PREEMPTIBLE`
         * Accepted values are:
         * * PREEMPTIBILITY_UNSPECIFIED
         * * NON_PREEMPTIBLE
         * * PREEMPTIBLE
         */
        preemptibility?: string;
    }

    export interface ClusterClusterConfigPreemptibleWorkerConfigDiskConfig {
        /**
         * Size of the primary disk attached to each preemptible worker node, specified
         * in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
         * computed value if not set (currently 500GB). Note: If SSDs are not
         * attached, it also contains the HDFS data blocks and Hadoop working directories.
         */
        bootDiskSizeGb: number;
        /**
         * The disk type of the primary disk attached to each preemptible worker node.
         * One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
         */
        bootDiskType?: string;
        /**
         * The amount of local SSD disks that will be
         * attached to each preemptible worker node. Defaults to 0.
         */
        numLocalSsds: number;
    }

    export interface ClusterClusterConfigSecurityConfig {
        /**
         * Kerberos Configuration
         */
        kerberosConfig: outputs.dataproc.ClusterClusterConfigSecurityConfigKerberosConfig;
    }

    export interface ClusterClusterConfigSecurityConfigKerberosConfig {
        /**
         * The admin server (IP or hostname) for the
         * remote trusted realm in a cross realm trust relationship.
         */
        crossRealmTrustAdminServer?: string;
        /**
         * The KDC (IP or hostname) for the
         * remote trusted realm in a cross realm trust relationship.
         */
        crossRealmTrustKdc?: string;
        /**
         * The remote realm the Dataproc on-cluster KDC will
         * trust, should the user enable cross realm trust.
         */
        crossRealmTrustRealm?: string;
        /**
         * The Cloud Storage URI of a KMS
         * encrypted file containing the shared password between the on-cluster Kerberos realm
         * and the remote trusted realm, in a cross realm trust relationship.
         */
        crossRealmTrustSharedPasswordUri?: string;
        /**
         * Flag to indicate whether to Kerberize the cluster.
         */
        enableKerberos?: boolean;
        /**
         * The Cloud Storage URI of a KMS encrypted file containing
         * the master key of the KDC database.
         */
        kdcDbKeyUri?: string;
        /**
         * The Cloud Storage URI of a KMS encrypted file containing
         * the password to the user provided key. For the self-signed certificate, this password
         * is generated by Dataproc.
         */
        keyPasswordUri?: string;
        /**
         * The Cloud Storage URI of a KMS encrypted file containing
         * the password to the user provided keystore. For the self-signed certificated, the password
         * is generated by Dataproc.
         */
        keystorePasswordUri?: string;
        /**
         * The Cloud Storage URI of the keystore file used for SSL encryption.
         * If not provided, Dataproc will provide a self-signed certificate.
         */
        keystoreUri?: string;
        /**
         * The URI of the KMS key used to encrypt various sensitive files.
         */
        kmsKeyUri: string;
        /**
         * The name of the on-cluster Kerberos realm. If not specified, the
         * uppercased domain of hostnames will be the realm.
         */
        realm?: string;
        /**
         * The Cloud Storage URI of a KMS encrypted file
         * containing the root principal password.
         */
        rootPrincipalPasswordUri: string;
        /**
         * The lifetime of the ticket granting ticket, in hours.
         */
        tgtLifetimeHours?: number;
        /**
         * The Cloud Storage URI of a KMS encrypted file
         * containing the password to the user provided truststore. For the self-signed
         * certificate, this password is generated by Dataproc.
         */
        truststorePasswordUri?: string;
        /**
         * The Cloud Storage URI of the truststore file used for
         * SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
         */
        truststoreUri?: string;
    }

    export interface ClusterClusterConfigSoftwareConfig {
        /**
         * The Cloud Dataproc image version to use
         * for the cluster - this controls the sets of software versions
         * installed onto the nodes when you create clusters. If not specified, defaults to the
         * latest version. For a list of valid versions see
         * [Cloud Dataproc versions](https://cloud.google.com/dataproc/docs/concepts/dataproc-versions)
         */
        imageVersion: string;
        /**
         * The set of optional components to activate on the cluster.
         * Accepted values are:
         * * ANACONDA
         * * DRUID
         * * FLINK
         * * HBASE
         * * HIVE_WEBHCAT
         * * JUPYTER
         * * PRESTO
         * * RANGER
         * * SOLR
         * * ZEPPELIN
         * * ZOOKEEPER
         */
        optionalComponents?: string[];
        /**
         * A list of override and additional properties (key/value pairs)
         * used to modify various aspects of the common configuration files used when creating
         * a cluster. For a list of valid properties please see
         * [Cluster properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties)
         */
        overrideProperties?: {[key: string]: string};
        properties: {[key: string]: any};
    }

    export interface ClusterClusterConfigWorkerConfig {
        /**
         * The Compute Engine accelerator configuration for these instances. Can be specified multiple times.
         */
        accelerators?: outputs.dataproc.ClusterClusterConfigWorkerConfigAccelerator[];
        /**
         * Disk Config
         */
        diskConfig: outputs.dataproc.ClusterClusterConfigWorkerConfigDiskConfig;
        /**
         * The URI for the image to use for this worker.  See [the guide](https://cloud.google.com/dataproc/docs/guides/dataproc-images)
         * for more information.
         */
        imageUri: string;
        instanceNames: string[];
        /**
         * The name of a Google Compute Engine machine type
         * to create for the worker nodes. If not specified, GCP will default to a predetermined
         * computed value (currently `n1-standard-4`).
         */
        machineType: string;
        /**
         * The name of a minimum generation of CPU family
         * for the master. If not specified, GCP will default to a predetermined computed value
         * for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
         * for details about which CPU families are available (and defaulted) for each zone.
         */
        minCpuPlatform: string;
        /**
         * Specifies the number of preemptible nodes to create.
         * Defaults to 0.
         */
        numInstances: number;
    }

    export interface ClusterClusterConfigWorkerConfigAccelerator {
        /**
         * The number of the accelerator cards of this type exposed to this instance. Often restricted to one of `1`, `2`, `4`, or `8`.
         */
        acceleratorCount: number;
        /**
         * The short name of the accelerator type to expose to this instance. For example, `nvidia-tesla-k80`.
         */
        acceleratorType: string;
    }

    export interface ClusterClusterConfigWorkerConfigDiskConfig {
        /**
         * Size of the primary disk attached to each preemptible worker node, specified
         * in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
         * computed value if not set (currently 500GB). Note: If SSDs are not
         * attached, it also contains the HDFS data blocks and Hadoop working directories.
         */
        bootDiskSizeGb: number;
        /**
         * The disk type of the primary disk attached to each preemptible worker node.
         * One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
         */
        bootDiskType?: string;
        /**
         * The amount of local SSD disks that will be
         * attached to each preemptible worker node. Defaults to 0.
         */
        numLocalSsds: number;
    }

    export interface ClusterIAMBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ClusterIAMMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface JobHadoopConfig {
        /**
         * HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
         */
        archiveUris?: string[];
        /**
         * The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
         */
        args?: string[];
        /**
         * HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
         */
        fileUris?: string[];
        /**
         * HCFS URIs of jar files to be added to the Spark CLASSPATH.
         */
        jarFileUris?: string[];
        loggingConfig: outputs.dataproc.JobHadoopConfigLoggingConfig;
        /**
         * The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jarFileUris`. Conflicts with `mainJarFileUri`
         */
        mainClass?: string;
        /**
         * The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'. Conflicts with `mainClass`
         */
        mainJarFileUri?: string;
        /**
         * A mapping of property names to values. Used to set Presto session properties Equivalent to using the --session flag in the Presto CLI.
         */
        properties?: {[key: string]: string};
    }

    export interface JobHadoopConfigLoggingConfig {
        driverLogLevels: {[key: string]: string};
    }

    export interface JobHiveConfig {
        /**
         * Whether to continue executing queries if a query fails. Setting to true can be useful when executing independent parallel queries. Defaults to false.
         */
        continueOnFailure?: boolean;
        /**
         * HCFS URIs of jar files to be added to the Spark CLASSPATH.
         */
        jarFileUris?: string[];
        /**
         * A mapping of property names to values. Used to set Presto session properties Equivalent to using the --session flag in the Presto CLI.
         */
        properties?: {[key: string]: string};
        /**
         * The HCFS URI of the script that contains SQL queries.
         * Conflicts with `queryList`
         */
        queryFileUri?: string;
        /**
         * The list of SQL queries or statements to execute as part of the job.
         * Conflicts with `queryFileUri`
         */
        queryLists?: string[];
        /**
         * Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
         */
        scriptVariables?: {[key: string]: string};
    }

    export interface JobIAMBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface JobIAMMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface JobPigConfig {
        /**
         * Whether to continue executing queries if a query fails. Setting to true can be useful when executing independent parallel queries. Defaults to false.
         */
        continueOnFailure?: boolean;
        /**
         * HCFS URIs of jar files to be added to the Spark CLASSPATH.
         */
        jarFileUris?: string[];
        loggingConfig: outputs.dataproc.JobPigConfigLoggingConfig;
        /**
         * A mapping of property names to values. Used to set Presto session properties Equivalent to using the --session flag in the Presto CLI.
         */
        properties?: {[key: string]: string};
        /**
         * The HCFS URI of the script that contains SQL queries.
         * Conflicts with `queryList`
         */
        queryFileUri?: string;
        /**
         * The list of SQL queries or statements to execute as part of the job.
         * Conflicts with `queryFileUri`
         */
        queryLists?: string[];
        /**
         * Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
         */
        scriptVariables?: {[key: string]: string};
    }

    export interface JobPigConfigLoggingConfig {
        driverLogLevels: {[key: string]: string};
    }

    export interface JobPlacement {
        clusterName: string;
        clusterUuid: string;
    }

    export interface JobPrestoConfig {
        /**
         * Presto client tags to attach to this query.
         */
        clientTags?: string[];
        /**
         * Whether to continue executing queries if a query fails. Setting to true can be useful when executing independent parallel queries. Defaults to false.
         */
        continueOnFailure?: boolean;
        loggingConfig: outputs.dataproc.JobPrestoConfigLoggingConfig;
        /**
         * The format in which query output will be displayed. See the Presto documentation for supported output formats.
         */
        outputFormat?: string;
        /**
         * A mapping of property names to values. Used to set Presto session properties Equivalent to using the --session flag in the Presto CLI.
         */
        properties?: {[key: string]: string};
        /**
         * The HCFS URI of the script that contains SQL queries.
         * Conflicts with `queryList`
         */
        queryFileUri?: string;
        /**
         * The list of SQL queries or statements to execute as part of the job.
         * Conflicts with `queryFileUri`
         */
        queryLists?: string[];
    }

    export interface JobPrestoConfigLoggingConfig {
        driverLogLevels: {[key: string]: string};
    }

    export interface JobPysparkConfig {
        /**
         * HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
         */
        archiveUris?: string[];
        /**
         * The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
         */
        args?: string[];
        /**
         * HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
         */
        fileUris?: string[];
        /**
         * HCFS URIs of jar files to be added to the Spark CLASSPATH.
         */
        jarFileUris?: string[];
        loggingConfig: outputs.dataproc.JobPysparkConfigLoggingConfig;
        /**
         * The HCFS URI of the main Python file to use as the driver. Must be a .py file.
         */
        mainPythonFileUri: string;
        /**
         * A mapping of property names to values. Used to set Presto session properties Equivalent to using the --session flag in the Presto CLI.
         */
        properties?: {[key: string]: string};
        /**
         * HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
         */
        pythonFileUris?: string[];
    }

    export interface JobPysparkConfigLoggingConfig {
        driverLogLevels: {[key: string]: string};
    }

    export interface JobReference {
        jobId: string;
    }

    export interface JobScheduling {
        maxFailuresPerHour: number;
        maxFailuresTotal: number;
    }

    export interface JobSparkConfig {
        /**
         * HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
         */
        archiveUris?: string[];
        /**
         * The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
         */
        args?: string[];
        /**
         * HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
         */
        fileUris?: string[];
        /**
         * HCFS URIs of jar files to be added to the Spark CLASSPATH.
         */
        jarFileUris?: string[];
        loggingConfig: outputs.dataproc.JobSparkConfigLoggingConfig;
        /**
         * The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jarFileUris`. Conflicts with `mainJarFileUri`
         */
        mainClass?: string;
        /**
         * The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'. Conflicts with `mainClass`
         */
        mainJarFileUri?: string;
        /**
         * A mapping of property names to values. Used to set Presto session properties Equivalent to using the --session flag in the Presto CLI.
         */
        properties?: {[key: string]: string};
    }

    export interface JobSparkConfigLoggingConfig {
        driverLogLevels: {[key: string]: string};
    }

    export interface JobSparksqlConfig {
        /**
         * HCFS URIs of jar files to be added to the Spark CLASSPATH.
         */
        jarFileUris?: string[];
        loggingConfig: outputs.dataproc.JobSparksqlConfigLoggingConfig;
        /**
         * A mapping of property names to values. Used to set Presto session properties Equivalent to using the --session flag in the Presto CLI.
         */
        properties?: {[key: string]: string};
        /**
         * The HCFS URI of the script that contains SQL queries.
         * Conflicts with `queryList`
         */
        queryFileUri?: string;
        /**
         * The list of SQL queries or statements to execute as part of the job.
         * Conflicts with `queryFileUri`
         */
        queryLists?: string[];
        /**
         * Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
         */
        scriptVariables?: {[key: string]: string};
    }

    export interface JobSparksqlConfigLoggingConfig {
        driverLogLevels: {[key: string]: string};
    }

    export interface JobStatus {
        details: string;
        state: string;
        stateStartTime: string;
        substate: string;
    }

    export interface MetastoreServiceEncryptionConfig {
        /**
         * The fully qualified customer provided Cloud KMS key name to use for customer data encryption.
         * Use the following format: `projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)`
         */
        kmsKey: string;
    }

    export interface MetastoreServiceHiveMetastoreConfig {
        /**
         * A mapping of Hive metastore configuration key-value pairs to apply to the Hive metastore (configured in hive-site.xml).
         * The mappings override system defaults (some keys cannot be overridden)
         */
        configOverrides: {[key: string]: string};
        /**
         * Information used to configure the Hive metastore service as a service principal in a Kerberos realm.
         * Structure is documented below.
         */
        kerberosConfig?: outputs.dataproc.MetastoreServiceHiveMetastoreConfigKerberosConfig;
        /**
         * The Hive metastore schema version.
         */
        version: string;
    }

    export interface MetastoreServiceHiveMetastoreConfigKerberosConfig {
        /**
         * A Kerberos keytab file that can be used to authenticate a service principal with a Kerberos Key Distribution Center (KDC).
         * Structure is documented below.
         */
        keytab: outputs.dataproc.MetastoreServiceHiveMetastoreConfigKerberosConfigKeytab;
        /**
         * A Cloud Storage URI that specifies the path to a krb5.conf file. It is of the form gs://{bucket_name}/path/to/krb5.conf, although the file does not need to be named krb5.conf explicitly.
         */
        krb5ConfigGcsUri: string;
        /**
         * A Kerberos principal that exists in the both the keytab the KDC to authenticate as. A typical principal is of the form "primary/instance@REALM", but there is no exact format.
         */
        principal: string;
    }

    export interface MetastoreServiceHiveMetastoreConfigKerberosConfigKeytab {
        /**
         * The relative resource name of a Secret Manager secret version, in the following form:
         * "projects/{projectNumber}/secrets/{secret_id}/versions/{version_id}".
         */
        cloudSecret: string;
    }

    export interface MetastoreServiceMaintenanceWindow {
        /**
         * The day of week, when the window starts.
         * Possible values are `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, and `SUNDAY`.
         */
        dayOfWeek: string;
        /**
         * The hour of day (0-23) when the window starts.
         */
        hourOfDay: number;
    }

    export interface WorkflowTemplateJob {
        /**
         * Optional. Job is a Hadoop job.
         */
        hadoopJob?: outputs.dataproc.WorkflowTemplateJobHadoopJob;
        /**
         * Optional. Job is a Hive job.
         */
        hiveJob?: outputs.dataproc.WorkflowTemplateJobHiveJob;
        /**
         * Optional. The labels to associate with this cluster. Label keys must be between 1 and 63 characters long, and must conform to the following PCRE regular expression: {0,63} No more than 32 labels can be associated with a given cluster.
         */
        labels?: {[key: string]: string};
        /**
         * Optional. Job is a Pig job.
         */
        pigJob?: outputs.dataproc.WorkflowTemplateJobPigJob;
        /**
         * Optional. The optional list of prerequisite job step_ids. If not specified, the job will start at the beginning of workflow.
         */
        prerequisiteStepIds?: string[];
        /**
         * Optional. Job is a Presto job.
         */
        prestoJob?: outputs.dataproc.WorkflowTemplateJobPrestoJob;
        /**
         * Optional. Job is a PySpark job.
         */
        pysparkJob?: outputs.dataproc.WorkflowTemplateJobPysparkJob;
        /**
         * Optional. Job scheduling configuration.
         */
        scheduling?: outputs.dataproc.WorkflowTemplateJobScheduling;
        /**
         * Optional. Job is a Spark job.
         */
        sparkJob?: outputs.dataproc.WorkflowTemplateJobSparkJob;
        /**
         * Optional. Job is a SparkR job.
         */
        sparkRJob?: outputs.dataproc.WorkflowTemplateJobSparkRJob;
        /**
         * Optional. Job is a SparkSql job.
         */
        sparkSqlJob?: outputs.dataproc.WorkflowTemplateJobSparkSqlJob;
        /**
         * Required. The step id. The id must be unique among all jobs within the template. The step id is used as prefix for job id, as job `goog-dataproc-workflow-step-id` label, and in field from other steps. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between 3 and 50 characters.
         */
        stepId: string;
    }

    export interface WorkflowTemplateJobHadoopJob {
        /**
         * Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
         */
        archiveUris?: string[];
        /**
         * Optional. The arguments to pass to the driver. Do not include arguments, such as `--conf`, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
         */
        args?: string[];
        /**
         * Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
         */
        fileUris?: string[];
        /**
         * Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
         */
        jarFileUris?: string[];
        /**
         * Optional. The runtime log config for job execution.
         */
        loggingConfig?: outputs.dataproc.WorkflowTemplateJobHadoopJobLoggingConfig;
        /**
         * The name of the driver's main class. The jar file that contains the class must be in the default CLASSPATH or specified in `jarFileUris`.
         */
        mainClass?: string;
        /**
         * The HCFS URI of the jar file that contains the main class.
         */
        mainJarFileUri?: string;
        /**
         * Optional. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. The following are supported prefixes and their mappings: * capacity-scheduler: `capacity-scheduler.xml` * core: `core-site.xml` * distcp: `distcp-default.xml` * hdfs: `hdfs-site.xml` * hive: `hive-site.xml` * mapred: `mapred-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf` * yarn: `yarn-site.xml` For more information, see (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
         */
        properties?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobHadoopJobLoggingConfig {
        /**
         * The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
         */
        driverLogLevels?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobHiveJob {
        /**
         * Optional. Whether to continue executing queries if a query fails. The default value is `false`. Setting to `true` can be useful when executing independent parallel queries.
         */
        continueOnFailure?: boolean;
        /**
         * Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
         */
        jarFileUris?: string[];
        /**
         * Optional. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. The following are supported prefixes and their mappings: * capacity-scheduler: `capacity-scheduler.xml` * core: `core-site.xml` * distcp: `distcp-default.xml` * hdfs: `hdfs-site.xml` * hive: `hive-site.xml` * mapred: `mapred-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf` * yarn: `yarn-site.xml` For more information, see (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
         */
        properties?: {[key: string]: string};
        /**
         * The HCFS URI of the script that contains SQL queries.
         */
        queryFileUri?: string;
        /**
         * A list of queries.
         */
        queryList?: outputs.dataproc.WorkflowTemplateJobHiveJobQueryList;
        /**
         * Optional. Mapping of query variable names to values (equivalent to the Spark SQL command: SET `name="value";`).
         */
        scriptVariables?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobHiveJobQueryList {
        /**
         * Required. The queries to execute. You do not need to end a query expression with a semicolon. Multiple queries can be specified in one string by separating each with a semicolon. Here is an example of a Dataproc API snippet that uses a QueryList to specify a HiveJob: "hiveJob": { "queryList": { "queries": } }
         */
        queries: string[];
    }

    export interface WorkflowTemplateJobPigJob {
        /**
         * Optional. Whether to continue executing queries if a query fails. The default value is `false`. Setting to `true` can be useful when executing independent parallel queries.
         */
        continueOnFailure?: boolean;
        /**
         * Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
         */
        jarFileUris?: string[];
        /**
         * Optional. The runtime log config for job execution.
         */
        loggingConfig?: outputs.dataproc.WorkflowTemplateJobPigJobLoggingConfig;
        /**
         * Optional. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. The following are supported prefixes and their mappings: * capacity-scheduler: `capacity-scheduler.xml` * core: `core-site.xml` * distcp: `distcp-default.xml` * hdfs: `hdfs-site.xml` * hive: `hive-site.xml` * mapred: `mapred-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf` * yarn: `yarn-site.xml` For more information, see (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
         */
        properties?: {[key: string]: string};
        /**
         * The HCFS URI of the script that contains SQL queries.
         */
        queryFileUri?: string;
        /**
         * A list of queries.
         */
        queryList?: outputs.dataproc.WorkflowTemplateJobPigJobQueryList;
        /**
         * Optional. Mapping of query variable names to values (equivalent to the Spark SQL command: SET `name="value";`).
         */
        scriptVariables?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobPigJobLoggingConfig {
        /**
         * The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
         */
        driverLogLevels?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobPigJobQueryList {
        /**
         * Required. The queries to execute. You do not need to end a query expression with a semicolon. Multiple queries can be specified in one string by separating each with a semicolon. Here is an example of a Dataproc API snippet that uses a QueryList to specify a HiveJob: "hiveJob": { "queryList": { "queries": } }
         */
        queries: string[];
    }

    export interface WorkflowTemplateJobPrestoJob {
        /**
         * Optional. Presto client tags to attach to this query
         */
        clientTags?: string[];
        /**
         * Optional. Whether to continue executing queries if a query fails. The default value is `false`. Setting to `true` can be useful when executing independent parallel queries.
         */
        continueOnFailure?: boolean;
        /**
         * Optional. The runtime log config for job execution.
         */
        loggingConfig?: outputs.dataproc.WorkflowTemplateJobPrestoJobLoggingConfig;
        /**
         * Optional. The format in which query output will be displayed. See the Presto documentation for supported output formats
         */
        outputFormat?: string;
        /**
         * Optional. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. The following are supported prefixes and their mappings: * capacity-scheduler: `capacity-scheduler.xml` * core: `core-site.xml` * distcp: `distcp-default.xml` * hdfs: `hdfs-site.xml` * hive: `hive-site.xml` * mapred: `mapred-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf` * yarn: `yarn-site.xml` For more information, see (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
         */
        properties?: {[key: string]: string};
        /**
         * The HCFS URI of the script that contains SQL queries.
         */
        queryFileUri?: string;
        /**
         * A list of queries.
         */
        queryList?: outputs.dataproc.WorkflowTemplateJobPrestoJobQueryList;
    }

    export interface WorkflowTemplateJobPrestoJobLoggingConfig {
        /**
         * The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
         */
        driverLogLevels?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobPrestoJobQueryList {
        /**
         * Required. The queries to execute. You do not need to end a query expression with a semicolon. Multiple queries can be specified in one string by separating each with a semicolon. Here is an example of a Dataproc API snippet that uses a QueryList to specify a HiveJob: "hiveJob": { "queryList": { "queries": } }
         */
        queries: string[];
    }

    export interface WorkflowTemplateJobPysparkJob {
        /**
         * Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
         */
        archiveUris?: string[];
        /**
         * Optional. The arguments to pass to the driver. Do not include arguments, such as `--conf`, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
         */
        args?: string[];
        /**
         * Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
         */
        fileUris?: string[];
        /**
         * Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
         */
        jarFileUris?: string[];
        /**
         * Optional. The runtime log config for job execution.
         */
        loggingConfig?: outputs.dataproc.WorkflowTemplateJobPysparkJobLoggingConfig;
        /**
         * Required. The HCFS URI of the main Python file to use as the driver. Must be a .py file.
         */
        mainPythonFileUri: string;
        /**
         * Optional. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. The following are supported prefixes and their mappings: * capacity-scheduler: `capacity-scheduler.xml` * core: `core-site.xml` * distcp: `distcp-default.xml` * hdfs: `hdfs-site.xml` * hive: `hive-site.xml` * mapred: `mapred-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf` * yarn: `yarn-site.xml` For more information, see (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
         */
        properties?: {[key: string]: string};
        /**
         * Optional. HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
         */
        pythonFileUris?: string[];
    }

    export interface WorkflowTemplateJobPysparkJobLoggingConfig {
        /**
         * The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
         */
        driverLogLevels?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobScheduling {
        /**
         * Optional. Maximum number of times per hour a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed. A job may be reported as thrashing if driver exits with non-zero code 4 times within 10 minute window. Maximum value is 10.
         */
        maxFailuresPerHour?: number;
        /**
         * Optional. Maximum number of times in total a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed. Maximum value is 240
         */
        maxFailuresTotal?: number;
    }

    export interface WorkflowTemplateJobSparkJob {
        /**
         * Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
         */
        archiveUris?: string[];
        /**
         * Optional. The arguments to pass to the driver. Do not include arguments, such as `--conf`, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
         */
        args?: string[];
        /**
         * Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
         */
        fileUris?: string[];
        /**
         * Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
         */
        jarFileUris?: string[];
        /**
         * Optional. The runtime log config for job execution.
         */
        loggingConfig?: outputs.dataproc.WorkflowTemplateJobSparkJobLoggingConfig;
        /**
         * The name of the driver's main class. The jar file that contains the class must be in the default CLASSPATH or specified in `jarFileUris`.
         */
        mainClass?: string;
        /**
         * The HCFS URI of the jar file that contains the main class.
         */
        mainJarFileUri?: string;
        /**
         * Optional. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. The following are supported prefixes and their mappings: * capacity-scheduler: `capacity-scheduler.xml` * core: `core-site.xml` * distcp: `distcp-default.xml` * hdfs: `hdfs-site.xml` * hive: `hive-site.xml` * mapred: `mapred-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf` * yarn: `yarn-site.xml` For more information, see (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
         */
        properties?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobSparkJobLoggingConfig {
        /**
         * The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
         */
        driverLogLevels?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobSparkRJob {
        /**
         * Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
         */
        archiveUris?: string[];
        /**
         * Optional. The arguments to pass to the driver. Do not include arguments, such as `--conf`, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
         */
        args?: string[];
        /**
         * Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
         */
        fileUris?: string[];
        /**
         * Optional. The runtime log config for job execution.
         */
        loggingConfig?: outputs.dataproc.WorkflowTemplateJobSparkRJobLoggingConfig;
        /**
         * Required. The HCFS URI of the main R file to use as the driver. Must be a .R file.
         */
        mainRFileUri: string;
        /**
         * Optional. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. The following are supported prefixes and their mappings: * capacity-scheduler: `capacity-scheduler.xml` * core: `core-site.xml` * distcp: `distcp-default.xml` * hdfs: `hdfs-site.xml` * hive: `hive-site.xml` * mapred: `mapred-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf` * yarn: `yarn-site.xml` For more information, see (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
         */
        properties?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobSparkRJobLoggingConfig {
        /**
         * The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
         */
        driverLogLevels?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobSparkSqlJob {
        /**
         * Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
         */
        jarFileUris?: string[];
        /**
         * Optional. The runtime log config for job execution.
         */
        loggingConfig?: outputs.dataproc.WorkflowTemplateJobSparkSqlJobLoggingConfig;
        /**
         * Optional. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. The following are supported prefixes and their mappings: * capacity-scheduler: `capacity-scheduler.xml` * core: `core-site.xml` * distcp: `distcp-default.xml` * hdfs: `hdfs-site.xml` * hive: `hive-site.xml` * mapred: `mapred-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf` * yarn: `yarn-site.xml` For more information, see (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
         */
        properties?: {[key: string]: string};
        /**
         * The HCFS URI of the script that contains SQL queries.
         */
        queryFileUri?: string;
        /**
         * A list of queries.
         */
        queryList?: outputs.dataproc.WorkflowTemplateJobSparkSqlJobQueryList;
        /**
         * Optional. Mapping of query variable names to values (equivalent to the Spark SQL command: SET `name="value";`).
         */
        scriptVariables?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobSparkSqlJobLoggingConfig {
        /**
         * The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
         */
        driverLogLevels?: {[key: string]: string};
    }

    export interface WorkflowTemplateJobSparkSqlJobQueryList {
        /**
         * Required. The queries to execute. You do not need to end a query expression with a semicolon. Multiple queries can be specified in one string by separating each with a semicolon. Here is an example of a Dataproc API snippet that uses a QueryList to specify a HiveJob: "hiveJob": { "queryList": { "queries": } }
         */
        queries: string[];
    }

    export interface WorkflowTemplateParameter {
        /**
         * Optional. Brief description of the parameter. Must not exceed 1024 characters.
         */
        description?: string;
        /**
         * Required. Paths to all fields that the parameter replaces. A field is allowed to appear in at most one parameter's list of field paths. A field path is similar in syntax to a .sparkJob.args
         */
        fields: string[];
        /**
         * Required. Parameter name. The parameter name is used as the key, and paired with the parameter value, which are passed to the template when the template is instantiated. The name must contain only capital letters (A-Z), numbers (0-9), and underscores (_), and must not start with a number. The maximum length is 40 characters.
         */
        name: string;
        /**
         * Optional. Validation rules to be applied to this parameter's value.
         */
        validation?: outputs.dataproc.WorkflowTemplateParameterValidation;
    }

    export interface WorkflowTemplateParameterValidation {
        /**
         * Validation based on regular expressions.
         */
        regex?: outputs.dataproc.WorkflowTemplateParameterValidationRegex;
        /**
         * Optional. Corresponds to the label values of reservation resource.
         */
        values?: outputs.dataproc.WorkflowTemplateParameterValidationValues;
    }

    export interface WorkflowTemplateParameterValidationRegex {
        /**
         * Required. RE2 regular expressions used to validate the parameter's value. The value must match the regex in its entirety (substring matches are not sufficient).
         */
        regexes: string[];
    }

    export interface WorkflowTemplateParameterValidationValues {
        /**
         * Optional. Corresponds to the label values of reservation resource.
         */
        values: string[];
    }

    export interface WorkflowTemplatePlacement {
        /**
         * Optional. A selector that chooses target cluster for jobs based on metadata. The selector is evaluated at the time each job is submitted.
         */
        clusterSelector?: outputs.dataproc.WorkflowTemplatePlacementClusterSelector;
        /**
         * A cluster that is managed by the workflow.
         */
        managedCluster?: outputs.dataproc.WorkflowTemplatePlacementManagedCluster;
    }

    export interface WorkflowTemplatePlacementClusterSelector {
        /**
         * Required. The cluster labels. Cluster must have all labels to match.
         */
        clusterLabels: {[key: string]: string};
        /**
         * Optional. The zone where the Compute Engine cluster will be located. On a create request, it is required in the "global" region. If omitted in a non-global Dataproc region, the service will pick a zone in the corresponding Compute Engine region. On a get request, zone will always be present. A full URL, partial URI, or short name are valid. Examples: * `https://www.googleapis.com/compute/v1/projects/` * `us-central1-f`
         */
        zone: string;
    }

    export interface WorkflowTemplatePlacementManagedCluster {
        /**
         * Required. The cluster name prefix. A unique cluster name will be formed by appending a random suffix. The name must contain only lower-case letters (a-z), numbers (0-9), and hyphens (-). Must begin with a letter. Cannot begin or end with hyphen. Must consist of between 2 and 35 characters.
         */
        clusterName: string;
        /**
         * Required. The cluster configuration.
         */
        config: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfig;
        /**
         * Optional. The labels to associate with this cluster. Label keys must be between 1 and 63 characters long, and must conform to the following PCRE regular expression: {0,63} No more than 32 labels can be associated with a given cluster.
         */
        labels?: {[key: string]: string};
    }

    export interface WorkflowTemplatePlacementManagedClusterConfig {
        /**
         * Optional. Autoscaling config for the policy associated with the cluster. Cluster does not autoscale if this field is unset.
         */
        autoscalingConfig?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigAutoscalingConfig;
        /**
         * Optional. Encryption settings for the cluster.
         */
        encryptionConfig?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigEncryptionConfig;
        /**
         * Optional. Port/endpoint configuration for this cluster
         */
        endpointConfig?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigEndpointConfig;
        /**
         * Optional. The shared Compute Engine config settings for all instances in a cluster.
         */
        gceClusterConfig?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigGceClusterConfig;
        /**
         * Optional. The Kubernetes Engine config for Dataproc clusters deployed to Kubernetes. Setting this is considered mutually exclusive with Compute Engine-based options such as `gceClusterConfig`, `masterConfig`, `workerConfig`, `secondaryWorkerConfig`, and `autoscalingConfig`.
         */
        gkeClusterConfig?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfig;
        /**
         * Optional. Commands to execute on each node after config is completed. By default, executables are run on master and all worker nodes. You can test a node's `role` metadata to run an executable on a master or worker node, as shown below using `curl` (you can also use `wget`): ROLE=$(curl -H Metadata-Flavor:Google http://metadata/computeMetadata/v1/instance/attributes/dataproc-role) if ; then ... master specific actions ... else ... worker specific actions ... fi
         */
        initializationActions?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigInitializationAction[];
        /**
         * Optional. Lifecycle setting for the cluster.
         */
        lifecycleConfig?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigLifecycleConfig;
        /**
         * Optional. The Compute Engine config settings for additional worker instances in a cluster.
         */
        masterConfig: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigMasterConfig;
        /**
         * Optional. Metastore configuration.
         */
        metastoreConfig?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigMetastoreConfig;
        /**
         * Optional. The Compute Engine config settings for additional worker instances in a cluster.
         */
        secondaryWorkerConfig: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfig;
        /**
         * Optional. Security settings for the cluster.
         */
        securityConfig?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigSecurityConfig;
        /**
         * Optional. The config settings for software inside the cluster.
         */
        softwareConfig?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigSoftwareConfig;
        /**
         * Optional. A Cloud Storage bucket used to stage job dependencies, config files, and job driver console output. If you do not specify a staging bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's staging bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket (see (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)).
         */
        stagingBucket?: string;
        /**
         * Optional. A Cloud Storage bucket used to store ephemeral cluster and jobs data, such as Spark and MapReduce history files. If you do not specify a temp bucket, Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's temp bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket. The default bucket has a TTL of 90 days, but you can use any TTL (or none) if you specify a bucket.
         */
        tempBucket?: string;
        /**
         * Optional. The Compute Engine config settings for additional worker instances in a cluster.
         */
        workerConfig: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigWorkerConfig;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigAutoscalingConfig {
        /**
         * Optional. The autoscaling policy used by the cluster. Only resource names including projectid and location (region) are valid. Examples: * `https://www.googleapis.com/compute/v1/projects/` Note that the policy must be in the same project and Dataproc region.
         */
        policy?: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigEncryptionConfig {
        /**
         * Optional. The Cloud KMS key name to use for PD disk encryption for all instances in the cluster.
         */
        gcePdKmsKeyName?: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigEndpointConfig {
        /**
         * Optional. If true, enable http access to specific ports on the cluster from external sources. Defaults to false.
         */
        enableHttpPortAccess?: boolean;
        /**
         * -
         * Output only. The map of port descriptions to URLs. Will only be populated if enableHttpPortAccess is true.
         */
        httpPorts: {[key: string]: string};
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigGceClusterConfig {
        /**
         * Optional. If true, all instances in the cluster will only have internal IP addresses. By default, clusters are not restricted to internal IP addresses, and will have ephemeral external IP addresses assigned to each instance. This `internalIpOnly` restriction can only be enabled for subnetwork enabled networks, and all off-cluster dependencies must be configured to be accessible without external IP addresses.
         */
        internalIpOnly: boolean;
        /**
         * The Compute Engine metadata entries to add to all instances (see (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
         */
        metadata?: {[key: string]: string};
        /**
         * Optional. The Compute Engine network to be used for machine communications. Cannot be specified with subnetwork_uri. If neither `networkUri` nor `subnetworkUri` is specified, the "default" network of the project is used, if it exists. Cannot be a "Custom Subnet Network" (see /regions/global/default` * `default`
         */
        network?: string;
        /**
         * Optional. Node Group Affinity for sole-tenant clusters.
         */
        nodeGroupAffinity?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigNodeGroupAffinity;
        /**
         * Optional. The type of IPv6 access for a cluster. Possible values: PRIVATE_IPV6_GOOGLE_ACCESS_UNSPECIFIED, INHERIT_FROM_SUBNETWORK, OUTBOUND, BIDIRECTIONAL
         */
        privateIpv6GoogleAccess?: string;
        /**
         * Optional. Reservation Affinity for consuming Zonal reservation.
         */
        reservationAffinity?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigReservationAffinity;
        /**
         * Optional. The (https://cloud.google.com/compute/docs/access/service-accounts#default_service_account) is used.
         */
        serviceAccount?: string;
        /**
         * Optional. The URIs of service account scopes to be included in Compute Engine instances. The following base set of scopes is always included: * https://www.googleapis.com/auth/cloud.useraccounts.readonly * https://www.googleapis.com/auth/devstorage.read_write * https://www.googleapis.com/auth/logging.write If no scopes are specified, the following defaults are also provided: * https://www.googleapis.com/auth/bigquery * https://www.googleapis.com/auth/bigtable.admin.table * https://www.googleapis.com/auth/bigtable.data * https://www.googleapis.com/auth/devstorage.full_control
         */
        serviceAccountScopes?: string[];
        /**
         * Optional. The Compute Engine subnetwork to be used for machine communications. Cannot be specified with network_uri. A full URL, partial URI, or short name are valid. Examples: * `https://www.googleapis.com/compute/v1/projects//regions/us-east1/subnetworks/sub0` * `sub0`
         */
        subnetwork?: string;
        /**
         * The Compute Engine tags to add to all instances (see (https://cloud.google.com/compute/docs/label-or-tag-resources#tags)).
         */
        tags?: string[];
        /**
         * Optional. The zone where the Compute Engine cluster will be located. On a create request, it is required in the "global" region. If omitted in a non-global Dataproc region, the service will pick a zone in the corresponding Compute Engine region. On a get request, zone will always be present. A full URL, partial URI, or short name are valid. Examples: * `https://www.googleapis.com/compute/v1/projects/` * `us-central1-f`
         */
        zone: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigNodeGroupAffinity {
        /**
         * Required. The URI of a sole-tenant /zones/us-central1-a/nodeGroups/node-group-1` * `node-group-1`
         */
        nodeGroup: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigReservationAffinity {
        /**
         * Optional. Type of reservation to consume Possible values: TYPE_UNSPECIFIED, NO_RESERVATION, ANY_RESERVATION, SPECIFIC_RESERVATION
         */
        consumeReservationType?: string;
        /**
         * Optional. Corresponds to the label key of reservation resource.
         */
        key?: string;
        /**
         * Optional. Corresponds to the label values of reservation resource.
         */
        values?: string[];
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfig {
        /**
         * Optional. A target for the deployment.
         */
        namespacedGkeDeploymentTarget?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfigNamespacedGkeDeploymentTarget;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfigNamespacedGkeDeploymentTarget {
        /**
         * Optional. A namespace within the GKE cluster to deploy into.
         */
        clusterNamespace?: string;
        /**
         * Optional. The target GKE cluster to deploy to. Format: 'projects/{project}/locations/{location}/clusters/{cluster_id}'
         */
        targetGkeCluster?: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigInitializationAction {
        /**
         * Required. Cloud Storage URI of executable file.
         */
        executableFile?: string;
        /**
         * Optional. Amount of time executable has to complete. Default is 10 minutes (see JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json)). Cluster creation fails with an explanatory error message (the name of the executable that caused the error and the exceeded timeout period) if the executable is not completed at end of the timeout period.
         */
        executionTimeout?: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigLifecycleConfig {
        /**
         * Optional. The time when cluster will be auto-deleted (see JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
         */
        autoDeleteTime?: string;
        /**
         * Optional. The lifetime duration of cluster. The cluster will be auto-deleted at the end of this period. Minimum value is 10 minutes; maximum value is 14 days (see JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
         */
        autoDeleteTtl?: string;
        /**
         * Optional. The duration to keep the cluster alive while idling (when no jobs are running). Passing this threshold will cause the cluster to be deleted. Minimum value is 5 minutes; maximum value is 14 days (see JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json).
         */
        idleDeleteTtl?: string;
        /**
         * -
         * Output only. The time when cluster became idle (most recent job finished) and became eligible for deletion due to idleness (see JSON representation of (https://developers.google.com/protocol-buffers/docs/proto3#json)).
         */
        idleStartTime: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigMasterConfig {
        /**
         * Optional. The Compute Engine accelerator configuration for these instances.
         */
        accelerators: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigMasterConfigAccelerator[];
        /**
         * Optional. Disk option config settings.
         */
        diskConfig: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfig;
        /**
         * Optional. The Compute Engine image resource used for cluster instances. The URI can represent an image or image family. Image examples: * `https://www.googleapis.com/compute/beta/projects/` If the URI is unspecified, it will be inferred from `SoftwareConfig.image_version` or the system default.
         */
        image?: string;
        /**
         * -
         * Output only. The list of instance names. Dataproc derives the names from `clusterName`, `numInstances`, and the instance group.
         */
        instanceNames: string[];
        /**
         * -
         * Output only. Specifies that this instance group contains preemptible instances.
         */
        isPreemptible: boolean;
        /**
         * Optional. The Compute Engine machine type used for cluster instances. A full URL, partial URI, or short name are valid. Examples: * `https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the machine type resource, for example, `n1-standard-2`.
         */
        machineType?: string;
        /**
         * -
         * Output only. The config for Compute Engine Instance Group Manager that manages this group. This is only used for preemptible instance groups.
         */
        managedGroupConfigs: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigMasterConfigManagedGroupConfig[];
        /**
         * Optional. Specifies the minimum cpu platform for the Instance Group. See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
         */
        minCpuPlatform: string;
        /**
         * Optional. The number of VM instances in the instance group. For master instance groups, must be set to 1.
         */
        numInstances?: number;
        /**
         * Optional. Specifies the preemptibility of the instance group. The default value for master and worker groups is `NON_PREEMPTIBLE`. This default cannot be changed. The default value for secondary instances is `PREEMPTIBLE`. Possible values: PREEMPTIBILITY_UNSPECIFIED, NON_PREEMPTIBLE, PREEMPTIBLE
         */
        preemptibility?: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigMasterConfigAccelerator {
        /**
         * The number of the accelerator cards of this type exposed to this instance.
         */
        acceleratorCount?: number;
        /**
         * Full URL, partial URI, or short name of the accelerator type resource to expose to this instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the accelerator type resource, for example, `nvidia-tesla-k80`.
         */
        acceleratorType?: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfig {
        /**
         * Optional. Size in GB of the boot disk (default is 500GB).
         */
        bootDiskSizeGb?: number;
        /**
         * Optional. Type of the boot disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
         */
        bootDiskType?: string;
        /**
         * Optional. Number of attached SSDs, from 0 to 4 (default is 0). If SSDs are not attached, the boot disk is used to store runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data. If one or more SSDs are attached, this runtime bulk data is spread across them, and the boot disk contains only basic config and installed binaries.
         */
        numLocalSsds: number;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigMasterConfigManagedGroupConfig {
        instanceGroupManagerName: string;
        instanceTemplateName: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigMetastoreConfig {
        /**
         * Required. Resource name of an existing Dataproc Metastore service. Example: * `projects/`
         */
        dataprocMetastoreService: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfig {
        /**
         * Optional. The Compute Engine accelerator configuration for these instances.
         */
        accelerators: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigAccelerator[];
        /**
         * Optional. Disk option config settings.
         */
        diskConfig: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigDiskConfig;
        /**
         * Optional. The Compute Engine image resource used for cluster instances. The URI can represent an image or image family. Image examples: * `https://www.googleapis.com/compute/beta/projects/` If the URI is unspecified, it will be inferred from `SoftwareConfig.image_version` or the system default.
         */
        image?: string;
        /**
         * -
         * Output only. The list of instance names. Dataproc derives the names from `clusterName`, `numInstances`, and the instance group.
         */
        instanceNames: string[];
        /**
         * -
         * Output only. Specifies that this instance group contains preemptible instances.
         */
        isPreemptible: boolean;
        /**
         * Optional. The Compute Engine machine type used for cluster instances. A full URL, partial URI, or short name are valid. Examples: * `https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the machine type resource, for example, `n1-standard-2`.
         */
        machineType?: string;
        /**
         * -
         * Output only. The config for Compute Engine Instance Group Manager that manages this group. This is only used for preemptible instance groups.
         */
        managedGroupConfigs: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigManagedGroupConfig[];
        /**
         * Optional. Specifies the minimum cpu platform for the Instance Group. See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
         */
        minCpuPlatform: string;
        /**
         * Optional. The number of VM instances in the instance group. For master instance groups, must be set to 1.
         */
        numInstances?: number;
        /**
         * Optional. Specifies the preemptibility of the instance group. The default value for master and worker groups is `NON_PREEMPTIBLE`. This default cannot be changed. The default value for secondary instances is `PREEMPTIBLE`. Possible values: PREEMPTIBILITY_UNSPECIFIED, NON_PREEMPTIBLE, PREEMPTIBLE
         */
        preemptibility?: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigAccelerator {
        /**
         * The number of the accelerator cards of this type exposed to this instance.
         */
        acceleratorCount?: number;
        /**
         * Full URL, partial URI, or short name of the accelerator type resource to expose to this instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the accelerator type resource, for example, `nvidia-tesla-k80`.
         */
        acceleratorType?: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigDiskConfig {
        /**
         * Optional. Size in GB of the boot disk (default is 500GB).
         */
        bootDiskSizeGb?: number;
        /**
         * Optional. Type of the boot disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
         */
        bootDiskType?: string;
        /**
         * Optional. Number of attached SSDs, from 0 to 4 (default is 0). If SSDs are not attached, the boot disk is used to store runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data. If one or more SSDs are attached, this runtime bulk data is spread across them, and the boot disk contains only basic config and installed binaries.
         */
        numLocalSsds: number;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigManagedGroupConfig {
        instanceGroupManagerName: string;
        instanceTemplateName: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigSecurityConfig {
        /**
         * Kerberos related configuration.
         */
        kerberosConfig?: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigSecurityConfigKerberosConfig;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigSecurityConfigKerberosConfig {
        /**
         * Optional. The admin server (IP or hostname) for the remote trusted realm in a cross realm trust relationship.
         */
        crossRealmTrustAdminServer?: string;
        /**
         * Optional. The KDC (IP or hostname) for the remote trusted realm in a cross realm trust relationship.
         */
        crossRealmTrustKdc?: string;
        /**
         * Optional. The remote realm the Dataproc on-cluster KDC will trust, should the user enable cross realm trust.
         */
        crossRealmTrustRealm?: string;
        /**
         * Optional. The Cloud Storage URI of a KMS encrypted file containing the shared password between the on-cluster Kerberos realm and the remote trusted realm, in a cross realm trust relationship.
         */
        crossRealmTrustSharedPassword?: string;
        /**
         * Optional. Flag to indicate whether to Kerberize the cluster (default: false). Set this field to true to enable Kerberos on a cluster.
         */
        enableKerberos?: boolean;
        /**
         * Optional. The Cloud Storage URI of a KMS encrypted file containing the master key of the KDC database.
         */
        kdcDbKey?: string;
        /**
         * Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided key. For the self-signed certificate, this password is generated by Dataproc.
         */
        keyPassword?: string;
        /**
         * Optional. The Cloud Storage URI of the keystore file used for SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
         */
        keystore?: string;
        /**
         * Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided keystore. For the self-signed certificate, this password is generated by Dataproc.
         */
        keystorePassword?: string;
        /**
         * Optional. The uri of the KMS key used to encrypt various sensitive files.
         */
        kmsKey?: string;
        /**
         * Optional. The name of the on-cluster Kerberos realm. If not specified, the uppercased domain of hostnames will be the realm.
         */
        realm?: string;
        /**
         * Optional. The Cloud Storage URI of a KMS encrypted file containing the root principal password.
         */
        rootPrincipalPassword?: string;
        /**
         * Optional. The lifetime of the ticket granting ticket, in hours. If not specified, or user specifies 0, then default value 10 will be used.
         */
        tgtLifetimeHours?: number;
        /**
         * Optional. The Cloud Storage URI of the truststore file used for SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
         */
        truststore?: string;
        /**
         * Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided truststore. For the self-signed certificate, this password is generated by Dataproc.
         */
        truststorePassword?: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigSoftwareConfig {
        /**
         * Optional. The version of software inside the cluster. It must be one of the supported (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#other_versions). If unspecified, it defaults to the latest Debian version.
         */
        imageVersion?: string;
        optionalComponents?: string[];
        /**
         * Optional. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. The following are supported prefixes and their mappings: * capacity-scheduler: `capacity-scheduler.xml` * core: `core-site.xml` * distcp: `distcp-default.xml` * hdfs: `hdfs-site.xml` * hive: `hive-site.xml` * mapred: `mapred-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf` * yarn: `yarn-site.xml` For more information, see (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
         */
        properties?: {[key: string]: string};
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigWorkerConfig {
        /**
         * Optional. The Compute Engine accelerator configuration for these instances.
         */
        accelerators: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigWorkerConfigAccelerator[];
        /**
         * Optional. Disk option config settings.
         */
        diskConfig: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfig;
        /**
         * Optional. The Compute Engine image resource used for cluster instances. The URI can represent an image or image family. Image examples: * `https://www.googleapis.com/compute/beta/projects/` If the URI is unspecified, it will be inferred from `SoftwareConfig.image_version` or the system default.
         */
        image?: string;
        /**
         * -
         * Output only. The list of instance names. Dataproc derives the names from `clusterName`, `numInstances`, and the instance group.
         */
        instanceNames: string[];
        /**
         * -
         * Output only. Specifies that this instance group contains preemptible instances.
         */
        isPreemptible: boolean;
        /**
         * Optional. The Compute Engine machine type used for cluster instances. A full URL, partial URI, or short name are valid. Examples: * `https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the machine type resource, for example, `n1-standard-2`.
         */
        machineType?: string;
        /**
         * -
         * Output only. The config for Compute Engine Instance Group Manager that manages this group. This is only used for preemptible instance groups.
         */
        managedGroupConfigs: outputs.dataproc.WorkflowTemplatePlacementManagedClusterConfigWorkerConfigManagedGroupConfig[];
        /**
         * Optional. Specifies the minimum cpu platform for the Instance Group. See (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
         */
        minCpuPlatform: string;
        /**
         * Optional. The number of VM instances in the instance group. For master instance groups, must be set to 1.
         */
        numInstances?: number;
        /**
         * Optional. Specifies the preemptibility of the instance group. The default value for master and worker groups is `NON_PREEMPTIBLE`. This default cannot be changed. The default value for secondary instances is `PREEMPTIBLE`. Possible values: PREEMPTIBILITY_UNSPECIFIED, NON_PREEMPTIBLE, PREEMPTIBLE
         */
        preemptibility?: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigWorkerConfigAccelerator {
        /**
         * The number of the accelerator cards of this type exposed to this instance.
         */
        acceleratorCount?: number;
        /**
         * Full URL, partial URI, or short name of the accelerator type resource to expose to this instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the accelerator type resource, for example, `nvidia-tesla-k80`.
         */
        acceleratorType?: string;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfig {
        /**
         * Optional. Size in GB of the boot disk (default is 500GB).
         */
        bootDiskSizeGb?: number;
        /**
         * Optional. Type of the boot disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
         */
        bootDiskType?: string;
        /**
         * Optional. Number of attached SSDs, from 0 to 4 (default is 0). If SSDs are not attached, the boot disk is used to store runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data. If one or more SSDs are attached, this runtime bulk data is spread across them, and the boot disk contains only basic config and installed binaries.
         */
        numLocalSsds: number;
    }

    export interface WorkflowTemplatePlacementManagedClusterConfigWorkerConfigManagedGroupConfig {
        instanceGroupManagerName: string;
        instanceTemplateName: string;
    }

}

export namespace datastore {
    export interface DataStoreIndexProperty {
        /**
         * The direction the index should optimize for sorting.
         * Possible values are `ASCENDING` and `DESCENDING`.
         */
        direction: string;
        /**
         * The property name to index.
         */
        name: string;
    }

}

export namespace deploymentmanager {
    export interface DeploymentLabel {
        /**
         * Key for label.
         */
        key?: string;
        /**
         * Value of label.
         */
        value?: string;
    }

    export interface DeploymentTarget {
        /**
         * The root configuration file to use for this deployment.
         * Structure is documented below.
         */
        config: outputs.deploymentmanager.DeploymentTargetConfig;
        /**
         * Specifies import files for this configuration. This can be
         * used to import templates or other files. For example, you might
         * import a text file in order to use the file in a template.
         * Structure is documented below.
         */
        imports?: outputs.deploymentmanager.DeploymentTargetImport[];
    }

    export interface DeploymentTargetConfig {
        /**
         * The full contents of the template that you want to import.
         */
        content: string;
    }

    export interface DeploymentTargetImport {
        /**
         * The full contents of the template that you want to import.
         */
        content?: string;
        /**
         * The name of the template to import, as declared in the YAML
         * configuration.
         */
        name?: string;
    }

}

export namespace diagflow {
    export interface CxAgentSpeechToTextSettings {
        /**
         * Whether to use speech adaptation for speech recognition.
         */
        enableSpeechAdaptation?: boolean;
    }

    export interface CxEntityTypeEntity {
        /**
         * A collection of value synonyms. For example, if the entity type is vegetable, and value is scallions, a synonym could be green onions.
         * For KIND_LIST entity types: This collection must contain exactly one synonym equal to value.
         */
        synonyms?: string[];
        /**
         * The word or phrase to be excluded.
         */
        value?: string;
    }

    export interface CxEntityTypeExcludedPhrase {
        /**
         * The word or phrase to be excluded.
         */
        value?: string;
    }

    export interface CxEnvironmentVersionConfig {
        /**
         * Format: projects/{{project}}/locations/{{location}}/agents/{{agent}}/flows/{{flow}}/versions/{{version}}.
         */
        version: string;
    }

    export interface CxFlowEventHandler {
        /**
         * The name of the event to handle.
         */
        event?: string;
        /**
         * -
         * The unique identifier of this event handler.
         */
        name: string;
        /**
         * The target flow to transition to.
         * Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>.
         */
        targetFlow?: string;
        /**
         * The target page to transition to.
         * Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>/pages/<Page ID>.
         */
        targetPage?: string;
        /**
         * The fulfillment to call when the event occurs. Handling webhook errors with a fulfillment enabled with webhook could cause infinite loop. It is invalid to specify such fulfillment for a handler handling webhooks.
         * Structure is documented below.
         */
        triggerFulfillment?: outputs.diagflow.CxFlowEventHandlerTriggerFulfillment;
    }

    export interface CxFlowEventHandlerTriggerFulfillment {
        /**
         * The list of rich message responses to present to the user.
         * Structure is documented below.
         */
        messages?: outputs.diagflow.CxFlowEventHandlerTriggerFulfillmentMessage[];
        /**
         * Whether Dialogflow should return currently queued fulfillment response messages in streaming APIs. If a webhook is specified, it happens before Dialogflow invokes webhook. Warning: 1) This flag only affects streaming API. Responses are still queued and returned once in non-streaming API. 2) The flag can be enabled in any fulfillment but only the first 3 partial responses will be returned. You may only want to apply it to fulfillments that have slow webhooks.
         */
        returnPartialResponses?: boolean;
        /**
         * The tag used by the webhook to identify which fulfillment is being called. This field is required if webhook is specified.
         */
        tag?: string;
        /**
         * The webhook to call. Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/webhooks/<Webhook ID>.
         */
        webhook?: string;
    }

    export interface CxFlowEventHandlerTriggerFulfillmentMessage {
        /**
         * A collection of text responses.
         */
        text?: outputs.diagflow.CxFlowEventHandlerTriggerFulfillmentMessageText;
    }

    export interface CxFlowEventHandlerTriggerFulfillmentMessageText {
        /**
         * -
         * Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.
         */
        allowPlaybackInterruption: boolean;
        /**
         * A collection of text responses.
         */
        texts?: string[];
    }

    export interface CxFlowNluSettings {
        /**
         * To filter out false positive results and still get variety in matched natural language inputs for your agent, you can tune the machine learning classification threshold.
         * If the returned score value is less than the threshold value, then a no-match event will be triggered. The score values range from 0.0 (completely uncertain) to 1.0 (completely certain). If set to 0.0, the default of 0.3 is used.
         */
        classificationThreshold?: number;
        /**
         * Indicates NLU model training mode.
         * * MODEL_TRAINING_MODE_AUTOMATIC: NLU model training is automatically triggered when a flow gets modified. User can also manually trigger model training in this mode.
         * * MODEL_TRAINING_MODE_MANUAL: User needs to manually trigger NLU model training. Best for large flows whose models take long time to train.
         * Possible values are `MODEL_TRAINING_MODE_AUTOMATIC` and `MODEL_TRAINING_MODE_MANUAL`.
         */
        modelTrainingMode?: string;
        /**
         * Indicates the type of NLU model.
         * * MODEL_TYPE_STANDARD: Use standard NLU model.
         * * MODEL_TYPE_ADVANCED: Use advanced NLU model.
         * Possible values are `MODEL_TYPE_STANDARD` and `MODEL_TYPE_ADVANCED`.
         */
        modelType?: string;
    }

    export interface CxFlowTransitionRoute {
        /**
         * The condition to evaluate against form parameters or session parameters.
         * At least one of intent or condition must be specified. When both intent and condition are specified, the transition can only happen when both are fulfilled.
         */
        condition?: string;
        /**
         * The unique identifier of an Intent.
         * Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/intents/<Intent ID>. Indicates that the transition can only happen when the given intent is matched. At least one of intent or condition must be specified. When both intent and condition are specified, the transition can only happen when both are fulfilled.
         */
        intent?: string;
        /**
         * -
         * The unique identifier of this event handler.
         */
        name: string;
        /**
         * The target flow to transition to.
         * Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>.
         */
        targetFlow?: string;
        /**
         * The target page to transition to.
         * Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>/pages/<Page ID>.
         */
        targetPage?: string;
        /**
         * The fulfillment to call when the event occurs. Handling webhook errors with a fulfillment enabled with webhook could cause infinite loop. It is invalid to specify such fulfillment for a handler handling webhooks.
         * Structure is documented below.
         */
        triggerFulfillment?: outputs.diagflow.CxFlowTransitionRouteTriggerFulfillment;
    }

    export interface CxFlowTransitionRouteTriggerFulfillment {
        /**
         * The list of rich message responses to present to the user.
         * Structure is documented below.
         */
        messages?: outputs.diagflow.CxFlowTransitionRouteTriggerFulfillmentMessage[];
        /**
         * Whether Dialogflow should return currently queued fulfillment response messages in streaming APIs. If a webhook is specified, it happens before Dialogflow invokes webhook. Warning: 1) This flag only affects streaming API. Responses are still queued and returned once in non-streaming API. 2) The flag can be enabled in any fulfillment but only the first 3 partial responses will be returned. You may only want to apply it to fulfillments that have slow webhooks.
         */
        returnPartialResponses?: boolean;
        /**
         * The tag used by the webhook to identify which fulfillment is being called. This field is required if webhook is specified.
         */
        tag?: string;
        /**
         * The webhook to call. Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/webhooks/<Webhook ID>.
         */
        webhook?: string;
    }

    export interface CxFlowTransitionRouteTriggerFulfillmentMessage {
        /**
         * A collection of text responses.
         */
        text?: outputs.diagflow.CxFlowTransitionRouteTriggerFulfillmentMessageText;
    }

    export interface CxFlowTransitionRouteTriggerFulfillmentMessageText {
        /**
         * -
         * Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.
         */
        allowPlaybackInterruption: boolean;
        /**
         * A collection of text responses.
         */
        texts?: string[];
    }

    export interface CxIntentParameter {
        /**
         * The entity type of the parameter.
         * Format: projects/-/locations/-/agents/-/entityTypes/<System Entity Type ID> for system entity types (for example, projects/-/locations/-/agents/-/entityTypes/sys.date), or projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/entityTypes/<Entity Type ID> for developer entity types.
         */
        entityType: string;
        /**
         * The unique identifier of the parameter. This field is used by training phrases to annotate their parts.
         */
        id: string;
        /**
         * Indicates whether the parameter represents a list of values.
         */
        isList?: boolean;
        /**
         * Indicates whether the parameter content should be redacted in log. If redaction is enabled, the parameter content will be replaced by parameter name during logging.
         * Note: the parameter content is subject to redaction if either parameter level redaction or entity type level redaction is enabled.
         */
        redact?: boolean;
    }

    export interface CxIntentTrainingPhrase {
        /**
         * The unique identifier of the parameter. This field is used by training phrases to annotate their parts.
         */
        id: string;
        /**
         * The ordered list of training phrase parts. The parts are concatenated in order to form the training phrase.
         * Note: The API does not automatically annotate training phrases like the Dialogflow Console does.
         * Note: Do not forget to include whitespace at part boundaries, so the training phrase is well formatted when the parts are concatenated.
         * If the training phrase does not need to be annotated with parameters, you just need a single part with only the Part.text field set.
         * If you want to annotate the training phrase, you must create multiple parts, where the fields of each part are populated in one of two ways:
         * Part.text is set to a part of the phrase that has no parameters.
         * Part.text is set to a part of the phrase that you want to annotate, and the parameterId field is set.
         * Structure is documented below.
         */
        parts: outputs.diagflow.CxIntentTrainingPhrasePart[];
        /**
         * Indicates how many times this example was added to the intent.
         */
        repeatCount?: number;
    }

    export interface CxIntentTrainingPhrasePart {
        /**
         * The parameter used to annotate this part of the training phrase. This field is required for annotated parts of the training phrase.
         */
        parameterId?: string;
        /**
         * The text for this part.
         */
        text: string;
    }

    export interface CxPageEntryFulfillment {
        /**
         * The list of rich message responses to present to the user.
         * Structure is documented below.
         */
        messages?: outputs.diagflow.CxPageEntryFulfillmentMessage[];
        /**
         * Whether Dialogflow should return currently queued fulfillment response messages in streaming APIs. If a webhook is specified, it happens before Dialogflow invokes webhook. Warning: 1) This flag only affects streaming API. Responses are still queued and returned once in non-streaming API. 2) The flag can be enabled in any fulfillment but only the first 3 partial responses will be returned. You may only want to apply it to fulfillments that have slow webhooks.
         */
        returnPartialResponses?: boolean;
        /**
         * The tag used by the webhook to identify which fulfillment is being called. This field is required if webhook is specified.
         */
        tag?: string;
        /**
         * The webhook to call. Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/webhooks/<Webhook ID>.
         */
        webhook?: string;
    }

    export interface CxPageEntryFulfillmentMessage {
        /**
         * A collection of text responses.
         */
        text?: outputs.diagflow.CxPageEntryFulfillmentMessageText;
    }

    export interface CxPageEntryFulfillmentMessageText {
        /**
         * -
         * Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.
         */
        allowPlaybackInterruption: boolean;
        /**
         * A collection of text responses.
         */
        texts?: string[];
    }

    export interface CxPageEventHandler {
        /**
         * The name of the event to handle.
         */
        event?: string;
        /**
         * -
         * The unique identifier of this event handler.
         */
        name: string;
        /**
         * The target flow to transition to.
         * Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>.
         */
        targetFlow?: string;
        /**
         * The target page to transition to.
         * Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>/pages/<Page ID>.
         */
        targetPage?: string;
        /**
         * The fulfillment to call when the event occurs. Handling webhook errors with a fulfillment enabled with webhook could cause infinite loop. It is invalid to specify such fulfillment for a handler handling webhooks.
         * Structure is documented below.
         */
        triggerFulfillment?: outputs.diagflow.CxPageEventHandlerTriggerFulfillment;
    }

    export interface CxPageEventHandlerTriggerFulfillment {
        /**
         * The list of rich message responses to present to the user.
         * Structure is documented below.
         */
        messages?: outputs.diagflow.CxPageEventHandlerTriggerFulfillmentMessage[];
        /**
         * Whether Dialogflow should return currently queued fulfillment response messages in streaming APIs. If a webhook is specified, it happens before Dialogflow invokes webhook. Warning: 1) This flag only affects streaming API. Responses are still queued and returned once in non-streaming API. 2) The flag can be enabled in any fulfillment but only the first 3 partial responses will be returned. You may only want to apply it to fulfillments that have slow webhooks.
         */
        returnPartialResponses?: boolean;
        /**
         * The tag used by the webhook to identify which fulfillment is being called. This field is required if webhook is specified.
         */
        tag?: string;
        /**
         * The webhook to call. Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/webhooks/<Webhook ID>.
         */
        webhook?: string;
    }

    export interface CxPageEventHandlerTriggerFulfillmentMessage {
        /**
         * A collection of text responses.
         */
        text?: outputs.diagflow.CxPageEventHandlerTriggerFulfillmentMessageText;
    }

    export interface CxPageEventHandlerTriggerFulfillmentMessageText {
        /**
         * -
         * Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.
         */
        allowPlaybackInterruption: boolean;
        /**
         * A collection of text responses.
         */
        texts?: string[];
    }

    export interface CxPageForm {
        /**
         * Parameters to collect from the user.
         * Structure is documented below.
         */
        parameters?: outputs.diagflow.CxPageFormParameter[];
    }

    export interface CxPageFormParameter {
        /**
         * The human-readable name of the parameter, unique within the form.
         */
        displayName?: string;
        /**
         * The entity type of the parameter.
         * Format: projects/-/locations/-/agents/-/entityTypes/<System Entity Type ID> for system entity types (for example, projects/-/locations/-/agents/-/entityTypes/sys.date), or projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/entityTypes/<Entity Type ID> for developer entity types.
         */
        entityType?: string;
        /**
         * Defines fill behavior for the parameter.
         * Structure is documented below.
         */
        fillBehavior?: outputs.diagflow.CxPageFormParameterFillBehavior;
        /**
         * Indicates whether the parameter represents a list of values.
         */
        isList?: boolean;
        /**
         * Indicates whether the parameter content should be redacted in log.
         * If redaction is enabled, the parameter content will be replaced by parameter name during logging. Note: the parameter content is subject to redaction if either parameter level redaction or entity type level redaction is enabled.
         */
        redact?: boolean;
        /**
         * Indicates whether the parameter is required. Optional parameters will not trigger prompts; however, they are filled if the user specifies them.
         * Required parameters must be filled before form filling concludes.
         */
        required?: boolean;
    }

    export interface CxPageFormParameterFillBehavior {
        /**
         * The fulfillment to provide the initial prompt that the agent can present to the user in order to fill the parameter.
         * Structure is documented below.
         */
        initialPromptFulfillment?: outputs.diagflow.CxPageFormParameterFillBehaviorInitialPromptFulfillment;
    }

    export interface CxPageFormParameterFillBehaviorInitialPromptFulfillment {
        /**
         * The list of rich message responses to present to the user.
         * Structure is documented below.
         */
        messages?: outputs.diagflow.CxPageFormParameterFillBehaviorInitialPromptFulfillmentMessage[];
        /**
         * Whether Dialogflow should return currently queued fulfillment response messages in streaming APIs. If a webhook is specified, it happens before Dialogflow invokes webhook. Warning: 1) This flag only affects streaming API. Responses are still queued and returned once in non-streaming API. 2) The flag can be enabled in any fulfillment but only the first 3 partial responses will be returned. You may only want to apply it to fulfillments that have slow webhooks.
         */
        returnPartialResponses?: boolean;
        /**
         * The tag used by the webhook to identify which fulfillment is being called. This field is required if webhook is specified.
         */
        tag?: string;
        /**
         * The webhook to call. Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/webhooks/<Webhook ID>.
         */
        webhook?: string;
    }

    export interface CxPageFormParameterFillBehaviorInitialPromptFulfillmentMessage {
        /**
         * A collection of text responses.
         */
        text?: outputs.diagflow.CxPageFormParameterFillBehaviorInitialPromptFulfillmentMessageText;
    }

    export interface CxPageFormParameterFillBehaviorInitialPromptFulfillmentMessageText {
        /**
         * -
         * Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.
         */
        allowPlaybackInterruption: boolean;
        /**
         * A collection of text responses.
         */
        texts?: string[];
    }

    export interface CxPageTransitionRoute {
        /**
         * The condition to evaluate against form parameters or session parameters.
         * At least one of intent or condition must be specified. When both intent and condition are specified, the transition can only happen when both are fulfilled.
         */
        condition?: string;
        /**
         * The unique identifier of an Intent.
         * Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/intents/<Intent ID>. Indicates that the transition can only happen when the given intent is matched. At least one of intent or condition must be specified. When both intent and condition are specified, the transition can only happen when both are fulfilled.
         */
        intent?: string;
        /**
         * -
         * The unique identifier of this event handler.
         */
        name: string;
        /**
         * The target flow to transition to.
         * Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>.
         */
        targetFlow?: string;
        /**
         * The target page to transition to.
         * Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>/pages/<Page ID>.
         */
        targetPage?: string;
        /**
         * The fulfillment to call when the event occurs. Handling webhook errors with a fulfillment enabled with webhook could cause infinite loop. It is invalid to specify such fulfillment for a handler handling webhooks.
         * Structure is documented below.
         */
        triggerFulfillment?: outputs.diagflow.CxPageTransitionRouteTriggerFulfillment;
    }

    export interface CxPageTransitionRouteTriggerFulfillment {
        /**
         * The list of rich message responses to present to the user.
         * Structure is documented below.
         */
        messages?: outputs.diagflow.CxPageTransitionRouteTriggerFulfillmentMessage[];
        /**
         * Whether Dialogflow should return currently queued fulfillment response messages in streaming APIs. If a webhook is specified, it happens before Dialogflow invokes webhook. Warning: 1) This flag only affects streaming API. Responses are still queued and returned once in non-streaming API. 2) The flag can be enabled in any fulfillment but only the first 3 partial responses will be returned. You may only want to apply it to fulfillments that have slow webhooks.
         */
        returnPartialResponses?: boolean;
        /**
         * The tag used by the webhook to identify which fulfillment is being called. This field is required if webhook is specified.
         */
        tag?: string;
        /**
         * The webhook to call. Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/webhooks/<Webhook ID>.
         */
        webhook?: string;
    }

    export interface CxPageTransitionRouteTriggerFulfillmentMessage {
        /**
         * A collection of text responses.
         */
        text?: outputs.diagflow.CxPageTransitionRouteTriggerFulfillmentMessageText;
    }

    export interface CxPageTransitionRouteTriggerFulfillmentMessageText {
        /**
         * -
         * Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.
         */
        allowPlaybackInterruption: boolean;
        /**
         * A collection of text responses.
         */
        texts?: string[];
    }

    export interface CxVersionNluSetting {
        classificationThreshold?: number;
        modelTrainingMode?: string;
        modelType?: string;
    }

    export interface EntityTypeEntity {
        /**
         * A collection of value synonyms. For example, if the entity type is vegetable, and value is scallions, a synonym
         * could be green onions.
         * For KIND_LIST entity types:
         * * This collection must contain exactly one synonym equal to value.
         */
        synonyms: string[];
        /**
         * The primary value associated with this entity entry. For example, if the entity type is vegetable, the value
         * could be scallions.
         * For KIND_MAP entity types:
         * * A reference value to be used in place of synonyms.
         * For KIND_LIST entity types:
         * * A string that can contain references to other entity types (with or without aliases).
         */
        value: string;
    }

    export interface FulfillmentFeature {
        /**
         * The type of the feature that enabled for fulfillment.
         * * SMALLTALK: Fulfillment is enabled for SmallTalk.
         * Possible values are `SMALLTALK`.
         */
        type: string;
    }

    export interface FulfillmentGenericWebService {
        /**
         * The password for HTTP Basic authentication.
         */
        password?: string;
        /**
         * The HTTP request headers to send together with fulfillment requests.
         */
        requestHeaders?: {[key: string]: string};
        /**
         * The fulfillment URI for receiving POST requests. It must use https protocol.
         */
        uri: string;
        /**
         * The user name for HTTP Basic authentication.
         */
        username?: string;
    }

    export interface IntentFollowupIntentInfo {
        followupIntentName?: string;
        /**
         * The unique identifier of the parent intent in the chain of followup intents.
         * Format: projects/<Project ID>/agent/intents/<Intent ID>.
         */
        parentFollowupIntentName?: string;
    }

}

export namespace dns {
    export interface GetKeysKeySigningKey {
        /**
         * String mnemonic specifying the DNSSEC algorithm of this key. Immutable after creation time. Possible values are `ecdsap256sha256`, `ecdsap384sha384`, `rsasha1`, `rsasha256`, and `rsasha512`.
         */
        algorithm: string;
        /**
         * The time that this resource was created in the control plane. This is in RFC3339 text format.
         */
        creationTime: string;
        /**
         * A mutable string of at most 1024 characters associated with this resource for the user's convenience.
         */
        description: string;
        /**
         * A list of cryptographic hashes of the DNSKEY resource record associated with this DnsKey. These digests are needed to construct a DS record that points at this DNS key. Each contains:
         */
        digests: outputs.dns.GetKeysKeySigningKeyDigest[];
        /**
         * The DS record based on the KSK record. This is used when [delegating](https://cloud.google.com/dns/docs/dnssec-advanced#subdelegation) DNSSEC-signed subdomains.
         */
        dsRecord: string;
        /**
         * Unique identifier for the resource; defined by the server.
         */
        id: string;
        /**
         * Active keys will be used to sign subsequent changes to the ManagedZone. Inactive keys will still be present as DNSKEY Resource Records for the use of resolvers validating existing signatures.
         */
        isActive: boolean;
        /**
         * Length of the key in bits. Specified at creation time then immutable.
         */
        keyLength: number;
        /**
         * The key tag is a non-cryptographic hash of the a DNSKEY resource record associated with this DnsKey. The key tag can be used to identify a DNSKEY more quickly (but it is not a unique identifier). In particular, the key tag is used in a parent zone's DS record to point at the DNSKEY in this child ManagedZone. The key tag is a number in the range [0, 65535] and the algorithm to calculate it is specified in RFC4034 Appendix B.
         */
        keyTag: number;
        /**
         * Base64 encoded public half of this key.
         */
        publicKey: string;
    }

    export interface GetKeysKeySigningKeyDigest {
        /**
         * The base-16 encoded bytes of this digest. Suitable for use in a DS resource record.
         */
        digest?: string;
        /**
         * Specifies the algorithm used to calculate this digest. Possible values are `sha1`, `sha256` and `sha384`
         */
        type?: string;
    }

    export interface GetKeysZoneSigningKey {
        /**
         * String mnemonic specifying the DNSSEC algorithm of this key. Immutable after creation time. Possible values are `ecdsap256sha256`, `ecdsap384sha384`, `rsasha1`, `rsasha256`, and `rsasha512`.
         */
        algorithm: string;
        /**
         * The time that this resource was created in the control plane. This is in RFC3339 text format.
         */
        creationTime: string;
        /**
         * A mutable string of at most 1024 characters associated with this resource for the user's convenience.
         */
        description: string;
        /**
         * A list of cryptographic hashes of the DNSKEY resource record associated with this DnsKey. These digests are needed to construct a DS record that points at this DNS key. Each contains:
         */
        digests: outputs.dns.GetKeysZoneSigningKeyDigest[];
        /**
         * Unique identifier for the resource; defined by the server.
         */
        id: string;
        /**
         * Active keys will be used to sign subsequent changes to the ManagedZone. Inactive keys will still be present as DNSKEY Resource Records for the use of resolvers validating existing signatures.
         */
        isActive: boolean;
        /**
         * Length of the key in bits. Specified at creation time then immutable.
         */
        keyLength: number;
        /**
         * The key tag is a non-cryptographic hash of the a DNSKEY resource record associated with this DnsKey. The key tag can be used to identify a DNSKEY more quickly (but it is not a unique identifier). In particular, the key tag is used in a parent zone's DS record to point at the DNSKEY in this child ManagedZone. The key tag is a number in the range [0, 65535] and the algorithm to calculate it is specified in RFC4034 Appendix B.
         */
        keyTag: number;
        /**
         * Base64 encoded public half of this key.
         */
        publicKey: string;
    }

    export interface GetKeysZoneSigningKeyDigest {
        /**
         * The base-16 encoded bytes of this digest. Suitable for use in a DS resource record.
         */
        digest?: string;
        /**
         * Specifies the algorithm used to calculate this digest. Possible values are `sha1`, `sha256` and `sha384`
         */
        type?: string;
    }

    export interface ManagedZoneDnssecConfig {
        /**
         * Specifies parameters that will be used for generating initial DnsKeys
         * for this ManagedZone. If you provide a spec for keySigning or zoneSigning,
         * you must also provide one for the other.
         * defaultKeySpecs can only be updated when the state is `off`.
         * Structure is documented below.
         */
        defaultKeySpecs: outputs.dns.ManagedZoneDnssecConfigDefaultKeySpec[];
        /**
         * Identifies what kind of resource this is
         */
        kind?: string;
        /**
         * Specifies the mechanism used to provide authenticated denial-of-existence responses.
         * nonExistence can only be updated when the state is `off`.
         * Possible values are `nsec` and `nsec3`.
         */
        nonExistence: string;
        /**
         * Specifies whether DNSSEC is enabled, and what mode it is in
         * Possible values are `off`, `on`, and `transfer`.
         */
        state?: string;
    }

    export interface ManagedZoneDnssecConfigDefaultKeySpec {
        /**
         * String mnemonic specifying the DNSSEC algorithm of this key
         * Possible values are `ecdsap256sha256`, `ecdsap384sha384`, `rsasha1`, `rsasha256`, and `rsasha512`.
         */
        algorithm?: string;
        /**
         * Length of the keys in bits
         */
        keyLength?: number;
        /**
         * Specifies whether this is a key signing key (KSK) or a zone
         * signing key (ZSK). Key signing keys have the Secure Entry
         * Point flag set and, when active, will only be used to sign
         * resource record sets of type DNSKEY. Zone signing keys do
         * not have the Secure Entry Point flag set and will be used
         * to sign all other types of resource record sets.
         * Possible values are `keySigning` and `zoneSigning`.
         */
        keyType?: string;
        /**
         * Identifies what kind of resource this is
         */
        kind?: string;
    }

    export interface ManagedZoneForwardingConfig {
        /**
         * List of target name servers to forward to. Cloud DNS will
         * select the best available name server if more than
         * one target is given.
         * Structure is documented below.
         */
        targetNameServers: outputs.dns.ManagedZoneForwardingConfigTargetNameServer[];
    }

    export interface ManagedZoneForwardingConfigTargetNameServer {
        /**
         * Forwarding path for this TargetNameServer. If unset or `default` Cloud DNS will make forwarding
         * decision based on address ranges, i.e. RFC1918 addresses go to the VPC, Non-RFC1918 addresses go
         * to the Internet. When set to `private`, Cloud DNS will always send queries through VPC for this target
         * Possible values are `default` and `private`.
         */
        forwardingPath?: string;
        /**
         * IPv4 address of a target name server.
         */
        ipv4Address: string;
    }

    export interface ManagedZonePeeringConfig {
        /**
         * The network with which to peer.
         * Structure is documented below.
         */
        targetNetwork: outputs.dns.ManagedZonePeeringConfigTargetNetwork;
    }

    export interface ManagedZonePeeringConfigTargetNetwork {
        /**
         * The id or fully qualified URL of the VPC network to forward queries to.
         * This should be formatted like `projects/{project}/global/networks/{network}` or
         * `https://www.googleapis.com/compute/v1/projects/{project}/global/networks/{network}`
         */
        networkUrl: string;
    }

    export interface ManagedZonePrivateVisibilityConfig {
        networks: outputs.dns.ManagedZonePrivateVisibilityConfigNetwork[];
    }

    export interface ManagedZonePrivateVisibilityConfigNetwork {
        /**
         * The id or fully qualified URL of the VPC network to forward queries to.
         * This should be formatted like `projects/{project}/global/networks/{network}` or
         * `https://www.googleapis.com/compute/v1/projects/{project}/global/networks/{network}`
         */
        networkUrl: string;
    }

    export interface ManagedZoneServiceDirectoryConfig {
        /**
         * The namespace associated with the zone.
         * Structure is documented below.
         */
        namespace: outputs.dns.ManagedZoneServiceDirectoryConfigNamespace;
    }

    export interface ManagedZoneServiceDirectoryConfigNamespace {
        /**
         * The fully qualified or partial URL of the service directory namespace that should be
         * associated with the zone. This should be formatted like
         * `https://servicedirectory.googleapis.com/v1/projects/{project}/locations/{location}/namespaces/{namespace_id}`
         * or simply `projects/{project}/locations/{location}/namespaces/{namespace_id}`
         * Ignored for `public` visibility zones.
         */
        namespaceUrl: string;
    }

    export interface PolicyAlternativeNameServerConfig {
        /**
         * Sets an alternative name server for the associated networks. When specified,
         * all DNS queries are forwarded to a name server that you choose. Names such as .internal
         * are not available when an alternative name server is specified.
         * Structure is documented below.
         */
        targetNameServers: outputs.dns.PolicyAlternativeNameServerConfigTargetNameServer[];
    }

    export interface PolicyAlternativeNameServerConfigTargetNameServer {
        /**
         * Forwarding path for this TargetNameServer. If unset or `default` Cloud DNS will make forwarding
         * decision based on address ranges, i.e. RFC1918 addresses go to the VPC, Non-RFC1918 addresses go
         * to the Internet. When set to `private`, Cloud DNS will always send queries through VPC for this target
         * Possible values are `default` and `private`.
         */
        forwardingPath?: string;
        /**
         * IPv4 address to forward to.
         */
        ipv4Address: string;
    }

    export interface PolicyNetwork {
        /**
         * The id or fully qualified URL of the VPC network to forward queries to.
         * This should be formatted like `projects/{project}/global/networks/{network}` or
         * `https://www.googleapis.com/compute/v1/projects/{project}/global/networks/{network}`
         */
        networkUrl: string;
    }

    export interface RecordSetRoutingPolicy {
        /**
         * The configuration for Geolocation based routing policy.
         * Structure is document below.
         */
        geos?: outputs.dns.RecordSetRoutingPolicyGeo[];
        /**
         * The configuration for Weighted Round Robin based routing policy.
         * Structure is document below.
         */
        wrrs?: outputs.dns.RecordSetRoutingPolicyWrr[];
    }

    export interface RecordSetRoutingPolicyGeo {
        /**
         * The location name defined in Google Cloud.
         */
        location: string;
        /**
         * Same as `rrdatas` above.
         */
        rrdatas: string[];
    }

    export interface RecordSetRoutingPolicyWrr {
        /**
         * Same as `rrdatas` above.
         */
        rrdatas: string[];
        /**
         * The ratio of traffic routed to the target.
         */
        weight: number;
    }

    export interface ResponsePolicyNetwork {
        /**
         * The fully qualified URL of the VPC network to bind to.
         * This should be formatted like
         * `https://www.googleapis.com/compute/v1/projects/{project}/global/networks/{network}`
         */
        networkUrl: string;
    }

    export interface ResponsePolicyRuleLocalData {
        /**
         * All resource record sets for this selector, one per resource record type. The name must match the dns_name.
         * Structure is documented below.
         */
        localDatas: outputs.dns.ResponsePolicyRuleLocalDataLocalData[];
    }

    export interface ResponsePolicyRuleLocalDataLocalData {
        /**
         * For example, www.example.com.
         */
        name: string;
        /**
         * As defined in RFC 1035 (section 5) and RFC 1034 (section 3.6.1)
         */
        rrdatas?: string[];
        /**
         * Number of seconds that this ResourceRecordSet can be cached by
         * resolvers.
         */
        ttl?: number;
        /**
         * One of valid DNS resource types.
         * Possible values are `A`, `AAAA`, `CAA`, `CNAME`, `DNSKEY`, `DS`, `HTTPS`, `IPSECVPNKEY`, `MX`, `NAPTR`, `NS`, `PTR`, `SOA`, `SPF`, `SRV`, `SSHFP`, `SVCB`, `TLSA`, and `TXT`.
         */
        type: string;
    }
}

export namespace endpoints {
    export interface ConsumersIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ConsumersIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ServiceApi {
        methods: outputs.endpoints.ServiceApiMethod[];
        name: string;
        syntax: string;
        version: string;
    }

    export interface ServiceApiMethod {
        name: string;
        requestType: string;
        responseType: string;
        syntax: string;
    }

    export interface ServiceEndpoint {
        address: string;
        name: string;
    }

    export interface ServiceIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ServiceIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

}

export namespace eventarc {
    export interface TriggerDestination {
        /**
         * [WARNING] Configuring a Cloud Function in Trigger is not supported as of today. The Cloud Function resource name. Format: projects/{project}/locations/{location}/functions/{function}
         */
        cloudFunction?: string;
        /**
         * Cloud Run fully-managed service that receives the events. The service should be running in the same project of the trigger.
         */
        cloudRunService?: outputs.eventarc.TriggerDestinationCloudRunService;
        /**
         * A GKE service capable of receiving events. The service should be running in the same project as the trigger.
         */
        gke?: outputs.eventarc.TriggerDestinationGke;
        /**
         * The resource name of the Workflow whose Executions are triggered by the events. The Workflow resource should be deployed in the same project as the trigger. Format: `projects/{project}/locations/{location}/workflows/{workflow}`
         */
        workflow?: string;
    }

    export interface TriggerDestinationCloudRunService {
        /**
         * Optional. The relative path on the GKE service the events should be sent to. The value must conform to the definition of a URI path segment (section 3.3 of RFC2396). Examples: "/route", "route", "route/subroute".
         */
        path?: string;
        /**
         * Required. The region the Cloud Run service is deployed in.
         */
        region: string;
        /**
         * Required. Name of the GKE service.
         */
        service: string;
    }

    export interface TriggerDestinationGke {
        /**
         * Required. The name of the cluster the GKE service is running in. The cluster must be running in the same project as the trigger being created.
         */
        cluster: string;
        /**
         * Required. The name of the Google Compute Engine in which the cluster resides, which can either be compute zone (for example, us-central1-a) for the zonal clusters or region (for example, us-central1) for regional clusters.
         */
        location: string;
        /**
         * Required. The namespace the GKE service is running in.
         */
        namespace: string;
        /**
         * Optional. The relative path on the GKE service the events should be sent to. The value must conform to the definition of a URI path segment (section 3.3 of RFC2396). Examples: "/route", "route", "route/subroute".
         */
        path?: string;
        /**
         * Required. Name of the GKE service.
         */
        service: string;
    }

    export interface TriggerMatchingCriteria {
        /**
         * Required. The name of a CloudEvents attribute. Currently, only a subset of attributes are supported for filtering. All triggers MUST provide a filter for the 'type' attribute.
         */
        attribute: string;
        /**
         * Optional. The operator used for matching the events with the value of the filter. If not specified, only events that have an exact key-value pair specified in the filter are matched. The only allowed value is `match-path-pattern`.
         */
        operator?: string;
        /**
         * Required. The value for the attribute. See https://cloud.google.com/eventarc/docs/creating-triggers#trigger-gcloud for available values.
         */
        value: string;
    }

    export interface TriggerTransport {
        /**
         * The Pub/Sub topic and subscription used by Eventarc as delivery intermediary.
         */
        pubsubs?: outputs.eventarc.TriggerTransportPubsub[];
    }

    export interface TriggerTransportPubsub {
        /**
         * -
         * Output only. The name of the Pub/Sub subscription created and managed by Eventarc system as a transport for the event delivery. Format: `projects/{PROJECT_ID}/subscriptions/{SUBSCRIPTION_NAME}`.
         */
        subscription: string;
        /**
         * Optional. The name of the Pub/Sub topic created and managed by Eventarc system as a transport for the event delivery. Format: `projects/{PROJECT_ID}/topics/{TOPIC_NAME}. You may set an existing topic for triggers of the type google.cloud.pubsub.topic.v1.messagePublished` only. The topic you provide here will not be deleted by Eventarc at trigger deletion.
         */
        topic?: string;
    }

}

export namespace filestore {
    export interface InstanceFileShares {
        /**
         * File share capacity in GiB. This must be at least 1024 GiB
         * for the standard tier, or 2560 GiB for the premium tier.
         */
        capacityGb: number;
        /**
         * The name of the fileshare (16 characters or less)
         */
        name: string;
        /**
         * Nfs Export Options. There is a limit of 10 export options per file share.
         * Structure is documented below.
         */
        nfsExportOptions?: outputs.filestore.InstanceFileSharesNfsExportOption[];
    }

    export interface InstanceFileSharesNfsExportOption {
        /**
         * Either READ_ONLY, for allowing only read requests on the exported directory,
         * or READ_WRITE, for allowing both read and write requests. The default is READ_WRITE.
         * Default value is `READ_WRITE`.
         * Possible values are `READ_ONLY` and `READ_WRITE`.
         */
        accessMode?: string;
        /**
         * An integer representing the anonymous group id with a default value of 65534.
         * Anon_gid may only be set with squashMode of ROOT_SQUASH. An error will be returned
         * if this field is specified for other squashMode settings.
         */
        anonGid?: number;
        /**
         * An integer representing the anonymous user id with a default value of 65534.
         * Anon_uid may only be set with squashMode of ROOT_SQUASH. An error will be returned
         * if this field is specified for other squashMode settings.
         */
        anonUid?: number;
        /**
         * List of either IPv4 addresses, or ranges in CIDR notation which may mount the file share.
         * Overlapping IP ranges are not allowed, both within and across NfsExportOptions. An error will be returned.
         * The limit is 64 IP ranges/addresses for each FileShareConfig among all NfsExportOptions.
         */
        ipRanges?: string[];
        /**
         * Either NO_ROOT_SQUASH, for allowing root access on the exported directory, or ROOT_SQUASH,
         * for not allowing root access. The default is NO_ROOT_SQUASH.
         * Default value is `NO_ROOT_SQUASH`.
         * Possible values are `NO_ROOT_SQUASH` and `ROOT_SQUASH`.
         */
        squashMode?: string;
    }

    export interface InstanceNetwork {
        /**
         * The network connect mode of the Filestore instance.
         * If not provided, the connect mode defaults to
         * DIRECT_PEERING.
         * Default value is `DIRECT_PEERING`.
         * Possible values are `DIRECT_PEERING` and `PRIVATE_SERVICE_ACCESS`.
         */
        connectMode?: string;
        /**
         * -
         * A list of IPv4 or IPv6 addresses.
         */
        ipAddresses: string[];
        /**
         * IP versions for which the instance has
         * IP addresses assigned.
         * Each value may be one of `ADDRESS_MODE_UNSPECIFIED`, `MODE_IPV4`, and `MODE_IPV6`.
         */
        modes: string[];
        /**
         * The name of the GCE VPC network to which the
         * instance is connected.
         */
        network: string;
        /**
         * A /29 CIDR block that identifies the range of IP
         * addresses reserved for this instance.
         */
        reservedIpRange: string;
    }

}

export namespace firebaserules {
    export interface RulesetMetadata {
        services: string[];
    }

    export interface RulesetSource {
        /**
         * `File` set constituting the `Source` bundle.
         */
        files: outputs.firebaserules.RulesetSourceFile[];
        /**
         * `Language` of the `Source` bundle. If unspecified, the language will default to `FIREBASE_RULES`. Possible values: LANGUAGE_UNSPECIFIED, FIREBASE_RULES, EVENT_FLOW_TRIGGERS
         */
        language?: string;
    }

    export interface RulesetSourceFile {
        /**
         * Textual Content.
         */
        content: string;
        /**
         * Fingerprint (e.g. github sha) associated with the `File`.
         */
        fingerprint?: string;
        /**
         * File name.
         */
        name: string;
    }

}

export namespace firestore {
    export interface IndexField {
        /**
         * Indicates that this field supports operations on arrayValues. Only one of `order` and `arrayConfig` can
         * be specified.
         * Possible values are `CONTAINS`.
         */
        arrayConfig?: string;
        /**
         * Name of the field.
         */
        fieldPath?: string;
        /**
         * Indicates that this field supports ordering by the specified order or comparing using =, <, <=, >, >=.
         * Only one of `order` and `arrayConfig` can be specified.
         * Possible values are `ASCENDING` and `DESCENDING`.
         */
        order?: string;
    }

}

export namespace folder {
    export interface AccessApprovalSettingsEnrolledService {
        /**
         * The product for which Access Approval will be enrolled. Allowed values are listed (case-sensitive):
         * * all
         * * App Engine
         * * BigQuery
         * * Cloud Bigtable
         * * Cloud Key Management Service
         * * Compute Engine
         * * Cloud Dataflow
         * * Cloud Identity and Access Management
         * * Cloud Pub/Sub
         * * Cloud Storage
         * * Persistent Disk
         * Note: These values are supported as input, but considered a legacy format:
         * * all
         * * appengine.googleapis.com
         * * bigquery.googleapis.com
         * * bigtable.googleapis.com
         * * cloudkms.googleapis.com
         * * compute.googleapis.com
         * * dataflow.googleapis.com
         * * iam.googleapis.com
         * * pubsub.googleapis.com
         * * storage.googleapis.com
         */
        cloudProduct: string;
        /**
         * The enrollment level of the service.
         * Default value is `BLOCK_ALL`.
         * Possible values are `BLOCK_ALL`.
         */
        enrollmentLevel?: string;
    }

    export interface GetOrganizationPolicyBooleanPolicy {
        enforced: boolean;
    }

    export interface GetOrganizationPolicyListPolicy {
        allows: outputs.folder.GetOrganizationPolicyListPolicyAllow[];
        denies: outputs.folder.GetOrganizationPolicyListPolicyDeny[];
        inheritFromParent: boolean;
        suggestedValue: string;
    }

    export interface GetOrganizationPolicyListPolicyAllow {
        all: boolean;
        values: string[];
    }

    export interface GetOrganizationPolicyListPolicyDeny {
        all: boolean;
        values: string[];
    }

    export interface GetOrganizationPolicyRestorePolicy {
        default: boolean;
    }

    export interface IAMBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface IAMMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface IamAuditConfigAuditLogConfig {
        /**
         * Identities that do not cause logging for this type of permission.  The format is the same as that for `members`.
         */
        exemptedMembers?: string[];
        /**
         * Permission type for which logging is to be configured.  Must be one of `DATA_READ`, `DATA_WRITE`, or `ADMIN_READ`.
         */
        logType: string;
    }

    export interface OrganizationPolicyBooleanPolicy {
        /**
         * If true, then the Policy is enforced. If false, then any configuration is acceptable.
         */
        enforced: boolean;
    }

    export interface OrganizationPolicyListPolicy {
        /**
         * or `deny` - (Optional) One or the other must be set.
         */
        allow?: outputs.folder.OrganizationPolicyListPolicyAllow;
        deny?: outputs.folder.OrganizationPolicyListPolicyDeny;
        /**
         * If set to true, the values from the effective Policy of the parent resource
         * are inherited, meaning the values set in this Policy are added to the values inherited up the hierarchy.
         */
        inheritFromParent?: boolean;
        /**
         * The Google Cloud Console will try to default to a configuration that matches the value specified in this field.
         */
        suggestedValue: string;
    }

    export interface OrganizationPolicyListPolicyAllow {
        /**
         * The policy allows or denies all values.
         */
        all?: boolean;
        /**
         * The policy can define specific values that are allowed or denied.
         */
        values?: string[];
    }

    export interface OrganizationPolicyListPolicyDeny {
        /**
         * The policy allows or denies all values.
         */
        all?: boolean;
        /**
         * The policy can define specific values that are allowed or denied.
         */
        values?: string[];
    }

    export interface OrganizationPolicyRestorePolicy {
        /**
         * May only be set to true. If set, then the default Policy is restored.
         */
        default: boolean;
    }
}

export namespace gameservices {
    export interface GameServerClusterConnectionInfo {
        /**
         * Reference of the GKE cluster where the game servers are installed.
         * Structure is documented below.
         */
        gkeClusterReference: outputs.gameservices.GameServerClusterConnectionInfoGkeClusterReference;
        /**
         * Namespace designated on the game server cluster where the game server
         * instances will be created. The namespace existence will be validated
         * during creation.
         */
        namespace: string;
    }

    export interface GameServerClusterConnectionInfoGkeClusterReference {
        /**
         * The full or partial name of a GKE cluster, using one of the following
         * forms:
         * * `projects/{project_id}/locations/{location}/clusters/{cluster_id}`
         * * `locations/{location}/clusters/{cluster_id}`
         * * `{cluster_id}`
         * If project and location are not specified, the project and location of the
         * GameServerCluster resource are used to generate the full name of the
         * GKE cluster.
         */
        cluster: string;
    }

    export interface GameServerConfigFleetConfig {
        /**
         * The fleet spec, which is sent to Agones to configure fleet.
         * The spec can be passed as inline json but it is recommended to use a file reference
         * instead. File references can contain the json or yaml format of the fleet spec. Eg:
         * * fleetSpec = jsonencode(yamldecode(file("fleet_configs.yaml")))
         * * fleetSpec = file("fleet_configs.json")
         * The format of the spec can be found :
         * `https://agones.dev/site/docs/reference/fleet/`.
         */
        fleetSpec: string;
        /**
         * The name of the ScalingConfig
         */
        name: string;
    }

    export interface GameServerConfigScalingConfig {
        /**
         * Fleet autoscaler spec, which is sent to Agones.
         * Example spec can be found :
         * https://agones.dev/site/docs/reference/fleetautoscaler/
         */
        fleetAutoscalerSpec: string;
        /**
         * The name of the ScalingConfig
         */
        name: string;
        /**
         * The schedules to which this scaling config applies.
         * Structure is documented below.
         */
        schedules?: outputs.gameservices.GameServerConfigScalingConfigSchedule[];
        /**
         * Labels used to identify the clusters to which this scaling config
         * applies. A cluster is subject to this scaling config if its labels match
         * any of the selector entries.
         * Structure is documented below.
         */
        selectors?: outputs.gameservices.GameServerConfigScalingConfigSelector[];
    }

    export interface GameServerConfigScalingConfigSchedule {
        /**
         * The duration for the cron job event. The duration of the event is effective
         * after the cron job's start time.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        cronJobDuration?: string;
        /**
         * The cron definition of the scheduled event. See
         * https://en.wikipedia.org/wiki/Cron. Cron spec specifies the local time as
         * defined by the realm.
         */
        cronSpec?: string;
        /**
         * The end time of the event.
         * A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds. Example: "2014-10-02T15:01:23.045123456Z".
         */
        endTime?: string;
        /**
         * The start time of the event.
         * A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds. Example: "2014-10-02T15:01:23.045123456Z".
         */
        startTime?: string;
    }

    export interface GameServerConfigScalingConfigSelector {
        /**
         * Set of labels to group by.
         */
        labels?: {[key: string]: string};
    }

    export interface GameServerDeploymentRolloutGameServerConfigOverride {
        /**
         * Version of the configuration.
         */
        configVersion?: string;
        /**
         * Selection by realms.
         * Structure is documented below.
         */
        realmsSelector?: outputs.gameservices.GameServerDeploymentRolloutGameServerConfigOverrideRealmsSelector;
    }

    export interface GameServerDeploymentRolloutGameServerConfigOverrideRealmsSelector {
        /**
         * List of realms to match against.
         */
        realms?: string[];
    }

    export interface GetGameServerDeploymentRolloutGameServerConfigOverride {
        configVersion: string;
        realmsSelectors: outputs.gameservices.GetGameServerDeploymentRolloutGameServerConfigOverrideRealmsSelector[];
    }

    export interface GetGameServerDeploymentRolloutGameServerConfigOverrideRealmsSelector {
        realms: string[];
    }

}

export namespace gkehub {
    export interface FeatureMembershipConfigmanagement {
        /**
         * Binauthz configuration for the cluster. Structure is documented below.
         */
        binauthz?: outputs.gkehub.FeatureMembershipConfigmanagementBinauthz;
        /**
         * Config Sync configuration for the cluster. Structure is documented below.
         */
        configSync?: outputs.gkehub.FeatureMembershipConfigmanagementConfigSync;
        /**
         * Hierarchy Controller configuration for the cluster. Structure is documented below.
         */
        hierarchyController?: outputs.gkehub.FeatureMembershipConfigmanagementHierarchyController;
        /**
         * Policy Controller configuration for the cluster. Structure is documented below.
         */
        policyController?: outputs.gkehub.FeatureMembershipConfigmanagementPolicyController;
        /**
         * Version of ACM installed.
         */
        version: string;
    }

    export interface FeatureMembershipConfigmanagementBinauthz {
        /**
         * Enables the installation of Policy Controller. If false, the rest of PolicyController fields take no effect.
         */
        enabled?: boolean;
    }

    export interface FeatureMembershipConfigmanagementConfigSync {
        /**
         * -
         * (Optional) Structure is documented below.
         */
        git?: outputs.gkehub.FeatureMembershipConfigmanagementConfigSyncGit;
        /**
         * Specifies whether the Config Sync Repo is in "hierarchical" or "unstructured" mode.
         */
        sourceFormat?: string;
    }

    export interface FeatureMembershipConfigmanagementConfigSyncGit {
        /**
         * The GCP Service Account Email used for auth when secretType is gcpServiceAccount.
         */
        gcpServiceAccountEmail?: string;
        /**
         * URL for the HTTPS proxy to be used when communicating with the Git repo.
         */
        httpsProxy?: string;
        /**
         * The path within the Git repository that represents the top level of the repo to sync. Default: the root directory of the repository.
         */
        policyDir?: string;
        /**
         * Type of secret configured for access to the Git repo.
         */
        secretType?: string;
        /**
         * The branch of the repository to sync from. Default: master.
         */
        syncBranch?: string;
        /**
         * The URL of the Git repository to use as the source of truth.
         */
        syncRepo?: string;
        /**
         * Git revision (tag or hash) to check out. Default HEAD.
         */
        syncRev?: string;
        /**
         * Period in seconds between consecutive syncs. Default: 15.
         */
        syncWaitSecs?: string;
    }

    export interface FeatureMembershipConfigmanagementHierarchyController {
        /**
         * Whether hierarchical resource quota is enabled in this cluster.
         */
        enableHierarchicalResourceQuota?: boolean;
        /**
         * Whether pod tree labels are enabled in this cluster.
         */
        enablePodTreeLabels?: boolean;
        /**
         * Enables the installation of Policy Controller. If false, the rest of PolicyController fields take no effect.
         */
        enabled?: boolean;
    }

    export interface FeatureMembershipConfigmanagementPolicyController {
        /**
         * Sets the interval for Policy Controller Audit Scans (in seconds). When set to 0, this disables audit functionality altogether.
         */
        auditIntervalSeconds?: string;
        /**
         * Enables the installation of Policy Controller. If false, the rest of PolicyController fields take no effect.
         */
        enabled?: boolean;
        /**
         * The set of namespaces that are excluded from Policy Controller checks. Namespaces do not need to currently exist on the cluster.
         */
        exemptableNamespaces?: string[];
        /**
         * Logs all denies and dry run failures.
         */
        logDeniesEnabled?: boolean;
        /**
         * Enables the ability to use Constraint Templates that reference to objects other than the object currently being evaluated.
         */
        referentialRulesEnabled?: boolean;
        /**
         * Installs the default template library along with Policy Controller.
         */
        templateLibraryInstalled?: boolean;
    }

    export interface FeatureResourceState {
        hasResources: boolean;
        state: string;
    }

    export interface FeatureSpec {
        /**
         * Multicluster Ingress-specific spec.
         * The `multiclusteringress` block supports:
         */
        multiclusteringress?: outputs.gkehub.FeatureSpecMulticlusteringress;
    }

    export interface FeatureSpecMulticlusteringress {
        /**
         * Fully-qualified Membership name which hosts the MultiClusterIngress CRD. Example: `projects/foo-proj/locations/global/memberships/bar`
         */
        configMembership: string;
    }

    export interface FeatureState {
        states: outputs.gkehub.FeatureStateState[];
    }

    export interface FeatureStateState {
        code: string;
        description: string;
        updateTime: string;
    }

    export interface MembershipAuthority {
        issuer: string;
    }

    export interface MembershipEndpoint {
        /**
         * If this Membership is a Kubernetes API server hosted on GKE, this is a self link to its GCP resource.
         * Structure is documented below.
         */
        gkeCluster?: outputs.gkehub.MembershipEndpointGkeCluster;
    }

    export interface MembershipEndpointGkeCluster {
        resourceLink: string;
    }

}

export namespace healthcare {
    export interface ConsentStoreIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ConsentStoreIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface DatasetIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface DatasetIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface DicomStoreIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface DicomStoreIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface DicomStoreNotificationConfig {
        /**
         * The Cloud Pub/Sub topic that notifications of changes are published on. Supplied by the client.
         * PubsubMessage.Data will contain the resource name. PubsubMessage.MessageId is the ID of this message.
         * It is guaranteed to be unique within the topic. PubsubMessage.PublishTime is the time at which the message
         * was published. Notifications are only sent if the topic is non-empty. Topic names must be scoped to a
         * project. service-PROJECT_NUMBER@gcp-sa-healthcare.iam.gserviceaccount.com must have publisher permissions on the given
         * Cloud Pub/Sub topic. Not having adequate permissions will cause the calls that send notifications to fail.
         */
        pubsubTopic: string;
    }

    export interface DicomStoreStreamConfig {
        /**
         * BigQueryDestination to include a fully qualified BigQuery table URI where DICOM instance metadata will be streamed.
         * Structure is documented below.
         */
        bigqueryDestination: outputs.healthcare.DicomStoreStreamConfigBigqueryDestination;
    }

    export interface DicomStoreStreamConfigBigqueryDestination {
        /**
         * a fully qualified BigQuery table URI where DICOM instance metadata will be streamed.
         */
        tableUri: string;
    }

    export interface FhirStoreIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface FhirStoreIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface FhirStoreNotificationConfig {
        /**
         * The Cloud Pub/Sub topic that notifications of changes are published on. Supplied by the client.
         * PubsubMessage.Data will contain the resource name. PubsubMessage.MessageId is the ID of this message.
         * It is guaranteed to be unique within the topic. PubsubMessage.PublishTime is the time at which the message
         * was published. Notifications are only sent if the topic is non-empty. Topic names must be scoped to a
         * project. service-PROJECT_NUMBER@gcp-sa-healthcare.iam.gserviceaccount.com must have publisher permissions on the given
         * Cloud Pub/Sub topic. Not having adequate permissions will cause the calls that send notifications to fail.
         */
        pubsubTopic: string;
    }

    export interface FhirStoreStreamConfig {
        /**
         * The destination BigQuery structure that contains both the dataset location and corresponding schema config.
         * The output is organized in one table per resource type. The server reuses the existing tables (if any) that
         * are named after the resource types, e.g. "Patient", "Observation". When there is no existing table for a given
         * resource type, the server attempts to create one.
         * See the [streaming config reference](https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.fhirStores#streamconfig) for more details.
         * Structure is documented below.
         */
        bigqueryDestination: outputs.healthcare.FhirStoreStreamConfigBigqueryDestination;
        /**
         * Supply a FHIR resource type (such as "Patient" or "Observation"). See
         * https://www.hl7.org/fhir/valueset-resource-types.html for a list of all FHIR resource types. The server treats
         * an empty list as an intent to stream all the supported resource types in this FHIR store.
         */
        resourceTypes?: string[];
    }

    export interface FhirStoreStreamConfigBigqueryDestination {
        /**
         * BigQuery URI to a dataset, up to 2000 characters long, in the format bq://projectId.bqDatasetId
         */
        datasetUri: string;
        /**
         * The configuration for the exported BigQuery schema.
         * Structure is documented below.
         */
        schemaConfig: outputs.healthcare.FhirStoreStreamConfigBigqueryDestinationSchemaConfig;
    }

    export interface FhirStoreStreamConfigBigqueryDestinationSchemaConfig {
        /**
         * The depth for all recursive structures in the output analytics schema. For example, concept in the CodeSystem
         * resource is a recursive structure; when the depth is 2, the CodeSystem table will have a column called
         * concept.concept but not concept.concept.concept. If not specified or set to 0, the server will use the default
         * value 2. The maximum depth allowed is 5.
         */
        recursiveStructureDepth: number;
        /**
         * Specifies the output schema type.
         * * ANALYTICS: Analytics schema defined by the FHIR community.
         * See https://github.com/FHIR/sql-on-fhir/blob/master/sql-on-fhir.md.
         * * ANALYTICS_V2: Analytics V2, similar to schema defined by the FHIR community, with added support for extensions with one or more occurrences and contained resources in stringified JSON.
         * * LOSSLESS: A data-driven schema generated from the fields present in the FHIR data being exported, with no additional simplification.
         * Default value is `ANALYTICS`.
         * Possible values are `ANALYTICS`, `ANALYTICS_V2`, and `LOSSLESS`.
         */
        schemaType?: string;
    }

    export interface Hl7StoreIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface Hl7StoreIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface Hl7StoreNotificationConfig {
        /**
         * The Cloud Pub/Sub topic that notifications of changes are published on. Supplied by the client.
         * PubsubMessage.Data will contain the resource name. PubsubMessage.MessageId is the ID of this message.
         * It is guaranteed to be unique within the topic. PubsubMessage.PublishTime is the time at which the message
         * was published. Notifications are only sent if the topic is non-empty. Topic names must be scoped to a
         * project. service-PROJECT_NUMBER@gcp-sa-healthcare.iam.gserviceaccount.com must have publisher permissions on the given
         * Cloud Pub/Sub topic. Not having adequate permissions will cause the calls that send notifications to fail.
         */
        pubsubTopic: string;
    }

    export interface Hl7StoreNotificationConfigs {
        /**
         * Restricts notifications sent for messages matching a filter. If this is empty, all messages
         * are matched. Syntax: https://cloud.google.com/appengine/docs/standard/python/search/query_strings
         * Fields/functions available for filtering are:
         * * messageType, from the MSH-9.1 field. For example, NOT messageType = "ADT".
         * * sendDate or sendDate, the YYYY-MM-DD date the message was sent in the dataset's timeZone, from the MSH-7 segment. For example, sendDate < "2017-01-02".
         * * sendTime, the timestamp when the message was sent, using the RFC3339 time format for comparisons, from the MSH-7 segment. For example, sendTime < "2017-01-02T00:00:00-05:00".
         * * sendFacility, the care center that the message came from, from the MSH-4 segment. For example, sendFacility = "ABC".
         * * PatientId(value, type), which matches if the message lists a patient having an ID of the given value and type in the PID-2, PID-3, or PID-4 segments. For example, PatientId("123456", "MRN").
         * * labels.x, a string value of the label with key x as set using the Message.labels map. For example, labels."priority"="high". The operator :* can be used to assert the existence of a label. For example, labels."priority":*.
         */
        filter?: string;
        /**
         * The Cloud Pub/Sub topic that notifications of changes are published on. Supplied by the client.
         * PubsubMessage.Data will contain the resource name. PubsubMessage.MessageId is the ID of this message.
         * It is guaranteed to be unique within the topic. PubsubMessage.PublishTime is the time at which the message
         * was published. Notifications are only sent if the topic is non-empty. Topic names must be scoped to a
         * project. service-PROJECT_NUMBER@gcp-sa-healthcare.iam.gserviceaccount.com must have publisher permissions on the given
         * Cloud Pub/Sub topic. Not having adequate permissions will cause the calls that send notifications to fail.
         */
        pubsubTopic: string;
    }

    export interface Hl7StoreParserConfig {
        /**
         * Determines whether messages with no header are allowed.
         */
        allowNullHeader?: boolean;
        /**
         * JSON encoded string for schemas used to parse messages in this
         * store if schematized parsing is desired.
         */
        schema?: string;
        /**
         * Byte(s) to be used as the segment terminator. If this is unset, '\r' will be used as segment terminator.
         * A base64-encoded string.
         */
        segmentTerminator?: string;
        /**
         * The version of the unschematized parser to be used when a custom `schema` is not set.
         * Default value is `V1`.
         * Possible values are `V1`, `V2`, and `V3`.
         */
        version?: string;
    }

}

export namespace iam {
    export interface DenyPolicyRule {
        /**
         * A deny rule in an IAM deny policy.
         * Structure is documented below.
         */
        denyRule?: outputs.iam.DenyPolicyRuleDenyRule;
        /**
         * Description of the expression. This is a longer text which describes the expression,
         * e.g. when hovered over it in a UI.
         */
        description?: string;
    }

    export interface DenyPolicyRuleDenyRule {
        /**
         * User defined CEVAL expression. A CEVAL expression is used to specify match criteria such as origin.ip, source.region_code and contents in the request header.
         * Structure is documented below.
         */
        denialCondition: outputs.iam.DenyPolicyRuleDenyRuleDenialCondition;
        /**
         * The permissions that are explicitly denied by this rule. Each permission uses the format `{service-fqdn}/{resource}.{verb}`,
         * where `{service-fqdn}` is the fully qualified domain name for the service. For example, `iam.googleapis.com/roles.list`.
         */
        deniedPermissions?: string[];
        /**
         * The identities that are prevented from using one or more permissions on Google Cloud resources.
         */
        deniedPrincipals?: string[];
        /**
         * Specifies the permissions that this rule excludes from the set of denied permissions given by deniedPermissions.
         * If a permission appears in deniedPermissions and in exceptionPermissions then it will not be denied.
         * The excluded permissions can be specified using the same syntax as deniedPermissions.
         */
        exceptionPermissions?: string[];
        /**
         * The identities that are excluded from the deny rule, even if they are listed in the deniedPrincipals.
         * For example, you could add a Google group to the deniedPrincipals, then exclude specific users who belong to that group.
         */
        exceptionPrincipals?: string[];
    }

    export interface DenyPolicyRuleDenyRuleDenialCondition {
        /**
         * Description of the expression. This is a longer text which describes the expression,
         * e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * String indicating the location of the expression for error reporting,
         * e.g. a file name and a position in the file.
         */
        location?: string;
        /**
         * Title for the expression, i.e. a short string describing its purpose.
         * This can be used e.g. in UIs which allow to enter the expression.
         */
        title?: string;
    }

    export interface GetTestablePermissionsPermission {
        /**
         * Whether the corresponding API has been enabled for the resource.
         */
        apiDisabled: boolean;
        /**
         * The level of support for custom roles. Can be one of `"NOT_SUPPORTED"`, `"SUPPORTED"`, `"TESTING"`. Default is `"SUPPORTED"`
         */
        customSupportLevel: string;
        /**
         * Name of the permission.
         */
        name: string;
        /**
         * Release stage of the permission.
         */
        stage: string;
        /**
         * Human readable title of the permission.
         */
        title: string;
    }

    export interface GetWorkloadIdentityPoolProviderAw {
        accountId: string;
    }

    export interface GetWorkloadIdentityPoolProviderOidc {
        allowedAudiences: string[];
        issuerUri: string;
    }

    export interface WorkloadIdentityPoolProviderAws {
        /**
         * The AWS account ID.
         */
        accountId: string;
    }

    export interface WorkloadIdentityPoolProviderOidc {
        /**
         * Acceptable values for the `aud` field (audience) in the OIDC token. Token exchange
         * requests are rejected if the token audience does not match one of the configured
         * values. Each audience may be at most 256 characters. A maximum of 10 audiences may
         * be configured.
         * If this list is empty, the OIDC token audience must be equal to the full canonical
         * resource name of the WorkloadIdentityPoolProvider, with or without the HTTPS prefix.
         * For example:
         * ```typescript
         * import * as pulumi from "@pulumi/pulumi";
         * ```
         */
        allowedAudiences?: string[];
        /**
         * The OIDC issuer URL.
         */
        issuerUri: string;
    }
}

export namespace iap {
    export interface AppEngineServiceIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface AppEngineServiceIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface AppEngineVersionIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface AppEngineVersionIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface TunnelIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface TunnelIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface TunnelInstanceIAMBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface TunnelInstanceIAMMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface WebBackendServiceIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface WebBackendServiceIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface WebIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface WebIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface WebTypeAppEngingIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface WebTypeAppEngingIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface WebTypeComputeIamBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface WebTypeComputeIamMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

}

export namespace identityplatform {
    export interface InboundSamlConfigIdpConfig {
        /**
         * The IdP's certificate data to verify the signature in the SAMLResponse issued by the IDP.
         * Structure is documented below.
         */
        idpCertificates: outputs.identityplatform.InboundSamlConfigIdpConfigIdpCertificate[];
        /**
         * Unique identifier for all SAML entities
         */
        idpEntityId: string;
        /**
         * Indicates if outbounding SAMLRequest should be signed.
         */
        signRequest?: boolean;
        /**
         * URL to send Authentication request to.
         */
        ssoUrl: string;
    }

    export interface InboundSamlConfigIdpConfigIdpCertificate {
        /**
         * -
         * The x509 certificate
         */
        x509Certificate?: string;
    }

    export interface InboundSamlConfigSpConfig {
        /**
         * Callback URI where responses from IDP are handled. Must start with `https://`.
         */
        callbackUri?: string;
        /**
         * -
         * The IDP's certificate data to verify the signature in the SAMLResponse issued by the IDP.
         * Structure is documented below.
         */
        spCertificates: outputs.identityplatform.InboundSamlConfigSpConfigSpCertificate[];
        /**
         * Unique identifier for all SAML entities.
         */
        spEntityId?: string;
    }

    export interface InboundSamlConfigSpConfigSpCertificate {
        /**
         * -
         * The x509 certificate
         */
        x509Certificate: string;
    }

    export interface TenantInboundSamlConfigIdpConfig {
        /**
         * The IDP's certificate data to verify the signature in the SAMLResponse issued by the IDP.
         * Structure is documented below.
         */
        idpCertificates: outputs.identityplatform.TenantInboundSamlConfigIdpConfigIdpCertificate[];
        /**
         * Unique identifier for all SAML entities
         */
        idpEntityId: string;
        /**
         * Indicates if outbounding SAMLRequest should be signed.
         */
        signRequest?: boolean;
        /**
         * URL to send Authentication request to.
         */
        ssoUrl: string;
    }

    export interface TenantInboundSamlConfigIdpConfigIdpCertificate {
        /**
         * -
         * The x509 certificate
         */
        x509Certificate?: string;
    }

    export interface TenantInboundSamlConfigSpConfig {
        /**
         * Callback URI where responses from IDP are handled. Must start with `https://`.
         */
        callbackUri: string;
        /**
         * -
         * The IDP's certificate data to verify the signature in the SAMLResponse issued by the IDP.
         * Structure is documented below.
         */
        spCertificates: outputs.identityplatform.TenantInboundSamlConfigSpConfigSpCertificate[];
        /**
         * Unique identifier for all SAML entities.
         */
        spEntityId: string;
    }

    export interface TenantInboundSamlConfigSpConfigSpCertificate {
        /**
         * -
         * The x509 certificate
         */
        x509Certificate: string;
    }

}

export namespace iot {
    export interface DeviceConfig {
        binaryData?: string;
        cloudUpdateTime: string;
        deviceAckTime: string;
        version: string;
    }

    export interface DeviceCredential {
        /**
         * The time at which this credential becomes invalid.
         */
        expirationTime: string;
        /**
         * A public key used to verify the signature of JSON Web Tokens (JWTs).
         * Structure is documented below.
         */
        publicKey: outputs.iot.DeviceCredentialPublicKey;
    }

    export interface DeviceCredentialPublicKey {
        /**
         * The format of the key.
         * Possible values are `RSA_PEM`, `RSA_X509_PEM`, `ES256_PEM`, and `ES256_X509_PEM`.
         */
        format: string;
        /**
         * The key data.
         */
        key: string;
    }

    export interface DeviceGatewayConfig {
        /**
         * Indicates whether the device is a gateway.
         * Possible values are `ASSOCIATION_ONLY`, `DEVICE_AUTH_TOKEN_ONLY`, and `ASSOCIATION_AND_DEVICE_AUTH_TOKEN`.
         */
        gatewayAuthMethod?: string;
        /**
         * Indicates whether the device is a gateway.
         * Default value is `NON_GATEWAY`.
         * Possible values are `GATEWAY` and `NON_GATEWAY`.
         */
        gatewayType?: string;
        /**
         * -
         * The ID of the gateway the device accessed most recently.
         */
        lastAccessedGatewayId: string;
        /**
         * -
         * The most recent time at which the device accessed the gateway specified in last_accessed_gateway.
         */
        lastAccessedGatewayTime: string;
    }

    export interface DeviceLastErrorStatus {
        details?: {[key: string]: any}[];
        message?: string;
        number?: number;
    }

    export interface DeviceState {
        binaryData?: string;
        updateTime?: string;
    }

    export interface RegistryCredential {
        /**
         * A public key certificate format and data.
         */
        publicKeyCertificate: {[key: string]: any};
    }

    export interface RegistryEventNotificationConfigItem {
        /**
         * PubSub topic name to publish device events.
         */
        pubsubTopicName: string;
        /**
         * If the subfolder name matches this string exactly, this
         * configuration will be used. The string must not include the
         * leading '/' character. If empty, all strings are matched. Empty
         * value can only be used for the last `eventNotificationConfigs`
         * item.
         */
        subfolderMatches?: string;
    }

}

export namespace kms {
    export interface CryptoKeyIAMBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface CryptoKeyIAMMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface CryptoKeyVersionTemplate {
        /**
         * The algorithm to use when creating a version based on this template.
         * See the [algorithm reference](https://cloud.google.com/kms/docs/reference/rest/v1/CryptoKeyVersionAlgorithm) for possible inputs.
         */
        algorithm: string;
        /**
         * The protection level to use when creating a version based on this template. Possible values include "SOFTWARE", "HSM", "EXTERNAL". Defaults to "SOFTWARE".
         */
        protectionLevel?: string;
    }

    export interface GetKMSCryptoKeyVersionPublicKey {
        /**
         * The CryptoKeyVersionAlgorithm that this CryptoKeyVersion supports.
         */
        algorithm: string;
        /**
         * The public key, encoded in PEM format. For more information, see the RFC 7468 sections for General Considerations and Textual Encoding of Subject Public Key Info.
         */
        pem: string;
    }

    export interface GetKMSCryptoKeyVersionTemplate {
        algorithm: string;
        protectionLevel: string;
    }

    export interface KeyRingIAMBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface KeyRingIAMMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface KeyRingImportJobAttestation {
        content: string;
        format: string;
    }

    export interface KeyRingImportJobPublicKey {
        pem: string;
    }

    export interface RegistryCredential {
        /**
         * A public key certificate format and data.
         */
        publicKeyCertificate: {[key: string]: any};
    }

    export interface RegistryEventNotificationConfigItem {
        /**
         * PubSub topic name to publish device events.
         */
        pubsubTopicName: string;
        /**
         * If the subfolder name matches this string exactly, this
         * configuration will be used. The string must not include the
         * leading '/' character. If empty, all strings are matched. Empty
         * value can only be used for the last `eventNotificationConfigs`
         * item.
         */
        subfolderMatches?: string;
    }

}

export namespace logging {
    export interface BillingAccountSinkBigqueryOptions {
        /**
         * Whether to use [BigQuery's partition tables](https://cloud.google.com/bigquery/docs/partitioned-tables).
         * By default, Logging creates dated tables based on the log entries' timestamps, e.g. syslog_20170523. With partitioned
         * tables the date suffix is no longer present and [special query syntax](https://cloud.google.com/bigquery/docs/querying-partitioned-tables)
         * has to be used instead. In both cases, tables are sharded based on UTC timezone.
         */
        usePartitionedTables: boolean;
    }

    export interface BillingAccountSinkExclusion {
        /**
         * A description of this exclusion.
         */
        description?: string;
        /**
         * If set to True, then this exclusion is disabled and it does not exclude any log entries.
         */
        disabled?: boolean;
        /**
         * An advanced logs filter that matches the log entries to be excluded. By using the sample function, you can exclude less than 100% of the matching log entries. See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced_filters) for information on how to
         * write a filter.
         */
        filter: string;
        /**
         * A client-assigned identifier, such as `load-balancer-exclusion`. Identifiers are limited to 100 characters and can include only letters, digits, underscores, hyphens, and periods. First character has to be alphanumeric.
         */
        name: string;
    }

    export interface FolderSinkBigqueryOptions {
        /**
         * Whether to use [BigQuery's partition tables](https://cloud.google.com/bigquery/docs/partitioned-tables).
         * By default, Logging creates dated tables based on the log entries' timestamps, e.g. syslog_20170523. With partitioned
         * tables the date suffix is no longer present and [special query syntax](https://cloud.google.com/bigquery/docs/querying-partitioned-tables)
         * has to be used instead. In both cases, tables are sharded based on UTC timezone.
         */
        usePartitionedTables: boolean;
    }

    export interface FolderSinkExclusion {
        /**
         * A description of this exclusion.
         */
        description?: string;
        /**
         * If set to True, then this exclusion is disabled and it does not exclude any log entries.
         */
        disabled?: boolean;
        /**
         * An advanced logs filter that matches the log entries to be excluded. By using the sample function, you can exclude less than 100% of the matching log entries. See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced_filters) for information on how to
         * write a filter.
         */
        filter: string;
        /**
         * A client-assigned identifier, such as `load-balancer-exclusion`. Identifiers are limited to 100 characters and can include only letters, digits, underscores, hyphens, and periods. First character has to be alphanumeric.
         */
        name: string;
    }

    export interface MetricBucketOptions {
        /**
         * Specifies a set of buckets with arbitrary widths.
         * Structure is documented below.
         */
        explicitBuckets?: outputs.logging.MetricBucketOptionsExplicitBuckets;
        /**
         * Specifies an exponential sequence of buckets that have a width that is proportional to the value of
         * the lower bound. Each bucket represents a constant relative uncertainty on a specific value in the bucket.
         * Structure is documented below.
         */
        exponentialBuckets?: outputs.logging.MetricBucketOptionsExponentialBuckets;
        /**
         * Specifies a linear sequence of buckets that all have the same width (except overflow and underflow).
         * Each bucket represents a constant absolute uncertainty on the specific value in the bucket.
         * Structure is documented below.
         */
        linearBuckets?: outputs.logging.MetricBucketOptionsLinearBuckets;
    }

    export interface MetricBucketOptionsExplicitBuckets {
        /**
         * The values must be monotonically increasing.
         */
        bounds: number[];
    }

    export interface MetricBucketOptionsExponentialBuckets {
        /**
         * Must be greater than 1.
         */
        growthFactor?: number;
        /**
         * Must be greater than 0.
         */
        numFiniteBuckets?: number;
        /**
         * Must be greater than 0.
         */
        scale?: number;
    }

    export interface MetricBucketOptionsLinearBuckets {
        /**
         * Must be greater than 0.
         */
        numFiniteBuckets?: number;
        /**
         * Lower bound of the first bucket.
         */
        offset?: number;
        /**
         * Must be greater than 0.
         */
        width?: number;
    }

    export interface MetricMetricDescriptor {
        /**
         * A concise name for the metric, which can be displayed in user interfaces. Use sentence case
         * without an ending period, for example "Request count". This field is optional but it is
         * recommended to be set for any metrics associated with user-visible concepts, such as Quota.
         */
        displayName?: string;
        /**
         * The set of labels that can be used to describe a specific instance of this metric type. For
         * example, the appengine.googleapis.com/http/server/response_latencies metric type has a label
         * for the HTTP response code, response_code, so you can look at latencies for successful responses
         * or just for responses that failed.
         * Structure is documented below.
         */
        labels?: outputs.logging.MetricMetricDescriptorLabel[];
        /**
         * Whether the metric records instantaneous values, changes to a value, etc.
         * Some combinations of metricKind and valueType might not be supported.
         * For counter metrics, set this to DELTA.
         * Possible values are `DELTA`, `GAUGE`, and `CUMULATIVE`.
         */
        metricKind: string;
        /**
         * The unit in which the metric value is reported. It is only applicable if the valueType is
         * `INT64`, `DOUBLE`, or `DISTRIBUTION`. The supported units are a subset of
         * [The Unified Code for Units of Measure](http://unitsofmeasure.org/ucum.html) standard
         */
        unit?: string;
        /**
         * The type of data that can be assigned to the label.
         * Default value is `STRING`.
         * Possible values are `BOOL`, `INT64`, and `STRING`.
         */
        valueType: string;
    }

    export interface MetricMetricDescriptorLabel {
        /**
         * A description of this metric, which is used in documentation. The maximum length of the
         * description is 8000 characters.
         */
        description?: string;
        /**
         * The label key.
         */
        key: string;
        /**
         * The type of data that can be assigned to the label.
         * Default value is `STRING`.
         * Possible values are `BOOL`, `INT64`, and `STRING`.
         */
        valueType?: string;
    }

    export interface OrganizationSinkBigqueryOptions {
        /**
         * Whether to use [BigQuery's partition tables](https://cloud.google.com/bigquery/docs/partitioned-tables).
         * By default, Logging creates dated tables based on the log entries' timestamps, e.g. syslog_20170523. With partitioned
         * tables the date suffix is no longer present and [special query syntax](https://cloud.google.com/bigquery/docs/querying-partitioned-tables)
         * has to be used instead. In both cases, tables are sharded based on UTC timezone.
         */
        usePartitionedTables: boolean;
    }

    export interface OrganizationSinkExclusion {
        /**
         * A description of this exclusion.
         */
        description?: string;
        /**
         * If set to True, then this exclusion is disabled and it does not exclude any log entries.
         */
        disabled?: boolean;
        /**
         * An advanced logs filter that matches the log entries to be excluded. By using the sample function, you can exclude less than 100% of the matching log entries. See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced_filters) for information on how to
         * write a filter.
         */
        filter: string;
        /**
         * A client-assigned identifier, such as `load-balancer-exclusion`. Identifiers are limited to 100 characters and can include only letters, digits, underscores, hyphens, and periods. First character has to be alphanumeric.
         */
        name: string;
    }

    export interface ProjectSinkBigqueryOptions {
        /**
         * Whether to use [BigQuery's partition tables](https://cloud.google.com/bigquery/docs/partitioned-tables).
         * By default, Logging creates dated tables based on the log entries' timestamps, e.g. syslog_20170523. With partitioned
         * tables the date suffix is no longer present and [special query syntax](https://cloud.google.com/bigquery/docs/querying-partitioned-tables)
         * has to be used instead. In both cases, tables are sharded based on UTC timezone.
         */
        usePartitionedTables: boolean;
    }

    export interface ProjectSinkExclusion {
        /**
         * A description of this exclusion.
         */
        description?: string;
        /**
         * If set to True, then this exclusion is disabled and it does not exclude any log entries.
         */
        disabled?: boolean;
        /**
         * An advanced logs filter that matches the log entries to be excluded. By using the sample function, you can exclude less than 100% of the matching log entries. See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced_filters) for information on how to
         * write a filter.
         */
        filter: string;
        /**
         * A client-assigned identifier, such as `load-balancer-exclusion`. Identifiers are limited to 100 characters and can include only letters, digits, underscores, hyphens, and periods. First character has to be alphanumeric.
         */
        name: string;
    }

}

export namespace memcache {
    export interface InstanceMaintenancePolicy {
        /**
         * -
         * Output only. The time when the policy was created.
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond
         * resolution and up to nine fractional digits
         */
        createTime: string;
        /**
         * Optional. Description of what this policy is for.
         * Create/Update methods return INVALID_ARGUMENT if the
         * length is greater than 512.
         */
        description?: string;
        /**
         * -
         * Output only. The time when the policy was updated.
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond
         * resolution and up to nine fractional digits.
         */
        updateTime: string;
        /**
         * Required. Maintenance window that is applied to resources covered by this policy.
         * Minimum 1. For the current version, the maximum number of weeklyMaintenanceWindows
         * is expected to be one.
         * Structure is documented below.
         */
        weeklyMaintenanceWindows: outputs.memcache.InstanceMaintenancePolicyWeeklyMaintenanceWindow[];
    }

    export interface InstanceMaintenancePolicyWeeklyMaintenanceWindow {
        /**
         * Required. The day of week that maintenance updates occur.
         * - DAY_OF_WEEK_UNSPECIFIED: The day of the week is unspecified.
         * - MONDAY: Monday
         * - TUESDAY: Tuesday
         * - WEDNESDAY: Wednesday
         * - THURSDAY: Thursday
         * - FRIDAY: Friday
         * - SATURDAY: Saturday
         * - SUNDAY: Sunday
         * Possible values are `DAY_OF_WEEK_UNSPECIFIED`, `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, and `SUNDAY`.
         */
        day: string;
        /**
         * Required. The length of the maintenance window, ranging from 3 hours to 8 hours.
         * A duration in seconds with up to nine fractional digits,
         * terminated by 's'. Example: "3.5s".
         */
        duration: string;
        /**
         * Required. Start time of the window in UTC time.
         * Structure is documented below.
         */
        startTime: outputs.memcache.InstanceMaintenancePolicyWeeklyMaintenanceWindowStartTime;
    }

    export interface InstanceMaintenancePolicyWeeklyMaintenanceWindowStartTime {
        /**
         * Hours of day in 24 hour format. Should be from 0 to 23.
         * An API may choose to allow the value "24:00:00" for scenarios like business closing time.
         */
        hours?: number;
        /**
         * Minutes of hour of day. Must be from 0 to 59.
         */
        minutes?: number;
        /**
         * Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999.
         */
        nanos?: number;
        /**
         * Seconds of minutes of the time. Must normally be from 0 to 59.
         * An API may allow the value 60 if it allows leap-seconds.
         */
        seconds?: number;
    }

    export interface InstanceMaintenanceSchedule {
        endTime: string;
        scheduleDeadlineTime: string;
        /**
         * Required. Start time of the window in UTC time.
         * Structure is documented below.
         */
        startTime: string;
    }

    export interface InstanceMemcacheNode {
        host: string;
        nodeId: string;
        port: number;
        state: string;
        zone: string;
    }

    export interface InstanceMemcacheParameters {
        /**
         * -
         * This is a unique ID associated with this set of parameters.
         */
        id: string;
        /**
         * User-defined set of parameters to use in the memcache process.
         */
        params?: {[key: string]: string};
    }

    export interface InstanceNodeConfig {
        /**
         * Number of CPUs per node.
         */
        cpuCount: number;
        /**
         * Memory size in Mebibytes for each memcache node.
         */
        memorySizeMb: number;
    }

}

export namespace ml {
    export interface EngineModelDefaultVersion {
        /**
         * The name specified for the version when it was created.
         */
        name: string;
    }

}

export namespace monitoring {
    export interface AlertPolicyAlertStrategy {
        /**
         * If an alert policy that was active has no data for this long, any open incidents will close.
         */
        autoClose?: string;
        /**
         * Required for alert policies with a LogMatch condition.
         * This limit is not implemented for alert policies that are not log-based.
         * Structure is documented below.
         */
        notificationRateLimit?: outputs.monitoring.AlertPolicyAlertStrategyNotificationRateLimit;
    }

    export interface AlertPolicyAlertStrategyNotificationRateLimit {
        /**
         * Not more than one notification per period.
         */
        period?: string;
    }

    export interface AlertPolicyCondition {
        /**
         * A condition that checks that a time series
         * continues to receive new data points.
         * Structure is documented below.
         */
        conditionAbsent?: outputs.monitoring.AlertPolicyConditionConditionAbsent;
        /**
         * A condition that checks for log messages matching given constraints.
         * If set, no other conditions can be present.
         * Structure is documented below.
         */
        conditionMatchedLog?: outputs.monitoring.AlertPolicyConditionConditionMatchedLog;
        /**
         * A Monitoring Query Language query that outputs a boolean stream
         * Structure is documented below.
         */
        conditionMonitoringQueryLanguage?: outputs.monitoring.AlertPolicyConditionConditionMonitoringQueryLanguage;
        /**
         * A condition that compares a time series against a
         * threshold.
         * Structure is documented below.
         */
        conditionThreshold?: outputs.monitoring.AlertPolicyConditionConditionThreshold;
        /**
         * A short name or phrase used to identify the
         * condition in dashboards, notifications, and
         * incidents. To avoid confusion, don't use the same
         * display name for multiple conditions in the same
         * policy.
         */
        displayName: string;
        /**
         * -
         * The unique resource name for this condition.
         * Its syntax is:
         * projects/[PROJECT_ID]/alertPolicies/[POLICY_ID]/conditions/[CONDITION_ID]
         * [CONDITION_ID] is assigned by Stackdriver Monitoring when
         * the condition is created as part of a new or updated alerting
         * policy.
         */
        name: string;
    }

    export interface AlertPolicyConditionConditionAbsent {
        /**
         * Specifies the alignment of data points in
         * individual time series as well as how to
         * combine the retrieved time series together
         * (such as when aggregating multiple streams
         * on each resource to a single stream for each
         * resource or when aggregating streams across
         * all members of a group of resources).
         * Multiple aggregations are applied in the
         * order specified.This field is similar to the
         * one in the MetricService.ListTimeSeries
         * request. It is advisable to use the
         * ListTimeSeries method when debugging this
         * field.
         * Structure is documented below.
         */
        aggregations?: outputs.monitoring.AlertPolicyConditionConditionAbsentAggregation[];
        /**
         * The amount of time that a time series must
         * violate the threshold to be considered
         * failing. Currently, only values that are a
         * multiple of a minute--e.g., 0, 60, 120, or
         * 300 seconds--are supported. If an invalid
         * value is given, an error will be returned.
         * When choosing a duration, it is useful to
         * keep in mind the frequency of the underlying
         * time series data (which may also be affected
         * by any alignments specified in the
         * aggregations field); a good duration is long
         * enough so that a single outlier does not
         * generate spurious alerts, but short enough
         * that unhealthy states are detected and
         * alerted on quickly.
         */
        duration: string;
        /**
         * A logs-based filter.
         */
        filter?: string;
        /**
         * The number/percent of time series for which
         * the comparison must hold in order for the
         * condition to trigger. If unspecified, then
         * the condition will trigger if the comparison
         * is true for any of the time series that have
         * been identified by filter and aggregations,
         * or by the ratio, if denominatorFilter and
         * denominatorAggregations are specified.
         * Structure is documented below.
         */
        trigger?: outputs.monitoring.AlertPolicyConditionConditionAbsentTrigger;
    }

    export interface AlertPolicyConditionConditionAbsentAggregation {
        /**
         * The alignment period for per-time
         * series alignment. If present,
         * alignmentPeriod must be at least
         * 60 seconds. After per-time series
         * alignment, each time series will
         * contain data points only on the
         * period boundaries. If
         * perSeriesAligner is not specified
         * or equals ALIGN_NONE, then this
         * field is ignored. If
         * perSeriesAligner is specified and
         * does not equal ALIGN_NONE, then
         * this field must be defined;
         * otherwise an error is returned.
         */
        alignmentPeriod?: string;
        /**
         * The approach to be used to combine
         * time series. Not all reducer
         * functions may be applied to all
         * time series, depending on the
         * metric type and the value type of
         * the original time series.
         * Reduction may change the metric
         * type of value type of the time
         * series.Time series data must be
         * aligned in order to perform cross-
         * time series reduction. If
         * crossSeriesReducer is specified,
         * then perSeriesAligner must be
         * specified and not equal ALIGN_NONE
         * and alignmentPeriod must be
         * specified; otherwise, an error is
         * returned.
         * Possible values are `REDUCE_NONE`, `REDUCE_MEAN`, `REDUCE_MIN`, `REDUCE_MAX`, `REDUCE_SUM`, `REDUCE_STDDEV`, `REDUCE_COUNT`, `REDUCE_COUNT_TRUE`, `REDUCE_COUNT_FALSE`, `REDUCE_FRACTION_TRUE`, `REDUCE_PERCENTILE_99`, `REDUCE_PERCENTILE_95`, `REDUCE_PERCENTILE_50`, and `REDUCE_PERCENTILE_05`.
         */
        crossSeriesReducer?: string;
        /**
         * The set of fields to preserve when
         * crossSeriesReducer is specified.
         * The groupByFields determine how
         * the time series are partitioned
         * into subsets prior to applying the
         * aggregation function. Each subset
         * contains time series that have the
         * same value for each of the
         * grouping fields. Each individual
         * time series is a member of exactly
         * one subset. The crossSeriesReducer
         * is applied to each subset of time
         * series. It is not possible to
         * reduce across different resource
         * types, so this field implicitly
         * contains resource.type. Fields not
         * specified in groupByFields are
         * aggregated away. If groupByFields
         * is not specified and all the time
         * series have the same resource
         * type, then the time series are
         * aggregated into a single output
         * time series. If crossSeriesReducer
         * is not defined, this field is
         * ignored.
         */
        groupByFields?: string[];
        /**
         * The approach to be used to align
         * individual time series. Not all
         * alignment functions may be applied
         * to all time series, depending on
         * the metric type and value type of
         * the original time series.
         * Alignment may change the metric
         * type or the value type of the time
         * series.Time series data must be
         * aligned in order to perform cross-
         * time series reduction. If
         * crossSeriesReducer is specified,
         * then perSeriesAligner must be
         * specified and not equal ALIGN_NONE
         * and alignmentPeriod must be
         * specified; otherwise, an error is
         * returned.
         * Possible values are `ALIGN_NONE`, `ALIGN_DELTA`, `ALIGN_RATE`, `ALIGN_INTERPOLATE`, `ALIGN_NEXT_OLDER`, `ALIGN_MIN`, `ALIGN_MAX`, `ALIGN_MEAN`, `ALIGN_COUNT`, `ALIGN_SUM`, `ALIGN_STDDEV`, `ALIGN_COUNT_TRUE`, `ALIGN_COUNT_FALSE`, `ALIGN_FRACTION_TRUE`, `ALIGN_PERCENTILE_99`, `ALIGN_PERCENTILE_95`, `ALIGN_PERCENTILE_50`, `ALIGN_PERCENTILE_05`, and `ALIGN_PERCENT_CHANGE`.
         */
        perSeriesAligner?: string;
    }

    export interface AlertPolicyConditionConditionAbsentTrigger {
        /**
         * The absolute number of time series
         * that must fail the predicate for the
         * condition to be triggered.
         */
        count?: number;
        /**
         * The percentage of time series that
         * must fail the predicate for the
         * condition to be triggered.
         */
        percent?: number;
    }

    export interface AlertPolicyConditionConditionMatchedLog {
        /**
         * A logs-based filter.
         */
        filter: string;
        /**
         * A map from a label key to an extractor expression, which is used to
         * extract the value for this label key. Each entry in this map is
         * a specification for how data should be extracted from log entries that
         * match filter. Each combination of extracted values is treated as
         * a separate rule for the purposes of triggering notifications.
         * Label keys and corresponding values can be used in notifications
         * generated by this condition.
         */
        labelExtractors?: {[key: string]: string};
    }

    export interface AlertPolicyConditionConditionMonitoringQueryLanguage {
        /**
         * The amount of time that a time series must
         * violate the threshold to be considered
         * failing. Currently, only values that are a
         * multiple of a minute--e.g., 0, 60, 120, or
         * 300 seconds--are supported. If an invalid
         * value is given, an error will be returned.
         * When choosing a duration, it is useful to
         * keep in mind the frequency of the underlying
         * time series data (which may also be affected
         * by any alignments specified in the
         * aggregations field); a good duration is long
         * enough so that a single outlier does not
         * generate spurious alerts, but short enough
         * that unhealthy states are detected and
         * alerted on quickly.
         */
        duration: string;
        /**
         * Monitoring Query Language query that outputs a boolean stream.
         */
        query: string;
        /**
         * The number/percent of time series for which
         * the comparison must hold in order for the
         * condition to trigger. If unspecified, then
         * the condition will trigger if the comparison
         * is true for any of the time series that have
         * been identified by filter and aggregations,
         * or by the ratio, if denominatorFilter and
         * denominatorAggregations are specified.
         * Structure is documented below.
         */
        trigger?: outputs.monitoring.AlertPolicyConditionConditionMonitoringQueryLanguageTrigger;
    }

    export interface AlertPolicyConditionConditionMonitoringQueryLanguageTrigger {
        /**
         * The absolute number of time series
         * that must fail the predicate for the
         * condition to be triggered.
         */
        count?: number;
        /**
         * The percentage of time series that
         * must fail the predicate for the
         * condition to be triggered.
         */
        percent?: number;
    }

    export interface AlertPolicyConditionConditionThreshold {
        /**
         * Specifies the alignment of data points in
         * individual time series as well as how to
         * combine the retrieved time series together
         * (such as when aggregating multiple streams
         * on each resource to a single stream for each
         * resource or when aggregating streams across
         * all members of a group of resources).
         * Multiple aggregations are applied in the
         * order specified.This field is similar to the
         * one in the MetricService.ListTimeSeries
         * request. It is advisable to use the
         * ListTimeSeries method when debugging this
         * field.
         * Structure is documented below.
         */
        aggregations?: outputs.monitoring.AlertPolicyConditionConditionThresholdAggregation[];
        /**
         * The comparison to apply between the time
         * series (indicated by filter and aggregation)
         * and the threshold (indicated by
         * threshold_value). The comparison is applied
         * on each time series, with the time series on
         * the left-hand side and the threshold on the
         * right-hand side. Only COMPARISON_LT and
         * COMPARISON_GT are supported currently.
         * Possible values are `COMPARISON_GT`, `COMPARISON_GE`, `COMPARISON_LT`, `COMPARISON_LE`, `COMPARISON_EQ`, and `COMPARISON_NE`.
         */
        comparison: string;
        /**
         * Specifies the alignment of data points in
         * individual time series selected by
         * denominatorFilter as well as how to combine
         * the retrieved time series together (such as
         * when aggregating multiple streams on each
         * resource to a single stream for each
         * resource or when aggregating streams across
         * all members of a group of resources).When
         * computing ratios, the aggregations and
         * denominatorAggregations fields must use the
         * same alignment period and produce time
         * series that have the same periodicity and
         * labels.This field is similar to the one in
         * the MetricService.ListTimeSeries request. It
         * is advisable to use the ListTimeSeries
         * method when debugging this field.
         * Structure is documented below.
         */
        denominatorAggregations?: outputs.monitoring.AlertPolicyConditionConditionThresholdDenominatorAggregation[];
        /**
         * A filter that identifies a time series that
         * should be used as the denominator of a ratio
         * that will be compared with the threshold. If
         * a denominatorFilter is specified, the time
         * series specified by the filter field will be
         * used as the numerator.The filter is similar
         * to the one that is specified in the
         * MetricService.ListTimeSeries request (that
         * call is useful to verify the time series
         * that will be retrieved / processed) and must
         * specify the metric type and optionally may
         * contain restrictions on resource type,
         * resource labels, and metric labels. This
         * field may not exceed 2048 Unicode characters
         * in length.
         */
        denominatorFilter?: string;
        /**
         * The amount of time that a time series must
         * violate the threshold to be considered
         * failing. Currently, only values that are a
         * multiple of a minute--e.g., 0, 60, 120, or
         * 300 seconds--are supported. If an invalid
         * value is given, an error will be returned.
         * When choosing a duration, it is useful to
         * keep in mind the frequency of the underlying
         * time series data (which may also be affected
         * by any alignments specified in the
         * aggregations field); a good duration is long
         * enough so that a single outlier does not
         * generate spurious alerts, but short enough
         * that unhealthy states are detected and
         * alerted on quickly.
         */
        duration: string;
        /**
         * A logs-based filter.
         */
        filter?: string;
        /**
         * A value against which to compare the time
         * series.
         */
        thresholdValue?: number;
        /**
         * The number/percent of time series for which
         * the comparison must hold in order for the
         * condition to trigger. If unspecified, then
         * the condition will trigger if the comparison
         * is true for any of the time series that have
         * been identified by filter and aggregations,
         * or by the ratio, if denominatorFilter and
         * denominatorAggregations are specified.
         * Structure is documented below.
         */
        trigger?: outputs.monitoring.AlertPolicyConditionConditionThresholdTrigger;
    }

    export interface AlertPolicyConditionConditionThresholdAggregation {
        /**
         * The alignment period for per-time
         * series alignment. If present,
         * alignmentPeriod must be at least
         * 60 seconds. After per-time series
         * alignment, each time series will
         * contain data points only on the
         * period boundaries. If
         * perSeriesAligner is not specified
         * or equals ALIGN_NONE, then this
         * field is ignored. If
         * perSeriesAligner is specified and
         * does not equal ALIGN_NONE, then
         * this field must be defined;
         * otherwise an error is returned.
         */
        alignmentPeriod?: string;
        /**
         * The approach to be used to combine
         * time series. Not all reducer
         * functions may be applied to all
         * time series, depending on the
         * metric type and the value type of
         * the original time series.
         * Reduction may change the metric
         * type of value type of the time
         * series.Time series data must be
         * aligned in order to perform cross-
         * time series reduction. If
         * crossSeriesReducer is specified,
         * then perSeriesAligner must be
         * specified and not equal ALIGN_NONE
         * and alignmentPeriod must be
         * specified; otherwise, an error is
         * returned.
         * Possible values are `REDUCE_NONE`, `REDUCE_MEAN`, `REDUCE_MIN`, `REDUCE_MAX`, `REDUCE_SUM`, `REDUCE_STDDEV`, `REDUCE_COUNT`, `REDUCE_COUNT_TRUE`, `REDUCE_COUNT_FALSE`, `REDUCE_FRACTION_TRUE`, `REDUCE_PERCENTILE_99`, `REDUCE_PERCENTILE_95`, `REDUCE_PERCENTILE_50`, and `REDUCE_PERCENTILE_05`.
         */
        crossSeriesReducer?: string;
        /**
         * The set of fields to preserve when
         * crossSeriesReducer is specified.
         * The groupByFields determine how
         * the time series are partitioned
         * into subsets prior to applying the
         * aggregation function. Each subset
         * contains time series that have the
         * same value for each of the
         * grouping fields. Each individual
         * time series is a member of exactly
         * one subset. The crossSeriesReducer
         * is applied to each subset of time
         * series. It is not possible to
         * reduce across different resource
         * types, so this field implicitly
         * contains resource.type. Fields not
         * specified in groupByFields are
         * aggregated away. If groupByFields
         * is not specified and all the time
         * series have the same resource
         * type, then the time series are
         * aggregated into a single output
         * time series. If crossSeriesReducer
         * is not defined, this field is
         * ignored.
         */
        groupByFields?: string[];
        /**
         * The approach to be used to align
         * individual time series. Not all
         * alignment functions may be applied
         * to all time series, depending on
         * the metric type and value type of
         * the original time series.
         * Alignment may change the metric
         * type or the value type of the time
         * series.Time series data must be
         * aligned in order to perform cross-
         * time series reduction. If
         * crossSeriesReducer is specified,
         * then perSeriesAligner must be
         * specified and not equal ALIGN_NONE
         * and alignmentPeriod must be
         * specified; otherwise, an error is
         * returned.
         * Possible values are `ALIGN_NONE`, `ALIGN_DELTA`, `ALIGN_RATE`, `ALIGN_INTERPOLATE`, `ALIGN_NEXT_OLDER`, `ALIGN_MIN`, `ALIGN_MAX`, `ALIGN_MEAN`, `ALIGN_COUNT`, `ALIGN_SUM`, `ALIGN_STDDEV`, `ALIGN_COUNT_TRUE`, `ALIGN_COUNT_FALSE`, `ALIGN_FRACTION_TRUE`, `ALIGN_PERCENTILE_99`, `ALIGN_PERCENTILE_95`, `ALIGN_PERCENTILE_50`, `ALIGN_PERCENTILE_05`, and `ALIGN_PERCENT_CHANGE`.
         */
        perSeriesAligner?: string;
    }

    export interface AlertPolicyConditionConditionThresholdDenominatorAggregation {
        /**
         * The alignment period for per-time
         * series alignment. If present,
         * alignmentPeriod must be at least
         * 60 seconds. After per-time series
         * alignment, each time series will
         * contain data points only on the
         * period boundaries. If
         * perSeriesAligner is not specified
         * or equals ALIGN_NONE, then this
         * field is ignored. If
         * perSeriesAligner is specified and
         * does not equal ALIGN_NONE, then
         * this field must be defined;
         * otherwise an error is returned.
         */
        alignmentPeriod?: string;
        /**
         * The approach to be used to combine
         * time series. Not all reducer
         * functions may be applied to all
         * time series, depending on the
         * metric type and the value type of
         * the original time series.
         * Reduction may change the metric
         * type of value type of the time
         * series.Time series data must be
         * aligned in order to perform cross-
         * time series reduction. If
         * crossSeriesReducer is specified,
         * then perSeriesAligner must be
         * specified and not equal ALIGN_NONE
         * and alignmentPeriod must be
         * specified; otherwise, an error is
         * returned.
         * Possible values are `REDUCE_NONE`, `REDUCE_MEAN`, `REDUCE_MIN`, `REDUCE_MAX`, `REDUCE_SUM`, `REDUCE_STDDEV`, `REDUCE_COUNT`, `REDUCE_COUNT_TRUE`, `REDUCE_COUNT_FALSE`, `REDUCE_FRACTION_TRUE`, `REDUCE_PERCENTILE_99`, `REDUCE_PERCENTILE_95`, `REDUCE_PERCENTILE_50`, and `REDUCE_PERCENTILE_05`.
         */
        crossSeriesReducer?: string;
        /**
         * The set of fields to preserve when
         * crossSeriesReducer is specified.
         * The groupByFields determine how
         * the time series are partitioned
         * into subsets prior to applying the
         * aggregation function. Each subset
         * contains time series that have the
         * same value for each of the
         * grouping fields. Each individual
         * time series is a member of exactly
         * one subset. The crossSeriesReducer
         * is applied to each subset of time
         * series. It is not possible to
         * reduce across different resource
         * types, so this field implicitly
         * contains resource.type. Fields not
         * specified in groupByFields are
         * aggregated away. If groupByFields
         * is not specified and all the time
         * series have the same resource
         * type, then the time series are
         * aggregated into a single output
         * time series. If crossSeriesReducer
         * is not defined, this field is
         * ignored.
         */
        groupByFields?: string[];
        /**
         * The approach to be used to align
         * individual time series. Not all
         * alignment functions may be applied
         * to all time series, depending on
         * the metric type and value type of
         * the original time series.
         * Alignment may change the metric
         * type or the value type of the time
         * series.Time series data must be
         * aligned in order to perform cross-
         * time series reduction. If
         * crossSeriesReducer is specified,
         * then perSeriesAligner must be
         * specified and not equal ALIGN_NONE
         * and alignmentPeriod must be
         * specified; otherwise, an error is
         * returned.
         * Possible values are `ALIGN_NONE`, `ALIGN_DELTA`, `ALIGN_RATE`, `ALIGN_INTERPOLATE`, `ALIGN_NEXT_OLDER`, `ALIGN_MIN`, `ALIGN_MAX`, `ALIGN_MEAN`, `ALIGN_COUNT`, `ALIGN_SUM`, `ALIGN_STDDEV`, `ALIGN_COUNT_TRUE`, `ALIGN_COUNT_FALSE`, `ALIGN_FRACTION_TRUE`, `ALIGN_PERCENTILE_99`, `ALIGN_PERCENTILE_95`, `ALIGN_PERCENTILE_50`, `ALIGN_PERCENTILE_05`, and `ALIGN_PERCENT_CHANGE`.
         */
        perSeriesAligner?: string;
    }

    export interface AlertPolicyConditionConditionThresholdTrigger {
        /**
         * The absolute number of time series
         * that must fail the predicate for the
         * condition to be triggered.
         */
        count?: number;
        /**
         * The percentage of time series that
         * must fail the predicate for the
         * condition to be triggered.
         */
        percent?: number;
    }

    export interface AlertPolicyCreationRecord {
        mutateTime: string;
        mutatedBy: string;
    }

    export interface AlertPolicyDocumentation {
        /**
         * The text of the documentation, interpreted according to mimeType.
         * The content may not exceed 8,192 Unicode characters and may not
         * exceed more than 10,240 bytes when encoded in UTF-8 format,
         * whichever is smaller.
         */
        content?: string;
        /**
         * The format of the content field. Presently, only the value
         * "text/markdown" is supported.
         */
        mimeType?: string;
    }

    export interface CustomServiceTelemetry {
        /**
         * The full name of the resource that defines this service.
         * Formatted as described in
         * https://cloud.google.com/apis/design/resource_names.
         */
        resourceName?: string;
    }

    export interface GetAppEngineServiceTelemetry {
        resourceName: string;
    }

    export interface GetClusterIstioServiceTelemetry {
        resourceName: string;
    }

    export interface GetIstioCanonicalServiceTelemetry {
        resourceName: string;
    }

    export interface GetMeshIstioServiceTelemetry {
        resourceName: string;
    }

    export interface GetNotificationChannelSensitiveLabel {
        authToken: string;
        password: string;
        serviceKey: string;
    }

    export interface GetUptimeCheckIPsUptimeCheckIp {
        /**
         * The IP address from which the Uptime check originates. This is a fully specified IP address
         * (not an IP address range). Most IP addresses, as of this publication, are in IPv4 format; however, one should not
         * rely on the IP addresses being in IPv4 format indefinitely, and should support interpreting this field in either
         * IPv4 or IPv6 format.
         */
        ipAddress: string;
        /**
         * A more specific location within the region that typically encodes a particular city/town/metro
         * (and its containing state/province or country) within the broader umbrella region category.
         */
        location: string;
        /**
         * A broad region category in which the IP address is located.
         */
        region: string;
    }

    export interface MetricDescriptorLabel {
        /**
         * A human-readable description for the label.
         */
        description?: string;
        /**
         * The key for this label. The key must not exceed 100 characters. The first character of the key must be an upper- or lower-case letter, the remaining characters must be letters, digits or underscores, and the key must match the regular expression [a-zA-Z][a-zA-Z0-9_]*
         */
        key: string;
        /**
         * The type of data that can be assigned to the label.
         * Default value is `STRING`.
         * Possible values are `STRING`, `BOOL`, and `INT64`.
         */
        valueType?: string;
    }

    export interface MetricDescriptorMetadata {
        /**
         * The delay of data points caused by ingestion. Data points older than this age are guaranteed to be ingested and available to be read, excluding data loss due to errors. In `[duration format](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf?&_ga=2.264881487.1507873253.1593446723-935052455.1591817775#google.protobuf.Duration)`.
         */
        ingestDelay?: string;
        /**
         * The sampling period of metric data points. For metrics which are written periodically, consecutive data points are stored at this time interval, excluding data loss due to errors. Metrics with a higher granularity have a smaller sampling period. In `[duration format](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf?&_ga=2.264881487.1507873253.1593446723-935052455.1591817775#google.protobuf.Duration)`.
         */
        samplePeriod?: string;
    }

    export interface NotificationChannelSensitiveLabels {
        /**
         * An authorization token for a notification channel. Channel types that support this field include: slack
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        authToken?: string;
        /**
         * An password for a notification channel. Channel types that support this field include: webhookBasicauth
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        password?: string;
        /**
         * An servicekey token for a notification channel. Channel types that support this field include: pagerduty
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        serviceKey?: string;
    }

    export interface SloBasicSli {
        /**
         * Availability based SLI, dervied from count of requests made to this service that return successfully.
         * Structure is documented below.
         */
        availability?: outputs.monitoring.SloBasicSliAvailability;
        /**
         * Parameters for a latency threshold SLI.
         * Structure is documented below.
         */
        latency?: outputs.monitoring.SloBasicSliLatency;
        /**
         * An optional set of locations to which this SLI is relevant.
         * Telemetry from other locations will not be used to calculate
         * performance for this SLI. If omitted, this SLI applies to all
         * locations in which the Service has activity. For service types
         * that don't support breaking down by location, setting this
         * field will result in an error.
         */
        locations?: string[];
        /**
         * An optional set of RPCs to which this SLI is relevant.
         * Telemetry from other methods will not be used to calculate
         * performance for this SLI. If omitted, this SLI applies to all
         * the Service's methods. For service types that don't support
         * breaking down by method, setting this field will result in an
         * error.
         */
        methods?: string[];
        /**
         * The set of API versions to which this SLI is relevant.
         * Telemetry from other API versions will not be used to
         * calculate performance for this SLI. If omitted,
         * this SLI applies to all API versions. For service types
         * that don't support breaking down by version, setting this
         * field will result in an error.
         */
        versions?: string[];
    }

    export interface SloBasicSliAvailability {
        /**
         * Whether an availability SLI is enabled or not. Must be set to `true. Defaults to `true`.
         */
        enabled?: boolean;
    }

    export interface SloBasicSliLatency {
        /**
         * A duration string, e.g. 10s.
         * Good service is defined to be the count of requests made to
         * this service that return in no more than threshold.
         */
        threshold: string;
    }

    export interface SloRequestBasedSli {
        /**
         * Used when goodService is defined by a count of values aggregated in a
         * Distribution that fall into a good range. The totalService is the
         * total count of all values aggregated in the Distribution.
         * Defines a distribution TimeSeries filter and thresholds used for
         * measuring good service and total service.
         * Structure is documented below.
         */
        distributionCut?: outputs.monitoring.SloRequestBasedSliDistributionCut;
        /**
         * A means to compute a ratio of `goodService` to `totalService`.
         * Defines computing this ratio with two TimeSeries [monitoring filters](https://cloud.google.com/monitoring/api/v3/filters)
         * Must specify exactly two of good, bad, and total service filters.
         * The relationship goodService + badService = totalService
         * will be assumed.
         * Structure is documented below.
         */
        goodTotalRatio?: outputs.monitoring.SloRequestBasedSliGoodTotalRatio;
    }

    export interface SloRequestBasedSliDistributionCut {
        /**
         * A TimeSeries [monitoring filter](https://cloud.google.com/monitoring/api/v3/filters)
         * aggregating values to quantify the good service provided.
         * Must have ValueType = DISTRIBUTION and
         * MetricKind = DELTA or MetricKind = CUMULATIVE.
         */
        distributionFilter: string;
        /**
         * Range of numerical values. The computed goodService
         * will be the count of values x in the Distribution such
         * that range.min <= x <= range.max. inclusive of min and
         * max. Open ranges can be defined by setting
         * just one of min or max. Summed value `X` should satisfy
         * `range.min <= X <= range.max` for a good window.
         * Structure is documented below.
         */
        range: outputs.monitoring.SloRequestBasedSliDistributionCutRange;
    }

    export interface SloRequestBasedSliDistributionCutRange {
        /**
         * max value for the range (inclusive). If not given,
         * will be set to "infinity", defining an open range
         * ">= range.min"
         */
        max?: number;
        /**
         * Min value for the range (inclusive). If not given,
         * will be set to "-infinity", defining an open range
         * "< range.max"
         */
        min?: number;
    }

    export interface SloRequestBasedSliGoodTotalRatio {
        /**
         * A TimeSeries [monitoring filter](https://cloud.google.com/monitoring/api/v3/filters)
         * quantifying bad service provided, either demanded service that
         * was not provided or demanded service that was of inadequate
         * quality. Exactly two of
         * good, bad, or total service filter must be defined (where
         * good + bad = total is assumed)
         * Must have ValueType = DOUBLE or ValueType = INT64 and
         * must have MetricKind = DELTA or MetricKind = CUMULATIVE.
         */
        badServiceFilter?: string;
        /**
         * A TimeSeries [monitoring filter](https://cloud.google.com/monitoring/api/v3/filters)
         * quantifying good service provided. Exactly two of
         * good, bad, or total service filter must be defined (where
         * good + bad = total is assumed)
         * Must have ValueType = DOUBLE or ValueType = INT64 and
         * must have MetricKind = DELTA or MetricKind = CUMULATIVE.
         */
        goodServiceFilter?: string;
        /**
         * A TimeSeries [monitoring filter](https://cloud.google.com/monitoring/api/v3/filters)
         * quantifying total demanded service. Exactly two of
         * good, bad, or total service filter must be defined (where
         * good + bad = total is assumed)
         * Must have ValueType = DOUBLE or ValueType = INT64 and
         * must have MetricKind = DELTA or MetricKind = CUMULATIVE.
         */
        totalServiceFilter?: string;
    }

    export interface SloWindowsBasedSli {
        /**
         * A TimeSeries [monitoring filter](https://cloud.google.com/monitoring/api/v3/filters)
         * with ValueType = BOOL. The window is good if any true values
         * appear in the window. One of `goodBadMetricFilter`,
         * `goodTotalRatioThreshold`, `metricMeanInRange`,
         * `metricSumInRange` must be set for `windowsBasedSli`.
         */
        goodBadMetricFilter?: string;
        /**
         * Criterion that describes a window as good if its performance is
         * high enough. One of `goodBadMetricFilter`,
         * `goodTotalRatioThreshold`, `metricMeanInRange`,
         * `metricSumInRange` must be set for `windowsBasedSli`.
         * Structure is documented below.
         */
        goodTotalRatioThreshold?: outputs.monitoring.SloWindowsBasedSliGoodTotalRatioThreshold;
        /**
         * Criterion that describes a window as good if the metric's value
         * is in a good range, *averaged* across returned streams.
         * One of `goodBadMetricFilter`,
         * `goodTotalRatioThreshold`, `metricMeanInRange`,
         * `metricSumInRange` must be set for `windowsBasedSli`.
         * Average value X of `timeSeries` should satisfy
         * `range.min <= X <= range.max` for a good window.
         * Structure is documented below.
         */
        metricMeanInRange?: outputs.monitoring.SloWindowsBasedSliMetricMeanInRange;
        /**
         * Criterion that describes a window as good if the metric's value
         * is in a good range, *summed* across returned streams.
         * Summed value `X` of `timeSeries` should satisfy
         * `range.min <= X <= range.max` for a good window.
         * One of `goodBadMetricFilter`,
         * `goodTotalRatioThreshold`, `metricMeanInRange`,
         * `metricSumInRange` must be set for `windowsBasedSli`.
         * Structure is documented below.
         */
        metricSumInRange?: outputs.monitoring.SloWindowsBasedSliMetricSumInRange;
        /**
         * Duration over which window quality is evaluated, given as a
         * duration string "{X}s" representing X seconds. Must be an
         * integer fraction of a day and at least 60s.
         */
        windowPeriod?: string;
    }

    export interface SloWindowsBasedSliGoodTotalRatioThreshold {
        /**
         * Basic SLI to evaluate to judge window quality.
         * Structure is documented below.
         */
        basicSliPerformance?: outputs.monitoring.SloWindowsBasedSliGoodTotalRatioThresholdBasicSliPerformance;
        /**
         * Request-based SLI to evaluate to judge window quality.
         * Structure is documented below.
         */
        performance?: outputs.monitoring.SloWindowsBasedSliGoodTotalRatioThresholdPerformance;
        /**
         * A duration string, e.g. 10s.
         * Good service is defined to be the count of requests made to
         * this service that return in no more than threshold.
         */
        threshold?: number;
    }

    export interface SloWindowsBasedSliGoodTotalRatioThresholdBasicSliPerformance {
        /**
         * Availability based SLI, dervied from count of requests made to this service that return successfully.
         * Structure is documented below.
         */
        availability?: outputs.monitoring.SloWindowsBasedSliGoodTotalRatioThresholdBasicSliPerformanceAvailability;
        /**
         * Parameters for a latency threshold SLI.
         * Structure is documented below.
         */
        latency?: outputs.monitoring.SloWindowsBasedSliGoodTotalRatioThresholdBasicSliPerformanceLatency;
        /**
         * An optional set of locations to which this SLI is relevant.
         * Telemetry from other locations will not be used to calculate
         * performance for this SLI. If omitted, this SLI applies to all
         * locations in which the Service has activity. For service types
         * that don't support breaking down by location, setting this
         * field will result in an error.
         */
        locations?: string[];
        /**
         * An optional set of RPCs to which this SLI is relevant.
         * Telemetry from other methods will not be used to calculate
         * performance for this SLI. If omitted, this SLI applies to all
         * the Service's methods. For service types that don't support
         * breaking down by method, setting this field will result in an
         * error.
         */
        methods?: string[];
        /**
         * The set of API versions to which this SLI is relevant.
         * Telemetry from other API versions will not be used to
         * calculate performance for this SLI. If omitted,
         * this SLI applies to all API versions. For service types
         * that don't support breaking down by version, setting this
         * field will result in an error.
         */
        versions?: string[];
    }

    export interface SloWindowsBasedSliGoodTotalRatioThresholdBasicSliPerformanceAvailability {
        /**
         * Whether an availability SLI is enabled or not. Must be set to `true. Defaults to `true`.
         */
        enabled?: boolean;
    }

    export interface SloWindowsBasedSliGoodTotalRatioThresholdBasicSliPerformanceLatency {
        /**
         * A duration string, e.g. 10s.
         * Good service is defined to be the count of requests made to
         * this service that return in no more than threshold.
         */
        threshold: string;
    }

    export interface SloWindowsBasedSliGoodTotalRatioThresholdPerformance {
        /**
         * Used when goodService is defined by a count of values aggregated in a
         * Distribution that fall into a good range. The totalService is the
         * total count of all values aggregated in the Distribution.
         * Defines a distribution TimeSeries filter and thresholds used for
         * measuring good service and total service.
         * Structure is documented below.
         */
        distributionCut?: outputs.monitoring.SloWindowsBasedSliGoodTotalRatioThresholdPerformanceDistributionCut;
        /**
         * A means to compute a ratio of `goodService` to `totalService`.
         * Defines computing this ratio with two TimeSeries [monitoring filters](https://cloud.google.com/monitoring/api/v3/filters)
         * Must specify exactly two of good, bad, and total service filters.
         * The relationship goodService + badService = totalService
         * will be assumed.
         * Structure is documented below.
         */
        goodTotalRatio?: outputs.monitoring.SloWindowsBasedSliGoodTotalRatioThresholdPerformanceGoodTotalRatio;
    }

    export interface SloWindowsBasedSliGoodTotalRatioThresholdPerformanceDistributionCut {
        /**
         * A TimeSeries [monitoring filter](https://cloud.google.com/monitoring/api/v3/filters)
         * aggregating values to quantify the good service provided.
         * Must have ValueType = DISTRIBUTION and
         * MetricKind = DELTA or MetricKind = CUMULATIVE.
         */
        distributionFilter: string;
        /**
         * Range of numerical values. The computed goodService
         * will be the count of values x in the Distribution such
         * that range.min <= x <= range.max. inclusive of min and
         * max. Open ranges can be defined by setting
         * just one of min or max. Summed value `X` should satisfy
         * `range.min <= X <= range.max` for a good window.
         * Structure is documented below.
         */
        range: outputs.monitoring.SloWindowsBasedSliGoodTotalRatioThresholdPerformanceDistributionCutRange;
    }

    export interface SloWindowsBasedSliGoodTotalRatioThresholdPerformanceDistributionCutRange {
        /**
         * max value for the range (inclusive). If not given,
         * will be set to "infinity", defining an open range
         * ">= range.min"
         */
        max?: number;
        /**
         * Min value for the range (inclusive). If not given,
         * will be set to "-infinity", defining an open range
         * "< range.max"
         */
        min?: number;
    }

    export interface SloWindowsBasedSliGoodTotalRatioThresholdPerformanceGoodTotalRatio {
        /**
         * A TimeSeries [monitoring filter](https://cloud.google.com/monitoring/api/v3/filters)
         * quantifying bad service provided, either demanded service that
         * was not provided or demanded service that was of inadequate
         * quality. Exactly two of
         * good, bad, or total service filter must be defined (where
         * good + bad = total is assumed)
         * Must have ValueType = DOUBLE or ValueType = INT64 and
         * must have MetricKind = DELTA or MetricKind = CUMULATIVE.
         */
        badServiceFilter?: string;
        /**
         * A TimeSeries [monitoring filter](https://cloud.google.com/monitoring/api/v3/filters)
         * quantifying good service provided. Exactly two of
         * good, bad, or total service filter must be defined (where
         * good + bad = total is assumed)
         * Must have ValueType = DOUBLE or ValueType = INT64 and
         * must have MetricKind = DELTA or MetricKind = CUMULATIVE.
         */
        goodServiceFilter?: string;
        /**
         * A TimeSeries [monitoring filter](https://cloud.google.com/monitoring/api/v3/filters)
         * quantifying total demanded service. Exactly two of
         * good, bad, or total service filter must be defined (where
         * good + bad = total is assumed)
         * Must have ValueType = DOUBLE or ValueType = INT64 and
         * must have MetricKind = DELTA or MetricKind = CUMULATIVE.
         */
        totalServiceFilter?: string;
    }

    export interface SloWindowsBasedSliMetricMeanInRange {
        /**
         * Range of numerical values. The computed goodService
         * will be the count of values x in the Distribution such
         * that range.min <= x <= range.max. inclusive of min and
         * max. Open ranges can be defined by setting
         * just one of min or max. Summed value `X` should satisfy
         * `range.min <= X <= range.max` for a good window.
         * Structure is documented below.
         */
        range: outputs.monitoring.SloWindowsBasedSliMetricMeanInRangeRange;
        /**
         * A [monitoring filter](https://cloud.google.com/monitoring/api/v3/filters)
         * specifying the TimeSeries to use for evaluating window
         * quality. The provided TimeSeries must have
         * ValueType = INT64 or ValueType = DOUBLE and
         * MetricKind = GAUGE.
         * Summed value `X` should satisfy
         * `range.min <= X <= range.max` for a good window.
         */
        timeSeries: string;
    }

    export interface SloWindowsBasedSliMetricMeanInRangeRange {
        /**
         * max value for the range (inclusive). If not given,
         * will be set to "infinity", defining an open range
         * ">= range.min"
         */
        max?: number;
        /**
         * Min value for the range (inclusive). If not given,
         * will be set to "-infinity", defining an open range
         * "< range.max"
         */
        min?: number;
    }

    export interface SloWindowsBasedSliMetricSumInRange {
        /**
         * Range of numerical values. The computed goodService
         * will be the count of values x in the Distribution such
         * that range.min <= x <= range.max. inclusive of min and
         * max. Open ranges can be defined by setting
         * just one of min or max. Summed value `X` should satisfy
         * `range.min <= X <= range.max` for a good window.
         * Structure is documented below.
         */
        range: outputs.monitoring.SloWindowsBasedSliMetricSumInRangeRange;
        /**
         * A [monitoring filter](https://cloud.google.com/monitoring/api/v3/filters)
         * specifying the TimeSeries to use for evaluating window
         * quality. The provided TimeSeries must have
         * ValueType = INT64 or ValueType = DOUBLE and
         * MetricKind = GAUGE.
         * Summed value `X` should satisfy
         * `range.min <= X <= range.max` for a good window.
         */
        timeSeries: string;
    }

    export interface SloWindowsBasedSliMetricSumInRangeRange {
        /**
         * max value for the range (inclusive). If not given,
         * will be set to "infinity", defining an open range
         * ">= range.min"
         */
        max?: number;
        /**
         * Min value for the range (inclusive). If not given,
         * will be set to "-infinity", defining an open range
         * "< range.max"
         */
        min?: number;
    }

    export interface UptimeCheckConfigContentMatcher {
        /**
         * String or regex content to match (max 1024 bytes)
         */
        content: string;
        /**
         * The type of content matcher that will be applied to the server output, compared to the content string when the check is run.
         * Default value is `CONTAINS_STRING`.
         * Possible values are `CONTAINS_STRING`, `NOT_CONTAINS_STRING`, `MATCHES_REGEX`, and `NOT_MATCHES_REGEX`.
         */
        matcher?: string;
    }

    export interface UptimeCheckConfigHttpCheck {
        /**
         * The authentication information. Optional when creating an HTTP check; defaults to empty.
         * Structure is documented below.
         */
        authInfo?: outputs.monitoring.UptimeCheckConfigHttpCheckAuthInfo;
        /**
         * The request body associated with the HTTP POST request. If contentType is URL_ENCODED, the body passed in must be URL-encoded. Users can provide a Content-Length header via the headers field or the API will do so. If the requestMethod is GET and body is not empty, the API will return an error. The maximum byte size is 1 megabyte. Note - As with all bytes fields JSON representations are base64 encoded. e.g. "foo=bar" in URL-encoded form is "foo%3Dbar" and in base64 encoding is "Zm9vJTI1M0RiYXI=".
         */
        body?: string;
        /**
         * The content type to use for the check.
         * Possible values are `TYPE_UNSPECIFIED` and `URL_ENCODED`.
         */
        contentType?: string;
        /**
         * The list of headers to send as part of the uptime check request. If two headers have the same key and different values, they should be entered as a single header, with the value being a comma-separated list of all the desired values as described at https://www.w3.org/Protocols/rfc2616/rfc2616.txt (page 31). Entering two separate headers with the same key in a Create call will cause the first to be overwritten by the second. The maximum number of headers allowed is 100.
         */
        headers: {[key: string]: string};
        /**
         * Boolean specifying whether to encrypt the header information. Encryption should be specified for any headers related to authentication that you do not wish to be seen when retrieving the configuration. The server will be responsible for encrypting the headers. On Get/List calls, if maskHeaders is set to True then the headers will be obscured with ******.
         */
        maskHeaders?: boolean;
        /**
         * The path to the page to run the check against. Will be combined with the host (specified within the MonitoredResource) and port to construct the full URL. If the provided path does not begin with "/", a "/" will be prepended automatically. Optional (defaults to "/").
         */
        path?: string;
        /**
         * The port to the page to run the check against. Will be combined with host (specified within the MonitoredResource) to construct the full URL.
         */
        port: number;
        /**
         * The HTTP request method to use for the check. If set to METHOD_UNSPECIFIED then requestMethod defaults to GET.
         * Default value is `GET`.
         * Possible values are `METHOD_UNSPECIFIED`, `GET`, and `POST`.
         */
        requestMethod?: string;
        /**
         * If true, use HTTPS instead of HTTP to run the check.
         */
        useSsl?: boolean;
        /**
         * Boolean specifying whether to include SSL certificate validation as a part of the Uptime check. Only applies to checks where monitoredResource is set to uptime_url. If useSsl is false, setting validateSsl to true has no effect.
         */
        validateSsl?: boolean;
    }

    export interface UptimeCheckConfigHttpCheckAuthInfo {
        /**
         * The password to authenticate.
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        password: string;
        /**
         * The username to authenticate.
         */
        username: string;
    }

    export interface UptimeCheckConfigMonitoredResource {
        /**
         * Values for all of the labels listed in the associated monitored resource descriptor. For example, Compute Engine VM instances use the labels "projectId", "instanceId", and "zone".
         */
        labels: {[key: string]: string};
        /**
         * The monitored resource type. This field must match the type field of a MonitoredResourceDescriptor (https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.monitoredResourceDescriptors#MonitoredResourceDescriptor) object. For example, the type of a Compute Engine VM instance is gce_instance. For a list of types, see Monitoring resource types (https://cloud.google.com/monitoring/api/resources) and Logging resource types (https://cloud.google.com/logging/docs/api/v2/resource-list).
         */
        type: string;
    }

    export interface UptimeCheckConfigResourceGroup {
        /**
         * The group of resources being monitored. Should be the `name` of a group
         */
        groupId?: string;
        /**
         * The resource type of the group members.
         * Possible values are `RESOURCE_TYPE_UNSPECIFIED`, `INSTANCE`, and `AWS_ELB_LOAD_BALANCER`.
         */
        resourceType?: string;
    }

    export interface UptimeCheckConfigTcpCheck {
        /**
         * The port to the page to run the check against. Will be combined with host (specified within the MonitoredResource) to construct the full URL.
         */
        port: number;
    }

}

export namespace networkconnectivity {
    export interface HubRoutingVpc {
        uri: string;
    }

    export interface SpokeLinkedInterconnectAttachments {
        /**
         * A value that controls whether site-to-site data transfer is enabled for these resources. Note that data transfer is available only in supported locations.
         */
        siteToSiteDataTransfer: boolean;
        /**
         * The URIs of linked VPN tunnel resources.
         */
        uris: string[];
    }

    export interface SpokeLinkedRouterApplianceInstances {
        /**
         * The list of router appliance instances
         */
        instances: outputs.networkconnectivity.SpokeLinkedRouterApplianceInstancesInstance[];
        /**
         * A value that controls whether site-to-site data transfer is enabled for these resources. Note that data transfer is available only in supported locations.
         */
        siteToSiteDataTransfer: boolean;
    }

    export interface SpokeLinkedRouterApplianceInstancesInstance {
        /**
         * The IP address on the VM to use for peering.
         */
        ipAddress?: string;
        /**
         * The URI of the virtual machine resource
         */
        virtualMachine?: string;
    }

    export interface SpokeLinkedVpnTunnels {
        /**
         * A value that controls whether site-to-site data transfer is enabled for these resources. Note that data transfer is available only in supported locations.
         */
        siteToSiteDataTransfer: boolean;
        /**
         * The URIs of linked VPN tunnel resources.
         */
        uris: string[];
    }

}

export namespace networkmanagement {
    export interface ConnectivityTestDestination {
        /**
         * A Compute Engine instance URI.
         */
        instance?: string;
        /**
         * The IP address of the endpoint, which can be an external or
         * internal IP. An IPv6 address is only allowed when the test's
         * destination is a global load balancer VIP.
         */
        ipAddress?: string;
        /**
         * A Compute Engine network URI.
         */
        network?: string;
        /**
         * The IP protocol port of the endpoint. Only applicable when
         * protocol is TCP or UDP.
         */
        port?: number;
        /**
         * Project ID where the endpoint is located. The Project ID can be
         * derived from the URI if you provide a VM instance or network URI.
         * The following are two cases where you must provide the project ID:
         * 1. Only the IP address is specified, and the IP address is within
         * a GCP project. 2. When you are using Shared VPC and the IP address
         * that you provide is from the service project. In this case, the
         * network that the IP address resides in is defined in the host
         * project.
         */
        projectId?: string;
    }

    export interface ConnectivityTestSource {
        /**
         * A Compute Engine instance URI.
         */
        instance?: string;
        /**
         * The IP address of the endpoint, which can be an external or
         * internal IP. An IPv6 address is only allowed when the test's
         * destination is a global load balancer VIP.
         */
        ipAddress?: string;
        /**
         * A Compute Engine network URI.
         */
        network?: string;
        /**
         * Type of the network where the endpoint is located.
         * Possible values are `GCP_NETWORK` and `NON_GCP_NETWORK`.
         */
        networkType?: string;
        /**
         * The IP protocol port of the endpoint. Only applicable when
         * protocol is TCP or UDP.
         */
        port?: number;
        /**
         * Project ID where the endpoint is located. The Project ID can be
         * derived from the URI if you provide a VM instance or network URI.
         * The following are two cases where you must provide the project ID:
         * 1. Only the IP address is specified, and the IP address is within
         * a GCP project. 2. When you are using Shared VPC and the IP address
         * that you provide is from the service project. In this case, the
         * network that the IP address resides in is defined in the host
         * project.
         */
        projectId?: string;
    }

}

export namespace networkservices {
    export interface EdgeCacheKeysetPublicKey {
        /**
         * The ID of the public key. The ID must be 1-63 characters long, and comply with RFC1035.
         * The name must be 1-64 characters long, and match the regular expression [a-zA-Z][a-zA-Z0-9_-]*
         * which means the first character must be a letter, and all following characters must be a dash, underscore, letter or digit.
         */
        id: string;
        /**
         * The base64-encoded value of the Ed25519 public key. The base64 encoding can be padded (44 bytes) or unpadded (43 bytes).
         * Representations or encodings of the public key other than this will be rejected with an error.
         * **Note**: This property is sensitive and will not be displayed in the plan.
         */
        value: string;
    }

    export interface EdgeCacheOriginTimeout {
        /**
         * The maximum duration to wait for a single origin connection to be established, including DNS lookup, TLS handshake and TCP/QUIC connection establishment.
         * Defaults to 5 seconds. The timeout must be a value between 1s and 15s.
         * The connectTimeout capped by the deadline set by the request's maxAttemptsTimeout.  The last connection attempt may have a smaller connectTimeout in order to adhere to the overall maxAttemptsTimeout.
         */
        connectTimeout?: string;
        /**
         * The maximum time across all connection attempts to the origin, including failover origins, before returning an error to the client. A HTTP 504 will be returned if the timeout is reached before a response is returned.
         * Defaults to 15 seconds. The timeout must be a value between 1s and 30s.
         * If a failoverOrigin is specified, the maxAttemptsTimeout of the first configured origin sets the deadline for all connection attempts across all failoverOrigins.
         */
        maxAttemptsTimeout?: string;
        /**
         * The maximum duration to wait between reads of a single HTTP connection/stream.
         * Defaults to 15 seconds.  The timeout must be a value between 1s and 30s.
         * The readTimeout is capped by the responseTimeout.  All reads of the HTTP connection/stream must be completed by the deadline set by the responseTimeout.
         * If the response headers have already been written to the connection, the response will be truncated and logged.
         */
        readTimeout?: string;
        /**
         * The maximum duration to wait for the last byte of a response to arrive when reading from the HTTP connection/stream.
         * Defaults to 30 seconds. The timeout must be a value between 1s and 120s.
         * The responseTimeout starts after the connection has been established.
         * This also applies to HTTP Chunked Transfer Encoding responses, and/or when an open-ended Range request is made to the origin. Origins that take longer to write additional bytes to the response than the configured responseTimeout will result in an error being returned to the client.
         * If the response headers have already been written to the connection, the response will be truncated and logged.
         */
        responseTimeout?: string;
    }

    export interface EdgeCacheServiceLogConfig {
        /**
         * Specifies whether to enable logging for traffic served by this service.
         */
        enable: boolean;
        /**
         * Configures the sampling rate of requests, where 1.0 means all logged requests are reported and 0.0 means no logged requests are reported. The default value is 1.0, and the value of the field must be in [0, 1].
         * This field can only be specified if logging is enabled for this service.
         */
        sampleRate?: number;
    }

    export interface EdgeCacheServiceRouting {
        /**
         * The list of hostRules to match against. These rules define which hostnames the EdgeCacheService will match against, and which route configurations apply.
         * Structure is documented below.
         */
        hostRules: outputs.networkservices.EdgeCacheServiceRoutingHostRule[];
        /**
         * The name of the pathMatcher associated with this hostRule.
         */
        pathMatchers: outputs.networkservices.EdgeCacheServiceRoutingPathMatcher[];
    }

    export interface EdgeCacheServiceRoutingHostRule {
        /**
         * A human-readable description of the resource.
         */
        description?: string;
        /**
         * The list of host patterns to match.
         * Host patterns must be valid hostnames. Ports are not allowed. Wildcard hosts are supported in the suffix or prefix form. * matches any string of ([a-z0-9-.]*). It does not match the empty string.
         * When multiple hosts are specified, hosts are matched in the following priority:
         * 1. Exact domain names: ``www.foo.com``.
         * 2. Suffix domain wildcards: ``*.foo.com`` or ``*-bar.foo.com``.
         * 3. Prefix domain wildcards: ``foo.*`` or ``foo-*``.
         * 4. Special wildcard ``*`` matching any domain.
         * Notes:
         * The wildcard will not match the empty string. e.g. ``*-bar.foo.com`` will match ``baz-bar.foo.com`` but not ``-bar.foo.com``. The longest wildcards match first. Only a single host in the entire service can match on ``*``. A domain must be unique across all configured hosts within a service.
         * Hosts are matched against the HTTP Host header, or for HTTP/2 and HTTP/3, the ":authority" header, from the incoming request.
         * You may specify up to 10 hosts.
         */
        hosts: string[];
        /**
         * The name of the pathMatcher associated with this hostRule.
         */
        pathMatcher: string;
    }

    export interface EdgeCacheServiceRoutingPathMatcher {
        /**
         * A human-readable description of the resource.
         */
        description?: string;
        /**
         * The name of the query parameter to match. The query parameter must exist in the request, in the absence of which the request match fails.
         */
        name: string;
        /**
         * The routeRules to match against. routeRules support advanced routing behaviour, and can match on paths, headers and query parameters, as well as status codes and HTTP methods.
         * Structure is documented below.
         */
        routeRules: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRule[];
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRule {
        /**
         * A human-readable description of the resource.
         */
        description?: string;
        /**
         * The header actions, including adding & removing headers, for requests that match this route.
         * Structure is documented below.
         */
        headerAction?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleHeaderAction;
        /**
         * The list of criteria for matching attributes of a request to this routeRule. This list has OR semantics: the request matches this routeRule when any of the matchRules are satisfied. However predicates
         * within a given matchRule have AND semantics. All predicates within a matchRule must match for the request to match the rule.
         * Structure is documented below.
         */
        matchRules: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleMatchRule[];
        /**
         * The Origin resource that requests to this route should fetch from when a matching response is not in cache. Origins can be defined as short names ("my-origin") or fully-qualified resource URLs - e.g. "networkservices.googleapis.com/projects/my-project/global/edgecacheorigins/my-origin"
         * Only one of origin or urlRedirect can be set.
         */
        origin?: string;
        /**
         * The priority of this route rule, where 1 is the highest priority.
         * You cannot configure two or more routeRules with the same priority. Priority for each rule must be set to a number between 1 and 999 inclusive.
         * Priority numbers can have gaps, which enable you to add or remove rules in the future without affecting the rest of the rules. For example, 1, 2, 3, 4, 5, 9, 12, 16 is a valid series of priority numbers
         * to which you could add rules numbered from 6 to 8, 10 to 11, and 13 to 15 in the future without any impact on existing rules.
         */
        priority: string;
        /**
         * In response to a matching path, the routeAction performs advanced routing actions like URL rewrites, header transformations, etc. prior to forwarding the request to the selected origin.
         * Structure is documented below.
         */
        routeAction?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleRouteAction;
        /**
         * The URL redirect configuration for requests that match this route.
         * Structure is documented below.
         */
        urlRedirect?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleUrlRedirect;
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleHeaderAction {
        /**
         * Describes a header to add.
         * Structure is documented below.
         */
        requestHeaderToAdds?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleHeaderActionRequestHeaderToAdd[];
        /**
         * A list of header names for headers that need to be removed from the request prior to forwarding the request to the origin.
         * Structure is documented below.
         */
        requestHeaderToRemoves?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleHeaderActionRequestHeaderToRemove[];
        /**
         * Headers to add to the response prior to sending it back to the client.
         * Response headers are only sent to the client, and do not have an effect on the cache serving the response.
         * Structure is documented below.
         */
        responseHeaderToAdds?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleHeaderActionResponseHeaderToAdd[];
        /**
         * A list of header names for headers that need to be removed from the request prior to forwarding the request to the origin.
         * Structure is documented below.
         */
        responseHeaderToRemoves?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleHeaderActionResponseHeaderToRemove[];
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleHeaderActionRequestHeaderToAdd {
        /**
         * Headers to remove from the response prior to sending it back to the client.
         * Response headers are only sent to the client, and do not have an effect on the cache serving the response.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * Whether to replace all existing headers with the same name.
         */
        replace: boolean;
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleHeaderActionRequestHeaderToRemove {
        /**
         * Headers to remove from the response prior to sending it back to the client.
         * Response headers are only sent to the client, and do not have an effect on the cache serving the response.
         */
        headerName: string;
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleHeaderActionResponseHeaderToAdd {
        /**
         * Headers to remove from the response prior to sending it back to the client.
         * Response headers are only sent to the client, and do not have an effect on the cache serving the response.
         */
        headerName: string;
        /**
         * The value of the header to add.
         */
        headerValue: string;
        /**
         * Whether to replace all existing headers with the same name.
         */
        replace: boolean;
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleHeaderActionResponseHeaderToRemove {
        /**
         * Headers to remove from the response prior to sending it back to the client.
         * Response headers are only sent to the client, and do not have an effect on the cache serving the response.
         */
        headerName: string;
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleMatchRule {
        /**
         * For satisfying the matchRule condition, the path of the request must exactly match the value specified in fullPathMatch after removing any query parameters and anchor that may be part of the original URL.
         */
        fullPathMatch?: string;
        /**
         * Specifies a list of header match criteria, all of which must match corresponding headers in the request.
         * Structure is documented below.
         */
        headerMatches?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleMatchRuleHeaderMatch[];
        /**
         * Specifies that prefixMatch and fullPathMatch matches are case sensitive.
         */
        ignoreCase: boolean;
        /**
         * For satisfying the matchRule condition, the path of the request
         * must match the wildcard pattern specified in pathTemplateMatch
         * after removing any query parameters and anchor that may be part
         * of the original URL.
         * pathTemplateMatch must be between 1 and 255 characters
         * (inclusive).  The pattern specified by pathTemplateMatch may
         * have at most 5 wildcard operators and at most 5 variable
         * captures in total.
         */
        pathTemplateMatch?: string;
        /**
         * The value of the header must start with the contents of prefixMatch.
         */
        prefixMatch?: string;
        /**
         * Specifies a list of query parameter match criteria, all of which must match corresponding query parameters in the request.
         * Structure is documented below.
         */
        queryParameterMatches?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleMatchRuleQueryParameterMatch[];
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleMatchRuleHeaderMatch {
        /**
         * The queryParameterMatch matches if the value of the parameter exactly matches the contents of exactMatch.
         */
        exactMatch?: string;
        /**
         * Headers to remove from the response prior to sending it back to the client.
         * Response headers are only sent to the client, and do not have an effect on the cache serving the response.
         */
        headerName: string;
        /**
         * If set to false (default), the headerMatch is considered a match if the match criteria above are met.
         * If set to true, the headerMatch is considered a match if the match criteria above are NOT met.
         */
        invertMatch: boolean;
        /**
         * The value of the header must start with the contents of prefixMatch.
         */
        prefixMatch?: string;
        /**
         * Specifies that the queryParameterMatch matches if the request contains the query parameter, irrespective of whether the parameter has a value or not.
         */
        presentMatch?: boolean;
        /**
         * The value of the header must end with the contents of suffixMatch.
         */
        suffixMatch?: string;
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleMatchRuleQueryParameterMatch {
        /**
         * The queryParameterMatch matches if the value of the parameter exactly matches the contents of exactMatch.
         */
        exactMatch?: string;
        /**
         * The name of the query parameter to match. The query parameter must exist in the request, in the absence of which the request match fails.
         */
        name: string;
        /**
         * Specifies that the queryParameterMatch matches if the request contains the query parameter, irrespective of whether the parameter has a value or not.
         */
        presentMatch?: boolean;
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleRouteAction {
        /**
         * The policy to use for defining caching and signed request behaviour for requests that match this route.
         * Structure is documented below.
         */
        cdnPolicy?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleRouteActionCdnPolicy;
        /**
         * CORSPolicy defines Cross-Origin-Resource-Sharing configuration, including which CORS response headers will be set.
         * Structure is documented below.
         */
        corsPolicy?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleRouteActionCorsPolicy;
        /**
         * The URL rewrite configuration for requests that match this route.
         * Structure is documented below.
         */
        urlRewrite?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleRouteActionUrlRewrite;
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleRouteActionCdnPolicy {
        /**
         * Defines the request parameters that contribute to the cache key.
         * Structure is documented below.
         */
        cacheKeyPolicy?: outputs.networkservices.EdgeCacheServiceRoutingPathMatcherRouteRuleRouteActionCdnPolicyCacheKeyPolicy;
        /**
         * Cache modes allow users to control the behaviour of the cache, what content it should cache automatically, whether to respect origin headers, or whether to unconditionally cache all responses.
         * For all cache modes, Cache-Control headers will be passed to the client. Use clientTtl to override what is sent to the client.
         * Possible values are `CACHE_ALL_STATIC`, `USE_ORIGIN_HEADERS`, `FORCE_CACHE_ALL`, and `BYPASS_CACHE`.
         */
        cacheMode: string;
        /**
         * Specifies a separate client (e.g. browser client) TTL, separate from the TTL used by the edge caches. Leaving this empty will use the same cache TTL for both the CDN and the client-facing response.
         * - The TTL must be > 0 and <= 86400s (1 day)
         * - The clientTtl cannot be larger than the defaultTtl (if set)
         * - Fractions of a second are not allowed.
         * Omit this field to use the defaultTtl, or the max-age set by the origin, as the client-facing TTL.
         * When the cache mode is set to "USE_ORIGIN_HEADERS" or "BYPASS_CACHE", you must omit this field.
         * A duration in seconds terminated by 's'. Example: "3s".
         */
        clientTtl?: string;
        /**
         * Specifies the default TTL for cached content served by this origin for responses that do not have an existing valid TTL (max-age or s-max-age).
         * Defaults to 3600s (1 hour).
         * - The TTL must be >= 0 and <= 31,536,000 seconds (1 year)
         * - Setting a TTL of "0" means "always revalidate" (equivalent to must-revalidate)
         * - The value of defaultTTL cannot be set to a value greater than that of maxTTL.
         * - Fractions of a second are not allowed.
         * - When the cacheMode is set to FORCE_CACHE_ALL, the defaultTTL will overwrite the TTL set in all responses.
         * Note that infrequently accessed objects may be evicted from the cache before the defined TTL. Objects that expire will be revalidated with the origin.
         * When the cache mode is set to "USE_ORIGIN_HEADERS" or "BYPASS_CACHE", you must omit this field.
         * A duration in seconds terminated by 's'. Example: "3s".
         */
        defaultTtl: string;
        /**
         * Specifies the maximum allowed TTL for cached content served by this origin.
         * Defaults to 86400s (1 day).
         * Cache directives that attempt to set a max-age or s-maxage higher than this, or an Expires header more than maxTtl seconds in the future will be capped at the value of maxTTL, as if it were the value of an s-maxage Cache-Control directive.
         * - The TTL must be >= 0 and <= 31,536,000 seconds (1 year)
         * - Setting a TTL of "0" means "always revalidate"
         * - The value of maxTtl must be equal to or greater than defaultTtl.
         * - Fractions of a second are not allowed.
         * When the cache mode is set to "USE_ORIGIN_HEADERS", "FORCE_CACHE_ALL", or "BYPASS_CACHE", you must omit this field.
         * A duration in seconds terminated by 's'. Example: "3s".
         */
        maxTtl: string;
        /**
         * Negative caching allows per-status code TTLs to be set, in order to apply fine-grained caching for common errors or redirects. This can reduce the load on your origin and improve end-user experience by reducing response latency.
         * By default, the CDNPolicy will apply the following default TTLs to these status codes:
         * - HTTP 300 (Multiple Choice), 301, 308 (Permanent Redirects): 10m
         * - HTTP 404 (Not Found), 410 (Gone), 451 (Unavailable For Legal Reasons): 120s
         * - HTTP 405 (Method Not Found), 414 (URI Too Long), 501 (Not Implemented): 60s
         * These defaults can be overridden in negativeCachingPolicy
         */
        negativeCaching?: boolean;
        /**
         * Sets a cache TTL for the specified HTTP status code. negativeCaching must be enabled to configure negativeCachingPolicy.
         * - Omitting the policy and leaving negativeCaching enabled will use the default TTLs for each status code, defined in negativeCaching.
         * - TTLs must be >= 0 (where 0 is "always revalidate") and <= 86400s (1 day)
         * Note that when specifying an explicit negativeCachingPolicy, you should take care to specify a cache TTL for all response codes that you wish to cache. The CDNPolicy will not apply any default negative caching when a policy exists.
         */
        negativeCachingPolicy?: {[key: string]: string};
        /**
         * The EdgeCacheKeyset containing the set of public keys used to validate signed requests at the edge.
         */
        signedRequestKeyset: string;
        /**
         * Whether to enforce signed requests. The default value is DISABLED, which means all content is public, and does not authorize access.
         * You must also set a signedRequestKeyset to enable signed requests.
         * When set to REQUIRE_SIGNATURES, all matching requests will have their signature validated. Requests that were not signed with the corresponding private key, or that are otherwise invalid (expired, do not match the signature, IP address, or header) will be rejected with a HTTP 403 and (if enabled) logged.
         * Possible values are `DISABLED` and `REQUIRE_SIGNATURES`.
         */
        signedRequestMode: string;
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleRouteActionCdnPolicyCacheKeyPolicy {
        /**
         * If true, requests to different hosts will be cached separately.
         * Note: this should only be enabled if hosts share the same origin and content. Removing the host from the cache key may inadvertently result in different objects being cached than intended, depending on which route the first user matched.
         */
        excludeHost: boolean;
        /**
         * If true, exclude query string parameters from the cache key
         * If false (the default), include the query string parameters in
         * the cache key according to includeQueryParameters and
         * excludeQueryParameters. If neither includeQueryParameters nor
         * excludeQueryParameters is set, the entire query string will be
         * included.
         */
        excludeQueryString?: boolean;
        /**
         * Names of query string parameters to exclude from cache keys. All other parameters will be included.
         * Either specify includedQueryParameters or excludedQueryParameters, not both. '&' and '=' will be percent encoded and not treated as delimiters.
         */
        excludedQueryParameters?: string[];
        /**
         * If true, http and https requests will be cached separately.
         */
        includeProtocol: boolean;
        /**
         * Names of Cookies to include in cache keys.  The cookie name and cookie value of each cookie named will be used as part of the cache key.
         * Cookie names:
         * - must be valid RFC 6265 "cookie-name" tokens
         * - are case sensitive
         * - cannot start with "Edge-Cache-" (case insensitive)
         * Note that specifying several cookies, and/or cookies that have a large range of values (e.g., per-user) will dramatically impact the cache hit rate, and may result in a higher eviction rate and reduced performance.
         * You may specify up to three cookie names.
         */
        includedCookieNames?: string[];
        /**
         * Names of HTTP request headers to include in cache keys. The value of the header field will be used as part of the cache key.
         * - Header names must be valid HTTP RFC 7230 header field values.
         * - Header field names are case insensitive
         * - To include the HTTP method, use ":method"
         * Note that specifying several headers, and/or headers that have a large range of values (e.g. per-user) will dramatically impact the cache hit rate, and may result in a higher eviction rate and reduced performance.
         */
        includedHeaderNames?: string[];
        /**
         * Names of query string parameters to include in cache keys. All other parameters will be excluded.
         * Either specify includedQueryParameters or excludedQueryParameters, not both. '&' and '=' will be percent encoded and not treated as delimiters.
         */
        includedQueryParameters?: string[];
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleRouteActionCorsPolicy {
        /**
         * In response to a preflight request, setting this to true indicates that the actual request can include user credentials.
         * This translates to the Access-Control-Allow-Credentials response header.
         */
        allowCredentials?: boolean;
        /**
         * Specifies the content for the Access-Control-Allow-Headers response header.
         */
        allowHeaders?: string[];
        /**
         * Specifies the content for the Access-Control-Allow-Methods response header.
         */
        allowMethods?: string[];
        /**
         * Specifies the list of origins that will be allowed to do CORS requests.
         * This translates to the Access-Control-Allow-Origin response header.
         */
        allowOrigins?: string[];
        /**
         * If true, specifies the CORS policy is disabled. The default value is false, which indicates that the CORS policy is in effect.
         */
        disabled?: boolean;
        /**
         * Specifies the content for the Access-Control-Allow-Headers response header.
         */
        exposeHeaders?: string[];
        /**
         * Specifies how long results of a preflight request can be cached by a client in seconds. Note that many browser clients enforce a maximum TTL of 600s (10 minutes).
         * - Setting the value to -1 forces a pre-flight check for all requests (not recommended)
         * - A maximum TTL of 86400s can be set, but note that (as above) some clients may force pre-flight checks at a more regular interval.
         * - This translates to the Access-Control-Max-Age header.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        maxAge: string;
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleRouteActionUrlRewrite {
        /**
         * Prior to forwarding the request to the selected origin, the request's host header is replaced with contents of hostRewrite.
         */
        hostRewrite?: string;
        /**
         * Prior to forwarding the request to the selected origin, the matching portion of the request's path is replaced by pathPrefixRewrite.
         */
        pathPrefixRewrite?: string;
        /**
         * Prior to forwarding the request to the selected origin, if the
         * request matched a pathTemplateMatch, the matching portion of the
         * request's path is replaced re-written using the pattern specified
         * by pathTemplateRewrite.
         * pathTemplateRewrite must be between 1 and 255 characters
         * (inclusive), must start with a '/', and must only use variables
         * captured by the route's pathTemplate matchers.
         * pathTemplateRewrite may only be used when all of a route's
         * MatchRules specify pathTemplate.
         * Only one of pathPrefixRewrite and pathTemplateRewrite may be
         * specified.
         */
        pathTemplateRewrite?: string;
    }

    export interface EdgeCacheServiceRoutingPathMatcherRouteRuleUrlRedirect {
        /**
         * The host that will be used in the redirect response instead of the one that was supplied in the request.
         */
        hostRedirect?: string;
        /**
         * If set to true, the URL scheme in the redirected request is set to https. If set to false, the URL scheme of the redirected request will remain the same as that of the request.
         * This can only be set if there is at least one (1) edgeSslCertificate set on the service.
         */
        httpsRedirect: boolean;
        /**
         * The path that will be used in the redirect response instead of the one that was supplied in the request.
         * pathRedirect cannot be supplied together with prefixRedirect. Supply one alone or neither. If neither is supplied, the path of the original request will be used for the redirect.
         * The path value must be between 1 and 1024 characters.
         */
        pathRedirect?: string;
        /**
         * The prefix that replaces the prefixMatch specified in the routeRule, retaining the remaining portion of the URL before redirecting the request.
         * prefixRedirect cannot be supplied together with pathRedirect. Supply one alone or neither. If neither is supplied, the path of the original request will be used for the redirect.
         */
        prefixRedirect?: string;
        /**
         * The HTTP Status code to use for this RedirectAction.
         * The supported values are:
         * - `MOVED_PERMANENTLY_DEFAULT`, which is the default value and corresponds to 301.
         * - `FOUND`, which corresponds to 302.
         */
        redirectResponseCode: string;
        /**
         * If set to true, any accompanying query portion of the original URL is removed prior to redirecting the request. If set to false, the query portion of the original URL is retained.
         */
        stripQuery: boolean;
    }

}

export namespace notebooks {
    export interface EnvironmentContainerImage {
        /**
         * The path to the container image repository.
         * For example: gcr.io/{project_id}/{imageName}
         */
        repository: string;
        /**
         * The tag of the container image. If not specified, this defaults to the latest tag.
         */
        tag?: string;
    }

    export interface EnvironmentVmImage {
        /**
         * Use this VM image family to find the image; the newest image in this family will be used.
         */
        imageFamily?: string;
        /**
         * Use VM image name to find the image.
         */
        imageName?: string;
        /**
         * The name of the Google Cloud project that this VM image belongs to.
         * Format: projects/{project_id}
         */
        project: string;
    }

    export interface InstanceAcceleratorConfig {
        /**
         * Count of cores of this accelerator.
         */
        coreCount: number;
        /**
         * Type of this accelerator.
         * Possible values are `ACCELERATOR_TYPE_UNSPECIFIED`, `NVIDIA_TESLA_K80`, `NVIDIA_TESLA_P100`, `NVIDIA_TESLA_V100`, `NVIDIA_TESLA_P4`, `NVIDIA_TESLA_T4`, `NVIDIA_TESLA_T4_VWS`, `NVIDIA_TESLA_P100_VWS`, `NVIDIA_TESLA_P4_VWS`, `NVIDIA_TESLA_A100`, `TPU_V2`, and `TPU_V3`.
         */
        type: string;
    }

    export interface InstanceContainerImage {
        /**
         * The path to the container image repository.
         * For example: gcr.io/{project_id}/{imageName}
         */
        repository: string;
        /**
         * The tag of the container image. If not specified, this defaults to the latest tag.
         */
        tag?: string;
    }

    export interface InstanceIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface InstanceIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface InstanceReservationAffinity {
        /**
         * The type of Compute Reservation.
         * Possible values are `NO_RESERVATION`, `ANY_RESERVATION`, and `SPECIFIC_RESERVATION`.
         */
        consumeReservationType: string;
        /**
         * Corresponds to the label key of reservation resource.
         */
        key?: string;
        /**
         * Corresponds to the label values of reservation resource.
         */
        values?: string[];
    }

    export interface InstanceShieldedInstanceConfig {
        /**
         * Defines whether the instance has integrity monitoring enabled. Enables monitoring and attestation of the
         * boot integrity of the instance. The attestation is performed against the integrity policy baseline.
         * This baseline is initially derived from the implicitly trusted boot image when the instance is created.
         * Enabled by default.
         */
        enableIntegrityMonitoring?: boolean;
        /**
         * Defines whether the instance has Secure Boot enabled. Secure Boot helps ensure that the system only runs
         * authentic software by verifying the digital signature of all boot components, and halting the boot process
         * if signature verification fails.
         * Disabled by default.
         */
        enableSecureBoot?: boolean;
        /**
         * Defines whether the instance has the vTPM enabled.
         * Enabled by default.
         */
        enableVtpm?: boolean;
    }

    export interface InstanceVmImage {
        /**
         * Use this VM image family to find the image; the newest image in this family will be used.
         */
        imageFamily?: string;
        /**
         * Use VM image name to find the image.
         */
        imageName?: string;
        /**
         * The name of the Google Cloud project that this VM image belongs to.
         * Format: projects/{project_id}
         */
        project: string;
    }

    export interface RuntimeAccessConfig {
        /**
         * The type of access mode this instance. For valid values, see
         * `https://cloud.google.com/vertex-ai/docs/workbench/reference/
         * rest/v1/projects.locations.runtimes#RuntimeAccessType`.
         */
        accessType?: string;
        /**
         * -
         * The proxy endpoint that is used to access the runtime.
         */
        proxyUri: string;
        /**
         * The owner of this runtime after creation. Format: `alias@example.com`.
         * Currently supports one owner only.
         */
        runtimeOwner?: string;
    }

    export interface RuntimeIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface RuntimeIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface RuntimeMetric {
        systemMetrics: {[key: string]: string};
    }

    export interface RuntimeSoftwareConfig {
        /**
         * Specify a custom Cloud Storage path where the GPU driver is stored.
         * If not specified, we'll automatically choose from official GPU drivers.
         */
        customGpuDriverPath?: string;
        /**
         * Verifies core internal services are running. Default: True.
         */
        enableHealthMonitoring?: boolean;
        /**
         * Runtime will automatically shutdown after idle_shutdown_time.
         * Default: True
         */
        idleShutdown?: boolean;
        /**
         * Time in minutes to wait before shuting down runtime.
         * Default: 180 minutes
         */
        idleShutdownTimeout?: number;
        /**
         * Install Nvidia Driver automatically.
         */
        installGpuDriver?: boolean;
        /**
         * Cron expression in UTC timezone for schedule instance auto upgrade.
         * Please follow the [cron format](https://en.wikipedia.org/wiki/Cron).
         */
        notebookUpgradeSchedule?: string;
        /**
         * Path to a Bash script that automatically runs after a notebook instance
         * fully boots up. The path must be a URL or
         * Cloud Storage path (gs://path-to-file/file-name).
         */
        postStartupScript?: string;
    }

    export interface RuntimeVirtualMachine {
        /**
         * -
         * The unique identifier of the Managed Compute Engine instance.
         */
        instanceId: string;
        /**
         * -
         * The user-friendly name of the Managed Compute Engine instance.
         */
        instanceName: string;
        /**
         * Virtual Machine configuration settings.
         * Structure is documented below.
         */
        virtualMachineConfig?: outputs.notebooks.RuntimeVirtualMachineVirtualMachineConfig;
    }

    export interface RuntimeVirtualMachineVirtualMachineConfig {
        /**
         * The Compute Engine accelerator configuration for this runtime.
         * Structure is documented below.
         */
        acceleratorConfig?: outputs.notebooks.RuntimeVirtualMachineVirtualMachineConfigAcceleratorConfig;
        /**
         * Use a list of container images to start the notebook instance.
         * Structure is documented below.
         */
        containerImages: outputs.notebooks.RuntimeVirtualMachineVirtualMachineConfigContainerImage[];
        /**
         * Data disk option configuration settings.
         * Structure is documented below.
         */
        dataDisk: outputs.notebooks.RuntimeVirtualMachineVirtualMachineConfigDataDisk;
        /**
         * Encryption settings for virtual machine data disk.
         * Structure is documented below.
         */
        encryptionConfig?: outputs.notebooks.RuntimeVirtualMachineVirtualMachineConfigEncryptionConfig;
        /**
         * -
         * The Compute Engine guest attributes. (see [Project and instance
         * guest attributes](https://cloud.google.com/compute/docs/
         * storing-retrieving-metadata#guest_attributes)).
         */
        guestAttributes: {[key: string]: string};
        /**
         * If true, runtime will only have internal IP addresses. By default,
         * runtimes are not restricted to internal IP addresses, and will
         * have ephemeral external IP addresses assigned to each vm. This
         * `internalIpOnly` restriction can only be enabled for subnetwork
         * enabled networks, and all dependencies must be configured to be
         * accessible without external IP addresses.
         */
        internalIpOnly?: boolean;
        /**
         * Labels to apply to this disk. These can be later modified
         * by the disks.setLabels method. This field is only
         * applicable for persistent disks.
         */
        labels: {[key: string]: string};
        /**
         * The Compute Engine machine type used for runtimes.
         */
        machineType: string;
        /**
         * The Compute Engine metadata entries to add to virtual machine.
         * (see [Project and instance metadata](https://cloud.google.com
         * /compute/docs/storing-retrieving-metadata#project_and_instance
         * _metadata)).
         */
        metadata: {[key: string]: string};
        /**
         * The Compute Engine network to be used for machine communications.
         * Cannot be specified with subnetwork. If neither `network` nor
         * `subnet` is specified, the "default" network of the project is
         * used, if it exists. A full URL or partial URI. Examples:
         * * `https://www.googleapis.com/compute/v1/projects/[projectId]/
         * regions/global/default`
         * * `projects/[projectId]/regions/global/default`
         * Runtimes are managed resources inside Google Infrastructure.
         * Runtimes support the following network configurations:
         * * Google Managed Network (Network & subnet are empty)
         * * Consumer Project VPC (network & subnet are required). Requires
         * configuring Private Service Access.
         * * Shared VPC (network & subnet are required). Requires
         * configuring Private Service Access.
         */
        network?: string;
        /**
         * The type of vNIC to be used on this interface. This may be gVNIC
         * or VirtioNet.
         * Possible values are `UNSPECIFIED_NIC_TYPE`, `VIRTIO_NET`, and `GVNIC`.
         */
        nicType?: string;
        /**
         * Shielded VM Instance configuration settings.
         * Structure is documented below.
         */
        shieldedInstanceConfig?: outputs.notebooks.RuntimeVirtualMachineVirtualMachineConfigShieldedInstanceConfig;
        /**
         * The Compute Engine subnetwork to be used for machine
         * communications. Cannot be specified with network. A full URL or
         * partial URI are valid. Examples:
         * * `https://www.googleapis.com/compute/v1/projects/[projectId]/
         * regions/us-east1/subnetworks/sub0`
         * * `projects/[projectId]/regions/us-east1/subnetworks/sub0`
         */
        subnet?: string;
        /**
         * The Compute Engine tags to add to runtime (see [Tagging instances]
         * (https://cloud.google.com/compute/docs/
         * label-or-tag-resources#tags)).
         */
        tags: string[];
        /**
         * -
         * The zone where the virtual machine is located.
         */
        zone: string;
    }

    export interface RuntimeVirtualMachineVirtualMachineConfigAcceleratorConfig {
        /**
         * Count of cores of this accelerator.
         */
        coreCount?: number;
        /**
         * Accelerator model. For valid values, see
         * `https://cloud.google.com/vertex-ai/docs/workbench/reference/
         * rest/v1/projects.locations.runtimes#AcceleratorType`
         */
        type?: string;
    }

    export interface RuntimeVirtualMachineVirtualMachineConfigContainerImage {
        /**
         * The path to the container image repository.
         * For example: gcr.io/{project_id}/{imageName}
         */
        repository: string;
        /**
         * The tag of the container image. If not specified, this defaults to the latest tag.
         */
        tag?: string;
    }

    export interface RuntimeVirtualMachineVirtualMachineConfigDataDisk {
        /**
         * -
         * Optional. Specifies whether the disk will be auto-deleted
         * when the instance is deleted (but not when the disk is
         * detached from the instance).
         */
        autoDelete: boolean;
        /**
         * -
         * Optional. Indicates that this is a boot disk. The virtual
         * machine will use the first partition of the disk for its
         * root filesystem.
         */
        boot: boolean;
        /**
         * -
         * Optional. Specifies a unique device name of your choice
         * that is reflected into the /dev/disk/by-id/google-* tree
         * of a Linux operating system running within the instance.
         * This name can be used to reference the device for mounting,
         * resizing, and so on, from within the instance.
         * If not specified, the server chooses a default device name
         * to apply to this disk, in the form persistent-disk-x, where
         * x is a number assigned by Google Compute Engine. This field
         * is only applicable for persistent disks.
         */
        deviceName: string;
        /**
         * -
         * Indicates a list of features to enable on the guest operating
         * system. Applicable only for bootable images. To see a list of
         * available features, read `https://cloud.google.com/compute/docs/
         * images/create-delete-deprecate-private-images#guest-os-features`
         * options. ``
         */
        guestOsFeatures: string[];
        /**
         * -
         * Output only. A zero-based index to this disk, where 0 is
         * reserved for the boot disk. If you have many disks attached
         * to an instance, each disk would have a unique index number.
         */
        index: number;
        /**
         * Input only. Specifies the parameters for a new disk that will
         * be created alongside the new instance. Use initialization
         * parameters to create boot disks or local SSDs attached to the
         * new instance. This property is mutually exclusive with the
         * source property; you can only define one or the other, but not
         * both.
         * Structure is documented below.
         */
        initializeParams?: outputs.notebooks.RuntimeVirtualMachineVirtualMachineConfigDataDiskInitializeParams;
        /**
         * "Specifies the disk interface to use for attaching this disk,
         * which is either SCSI or NVME. The default is SCSI. Persistent
         * disks must always use SCSI and the request will fail if you attempt
         * to attach a persistent disk in any other format than SCSI. Local SSDs
         * can use either NVME or SCSI. For performance characteristics of SCSI
         * over NVMe, see Local SSD performance. Valid values: * NVME * SCSI".
         */
        interface?: string;
        /**
         * -
         * Type of the resource. Always compute#attachedDisk for attached
         * disks.
         */
        kind: string;
        /**
         * -
         * Output only. Any valid publicly visible licenses.
         */
        licenses: string[];
        /**
         * The mode in which to attach this disk, either READ_WRITE
         * or READ_ONLY. If not specified, the default is to attach
         * the disk in READ_WRITE mode.
         */
        mode?: string;
        /**
         * Specifies a valid partial or full URL to an existing
         * Persistent Disk resource.
         */
        source?: string;
        /**
         * Accelerator model. For valid values, see
         * `https://cloud.google.com/vertex-ai/docs/workbench/reference/
         * rest/v1/projects.locations.runtimes#AcceleratorType`
         */
        type?: string;
    }

    export interface RuntimeVirtualMachineVirtualMachineConfigDataDiskInitializeParams {
        /**
         * Provide this property when creating the disk.
         */
        description?: string;
        /**
         * Specifies the disk name. If not specified, the default is
         * to use the name of the instance. If the disk with the
         * instance name exists already in the given zone/region, a
         * new name will be automatically generated.
         */
        diskName?: string;
        /**
         * Specifies the size of the disk in base-2 GB. If not
         * specified, the disk will be the same size as the image
         * (usually 10GB). If specified, the size must be equal to
         * or larger than 10GB. Default 100 GB.
         */
        diskSizeGb?: number;
        /**
         * The type of the boot disk attached to this runtime,
         * defaults to standard persistent disk. For valid values,
         * see `https://cloud.google.com/vertex-ai/docs/workbench/
         * reference/rest/v1/projects.locations.runtimes#disktype`
         */
        diskType?: string;
        /**
         * Labels to apply to this disk. These can be later modified
         * by the disks.setLabels method. This field is only
         * applicable for persistent disks.
         */
        labels: {[key: string]: string};
    }

    export interface RuntimeVirtualMachineVirtualMachineConfigEncryptionConfig {
        /**
         * The Cloud KMS resource identifier of the customer-managed
         * encryption key used to protect a resource, such as a disks.
         * It has the following format:
         * `projects/{PROJECT_ID}/locations/{REGION}/keyRings/
         * {KEY_RING_NAME}/cryptoKeys/{KEY_NAME}`
         */
        kmsKey?: string;
    }

    export interface RuntimeVirtualMachineVirtualMachineConfigShieldedInstanceConfig {
        /**
         * Defines whether the instance has integrity monitoring enabled.
         * Enables monitoring and attestation of the boot integrity of
         * the instance. The attestation is performed against the
         * integrity policy baseline. This baseline is initially derived
         * from the implicitly trusted boot image when the instance is
         * created. Enabled by default.
         */
        enableIntegrityMonitoring?: boolean;
        /**
         * Defines whether the instance has Secure Boot enabled.Secure
         * Boot helps ensure that the system only runs authentic software
         * by verifying the digital signature of all boot components, and
         * halting the boot process if signature verification fails.
         * Disabled by default.
         */
        enableSecureBoot?: boolean;
        /**
         * Defines whether the instance has the vTPM enabled. Enabled by
         * default.
         */
        enableVtpm?: boolean;
    }

}

export namespace organizations {
    export interface AccessApprovalSettingsEnrolledService {
        /**
         * The product for which Access Approval will be enrolled. Allowed values are listed (case-sensitive):
         * all
         * appengine.googleapis.com
         * bigquery.googleapis.com
         * bigtable.googleapis.com
         * cloudkms.googleapis.com
         * compute.googleapis.com
         * dataflow.googleapis.com
         * iam.googleapis.com
         * pubsub.googleapis.com
         * storage.googleapis.com
         */
        cloudProduct: string;
        /**
         * The enrollment level of the service.
         * Default value is `BLOCK_ALL`.
         * Possible values are `BLOCK_ALL`.
         */
        enrollmentLevel?: string;
    }

    export interface GetFoldersFolder {
        /**
         * The timestamp of when the folder was created
         */
        createTime: string;
        /**
         * The timestamp of when the folder was requested to be deleted (if applicable)
         */
        deleteTime: string;
        /**
         * The display name of the folder
         */
        displayName: string;
        /**
         * Entity tag identifier of the folder
         */
        etag: string;
        /**
         * The id of the folder
         */
        name: string;
        /**
         * The parent id of the folder
         */
        parent: string;
        /**
         * The lifecycle state of the folder
         */
        state: string;
        /**
         * The timestamp of when the folder was last modified
         */
        updateTime: string;
    }

    export interface GetIAMPolicyAuditConfig {
        /**
         * A nested block that defines the operations you'd like to log.
         */
        auditLogConfigs: outputs.organizations.GetIAMPolicyAuditConfigAuditLogConfig[];
        /**
         * Defines a service that will be enabled for audit logging. For example, `storage.googleapis.com`, `cloudsql.googleapis.com`. `allServices` is a special value that covers all services.
         */
        service: string;
    }

    export interface GetIAMPolicyAuditConfigAuditLogConfig {
        /**
         * Specifies the identities that are exempt from these types of logging operations. Follows the same format of the `members` array for `binding`.
         */
        exemptedMembers?: string[];
        /**
         * Defines the logging level. `DATA_READ`, `DATA_WRITE` and `ADMIN_READ` capture different types of events. See [the audit configuration documentation](https://cloud.google.com/resource-manager/reference/rest/Shared.Types/AuditConfig) for more details.
         */
        logType: string;
    }

    export interface GetIAMPolicyBinding {
        /**
         * An [IAM Condition](https://cloud.google.com/iam/docs/conditions-overview) for a given binding. Structure is documented below.
         */
        condition?: outputs.organizations.GetIAMPolicyBindingCondition;
        /**
         * An array of identities that will be granted the privilege in the `role`. For more details on format and restrictions see https://cloud.google.com/billing/reference/rest/v1/Policy#Binding
         * Each entry can have one of the following values:
         * * **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account. Some resources **don't** support this identity.
         * * **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account. Some resources **don't** support this identity.
         * * **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com.
         * * **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
         * * **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
         * * **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
         */
        members: string[];
        /**
         * The role/permission that will be granted to the members.
         * See the [IAM Roles](https://cloud.google.com/compute/docs/access/iam) documentation for a complete list of roles.
         * Note that custom roles must be of the format `[projects|organizations]/{parent-name}/roles/{role-name}`.
         */
        role: string;
    }

    export interface GetIAMPolicyBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface IAMBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface IAMMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface IamAuditConfigAuditLogConfig {
        /**
         * Identities that do not cause logging for this type of permission.
         * Each entry can have one of the following values:
         * * **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
         * * **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
         * * **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
         * * **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
         */
        exemptedMembers?: string[];
        /**
         * Permission type for which logging is to be configured.  Must be one of `DATA_READ`, `DATA_WRITE`, or `ADMIN_READ`.
         */
        logType: string;
    }

    export interface PolicyBooleanPolicy {
        /**
         * If true, then the Policy is enforced. If false, then any configuration is acceptable.
         */
        enforced: boolean;
    }

    export interface PolicyListPolicy {
        /**
         * or `deny` - (Optional) One or the other must be set.
         */
        allow?: outputs.organizations.PolicyListPolicyAllow;
        deny?: outputs.organizations.PolicyListPolicyDeny;
        /**
         * If set to true, the values from the effective Policy of the parent resource
         * are inherited, meaning the values set in this Policy are added to the values inherited up the hierarchy.
         */
        inheritFromParent?: boolean;
        /**
         * The Google Cloud Console will try to default to a configuration that matches the value specified in this field.
         */
        suggestedValue: string;
    }

    export interface PolicyListPolicyAllow {
        /**
         * The policy allows or denies all values.
         */
        all?: boolean;
        /**
         * The policy can define specific values that are allowed or denied.
         */
        values?: string[];
    }

    export interface PolicyListPolicyDeny {
        /**
         * The policy allows or denies all values.
         */
        all?: boolean;
        /**
         * The policy can define specific values that are allowed or denied.
         */
        values?: string[];
    }

    export interface PolicyRestorePolicy {
        /**
         * May only be set to true. If set, then the default Policy is restored.
         */
        default: boolean;
    }
}

export namespace orgpolicy {
    export interface PolicySpec {
        /**
         * -
         * An opaque tag indicating the current version of the `Policy`, used for concurrency control. This field is ignored if used in a `CreatePolicy` request. When the `Policy` is returned from either a `GetPolicy` or a `ListPolicies` request, this `etag` indicates the version of the current `Policy` to use when executing a read-modify-write loop. When the `Policy` is returned from a `GetEffectivePolicy` request, the `etag` will be unset.
         */
        etag: string;
        /**
         * Determines the inheritance behavior for this `Policy`. If `inheritFromParent` is true, PolicyRules set higher up in the hierarchy (up to the closest root) are inherited and present in the effective policy. If it is false, then no rules are inherited, and this Policy becomes the new root for evaluation. This field can be set only for Policies which configure list constraints.
         */
        inheritFromParent?: boolean;
        /**
         * Ignores policies set above this resource and restores the `constraintDefault` enforcement behavior of the specific `Constraint` at this resource. This field can be set in policies for either list or boolean constraints. If set, `rules` must be empty and `inheritFromParent` must be set to false.
         */
        reset?: boolean;
        /**
         * Up to 10 PolicyRules are allowed. In Policies for boolean constraints, the following requirements apply: - There must be one and only one PolicyRule where condition is unset. - BooleanPolicyRules with conditions must set `enforced` to the opposite of the PolicyRule without a condition. - During policy evaluation, PolicyRules with conditions that are true for a target resource take precedence.
         */
        rules?: outputs.orgpolicy.PolicySpecRule[];
        /**
         * -
         * Output only. The time stamp this was previously updated. This represents the last time a call to `CreatePolicy` or `UpdatePolicy` was made for that `Policy`.
         */
        updateTime: string;
    }

    export interface PolicySpecRule {
        /**
         * Setting this to true means that all values are allowed. This field can be set only in Policies for list constraints.
         */
        allowAll?: string;
        /**
         * A condition which determines whether this rule is used in the evaluation of the policy. When set, the `expression` field in the `Expr' must include from 1 to 10 subexpressions, joined by the "||" or "&&" operators. Each subexpression must be of the form "resource.matchTag('/tag_key_short_name, 'tag_value_short_name')". or "resource.matchTagId('tagKeys/key_id', 'tagValues/value_id')". where keyName and valueName are the resource names for Label Keys and Values. These names are available from the Tag Manager Service. An example expression is: "resource.matchTag('123456789/environment, 'prod')". or "resource.matchTagId('tagKeys/123', 'tagValues/456')".
         */
        condition?: outputs.orgpolicy.PolicySpecRuleCondition;
        /**
         * Setting this to true means that all values are denied. This field can be set only in Policies for list constraints.
         */
        denyAll?: string;
        /**
         * If `true`, then the `Policy` is enforced. If `false`, then any configuration is acceptable. This field can be set only in Policies for boolean constraints.
         */
        enforce?: string;
        /**
         * List of values to be used for this PolicyRule. This field can be set only in Policies for list constraints.
         */
        values?: outputs.orgpolicy.PolicySpecRuleValues;
    }

    export interface PolicySpecRuleCondition {
        /**
         * Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression?: string;
        /**
         * Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
         */
        location?: string;
        /**
         * Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
         */
        title?: string;
    }

    export interface PolicySpecRuleValues {
        /**
         * List of values allowed at this resource.
         */
        allowedValues?: string[];
        /**
         * List of values denied at this resource.
         */
        deniedValues?: string[];
    }

}

export namespace osconfig {
    export interface GuestPoliciesAssignment {
        /**
         * Targets instances matching at least one of these label sets. This allows an assignment to target disparate groups,
         * for example "env=prod or env=staging".
         * Structure is documented below.
         */
        groupLabels?: outputs.osconfig.GuestPoliciesAssignmentGroupLabel[];
        /**
         * Targets VM instances whose name starts with one of these prefixes.
         * Like labels, this is another way to group VM instances when targeting configs,
         * for example prefix="prod-".
         * Only supported for project-level policies.
         */
        instanceNamePrefixes?: string[];
        /**
         * Targets any of the instances specified. Instances are specified by their URI in the form
         * zones/[ZONE]/instances/[INSTANCE_NAME].
         * Instance targeting is uncommon and is supported to facilitate the management of changes
         * by the instance or to target specific VM instances for development and testing.
         * Only supported for project-level policies and must reference instances within this project.
         */
        instances?: string[];
        /**
         * Targets VM instances matching at least one of the following OS types.
         * VM instances must match all supplied criteria for a given OsType to be included.
         * Structure is documented below.
         */
        osTypes?: outputs.osconfig.GuestPoliciesAssignmentOsType[];
        /**
         * Targets instances in any of these zones. Leave empty to target instances in any zone.
         * Zonal targeting is uncommon and is supported to facilitate the management of changes by zone.
         */
        zones?: string[];
    }

    export interface GuestPoliciesAssignmentGroupLabel {
        /**
         * Google Compute Engine instance labels that must be present for an instance to be included in this assignment group.
         */
        labels: {[key: string]: string};
    }

    export interface GuestPoliciesAssignmentOsType {
        /**
         * Targets VM instances with OS Inventory enabled and having the following OS architecture.
         */
        osArchitecture?: string;
        /**
         * Targets VM instances with OS Inventory enabled and having the following OS short name, for example "debian" or "windows".
         */
        osShortName?: string;
        /**
         * Targets VM instances with OS Inventory enabled and having the following following OS version.
         */
        osVersion?: string;
    }

    export interface GuestPoliciesPackage {
        /**
         * Default is INSTALLED. The desired state the agent should maintain for this recipe.
         * INSTALLED: The software recipe is installed on the instance but won't be updated to new versions.
         * INSTALLED_KEEP_UPDATED: The software recipe is installed on the instance. The recipe is updated to a higher version,
         * if a higher version of the recipe is assigned to this instance.
         * REMOVE: Remove is unsupported for software recipes and attempts to create or update a recipe to the REMOVE state is rejected.
         * Default value is `INSTALLED`.
         * Possible values are `INSTALLED`, `UPDATED`, and `REMOVED`.
         */
        desiredState?: string;
        /**
         * Type of package manager that can be used to install this package. If a system does not have the package manager,
         * the package is not installed or removed no error message is returned. By default, or if you specify ANY,
         * the agent attempts to install and remove this package using the default package manager.
         * This is useful when creating a policy that applies to different types of systems.
         * The default behavior is ANY.
         * Default value is `ANY`.
         * Possible values are `ANY`, `APT`, `YUM`, `ZYPPER`, and `GOO`.
         */
        manager?: string;
        /**
         * Unique identifier for the recipe. Only one recipe with a given name is installed on an instance.
         * Names are also used to identify resources which helps to determine whether guest policies have conflicts.
         * This means that requests to create multiple recipes with the same name and version are rejected since they
         * could potentially have conflicting assignments.
         */
        name: string;
    }

    export interface GuestPoliciesPackageRepository {
        /**
         * An Apt Repository.
         * Structure is documented below.
         */
        apt?: outputs.osconfig.GuestPoliciesPackageRepositoryApt;
        /**
         * A Goo Repository.
         * Structure is documented below.
         */
        goo?: outputs.osconfig.GuestPoliciesPackageRepositoryGoo;
        /**
         * A Yum Repository.
         * Structure is documented below.
         */
        yum?: outputs.osconfig.GuestPoliciesPackageRepositoryYum;
        /**
         * A Zypper Repository.
         * Structure is documented below.
         */
        zypper?: outputs.osconfig.GuestPoliciesPackageRepositoryZypper;
    }

    export interface GuestPoliciesPackageRepositoryApt {
        /**
         * Type of archive files in this repository. The default behavior is DEB.
         * Default value is `DEB`.
         * Possible values are `DEB` and `DEB_SRC`.
         */
        archiveType?: string;
        /**
         * List of components for this repository. Must contain at least one item.
         */
        components: string[];
        /**
         * Distribution of this repository.
         */
        distribution: string;
        /**
         * URI of the key file for this repository. The agent maintains a keyring at
         * /etc/apt/trusted.gpg.d/osconfig_agent_managed.gpg containing all the keys in any applied guest policy.
         */
        gpgKey?: string;
        /**
         * URI from which to fetch the object. It should contain both the protocol and path following the format {protocol}://{location}.
         */
        uri: string;
    }

    export interface GuestPoliciesPackageRepositoryGoo {
        /**
         * Unique identifier for the recipe. Only one recipe with a given name is installed on an instance.
         * Names are also used to identify resources which helps to determine whether guest policies have conflicts.
         * This means that requests to create multiple recipes with the same name and version are rejected since they
         * could potentially have conflicting assignments.
         */
        name: string;
        /**
         * The url of the repository.
         */
        url: string;
    }

    export interface GuestPoliciesPackageRepositoryYum {
        /**
         * The location of the repository directory.
         */
        baseUrl: string;
        /**
         * The display name of the repository.
         */
        displayName?: string;
        /**
         * URIs of GPG keys.
         */
        gpgKeys?: string[];
        /**
         * Id of the artifact, which the installation and update steps of this recipe can reference.
         * Artifacts in a recipe cannot have the same id.
         */
        id: string;
    }

    export interface GuestPoliciesPackageRepositoryZypper {
        /**
         * The location of the repository directory.
         */
        baseUrl: string;
        /**
         * The display name of the repository.
         */
        displayName?: string;
        /**
         * URIs of GPG keys.
         */
        gpgKeys?: string[];
        /**
         * Id of the artifact, which the installation and update steps of this recipe can reference.
         * Artifacts in a recipe cannot have the same id.
         */
        id: string;
    }

    export interface GuestPoliciesRecipe {
        /**
         * Resources available to be used in the steps in the recipe.
         * Structure is documented below.
         */
        artifacts?: outputs.osconfig.GuestPoliciesRecipeArtifact[];
        /**
         * Default is INSTALLED. The desired state the agent should maintain for this recipe.
         * INSTALLED: The software recipe is installed on the instance but won't be updated to new versions.
         * INSTALLED_KEEP_UPDATED: The software recipe is installed on the instance. The recipe is updated to a higher version,
         * if a higher version of the recipe is assigned to this instance.
         * REMOVE: Remove is unsupported for software recipes and attempts to create or update a recipe to the REMOVE state is rejected.
         * Default value is `INSTALLED`.
         * Possible values are `INSTALLED`, `UPDATED`, and `REMOVED`.
         */
        desiredState?: string;
        /**
         * Actions to be taken for installing this recipe. On failure it stops executing steps and does not attempt another installation.
         * Any steps taken (including partially completed steps) are not rolled back.
         * Structure is documented below.
         */
        installSteps?: outputs.osconfig.GuestPoliciesRecipeInstallStep[];
        /**
         * Unique identifier for the recipe. Only one recipe with a given name is installed on an instance.
         * Names are also used to identify resources which helps to determine whether guest policies have conflicts.
         * This means that requests to create multiple recipes with the same name and version are rejected since they
         * could potentially have conflicting assignments.
         */
        name: string;
        /**
         * Actions to be taken for updating this recipe. On failure it stops executing steps and does not attempt another update for this recipe.
         * Any steps taken (including partially completed steps) are not rolled back.
         * Structure is documented below.
         */
        updateSteps?: outputs.osconfig.GuestPoliciesRecipeUpdateStep[];
        /**
         * The version of this software recipe. Version can be up to 4 period separated numbers (e.g. 12.34.56.78).
         */
        version?: string;
    }

    export interface GuestPoliciesRecipeArtifact {
        /**
         * Defaults to false. When false, recipes are subject to validations based on the artifact type:
         * Remote: A checksum must be specified, and only protocols with transport-layer security are permitted.
         * GCS: An object generation number must be specified.
         */
        allowInsecure?: boolean;
        /**
         * A Google Cloud Storage artifact.
         * Structure is documented below.
         */
        gcs?: outputs.osconfig.GuestPoliciesRecipeArtifactGcs;
        /**
         * Id of the artifact, which the installation and update steps of this recipe can reference.
         * Artifacts in a recipe cannot have the same id.
         */
        id: string;
        /**
         * A generic remote artifact.
         * Structure is documented below.
         */
        remote?: outputs.osconfig.GuestPoliciesRecipeArtifactRemote;
    }

    export interface GuestPoliciesRecipeArtifactGcs {
        /**
         * Bucket of the Google Cloud Storage object. Given an example URL: https://storage.googleapis.com/my-bucket/foo/bar#1234567
         * this value would be my-bucket.
         */
        bucket?: string;
        /**
         * Must be provided if allowInsecure is false. Generation number of the Google Cloud Storage object.
         * https://storage.googleapis.com/my-bucket/foo/bar#1234567 this value would be 1234567.
         */
        generation?: number;
        /**
         * Name of the Google Cloud Storage object. Given an example URL: https://storage.googleapis.com/my-bucket/foo/bar#1234567
         * this value would be foo/bar.
         */
        object?: string;
    }

    export interface GuestPoliciesRecipeArtifactRemote {
        /**
         * Must be provided if allowInsecure is false. SHA256 checksum in hex format, to compare to the checksum of the artifact.
         * If the checksum is not empty and it doesn't match the artifact then the recipe installation fails before running any
         * of the steps.
         */
        checkSum?: string;
        /**
         * URI from which to fetch the object. It should contain both the protocol and path following the format {protocol}://{location}.
         */
        uri?: string;
    }

    export interface GuestPoliciesRecipeInstallStep {
        /**
         * Extracts an archive into the specified directory.
         * Structure is documented below.
         */
        archiveExtraction?: outputs.osconfig.GuestPoliciesRecipeInstallStepArchiveExtraction;
        /**
         * Installs a deb file via dpkg.
         * Structure is documented below.
         */
        dpkgInstallation?: outputs.osconfig.GuestPoliciesRecipeInstallStepDpkgInstallation;
        /**
         * Copies a file onto the instance.
         * Structure is documented below.
         */
        fileCopy?: outputs.osconfig.GuestPoliciesRecipeInstallStepFileCopy;
        /**
         * Executes an artifact or local file.
         * Structure is documented below.
         */
        fileExec?: outputs.osconfig.GuestPoliciesRecipeInstallStepFileExec;
        /**
         * Installs an MSI file.
         * Structure is documented below.
         */
        msiInstallation?: outputs.osconfig.GuestPoliciesRecipeInstallStepMsiInstallation;
        /**
         * Installs an rpm file via the rpm utility.
         * Structure is documented below.
         */
        rpmInstallation?: outputs.osconfig.GuestPoliciesRecipeInstallStepRpmInstallation;
        /**
         * Runs commands in a shell.
         * Structure is documented below.
         */
        scriptRun?: outputs.osconfig.GuestPoliciesRecipeInstallStepScriptRun;
    }

    export interface GuestPoliciesRecipeInstallStepArchiveExtraction {
        /**
         * The id of the relevant artifact in the recipe.
         */
        artifactId: string;
        /**
         * Directory to extract archive to. Defaults to / on Linux or C:\ on Windows.
         */
        destination: string;
        /**
         * The type of the archive to extract.
         * Possible values are `TAR`, `TAR_GZIP`, `TAR_BZIP`, `TAR_LZMA`, `TAR_XZ`, and `ZIP`.
         */
        type: string;
    }

    export interface GuestPoliciesRecipeInstallStepDpkgInstallation {
        /**
         * The id of the relevant artifact in the recipe.
         */
        artifactId: string;
    }

    export interface GuestPoliciesRecipeInstallStepFileCopy {
        /**
         * The id of the relevant artifact in the recipe.
         */
        artifactId: string;
        /**
         * Directory to extract archive to. Defaults to / on Linux or C:\ on Windows.
         */
        destination: string;
        /**
         * Whether to allow this step to overwrite existing files.If this is false and the file already exists the file
         * is not overwritten and the step is considered a success. Defaults to false.
         */
        overwrite?: boolean;
        /**
         * Consists of three octal digits which represent, in order, the permissions of the owner, group, and other users
         * for the file (similarly to the numeric mode used in the linux chmod utility). Each digit represents a three bit
         * number with the 4 bit corresponding to the read permissions, the 2 bit corresponds to the write bit, and the one
         * bit corresponds to the execute permission. Default behavior is 755.
         * Below are some examples of permissions and their associated values:
         * read, write, and execute: 7 read and execute: 5 read and write: 6 read only: 4
         */
        permissions?: string;
    }

    export interface GuestPoliciesRecipeInstallStepFileExec {
        /**
         * Return codes that indicate that the software installed or updated successfully. Behaviour defaults to [0]
         */
        allowedExitCodes: string;
        /**
         * Arguments to be passed to the provided executable.
         */
        args?: string[];
        /**
         * The id of the relevant artifact in the recipe.
         */
        artifactId?: string;
        /**
         * The absolute path of the file on the local filesystem.
         */
        localPath?: string;
    }

    export interface GuestPoliciesRecipeInstallStepMsiInstallation {
        /**
         * Return codes that indicate that the software installed or updated successfully. Behaviour defaults to [0]
         */
        allowedExitCodes: number[];
        /**
         * The id of the relevant artifact in the recipe.
         */
        artifactId: string;
        /**
         * The flags to use when installing the MSI. Defaults to the install flag.
         */
        flags: string[];
    }

    export interface GuestPoliciesRecipeInstallStepRpmInstallation {
        /**
         * The id of the relevant artifact in the recipe.
         */
        artifactId: string;
    }

    export interface GuestPoliciesRecipeInstallStepScriptRun {
        /**
         * Return codes that indicate that the software installed or updated successfully. Behaviour defaults to [0]
         */
        allowedExitCodes: number[];
        /**
         * The script interpreter to use to run the script. If no interpreter is specified the script is executed directly,
         * which likely only succeed for scripts with shebang lines.
         * Possible values are `SHELL` and `POWERSHELL`.
         */
        interpreter?: string;
        /**
         * The shell script to be executed.
         */
        script: string;
    }

    export interface GuestPoliciesRecipeUpdateStep {
        /**
         * Extracts an archive into the specified directory.
         * Structure is documented below.
         */
        archiveExtraction?: outputs.osconfig.GuestPoliciesRecipeUpdateStepArchiveExtraction;
        /**
         * Installs a deb file via dpkg.
         * Structure is documented below.
         */
        dpkgInstallation?: outputs.osconfig.GuestPoliciesRecipeUpdateStepDpkgInstallation;
        /**
         * Copies a file onto the instance.
         * Structure is documented below.
         */
        fileCopy?: outputs.osconfig.GuestPoliciesRecipeUpdateStepFileCopy;
        /**
         * Executes an artifact or local file.
         * Structure is documented below.
         */
        fileExec?: outputs.osconfig.GuestPoliciesRecipeUpdateStepFileExec;
        /**
         * Installs an MSI file.
         * Structure is documented below.
         */
        msiInstallation?: outputs.osconfig.GuestPoliciesRecipeUpdateStepMsiInstallation;
        /**
         * Installs an rpm file via the rpm utility.
         * Structure is documented below.
         */
        rpmInstallation?: outputs.osconfig.GuestPoliciesRecipeUpdateStepRpmInstallation;
        /**
         * Runs commands in a shell.
         * Structure is documented below.
         */
        scriptRun?: outputs.osconfig.GuestPoliciesRecipeUpdateStepScriptRun;
    }

    export interface GuestPoliciesRecipeUpdateStepArchiveExtraction {
        /**
         * The id of the relevant artifact in the recipe.
         */
        artifactId: string;
        /**
         * Directory to extract archive to. Defaults to / on Linux or C:\ on Windows.
         */
        destination: string;
        /**
         * The type of the archive to extract.
         * Possible values are `TAR`, `TAR_GZIP`, `TAR_BZIP`, `TAR_LZMA`, `TAR_XZ`, and `ZIP`.
         */
        type: string;
    }

    export interface GuestPoliciesRecipeUpdateStepDpkgInstallation {
        /**
         * The id of the relevant artifact in the recipe.
         */
        artifactId: string;
    }

    export interface GuestPoliciesRecipeUpdateStepFileCopy {
        /**
         * The id of the relevant artifact in the recipe.
         */
        artifactId: string;
        /**
         * Directory to extract archive to. Defaults to / on Linux or C:\ on Windows.
         */
        destination: string;
        /**
         * Whether to allow this step to overwrite existing files.If this is false and the file already exists the file
         * is not overwritten and the step is considered a success. Defaults to false.
         */
        overwrite?: boolean;
        /**
         * Consists of three octal digits which represent, in order, the permissions of the owner, group, and other users
         * for the file (similarly to the numeric mode used in the linux chmod utility). Each digit represents a three bit
         * number with the 4 bit corresponding to the read permissions, the 2 bit corresponds to the write bit, and the one
         * bit corresponds to the execute permission. Default behavior is 755.
         * Below are some examples of permissions and their associated values:
         * read, write, and execute: 7 read and execute: 5 read and write: 6 read only: 4
         */
        permissions?: string;
    }

    export interface GuestPoliciesRecipeUpdateStepFileExec {
        /**
         * Return codes that indicate that the software installed or updated successfully. Behaviour defaults to [0]
         */
        allowedExitCodes: number[];
        /**
         * Arguments to be passed to the provided executable.
         */
        args?: string[];
        /**
         * The id of the relevant artifact in the recipe.
         */
        artifactId?: string;
        /**
         * The absolute path of the file on the local filesystem.
         */
        localPath?: string;
    }

    export interface GuestPoliciesRecipeUpdateStepMsiInstallation {
        /**
         * Return codes that indicate that the software installed or updated successfully. Behaviour defaults to [0]
         */
        allowedExitCodes: number[];
        /**
         * The id of the relevant artifact in the recipe.
         */
        artifactId: string;
        /**
         * The flags to use when installing the MSI. Defaults to the install flag.
         */
        flags: string[];
    }

    export interface GuestPoliciesRecipeUpdateStepRpmInstallation {
        /**
         * The id of the relevant artifact in the recipe.
         */
        artifactId: string;
    }

    export interface GuestPoliciesRecipeUpdateStepScriptRun {
        /**
         * Return codes that indicate that the software installed or updated successfully. Behaviour defaults to [0]
         */
        allowedExitCodes: number[];
        /**
         * The script interpreter to use to run the script. If no interpreter is specified the script is executed directly,
         * which likely only succeed for scripts with shebang lines.
         * Possible values are `SHELL` and `POWERSHELL`.
         */
        interpreter?: string;
        /**
         * The shell script to be executed.
         */
        script: string;
    }

    export interface OsPolicyAssignmentInstanceFilter {
        /**
         * Target all VMs in the project. If true, no other criteria is permitted.
         */
        all?: boolean;
        /**
         * List of label sets used for VM exclusion. If the list has more than one label set, the VM is excluded if any of the label sets are applicable for the VM.
         */
        exclusionLabels?: outputs.osconfig.OsPolicyAssignmentInstanceFilterExclusionLabel[];
        /**
         * List of label sets used for VM inclusion. If the list has more than one `LabelSet`, the VM is included if any of the label sets are applicable for the VM.
         */
        inclusionLabels?: outputs.osconfig.OsPolicyAssignmentInstanceFilterInclusionLabel[];
        /**
         * List of inventories to select VMs. A VM is selected if its inventory data matches at least one of the following inventories.
         */
        inventories?: outputs.osconfig.OsPolicyAssignmentInstanceFilterInventory[];
    }

    export interface OsPolicyAssignmentInstanceFilterExclusionLabel {
        /**
         * Labels are identified by key/value pairs in this map. A VM should contain all the key/value pairs specified in this map to be selected.
         */
        labels?: {[key: string]: string};
    }

    export interface OsPolicyAssignmentInstanceFilterInclusionLabel {
        /**
         * Labels are identified by key/value pairs in this map. A VM should contain all the key/value pairs specified in this map to be selected.
         */
        labels?: {[key: string]: string};
    }

    export interface OsPolicyAssignmentInstanceFilterInventory {
        /**
         * Required. The OS short name
         */
        osShortName: string;
        /**
         * The OS version Prefix matches are supported if asterisk(*) is provided as the last character. For example, to match all versions with a major version of `7`, specify the following value for this field `7.*` An empty string matches all OS versions.
         */
        osVersion?: string;
    }

    export interface OsPolicyAssignmentOsPolicy {
        /**
         * This flag determines the OS policy compliance status when none of the resource groups within the policy are applicable for a VM. Set this value to `true` if the policy needs to be reported as compliant even if the policy has nothing to validate or enforce.
         */
        allowNoResourceGroupMatch?: boolean;
        /**
         * OS policy assignment description. Length of the description is limited to 1024 characters.
         */
        description?: string;
        /**
         * Required. A one word, unique name for this repository. This is the `repo id` in the zypper config file and also the `displayName` if `displayName` is omitted. This id is also used as the unique identifier when checking for GuestPolicy conflicts.
         */
        id: string;
        /**
         * Required. Policy mode Possible values: MODE_UNSPECIFIED, VALIDATION, ENFORCEMENT
         */
        mode: string;
        /**
         * Required. List of resource groups for the policy. For a particular VM, resource groups are evaluated in the order specified and the first resource group that is applicable is selected and the rest are ignored. If none of the resource groups are applicable for a VM, the VM is considered to be non-compliant w.r.t this policy. This behavior can be toggled by the flag `allowNoResourceGroupMatch`
         */
        resourceGroups: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroup[];
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroup {
        /**
         * List of inventory filters for the resource group. The resources in this resource group are applied to the target VM if it satisfies at least one of the following inventory filters. For example, to apply this resource group to VMs running either `RHEL` or `CentOS` operating systems, specify 2 items for the list with following values: inventory_filters[0].os_short_name='rhel' and inventory_filters[1].os_short_name='centos' If the list is empty, this resource group will be applied to the target VM unconditionally.
         */
        inventoryFilters?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupInventoryFilter[];
        /**
         * Required. List of resources configured for this resource group. The resources are executed in the exact order specified here.
         */
        resources: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResource[];
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupInventoryFilter {
        /**
         * Required. The OS short name
         */
        osShortName: string;
        /**
         * The OS version Prefix matches are supported if asterisk(*) is provided as the last character. For example, to match all versions with a major version of `7`, specify the following value for this field `7.*` An empty string matches all OS versions.
         */
        osVersion?: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResource {
        /**
         * Exec resource
         */
        exec?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceExec;
        /**
         * A remote or local source.
         */
        file?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceFile;
        /**
         * Required. A one word, unique name for this repository. This is the `repo id` in the zypper config file and also the `displayName` if `displayName` is omitted. This id is also used as the unique identifier when checking for GuestPolicy conflicts.
         */
        id: string;
        /**
         * Package resource
         */
        pkg?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkg;
        /**
         * Package repository resource
         */
        repository?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceRepository;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceExec {
        /**
         * What to run to bring this resource into the desired state. An exit code of 100 indicates "success", any other exit code indicates a failure running enforce.
         */
        enforce?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceExecEnforce;
        /**
         * Required. What to run to validate this resource is in the desired state. An exit code of 100 indicates "in desired state", and exit code of 101 indicates "not in desired state". Any other exit code indicates a failure running validate.
         */
        validate: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceExecValidate;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceExecEnforce {
        /**
         * Optional arguments to pass to the source during execution.
         */
        args?: string[];
        /**
         * A remote or local source.
         */
        file?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceExecEnforceFile;
        /**
         * Required. The script interpreter to use. Possible values: INTERPRETER_UNSPECIFIED, NONE, SHELL, POWERSHELL
         */
        interpreter: string;
        /**
         * Only recorded for enforce Exec. Path to an output file (that is created by this Exec) whose content will be recorded in OSPolicyResourceCompliance after a successful run. Absence or failure to read this file will result in this ExecResource being non-compliant. Output file size is limited to 100K bytes.
         */
        outputFilePath?: string;
        /**
         * An inline script. The size of the script is limited to 1024 characters.
         */
        script?: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceExecEnforceFile {
        /**
         * Defaults to false. When false, files are subject to validations based on the file type: Remote: A checksum must be specified. Cloud Storage: An object generation number must be specified.
         */
        allowInsecure?: boolean;
        /**
         * A Cloud Storage object.
         */
        gcs?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceExecEnforceFileGcs;
        /**
         * A local path within the VM to use.
         */
        localPath?: string;
        /**
         * A generic remote file.
         */
        remote?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceExecEnforceFileRemote;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceExecEnforceFileGcs {
        /**
         * Required. Bucket of the Cloud Storage object.
         */
        bucket: string;
        /**
         * Generation number of the Cloud Storage object.
         */
        generation?: number;
        /**
         * Required. Name of the Cloud Storage object.
         */
        object: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceExecEnforceFileRemote {
        /**
         * SHA256 checksum of the remote file.
         */
        sha256Checksum?: string;
        /**
         * Required. URI for this repository.
         */
        uri: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceExecValidate {
        /**
         * Optional arguments to pass to the source during execution.
         */
        args?: string[];
        /**
         * A remote or local source.
         */
        file?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceExecValidateFile;
        /**
         * Required. The script interpreter to use. Possible values: INTERPRETER_UNSPECIFIED, NONE, SHELL, POWERSHELL
         */
        interpreter: string;
        /**
         * Only recorded for enforce Exec. Path to an output file (that is created by this Exec) whose content will be recorded in OSPolicyResourceCompliance after a successful run. Absence or failure to read this file will result in this ExecResource being non-compliant. Output file size is limited to 100K bytes.
         */
        outputFilePath?: string;
        /**
         * An inline script. The size of the script is limited to 1024 characters.
         */
        script?: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceExecValidateFile {
        /**
         * Defaults to false. When false, files are subject to validations based on the file type: Remote: A checksum must be specified. Cloud Storage: An object generation number must be specified.
         */
        allowInsecure?: boolean;
        /**
         * A Cloud Storage object.
         */
        gcs?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceExecValidateFileGcs;
        /**
         * A local path within the VM to use.
         */
        localPath?: string;
        /**
         * A generic remote file.
         */
        remote?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceExecValidateFileRemote;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceExecValidateFileGcs {
        /**
         * Required. Bucket of the Cloud Storage object.
         */
        bucket: string;
        /**
         * Generation number of the Cloud Storage object.
         */
        generation?: number;
        /**
         * Required. Name of the Cloud Storage object.
         */
        object: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceExecValidateFileRemote {
        /**
         * SHA256 checksum of the remote file.
         */
        sha256Checksum?: string;
        /**
         * Required. URI for this repository.
         */
        uri: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceFile {
        /**
         * A a file with this content. The size of the content is limited to 1024 characters.
         */
        content?: string;
        /**
         * A remote or local source.
         */
        file?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceFileFile;
        /**
         * Required. The absolute path of the file within the VM.
         */
        path: string;
        /**
         * -
         * Consists of three octal digits which represent, in order, the permissions of the owner, group, and other users for the file (similarly to the numeric mode used in the linux chmod utility). Each digit represents a three bit number with the 4 bit corresponding to the read permissions, the 2 bit corresponds to the write bit, and the one bit corresponds to the execute permission. Default behavior is 755. Below are some examples of permissions and their associated values: read, write, and execute: 7 read and execute: 5 read and write: 6 read only: 4
         */
        permissions: string;
        /**
         * Required. Desired state of the file. Possible values: OS_POLICY_COMPLIANCE_STATE_UNSPECIFIED, COMPLIANT, NON_COMPLIANT, UNKNOWN, NO_OS_POLICIES_APPLICABLE
         */
        state: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceFileFile {
        /**
         * Defaults to false. When false, files are subject to validations based on the file type: Remote: A checksum must be specified. Cloud Storage: An object generation number must be specified.
         */
        allowInsecure?: boolean;
        /**
         * A Cloud Storage object.
         */
        gcs?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceFileFileGcs;
        /**
         * A local path within the VM to use.
         */
        localPath?: string;
        /**
         * A generic remote file.
         */
        remote?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceFileFileRemote;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceFileFileGcs {
        /**
         * Required. Bucket of the Cloud Storage object.
         */
        bucket: string;
        /**
         * Generation number of the Cloud Storage object.
         */
        generation?: number;
        /**
         * Required. Name of the Cloud Storage object.
         */
        object: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceFileFileRemote {
        /**
         * SHA256 checksum of the remote file.
         */
        sha256Checksum?: string;
        /**
         * Required. URI for this repository.
         */
        uri: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkg {
        /**
         * An Apt Repository.
         */
        apt?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgApt;
        /**
         * A deb package file.
         */
        deb?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgDeb;
        /**
         * Required. The desired state the agent should maintain for this package. Possible values: DESIRED_STATE_UNSPECIFIED, INSTALLED, REMOVED
         */
        desiredState: string;
        /**
         * A package managed by GooGet.
         */
        googet?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgGooget;
        /**
         * An MSI package.
         */
        msi?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgMsi;
        /**
         * An rpm package file.
         */
        rpm?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgRpm;
        /**
         * A Yum Repository.
         */
        yum?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgYum;
        /**
         * A Zypper Repository.
         */
        zypper?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgZypper;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgApt {
        /**
         * Required. The name of the repository.
         */
        name: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgDeb {
        /**
         * Whether dependencies should also be installed. - install when false: `rpm --upgrade --replacepkgs package.rpm` - install when true: `yum -y install package.rpm` or `zypper -y install package.rpm`
         */
        pullDeps?: boolean;
        /**
         * Required. An rpm package.
         */
        source: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgDebSource;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgDebSource {
        /**
         * Defaults to false. When false, files are subject to validations based on the file type: Remote: A checksum must be specified. Cloud Storage: An object generation number must be specified.
         */
        allowInsecure?: boolean;
        /**
         * A Cloud Storage object.
         */
        gcs?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgDebSourceGcs;
        /**
         * A local path within the VM to use.
         */
        localPath?: string;
        /**
         * A generic remote file.
         */
        remote?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgDebSourceRemote;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgDebSourceGcs {
        /**
         * Required. Bucket of the Cloud Storage object.
         */
        bucket: string;
        /**
         * Generation number of the Cloud Storage object.
         */
        generation?: number;
        /**
         * Required. Name of the Cloud Storage object.
         */
        object: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgDebSourceRemote {
        /**
         * SHA256 checksum of the remote file.
         */
        sha256Checksum?: string;
        /**
         * Required. URI for this repository.
         */
        uri: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgGooget {
        /**
         * Required. The name of the repository.
         */
        name: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgMsi {
        /**
         * Additional properties to use during installation. This should be in the format of Property=Setting. Appended to the defaults of `ACTION=INSTALL REBOOT=ReallySuppress`.
         */
        properties?: string[];
        /**
         * Required. An rpm package.
         */
        source: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgMsiSource;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgMsiSource {
        /**
         * Defaults to false. When false, files are subject to validations based on the file type: Remote: A checksum must be specified. Cloud Storage: An object generation number must be specified.
         */
        allowInsecure?: boolean;
        /**
         * A Cloud Storage object.
         */
        gcs?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgMsiSourceGcs;
        /**
         * A local path within the VM to use.
         */
        localPath?: string;
        /**
         * A generic remote file.
         */
        remote?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgMsiSourceRemote;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgMsiSourceGcs {
        /**
         * Required. Bucket of the Cloud Storage object.
         */
        bucket: string;
        /**
         * Generation number of the Cloud Storage object.
         */
        generation?: number;
        /**
         * Required. Name of the Cloud Storage object.
         */
        object: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgMsiSourceRemote {
        /**
         * SHA256 checksum of the remote file.
         */
        sha256Checksum?: string;
        /**
         * Required. URI for this repository.
         */
        uri: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgRpm {
        /**
         * Whether dependencies should also be installed. - install when false: `rpm --upgrade --replacepkgs package.rpm` - install when true: `yum -y install package.rpm` or `zypper -y install package.rpm`
         */
        pullDeps?: boolean;
        /**
         * Required. An rpm package.
         */
        source: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgRpmSource;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgRpmSource {
        /**
         * Defaults to false. When false, files are subject to validations based on the file type: Remote: A checksum must be specified. Cloud Storage: An object generation number must be specified.
         */
        allowInsecure?: boolean;
        /**
         * A Cloud Storage object.
         */
        gcs?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgRpmSourceGcs;
        /**
         * A local path within the VM to use.
         */
        localPath?: string;
        /**
         * A generic remote file.
         */
        remote?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourcePkgRpmSourceRemote;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgRpmSourceGcs {
        /**
         * Required. Bucket of the Cloud Storage object.
         */
        bucket: string;
        /**
         * Generation number of the Cloud Storage object.
         */
        generation?: number;
        /**
         * Required. Name of the Cloud Storage object.
         */
        object: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgRpmSourceRemote {
        /**
         * SHA256 checksum of the remote file.
         */
        sha256Checksum?: string;
        /**
         * Required. URI for this repository.
         */
        uri: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgYum {
        /**
         * Required. The name of the repository.
         */
        name: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourcePkgZypper {
        /**
         * Required. The name of the repository.
         */
        name: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceRepository {
        /**
         * An Apt Repository.
         */
        apt?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceRepositoryApt;
        /**
         * A Goo Repository.
         */
        goo?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceRepositoryGoo;
        /**
         * A Yum Repository.
         */
        yum?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceRepositoryYum;
        /**
         * A Zypper Repository.
         */
        zypper?: outputs.osconfig.OsPolicyAssignmentOsPolicyResourceGroupResourceRepositoryZypper;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceRepositoryApt {
        /**
         * Required. Type of archive files in this repository. Possible values: ARCHIVE_TYPE_UNSPECIFIED, DEB, DEB_SRC
         */
        archiveType: string;
        /**
         * Required. List of components for this repository. Must contain at least one item.
         */
        components: string[];
        /**
         * Required. Distribution of this repository.
         */
        distribution: string;
        /**
         * URI of the key file for this repository. The agent maintains a keyring at `/etc/apt/trusted.gpg.d/osconfig_agent_managed.gpg`.
         */
        gpgKey?: string;
        /**
         * Required. URI for this repository.
         */
        uri: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceRepositoryGoo {
        /**
         * Required. The name of the repository.
         */
        name: string;
        /**
         * Required. The url of the repository.
         */
        url: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceRepositoryYum {
        /**
         * Required. The location of the repository directory.
         */
        baseUrl: string;
        /**
         * The display name of the repository.
         */
        displayName?: string;
        /**
         * URIs of GPG keys.
         */
        gpgKeys?: string[];
        /**
         * Required. A one word, unique name for this repository. This is the `repo id` in the zypper config file and also the `displayName` if `displayName` is omitted. This id is also used as the unique identifier when checking for GuestPolicy conflicts.
         */
        id: string;
    }

    export interface OsPolicyAssignmentOsPolicyResourceGroupResourceRepositoryZypper {
        /**
         * Required. The location of the repository directory.
         */
        baseUrl: string;
        /**
         * The display name of the repository.
         */
        displayName?: string;
        /**
         * URIs of GPG keys.
         */
        gpgKeys?: string[];
        /**
         * Required. A one word, unique name for this repository. This is the `repo id` in the zypper config file and also the `displayName` if `displayName` is omitted. This id is also used as the unique identifier when checking for GuestPolicy conflicts.
         */
        id: string;
    }

    export interface OsPolicyAssignmentRollout {
        /**
         * Required. The maximum number (or percentage) of VMs per zone to disrupt at any given moment.
         */
        disruptionBudget: outputs.osconfig.OsPolicyAssignmentRolloutDisruptionBudget;
        /**
         * Required. This determines the minimum duration of time to wait after the configuration changes are applied through the current rollout. A VM continues to count towards the `disruptionBudget` at least until this duration of time has passed after configuration changes are applied.
         */
        minWaitDuration: string;
    }

    export interface OsPolicyAssignmentRolloutDisruptionBudget {
        /**
         * Specifies a fixed value.
         */
        fixed?: number;
        /**
         * Specifies the relative value defined as a percentage, which will be multiplied by a reference value.
         */
        percent?: number;
    }

    export interface PatchDeploymentInstanceFilter {
        /**
         * Target all VM instances in the project. If true, no other criteria is permitted.
         */
        all?: boolean;
        /**
         * Targets VM instances matching ANY of these GroupLabels. This allows targeting of disparate groups of VM instances.
         * Structure is documented below.
         */
        groupLabels?: outputs.osconfig.PatchDeploymentInstanceFilterGroupLabel[];
        /**
         * Targets VMs whose name starts with one of these prefixes. Similar to labels, this is another way to group
         * VMs when targeting configs, for example prefix="prod-".
         */
        instanceNamePrefixes?: string[];
        /**
         * Targets any of the VM instances specified. Instances are specified by their URI in the `form zones/{{zone}}/instances/{{instance_name}}`,
         * `projects/{{project_id}}/zones/{{zone}}/instances/{{instance_name}}`, or
         * `https://www.googleapis.com/compute/v1/projects/{{project_id}}/zones/{{zone}}/instances/{{instance_name}}`
         */
        instances?: string[];
        /**
         * Targets VM instances in ANY of these zones. Leave empty to target VM instances in any zone.
         */
        zones?: string[];
    }

    export interface PatchDeploymentInstanceFilterGroupLabel {
        /**
         * Compute Engine instance labels that must be present for a VM instance to be targeted by this filter
         */
        labels: {[key: string]: string};
    }

    export interface PatchDeploymentOneTimeSchedule {
        /**
         * The desired patch job execution time. A timestamp in RFC3339 UTC "Zulu" format,
         * accurate to nanoseconds. Example: "2014-10-02T15:01:23.045123456Z".
         */
        executeTime: string;
    }

    export interface PatchDeploymentPatchConfig {
        /**
         * Apt update settings. Use this setting to override the default apt patch rules.
         * Structure is documented below.
         */
        apt?: outputs.osconfig.PatchDeploymentPatchConfigApt;
        /**
         * goo update settings. Use this setting to override the default goo patch rules.
         * Structure is documented below.
         */
        goo?: outputs.osconfig.PatchDeploymentPatchConfigGoo;
        /**
         * Allows the patch job to run on Managed instance groups (MIGs).
         */
        migInstancesAllowed?: boolean;
        /**
         * The ExecStep to run after the patch update.
         * Structure is documented below.
         */
        postStep?: outputs.osconfig.PatchDeploymentPatchConfigPostStep;
        /**
         * The ExecStep to run before the patch update.
         * Structure is documented below.
         */
        preStep?: outputs.osconfig.PatchDeploymentPatchConfigPreStep;
        /**
         * Post-patch reboot settings.
         * Possible values are `DEFAULT`, `ALWAYS`, and `NEVER`.
         */
        rebootConfig?: string;
        /**
         * Windows update settings. Use this setting to override the default Windows patch rules.
         * Structure is documented below.
         */
        windowsUpdate?: outputs.osconfig.PatchDeploymentPatchConfigWindowsUpdate;
        /**
         * Yum update settings. Use this setting to override the default yum patch rules.
         * Structure is documented below.
         */
        yum?: outputs.osconfig.PatchDeploymentPatchConfigYum;
        /**
         * zypper update settings. Use this setting to override the default zypper patch rules.
         * Structure is documented below.
         */
        zypper?: outputs.osconfig.PatchDeploymentPatchConfigZypper;
    }

    export interface PatchDeploymentPatchConfigApt {
        /**
         * List of KBs to exclude from update.
         */
        excludes?: string[];
        /**
         * An exclusive list of packages to be updated. These are the only packages that will be updated.
         * If these packages are not installed, they will be ignored. This field cannot be specified with
         * any other patch configuration fields.
         */
        exclusivePackages?: string[];
        /**
         * By changing the type to DIST, the patching is performed using apt-get dist-upgrade instead.
         * Possible values are `DIST` and `UPGRADE`.
         */
        type?: string;
    }

    export interface PatchDeploymentPatchConfigGoo {
        /**
         * goo update settings. Use this setting to override the default goo patch rules.
         */
        enabled: boolean;
    }

    export interface PatchDeploymentPatchConfigPostStep {
        /**
         * The ExecStepConfig for all Linux VMs targeted by the PatchJob.
         * Structure is documented below.
         */
        linuxExecStepConfig?: outputs.osconfig.PatchDeploymentPatchConfigPostStepLinuxExecStepConfig;
        /**
         * The ExecStepConfig for all Windows VMs targeted by the PatchJob.
         * Structure is documented below.
         */
        windowsExecStepConfig?: outputs.osconfig.PatchDeploymentPatchConfigPostStepWindowsExecStepConfig;
    }

    export interface PatchDeploymentPatchConfigPostStepLinuxExecStepConfig {
        /**
         * Defaults to [0]. A list of possible return values that the execution can return to indicate a success.
         */
        allowedSuccessCodes?: number[];
        /**
         * A Cloud Storage object containing the executable.
         * Structure is documented below.
         */
        gcsObject?: outputs.osconfig.PatchDeploymentPatchConfigPostStepLinuxExecStepConfigGcsObject;
        /**
         * The script interpreter to use to run the script. If no interpreter is specified the script will
         * be executed directly, which will likely only succeed for scripts with shebang lines.
         * Possible values are `SHELL` and `POWERSHELL`.
         */
        interpreter?: string;
        /**
         * An absolute path to the executable on the VM.
         */
        localPath?: string;
    }

    export interface PatchDeploymentPatchConfigPostStepLinuxExecStepConfigGcsObject {
        /**
         * Bucket of the Cloud Storage object.
         */
        bucket: string;
        /**
         * Generation number of the Cloud Storage object. This is used to ensure that the ExecStep specified by this PatchJob does not change.
         */
        generationNumber: string;
        /**
         * Name of the Cloud Storage object.
         */
        object: string;
    }

    export interface PatchDeploymentPatchConfigPostStepWindowsExecStepConfig {
        /**
         * Defaults to [0]. A list of possible return values that the execution can return to indicate a success.
         */
        allowedSuccessCodes?: number[];
        /**
         * A Cloud Storage object containing the executable.
         * Structure is documented below.
         */
        gcsObject?: outputs.osconfig.PatchDeploymentPatchConfigPostStepWindowsExecStepConfigGcsObject;
        /**
         * The script interpreter to use to run the script. If no interpreter is specified the script will
         * be executed directly, which will likely only succeed for scripts with shebang lines.
         * Possible values are `SHELL` and `POWERSHELL`.
         */
        interpreter?: string;
        /**
         * An absolute path to the executable on the VM.
         */
        localPath?: string;
    }

    export interface PatchDeploymentPatchConfigPostStepWindowsExecStepConfigGcsObject {
        /**
         * Bucket of the Cloud Storage object.
         */
        bucket: string;
        /**
         * Generation number of the Cloud Storage object. This is used to ensure that the ExecStep specified by this PatchJob does not change.
         */
        generationNumber: string;
        /**
         * Name of the Cloud Storage object.
         */
        object: string;
    }

    export interface PatchDeploymentPatchConfigPreStep {
        /**
         * The ExecStepConfig for all Linux VMs targeted by the PatchJob.
         * Structure is documented below.
         */
        linuxExecStepConfig?: outputs.osconfig.PatchDeploymentPatchConfigPreStepLinuxExecStepConfig;
        /**
         * The ExecStepConfig for all Windows VMs targeted by the PatchJob.
         * Structure is documented below.
         */
        windowsExecStepConfig?: outputs.osconfig.PatchDeploymentPatchConfigPreStepWindowsExecStepConfig;
    }

    export interface PatchDeploymentPatchConfigPreStepLinuxExecStepConfig {
        /**
         * Defaults to [0]. A list of possible return values that the execution can return to indicate a success.
         */
        allowedSuccessCodes?: number[];
        /**
         * A Cloud Storage object containing the executable.
         * Structure is documented below.
         */
        gcsObject?: outputs.osconfig.PatchDeploymentPatchConfigPreStepLinuxExecStepConfigGcsObject;
        /**
         * The script interpreter to use to run the script. If no interpreter is specified the script will
         * be executed directly, which will likely only succeed for scripts with shebang lines.
         * Possible values are `SHELL` and `POWERSHELL`.
         */
        interpreter?: string;
        /**
         * An absolute path to the executable on the VM.
         */
        localPath?: string;
    }

    export interface PatchDeploymentPatchConfigPreStepLinuxExecStepConfigGcsObject {
        /**
         * Bucket of the Cloud Storage object.
         */
        bucket: string;
        /**
         * Generation number of the Cloud Storage object. This is used to ensure that the ExecStep specified by this PatchJob does not change.
         */
        generationNumber: string;
        /**
         * Name of the Cloud Storage object.
         */
        object: string;
    }

    export interface PatchDeploymentPatchConfigPreStepWindowsExecStepConfig {
        /**
         * Defaults to [0]. A list of possible return values that the execution can return to indicate a success.
         */
        allowedSuccessCodes?: number[];
        /**
         * A Cloud Storage object containing the executable.
         * Structure is documented below.
         */
        gcsObject?: outputs.osconfig.PatchDeploymentPatchConfigPreStepWindowsExecStepConfigGcsObject;
        /**
         * The script interpreter to use to run the script. If no interpreter is specified the script will
         * be executed directly, which will likely only succeed for scripts with shebang lines.
         * Possible values are `SHELL` and `POWERSHELL`.
         */
        interpreter?: string;
        /**
         * An absolute path to the executable on the VM.
         */
        localPath?: string;
    }

    export interface PatchDeploymentPatchConfigPreStepWindowsExecStepConfigGcsObject {
        /**
         * Bucket of the Cloud Storage object.
         */
        bucket: string;
        /**
         * Generation number of the Cloud Storage object. This is used to ensure that the ExecStep specified by this PatchJob does not change.
         */
        generationNumber: string;
        /**
         * Name of the Cloud Storage object.
         */
        object: string;
    }

    export interface PatchDeploymentPatchConfigWindowsUpdate {
        /**
         * Only apply updates of these windows update classifications. If empty, all updates are applied.
         * Each value may be one of `CRITICAL`, `SECURITY`, `DEFINITION`, `DRIVER`, `FEATURE_PACK`, `SERVICE_PACK`, `TOOL`, `UPDATE_ROLLUP`, and `UPDATE`.
         */
        classifications?: string[];
        /**
         * List of KBs to exclude from update.
         */
        excludes?: string[];
        /**
         * An exclusive list of kbs to be updated. These are the only patches that will be updated.
         * This field must not be used with other patch configurations.
         */
        exclusivePatches?: string[];
    }

    export interface PatchDeploymentPatchConfigYum {
        /**
         * List of KBs to exclude from update.
         */
        excludes?: string[];
        /**
         * An exclusive list of packages to be updated. These are the only packages that will be updated.
         * If these packages are not installed, they will be ignored. This field cannot be specified with
         * any other patch configuration fields.
         */
        exclusivePackages?: string[];
        /**
         * Will cause patch to run yum update-minimal instead.
         */
        minimal?: boolean;
        /**
         * Adds the --security flag to yum update. Not supported on all platforms.
         */
        security?: boolean;
    }

    export interface PatchDeploymentPatchConfigZypper {
        /**
         * Install only patches with these categories. Common categories include security, recommended, and feature.
         */
        categories?: string[];
        /**
         * List of KBs to exclude from update.
         */
        excludes?: string[];
        /**
         * An exclusive list of kbs to be updated. These are the only patches that will be updated.
         * This field must not be used with other patch configurations.
         */
        exclusivePatches?: string[];
        /**
         * Install only patches with these severities. Common severities include critical, important, moderate, and low.
         */
        severities?: string[];
        /**
         * Adds the --with-optional flag to zypper patch.
         */
        withOptional?: boolean;
        /**
         * Adds the --with-update flag, to zypper patch.
         */
        withUpdate?: boolean;
    }

    export interface PatchDeploymentRecurringSchedule {
        /**
         * The end time at which a recurring patch deployment schedule is no longer active.
         * A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds. Example: "2014-10-02T15:01:23.045123456Z".
         */
        endTime?: string;
        /**
         * -
         * The time the last patch job ran successfully.
         * A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds. Example: "2014-10-02T15:01:23.045123456Z".
         */
        lastExecuteTime: string;
        /**
         * Schedule with monthly executions.
         * Structure is documented below.
         */
        monthly?: outputs.osconfig.PatchDeploymentRecurringScheduleMonthly;
        /**
         * -
         * The time the next patch job is scheduled to run.
         * A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds. Example: "2014-10-02T15:01:23.045123456Z".
         */
        nextExecuteTime: string;
        /**
         * The time that the recurring schedule becomes effective. Defaults to createTime of the patch deployment.
         * A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds. Example: "2014-10-02T15:01:23.045123456Z".
         */
        startTime?: string;
        /**
         * Time of the day to run a recurring deployment.
         * Structure is documented below.
         */
        timeOfDay: outputs.osconfig.PatchDeploymentRecurringScheduleTimeOfDay;
        /**
         * Defines the time zone that timeOfDay is relative to. The rules for daylight saving time are
         * determined by the chosen time zone.
         * Structure is documented below.
         */
        timeZone: outputs.osconfig.PatchDeploymentRecurringScheduleTimeZone;
        /**
         * Schedule with weekly executions.
         * Structure is documented below.
         */
        weekly?: outputs.osconfig.PatchDeploymentRecurringScheduleWeekly;
    }

    export interface PatchDeploymentRecurringScheduleMonthly {
        /**
         * One day of the month. 1-31 indicates the 1st to the 31st day. -1 indicates the last day of the month.
         * Months without the target day will be skipped. For example, a schedule to run "every month on the 31st"
         * will not run in February, April, June, etc.
         */
        monthDay?: number;
        /**
         * Week day in a month.
         * Structure is documented below.
         */
        weekDayOfMonth?: outputs.osconfig.PatchDeploymentRecurringScheduleMonthlyWeekDayOfMonth;
    }

    export interface PatchDeploymentRecurringScheduleMonthlyWeekDayOfMonth {
        /**
         * A day of the week.
         * Possible values are `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, and `SUNDAY`.
         */
        dayOfWeek: string;
        /**
         * Week number in a month. 1-4 indicates the 1st to 4th week of the month. -1 indicates the last week of the month.
         */
        weekOrdinal: number;
    }

    export interface PatchDeploymentRecurringScheduleTimeOfDay {
        /**
         * Hours of day in 24 hour format. Should be from 0 to 23.
         * An API may choose to allow the value "24:00:00" for scenarios like business closing time.
         */
        hours?: number;
        /**
         * Minutes of hour of day. Must be from 0 to 59.
         */
        minutes?: number;
        /**
         * Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999.
         */
        nanos?: number;
        /**
         * Seconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
         */
        seconds?: number;
    }

    export interface PatchDeploymentRecurringScheduleTimeZone {
        /**
         * IANA Time Zone Database time zone, e.g. "America/New_York".
         */
        id: string;
        /**
         * IANA Time Zone Database version number, e.g. "2019a".
         */
        version?: string;
    }

    export interface PatchDeploymentRecurringScheduleWeekly {
        /**
         * A day of the week.
         * Possible values are `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, and `SUNDAY`.
         */
        dayOfWeek: string;
    }

    export interface PatchDeploymentRollout {
        /**
         * The maximum number (or percentage) of VMs per zone to disrupt at any given moment. The number of VMs calculated from multiplying the percentage by the total number of VMs in a zone is rounded up.
         * During patching, a VM is considered disrupted from the time the agent is notified to begin until patching has completed. This disruption time includes the time to complete reboot and any post-patch steps.
         * A VM contributes to the disruption budget if its patching operation fails either when applying the patches, running pre or post patch steps, or if it fails to respond with a success notification before timing out. VMs that are not running or do not have an active agent do not count toward this disruption budget.
         * For zone-by-zone rollouts, if the disruption budget in a zone is exceeded, the patch job stops, because continuing to the next zone requires completion of the patch process in the previous zone.
         * For example, if the disruption budget has a fixed value of 10, and 8 VMs fail to patch in the current zone, the patch job continues to patch 2 VMs at a time until the zone is completed. When that zone is completed successfully, patching begins with 10 VMs at a time in the next zone. If 10 VMs in the next zone fail to patch, the patch job stops.
         * Structure is documented below.
         */
        disruptionBudget: outputs.osconfig.PatchDeploymentRolloutDisruptionBudget;
        /**
         * Mode of the patch rollout.
         * Possible values are `ZONE_BY_ZONE` and `CONCURRENT_ZONES`.
         */
        mode: string;
    }

    export interface PatchDeploymentRolloutDisruptionBudget {
        /**
         * Specifies a fixed value.
         */
        fixed?: number;
        /**
         * Specifies the relative value defined as a percentage, which will be multiplied by a reference value.
         */
        percentage?: number;
    }

}

export namespace projects {
    export interface AccessApprovalSettingsEnrolledService {
        /**
         * The product for which Access Approval will be enrolled. Allowed values are listed (case-sensitive):
         * all
         * appengine.googleapis.com
         * bigquery.googleapis.com
         * bigtable.googleapis.com
         * cloudkms.googleapis.com
         * compute.googleapis.com
         * dataflow.googleapis.com
         * iam.googleapis.com
         * pubsub.googleapis.com
         * storage.googleapis.com
         */
        cloudProduct: string;
        /**
         * The enrollment level of the service.
         * Default value is `BLOCK_ALL`.
         * Possible values are `BLOCK_ALL`.
         */
        enrollmentLevel?: string;
    }

    export interface ApiKeyRestrictions {
        /**
         * The Android apps that are allowed to use the key.
         */
        androidKeyRestrictions?: outputs.projects.ApiKeyRestrictionsAndroidKeyRestrictions;
        /**
         * A restriction for a specific service and optionally one or more specific methods. Requests are allowed if they match any of these restrictions. If no restrictions are specified, all targets are allowed.
         */
        apiTargets?: outputs.projects.ApiKeyRestrictionsApiTarget[];
        /**
         * The HTTP referrers (websites) that are allowed to use the key.
         */
        browserKeyRestrictions?: outputs.projects.ApiKeyRestrictionsBrowserKeyRestrictions;
        /**
         * The iOS apps that are allowed to use the key.
         */
        iosKeyRestrictions?: outputs.projects.ApiKeyRestrictionsIosKeyRestrictions;
        /**
         * The IP addresses of callers that are allowed to use the key.
         */
        serverKeyRestrictions?: outputs.projects.ApiKeyRestrictionsServerKeyRestrictions;
    }

    export interface ApiKeyRestrictionsAndroidKeyRestrictions {
        /**
         * A list of Android applications that are allowed to make API calls with this key.
         */
        allowedApplications: outputs.projects.ApiKeyRestrictionsAndroidKeyRestrictionsAllowedApplication[];
    }

    export interface ApiKeyRestrictionsAndroidKeyRestrictionsAllowedApplication {
        /**
         * The package name of the application.
         */
        packageName: string;
        /**
         * The SHA1 fingerprint of the application. For example, both sha1 formats are acceptable : DA:39:A3:EE:5E:6B:4B:0D:32:55:BF:EF:95:60:18:90:AF:D8:07:09 or DA39A3EE5E6B4B0D3255BFEF95601890AFD80709. Output format is the latter.
         */
        sha1Fingerprint: string;
    }

    export interface ApiKeyRestrictionsApiTarget {
        /**
         * Optional. List of one or more methods that can be called. If empty, all methods for the service are allowed. A wildcard (*) can be used as the last symbol. Valid examples: `google.cloud.translate.v2.TranslateService.GetSupportedLanguage` `TranslateText` `Get*` `translate.googleapis.com.Get*`
         */
        methods?: string[];
        /**
         * The service for this restriction. It should be the canonical service name, for example: `translate.googleapis.com`. You can use `gcloud services list` to get a list of services that are enabled in the project.
         */
        service: string;
    }

    export interface ApiKeyRestrictionsBrowserKeyRestrictions {
        /**
         * A list of regular expressions for the referrer URLs that are allowed to make API calls with this key.
         */
        allowedReferrers: string[];
    }

    export interface ApiKeyRestrictionsIosKeyRestrictions {
        /**
         * A list of bundle IDs that are allowed when making API calls with this key.
         */
        allowedBundleIds: string[];
    }

    export interface ApiKeyRestrictionsServerKeyRestrictions {
        /**
         * A list of the caller IP addresses that are allowed to make API calls with this key.
         */
        allowedIps: string[];
    }

    export interface GetOrganizationPolicyBooleanPolicy {
        enforced: boolean;
    }

    export interface GetOrganizationPolicyListPolicy {
        allows: outputs.projects.GetOrganizationPolicyListPolicyAllow[];
        denies: outputs.projects.GetOrganizationPolicyListPolicyDeny[];
        inheritFromParent: boolean;
        suggestedValue: string;
    }

    export interface GetOrganizationPolicyListPolicyAllow {
        all: boolean;
        values: string[];
    }

    export interface GetOrganizationPolicyListPolicyDeny {
        all: boolean;
        values: string[];
    }

    export interface GetOrganizationPolicyRestorePolicy {
        default: boolean;
    }

    export interface GetProjectProject {
        /**
         * Creation time in RFC3339 UTC "Zulu" format.
         */
        createTime: string;
        /**
         * A set of key/value label pairs assigned on a project.
         */
        labels: {[key: string]: string};
        /**
         * The Project lifecycle state.
         */
        lifecycleState: string;
        /**
         * The optional user-assigned display name of the project.
         */
        name: string;
        /**
         * The numeric identifier of the project.
         */
        number: string;
        /**
         * An optional reference to a parent resource.
         */
        parent: {[key: string]: string};
        /**
         * The project id of the project.
         */
        projectId: string;
    }

    export interface IAMAuditConfigAuditLogConfig {
        /**
         * Identities that do not cause logging for this type of permission.  The format is the same as that for `members`.
         */
        exemptedMembers?: string[];
        /**
         * Permission type for which logging is to be configured.  Must be one of `DATA_READ`, `DATA_WRITE`, or `ADMIN_READ`.
         */
        logType: string;
    }

    export interface IAMBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface IAMMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface OrganizationPolicyBooleanPolicy {
        /**
         * If true, then the Policy is enforced. If false, then any configuration is acceptable.
         */
        enforced: boolean;
    }

    export interface OrganizationPolicyListPolicy {
        /**
         * or `deny` - (Optional) One or the other must be set.
         */
        allow?: outputs.projects.OrganizationPolicyListPolicyAllow;
        deny?: outputs.projects.OrganizationPolicyListPolicyDeny;
        /**
         * If set to true, the values from the effective Policy of the parent resource
         * are inherited, meaning the values set in this Policy are added to the values inherited up the hierarchy.
         */
        inheritFromParent?: boolean;
        /**
         * The Google Cloud Console will try to default to a configuration that matches the value specified in this field.
         */
        suggestedValue: string;
    }

    export interface OrganizationPolicyListPolicyAllow {
        /**
         * The policy allows or denies all values.
         */
        all?: boolean;
        /**
         * The policy can define specific values that are allowed or denied.
         */
        values?: string[];
    }

    export interface OrganizationPolicyListPolicyDeny {
        /**
         * The policy allows or denies all values.
         */
        all?: boolean;
        /**
         * The policy can define specific values that are allowed or denied.
         */
        values?: string[];
    }

    export interface OrganizationPolicyRestorePolicy {
        /**
         * May only be set to true. If set, then the default Policy is restored.
         */
        default: boolean;
    }

}

export namespace pubsub {
    export interface GetTopicMessageStoragePolicy {
        allowedPersistenceRegions: string[];
    }

    export interface GetTopicSchemaSetting {
        encoding: string;
        schema: string;
    }

    export interface LiteSubscriptionDeliveryConfig {
        /**
         * When this subscription should send messages to subscribers relative to messages persistence in storage.
         * Possible values are `DELIVER_IMMEDIATELY`, `DELIVER_AFTER_STORED`, and `DELIVERY_REQUIREMENT_UNSPECIFIED`.
         */
        deliveryRequirement: string;
    }

    export interface LiteTopicPartitionConfig {
        /**
         * The capacity configuration.
         * Structure is documented below.
         */
        capacity?: outputs.pubsub.LiteTopicPartitionConfigCapacity;
        /**
         * The number of partitions in the topic. Must be at least 1.
         */
        count: number;
    }

    export interface LiteTopicPartitionConfigCapacity {
        /**
         * Subscribe throughput capacity per partition in MiB/s. Must be >= 4 and <= 16.
         */
        publishMibPerSec: number;
        /**
         * Publish throughput capacity per partition in MiB/s. Must be >= 4 and <= 16.
         */
        subscribeMibPerSec: number;
    }

    export interface LiteTopicReservationConfig {
        /**
         * The Reservation to use for this topic's throughput capacity.
         */
        throughputReservation?: string;
    }

    export interface LiteTopicRetentionConfig {
        /**
         * The provisioned storage, in bytes, per partition. If the number of bytes stored
         * in any of the topic's partitions grows beyond this value, older messages will be
         * dropped to make room for newer ones, regardless of the value of period.
         */
        perPartitionBytes: string;
        /**
         * How long a published message is retained. If unset, messages will be retained as
         * long as the bytes retained for each partition is below perPartitionBytes. A
         * duration in seconds with up to nine fractional digits, terminated by 's'.
         * Example: "3.5s".
         */
        period?: string;
    }

    export interface SubscriptionDeadLetterPolicy {
        /**
         * The name of the topic to which dead letter messages should be published.
         * Format is `projects/{project}/topics/{topic}`.
         * The Cloud Pub/Sub service account associated with the enclosing subscription's
         * parent project (i.e.,
         * service-{project_number}@gcp-sa-pubsub.iam.gserviceaccount.com) must have
         * permission to Publish() to this topic.
         * The operation will fail if the topic does not exist.
         * Users should ensure that there is a subscription attached to this topic
         * since messages published to a topic with no subscriptions are lost.
         */
        deadLetterTopic?: string;
        /**
         * The maximum number of delivery attempts for any message. The value must be
         * between 5 and 100.
         * The number of delivery attempts is defined as 1 + (the sum of number of
         * NACKs and number of times the acknowledgement deadline has been exceeded for the message).
         * A NACK is any call to ModifyAckDeadline with a 0 deadline. Note that
         * client libraries may automatically extend ack_deadlines.
         * This field will be honored on a best effort basis.
         * If this parameter is 0, a default value of 5 is used.
         */
        maxDeliveryAttempts?: number;
    }

    export interface SubscriptionExpirationPolicy {
        /**
         * Specifies the "time-to-live" duration for an associated resource. The
         * resource expires if it is not active for a period of ttl.
         * If ttl is not set, the associated resource never expires.
         * A duration in seconds with up to nine fractional digits, terminated by 's'.
         * Example - "3.5s".
         */
        ttl: string;
    }

    export interface SubscriptionIAMBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface SubscriptionIAMMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface SubscriptionPushConfig {
        /**
         * Endpoint configuration attributes.
         * Every endpoint has a set of API supported attributes that can
         * be used to control different aspects of the message delivery.
         * The currently supported attribute is x-goog-version, which you
         * can use to change the format of the pushed message. This
         * attribute indicates the version of the data expected by
         * the endpoint. This controls the shape of the pushed message
         * (i.e., its fields and metadata). The endpoint version is
         * based on the version of the Pub/Sub API.
         * If not present during the subscriptions.create call,
         * it will default to the version of the API used to make
         * such call. If not present during a subscriptions.modifyPushConfig
         * call, its value will not be changed. subscriptions.get
         * calls will always return a valid version, even if the
         * subscription was created without this attribute.
         * The possible values for this attribute are:
         * - v1beta1: uses the push format defined in the v1beta1 Pub/Sub API.
         * - v1 or v1beta2: uses the push format defined in the v1 Pub/Sub API.
         */
        attributes?: {[key: string]: string};
        /**
         * If specified, Pub/Sub will generate and attach an OIDC JWT token as
         * an Authorization header in the HTTP request for every pushed message.
         * Structure is documented below.
         */
        oidcToken?: outputs.pubsub.SubscriptionPushConfigOidcToken;
        /**
         * A URL locating the endpoint to which messages should be pushed.
         * For example, a Webhook endpoint might use
         * "https://example.com/push".
         */
        pushEndpoint: string;
    }

    export interface SubscriptionPushConfigOidcToken {
        /**
         * Audience to be used when generating OIDC token. The audience claim
         * identifies the recipients that the JWT is intended for. The audience
         * value is a single case-sensitive string. Having multiple values (array)
         * for the audience field is not supported. More info about the OIDC JWT
         * token audience here: https://tools.ietf.org/html/rfc7519#section-4.1.3
         * Note: if not specified, the Push endpoint URL will be used.
         */
        audience?: string;
        /**
         * Service account email to be used for generating the OIDC token.
         * The caller (for subscriptions.create, subscriptions.patch, and
         * subscriptions.modifyPushConfig RPCs) must have the
         * iam.serviceAccounts.actAs permission for the service account.
         */
        serviceAccountEmail: string;
    }

    export interface SubscriptionRetryPolicy {
        /**
         * The maximum delay between consecutive deliveries of a given message. Value should be between 0 and 600 seconds. Defaults to 600 seconds.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        maximumBackoff: string;
        /**
         * The minimum delay between consecutive deliveries of a given message. Value should be between 0 and 600 seconds. Defaults to 10 seconds.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        minimumBackoff: string;
    }

    export interface TopicIAMBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface TopicIAMMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface TopicMessageStoragePolicy {
        /**
         * A list of IDs of GCP regions where messages that are published to
         * the topic may be persisted in storage. Messages published by
         * publishers running in non-allowed GCP regions (or running outside
         * of GCP altogether) will be routed for storage in one of the
         * allowed regions. An empty list means that no regions are allowed,
         * and is not a valid configuration.
         */
        allowedPersistenceRegions: string[];
    }

    export interface TopicSchemaSettings {
        /**
         * The encoding of messages validated against schema.
         * Default value is `ENCODING_UNSPECIFIED`.
         * Possible values are `ENCODING_UNSPECIFIED`, `JSON`, and `BINARY`.
         */
        encoding?: string;
        /**
         * The name of the schema that messages published should be
         * validated against. Format is projects/{project}/schemas/{schema}.
         * The value of this field will be _deleted-schema_
         * if the schema has been deleted.
         */
        schema: string;
    }

}

export namespace recaptcha {
    export interface EnterpriseKeyAndroidSettings {
        /**
         * If set to true, it means allowedPackageNames will not be enforced.
         */
        allowAllPackageNames?: boolean;
        /**
         * Android package names of apps allowed to use the key. Example: 'com.companyname.appname'
         */
        allowedPackageNames?: string[];
    }

    export interface EnterpriseKeyIosSettings {
        /**
         * If set to true, it means allowedBundleIds will not be enforced.
         */
        allowAllBundleIds?: boolean;
        /**
         * iOS bundle ids of apps allowed to use the key. Example: 'com.companyname.productname.appname'
         */
        allowedBundleIds?: string[];
    }

    export interface EnterpriseKeyTestingOptions {
        /**
         * For challenge-based keys only (CHECKBOX, INVISIBLE), all challenge requests for this site will return nocaptcha if NOCAPTCHA, or an unsolvable challenge if UNSOLVABLE_CHALLENGE. Possible values: TESTING_CHALLENGE_UNSPECIFIED, NOCAPTCHA, UNSOLVABLE_CHALLENGE
         */
        testingChallenge: string;
        /**
         * All assessments for this Key will return this score. Must be between 0 (likely not legitimate) and 1 (likely legitimate) inclusive.
         */
        testingScore?: number;
    }

    export interface EnterpriseKeyWebSettings {
        /**
         * If set to true, it means allowedDomains will not be enforced.
         */
        allowAllDomains?: boolean;
        /**
         * If set to true, the key can be used on AMP (Accelerated Mobile Pages) websites. This is supported only for the SCORE integration type.
         */
        allowAmpTraffic?: boolean;
        /**
         * Domains or subdomains of websites allowed to use the key. All subdomains of an allowed domain are automatically allowed. A valid domain requires a host and must not include any path, port, query or fragment. Examples: 'example.com' or 'subdomain.example.com'
         */
        allowedDomains?: string[];
        /**
         * Settings for the frequency and difficulty at which this key triggers captcha challenges. This should only be specified for IntegrationTypes CHECKBOX and INVISIBLE. Possible values: CHALLENGE_SECURITY_PREFERENCE_UNSPECIFIED, USABILITY, BALANCE, SECURITY
         */
        challengeSecurityPreference: string;
        /**
         * Required. Describes how this key is integrated with the website. Possible values: SCORE, CHECKBOX, INVISIBLE
         */
        integrationType: string;
    }

}

export namespace redis {
    export interface GetInstanceMaintenancePolicy {
        createTime: string;
        description: string;
        updateTime: string;
        weeklyMaintenanceWindows: outputs.redis.GetInstanceMaintenancePolicyWeeklyMaintenanceWindow[];
    }

    export interface GetInstanceMaintenancePolicyWeeklyMaintenanceWindow {
        day: string;
        duration: string;
        startTimes: outputs.redis.GetInstanceMaintenancePolicyWeeklyMaintenanceWindowStartTime[];
    }

    export interface GetInstanceMaintenancePolicyWeeklyMaintenanceWindowStartTime {
        hours: number;
        minutes: number;
        nanos: number;
        seconds: number;
    }

    export interface GetInstanceMaintenanceSchedule {
        endTime: string;
        scheduleDeadlineTime: string;
        startTime: string;
    }

    export interface GetInstanceNode {
        id: string;
        zone: string;
    }

    export interface GetInstanceServerCaCert {
        cert: string;
        createTime: string;
        expireTime: string;
        serialNumber: string;
        sha1Fingerprint: string;
    }

    export interface InstanceMaintenancePolicy {
        /**
         * -
         * Output only. The time when the policy was created.
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond
         * resolution and up to nine fractional digits.
         */
        createTime: string;
        /**
         * Optional. Description of what this policy is for.
         * Create/Update methods return INVALID_ARGUMENT if the
         * length is greater than 512.
         */
        description?: string;
        /**
         * -
         * Output only. The time when the policy was last updated.
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond
         * resolution and up to nine fractional digits.
         */
        updateTime: string;
        /**
         * Optional. Maintenance window that is applied to resources covered by this policy.
         * Minimum 1. For the current version, the maximum number
         * of weeklyWindow is expected to be one.
         * Structure is documented below.
         */
        weeklyMaintenanceWindows?: outputs.redis.InstanceMaintenancePolicyWeeklyMaintenanceWindow[];
    }

    export interface InstanceMaintenancePolicyWeeklyMaintenanceWindow {
        /**
         * Required. The day of week that maintenance updates occur.
         * - DAY_OF_WEEK_UNSPECIFIED: The day of the week is unspecified.
         * - MONDAY: Monday
         * - TUESDAY: Tuesday
         * - WEDNESDAY: Wednesday
         * - THURSDAY: Thursday
         * - FRIDAY: Friday
         * - SATURDAY: Saturday
         * - SUNDAY: Sunday
         * Possible values are `DAY_OF_WEEK_UNSPECIFIED`, `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, and `SUNDAY`.
         */
        day: string;
        /**
         * -
         * Output only. Duration of the maintenance window.
         * The current window is fixed at 1 hour.
         * A duration in seconds with up to nine fractional digits,
         * terminated by 's'. Example: "3.5s".
         */
        duration: string;
        /**
         * -
         * Output only. The start time of any upcoming scheduled maintenance for this instance.
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond
         * resolution and up to nine fractional digits.
         */
        startTime: outputs.redis.InstanceMaintenancePolicyWeeklyMaintenanceWindowStartTime;
    }

    export interface InstanceMaintenancePolicyWeeklyMaintenanceWindowStartTime {
        /**
         * Hours of day in 24 hour format. Should be from 0 to 23.
         * An API may choose to allow the value "24:00:00" for scenarios like business closing time.
         */
        hours?: number;
        /**
         * Minutes of hour of day. Must be from 0 to 59.
         */
        minutes?: number;
        /**
         * Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999.
         */
        nanos?: number;
        /**
         * Seconds of minutes of the time. Must normally be from 0 to 59.
         * An API may allow the value 60 if it allows leap-seconds.
         */
        seconds?: number;
    }

    export interface InstanceMaintenanceSchedule {
        /**
         * -
         * Output only. The end time of any upcoming scheduled maintenance for this instance.
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond
         * resolution and up to nine fractional digits.
         */
        endTime: string;
        /**
         * -
         * Output only. The deadline that the maintenance schedule start time
         * can not go beyond, including reschedule.
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond
         * resolution and up to nine fractional digits.
         */
        scheduleDeadlineTime: string;
        /**
         * -
         * Output only. The start time of any upcoming scheduled maintenance for this instance.
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond
         * resolution and up to nine fractional digits.
         */
        startTime: string;
    }

    export interface InstanceNode {
        /**
         * an identifier for the resource with format `projects/{{project}}/locations/{{region}}/instances/{{name}}`
         */
        id: string;
        zone: string;
    }

    export interface InstanceServerCaCert {
        cert: string;
        /**
         * -
         * Output only. The time when the policy was created.
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond
         * resolution and up to nine fractional digits.
         */
        createTime: string;
        expireTime: string;
        serialNumber: string;
        sha1Fingerprint: string;
    }
}

export namespace runtimeconfig {
    export interface ConfigIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ConfigIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

}

export namespace secretmanager {
    export interface GetSecretReplication {
        automatic: boolean;
        userManageds: outputs.secretmanager.GetSecretReplicationUserManaged[];
    }

    export interface GetSecretReplicationUserManaged {
        replicas: outputs.secretmanager.GetSecretReplicationUserManagedReplica[];
    }

    export interface GetSecretReplicationUserManagedReplica {
        customerManagedEncryptions: outputs.secretmanager.GetSecretReplicationUserManagedReplicaCustomerManagedEncryption[];
        location: string;
    }

    export interface GetSecretReplicationUserManagedReplicaCustomerManagedEncryption {
        kmsKeyName: string;
    }

    export interface GetSecretRotation {
        nextRotationTime: string;
        rotationPeriod: string;
    }

    export interface GetSecretTopic {
        name: string;
    }

    export interface SecretIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface SecretIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface SecretReplication {
        /**
         * The Secret will automatically be replicated without any restrictions.
         */
        automatic?: boolean;
        /**
         * The Secret will automatically be replicated without any restrictions.
         * Structure is documented below.
         */
        userManaged?: outputs.secretmanager.SecretReplicationUserManaged;
    }

    export interface SecretReplicationUserManaged {
        /**
         * The list of Replicas for this Secret. Cannot be empty.
         * Structure is documented below.
         */
        replicas: outputs.secretmanager.SecretReplicationUserManagedReplica[];
    }

    export interface SecretReplicationUserManagedReplica {
        /**
         * Customer Managed Encryption for the secret.
         * Structure is documented below.
         */
        customerManagedEncryption?: outputs.secretmanager.SecretReplicationUserManagedReplicaCustomerManagedEncryption;
        /**
         * The canonical IDs of the location to replicate data. For example: "us-east1".
         */
        location: string;
    }

    export interface SecretReplicationUserManagedReplicaCustomerManagedEncryption {
        /**
         * Describes the Cloud KMS encryption key that will be used to protect destination secret.
         */
        kmsKeyName: string;
    }

    export interface SecretRotation {
        /**
         * Timestamp in UTC at which the Secret is scheduled to rotate.
         * A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
         */
        nextRotationTime?: string;
        /**
         * The Duration between rotation notifications. Must be in seconds and at least 3600s (1h) and at most 3153600000s (100 years).
         * If rotationPeriod is set, `nextRotationTime` must be set. `nextRotationTime` will be advanced by this period when the service automatically sends rotation notifications.
         */
        rotationPeriod?: string;
    }

    export interface SecretTopic {
        /**
         * The resource name of the Pub/Sub topic that will be published to, in the following format: projects/*&#47;topics/*.
         * For publication to succeed, the Secret Manager Service Agent service account must have pubsub.publisher permissions on the topic.
         */
        name: string;
    }
}

export namespace securitycenter {
    export interface NotificationConfigStreamingConfig {
        /**
         * Expression that defines the filter to apply across create/update
         * events of assets or findings as specified by the event type. The
         * expression is a list of zero or more restrictions combined via
         * logical operators AND and OR. Parentheses are supported, and OR
         * has higher precedence than AND.
         * Restrictions have the form <field> <operator> <value> and may have
         * a - character in front of them to indicate negation. The fields
         * map to those defined in the corresponding resource.
         * The supported operators are:
         * * = for all value types.
         * * >, <, >=, <= for integer values.
         * * :, meaning substring matching, for strings.
         * The supported value types are:
         * * string literals in quotes.
         * * integer literals without quotes.
         * * boolean literals true and false without quotes.
         * See
         * [Filtering notifications](https://cloud.google.com/security-command-center/docs/how-to-api-filter-notifications)
         * for information on how to write a filter.
         */
        filter: string;
    }

}

export namespace serviceAccount {
    export interface IAMBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface IAMMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

}

export namespace servicedirectory {
    export interface NamespaceIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface NamespaceIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ServiceIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface ServiceIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

}

export namespace sourcerepo {
    export interface GetRepositoryPubsubConfig {
        messageFormat: string;
        serviceAccountEmail: string;
        topic: string;
    }

    export interface RepositoryIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface RepositoryIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface RepositoryPubsubConfig {
        /**
         * The format of the Cloud Pub/Sub messages.
         * - PROTOBUF: The message payload is a serialized protocol buffer of SourceRepoEvent.
         * - JSON: The message payload is a JSON string of SourceRepoEvent.
         * Possible values are `PROTOBUF` and `JSON`.
         */
        messageFormat: string;
        /**
         * Email address of the service account used for publishing Cloud Pub/Sub messages.
         * This service account needs to be in the same project as the PubsubConfig. When added,
         * the caller needs to have iam.serviceAccounts.actAs permission on this service account.
         * If unspecified, it defaults to the compute engine default service account.
         */
        serviceAccountEmail: string;
        /**
         * The identifier for this object. Format specified above.
         */
        topic: string;
    }

}

export namespace spanner {
    export interface DatabaseEncryptionConfig {
        /**
         * Fully qualified name of the KMS key to use to encrypt this database. This key must exist
         * in the same location as the Spanner Database.
         */
        kmsKeyName: string;
    }

    export interface DatabaseIAMBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface DatabaseIAMMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface InstanceIAMBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface InstanceIAMMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

}

export namespace sql {
    export interface DatabaseInstanceClone {
        /**
         * The name of the allocated ip range for the private ip CloudSQL instance. For example: "google-managed-services-default". If set, the cloned instance ip will be created in the allocated range. The range name must comply with [RFC 1035](https://tools.ietf.org/html/rfc1035). Specifically, the name must be 1-63 characters long and match the regular expression a-z?.
         */
        allocatedIpRange?: string;
        /**
         * The timestamp of the point in time that should be restored.
         */
        pointInTime?: string;
        /**
         * Name of the source instance which will be cloned.
         */
        sourceInstanceName: string;
    }

    export interface DatabaseInstanceIpAddress {
        ipAddress: string;
        timeToRetire: string;
        type: string;
    }

    export interface DatabaseInstanceReplicaConfiguration {
        /**
         * PEM representation of the trusted CA's x509
         * certificate.
         */
        caCertificate?: string;
        /**
         * PEM representation of the replica's x509
         * certificate.
         */
        clientCertificate?: string;
        /**
         * PEM representation of the replica's private key. The
         * corresponding public key in encoded in the `clientCertificate`.
         */
        clientKey?: string;
        /**
         * The number of seconds
         * between connect retries.
         */
        connectRetryInterval?: number;
        /**
         * Path to a SQL file in GCS from which replica
         * instances are created. Format is `gs://bucket/filename`.
         */
        dumpFilePath?: string;
        /**
         * Specifies if the replica is the failover target.
         * If the field is set to true the replica will be designated as a failover replica.
         * If the master instance fails, the replica instance will be promoted as
         * the new master instance.
         */
        failoverTarget?: boolean;
        /**
         * Time in ms between replication
         * heartbeats.
         */
        masterHeartbeatPeriod?: number;
        /**
         * Password for the replication connection.
         */
        password?: string;
        sslCipher?: string;
        /**
         * Username for replication connection.
         */
        username?: string;
        /**
         * True if the master's common name
         * value is checked during the SSL handshake.
         */
        verifyServerCertificate?: boolean;
    }

    export interface DatabaseInstanceRestoreBackupContext {
        /**
         * The ID of the backup run to restore from.
         */
        backupRunId: number;
        /**
         * The ID of the instance that the backup was taken from. If left empty,
         * this instance's ID will be used.
         */
        instanceId?: string;
        /**
         * The full project ID of the source instance.`
         */
        project?: string;
    }

    export interface DatabaseInstanceServerCaCert {
        cert: string;
        commonName: string;
        createTime: string;
        /**
         * The [RFC 3339](https://tools.ietf.org/html/rfc3339)
         * formatted date time string indicating when this whitelist expires.
         */
        expirationTime: string;
        sha1Fingerprint: string;
    }

    export interface DatabaseInstanceSettings {
        /**
         * This specifies when the instance should be
         * active. Can be either `ALWAYS`, `NEVER` or `ON_DEMAND`.
         */
        activationPolicy?: string;
        activeDirectoryConfig?: outputs.sql.DatabaseInstanceSettingsActiveDirectoryConfig;
        /**
         * The availability type of the Cloud SQL
         * instance, high availability (`REGIONAL`) or single zone (`ZONAL`).' For all instances, ensure that
         * `settings.backup_configuration.enabled` is set to `true`.
         * For MySQL instances, ensure that `settings.backup_configuration.binary_log_enabled` is set to `true`.
         * For Postgres instances, ensure that `settings.backup_configuration.point_in_time_recovery_enabled`
         * is set to `true`.
         */
        availabilityType?: string;
        backupConfiguration: outputs.sql.DatabaseInstanceSettingsBackupConfiguration;
        /**
         * The name of server instance collation.
         */
        collation?: string;
        databaseFlags?: outputs.sql.DatabaseInstanceSettingsDatabaseFlag[];
        /**
         * Enables auto-resizing of the storage size. Set to false if you want to set `diskSize`.
         */
        diskAutoresize?: boolean;
        diskAutoresizeLimit?: number;
        /**
         * The size of data disk, in GB. Size of a running instance cannot be reduced but can be increased. If you want to set this field, set `diskAutoresize` to false.
         */
        diskSize: number;
        /**
         * The type of data disk: PD_SSD or PD_HDD.
         */
        diskType?: string;
        insightsConfig?: outputs.sql.DatabaseInstanceSettingsInsightsConfig;
        ipConfiguration: outputs.sql.DatabaseInstanceSettingsIpConfiguration;
        locationPreference: outputs.sql.DatabaseInstanceSettingsLocationPreference;
        maintenanceWindow?: outputs.sql.DatabaseInstanceSettingsMaintenanceWindow;
        /**
         * Pricing plan for this instance, can only be `PER_USE`.
         */
        pricingPlan?: string;
        /**
         * The machine type to use. See [tiers](https://cloud.google.com/sql/docs/admin-api/v1beta4/tiers)
         * for more details and supported versions. Postgres supports only shared-core machine types,
         * and custom machine types such as `db-custom-2-13312`. See the [Custom Machine Type Documentation](https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type#create) to learn about specifying custom machine types.
         */
        tier: string;
        /**
         * A set of key/value user label pairs to assign to the instance.
         */
        userLabels: {[key: string]: string};
        version: number;
    }

    export interface DatabaseInstanceSettingsActiveDirectoryConfig {
        /**
         * The domain name for the active directory (e.g., mydomain.com).
         * Can only be used with SQL Server.
         */
        domain: string;
    }

    export interface DatabaseInstanceSettingsBackupConfiguration {
        /**
         * Backup retention settings. The configuration is detailed below.
         */
        backupRetentionSettings: outputs.sql.DatabaseInstanceSettingsBackupConfigurationBackupRetentionSettings;
        /**
         * True if binary logging is enabled.
         * Can only be used with MySQL.
         */
        binaryLogEnabled?: boolean;
        /**
         * True if backup configuration is enabled.
         */
        enabled?: boolean;
        /**
         * The region where the backup will be stored
         */
        location?: string;
        /**
         * True if Point-in-time recovery is enabled. Will restart database if enabled after instance creation. Valid only for PostgreSQL instances.
         */
        pointInTimeRecoveryEnabled?: boolean;
        /**
         * `HH:MM` format time indicating when backup
         * configuration starts.
         */
        startTime: string;
        /**
         * The number of days of transaction logs we retain for point in time restore, from 1-7.
         */
        transactionLogRetentionDays: number;
    }

    export interface DatabaseInstanceSettingsBackupConfigurationBackupRetentionSettings {
        /**
         * Depending on the value of retention_unit, this is used to determine if a backup needs to be deleted. If retentionUnit
         * is 'COUNT', we will retain this many backups.
         */
        retainedBackups: number;
        /**
         * The unit that 'retained_backups' represents. Defaults to `COUNT`.
         */
        retentionUnit?: string;
    }

    export interface DatabaseInstanceSettingsDatabaseFlag {
        /**
         * A name for this whitelist entry.
         */
        name: string;
        /**
         * A CIDR notation IPv4 or IPv6 address that is allowed to
         * access this instance. Must be set even if other two attributes are not for
         * the whitelist to become active.
         */
        value: string;
    }

    export interface DatabaseInstanceSettingsInsightsConfig {
        /**
         * True if Query Insights feature is enabled.
         */
        queryInsightsEnabled?: boolean;
        /**
         * Maximum query length stored in bytes. Between 256 and 4500. Default to 1024.
         */
        queryStringLength?: number;
        /**
         * True if Query Insights will record application tags from query when enabled.
         */
        recordApplicationTags?: boolean;
        /**
         * True if Query Insights will record client address when enabled.
         */
        recordClientAddress?: boolean;
    }

    export interface DatabaseInstanceSettingsIpConfiguration {
        /**
         * The name of the allocated ip range for the private ip CloudSQL instance. For example: "google-managed-services-default". If set, the cloned instance ip will be created in the allocated range. The range name must comply with [RFC 1035](https://tools.ietf.org/html/rfc1035). Specifically, the name must be 1-63 characters long and match the regular expression a-z?.
         */
        allocatedIpRange?: string;
        authorizedNetworks?: outputs.sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetwork[];
        /**
         * Whether this Cloud SQL instance should be assigned
         * a public IPV4 address. At least `ipv4Enabled` must be enabled or a
         * `privateNetwork` must be configured.
         */
        ipv4Enabled?: boolean;
        /**
         * The VPC network from which the Cloud SQL
         * instance is accessible for private IP. For example,projects/myProject/global/networks/default.
         * Specifying a network enables private IP.
         * At least `ipv4Enabled` must be enabled or a `privateNetwork` must be configured.
         * This setting can be updated, but it cannot be removed after it is set.
         */
        privateNetwork?: string;
        /**
         * Whether SSL connections over IP are enforced or not.
         */
        requireSsl?: boolean;
    }

    export interface DatabaseInstanceSettingsIpConfigurationAuthorizedNetwork {
        /**
         * The [RFC 3339](https://tools.ietf.org/html/rfc3339)
         * formatted date time string indicating when this whitelist expires.
         */
        expirationTime?: string;
        /**
         * A name for this whitelist entry.
         */
        name?: string;
        /**
         * A CIDR notation IPv4 or IPv6 address that is allowed to
         * access this instance. Must be set even if other two attributes are not for
         * the whitelist to become active.
         */
        value: string;
    }

    export interface DatabaseInstanceSettingsLocationPreference {
        /**
         * A GAE application whose zone to remain
         * in. Must be in the same region as this instance.
         */
        followGaeApplication?: string;
        /**
         * The preferred compute engine
         * [zone](https://cloud.google.com/compute/docs/zones?hl=en).
         */
        zone?: string;
    }

    export interface DatabaseInstanceSettingsMaintenanceWindow {
        /**
         * Day of week (`1-7`), starting on Monday
         */
        day?: number;
        /**
         * Hour of day (`0-23`), ignored if `day` not set
         */
        hour?: number;
        /**
         * Receive updates earlier (`canary`) or later
         * (`stable`)
         */
        updateTrack?: string;
    }

    export interface GetCaCertsCert {
        /**
         * The CA certificate used to connect to the SQL instance via SSL.
         */
        cert: string;
        /**
         * The CN valid for the CA cert.
         */
        commonName: string;
        /**
         * Creation time of the CA cert.
         */
        createTime: string;
        /**
         * Expiration time of the CA cert.
         */
        expirationTime: string;
        /**
         * SHA1 fingerprint of the CA cert.
         */
        sha1Fingerprint: string;
    }

    export interface GetDatabaseInstanceClone {
        allocatedIpRange: string;
        pointInTime: string;
        sourceInstanceName: string;
    }

    export interface GetDatabaseInstanceIpAddress {
        ipAddress: string;
        timeToRetire: string;
        type: string;
    }

    export interface GetDatabaseInstanceReplicaConfiguration {
        caCertificate: string;
        clientCertificate: string;
        clientKey: string;
        connectRetryInterval: number;
        dumpFilePath: string;
        failoverTarget: boolean;
        masterHeartbeatPeriod: number;
        password: string;
        sslCipher: string;
        username: string;
        verifyServerCertificate: boolean;
    }

    export interface GetDatabaseInstanceRestoreBackupContext {
        backupRunId: number;
        instanceId: string;
        /**
         * The ID of the project in which the resource belongs.
         */
        project: string;
    }

    export interface GetDatabaseInstanceServerCaCert {
        cert: string;
        commonName: string;
        createTime: string;
        expirationTime: string;
        sha1Fingerprint: string;
    }

    export interface GetDatabaseInstanceSetting {
        activationPolicy: string;
        activeDirectoryConfigs: outputs.sql.GetDatabaseInstanceSettingActiveDirectoryConfig[];
        availabilityType: string;
        backupConfigurations: outputs.sql.GetDatabaseInstanceSettingBackupConfiguration[];
        collation: string;
        databaseFlags: outputs.sql.GetDatabaseInstanceSettingDatabaseFlag[];
        diskAutoresize: boolean;
        diskAutoresizeLimit: number;
        diskSize: number;
        diskType: string;
        insightsConfigs: outputs.sql.GetDatabaseInstanceSettingInsightsConfig[];
        ipConfigurations: outputs.sql.GetDatabaseInstanceSettingIpConfiguration[];
        locationPreferences: outputs.sql.GetDatabaseInstanceSettingLocationPreference[];
        maintenanceWindows: outputs.sql.GetDatabaseInstanceSettingMaintenanceWindow[];
        pricingPlan: string;
        tier: string;
        userLabels: {[key: string]: string};
        version: number;
    }

    export interface GetDatabaseInstanceSettingActiveDirectoryConfig {
        domain: string;
    }

    export interface GetDatabaseInstanceSettingBackupConfiguration {
        backupRetentionSettings: outputs.sql.GetDatabaseInstanceSettingBackupConfigurationBackupRetentionSetting[];
        binaryLogEnabled: boolean;
        enabled: boolean;
        location: string;
        pointInTimeRecoveryEnabled: boolean;
        startTime: string;
        transactionLogRetentionDays: number;
    }

    export interface GetDatabaseInstanceSettingBackupConfigurationBackupRetentionSetting {
        retainedBackups: number;
        retentionUnit: string;
    }

    export interface GetDatabaseInstanceSettingDatabaseFlag {
        /**
         * The name of the instance.
         */
        name: string;
        value: string;
    }

    export interface GetDatabaseInstanceSettingInsightsConfig {
        queryInsightsEnabled: boolean;
        queryStringLength: number;
        recordApplicationTags: boolean;
        recordClientAddress: boolean;
    }

    export interface GetDatabaseInstanceSettingIpConfiguration {
        allocatedIpRange: string;
        authorizedNetworks: outputs.sql.GetDatabaseInstanceSettingIpConfigurationAuthorizedNetwork[];
        ipv4Enabled: boolean;
        privateNetwork: string;
        requireSsl: boolean;
    }

    export interface GetDatabaseInstanceSettingIpConfigurationAuthorizedNetwork {
        expirationTime: string;
        /**
         * The name of the instance.
         */
        name: string;
        value: string;
    }

    export interface GetDatabaseInstanceSettingLocationPreference {
        followGaeApplication: string;
        zone: string;
    }

    export interface GetDatabaseInstanceSettingMaintenanceWindow {
        day: number;
        hour: number;
        updateTrack: string;
    }

}

export namespace storage {
    export interface BucketCor {
        /**
         * The value, in seconds, to return in the [Access-Control-Max-Age header](https://www.w3.org/TR/cors/#access-control-max-age-response-header) used in preflight responses.
         */
        maxAgeSeconds?: number;
        /**
         * The list of HTTP methods on which to include CORS response headers, (GET, OPTIONS, POST, etc) Note: "*" is permitted in the list of methods, and means "any method".
         */
        methods?: string[];
        /**
         * The list of [Origins](https://tools.ietf.org/html/rfc6454) eligible to receive CORS response headers. Note: "*" is permitted in the list of origins, and means "any Origin".
         */
        origins?: string[];
        /**
         * The list of HTTP headers other than the [simple response headers](https://www.w3.org/TR/cors/#simple-response-header) to give permission for the user-agent to share across domains.
         */
        responseHeaders?: string[];
    }

    export interface BucketEncryption {
        defaultKmsKeyName: string;
    }

    export interface BucketIAMBindingCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface BucketIAMMemberCondition {
        /**
         * An optional description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
         */
        description?: string;
        /**
         * Textual representation of an expression in Common Expression Language syntax.
         */
        expression: string;
        /**
         * A title for the expression, i.e. a short string describing its purpose.
         */
        title: string;
    }

    export interface BucketLifecycleRule {
        /**
         * The Lifecycle Rule's action configuration. A single block of this type is supported. Structure is documented below.
         */
        action: outputs.storage.BucketLifecycleRuleAction;
        /**
         * The Lifecycle Rule's condition configuration. A single block of this type is supported. Structure is documented below.
         */
        condition: outputs.storage.BucketLifecycleRuleCondition;
    }

    export interface BucketLifecycleRuleAction {
        /**
         * The target [Storage Class](https://cloud.google.com/storage/docs/storage-classes) of objects affected by this Lifecycle Rule. Supported values include: `STANDARD`, `MULTI_REGIONAL`, `REGIONAL`, `NEARLINE`, `COLDLINE`, `ARCHIVE`.
         */
        storageClass?: string;
        /**
         * The type of the action of this Lifecycle Rule. Supported values include: `Delete` and `SetStorageClass`.
         */
        type: string;
    }

    export interface BucketLifecycleRuleCondition {
        /**
         * Minimum age of an object in days to satisfy this condition.
         */
        age?: number;
        /**
         * A date in the RFC 3339 format YYYY-MM-DD. This condition is satisfied when an object is created before midnight of the specified date in UTC.
         */
        createdBefore?: string;
        /**
         * A date in the RFC 3339 format YYYY-MM-DD. This condition is satisfied when the customTime metadata for the object is set to an earlier date than the date used in this lifecycle condition.
         */
        customTimeBefore?: string;
        /**
         * Days since the date set in the `customTime` metadata for the object. This condition is satisfied when the current date and time is at least the specified number of days after the `customTime`.
         */
        daysSinceCustomTime?: number;
        /**
         * Relevant only for versioned objects. Number of days elapsed since the noncurrent timestamp of an object.
         */
        daysSinceNoncurrentTime?: number;
        /**
         * [Storage Class](https://cloud.google.com/storage/docs/storage-classes) of objects to satisfy this condition. Supported values include: `STANDARD`, `MULTI_REGIONAL`, `REGIONAL`, `NEARLINE`, `COLDLINE`, `ARCHIVE`, `DURABLE_REDUCED_AVAILABILITY`.
         */
        matchesStorageClasses?: string[];
        /**
         * Relevant only for versioned objects. The date in RFC 3339 (e.g. `2017-06-13`) when the object became nonconcurrent.
         */
        noncurrentTimeBefore?: string;
        /**
         * Relevant only for versioned objects. The number of newer versions of an object to satisfy this condition.
         */
        numNewerVersions?: number;
        /**
         * Match to live and/or archived objects. Unversioned buckets have only live objects. Supported values include: `"LIVE"`, `"ARCHIVED"`, `"ANY"`.
         */
        withState: string;
    }

    export interface BucketLogging {
        /**
         * The bucket that will receive log objects.
         */
        logBucket: string;
        /**
         * The object prefix for log objects. If it's not provided,
         * by default GCS sets this to this bucket's name.
         */
        logObjectPrefix: string;
    }

    export interface BucketObjectCustomerEncryption {
        /**
         * Encryption algorithm. Default: AES256
         */
        encryptionAlgorithm?: string;
        /**
         * Base64 encoded Customer-Supplied Encryption Key.
         */
        encryptionKey: string;
    }

    export interface BucketRetentionPolicy {
        /**
         * If set to `true`, the bucket will be [locked](https://cloud.google.com/storage/docs/using-bucket-lock#lock-bucket) and permanently restrict edits to the bucket's retention policy.  Caution: Locking a bucket is an irreversible action.
         */
        isLocked?: boolean;
        /**
         * The period of time, in seconds, that objects in the bucket must be retained and cannot be deleted, overwritten, or archived. The value must be less than 2,147,483,647 seconds.
         */
        retentionPeriod: number;
    }

    export interface BucketVersioning {
        /**
         * While set to `true`, versioning is fully enabled for this bucket.
         */
        enabled: boolean;
    }

    export interface BucketWebsite {
        /**
         * Behaves as the bucket's directory index where
         * missing objects are treated as potential directories.
         */
        mainPageSuffix?: string;
        /**
         * The custom object to return when a requested
         * resource is not found.
         */
        notFoundPage?: string;
    }

    export interface DefaultObjectAccessControlProjectTeam {
        projectNumber?: string;
        team?: string;
    }

    export interface GetBucketCor {
        maxAgeSeconds: number;
        methods: string[];
        origins: string[];
        responseHeaders: string[];
    }

    export interface GetBucketEncryption {
        defaultKmsKeyName: string;
    }

    export interface GetBucketLifecycleRule {
        actions: outputs.storage.GetBucketLifecycleRuleAction[];
        conditions: outputs.storage.GetBucketLifecycleRuleCondition[];
    }

    export interface GetBucketLifecycleRuleAction {
        storageClass: string;
        type: string;
    }

    export interface GetBucketLifecycleRuleCondition {
        age: number;
        createdBefore: string;
        customTimeBefore: string;
        daysSinceCustomTime: number;
        daysSinceNoncurrentTime: number;
        matchesStorageClasses: string[];
        noncurrentTimeBefore: string;
        numNewerVersions: number;
        withState: string;
    }

    export interface GetBucketLogging {
        logBucket: string;
        logObjectPrefix: string;
    }

    export interface GetBucketObjectContentCustomerEncryption {
        encryptionAlgorithm: string;
        encryptionKey: string;
    }

    export interface GetBucketObjectCustomerEncryption {
        encryptionAlgorithm: string;
        encryptionKey: string;
    }

    export interface GetBucketRetentionPolicy {
        isLocked: boolean;
        retentionPeriod: number;
    }

    export interface GetBucketVersioning {
        enabled: boolean;
    }

    export interface GetBucketWebsite {
        mainPageSuffix: string;
        notFoundPage: string;
    }

    export interface ObjectAccessControlProjectTeam {
        projectNumber?: string;
        team?: string;
    }

    export interface TransferJobSchedule {
        /**
         * Interval between the start of each scheduled transfer. If unspecified, the default value is 24 hours. This value may not be less than 1 hour. A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        repeatInterval?: string;
        /**
         * The last day the recurring transfer will be run. If `scheduleEndDate` is the same as `scheduleStartDate`, the transfer will be executed only once. Structure documented below.
         */
        scheduleEndDate?: outputs.storage.TransferJobScheduleScheduleEndDate;
        /**
         * The first day the recurring transfer is scheduled to run. If `scheduleStartDate` is in the past, the transfer will run for the first time on the following day. Structure documented below.
         */
        scheduleStartDate: outputs.storage.TransferJobScheduleScheduleStartDate;
        /**
         * The time in UTC at which the transfer will be scheduled to start in a day. Transfers may start later than this time. If not specified, recurring and one-time transfers that are scheduled to run today will run immediately; recurring transfers that are scheduled to run on a future date will start at approximately midnight UTC on that date. Note that when configuring a transfer with the Cloud Platform Console, the transfer's start time in a day is specified in your local timezone. Structure documented below.
         */
        startTimeOfDay?: outputs.storage.TransferJobScheduleStartTimeOfDay;
    }

    export interface TransferJobScheduleScheduleEndDate {
        /**
         * Day of month. Must be from 1 to 31 and valid for the year and month.
         */
        day: number;
        /**
         * Month of year. Must be from 1 to 12.
         */
        month: number;
        /**
         * Year of date. Must be from 1 to 9999.
         */
        year: number;
    }

    export interface TransferJobScheduleScheduleStartDate {
        /**
         * Day of month. Must be from 1 to 31 and valid for the year and month.
         */
        day: number;
        /**
         * Month of year. Must be from 1 to 12.
         */
        month: number;
        /**
         * Year of date. Must be from 1 to 9999.
         */
        year: number;
    }

    export interface TransferJobScheduleStartTimeOfDay {
        /**
         * Hours of day in 24 hour format. Should be from 0 to 23
         */
        hours: number;
        /**
         * Minutes of hour of day. Must be from 0 to 59.
         */
        minutes: number;
        /**
         * Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999.
         */
        nanos: number;
        /**
         * Seconds of minutes of the time. Must normally be from 0 to 59.
         */
        seconds: number;
    }

    export interface TransferJobTransferSpec {
        /**
         * An AWS S3 data source. Structure documented below.
         */
        awsS3DataSource?: outputs.storage.TransferJobTransferSpecAwsS3DataSource;
        /**
         * An Azure Blob Storage data source. Structure documented below.
         */
        azureBlobStorageDataSource?: outputs.storage.TransferJobTransferSpecAzureBlobStorageDataSource;
        /**
         * A Google Cloud Storage data sink. Structure documented below.
         */
        gcsDataSink?: outputs.storage.TransferJobTransferSpecGcsDataSink;
        /**
         * A Google Cloud Storage data source. Structure documented below.
         */
        gcsDataSource?: outputs.storage.TransferJobTransferSpecGcsDataSource;
        /**
         * A HTTP URL data source. Structure documented below.
         */
        httpDataSource?: outputs.storage.TransferJobTransferSpecHttpDataSource;
        /**
         * Only objects that satisfy these object conditions are included in the set of data source and data sink objects. Object conditions based on objects' `lastModificationTime` do not exclude objects in a data sink. Structure documented below.
         */
        objectConditions?: outputs.storage.TransferJobTransferSpecObjectConditions;
        /**
         * A POSIX data sink. Structure documented below.
         */
        posixDataSink?: outputs.storage.TransferJobTransferSpecPosixDataSink;
        /**
         * A POSIX filesystem data source. Structure documented below.
         */
        posixDataSource?: outputs.storage.TransferJobTransferSpecPosixDataSource;
        /**
         * Characteristics of how to treat files from datasource and sink during job. If the option `deleteObjectsUniqueInSink` is true, object conditions based on objects' `lastModificationTime` are ignored and do not exclude objects in a data source or a data sink. Structure documented below.
         */
        transferOptions?: outputs.storage.TransferJobTransferSpecTransferOptions;
    }

    export interface TransferJobTransferSpecAwsS3DataSource {
        /**
         * AWS credentials block.
         */
        awsAccessKey?: outputs.storage.TransferJobTransferSpecAwsS3DataSourceAwsAccessKey;
        /**
         * S3 Bucket name.
         */
        bucketName: string;
        /**
         * The Amazon Resource Name (ARN) of the role to support temporary credentials via 'AssumeRoleWithWebIdentity'. For more information about ARNs, see [IAM ARNs](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns). When a role ARN is provided, Transfer Service fetches temporary credentials for the session using a 'AssumeRoleWithWebIdentity' call for the provided role using the [GoogleServiceAccount][] for this project.
         */
        roleArn?: string;
    }

    export interface TransferJobTransferSpecAwsS3DataSourceAwsAccessKey {
        /**
         * AWS Key ID.
         */
        accessKeyId: string;
        /**
         * AWS Secret Access Key.
         */
        secretAccessKey: string;
    }

    export interface TransferJobTransferSpecAzureBlobStorageDataSource {
        /**
         * Credentials used to authenticate API requests to Azure block.
         */
        azureCredentials: outputs.storage.TransferJobTransferSpecAzureBlobStorageDataSourceAzureCredentials;
        /**
         * The container to transfer from the Azure Storage account.`
         */
        container: string;
        /**
         * Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'.
         */
        path: string;
        /**
         * The name of the Azure Storage account.
         */
        storageAccount: string;
    }

    export interface TransferJobTransferSpecAzureBlobStorageDataSourceAzureCredentials {
        /**
         * Azure shared access signature. See [Grant limited access to Azure Storage resources using shared access signatures (SAS)](https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview).
         */
        sasToken: string;
    }

    export interface TransferJobTransferSpecGcsDataSink {
        /**
         * S3 Bucket name.
         */
        bucketName: string;
        /**
         * Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'.
         */
        path: string;
    }

    export interface TransferJobTransferSpecGcsDataSource {
        /**
         * S3 Bucket name.
         */
        bucketName: string;
        /**
         * Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'.
         */
        path: string;
    }

    export interface TransferJobTransferSpecHttpDataSource {
        /**
         * The URL that points to the file that stores the object list entries. This file must allow public access. Currently, only URLs with HTTP and HTTPS schemes are supported.
         */
        listUrl: string;
    }

    export interface TransferJobTransferSpecObjectConditions {
        /**
         * `excludePrefixes` must follow the requirements described for `includePrefixes`. See [Requirements](https://cloud.google.com/storage-transfer/docs/reference/rest/v1/TransferSpec#ObjectConditions).
         */
        excludePrefixes?: string[];
        /**
         * If `includePrefixes` is specified, objects that satisfy the object conditions must have names that start with one of the `includePrefixes` and that do not start with any of the `excludePrefixes`. If `includePrefixes` is not specified, all objects except those that have names starting with one of the `excludePrefixes` must satisfy the object conditions. See [Requirements](https://cloud.google.com/storage-transfer/docs/reference/rest/v1/TransferSpec#ObjectConditions).
         */
        includePrefixes?: string[];
        /**
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        maxTimeElapsedSinceLastModification?: string;
        /**
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        minTimeElapsedSinceLastModification?: string;
    }

    export interface TransferJobTransferSpecPosixDataSink {
        /**
         * Root directory path to the filesystem.
         */
        rootDirectory: string;
    }

    export interface TransferJobTransferSpecPosixDataSource {
        /**
         * Root directory path to the filesystem.
         */
        rootDirectory: string;
    }

    export interface TransferJobTransferSpecTransferOptions {
        /**
         * Whether objects should be deleted from the source after they are transferred to the sink. Note that this option and `deleteObjectsUniqueInSink` are mutually exclusive.
         */
        deleteObjectsFromSourceAfterTransfer?: boolean;
        /**
         * Whether objects that exist only in the sink should be deleted. Note that this option and
         * `deleteObjectsFromSourceAfterTransfer` are mutually exclusive.
         */
        deleteObjectsUniqueInSink?: boolean;
        /**
         * Whether overwriting objects that already exist in the sink is allowed.
         */
        overwriteObjectsAlreadyExistingInSink?: boolean;
    }
}

export namespace tags {
    export interface TagKeyIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface TagKeyIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface TagValueIamBindingCondition {
        description?: string;
        expression: string;
        title: string;
    }

    export interface TagValueIamMemberCondition {
        description?: string;
        expression: string;
        title: string;
    }

}

export namespace tpu {
    export interface NodeNetworkEndpoint {
        ipAddress: string;
        port: number;
    }

    export interface NodeSchedulingConfig {
        /**
         * Defines whether the TPU instance is preemptible.
         */
        preemptible: boolean;
    }

}

export namespace vertex {
    export interface AiDatasetEncryptionSpec {
        /**
         * Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
         * Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
         */
        kmsKeyName?: string;
    }

    export interface AiFeatureStoreEntityTypeMonitoringConfig {
        /**
         * Configuration of how features in Featurestore are monitored.
         * Structure is documented below.
         */
        snapshotAnalysis?: outputs.vertex.AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis;
    }

    export interface AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis {
        /**
         * The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoringInterval for Features under it.
         */
        disabled?: boolean;
        /**
         * Configuration of the snapshot analysis based monitoring pipeline running interval. The value is rolled up to full day.
         * A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
         */
        monitoringInterval?: string;
    }

    export interface AiFeatureStoreOnlineServingConfig {
        /**
         * The number of nodes for each cluster. The number of nodes will not scale automatically but can be scaled manually by providing different values when updating.
         */
        fixedNodeCount: number;
    }

    export interface AiMetadataStoreEncryptionSpec {
        /**
         * Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
         * Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
         */
        kmsKeyName?: string;
    }

    export interface AiMetadataStoreState {
        diskUtilizationBytes: string;
    }

}

export namespace vpcaccess {
    export interface ConnectorSubnet {
        /**
         * Subnet name (relative, not fully qualified). E.g. if the full subnet selfLink is
         * https://compute.googleapis.com/compute/v1/projects/{project}/regions/{region}/subnetworks/{subnetName} the correct input for this field would be {subnetName}"
         */
        name?: string;
        /**
         * Project in which the subnet exists. If not set, this project is assumed to be the project for which the connector create request was issued.
         */
        projectId: string;
    }

}
