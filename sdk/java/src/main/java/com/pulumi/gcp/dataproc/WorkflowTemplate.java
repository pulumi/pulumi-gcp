// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.dataproc;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.gcp.Utilities;
import com.pulumi.gcp.dataproc.WorkflowTemplateArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplateState;
import com.pulumi.gcp.dataproc.outputs.WorkflowTemplateJob;
import com.pulumi.gcp.dataproc.outputs.WorkflowTemplateParameter;
import com.pulumi.gcp.dataproc.outputs.WorkflowTemplatePlacement;
import java.lang.Integer;
import java.lang.Object;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * A Workflow Template is a reusable workflow configuration. It defines a graph of jobs with information on where to run those jobs.
 * 
 * ## Example Usage
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.dataproc.WorkflowTemplate;
 * import com.pulumi.gcp.dataproc.WorkflowTemplateArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigMasterConfigArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfigArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigWorkerConfigArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfigArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigSoftwareConfigArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplateJobArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplateJobSparkJobArgs;
 * import com.pulumi.gcp.dataproc.inputs.WorkflowTemplateJobPrestoJobArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var template = new WorkflowTemplate("template", WorkflowTemplateArgs.builder()        
 *             .name("template-example")
 *             .location("us-central1")
 *             .placement(WorkflowTemplatePlacementArgs.builder()
 *                 .managedCluster(WorkflowTemplatePlacementManagedClusterArgs.builder()
 *                     .clusterName("my-cluster")
 *                     .config(WorkflowTemplatePlacementManagedClusterConfigArgs.builder()
 *                         .gceClusterConfig(WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigArgs.builder()
 *                             .zone("us-central1-a")
 *                             .tags(                            
 *                                 "foo",
 *                                 "bar")
 *                             .build())
 *                         .masterConfig(WorkflowTemplatePlacementManagedClusterConfigMasterConfigArgs.builder()
 *                             .numInstances(1)
 *                             .machineType("n1-standard-1")
 *                             .diskConfig(WorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfigArgs.builder()
 *                                 .bootDiskType("pd-ssd")
 *                                 .bootDiskSizeGb(15)
 *                                 .build())
 *                             .build())
 *                         .workerConfig(WorkflowTemplatePlacementManagedClusterConfigWorkerConfigArgs.builder()
 *                             .numInstances(3)
 *                             .machineType("n1-standard-2")
 *                             .diskConfig(WorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfigArgs.builder()
 *                                 .bootDiskSizeGb(10)
 *                                 .numLocalSsds(2)
 *                                 .build())
 *                             .build())
 *                         .secondaryWorkerConfig(WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigArgs.builder()
 *                             .numInstances(2)
 *                             .build())
 *                         .softwareConfig(WorkflowTemplatePlacementManagedClusterConfigSoftwareConfigArgs.builder()
 *                             .imageVersion("2.0.35-debian10")
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .jobs(            
 *                 WorkflowTemplateJobArgs.builder()
 *                     .stepId("someJob")
 *                     .sparkJob(WorkflowTemplateJobSparkJobArgs.builder()
 *                         .mainClass("SomeClass")
 *                         .build())
 *                     .build(),
 *                 WorkflowTemplateJobArgs.builder()
 *                     .stepId("otherJob")
 *                     .prerequisiteStepIds("someJob")
 *                     .prestoJob(WorkflowTemplateJobPrestoJobArgs.builder()
 *                         .queryFileUri("someuri")
 *                         .build())
 *                     .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * ## Import
 * 
 * WorkflowTemplate can be imported using any of these accepted formats:
 * 
 * * `projects/{{project}}/locations/{{location}}/workflowTemplates/{{name}}`
 * 
 * * `{{project}}/{{location}}/{{name}}`
 * 
 * * `{{location}}/{{name}}`
 * 
 * When using the `pulumi import` command, WorkflowTemplate can be imported using one of the formats above. For example:
 * 
 * ```sh
 * $ pulumi import gcp:dataproc/workflowTemplate:WorkflowTemplate default projects/{{project}}/locations/{{location}}/workflowTemplates/{{name}}
 * ```
 * 
 * ```sh
 * $ pulumi import gcp:dataproc/workflowTemplate:WorkflowTemplate default {{project}}/{{location}}/{{name}}
 * ```
 * 
 * ```sh
 * $ pulumi import gcp:dataproc/workflowTemplate:WorkflowTemplate default {{location}}/{{name}}
 * ```
 * 
 */
@ResourceType(type="gcp:dataproc/workflowTemplate:WorkflowTemplate")
public class WorkflowTemplate extends com.pulumi.resources.CustomResource {
    /**
     * Output only. The time template was created.
     * 
     */
    @Export(name="createTime", refs={String.class}, tree="[0]")
    private Output<String> createTime;

    /**
     * @return Output only. The time template was created.
     * 
     */
    public Output<String> createTime() {
        return this.createTime;
    }
    /**
     * Optional. Timeout duration for the DAG of jobs, expressed in seconds (see [JSON representation of
     * duration](https://developers.google.com/protocol-buffers/docs/proto3#json)). The timeout duration must be from 10
     * minutes (&#34;600s&#34;) to 24 hours (&#34;86400s&#34;). The timer begins when the first job is submitted. If the workflow is running at
     * the end of the timeout period, any remaining jobs are cancelled, the workflow is ended, and if the workflow was running
     * on a [managed
     * cluster](https://www.terraform.io/dataproc/docs/concepts/workflows/using-workflows#configuring_or_selecting_a_cluster),
     * the cluster is deleted.
     * 
     */
    @Export(name="dagTimeout", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> dagTimeout;

    /**
     * @return Optional. Timeout duration for the DAG of jobs, expressed in seconds (see [JSON representation of
     * duration](https://developers.google.com/protocol-buffers/docs/proto3#json)). The timeout duration must be from 10
     * minutes (&#34;600s&#34;) to 24 hours (&#34;86400s&#34;). The timer begins when the first job is submitted. If the workflow is running at
     * the end of the timeout period, any remaining jobs are cancelled, the workflow is ended, and if the workflow was running
     * on a [managed
     * cluster](https://www.terraform.io/dataproc/docs/concepts/workflows/using-workflows#configuring_or_selecting_a_cluster),
     * the cluster is deleted.
     * 
     */
    public Output<Optional<String>> dagTimeout() {
        return Codegen.optional(this.dagTimeout);
    }
    @Export(name="effectiveLabels", refs={Map.class,String.class,Object.class}, tree="[0,1,2]")
    private Output<Map<String,Object>> effectiveLabels;

    public Output<Map<String,Object>> effectiveLabels() {
        return this.effectiveLabels;
    }
    /**
     * Required. The Directed Acyclic Graph of Jobs to submit.
     * 
     */
    @Export(name="jobs", refs={List.class,WorkflowTemplateJob.class}, tree="[0,1]")
    private Output<List<WorkflowTemplateJob>> jobs;

    /**
     * @return Required. The Directed Acyclic Graph of Jobs to submit.
     * 
     */
    public Output<List<WorkflowTemplateJob>> jobs() {
        return this.jobs;
    }
    /**
     * Optional. The labels to associate with this template. These labels will be propagated to all jobs and clusters created
     * by the workflow instance. Label **keys** must contain 1 to 63 characters, and must conform to [RFC
     * 1035](https://www.ietf.org/rfc/rfc1035.txt). Label **values** may be empty, but, if present, must contain 1 to 63
     * characters, and must conform to [RFC 1035](https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be
     * associated with a template. **Note**: This field is non-authoritative, and will only manage the labels present in your
     * configuration. Please refer to the field `effective_labels` for all of the labels present on the resource.
     * 
     */
    @Export(name="labels", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> labels;

    /**
     * @return Optional. The labels to associate with this template. These labels will be propagated to all jobs and clusters created
     * by the workflow instance. Label **keys** must contain 1 to 63 characters, and must conform to [RFC
     * 1035](https://www.ietf.org/rfc/rfc1035.txt). Label **values** may be empty, but, if present, must contain 1 to 63
     * characters, and must conform to [RFC 1035](https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be
     * associated with a template. **Note**: This field is non-authoritative, and will only manage the labels present in your
     * configuration. Please refer to the field `effective_labels` for all of the labels present on the resource.
     * 
     */
    public Output<Optional<Map<String,String>>> labels() {
        return Codegen.optional(this.labels);
    }
    /**
     * The location for the resource
     * 
     */
    @Export(name="location", refs={String.class}, tree="[0]")
    private Output<String> location;

    /**
     * @return The location for the resource
     * 
     */
    public Output<String> location() {
        return this.location;
    }
    /**
     * Output only. The resource name of the workflow template, as described in https://cloud.google.com/apis/design/resource_names. * For `projects.regions.workflowTemplates`, the resource name of the template has the following format: `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}` * For `projects.locations.workflowTemplates`, the resource name of the template has the following format: `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return Output only. The resource name of the workflow template, as described in https://cloud.google.com/apis/design/resource_names. * For `projects.regions.workflowTemplates`, the resource name of the template has the following format: `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}` * For `projects.locations.workflowTemplates`, the resource name of the template has the following format: `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * Optional. Template parameters whose values are substituted into the template. Values for parameters must be provided
     * when the template is instantiated.
     * 
     */
    @Export(name="parameters", refs={List.class,WorkflowTemplateParameter.class}, tree="[0,1]")
    private Output</* @Nullable */ List<WorkflowTemplateParameter>> parameters;

    /**
     * @return Optional. Template parameters whose values are substituted into the template. Values for parameters must be provided
     * when the template is instantiated.
     * 
     */
    public Output<Optional<List<WorkflowTemplateParameter>>> parameters() {
        return Codegen.optional(this.parameters);
    }
    /**
     * Required. WorkflowTemplate scheduling information.
     * 
     */
    @Export(name="placement", refs={WorkflowTemplatePlacement.class}, tree="[0]")
    private Output<WorkflowTemplatePlacement> placement;

    /**
     * @return Required. WorkflowTemplate scheduling information.
     * 
     */
    public Output<WorkflowTemplatePlacement> placement() {
        return this.placement;
    }
    /**
     * The project for the resource
     * 
     */
    @Export(name="project", refs={String.class}, tree="[0]")
    private Output<String> project;

    /**
     * @return The project for the resource
     * 
     */
    public Output<String> project() {
        return this.project;
    }
    /**
     * The combination of labels configured directly on the resource and default labels configured on the provider.
     * 
     */
    @Export(name="pulumiLabels", refs={Map.class,String.class,Object.class}, tree="[0,1,2]")
    private Output<Map<String,Object>> pulumiLabels;

    /**
     * @return The combination of labels configured directly on the resource and default labels configured on the provider.
     * 
     */
    public Output<Map<String,Object>> pulumiLabels() {
        return this.pulumiLabels;
    }
    /**
     * Output only. The time template was last updated.
     * 
     */
    @Export(name="updateTime", refs={String.class}, tree="[0]")
    private Output<String> updateTime;

    /**
     * @return Output only. The time template was last updated.
     * 
     */
    public Output<String> updateTime() {
        return this.updateTime;
    }
    /**
     * Output only. The current version of this workflow template.
     * 
     * @deprecated
     * version is not useful as a configurable field, and will be removed in the future.
     * 
     */
    @Deprecated /* version is not useful as a configurable field, and will be removed in the future. */
    @Export(name="version", refs={Integer.class}, tree="[0]")
    private Output<Integer> version;

    /**
     * @return Output only. The current version of this workflow template.
     * 
     */
    public Output<Integer> version() {
        return this.version;
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public WorkflowTemplate(String name) {
        this(name, WorkflowTemplateArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public WorkflowTemplate(String name, WorkflowTemplateArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public WorkflowTemplate(String name, WorkflowTemplateArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:dataproc/workflowTemplate:WorkflowTemplate", name, args == null ? WorkflowTemplateArgs.Empty : args, makeResourceOptions(options, Codegen.empty()));
    }

    private WorkflowTemplate(String name, Output<String> id, @Nullable WorkflowTemplateState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:dataproc/workflowTemplate:WorkflowTemplate", name, state, makeResourceOptions(options, id));
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .additionalSecretOutputs(List.of(
                "effectiveLabels",
                "pulumiLabels"
            ))
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static WorkflowTemplate get(String name, Output<String> id, @Nullable WorkflowTemplateState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new WorkflowTemplate(name, id, state, options);
    }
}
