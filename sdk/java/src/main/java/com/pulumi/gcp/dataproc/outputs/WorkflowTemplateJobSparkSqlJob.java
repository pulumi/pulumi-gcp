// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.dataproc.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.gcp.dataproc.outputs.WorkflowTemplateJobSparkSqlJobLoggingConfig;
import com.pulumi.gcp.dataproc.outputs.WorkflowTemplateJobSparkSqlJobQueryList;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class WorkflowTemplateJobSparkSqlJob {
    /**
     * @return Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
     * 
     */
    private @Nullable List<String> jarFileUris;
    /**
     * @return Optional. The runtime log config for job execution.
     * 
     */
    private @Nullable WorkflowTemplateJobSparkSqlJobLoggingConfig loggingConfig;
    /**
     * @return Optional. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. The following are supported prefixes and their mappings: * capacity-scheduler: `capacity-scheduler.xml` * core: `core-site.xml` * distcp: `distcp-default.xml` * hdfs: `hdfs-site.xml` * hive: `hive-site.xml` * mapred: `mapred-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf` * yarn: `yarn-site.xml` For more information, see (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
     * 
     */
    private @Nullable Map<String,String> properties;
    /**
     * @return The HCFS URI of the script that contains SQL queries.
     * 
     */
    private @Nullable String queryFileUri;
    /**
     * @return A list of queries.
     * 
     */
    private @Nullable WorkflowTemplateJobSparkSqlJobQueryList queryList;
    /**
     * @return Optional. Mapping of query variable names to values (equivalent to the Spark SQL command: SET `name=&#34;value&#34;;`).
     * 
     */
    private @Nullable Map<String,String> scriptVariables;

    private WorkflowTemplateJobSparkSqlJob() {}
    /**
     * @return Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
     * 
     */
    public List<String> jarFileUris() {
        return this.jarFileUris == null ? List.of() : this.jarFileUris;
    }
    /**
     * @return Optional. The runtime log config for job execution.
     * 
     */
    public Optional<WorkflowTemplateJobSparkSqlJobLoggingConfig> loggingConfig() {
        return Optional.ofNullable(this.loggingConfig);
    }
    /**
     * @return Optional. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. The following are supported prefixes and their mappings: * capacity-scheduler: `capacity-scheduler.xml` * core: `core-site.xml` * distcp: `distcp-default.xml` * hdfs: `hdfs-site.xml` * hive: `hive-site.xml` * mapred: `mapred-site.xml` * pig: `pig.properties` * spark: `spark-defaults.conf` * yarn: `yarn-site.xml` For more information, see (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
     * 
     */
    public Map<String,String> properties() {
        return this.properties == null ? Map.of() : this.properties;
    }
    /**
     * @return The HCFS URI of the script that contains SQL queries.
     * 
     */
    public Optional<String> queryFileUri() {
        return Optional.ofNullable(this.queryFileUri);
    }
    /**
     * @return A list of queries.
     * 
     */
    public Optional<WorkflowTemplateJobSparkSqlJobQueryList> queryList() {
        return Optional.ofNullable(this.queryList);
    }
    /**
     * @return Optional. Mapping of query variable names to values (equivalent to the Spark SQL command: SET `name=&#34;value&#34;;`).
     * 
     */
    public Map<String,String> scriptVariables() {
        return this.scriptVariables == null ? Map.of() : this.scriptVariables;
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(WorkflowTemplateJobSparkSqlJob defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable List<String> jarFileUris;
        private @Nullable WorkflowTemplateJobSparkSqlJobLoggingConfig loggingConfig;
        private @Nullable Map<String,String> properties;
        private @Nullable String queryFileUri;
        private @Nullable WorkflowTemplateJobSparkSqlJobQueryList queryList;
        private @Nullable Map<String,String> scriptVariables;
        public Builder() {}
        public Builder(WorkflowTemplateJobSparkSqlJob defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.jarFileUris = defaults.jarFileUris;
    	      this.loggingConfig = defaults.loggingConfig;
    	      this.properties = defaults.properties;
    	      this.queryFileUri = defaults.queryFileUri;
    	      this.queryList = defaults.queryList;
    	      this.scriptVariables = defaults.scriptVariables;
        }

        @CustomType.Setter
        public Builder jarFileUris(@Nullable List<String> jarFileUris) {
            this.jarFileUris = jarFileUris;
            return this;
        }
        public Builder jarFileUris(String... jarFileUris) {
            return jarFileUris(List.of(jarFileUris));
        }
        @CustomType.Setter
        public Builder loggingConfig(@Nullable WorkflowTemplateJobSparkSqlJobLoggingConfig loggingConfig) {
            this.loggingConfig = loggingConfig;
            return this;
        }
        @CustomType.Setter
        public Builder properties(@Nullable Map<String,String> properties) {
            this.properties = properties;
            return this;
        }
        @CustomType.Setter
        public Builder queryFileUri(@Nullable String queryFileUri) {
            this.queryFileUri = queryFileUri;
            return this;
        }
        @CustomType.Setter
        public Builder queryList(@Nullable WorkflowTemplateJobSparkSqlJobQueryList queryList) {
            this.queryList = queryList;
            return this;
        }
        @CustomType.Setter
        public Builder scriptVariables(@Nullable Map<String,String> scriptVariables) {
            this.scriptVariables = scriptVariables;
            return this;
        }
        public WorkflowTemplateJobSparkSqlJob build() {
            final var o = new WorkflowTemplateJobSparkSqlJob();
            o.jarFileUris = jarFileUris;
            o.loggingConfig = loggingConfig;
            o.properties = properties;
            o.queryFileUri = queryFileUri;
            o.queryList = queryList;
            o.scriptVariables = scriptVariables;
            return o;
        }
    }
}
