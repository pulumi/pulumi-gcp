// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.bigquery;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.gcp.Utilities;
import com.pulumi.gcp.bigquery.DataTransferConfigArgs;
import com.pulumi.gcp.bigquery.inputs.DataTransferConfigState;
import com.pulumi.gcp.bigquery.outputs.DataTransferConfigEmailPreferences;
import com.pulumi.gcp.bigquery.outputs.DataTransferConfigEncryptionConfiguration;
import com.pulumi.gcp.bigquery.outputs.DataTransferConfigScheduleOptions;
import com.pulumi.gcp.bigquery.outputs.DataTransferConfigSensitiveParams;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * Represents a data transfer configuration. A transfer configuration
 * contains all metadata needed to perform a data transfer.
 * 
 * To get more information about Config, see:
 * 
 * * [API documentation](https://cloud.google.com/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs/create)
 * * How-to Guides
 *     * [Official Documentation](https://cloud.google.com/bigquery/docs/reference/datatransfer/rest/)
 * 
 * &gt; **Note:**  All arguments marked as write-only values will not be stored in the state: `sensitive_params.secret_access_key_wo`.
 * Read more about Write-only Arguments.
 * 
 * ## Example Usage
 * 
 * ### Bigquerydatatransfer Config Scheduled Query
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.organizations.OrganizationsFunctions;
 * import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
 * import com.pulumi.gcp.projects.IAMMember;
 * import com.pulumi.gcp.projects.IAMMemberArgs;
 * import com.pulumi.gcp.bigquery.Dataset;
 * import com.pulumi.gcp.bigquery.DatasetArgs;
 * import com.pulumi.gcp.bigquery.DataTransferConfig;
 * import com.pulumi.gcp.bigquery.DataTransferConfigArgs;
 * import com.pulumi.resources.CustomResourceOptions;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App }{{@code
 *     public static void main(String[] args) }{{@code
 *         Pulumi.run(App::stack);
 *     }}{@code
 * 
 *     public static void stack(Context ctx) }{{@code
 *         final var project = OrganizationsFunctions.getProject(GetProjectArgs.builder()
 *             .build());
 * 
 *         var permissions = new IAMMember("permissions", IAMMemberArgs.builder()
 *             .project(project.projectId())
 *             .role("roles/iam.serviceAccountTokenCreator")
 *             .member(String.format("serviceAccount:service-%s}{@literal @}{@code gcp-sa-bigquerydatatransfer.iam.gserviceaccount.com", project.number()))
 *             .build());
 * 
 *         var myDataset = new Dataset("myDataset", DatasetArgs.builder()
 *             .datasetId("my_dataset")
 *             .friendlyName("foo")
 *             .description("bar")
 *             .location("asia-northeast1")
 *             .build(), CustomResourceOptions.builder()
 *                 .dependsOn(permissions)
 *                 .build());
 * 
 *         var queryConfig = new DataTransferConfig("queryConfig", DataTransferConfigArgs.builder()
 *             .displayName("my-query")
 *             .location("asia-northeast1")
 *             .dataSourceId("scheduled_query")
 *             .schedule("first sunday of quarter 00:00")
 *             .destinationDatasetId(myDataset.datasetId())
 *             .params(Map.ofEntries(
 *                 Map.entry("destination_table_name_template", "my_table"),
 *                 Map.entry("write_disposition", "WRITE_APPEND"),
 *                 Map.entry("query", "SELECT name FROM tabl WHERE x = 'y'")
 *             ))
 *             .build(), CustomResourceOptions.builder()
 *                 .dependsOn(permissions)
 *                 .build());
 * 
 *     }}{@code
 * }}{@code
 * }
 * </pre>
 * ### Bigquerydatatransfer Config Cmek
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.organizations.OrganizationsFunctions;
 * import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
 * import com.pulumi.gcp.projects.IAMMember;
 * import com.pulumi.gcp.projects.IAMMemberArgs;
 * import com.pulumi.gcp.bigquery.Dataset;
 * import com.pulumi.gcp.bigquery.DatasetArgs;
 * import com.pulumi.gcp.kms.KeyRing;
 * import com.pulumi.gcp.kms.KeyRingArgs;
 * import com.pulumi.gcp.kms.CryptoKey;
 * import com.pulumi.gcp.kms.CryptoKeyArgs;
 * import com.pulumi.gcp.bigquery.DataTransferConfig;
 * import com.pulumi.gcp.bigquery.DataTransferConfigArgs;
 * import com.pulumi.gcp.bigquery.inputs.DataTransferConfigEncryptionConfigurationArgs;
 * import com.pulumi.resources.CustomResourceOptions;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App }{{@code
 *     public static void main(String[] args) }{{@code
 *         Pulumi.run(App::stack);
 *     }}{@code
 * 
 *     public static void stack(Context ctx) }{{@code
 *         final var project = OrganizationsFunctions.getProject(GetProjectArgs.builder()
 *             .build());
 * 
 *         var permissions = new IAMMember("permissions", IAMMemberArgs.builder()
 *             .project(project.projectId())
 *             .role("roles/iam.serviceAccountTokenCreator")
 *             .member(String.format("serviceAccount:service-%s}{@literal @}{@code gcp-sa-bigquerydatatransfer.iam.gserviceaccount.com", project.number()))
 *             .build());
 * 
 *         var myDataset = new Dataset("myDataset", DatasetArgs.builder()
 *             .datasetId("example_dataset")
 *             .friendlyName("foo")
 *             .description("bar")
 *             .location("asia-northeast1")
 *             .build(), CustomResourceOptions.builder()
 *                 .dependsOn(permissions)
 *                 .build());
 * 
 *         var keyRing = new KeyRing("keyRing", KeyRingArgs.builder()
 *             .name("example-keyring")
 *             .location("us")
 *             .build());
 * 
 *         var cryptoKey = new CryptoKey("cryptoKey", CryptoKeyArgs.builder()
 *             .name("example-key")
 *             .keyRing(keyRing.id())
 *             .build());
 * 
 *         var queryConfigCmek = new DataTransferConfig("queryConfigCmek", DataTransferConfigArgs.builder()
 *             .displayName("display-name")
 *             .location("asia-northeast1")
 *             .dataSourceId("scheduled_query")
 *             .schedule("first sunday of quarter 00:00")
 *             .destinationDatasetId(myDataset.datasetId())
 *             .params(Map.ofEntries(
 *                 Map.entry("destination_table_name_template", "my_table"),
 *                 Map.entry("write_disposition", "WRITE_APPEND"),
 *                 Map.entry("query", "SELECT name FROM tabl WHERE x = 'y'")
 *             ))
 *             .encryptionConfiguration(DataTransferConfigEncryptionConfigurationArgs.builder()
 *                 .kmsKeyName(cryptoKey.id())
 *                 .build())
 *             .build(), CustomResourceOptions.builder()
 *                 .dependsOn(permissions)
 *                 .build());
 * 
 *     }}{@code
 * }}{@code
 * }
 * </pre>
 * ### Bigquerydatatransfer Config Salesforce
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.organizations.OrganizationsFunctions;
 * import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
 * import com.pulumi.gcp.bigquery.Dataset;
 * import com.pulumi.gcp.bigquery.DatasetArgs;
 * import com.pulumi.gcp.bigquery.DataTransferConfig;
 * import com.pulumi.gcp.bigquery.DataTransferConfigArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         final var project = OrganizationsFunctions.getProject(GetProjectArgs.builder()
 *             .build());
 * 
 *         var myDataset = new Dataset("myDataset", DatasetArgs.builder()
 *             .datasetId("my_dataset")
 *             .description("My dataset")
 *             .location("asia-northeast1")
 *             .build());
 * 
 *         var salesforceConfig = new DataTransferConfig("salesforceConfig", DataTransferConfigArgs.builder()
 *             .displayName("my-salesforce-config")
 *             .location("asia-northeast1")
 *             .dataSourceId("salesforce")
 *             .schedule("first sunday of quarter 00:00")
 *             .destinationDatasetId(myDataset.datasetId())
 *             .params(Map.ofEntries(
 *                 Map.entry("connector.authentication.oauth.clientId", "client-id"),
 *                 Map.entry("connector.authentication.oauth.clientSecret", "client-secret"),
 *                 Map.entry("connector.authentication.oauth.myDomain", "MyDomainName"),
 *                 Map.entry("assets", "[\"asset-a\",\"asset-b\"]")
 *             ))
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ## Import
 * 
 * Config can be imported using any of these accepted formats:
 * 
 * * `{{project}}/{{name}}`
 * 
 * * `{{project}} {{name}}`
 * 
 * * `{{name}}`
 * 
 * When using the `pulumi import` command, Config can be imported using one of the formats above. For example:
 * 
 * ```sh
 * $ pulumi import gcp:bigquery/dataTransferConfig:DataTransferConfig default {{project}}/{{name}}
 * ```
 * 
 * ```sh
 * $ pulumi import gcp:bigquery/dataTransferConfig:DataTransferConfig default &#34;{{project}} {{name}}&#34;
 * ```
 * 
 * ```sh
 * $ pulumi import gcp:bigquery/dataTransferConfig:DataTransferConfig default {{name}}
 * ```
 * 
 */
@ResourceType(type="gcp:bigquery/dataTransferConfig:DataTransferConfig")
public class DataTransferConfig extends com.pulumi.resources.CustomResource {
    /**
     * The number of days to look back to automatically refresh the data.
     * For example, if dataRefreshWindowDays = 10, then every day BigQuery
     * reingests data for [today-10, today-1], rather than ingesting data for
     * just [today-1]. Only valid if the data source supports the feature.
     * Set the value to 0 to use the default value.
     * 
     */
    @Export(name="dataRefreshWindowDays", refs={Integer.class}, tree="[0]")
    private Output</* @Nullable */ Integer> dataRefreshWindowDays;

    /**
     * @return The number of days to look back to automatically refresh the data.
     * For example, if dataRefreshWindowDays = 10, then every day BigQuery
     * reingests data for [today-10, today-1], rather than ingesting data for
     * just [today-1]. Only valid if the data source supports the feature.
     * Set the value to 0 to use the default value.
     * 
     */
    public Output<Optional<Integer>> dataRefreshWindowDays() {
        return Codegen.optional(this.dataRefreshWindowDays);
    }
    /**
     * The data source id. Cannot be changed once the transfer config is created.
     * 
     */
    @Export(name="dataSourceId", refs={String.class}, tree="[0]")
    private Output<String> dataSourceId;

    /**
     * @return The data source id. Cannot be changed once the transfer config is created.
     * 
     */
    public Output<String> dataSourceId() {
        return this.dataSourceId;
    }
    /**
     * The BigQuery target dataset id.
     * 
     */
    @Export(name="destinationDatasetId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> destinationDatasetId;

    /**
     * @return The BigQuery target dataset id.
     * 
     */
    public Output<Optional<String>> destinationDatasetId() {
        return Codegen.optional(this.destinationDatasetId);
    }
    /**
     * When set to true, no runs are scheduled for a given transfer.
     * 
     */
    @Export(name="disabled", refs={Boolean.class}, tree="[0]")
    private Output</* @Nullable */ Boolean> disabled;

    /**
     * @return When set to true, no runs are scheduled for a given transfer.
     * 
     */
    public Output<Optional<Boolean>> disabled() {
        return Codegen.optional(this.disabled);
    }
    /**
     * The user specified display name for the transfer config.
     * 
     */
    @Export(name="displayName", refs={String.class}, tree="[0]")
    private Output<String> displayName;

    /**
     * @return The user specified display name for the transfer config.
     * 
     */
    public Output<String> displayName() {
        return this.displayName;
    }
    /**
     * Email notifications will be sent according to these preferences to the
     * email address of the user who owns this transfer config.
     * Structure is documented below.
     * 
     */
    @Export(name="emailPreferences", refs={DataTransferConfigEmailPreferences.class}, tree="[0]")
    private Output</* @Nullable */ DataTransferConfigEmailPreferences> emailPreferences;

    /**
     * @return Email notifications will be sent according to these preferences to the
     * email address of the user who owns this transfer config.
     * Structure is documented below.
     * 
     */
    public Output<Optional<DataTransferConfigEmailPreferences>> emailPreferences() {
        return Codegen.optional(this.emailPreferences);
    }
    /**
     * Represents the encryption configuration for a transfer.
     * Structure is documented below.
     * 
     */
    @Export(name="encryptionConfiguration", refs={DataTransferConfigEncryptionConfiguration.class}, tree="[0]")
    private Output</* @Nullable */ DataTransferConfigEncryptionConfiguration> encryptionConfiguration;

    /**
     * @return Represents the encryption configuration for a transfer.
     * Structure is documented below.
     * 
     */
    public Output<Optional<DataTransferConfigEncryptionConfiguration>> encryptionConfiguration() {
        return Codegen.optional(this.encryptionConfiguration);
    }
    /**
     * The geographic location where the transfer config should reside.
     * Examples: US, EU, asia-northeast1. The default value is US.
     * 
     */
    @Export(name="location", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> location;

    /**
     * @return The geographic location where the transfer config should reside.
     * Examples: US, EU, asia-northeast1. The default value is US.
     * 
     */
    public Output<Optional<String>> location() {
        return Codegen.optional(this.location);
    }
    /**
     * The resource name of the transfer config. Transfer config names have the
     * form projects/{projectId}/locations/{location}/transferConfigs/{configId}
     * or projects/{projectId}/transferConfigs/{configId},
     * where configId is usually a uuid, but this is not required.
     * The name is ignored when creating a transfer config.
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return The resource name of the transfer config. Transfer config names have the
     * form projects/{projectId}/locations/{location}/transferConfigs/{configId}
     * or projects/{projectId}/transferConfigs/{configId},
     * where configId is usually a uuid, but this is not required.
     * The name is ignored when creating a transfer config.
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * Pub/Sub topic where notifications will be sent after transfer runs
     * associated with this transfer config finish.
     * 
     */
    @Export(name="notificationPubsubTopic", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> notificationPubsubTopic;

    /**
     * @return Pub/Sub topic where notifications will be sent after transfer runs
     * associated with this transfer config finish.
     * 
     */
    public Output<Optional<String>> notificationPubsubTopic() {
        return Codegen.optional(this.notificationPubsubTopic);
    }
    /**
     * Parameters specific to each data source. For more information see the bq tab in the &#39;Setting up a data transfer&#39;
     * section for each data source. For example the parameters for Cloud Storage transfers are listed here:
     * https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
     * **NOTE** : If you are attempting to update a parameter that cannot be updated (due to api limitations) please force recreation of the resource.
     * 
     */
    @Export(name="params", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> params;

    /**
     * @return Parameters specific to each data source. For more information see the bq tab in the &#39;Setting up a data transfer&#39;
     * section for each data source. For example the parameters for Cloud Storage transfers are listed here:
     * https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
     * **NOTE** : If you are attempting to update a parameter that cannot be updated (due to api limitations) please force recreation of the resource.
     * 
     */
    public Output<Map<String,String>> params() {
        return this.params;
    }
    /**
     * The ID of the project in which the resource belongs.
     * If it is not provided, the provider project is used.
     * 
     */
    @Export(name="project", refs={String.class}, tree="[0]")
    private Output<String> project;

    /**
     * @return The ID of the project in which the resource belongs.
     * If it is not provided, the provider project is used.
     * 
     */
    public Output<String> project() {
        return this.project;
    }
    /**
     * Data transfer schedule. If the data source does not support a custom
     * schedule, this should be empty. If it is empty, the default value for
     * the data source will be used. The specified times are in UTC. Examples
     * of valid format: 1st,3rd monday of month 15:30, every wed,fri of jan,
     * jun 13:15, and first sunday of quarter 00:00. See more explanation
     * about the format here:
     * https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format
     * NOTE: The minimum interval time between recurring transfers depends
     * on the data source; refer to the documentation for your data source.
     * 
     */
    @Export(name="schedule", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> schedule;

    /**
     * @return Data transfer schedule. If the data source does not support a custom
     * schedule, this should be empty. If it is empty, the default value for
     * the data source will be used. The specified times are in UTC. Examples
     * of valid format: 1st,3rd monday of month 15:30, every wed,fri of jan,
     * jun 13:15, and first sunday of quarter 00:00. See more explanation
     * about the format here:
     * https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format
     * NOTE: The minimum interval time between recurring transfers depends
     * on the data source; refer to the documentation for your data source.
     * 
     */
    public Output<Optional<String>> schedule() {
        return Codegen.optional(this.schedule);
    }
    /**
     * Options customizing the data transfer schedule.
     * Structure is documented below.
     * 
     */
    @Export(name="scheduleOptions", refs={DataTransferConfigScheduleOptions.class}, tree="[0]")
    private Output</* @Nullable */ DataTransferConfigScheduleOptions> scheduleOptions;

    /**
     * @return Options customizing the data transfer schedule.
     * Structure is documented below.
     * 
     */
    public Output<Optional<DataTransferConfigScheduleOptions>> scheduleOptions() {
        return Codegen.optional(this.scheduleOptions);
    }
    /**
     * Different parameters are configured primarily using the the `params` field on this
     * resource. This block contains the parameters which contain secrets or passwords so that they can be marked
     * sensitive and hidden from plan output. The name of the field, eg: secret_access_key, will be the key
     * in the `params` map in the api request.
     * Credentials may not be specified in both locations and will cause an error. Changing from one location
     * to a different credential configuration in the config will require an apply to update state.
     * Structure is documented below.
     * 
     */
    @Export(name="sensitiveParams", refs={DataTransferConfigSensitiveParams.class}, tree="[0]")
    private Output</* @Nullable */ DataTransferConfigSensitiveParams> sensitiveParams;

    /**
     * @return Different parameters are configured primarily using the the `params` field on this
     * resource. This block contains the parameters which contain secrets or passwords so that they can be marked
     * sensitive and hidden from plan output. The name of the field, eg: secret_access_key, will be the key
     * in the `params` map in the api request.
     * Credentials may not be specified in both locations and will cause an error. Changing from one location
     * to a different credential configuration in the config will require an apply to update state.
     * Structure is documented below.
     * 
     */
    public Output<Optional<DataTransferConfigSensitiveParams>> sensitiveParams() {
        return Codegen.optional(this.sensitiveParams);
    }
    /**
     * Service account email. If this field is set, transfer config will
     * be created with this service account credentials. It requires that
     * requesting user calling this API has permissions to act as this service account.
     * 
     */
    @Export(name="serviceAccountName", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> serviceAccountName;

    /**
     * @return Service account email. If this field is set, transfer config will
     * be created with this service account credentials. It requires that
     * requesting user calling this API has permissions to act as this service account.
     * 
     */
    public Output<Optional<String>> serviceAccountName() {
        return Codegen.optional(this.serviceAccountName);
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public DataTransferConfig(java.lang.String name) {
        this(name, DataTransferConfigArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public DataTransferConfig(java.lang.String name, DataTransferConfigArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public DataTransferConfig(java.lang.String name, DataTransferConfigArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:bigquery/dataTransferConfig:DataTransferConfig", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private DataTransferConfig(java.lang.String name, Output<java.lang.String> id, @Nullable DataTransferConfigState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:bigquery/dataTransferConfig:DataTransferConfig", name, state, makeResourceOptions(options, id), false);
    }

    private static DataTransferConfigArgs makeArgs(DataTransferConfigArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? DataTransferConfigArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static DataTransferConfig get(java.lang.String name, Output<java.lang.String> id, @Nullable DataTransferConfigState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new DataTransferConfig(name, id, state, options);
    }
}
