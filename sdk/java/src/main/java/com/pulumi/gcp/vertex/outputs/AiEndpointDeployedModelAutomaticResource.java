// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.vertex.outputs;

import com.pulumi.core.annotations.CustomType;
import java.lang.Integer;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class AiEndpointDeployedModelAutomaticResource {
    /**
     * @return The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
     * 
     */
    private @Nullable Integer maxReplicaCount;
    /**
     * @return The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
     * 
     */
    private @Nullable Integer minReplicaCount;

    private AiEndpointDeployedModelAutomaticResource() {}
    /**
     * @return The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
     * 
     */
    public Optional<Integer> maxReplicaCount() {
        return Optional.ofNullable(this.maxReplicaCount);
    }
    /**
     * @return The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
     * 
     */
    public Optional<Integer> minReplicaCount() {
        return Optional.ofNullable(this.minReplicaCount);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(AiEndpointDeployedModelAutomaticResource defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable Integer maxReplicaCount;
        private @Nullable Integer minReplicaCount;
        public Builder() {}
        public Builder(AiEndpointDeployedModelAutomaticResource defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.maxReplicaCount = defaults.maxReplicaCount;
    	      this.minReplicaCount = defaults.minReplicaCount;
        }

        @CustomType.Setter
        public Builder maxReplicaCount(@Nullable Integer maxReplicaCount) {
            this.maxReplicaCount = maxReplicaCount;
            return this;
        }
        @CustomType.Setter
        public Builder minReplicaCount(@Nullable Integer minReplicaCount) {
            this.minReplicaCount = minReplicaCount;
            return this;
        }
        public AiEndpointDeployedModelAutomaticResource build() {
            final var o = new AiEndpointDeployedModelAutomaticResource();
            o.maxReplicaCount = maxReplicaCount;
            o.minReplicaCount = minReplicaCount;
            return o;
        }
    }
}
