// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.vertex.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.gcp.vertex.outputs.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity;
import java.lang.Integer;
import java.lang.String;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec {
    /**
     * @return The number of accelerators to attach to the machine.
     * 
     */
    private @Nullable Integer acceleratorCount;
    /**
     * @return Possible values:
     * ACCELERATOR_TYPE_UNSPECIFIED
     * NVIDIA_TESLA_K80
     * NVIDIA_TESLA_P100
     * NVIDIA_TESLA_V100
     * NVIDIA_TESLA_P4
     * NVIDIA_TESLA_T4
     * NVIDIA_TESLA_A100
     * NVIDIA_A100_80GB
     * NVIDIA_L4
     * NVIDIA_H100_80GB
     * NVIDIA_H100_MEGA_80GB
     * NVIDIA_H200_141GB
     * NVIDIA_B200
     * TPU_V2
     * TPU_V3
     * TPU_V4_POD
     * TPU_V5_LITEPOD
     * 
     */
    private @Nullable String acceleratorType;
    /**
     * @return The type of the machine.
     * See the [list of machine types supported for
     * prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)
     * See the [list of machine types supported for custom
     * training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
     * For DeployedModel this field is optional, and the default
     * value is `n1-standard-2`. For BatchPredictionJob or as part of
     * WorkerPoolSpec this field is required.
     * 
     */
    private @Nullable String machineType;
    /**
     * @return The number of nodes per replica for multihost GPU deployments.
     * 
     */
    private @Nullable Integer multihostGpuNodeCount;
    /**
     * @return A ReservationAffinity can be used to configure a Vertex AI resource (e.g., a
     * DeployedModel) to draw its Compute Engine resources from a Shared
     * Reservation, or exclusively from on-demand capacity.
     * Structure is documented below.
     * 
     */
    private @Nullable AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity reservationAffinity;
    /**
     * @return The topology of the TPUs. Corresponds to the TPU topologies available from
     * GKE. (Example: tpu_topology: &#34;2x2x1&#34;).
     * 
     */
    private @Nullable String tpuTopology;

    private AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec() {}
    /**
     * @return The number of accelerators to attach to the machine.
     * 
     */
    public Optional<Integer> acceleratorCount() {
        return Optional.ofNullable(this.acceleratorCount);
    }
    /**
     * @return Possible values:
     * ACCELERATOR_TYPE_UNSPECIFIED
     * NVIDIA_TESLA_K80
     * NVIDIA_TESLA_P100
     * NVIDIA_TESLA_V100
     * NVIDIA_TESLA_P4
     * NVIDIA_TESLA_T4
     * NVIDIA_TESLA_A100
     * NVIDIA_A100_80GB
     * NVIDIA_L4
     * NVIDIA_H100_80GB
     * NVIDIA_H100_MEGA_80GB
     * NVIDIA_H200_141GB
     * NVIDIA_B200
     * TPU_V2
     * TPU_V3
     * TPU_V4_POD
     * TPU_V5_LITEPOD
     * 
     */
    public Optional<String> acceleratorType() {
        return Optional.ofNullable(this.acceleratorType);
    }
    /**
     * @return The type of the machine.
     * See the [list of machine types supported for
     * prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)
     * See the [list of machine types supported for custom
     * training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
     * For DeployedModel this field is optional, and the default
     * value is `n1-standard-2`. For BatchPredictionJob or as part of
     * WorkerPoolSpec this field is required.
     * 
     */
    public Optional<String> machineType() {
        return Optional.ofNullable(this.machineType);
    }
    /**
     * @return The number of nodes per replica for multihost GPU deployments.
     * 
     */
    public Optional<Integer> multihostGpuNodeCount() {
        return Optional.ofNullable(this.multihostGpuNodeCount);
    }
    /**
     * @return A ReservationAffinity can be used to configure a Vertex AI resource (e.g., a
     * DeployedModel) to draw its Compute Engine resources from a Shared
     * Reservation, or exclusively from on-demand capacity.
     * Structure is documented below.
     * 
     */
    public Optional<AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity> reservationAffinity() {
        return Optional.ofNullable(this.reservationAffinity);
    }
    /**
     * @return The topology of the TPUs. Corresponds to the TPU topologies available from
     * GKE. (Example: tpu_topology: &#34;2x2x1&#34;).
     * 
     */
    public Optional<String> tpuTopology() {
        return Optional.ofNullable(this.tpuTopology);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable Integer acceleratorCount;
        private @Nullable String acceleratorType;
        private @Nullable String machineType;
        private @Nullable Integer multihostGpuNodeCount;
        private @Nullable AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity reservationAffinity;
        private @Nullable String tpuTopology;
        public Builder() {}
        public Builder(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.acceleratorCount = defaults.acceleratorCount;
    	      this.acceleratorType = defaults.acceleratorType;
    	      this.machineType = defaults.machineType;
    	      this.multihostGpuNodeCount = defaults.multihostGpuNodeCount;
    	      this.reservationAffinity = defaults.reservationAffinity;
    	      this.tpuTopology = defaults.tpuTopology;
        }

        @CustomType.Setter
        public Builder acceleratorCount(@Nullable Integer acceleratorCount) {

            this.acceleratorCount = acceleratorCount;
            return this;
        }
        @CustomType.Setter
        public Builder acceleratorType(@Nullable String acceleratorType) {

            this.acceleratorType = acceleratorType;
            return this;
        }
        @CustomType.Setter
        public Builder machineType(@Nullable String machineType) {

            this.machineType = machineType;
            return this;
        }
        @CustomType.Setter
        public Builder multihostGpuNodeCount(@Nullable Integer multihostGpuNodeCount) {

            this.multihostGpuNodeCount = multihostGpuNodeCount;
            return this;
        }
        @CustomType.Setter
        public Builder reservationAffinity(@Nullable AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity reservationAffinity) {

            this.reservationAffinity = reservationAffinity;
            return this;
        }
        @CustomType.Setter
        public Builder tpuTopology(@Nullable String tpuTopology) {

            this.tpuTopology = tpuTopology;
            return this;
        }
        public AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec build() {
            final var _resultValue = new AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec();
            _resultValue.acceleratorCount = acceleratorCount;
            _resultValue.acceleratorType = acceleratorType;
            _resultValue.machineType = machineType;
            _resultValue.multihostGpuNodeCount = multihostGpuNodeCount;
            _resultValue.reservationAffinity = reservationAffinity;
            _resultValue.tpuTopology = tpuTopology;
            return _resultValue;
        }
    }
}
