// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.bigquery.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import com.pulumi.gcp.bigquery.outputs.JobLoadDestinationEncryptionConfiguration;
import com.pulumi.gcp.bigquery.outputs.JobLoadDestinationTable;
import com.pulumi.gcp.bigquery.outputs.JobLoadParquetOptions;
import com.pulumi.gcp.bigquery.outputs.JobLoadTimePartitioning;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class JobLoad {
    /**
     * @return Accept rows that are missing trailing optional columns. The missing values are treated as nulls.
     * If false, records with missing trailing columns are treated as bad records, and if there are too many bad records,
     * an invalid error is returned in the job result. The default value is false. Only applicable to CSV, ignored for other formats.
     * 
     */
    private @Nullable Boolean allowJaggedRows;
    /**
     * @return Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file.
     * The default value is false.
     * 
     */
    private @Nullable Boolean allowQuotedNewlines;
    /**
     * @return Indicates if we should automatically infer the options and schema for CSV and JSON sources.
     * 
     */
    private @Nullable Boolean autodetect;
    /**
     * @return Specifies whether the job is allowed to create new tables. The following values are supported:
     * CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
     * CREATE_NEVER: The table must already exist. If it does not, a &#39;notFound&#39; error is returned in the job result.
     * Creation, truncation and append actions occur as one atomic update upon job completion
     * Default value is `CREATE_IF_NEEDED`.
     * Possible values are: `CREATE_IF_NEEDED`, `CREATE_NEVER`.
     * 
     */
    private @Nullable String createDisposition;
    /**
     * @return Custom encryption configuration (e.g., Cloud KMS keys)
     * Structure is documented below.
     * 
     */
    private @Nullable JobLoadDestinationEncryptionConfiguration destinationEncryptionConfiguration;
    /**
     * @return The destination table to load the data into.
     * Structure is documented below.
     * 
     */
    private JobLoadDestinationTable destinationTable;
    /**
     * @return The character encoding of the data. The supported values are UTF-8 or ISO-8859-1.
     * The default value is UTF-8. BigQuery decodes the data after the raw, binary data
     * has been split using the values of the quote and fieldDelimiter properties.
     * 
     */
    private @Nullable String encoding;
    /**
     * @return The separator for fields in a CSV file. The separator can be any ISO-8859-1 single-byte character.
     * To use a character in the range 128-255, you must encode the character as UTF8. BigQuery converts
     * the string to ISO-8859-1 encoding, and then uses the first byte of the encoded string to split the
     * data in its raw, binary state. BigQuery also supports the escape sequence &#34;\t&#34; to specify a tab separator.
     * The default value is a comma (&#39;,&#39;).
     * 
     */
    private @Nullable String fieldDelimiter;
    /**
     * @return Indicates if BigQuery should allow extra values that are not represented in the table schema.
     * If true, the extra values are ignored. If false, records with extra columns are treated as bad records,
     * and if there are too many bad records, an invalid error is returned in the job result.
     * The default value is false. The sourceFormat property determines what BigQuery treats as an extra value:
     * CSV: Trailing columns
     * JSON: Named values that don&#39;t match any column names
     * 
     */
    private @Nullable Boolean ignoreUnknownValues;
    /**
     * @return If sourceFormat is set to newline-delimited JSON, indicates whether it should be processed as a JSON variant such as GeoJSON.
     * For a sourceFormat other than JSON, omit this field. If the sourceFormat is newline-delimited JSON: - for newline-delimited
     * GeoJSON: set to GEOJSON.
     * 
     */
    private @Nullable String jsonExtension;
    /**
     * @return The maximum number of bad records that BigQuery can ignore when running the job. If the number of bad records exceeds this value,
     * an invalid error is returned in the job result. The default value is 0, which requires that all records are valid.
     * 
     */
    private @Nullable Integer maxBadRecords;
    /**
     * @return Specifies a string that represents a null value in a CSV file. The default value is the empty string. If you set this
     * property to a custom value, BigQuery throws an error if an
     * empty string is present for all data types except for STRING and BYTE. For STRING and BYTE columns, BigQuery interprets the empty string as
     * an empty value.
     * 
     */
    private @Nullable String nullMarker;
    /**
     * @return Parquet Options for load and make external tables.
     * Structure is documented below.
     * 
     */
    private @Nullable JobLoadParquetOptions parquetOptions;
    /**
     * @return If sourceFormat is set to &#34;DATASTORE_BACKUP&#34;, indicates which entity properties to load into BigQuery from a Cloud Datastore backup.
     * Property names are case sensitive and must be top-level properties. If no properties are specified, BigQuery loads all properties.
     * If any named property isn&#39;t found in the Cloud Datastore backup, an invalid error is returned in the job result.
     * 
     */
    private @Nullable List<String> projectionFields;
    /**
     * @return The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding,
     * and then uses the first byte of the encoded string to split the data in its raw, binary state.
     * The default value is a double-quote (&#39;&#34;&#39;). If your data does not contain quoted sections, set the property value to an empty string.
     * If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true.
     * 
     */
    private @Nullable String quote;
    /**
     * @return Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
     * supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
     * when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
     * For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
     * ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
     * ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
     * 
     */
    private @Nullable List<String> schemaUpdateOptions;
    /**
     * @return The number of rows at the top of a CSV file that BigQuery will skip when loading the data.
     * The default value is 0. This property is useful if you have header rows in the file that should be skipped.
     * When autodetect is on, the behavior is the following:
     * skipLeadingRows unspecified - Autodetect tries to detect headers in the first row. If they are not detected,
     * the row is read as data. Otherwise data is read starting from the second row.
     * skipLeadingRows is 0 - Instructs autodetect that there are no headers and data should be read starting from the first row.
     * skipLeadingRows = N &gt; 0 - Autodetect skips N-1 rows and tries to detect headers in row N. If headers are not detected,
     * row N is just skipped. Otherwise row N is used to extract column names for the detected schema.
     * 
     */
    private @Nullable Integer skipLeadingRows;
    /**
     * @return The format of the data files. For CSV files, specify &#34;CSV&#34;. For datastore backups, specify &#34;DATASTORE_BACKUP&#34;.
     * For newline-delimited JSON, specify &#34;NEWLINE_DELIMITED_JSON&#34;. For Avro, specify &#34;AVRO&#34;. For parquet, specify &#34;PARQUET&#34;.
     * For orc, specify &#34;ORC&#34;. [Beta] For Bigtable, specify &#34;BIGTABLE&#34;.
     * The default value is CSV.
     * 
     */
    private @Nullable String sourceFormat;
    /**
     * @return The fully-qualified URIs that point to your data in Google Cloud.
     * For Google Cloud Storage URIs: Each URI can contain one &#39;\*&#39; wildcard character
     * and it must come after the &#39;bucket&#39; name. Size limits related to load jobs apply
     * to external data sources. For Google Cloud Bigtable URIs: Exactly one URI can be
     * specified and it has be a fully specified and valid HTTPS URL for a Google Cloud Bigtable table.
     * For Google Cloud Datastore backups: Exactly one URI can be specified. Also, the &#39;\*&#39; wildcard character is not allowed.
     * 
     */
    private List<String> sourceUris;
    /**
     * @return Time-based partitioning specification for the destination table.
     * Structure is documented below.
     * 
     */
    private @Nullable JobLoadTimePartitioning timePartitioning;
    /**
     * @return Specifies the action that occurs if the destination table already exists. The following values are supported:
     * WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
     * WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
     * WRITE_EMPTY: If the table already exists and contains data, a &#39;duplicate&#39; error is returned in the job result.
     * Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
     * Creation, truncation and append actions occur as one atomic update upon job completion.
     * Default value is `WRITE_EMPTY`.
     * Possible values are: `WRITE_TRUNCATE`, `WRITE_APPEND`, `WRITE_EMPTY`.
     * 
     */
    private @Nullable String writeDisposition;

    private JobLoad() {}
    /**
     * @return Accept rows that are missing trailing optional columns. The missing values are treated as nulls.
     * If false, records with missing trailing columns are treated as bad records, and if there are too many bad records,
     * an invalid error is returned in the job result. The default value is false. Only applicable to CSV, ignored for other formats.
     * 
     */
    public Optional<Boolean> allowJaggedRows() {
        return Optional.ofNullable(this.allowJaggedRows);
    }
    /**
     * @return Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file.
     * The default value is false.
     * 
     */
    public Optional<Boolean> allowQuotedNewlines() {
        return Optional.ofNullable(this.allowQuotedNewlines);
    }
    /**
     * @return Indicates if we should automatically infer the options and schema for CSV and JSON sources.
     * 
     */
    public Optional<Boolean> autodetect() {
        return Optional.ofNullable(this.autodetect);
    }
    /**
     * @return Specifies whether the job is allowed to create new tables. The following values are supported:
     * CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
     * CREATE_NEVER: The table must already exist. If it does not, a &#39;notFound&#39; error is returned in the job result.
     * Creation, truncation and append actions occur as one atomic update upon job completion
     * Default value is `CREATE_IF_NEEDED`.
     * Possible values are: `CREATE_IF_NEEDED`, `CREATE_NEVER`.
     * 
     */
    public Optional<String> createDisposition() {
        return Optional.ofNullable(this.createDisposition);
    }
    /**
     * @return Custom encryption configuration (e.g., Cloud KMS keys)
     * Structure is documented below.
     * 
     */
    public Optional<JobLoadDestinationEncryptionConfiguration> destinationEncryptionConfiguration() {
        return Optional.ofNullable(this.destinationEncryptionConfiguration);
    }
    /**
     * @return The destination table to load the data into.
     * Structure is documented below.
     * 
     */
    public JobLoadDestinationTable destinationTable() {
        return this.destinationTable;
    }
    /**
     * @return The character encoding of the data. The supported values are UTF-8 or ISO-8859-1.
     * The default value is UTF-8. BigQuery decodes the data after the raw, binary data
     * has been split using the values of the quote and fieldDelimiter properties.
     * 
     */
    public Optional<String> encoding() {
        return Optional.ofNullable(this.encoding);
    }
    /**
     * @return The separator for fields in a CSV file. The separator can be any ISO-8859-1 single-byte character.
     * To use a character in the range 128-255, you must encode the character as UTF8. BigQuery converts
     * the string to ISO-8859-1 encoding, and then uses the first byte of the encoded string to split the
     * data in its raw, binary state. BigQuery also supports the escape sequence &#34;\t&#34; to specify a tab separator.
     * The default value is a comma (&#39;,&#39;).
     * 
     */
    public Optional<String> fieldDelimiter() {
        return Optional.ofNullable(this.fieldDelimiter);
    }
    /**
     * @return Indicates if BigQuery should allow extra values that are not represented in the table schema.
     * If true, the extra values are ignored. If false, records with extra columns are treated as bad records,
     * and if there are too many bad records, an invalid error is returned in the job result.
     * The default value is false. The sourceFormat property determines what BigQuery treats as an extra value:
     * CSV: Trailing columns
     * JSON: Named values that don&#39;t match any column names
     * 
     */
    public Optional<Boolean> ignoreUnknownValues() {
        return Optional.ofNullable(this.ignoreUnknownValues);
    }
    /**
     * @return If sourceFormat is set to newline-delimited JSON, indicates whether it should be processed as a JSON variant such as GeoJSON.
     * For a sourceFormat other than JSON, omit this field. If the sourceFormat is newline-delimited JSON: - for newline-delimited
     * GeoJSON: set to GEOJSON.
     * 
     */
    public Optional<String> jsonExtension() {
        return Optional.ofNullable(this.jsonExtension);
    }
    /**
     * @return The maximum number of bad records that BigQuery can ignore when running the job. If the number of bad records exceeds this value,
     * an invalid error is returned in the job result. The default value is 0, which requires that all records are valid.
     * 
     */
    public Optional<Integer> maxBadRecords() {
        return Optional.ofNullable(this.maxBadRecords);
    }
    /**
     * @return Specifies a string that represents a null value in a CSV file. The default value is the empty string. If you set this
     * property to a custom value, BigQuery throws an error if an
     * empty string is present for all data types except for STRING and BYTE. For STRING and BYTE columns, BigQuery interprets the empty string as
     * an empty value.
     * 
     */
    public Optional<String> nullMarker() {
        return Optional.ofNullable(this.nullMarker);
    }
    /**
     * @return Parquet Options for load and make external tables.
     * Structure is documented below.
     * 
     */
    public Optional<JobLoadParquetOptions> parquetOptions() {
        return Optional.ofNullable(this.parquetOptions);
    }
    /**
     * @return If sourceFormat is set to &#34;DATASTORE_BACKUP&#34;, indicates which entity properties to load into BigQuery from a Cloud Datastore backup.
     * Property names are case sensitive and must be top-level properties. If no properties are specified, BigQuery loads all properties.
     * If any named property isn&#39;t found in the Cloud Datastore backup, an invalid error is returned in the job result.
     * 
     */
    public List<String> projectionFields() {
        return this.projectionFields == null ? List.of() : this.projectionFields;
    }
    /**
     * @return The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding,
     * and then uses the first byte of the encoded string to split the data in its raw, binary state.
     * The default value is a double-quote (&#39;&#34;&#39;). If your data does not contain quoted sections, set the property value to an empty string.
     * If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true.
     * 
     */
    public Optional<String> quote() {
        return Optional.ofNullable(this.quote);
    }
    /**
     * @return Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
     * supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
     * when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
     * For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
     * ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
     * ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
     * 
     */
    public List<String> schemaUpdateOptions() {
        return this.schemaUpdateOptions == null ? List.of() : this.schemaUpdateOptions;
    }
    /**
     * @return The number of rows at the top of a CSV file that BigQuery will skip when loading the data.
     * The default value is 0. This property is useful if you have header rows in the file that should be skipped.
     * When autodetect is on, the behavior is the following:
     * skipLeadingRows unspecified - Autodetect tries to detect headers in the first row. If they are not detected,
     * the row is read as data. Otherwise data is read starting from the second row.
     * skipLeadingRows is 0 - Instructs autodetect that there are no headers and data should be read starting from the first row.
     * skipLeadingRows = N &gt; 0 - Autodetect skips N-1 rows and tries to detect headers in row N. If headers are not detected,
     * row N is just skipped. Otherwise row N is used to extract column names for the detected schema.
     * 
     */
    public Optional<Integer> skipLeadingRows() {
        return Optional.ofNullable(this.skipLeadingRows);
    }
    /**
     * @return The format of the data files. For CSV files, specify &#34;CSV&#34;. For datastore backups, specify &#34;DATASTORE_BACKUP&#34;.
     * For newline-delimited JSON, specify &#34;NEWLINE_DELIMITED_JSON&#34;. For Avro, specify &#34;AVRO&#34;. For parquet, specify &#34;PARQUET&#34;.
     * For orc, specify &#34;ORC&#34;. [Beta] For Bigtable, specify &#34;BIGTABLE&#34;.
     * The default value is CSV.
     * 
     */
    public Optional<String> sourceFormat() {
        return Optional.ofNullable(this.sourceFormat);
    }
    /**
     * @return The fully-qualified URIs that point to your data in Google Cloud.
     * For Google Cloud Storage URIs: Each URI can contain one &#39;\*&#39; wildcard character
     * and it must come after the &#39;bucket&#39; name. Size limits related to load jobs apply
     * to external data sources. For Google Cloud Bigtable URIs: Exactly one URI can be
     * specified and it has be a fully specified and valid HTTPS URL for a Google Cloud Bigtable table.
     * For Google Cloud Datastore backups: Exactly one URI can be specified. Also, the &#39;\*&#39; wildcard character is not allowed.
     * 
     */
    public List<String> sourceUris() {
        return this.sourceUris;
    }
    /**
     * @return Time-based partitioning specification for the destination table.
     * Structure is documented below.
     * 
     */
    public Optional<JobLoadTimePartitioning> timePartitioning() {
        return Optional.ofNullable(this.timePartitioning);
    }
    /**
     * @return Specifies the action that occurs if the destination table already exists. The following values are supported:
     * WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
     * WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
     * WRITE_EMPTY: If the table already exists and contains data, a &#39;duplicate&#39; error is returned in the job result.
     * Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
     * Creation, truncation and append actions occur as one atomic update upon job completion.
     * Default value is `WRITE_EMPTY`.
     * Possible values are: `WRITE_TRUNCATE`, `WRITE_APPEND`, `WRITE_EMPTY`.
     * 
     */
    public Optional<String> writeDisposition() {
        return Optional.ofNullable(this.writeDisposition);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(JobLoad defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable Boolean allowJaggedRows;
        private @Nullable Boolean allowQuotedNewlines;
        private @Nullable Boolean autodetect;
        private @Nullable String createDisposition;
        private @Nullable JobLoadDestinationEncryptionConfiguration destinationEncryptionConfiguration;
        private JobLoadDestinationTable destinationTable;
        private @Nullable String encoding;
        private @Nullable String fieldDelimiter;
        private @Nullable Boolean ignoreUnknownValues;
        private @Nullable String jsonExtension;
        private @Nullable Integer maxBadRecords;
        private @Nullable String nullMarker;
        private @Nullable JobLoadParquetOptions parquetOptions;
        private @Nullable List<String> projectionFields;
        private @Nullable String quote;
        private @Nullable List<String> schemaUpdateOptions;
        private @Nullable Integer skipLeadingRows;
        private @Nullable String sourceFormat;
        private List<String> sourceUris;
        private @Nullable JobLoadTimePartitioning timePartitioning;
        private @Nullable String writeDisposition;
        public Builder() {}
        public Builder(JobLoad defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.allowJaggedRows = defaults.allowJaggedRows;
    	      this.allowQuotedNewlines = defaults.allowQuotedNewlines;
    	      this.autodetect = defaults.autodetect;
    	      this.createDisposition = defaults.createDisposition;
    	      this.destinationEncryptionConfiguration = defaults.destinationEncryptionConfiguration;
    	      this.destinationTable = defaults.destinationTable;
    	      this.encoding = defaults.encoding;
    	      this.fieldDelimiter = defaults.fieldDelimiter;
    	      this.ignoreUnknownValues = defaults.ignoreUnknownValues;
    	      this.jsonExtension = defaults.jsonExtension;
    	      this.maxBadRecords = defaults.maxBadRecords;
    	      this.nullMarker = defaults.nullMarker;
    	      this.parquetOptions = defaults.parquetOptions;
    	      this.projectionFields = defaults.projectionFields;
    	      this.quote = defaults.quote;
    	      this.schemaUpdateOptions = defaults.schemaUpdateOptions;
    	      this.skipLeadingRows = defaults.skipLeadingRows;
    	      this.sourceFormat = defaults.sourceFormat;
    	      this.sourceUris = defaults.sourceUris;
    	      this.timePartitioning = defaults.timePartitioning;
    	      this.writeDisposition = defaults.writeDisposition;
        }

        @CustomType.Setter
        public Builder allowJaggedRows(@Nullable Boolean allowJaggedRows) {

            this.allowJaggedRows = allowJaggedRows;
            return this;
        }
        @CustomType.Setter
        public Builder allowQuotedNewlines(@Nullable Boolean allowQuotedNewlines) {

            this.allowQuotedNewlines = allowQuotedNewlines;
            return this;
        }
        @CustomType.Setter
        public Builder autodetect(@Nullable Boolean autodetect) {

            this.autodetect = autodetect;
            return this;
        }
        @CustomType.Setter
        public Builder createDisposition(@Nullable String createDisposition) {

            this.createDisposition = createDisposition;
            return this;
        }
        @CustomType.Setter
        public Builder destinationEncryptionConfiguration(@Nullable JobLoadDestinationEncryptionConfiguration destinationEncryptionConfiguration) {

            this.destinationEncryptionConfiguration = destinationEncryptionConfiguration;
            return this;
        }
        @CustomType.Setter
        public Builder destinationTable(JobLoadDestinationTable destinationTable) {
            if (destinationTable == null) {
              throw new MissingRequiredPropertyException("JobLoad", "destinationTable");
            }
            this.destinationTable = destinationTable;
            return this;
        }
        @CustomType.Setter
        public Builder encoding(@Nullable String encoding) {

            this.encoding = encoding;
            return this;
        }
        @CustomType.Setter
        public Builder fieldDelimiter(@Nullable String fieldDelimiter) {

            this.fieldDelimiter = fieldDelimiter;
            return this;
        }
        @CustomType.Setter
        public Builder ignoreUnknownValues(@Nullable Boolean ignoreUnknownValues) {

            this.ignoreUnknownValues = ignoreUnknownValues;
            return this;
        }
        @CustomType.Setter
        public Builder jsonExtension(@Nullable String jsonExtension) {

            this.jsonExtension = jsonExtension;
            return this;
        }
        @CustomType.Setter
        public Builder maxBadRecords(@Nullable Integer maxBadRecords) {

            this.maxBadRecords = maxBadRecords;
            return this;
        }
        @CustomType.Setter
        public Builder nullMarker(@Nullable String nullMarker) {

            this.nullMarker = nullMarker;
            return this;
        }
        @CustomType.Setter
        public Builder parquetOptions(@Nullable JobLoadParquetOptions parquetOptions) {

            this.parquetOptions = parquetOptions;
            return this;
        }
        @CustomType.Setter
        public Builder projectionFields(@Nullable List<String> projectionFields) {

            this.projectionFields = projectionFields;
            return this;
        }
        public Builder projectionFields(String... projectionFields) {
            return projectionFields(List.of(projectionFields));
        }
        @CustomType.Setter
        public Builder quote(@Nullable String quote) {

            this.quote = quote;
            return this;
        }
        @CustomType.Setter
        public Builder schemaUpdateOptions(@Nullable List<String> schemaUpdateOptions) {

            this.schemaUpdateOptions = schemaUpdateOptions;
            return this;
        }
        public Builder schemaUpdateOptions(String... schemaUpdateOptions) {
            return schemaUpdateOptions(List.of(schemaUpdateOptions));
        }
        @CustomType.Setter
        public Builder skipLeadingRows(@Nullable Integer skipLeadingRows) {

            this.skipLeadingRows = skipLeadingRows;
            return this;
        }
        @CustomType.Setter
        public Builder sourceFormat(@Nullable String sourceFormat) {

            this.sourceFormat = sourceFormat;
            return this;
        }
        @CustomType.Setter
        public Builder sourceUris(List<String> sourceUris) {
            if (sourceUris == null) {
              throw new MissingRequiredPropertyException("JobLoad", "sourceUris");
            }
            this.sourceUris = sourceUris;
            return this;
        }
        public Builder sourceUris(String... sourceUris) {
            return sourceUris(List.of(sourceUris));
        }
        @CustomType.Setter
        public Builder timePartitioning(@Nullable JobLoadTimePartitioning timePartitioning) {

            this.timePartitioning = timePartitioning;
            return this;
        }
        @CustomType.Setter
        public Builder writeDisposition(@Nullable String writeDisposition) {

            this.writeDisposition = writeDisposition;
            return this;
        }
        public JobLoad build() {
            final var _resultValue = new JobLoad();
            _resultValue.allowJaggedRows = allowJaggedRows;
            _resultValue.allowQuotedNewlines = allowQuotedNewlines;
            _resultValue.autodetect = autodetect;
            _resultValue.createDisposition = createDisposition;
            _resultValue.destinationEncryptionConfiguration = destinationEncryptionConfiguration;
            _resultValue.destinationTable = destinationTable;
            _resultValue.encoding = encoding;
            _resultValue.fieldDelimiter = fieldDelimiter;
            _resultValue.ignoreUnknownValues = ignoreUnknownValues;
            _resultValue.jsonExtension = jsonExtension;
            _resultValue.maxBadRecords = maxBadRecords;
            _resultValue.nullMarker = nullMarker;
            _resultValue.parquetOptions = parquetOptions;
            _resultValue.projectionFields = projectionFields;
            _resultValue.quote = quote;
            _resultValue.schemaUpdateOptions = schemaUpdateOptions;
            _resultValue.skipLeadingRows = skipLeadingRows;
            _resultValue.sourceFormat = sourceFormat;
            _resultValue.sourceUris = sourceUris;
            _resultValue.timePartitioning = timePartitioning;
            _resultValue.writeDisposition = writeDisposition;
            return _resultValue;
        }
    }
}
