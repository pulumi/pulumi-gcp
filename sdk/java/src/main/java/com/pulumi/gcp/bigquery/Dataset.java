// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.bigquery;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.gcp.Utilities;
import com.pulumi.gcp.bigquery.DatasetArgs;
import com.pulumi.gcp.bigquery.inputs.DatasetState;
import com.pulumi.gcp.bigquery.outputs.DatasetAccess;
import com.pulumi.gcp.bigquery.outputs.DatasetDefaultEncryptionConfiguration;
import com.pulumi.gcp.bigquery.outputs.DatasetExternalCatalogDatasetOptions;
import com.pulumi.gcp.bigquery.outputs.DatasetExternalDatasetReference;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * ## Example Usage
 * 
 * ### Bigquery Dataset Basic
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.serviceaccount.Account;
 * import com.pulumi.gcp.serviceaccount.AccountArgs;
 * import com.pulumi.gcp.bigquery.Dataset;
 * import com.pulumi.gcp.bigquery.DatasetArgs;
 * import com.pulumi.gcp.bigquery.inputs.DatasetAccessArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var bqowner = new Account("bqowner", AccountArgs.builder()
 *             .accountId("bqowner")
 *             .build());
 * 
 *         var dataset = new Dataset("dataset", DatasetArgs.builder()
 *             .datasetId("example_dataset")
 *             .friendlyName("test")
 *             .description("This is a test description")
 *             .location("EU")
 *             .defaultTableExpirationMs(3600000)
 *             .labels(Map.of("env", "default"))
 *             .accesses(            
 *                 DatasetAccessArgs.builder()
 *                     .role("OWNER")
 *                     .userByEmail(bqowner.email())
 *                     .build(),
 *                 DatasetAccessArgs.builder()
 *                     .role("READER")
 *                     .domain("hashicorp.com")
 *                     .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * ### Bigquery Dataset Cmek
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.kms.KeyRing;
 * import com.pulumi.gcp.kms.KeyRingArgs;
 * import com.pulumi.gcp.kms.CryptoKey;
 * import com.pulumi.gcp.kms.CryptoKeyArgs;
 * import com.pulumi.gcp.bigquery.Dataset;
 * import com.pulumi.gcp.bigquery.DatasetArgs;
 * import com.pulumi.gcp.bigquery.inputs.DatasetDefaultEncryptionConfigurationArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var keyRing = new KeyRing("keyRing", KeyRingArgs.builder()
 *             .name("example-keyring")
 *             .location("us")
 *             .build());
 * 
 *         var cryptoKey = new CryptoKey("cryptoKey", CryptoKeyArgs.builder()
 *             .name("example-key")
 *             .keyRing(keyRing.id())
 *             .build());
 * 
 *         var dataset = new Dataset("dataset", DatasetArgs.builder()
 *             .datasetId("example_dataset")
 *             .friendlyName("test")
 *             .description("This is a test description")
 *             .location("US")
 *             .defaultTableExpirationMs(3600000)
 *             .defaultEncryptionConfiguration(DatasetDefaultEncryptionConfigurationArgs.builder()
 *                 .kmsKeyName(cryptoKey.id())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * ### Bigquery Dataset Authorized Dataset
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.serviceaccount.Account;
 * import com.pulumi.gcp.serviceaccount.AccountArgs;
 * import com.pulumi.gcp.bigquery.Dataset;
 * import com.pulumi.gcp.bigquery.DatasetArgs;
 * import com.pulumi.gcp.bigquery.inputs.DatasetAccessArgs;
 * import com.pulumi.gcp.bigquery.inputs.DatasetAccessDatasetArgs;
 * import com.pulumi.gcp.bigquery.inputs.DatasetAccessDatasetDatasetArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var bqowner = new Account("bqowner", AccountArgs.builder()
 *             .accountId("bqowner")
 *             .build());
 * 
 *         var public_ = new Dataset("public", DatasetArgs.builder()
 *             .datasetId("public")
 *             .friendlyName("test")
 *             .description("This dataset is public")
 *             .location("EU")
 *             .defaultTableExpirationMs(3600000)
 *             .labels(Map.of("env", "default"))
 *             .accesses(            
 *                 DatasetAccessArgs.builder()
 *                     .role("OWNER")
 *                     .userByEmail(bqowner.email())
 *                     .build(),
 *                 DatasetAccessArgs.builder()
 *                     .role("READER")
 *                     .domain("hashicorp.com")
 *                     .build())
 *             .build());
 * 
 *         var dataset = new Dataset("dataset", DatasetArgs.builder()
 *             .datasetId("private")
 *             .friendlyName("test")
 *             .description("This dataset is private")
 *             .location("EU")
 *             .defaultTableExpirationMs(3600000)
 *             .labels(Map.of("env", "default"))
 *             .accesses(            
 *                 DatasetAccessArgs.builder()
 *                     .role("OWNER")
 *                     .userByEmail(bqowner.email())
 *                     .build(),
 *                 DatasetAccessArgs.builder()
 *                     .role("READER")
 *                     .domain("hashicorp.com")
 *                     .build(),
 *                 DatasetAccessArgs.builder()
 *                     .dataset(DatasetAccessDatasetArgs.builder()
 *                         .dataset(DatasetAccessDatasetDatasetArgs.builder()
 *                             .projectId(public_.project())
 *                             .datasetId(public_.datasetId())
 *                             .build())
 *                         .targetTypes("VIEWS")
 *                         .build())
 *                     .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * ### Bigquery Dataset Authorized Routine
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.bigquery.Dataset;
 * import com.pulumi.gcp.bigquery.DatasetArgs;
 * import com.pulumi.gcp.bigquery.Routine;
 * import com.pulumi.gcp.bigquery.RoutineArgs;
 * import com.pulumi.gcp.bigquery.inputs.RoutineArgumentArgs;
 * import com.pulumi.gcp.bigquery.inputs.DatasetAccessArgs;
 * import com.pulumi.gcp.bigquery.inputs.DatasetAccessRoutineArgs;
 * import static com.pulumi.codegen.internal.Serialization.*;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App }{{@code
 *     public static void main(String[] args) }{{@code
 *         Pulumi.run(App::stack);
 *     }}{@code
 * 
 *     public static void stack(Context ctx) }{{@code
 *         var public_ = new Dataset("public", DatasetArgs.builder()
 *             .datasetId("public_dataset")
 *             .description("This dataset is public")
 *             .build());
 * 
 *         var publicRoutine = new Routine("publicRoutine", RoutineArgs.builder()
 *             .datasetId(public_.datasetId())
 *             .routineId("public_routine")
 *             .routineType("TABLE_VALUED_FUNCTION")
 *             .language("SQL")
 *             .definitionBody("""
 * SELECT 1 + value AS value
 *             """)
 *             .arguments(RoutineArgumentArgs.builder()
 *                 .name("value")
 *                 .argumentKind("FIXED_TYPE")
 *                 .dataType(serializeJson(
 *                     jsonObject(
 *                         jsonProperty("typeKind", "INT64")
 *                     )))
 *                 .build())
 *             .returnTableType(serializeJson(
 *                 jsonObject(
 *                     jsonProperty("columns", jsonArray(jsonObject(
 *                         jsonProperty("name", "value"),
 *                         jsonProperty("type", jsonObject(
 *                             jsonProperty("typeKind", "INT64")
 *                         ))
 *                     )))
 *                 )))
 *             .build());
 * 
 *         var private_ = new Dataset("private", DatasetArgs.builder()
 *             .datasetId("private_dataset")
 *             .description("This dataset is private")
 *             .accesses(            
 *                 DatasetAccessArgs.builder()
 *                     .role("OWNER")
 *                     .userByEmail("my}{@literal @}{@code service-account.com")
 *                     .build(),
 *                 DatasetAccessArgs.builder()
 *                     .routine(DatasetAccessRoutineArgs.builder()
 *                         .projectId(publicRoutine.project())
 *                         .datasetId(publicRoutine.datasetId())
 *                         .routineId(publicRoutine.routineId())
 *                         .build())
 *                     .build())
 *             .build());
 * 
 *     }}{@code
 * }}{@code
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * ### Bigquery Dataset External Reference Aws
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.bigquery.Dataset;
 * import com.pulumi.gcp.bigquery.DatasetArgs;
 * import com.pulumi.gcp.bigquery.inputs.DatasetExternalDatasetReferenceArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var dataset = new Dataset("dataset", DatasetArgs.builder()
 *             .datasetId("example_dataset")
 *             .friendlyName("test")
 *             .description("This is a test description")
 *             .location("aws-us-east-1")
 *             .externalDatasetReference(DatasetExternalDatasetReferenceArgs.builder()
 *                 .externalSource("aws-glue://arn:aws:glue:us-east-1:999999999999:database/database")
 *                 .connection("projects/project/locations/aws-us-east-1/connections/connection")
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * ### Bigquery Dataset External Catalog Dataset Options
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.bigquery.Dataset;
 * import com.pulumi.gcp.bigquery.DatasetArgs;
 * import com.pulumi.gcp.bigquery.inputs.DatasetExternalCatalogDatasetOptionsArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var dataset = new Dataset("dataset", DatasetArgs.builder()
 *             .datasetId("example_dataset")
 *             .friendlyName("test")
 *             .description("This is a test description")
 *             .location("US")
 *             .externalCatalogDatasetOptions(DatasetExternalCatalogDatasetOptionsArgs.builder()
 *                 .parameters(Map.of("dataset_owner", "test_dataset_owner"))
 *                 .defaultStorageLocationUri("gs://test_dataset/tables")
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * ## Import
 * 
 * Dataset can be imported using any of these accepted formats:
 * 
 * * `projects/{{project}}/datasets/{{dataset_id}}`
 * 
 * * `{{project}}/{{dataset_id}}`
 * 
 * * `{{dataset_id}}`
 * 
 * When using the `pulumi import` command, Dataset can be imported using one of the formats above. For example:
 * 
 * ```sh
 * $ pulumi import gcp:bigquery/dataset:Dataset default projects/{{project}}/datasets/{{dataset_id}}
 * ```
 * 
 * ```sh
 * $ pulumi import gcp:bigquery/dataset:Dataset default {{project}}/{{dataset_id}}
 * ```
 * 
 * ```sh
 * $ pulumi import gcp:bigquery/dataset:Dataset default {{dataset_id}}
 * ```
 * 
 */
@ResourceType(type="gcp:bigquery/dataset:Dataset")
public class Dataset extends com.pulumi.resources.CustomResource {
    /**
     * An array of objects that define dataset access for one or more entities.
     * Structure is documented below.
     * 
     */
    @Export(name="accesses", refs={List.class,DatasetAccess.class}, tree="[0,1]")
    private Output<List<DatasetAccess>> accesses;

    /**
     * @return An array of objects that define dataset access for one or more entities.
     * Structure is documented below.
     * 
     */
    public Output<List<DatasetAccess>> accesses() {
        return this.accesses;
    }
    /**
     * The time when this dataset was created, in milliseconds since the
     * epoch.
     * 
     */
    @Export(name="creationTime", refs={Integer.class}, tree="[0]")
    private Output<Integer> creationTime;

    /**
     * @return The time when this dataset was created, in milliseconds since the
     * epoch.
     * 
     */
    public Output<Integer> creationTime() {
        return this.creationTime;
    }
    /**
     * A unique ID for this dataset, without the project name. The ID
     * must contain only letters (a-z, A-Z), numbers (0-9), or
     * underscores (_). The maximum length is 1,024 characters.
     * 
     */
    @Export(name="datasetId", refs={String.class}, tree="[0]")
    private Output<String> datasetId;

    /**
     * @return A unique ID for this dataset, without the project name. The ID
     * must contain only letters (a-z, A-Z), numbers (0-9), or
     * underscores (_). The maximum length is 1,024 characters.
     * 
     */
    public Output<String> datasetId() {
        return this.datasetId;
    }
    /**
     * Defines the default collation specification of future tables created
     * in the dataset. If a table is created in this dataset without table-level
     * default collation, then the table inherits the dataset default collation,
     * which is applied to the string fields that do not have explicit collation
     * specified. A change to this field affects only tables created afterwards,
     * and does not alter the existing tables.
     * The following values are supported:
     * - &#39;und:ci&#39;: undetermined locale, case insensitive.
     * - &#39;&#39;: empty string. Default to case-sensitive behavior.
     * 
     */
    @Export(name="defaultCollation", refs={String.class}, tree="[0]")
    private Output<String> defaultCollation;

    /**
     * @return Defines the default collation specification of future tables created
     * in the dataset. If a table is created in this dataset without table-level
     * default collation, then the table inherits the dataset default collation,
     * which is applied to the string fields that do not have explicit collation
     * specified. A change to this field affects only tables created afterwards,
     * and does not alter the existing tables.
     * The following values are supported:
     * - &#39;und:ci&#39;: undetermined locale, case insensitive.
     * - &#39;&#39;: empty string. Default to case-sensitive behavior.
     * 
     */
    public Output<String> defaultCollation() {
        return this.defaultCollation;
    }
    /**
     * The default encryption key for all tables in the dataset. Once this property is set,
     * all newly-created partitioned tables in the dataset will have encryption key set to
     * this value, unless table creation request (or query) overrides the key.
     * Structure is documented below.
     * 
     */
    @Export(name="defaultEncryptionConfiguration", refs={DatasetDefaultEncryptionConfiguration.class}, tree="[0]")
    private Output</* @Nullable */ DatasetDefaultEncryptionConfiguration> defaultEncryptionConfiguration;

    /**
     * @return The default encryption key for all tables in the dataset. Once this property is set,
     * all newly-created partitioned tables in the dataset will have encryption key set to
     * this value, unless table creation request (or query) overrides the key.
     * Structure is documented below.
     * 
     */
    public Output<Optional<DatasetDefaultEncryptionConfiguration>> defaultEncryptionConfiguration() {
        return Codegen.optional(this.defaultEncryptionConfiguration);
    }
    /**
     * The default partition expiration for all partitioned tables in
     * the dataset, in milliseconds.
     * Once this property is set, all newly-created partitioned tables in
     * the dataset will have an `expirationMs` property in the `timePartitioning`
     * settings set to this value, and changing the value will only
     * affect new tables, not existing ones. The storage in a partition will
     * have an expiration time of its partition time plus this value.
     * Setting this property overrides the use of `defaultTableExpirationMs`
     * for partitioned tables: only one of `defaultTableExpirationMs` and
     * `defaultPartitionExpirationMs` will be used for any new partitioned
     * table. If you provide an explicit `timePartitioning.expirationMs` when
     * creating or updating a partitioned table, that value takes precedence
     * over the default partition expiration time indicated by this property.
     * 
     */
    @Export(name="defaultPartitionExpirationMs", refs={Integer.class}, tree="[0]")
    private Output</* @Nullable */ Integer> defaultPartitionExpirationMs;

    /**
     * @return The default partition expiration for all partitioned tables in
     * the dataset, in milliseconds.
     * Once this property is set, all newly-created partitioned tables in
     * the dataset will have an `expirationMs` property in the `timePartitioning`
     * settings set to this value, and changing the value will only
     * affect new tables, not existing ones. The storage in a partition will
     * have an expiration time of its partition time plus this value.
     * Setting this property overrides the use of `defaultTableExpirationMs`
     * for partitioned tables: only one of `defaultTableExpirationMs` and
     * `defaultPartitionExpirationMs` will be used for any new partitioned
     * table. If you provide an explicit `timePartitioning.expirationMs` when
     * creating or updating a partitioned table, that value takes precedence
     * over the default partition expiration time indicated by this property.
     * 
     */
    public Output<Optional<Integer>> defaultPartitionExpirationMs() {
        return Codegen.optional(this.defaultPartitionExpirationMs);
    }
    /**
     * The default lifetime of all tables in the dataset, in milliseconds.
     * The minimum value is 3600000 milliseconds (one hour).
     * Once this property is set, all newly-created tables in the dataset
     * will have an `expirationTime` property set to the creation time plus
     * the value in this property, and changing the value will only affect
     * new tables, not existing ones. When the `expirationTime` for a given
     * table is reached, that table will be deleted automatically.
     * If a table&#39;s `expirationTime` is modified or removed before the
     * table expires, or if you provide an explicit `expirationTime` when
     * creating a table, that value takes precedence over the default
     * expiration time indicated by this property.
     * 
     */
    @Export(name="defaultTableExpirationMs", refs={Integer.class}, tree="[0]")
    private Output</* @Nullable */ Integer> defaultTableExpirationMs;

    /**
     * @return The default lifetime of all tables in the dataset, in milliseconds.
     * The minimum value is 3600000 milliseconds (one hour).
     * Once this property is set, all newly-created tables in the dataset
     * will have an `expirationTime` property set to the creation time plus
     * the value in this property, and changing the value will only affect
     * new tables, not existing ones. When the `expirationTime` for a given
     * table is reached, that table will be deleted automatically.
     * If a table&#39;s `expirationTime` is modified or removed before the
     * table expires, or if you provide an explicit `expirationTime` when
     * creating a table, that value takes precedence over the default
     * expiration time indicated by this property.
     * 
     */
    public Output<Optional<Integer>> defaultTableExpirationMs() {
        return Codegen.optional(this.defaultTableExpirationMs);
    }
    /**
     * If set to `true`, delete all the tables in the
     * dataset when destroying the resource; otherwise,
     * destroying the resource will fail if tables are present.
     * 
     */
    @Export(name="deleteContentsOnDestroy", refs={Boolean.class}, tree="[0]")
    private Output</* @Nullable */ Boolean> deleteContentsOnDestroy;

    /**
     * @return If set to `true`, delete all the tables in the
     * dataset when destroying the resource; otherwise,
     * destroying the resource will fail if tables are present.
     * 
     */
    public Output<Optional<Boolean>> deleteContentsOnDestroy() {
        return Codegen.optional(this.deleteContentsOnDestroy);
    }
    /**
     * A user-friendly description of the dataset
     * 
     */
    @Export(name="description", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> description;

    /**
     * @return A user-friendly description of the dataset
     * 
     */
    public Output<Optional<String>> description() {
        return Codegen.optional(this.description);
    }
    /**
     * All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
     * 
     */
    @Export(name="effectiveLabels", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> effectiveLabels;

    /**
     * @return All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
     * 
     */
    public Output<Map<String,String>> effectiveLabels() {
        return this.effectiveLabels;
    }
    /**
     * A hash of the resource.
     * 
     */
    @Export(name="etag", refs={String.class}, tree="[0]")
    private Output<String> etag;

    /**
     * @return A hash of the resource.
     * 
     */
    public Output<String> etag() {
        return this.etag;
    }
    /**
     * Options defining open source compatible datasets living in the BigQuery catalog. Contains
     * metadata of open source database, schema or namespace represented by the current dataset.
     * Structure is documented below.
     * 
     */
    @Export(name="externalCatalogDatasetOptions", refs={DatasetExternalCatalogDatasetOptions.class}, tree="[0]")
    private Output</* @Nullable */ DatasetExternalCatalogDatasetOptions> externalCatalogDatasetOptions;

    /**
     * @return Options defining open source compatible datasets living in the BigQuery catalog. Contains
     * metadata of open source database, schema or namespace represented by the current dataset.
     * Structure is documented below.
     * 
     */
    public Output<Optional<DatasetExternalCatalogDatasetOptions>> externalCatalogDatasetOptions() {
        return Codegen.optional(this.externalCatalogDatasetOptions);
    }
    /**
     * Information about the external metadata storage where the dataset is defined.
     * Structure is documented below.
     * 
     */
    @Export(name="externalDatasetReference", refs={DatasetExternalDatasetReference.class}, tree="[0]")
    private Output</* @Nullable */ DatasetExternalDatasetReference> externalDatasetReference;

    /**
     * @return Information about the external metadata storage where the dataset is defined.
     * Structure is documented below.
     * 
     */
    public Output<Optional<DatasetExternalDatasetReference>> externalDatasetReference() {
        return Codegen.optional(this.externalDatasetReference);
    }
    /**
     * A descriptive name for the dataset
     * 
     */
    @Export(name="friendlyName", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> friendlyName;

    /**
     * @return A descriptive name for the dataset
     * 
     */
    public Output<Optional<String>> friendlyName() {
        return Codegen.optional(this.friendlyName);
    }
    /**
     * TRUE if the dataset and its table names are case-insensitive, otherwise FALSE.
     * By default, this is FALSE, which means the dataset and its table names are
     * case-sensitive. This field does not affect routine references.
     * 
     */
    @Export(name="isCaseInsensitive", refs={Boolean.class}, tree="[0]")
    private Output<Boolean> isCaseInsensitive;

    /**
     * @return TRUE if the dataset and its table names are case-insensitive, otherwise FALSE.
     * By default, this is FALSE, which means the dataset and its table names are
     * case-sensitive. This field does not affect routine references.
     * 
     */
    public Output<Boolean> isCaseInsensitive() {
        return this.isCaseInsensitive;
    }
    /**
     * The labels associated with this dataset. You can use these to
     * organize and group your datasets.
     * 
     * **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
     * Please refer to the field `effective_labels` for all of the labels present on the resource.
     * 
     */
    @Export(name="labels", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> labels;

    /**
     * @return The labels associated with this dataset. You can use these to
     * organize and group your datasets.
     * 
     * **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
     * Please refer to the field `effective_labels` for all of the labels present on the resource.
     * 
     */
    public Output<Optional<Map<String,String>>> labels() {
        return Codegen.optional(this.labels);
    }
    /**
     * The date when this dataset or any of its tables was last modified, in
     * milliseconds since the epoch.
     * 
     */
    @Export(name="lastModifiedTime", refs={Integer.class}, tree="[0]")
    private Output<Integer> lastModifiedTime;

    /**
     * @return The date when this dataset or any of its tables was last modified, in
     * milliseconds since the epoch.
     * 
     */
    public Output<Integer> lastModifiedTime() {
        return this.lastModifiedTime;
    }
    /**
     * The geographic location where the dataset should reside.
     * See [official docs](https://cloud.google.com/bigquery/docs/dataset-locations).
     * There are two types of locations, regional or multi-regional. A regional
     * location is a specific geographic place, such as Tokyo, and a multi-regional
     * location is a large geographic area, such as the United States, that
     * contains at least two geographic places.
     * The default value is multi-regional location `US`.
     * Changing this forces a new resource to be created.
     * 
     */
    @Export(name="location", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> location;

    /**
     * @return The geographic location where the dataset should reside.
     * See [official docs](https://cloud.google.com/bigquery/docs/dataset-locations).
     * There are two types of locations, regional or multi-regional. A regional
     * location is a specific geographic place, such as Tokyo, and a multi-regional
     * location is a large geographic area, such as the United States, that
     * contains at least two geographic places.
     * The default value is multi-regional location `US`.
     * Changing this forces a new resource to be created.
     * 
     */
    public Output<Optional<String>> location() {
        return Codegen.optional(this.location);
    }
    /**
     * Defines the time travel window in hours. The value can be from 48 to 168 hours (2 to 7 days).
     * 
     */
    @Export(name="maxTimeTravelHours", refs={String.class}, tree="[0]")
    private Output<String> maxTimeTravelHours;

    /**
     * @return Defines the time travel window in hours. The value can be from 48 to 168 hours (2 to 7 days).
     * 
     */
    public Output<String> maxTimeTravelHours() {
        return this.maxTimeTravelHours;
    }
    /**
     * The ID of the project in which the resource belongs.
     * If it is not provided, the provider project is used.
     * 
     */
    @Export(name="project", refs={String.class}, tree="[0]")
    private Output<String> project;

    /**
     * @return The ID of the project in which the resource belongs.
     * If it is not provided, the provider project is used.
     * 
     */
    public Output<String> project() {
        return this.project;
    }
    /**
     * The combination of labels configured directly on the resource
     * and default labels configured on the provider.
     * 
     */
    @Export(name="pulumiLabels", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> pulumiLabels;

    /**
     * @return The combination of labels configured directly on the resource
     * and default labels configured on the provider.
     * 
     */
    public Output<Map<String,String>> pulumiLabels() {
        return this.pulumiLabels;
    }
    /**
     * The tags attached to this table. Tag keys are globally unique. Tag key is expected to be
     * in the namespaced format, for example &#34;123456789012/environment&#34; where 123456789012 is the
     * ID of the parent organization or project resource for this tag key. Tag value is expected
     * to be the short name, for example &#34;Production&#34;. See [Tag definitions](https://cloud.google.com/iam/docs/tags-access-control#definitions)
     * for more details.
     * 
     */
    @Export(name="resourceTags", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> resourceTags;

    /**
     * @return The tags attached to this table. Tag keys are globally unique. Tag key is expected to be
     * in the namespaced format, for example &#34;123456789012/environment&#34; where 123456789012 is the
     * ID of the parent organization or project resource for this tag key. Tag value is expected
     * to be the short name, for example &#34;Production&#34;. See [Tag definitions](https://cloud.google.com/iam/docs/tags-access-control#definitions)
     * for more details.
     * 
     */
    public Output<Optional<Map<String,String>>> resourceTags() {
        return Codegen.optional(this.resourceTags);
    }
    /**
     * The URI of the created resource.
     * 
     */
    @Export(name="selfLink", refs={String.class}, tree="[0]")
    private Output<String> selfLink;

    /**
     * @return The URI of the created resource.
     * 
     */
    public Output<String> selfLink() {
        return this.selfLink;
    }
    /**
     * Specifies the storage billing model for the dataset.
     * Set this flag value to LOGICAL to use logical bytes for storage billing,
     * or to PHYSICAL to use physical bytes instead.
     * LOGICAL is the default if this flag isn&#39;t specified.
     * 
     */
    @Export(name="storageBillingModel", refs={String.class}, tree="[0]")
    private Output<String> storageBillingModel;

    /**
     * @return Specifies the storage billing model for the dataset.
     * Set this flag value to LOGICAL to use logical bytes for storage billing,
     * or to PHYSICAL to use physical bytes instead.
     * LOGICAL is the default if this flag isn&#39;t specified.
     * 
     */
    public Output<String> storageBillingModel() {
        return this.storageBillingModel;
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public Dataset(java.lang.String name) {
        this(name, DatasetArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public Dataset(java.lang.String name, DatasetArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public Dataset(java.lang.String name, DatasetArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:bigquery/dataset:Dataset", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private Dataset(java.lang.String name, Output<java.lang.String> id, @Nullable DatasetState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:bigquery/dataset:Dataset", name, state, makeResourceOptions(options, id), false);
    }

    private static DatasetArgs makeArgs(DatasetArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? DatasetArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .additionalSecretOutputs(List.of(
                "effectiveLabels",
                "pulumiLabels"
            ))
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static Dataset get(java.lang.String name, Output<java.lang.String> id, @Nullable DatasetState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new Dataset(name, id, state, options);
    }
}
