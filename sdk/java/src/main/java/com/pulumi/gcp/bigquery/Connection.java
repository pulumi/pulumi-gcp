// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.bigquery;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.gcp.Utilities;
import com.pulumi.gcp.bigquery.ConnectionArgs;
import com.pulumi.gcp.bigquery.inputs.ConnectionState;
import com.pulumi.gcp.bigquery.outputs.ConnectionAws;
import com.pulumi.gcp.bigquery.outputs.ConnectionAzure;
import com.pulumi.gcp.bigquery.outputs.ConnectionCloudResource;
import com.pulumi.gcp.bigquery.outputs.ConnectionCloudSpanner;
import com.pulumi.gcp.bigquery.outputs.ConnectionCloudSql;
import com.pulumi.gcp.bigquery.outputs.ConnectionSpark;
import java.lang.Boolean;
import java.lang.String;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * A connection allows BigQuery connections to external data sources..
 * 
 * To get more information about Connection, see:
 * 
 * * [API documentation](https://cloud.google.com/bigquery/docs/reference/bigqueryconnection/rest/v1/projects.locations.connections/create)
 * * How-to Guides
 *     * [Cloud SQL federated queries](https://cloud.google.com/bigquery/docs/cloud-sql-federated-queries)
 * 
 * ## Example Usage
 * 
 * ### Bigquery Connection Cloud Resource
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.bigquery.Connection;
 * import com.pulumi.gcp.bigquery.ConnectionArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionCloudResourceArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var connection = new Connection("connection", ConnectionArgs.builder()
 *             .connectionId("my-connection")
 *             .location("US")
 *             .friendlyName("ðŸ‘‹")
 *             .description("a riveting description")
 *             .cloudResource(ConnectionCloudResourceArgs.builder()
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * ### Bigquery Connection Basic
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.sql.DatabaseInstance;
 * import com.pulumi.gcp.sql.DatabaseInstanceArgs;
 * import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
 * import com.pulumi.gcp.sql.Database;
 * import com.pulumi.gcp.sql.DatabaseArgs;
 * import com.pulumi.random.RandomPassword;
 * import com.pulumi.random.RandomPasswordArgs;
 * import com.pulumi.gcp.sql.User;
 * import com.pulumi.gcp.sql.UserArgs;
 * import com.pulumi.gcp.bigquery.Connection;
 * import com.pulumi.gcp.bigquery.ConnectionArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionCloudSqlArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionCloudSqlCredentialArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
 *             .name("my-database-instance")
 *             .databaseVersion("POSTGRES_11")
 *             .region("us-central1")
 *             .settings(DatabaseInstanceSettingsArgs.builder()
 *                 .tier("db-f1-micro")
 *                 .build())
 *             .deletionProtection(true)
 *             .build());
 * 
 *         var db = new Database("db", DatabaseArgs.builder()
 *             .instance(instance.name())
 *             .name("db")
 *             .build());
 * 
 *         var pwd = new RandomPassword("pwd", RandomPasswordArgs.builder()
 *             .length(16)
 *             .special(false)
 *             .build());
 * 
 *         var user = new User("user", UserArgs.builder()
 *             .name("user")
 *             .instance(instance.name())
 *             .password(pwd.result())
 *             .build());
 * 
 *         var connection = new Connection("connection", ConnectionArgs.builder()
 *             .friendlyName("ðŸ‘‹")
 *             .description("a riveting description")
 *             .location("US")
 *             .cloudSql(ConnectionCloudSqlArgs.builder()
 *                 .instanceId(instance.connectionName())
 *                 .database(db.name())
 *                 .type("POSTGRES")
 *                 .credential(ConnectionCloudSqlCredentialArgs.builder()
 *                     .username(user.name())
 *                     .password(user.password())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * ### Bigquery Connection Full
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.sql.DatabaseInstance;
 * import com.pulumi.gcp.sql.DatabaseInstanceArgs;
 * import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
 * import com.pulumi.gcp.sql.Database;
 * import com.pulumi.gcp.sql.DatabaseArgs;
 * import com.pulumi.random.RandomPassword;
 * import com.pulumi.random.RandomPasswordArgs;
 * import com.pulumi.gcp.sql.User;
 * import com.pulumi.gcp.sql.UserArgs;
 * import com.pulumi.gcp.bigquery.Connection;
 * import com.pulumi.gcp.bigquery.ConnectionArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionCloudSqlArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionCloudSqlCredentialArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
 *             .name("my-database-instance")
 *             .databaseVersion("POSTGRES_11")
 *             .region("us-central1")
 *             .settings(DatabaseInstanceSettingsArgs.builder()
 *                 .tier("db-f1-micro")
 *                 .build())
 *             .deletionProtection(true)
 *             .build());
 * 
 *         var db = new Database("db", DatabaseArgs.builder()
 *             .instance(instance.name())
 *             .name("db")
 *             .build());
 * 
 *         var pwd = new RandomPassword("pwd", RandomPasswordArgs.builder()
 *             .length(16)
 *             .special(false)
 *             .build());
 * 
 *         var user = new User("user", UserArgs.builder()
 *             .name("user")
 *             .instance(instance.name())
 *             .password(pwd.result())
 *             .build());
 * 
 *         var connection = new Connection("connection", ConnectionArgs.builder()
 *             .connectionId("my-connection")
 *             .location("US")
 *             .friendlyName("ðŸ‘‹")
 *             .description("a riveting description")
 *             .cloudSql(ConnectionCloudSqlArgs.builder()
 *                 .instanceId(instance.connectionName())
 *                 .database(db.name())
 *                 .type("POSTGRES")
 *                 .credential(ConnectionCloudSqlCredentialArgs.builder()
 *                     .username(user.name())
 *                     .password(user.password())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * ### Bigquery Connection Aws
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.bigquery.Connection;
 * import com.pulumi.gcp.bigquery.ConnectionArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionAwsArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionAwsAccessRoleArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var connection = new Connection("connection", ConnectionArgs.builder()
 *             .connectionId("my-connection")
 *             .location("aws-us-east-1")
 *             .friendlyName("ðŸ‘‹")
 *             .description("a riveting description")
 *             .aws(ConnectionAwsArgs.builder()
 *                 .accessRole(ConnectionAwsAccessRoleArgs.builder()
 *                     .iamRoleId("arn:aws:iam::999999999999:role/omnirole")
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * ### Bigquery Connection Azure
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.bigquery.Connection;
 * import com.pulumi.gcp.bigquery.ConnectionArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionAzureArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var connection = new Connection("connection", ConnectionArgs.builder()
 *             .connectionId("my-connection")
 *             .location("azure-eastus2")
 *             .friendlyName("ðŸ‘‹")
 *             .description("a riveting description")
 *             .azure(ConnectionAzureArgs.builder()
 *                 .customerTenantId("customer-tenant-id")
 *                 .federatedApplicationClientId("b43eeeee-eeee-eeee-eeee-a480155501ce")
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * ### Bigquery Connection Cloudspanner
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.bigquery.Connection;
 * import com.pulumi.gcp.bigquery.ConnectionArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionCloudSpannerArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var connection = new Connection("connection", ConnectionArgs.builder()
 *             .connectionId("my-connection")
 *             .location("US")
 *             .friendlyName("ðŸ‘‹")
 *             .description("a riveting description")
 *             .cloudSpanner(ConnectionCloudSpannerArgs.builder()
 *                 .database("projects/project/instances/instance/databases/database")
 *                 .databaseRole("database_role")
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * ### Bigquery Connection Cloudspanner Databoost
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.bigquery.Connection;
 * import com.pulumi.gcp.bigquery.ConnectionArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionCloudSpannerArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var connection = new Connection("connection", ConnectionArgs.builder()
 *             .connectionId("my-connection")
 *             .location("US")
 *             .friendlyName("ðŸ‘‹")
 *             .description("a riveting description")
 *             .cloudSpanner(ConnectionCloudSpannerArgs.builder()
 *                 .database("projects/project/instances/instance/databases/database")
 *                 .useParallelism(true)
 *                 .useDataBoost(true)
 *                 .maxParallelism(100)
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * ### Bigquery Connection Spark
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.dataproc.Cluster;
 * import com.pulumi.gcp.dataproc.ClusterArgs;
 * import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigArgs;
 * import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigSoftwareConfigArgs;
 * import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigMasterConfigArgs;
 * import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigMasterConfigDiskConfigArgs;
 * import com.pulumi.gcp.bigquery.Connection;
 * import com.pulumi.gcp.bigquery.ConnectionArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionSparkArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionSparkSparkHistoryServerConfigArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var basic = new Cluster("basic", ClusterArgs.builder()
 *             .name("my-connection")
 *             .region("us-central1")
 *             .clusterConfig(ClusterClusterConfigArgs.builder()
 *                 .softwareConfig(ClusterClusterConfigSoftwareConfigArgs.builder()
 *                     .overrideProperties(Map.of("dataproc:dataproc.allow.zero.workers", "true"))
 *                     .build())
 *                 .masterConfig(ClusterClusterConfigMasterConfigArgs.builder()
 *                     .numInstances(1)
 *                     .machineType("e2-standard-2")
 *                     .diskConfig(ClusterClusterConfigMasterConfigDiskConfigArgs.builder()
 *                         .bootDiskSizeGb(35)
 *                         .build())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *         var connection = new Connection("connection", ConnectionArgs.builder()
 *             .connectionId("my-connection")
 *             .location("US")
 *             .friendlyName("ðŸ‘‹")
 *             .description("a riveting description")
 *             .spark(ConnectionSparkArgs.builder()
 *                 .sparkHistoryServerConfig(ConnectionSparkSparkHistoryServerConfigArgs.builder()
 *                     .dataprocCluster(basic.id())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * ### Bigquery Connection Sql With Cmek
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.sql.DatabaseInstance;
 * import com.pulumi.gcp.sql.DatabaseInstanceArgs;
 * import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
 * import com.pulumi.gcp.sql.Database;
 * import com.pulumi.gcp.sql.DatabaseArgs;
 * import com.pulumi.gcp.sql.User;
 * import com.pulumi.gcp.sql.UserArgs;
 * import com.pulumi.gcp.bigquery.Connection;
 * import com.pulumi.gcp.bigquery.ConnectionArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionCloudSqlArgs;
 * import com.pulumi.gcp.bigquery.inputs.ConnectionCloudSqlCredentialArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
 *             .name("my-database-instance")
 *             .region("us-central1")
 *             .databaseVersion("POSTGRES_11")
 *             .settings(DatabaseInstanceSettingsArgs.builder()
 *                 .tier("db-f1-micro")
 *                 .build())
 *             .deletionProtection(true)
 *             .build());
 * 
 *         var db = new Database("db", DatabaseArgs.builder()
 *             .instance(instance.name())
 *             .name("db")
 *             .build());
 * 
 *         var user = new User("user", UserArgs.builder()
 *             .name("user")
 *             .instance(instance.name())
 *             .password("tf-test-my-password_15222")
 *             .build());
 * 
 *         var bq_connection_cmek = new Connection("bq-connection-cmek", ConnectionArgs.builder()
 *             .friendlyName("ðŸ‘‹")
 *             .description("a riveting description")
 *             .location("US")
 *             .kmsKeyName("projects/project/locations/us-central1/keyRings/us-central1/cryptoKeys/bq-key")
 *             .cloudSql(ConnectionCloudSqlArgs.builder()
 *                 .instanceId(instance.connectionName())
 *                 .database(db.name())
 *                 .type("POSTGRES")
 *                 .credential(ConnectionCloudSqlCredentialArgs.builder()
 *                     .username(user.name())
 *                     .password(user.password())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ## Import
 * 
 * Connection can be imported using any of these accepted formats:
 * 
 * * `projects/{{project}}/locations/{{location}}/connections/{{connection_id}}`
 * 
 * * `{{project}}/{{location}}/{{connection_id}}`
 * 
 * * `{{location}}/{{connection_id}}`
 * 
 * When using the `pulumi import` command, Connection can be imported using one of the formats above. For example:
 * 
 * ```sh
 * $ pulumi import gcp:bigquery/connection:Connection default projects/{{project}}/locations/{{location}}/connections/{{connection_id}}
 * ```
 * 
 * ```sh
 * $ pulumi import gcp:bigquery/connection:Connection default {{project}}/{{location}}/{{connection_id}}
 * ```
 * 
 * ```sh
 * $ pulumi import gcp:bigquery/connection:Connection default {{location}}/{{connection_id}}
 * ```
 * 
 */
@ResourceType(type="gcp:bigquery/connection:Connection")
public class Connection extends com.pulumi.resources.CustomResource {
    /**
     * Connection properties specific to Amazon Web Services.
     * Structure is documented below.
     * 
     */
    @Export(name="aws", refs={ConnectionAws.class}, tree="[0]")
    private Output</* @Nullable */ ConnectionAws> aws;

    /**
     * @return Connection properties specific to Amazon Web Services.
     * Structure is documented below.
     * 
     */
    public Output<Optional<ConnectionAws>> aws() {
        return Codegen.optional(this.aws);
    }
    /**
     * Container for connection properties specific to Azure.
     * Structure is documented below.
     * 
     */
    @Export(name="azure", refs={ConnectionAzure.class}, tree="[0]")
    private Output</* @Nullable */ ConnectionAzure> azure;

    /**
     * @return Container for connection properties specific to Azure.
     * Structure is documented below.
     * 
     */
    public Output<Optional<ConnectionAzure>> azure() {
        return Codegen.optional(this.azure);
    }
    /**
     * Container for connection properties for delegation of access to GCP resources.
     * Structure is documented below.
     * 
     */
    @Export(name="cloudResource", refs={ConnectionCloudResource.class}, tree="[0]")
    private Output</* @Nullable */ ConnectionCloudResource> cloudResource;

    /**
     * @return Container for connection properties for delegation of access to GCP resources.
     * Structure is documented below.
     * 
     */
    public Output<Optional<ConnectionCloudResource>> cloudResource() {
        return Codegen.optional(this.cloudResource);
    }
    /**
     * Connection properties specific to Cloud Spanner
     * Structure is documented below.
     * 
     */
    @Export(name="cloudSpanner", refs={ConnectionCloudSpanner.class}, tree="[0]")
    private Output</* @Nullable */ ConnectionCloudSpanner> cloudSpanner;

    /**
     * @return Connection properties specific to Cloud Spanner
     * Structure is documented below.
     * 
     */
    public Output<Optional<ConnectionCloudSpanner>> cloudSpanner() {
        return Codegen.optional(this.cloudSpanner);
    }
    /**
     * Connection properties specific to the Cloud SQL.
     * Structure is documented below.
     * 
     */
    @Export(name="cloudSql", refs={ConnectionCloudSql.class}, tree="[0]")
    private Output</* @Nullable */ ConnectionCloudSql> cloudSql;

    /**
     * @return Connection properties specific to the Cloud SQL.
     * Structure is documented below.
     * 
     */
    public Output<Optional<ConnectionCloudSql>> cloudSql() {
        return Codegen.optional(this.cloudSql);
    }
    /**
     * Optional connection id that should be assigned to the created connection.
     * 
     */
    @Export(name="connectionId", refs={String.class}, tree="[0]")
    private Output<String> connectionId;

    /**
     * @return Optional connection id that should be assigned to the created connection.
     * 
     */
    public Output<String> connectionId() {
        return this.connectionId;
    }
    /**
     * A descriptive description for the connection
     * 
     */
    @Export(name="description", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> description;

    /**
     * @return A descriptive description for the connection
     * 
     */
    public Output<Optional<String>> description() {
        return Codegen.optional(this.description);
    }
    /**
     * A descriptive name for the connection
     * 
     */
    @Export(name="friendlyName", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> friendlyName;

    /**
     * @return A descriptive name for the connection
     * 
     */
    public Output<Optional<String>> friendlyName() {
        return Codegen.optional(this.friendlyName);
    }
    /**
     * True if the connection has credential assigned.
     * 
     */
    @Export(name="hasCredential", refs={Boolean.class}, tree="[0]")
    private Output<Boolean> hasCredential;

    /**
     * @return True if the connection has credential assigned.
     * 
     */
    public Output<Boolean> hasCredential() {
        return this.hasCredential;
    }
    /**
     * Optional. The Cloud KMS key that is used for encryption.
     * Example: projects/[kmsProjectId]/locations/[region]/keyRings/[keyRegion]/cryptoKeys/[key]
     * 
     */
    @Export(name="kmsKeyName", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> kmsKeyName;

    /**
     * @return Optional. The Cloud KMS key that is used for encryption.
     * Example: projects/[kmsProjectId]/locations/[region]/keyRings/[keyRegion]/cryptoKeys/[key]
     * 
     */
    public Output<Optional<String>> kmsKeyName() {
        return Codegen.optional(this.kmsKeyName);
    }
    /**
     * The geographic location where the connection should reside.
     * Cloud SQL instance must be in the same location as the connection
     * with following exceptions: Cloud SQL us-central1 maps to BigQuery US, Cloud SQL europe-west1 maps to BigQuery EU.
     * Examples: US, EU, asia-northeast1, us-central1, europe-west1.
     * Spanner Connections same as spanner region
     * AWS allowed regions are aws-us-east-1
     * Azure allowed regions are azure-eastus2
     * 
     */
    @Export(name="location", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> location;

    /**
     * @return The geographic location where the connection should reside.
     * Cloud SQL instance must be in the same location as the connection
     * with following exceptions: Cloud SQL us-central1 maps to BigQuery US, Cloud SQL europe-west1 maps to BigQuery EU.
     * Examples: US, EU, asia-northeast1, us-central1, europe-west1.
     * Spanner Connections same as spanner region
     * AWS allowed regions are aws-us-east-1
     * Azure allowed regions are azure-eastus2
     * 
     */
    public Output<Optional<String>> location() {
        return Codegen.optional(this.location);
    }
    /**
     * The resource name of the connection in the form of:
     * &#34;projects/{project_id}/locations/{location_id}/connections/{connectionId}&#34;
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return The resource name of the connection in the form of:
     * &#34;projects/{project_id}/locations/{location_id}/connections/{connectionId}&#34;
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * The ID of the project in which the resource belongs.
     * If it is not provided, the provider project is used.
     * 
     */
    @Export(name="project", refs={String.class}, tree="[0]")
    private Output<String> project;

    /**
     * @return The ID of the project in which the resource belongs.
     * If it is not provided, the provider project is used.
     * 
     */
    public Output<String> project() {
        return this.project;
    }
    /**
     * Container for connection properties to execute stored procedures for Apache Spark. resources.
     * Structure is documented below.
     * 
     */
    @Export(name="spark", refs={ConnectionSpark.class}, tree="[0]")
    private Output</* @Nullable */ ConnectionSpark> spark;

    /**
     * @return Container for connection properties to execute stored procedures for Apache Spark. resources.
     * Structure is documented below.
     * 
     */
    public Output<Optional<ConnectionSpark>> spark() {
        return Codegen.optional(this.spark);
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public Connection(java.lang.String name) {
        this(name, ConnectionArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public Connection(java.lang.String name, @Nullable ConnectionArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public Connection(java.lang.String name, @Nullable ConnectionArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:bigquery/connection:Connection", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private Connection(java.lang.String name, Output<java.lang.String> id, @Nullable ConnectionState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:bigquery/connection:Connection", name, state, makeResourceOptions(options, id), false);
    }

    private static ConnectionArgs makeArgs(@Nullable ConnectionArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? ConnectionArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static Connection get(java.lang.String name, Output<java.lang.String> id, @Nullable ConnectionState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new Connection(name, id, state, options);
    }
}
