// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.dataflow;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.gcp.Utilities;
import com.pulumi.gcp.dataflow.FlexTemplateJobArgs;
import com.pulumi.gcp.dataflow.inputs.FlexTemplateJobState;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * Creates a [Flex Template](https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates)
 * job on Dataflow, which is an implementation of Apache Beam running on Google
 * Compute Engine. For more information see the official documentation for [Beam](https://beam.apache.org)
 * and [Dataflow](https://cloud.google.com/dataflow/).
 * 
 * &gt; **Warning:** This resource is in beta, and should be used with the terraform-provider-google-beta provider.
 * See Provider Versions for more details on beta resources.
 * 
 * ## Example Usage
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.dataflow.FlexTemplateJob;
 * import com.pulumi.gcp.dataflow.FlexTemplateJobArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var bigDataJob = new FlexTemplateJob("bigDataJob", FlexTemplateJobArgs.builder()
 *             .name("dataflow-flextemplates-job")
 *             .containerSpecGcsPath("gs://my-bucket/templates/template.json")
 *             .parameters(Map.of("inputSubscription", "messages"))
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ## Note on &#34;destroy&#34; / &#34;apply&#34;
 * 
 * There are many types of Dataflow jobs.  Some Dataflow jobs run constantly,
 * getting new data from (e.g.) a GCS bucket, and outputting data continuously.
 * Some jobs process a set amount of data then terminate. All jobs can fail while
 * running due to programming errors or other issues. In this way, Dataflow jobs
 * are different from most other provider / Google resources.
 * 
 * The Dataflow resource is considered &#39;existing&#39; while it is in a nonterminal
 * state.  If it reaches a terminal state (e.g. &#39;FAILED&#39;, &#39;COMPLETE&#39;,
 * &#39;CANCELLED&#39;), it will be recreated on the next &#39;apply&#39;.  This is as expected for
 * jobs which run continuously, but may surprise users who use this resource for
 * other kinds of Dataflow jobs.
 * 
 * A Dataflow job which is &#39;destroyed&#39; may be &#34;cancelled&#34; or &#34;drained&#34;.  If
 * &#34;cancelled&#34;, the job terminates - any data written remains where it is, but no
 * new data will be processed.  If &#34;drained&#34;, no new data will enter the pipeline,
 * but any data currently in the pipeline will finish being processed.  The default
 * is &#34;cancelled&#34;, but if a user sets `onDelete` to `&#34;drain&#34;` in the
 * configuration, you may experience a long wait for your `pulumi destroy` to
 * complete.
 * 
 * You can potentially short-circuit the wait by setting `skipWaitOnJobTermination`
 * to `true`, but beware that unless you take active steps to ensure that the job
 * `name` parameter changes between instances, the name will conflict and the launch
 * of the new job will fail. One way to do this is with a
 * randomId
 * resource, for example:
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.random.Id;
 * import com.pulumi.random.IdArgs;
 * import com.pulumi.gcp.dataflow.FlexTemplateJob;
 * import com.pulumi.gcp.dataflow.FlexTemplateJobArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         final var config = ctx.config();
 *         final var bigDataJobSubscriptionId = config.get("bigDataJobSubscriptionId").orElse("projects/myproject/subscriptions/messages");
 *         var bigDataJobNameSuffix = new Id("bigDataJobNameSuffix", IdArgs.builder()
 *             .byteLength(4)
 *             .keepers(Map.ofEntries(
 *                 Map.entry("region", region),
 *                 Map.entry("subscriptionId", bigDataJobSubscriptionId)
 *             ))
 *             .build());
 * 
 *         var bigDataJob = new FlexTemplateJob("bigDataJob", FlexTemplateJobArgs.builder()
 *             .name(String.format("dataflow-flextemplates-job-%s", bigDataJobNameSuffix.dec()))
 *             .region(region)
 *             .containerSpecGcsPath("gs://my-bucket/templates/template.json")
 *             .skipWaitOnJobTermination(true)
 *             .parameters(Map.of("inputSubscription", bigDataJobSubscriptionId))
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ## Import
 * 
 * This resource does not support import.
 * 
 */
@ResourceType(type="gcp:dataflow/flexTemplateJob:FlexTemplateJob")
public class FlexTemplateJob extends com.pulumi.resources.CustomResource {
    /**
     * List of experiments that should be used by the job. An example value is `[&#34;enableStackdriverAgentMetrics&#34;]`.
     * 
     */
    @Export(name="additionalExperiments", refs={List.class,String.class}, tree="[0,1]")
    private Output<List<String>> additionalExperiments;

    /**
     * @return List of experiments that should be used by the job. An example value is `[&#34;enableStackdriverAgentMetrics&#34;]`.
     * 
     */
    public Output<List<String>> additionalExperiments() {
        return this.additionalExperiments;
    }
    /**
     * List of pipeline options that should be used by the job. An example value is `[&#34;numberOfWorkerHarnessThreads=20&#34;]`.
     * 
     */
    @Export(name="additionalPipelineOptions", refs={List.class,String.class}, tree="[0,1]")
    private Output</* @Nullable */ List<String>> additionalPipelineOptions;

    /**
     * @return List of pipeline options that should be used by the job. An example value is `[&#34;numberOfWorkerHarnessThreads=20&#34;]`.
     * 
     */
    public Output<Optional<List<String>>> additionalPipelineOptions() {
        return Codegen.optional(this.additionalPipelineOptions);
    }
    /**
     * The algorithm to use for autoscaling.
     * 
     */
    @Export(name="autoscalingAlgorithm", refs={String.class}, tree="[0]")
    private Output<String> autoscalingAlgorithm;

    /**
     * @return The algorithm to use for autoscaling.
     * 
     */
    public Output<String> autoscalingAlgorithm() {
        return this.autoscalingAlgorithm;
    }
    /**
     * The GCS path to the Dataflow job Flex
     * Template.
     * 
     * ***
     * 
     */
    @Export(name="containerSpecGcsPath", refs={String.class}, tree="[0]")
    private Output<String> containerSpecGcsPath;

    /**
     * @return The GCS path to the Dataflow job Flex
     * Template.
     * 
     * ***
     * 
     */
    public Output<String> containerSpecGcsPath() {
        return this.containerSpecGcsPath;
    }
    /**
     * All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Terraform, other clients and services.
     * 
     */
    @Export(name="effectiveLabels", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> effectiveLabels;

    /**
     * @return All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Terraform, other clients and services.
     * 
     */
    public Output<Map<String,String>> effectiveLabels() {
        return this.effectiveLabels;
    }
    /**
     * Immutable. Indicates if the job should use the streaming engine feature.
     * 
     */
    @Export(name="enableStreamingEngine", refs={Boolean.class}, tree="[0]")
    private Output</* @Nullable */ Boolean> enableStreamingEngine;

    /**
     * @return Immutable. Indicates if the job should use the streaming engine feature.
     * 
     */
    public Output<Optional<Boolean>> enableStreamingEngine() {
        return Codegen.optional(this.enableStreamingEngine);
    }
    /**
     * The configuration for VM IPs.  Options are `&#34;WORKER_IP_PUBLIC&#34;` or `&#34;WORKER_IP_PRIVATE&#34;`.
     * 
     */
    @Export(name="ipConfiguration", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> ipConfiguration;

    /**
     * @return The configuration for VM IPs.  Options are `&#34;WORKER_IP_PUBLIC&#34;` or `&#34;WORKER_IP_PRIVATE&#34;`.
     * 
     */
    public Output<Optional<String>> ipConfiguration() {
        return Codegen.optional(this.ipConfiguration);
    }
    /**
     * The unique ID of this job.
     * 
     */
    @Export(name="jobId", refs={String.class}, tree="[0]")
    private Output<String> jobId;

    /**
     * @return The unique ID of this job.
     * 
     */
    public Output<String> jobId() {
        return this.jobId;
    }
    /**
     * The name for the Cloud KMS key for the job. Key format is: `projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY`
     * 
     */
    @Export(name="kmsKeyName", refs={String.class}, tree="[0]")
    private Output<String> kmsKeyName;

    /**
     * @return The name for the Cloud KMS key for the job. Key format is: `projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY`
     * 
     */
    public Output<String> kmsKeyName() {
        return this.kmsKeyName;
    }
    /**
     * User labels to be specified for the job. Keys and values
     * should follow the restrictions specified in the [labeling restrictions](https://cloud.google.com/compute/docs/labeling-resources#restrictions)
     * page. **Note**: This field is marked as deprecated as the API does not currently
     * support adding labels.
     * **NOTE**: Google-provided Dataflow templates often provide default labels
     * that begin with `goog-dataflow-provided`. Unless explicitly set in config, these
     * labels will be ignored to prevent diffs on re-apply.
     * 
     */
    @Export(name="labels", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> labels;

    /**
     * @return User labels to be specified for the job. Keys and values
     * should follow the restrictions specified in the [labeling restrictions](https://cloud.google.com/compute/docs/labeling-resources#restrictions)
     * page. **Note**: This field is marked as deprecated as the API does not currently
     * support adding labels.
     * **NOTE**: Google-provided Dataflow templates often provide default labels
     * that begin with `goog-dataflow-provided`. Unless explicitly set in config, these
     * labels will be ignored to prevent diffs on re-apply.
     * 
     */
    public Output<Optional<Map<String,String>>> labels() {
        return Codegen.optional(this.labels);
    }
    /**
     * The machine type to use for launching the job. The default is n1-standard-1.
     * 
     */
    @Export(name="launcherMachineType", refs={String.class}, tree="[0]")
    private Output<String> launcherMachineType;

    /**
     * @return The machine type to use for launching the job. The default is n1-standard-1.
     * 
     */
    public Output<String> launcherMachineType() {
        return this.launcherMachineType;
    }
    /**
     * The machine type to use for the job.
     * 
     */
    @Export(name="machineType", refs={String.class}, tree="[0]")
    private Output<String> machineType;

    /**
     * @return The machine type to use for the job.
     * 
     */
    public Output<String> machineType() {
        return this.machineType;
    }
    /**
     * Immutable. The maximum number of Google Compute Engine instances to be made available to your pipeline during execution, from 1 to 1000.
     * 
     */
    @Export(name="maxWorkers", refs={Integer.class}, tree="[0]")
    private Output<Integer> maxWorkers;

    /**
     * @return Immutable. The maximum number of Google Compute Engine instances to be made available to your pipeline during execution, from 1 to 1000.
     * 
     */
    public Output<Integer> maxWorkers() {
        return this.maxWorkers;
    }
    /**
     * Immutable. A unique name for the resource, required by Dataflow.
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return Immutable. A unique name for the resource, required by Dataflow.
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * The network to which VMs will be assigned. If it is not provided, &#34;default&#34; will be used.
     * 
     */
    @Export(name="network", refs={String.class}, tree="[0]")
    private Output<String> network;

    /**
     * @return The network to which VMs will be assigned. If it is not provided, &#34;default&#34; will be used.
     * 
     */
    public Output<String> network() {
        return this.network;
    }
    /**
     * Immutable. The initial number of Google Compute Engine instances for the job.
     * 
     */
    @Export(name="numWorkers", refs={Integer.class}, tree="[0]")
    private Output<Integer> numWorkers;

    /**
     * @return Immutable. The initial number of Google Compute Engine instances for the job.
     * 
     */
    public Output<Integer> numWorkers() {
        return this.numWorkers;
    }
    /**
     * One of &#34;drain&#34; or &#34;cancel&#34;. Specifies behavior of
     * deletion during `pulumi destroy`.  See above note.
     * 
     */
    @Export(name="onDelete", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> onDelete;

    /**
     * @return One of &#34;drain&#34; or &#34;cancel&#34;. Specifies behavior of
     * deletion during `pulumi destroy`.  See above note.
     * 
     */
    public Output<Optional<String>> onDelete() {
        return Codegen.optional(this.onDelete);
    }
    /**
     * **Template specific** Key/Value pairs to be forwarded to the pipeline&#39;s options; keys are
     * case-sensitive based on the language on which the pipeline is coded, mostly Java.
     * **Note**: do not configure Dataflow options here in parameters.
     * 
     */
    @Export(name="parameters", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> parameters;

    /**
     * @return **Template specific** Key/Value pairs to be forwarded to the pipeline&#39;s options; keys are
     * case-sensitive based on the language on which the pipeline is coded, mostly Java.
     * **Note**: do not configure Dataflow options here in parameters.
     * 
     */
    public Output<Optional<Map<String,String>>> parameters() {
        return Codegen.optional(this.parameters);
    }
    /**
     * The project in which the resource belongs. If it is not
     * provided, the provider project is used.
     * 
     */
    @Export(name="project", refs={String.class}, tree="[0]")
    private Output<String> project;

    /**
     * @return The project in which the resource belongs. If it is not
     * provided, the provider project is used.
     * 
     */
    public Output<String> project() {
        return this.project;
    }
    /**
     * The combination of labels configured directly on the resource and default labels configured on the provider.
     * 
     */
    @Export(name="pulumiLabels", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> pulumiLabels;

    /**
     * @return The combination of labels configured directly on the resource and default labels configured on the provider.
     * 
     */
    public Output<Map<String,String>> pulumiLabels() {
        return this.pulumiLabels;
    }
    /**
     * Immutable. The region in which the created job should run.
     * 
     */
    @Export(name="region", refs={String.class}, tree="[0]")
    private Output<String> region;

    /**
     * @return Immutable. The region in which the created job should run.
     * 
     */
    public Output<String> region() {
        return this.region;
    }
    /**
     * Docker registry location of container image to use for the &#39;worker harness. Default is the container for the version of the SDK. Note this field is only valid for portable pipelines.
     * 
     */
    @Export(name="sdkContainerImage", refs={String.class}, tree="[0]")
    private Output<String> sdkContainerImage;

    /**
     * @return Docker registry location of container image to use for the &#39;worker harness. Default is the container for the version of the SDK. Note this field is only valid for portable pipelines.
     * 
     */
    public Output<String> sdkContainerImage() {
        return this.sdkContainerImage;
    }
    /**
     * Service account email to run the workers as. This should be just an email e.g. `myserviceaccount{@literal @}myproject.iam.gserviceaccount.com`. Do not include any `serviceAccount:` or other prefix.
     * 
     */
    @Export(name="serviceAccountEmail", refs={String.class}, tree="[0]")
    private Output<String> serviceAccountEmail;

    /**
     * @return Service account email to run the workers as. This should be just an email e.g. `myserviceaccount{@literal @}myproject.iam.gserviceaccount.com`. Do not include any `serviceAccount:` or other prefix.
     * 
     */
    public Output<String> serviceAccountEmail() {
        return this.serviceAccountEmail;
    }
    /**
     * If set to `true`, terraform will
     * treat `DRAINING` and `CANCELLING` as terminal states when deleting the resource,
     * and will remove the resource from terraform state and move on.  See above note.
     * 
     */
    @Export(name="skipWaitOnJobTermination", refs={Boolean.class}, tree="[0]")
    private Output</* @Nullable */ Boolean> skipWaitOnJobTermination;

    /**
     * @return If set to `true`, terraform will
     * treat `DRAINING` and `CANCELLING` as terminal states when deleting the resource,
     * and will remove the resource from terraform state and move on.  See above note.
     * 
     */
    public Output<Optional<Boolean>> skipWaitOnJobTermination() {
        return Codegen.optional(this.skipWaitOnJobTermination);
    }
    /**
     * The Cloud Storage path to use for staging files. Must be a valid Cloud Storage URL, beginning with gs://.
     * 
     */
    @Export(name="stagingLocation", refs={String.class}, tree="[0]")
    private Output<String> stagingLocation;

    /**
     * @return The Cloud Storage path to use for staging files. Must be a valid Cloud Storage URL, beginning with gs://.
     * 
     */
    public Output<String> stagingLocation() {
        return this.stagingLocation;
    }
    /**
     * The current state of the resource, selected from the [JobState enum](https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.jobs#Job.JobState)
     * 
     */
    @Export(name="state", refs={String.class}, tree="[0]")
    private Output<String> state;

    /**
     * @return The current state of the resource, selected from the [JobState enum](https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.jobs#Job.JobState)
     * 
     */
    public Output<String> state() {
        return this.state;
    }
    /**
     * The subnetwork to which VMs will be assigned. Should be of the form &#34;regions/REGION/subnetworks/SUBNETWORK&#34;.
     * 
     */
    @Export(name="subnetwork", refs={String.class}, tree="[0]")
    private Output<String> subnetwork;

    /**
     * @return The subnetwork to which VMs will be assigned. Should be of the form &#34;regions/REGION/subnetworks/SUBNETWORK&#34;.
     * 
     */
    public Output<String> subnetwork() {
        return this.subnetwork;
    }
    /**
     * The Cloud Storage path to use for temporary files. Must be a valid Cloud Storage URL, beginning with gs://.
     * 
     */
    @Export(name="tempLocation", refs={String.class}, tree="[0]")
    private Output<String> tempLocation;

    /**
     * @return The Cloud Storage path to use for temporary files. Must be a valid Cloud Storage URL, beginning with gs://.
     * 
     */
    public Output<String> tempLocation() {
        return this.tempLocation;
    }
    /**
     * Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the corresponding name prefixes of the new job.Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the corresponding name prefixes of the new job.
     * 
     */
    @Export(name="transformNameMapping", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> transformNameMapping;

    /**
     * @return Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the corresponding name prefixes of the new job.Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the corresponding name prefixes of the new job.
     * 
     */
    public Output<Optional<Map<String,String>>> transformNameMapping() {
        return Codegen.optional(this.transformNameMapping);
    }
    /**
     * The type of this job, selected from the JobType enum.
     * 
     */
    @Export(name="type", refs={String.class}, tree="[0]")
    private Output<String> type;

    /**
     * @return The type of this job, selected from the JobType enum.
     * 
     */
    public Output<String> type() {
        return this.type;
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public FlexTemplateJob(java.lang.String name) {
        this(name, FlexTemplateJobArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public FlexTemplateJob(java.lang.String name, FlexTemplateJobArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public FlexTemplateJob(java.lang.String name, FlexTemplateJobArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:dataflow/flexTemplateJob:FlexTemplateJob", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private FlexTemplateJob(java.lang.String name, Output<java.lang.String> id, @Nullable FlexTemplateJobState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:dataflow/flexTemplateJob:FlexTemplateJob", name, state, makeResourceOptions(options, id), false);
    }

    private static FlexTemplateJobArgs makeArgs(FlexTemplateJobArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? FlexTemplateJobArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .additionalSecretOutputs(List.of(
                "effectiveLabels",
                "pulumiLabels"
            ))
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static FlexTemplateJob get(java.lang.String name, Output<java.lang.String> id, @Nullable FlexTemplateJobState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new FlexTemplateJob(name, id, state, options);
    }
}
