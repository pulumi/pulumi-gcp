// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.vertex;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.gcp.Utilities;
import com.pulumi.gcp.vertex.AiEndpointWithModelGardenDeploymentArgs;
import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentState;
import com.pulumi.gcp.vertex.outputs.AiEndpointWithModelGardenDeploymentDeployConfig;
import com.pulumi.gcp.vertex.outputs.AiEndpointWithModelGardenDeploymentEndpointConfig;
import com.pulumi.gcp.vertex.outputs.AiEndpointWithModelGardenDeploymentModelConfig;
import java.lang.String;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * Create an Endpoint and deploy a Model Garden model to it.
 * 
 * To get more information about EndpointWithModelGardenDeployment, see:
 * 
 * * [API documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations/deploy)
 * * How-to Guides
 *     * [Overview of Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)
 *     * [Overview of self-deployed models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/self-deployed-models)
 *     * [Use models in Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/use-models)
 * 
 * ## Example Usage
 * 
 * ### Vertex Ai Deploy Basic
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.vertex.AiEndpointWithModelGardenDeployment;
 * import com.pulumi.gcp.vertex.AiEndpointWithModelGardenDeploymentArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentModelConfigArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App }{{@code
 *     public static void main(String[] args) }{{@code
 *         Pulumi.run(App::stack);
 *     }}{@code
 * 
 *     public static void stack(Context ctx) }{{@code
 *         var deploy = new AiEndpointWithModelGardenDeployment("deploy", AiEndpointWithModelGardenDeploymentArgs.builder()
 *             .publisherModelName("publishers/google/models/paligemma}{@literal @}{@code paligemma-224-float32")
 *             .location("us-central1")
 *             .modelConfig(AiEndpointWithModelGardenDeploymentModelConfigArgs.builder()
 *                 .acceptEula(true)
 *                 .build())
 *             .build());
 * 
 *     }}{@code
 * }}{@code
 * }
 * </pre>
 * ### Vertex Ai Deploy Huggingface Model
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.vertex.AiEndpointWithModelGardenDeployment;
 * import com.pulumi.gcp.vertex.AiEndpointWithModelGardenDeploymentArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentModelConfigArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var deploy = new AiEndpointWithModelGardenDeployment("deploy", AiEndpointWithModelGardenDeploymentArgs.builder()
 *             .huggingFaceModelId("Qwen/Qwen3-0.6B")
 *             .location("us-central1")
 *             .modelConfig(AiEndpointWithModelGardenDeploymentModelConfigArgs.builder()
 *                 .acceptEula(true)
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * ### Vertex Ai Deploy With Configs
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.vertex.AiEndpointWithModelGardenDeployment;
 * import com.pulumi.gcp.vertex.AiEndpointWithModelGardenDeploymentArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentModelConfigArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentDeployConfigArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App }{{@code
 *     public static void main(String[] args) }{{@code
 *         Pulumi.run(App::stack);
 *     }}{@code
 * 
 *     public static void stack(Context ctx) }{{@code
 *         var deploy = new AiEndpointWithModelGardenDeployment("deploy", AiEndpointWithModelGardenDeploymentArgs.builder()
 *             .publisherModelName("publishers/google/models/paligemma}{@literal @}{@code paligemma-224-float32")
 *             .location("us-central1")
 *             .modelConfig(AiEndpointWithModelGardenDeploymentModelConfigArgs.builder()
 *                 .acceptEula(true)
 *                 .build())
 *             .deployConfig(AiEndpointWithModelGardenDeploymentDeployConfigArgs.builder()
 *                 .dedicatedResources(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs.builder()
 *                     .machineSpec(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs.builder()
 *                         .machineType("g2-standard-16")
 *                         .acceleratorType("NVIDIA_L4")
 *                         .acceleratorCount(1)
 *                         .build())
 *                     .minReplicaCount(1)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }}{@code
 * }}{@code
 * }
 * </pre>
 * ### Vertex Ai Deploy Multiple Models In Parallel
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.vertex.AiEndpointWithModelGardenDeployment;
 * import com.pulumi.gcp.vertex.AiEndpointWithModelGardenDeploymentArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentModelConfigArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentDeployConfigArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App }{{@code
 *     public static void main(String[] args) }{{@code
 *         Pulumi.run(App::stack);
 *     }}{@code
 * 
 *     public static void stack(Context ctx) }{{@code
 *         var deploy_gemma_11_2b_it = new AiEndpointWithModelGardenDeployment("deploy-gemma-11-2b-it", AiEndpointWithModelGardenDeploymentArgs.builder()
 *             .publisherModelName("publishers/google/models/gemma}{@literal @}{@code gemma-1.1-2b-it")
 *             .location("us-central1")
 *             .modelConfig(AiEndpointWithModelGardenDeploymentModelConfigArgs.builder()
 *                 .acceptEula(true)
 *                 .build())
 *             .deployConfig(AiEndpointWithModelGardenDeploymentDeployConfigArgs.builder()
 *                 .dedicatedResources(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs.builder()
 *                     .machineSpec(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs.builder()
 *                         .machineType("g2-standard-12")
 *                         .acceleratorType("us-central1")
 *                         .acceleratorCount(1)
 *                         .build())
 *                     .minReplicaCount(1)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *         var deploy_qwen3_06b = new AiEndpointWithModelGardenDeployment("deploy-qwen3-06b", AiEndpointWithModelGardenDeploymentArgs.builder()
 *             .huggingFaceModelId("Qwen/Qwen3-0.6B")
 *             .location("us-central1")
 *             .modelConfig(AiEndpointWithModelGardenDeploymentModelConfigArgs.builder()
 *                 .acceptEula(true)
 *                 .build())
 *             .deployConfig(AiEndpointWithModelGardenDeploymentDeployConfigArgs.builder()
 *                 .dedicatedResources(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs.builder()
 *                     .machineSpec(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs.builder()
 *                         .machineType("g2-standard-12")
 *                         .acceleratorType("NVIDIA_L4")
 *                         .acceleratorCount(1)
 *                         .build())
 *                     .minReplicaCount(1)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *         var deploy_llama_32_1b = new AiEndpointWithModelGardenDeployment("deploy-llama-32-1b", AiEndpointWithModelGardenDeploymentArgs.builder()
 *             .publisherModelName("publishers/meta/models/llama3-2}{@literal @}{@code llama-3.2-1b")
 *             .location("us-central1")
 *             .modelConfig(AiEndpointWithModelGardenDeploymentModelConfigArgs.builder()
 *                 .acceptEula(true)
 *                 .build())
 *             .deployConfig(AiEndpointWithModelGardenDeploymentDeployConfigArgs.builder()
 *                 .dedicatedResources(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs.builder()
 *                     .machineSpec(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs.builder()
 *                         .machineType("g2-standard-12")
 *                         .acceleratorType("NVIDIA_L4")
 *                         .acceleratorCount(1)
 *                         .build())
 *                     .minReplicaCount(1)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }}{@code
 * }}{@code
 * }
 * </pre>
 * ### Vertex Ai Deploy Multiple Models In Sequence
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.vertex.AiEndpointWithModelGardenDeployment;
 * import com.pulumi.gcp.vertex.AiEndpointWithModelGardenDeploymentArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentModelConfigArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentDeployConfigArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs;
 * import com.pulumi.gcp.vertex.inputs.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs;
 * import com.pulumi.resources.CustomResourceOptions;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App }{{@code
 *     public static void main(String[] args) }{{@code
 *         Pulumi.run(App::stack);
 *     }}{@code
 * 
 *     public static void stack(Context ctx) }{{@code
 *         var deploy_gemma_11_2b_it = new AiEndpointWithModelGardenDeployment("deploy-gemma-11-2b-it", AiEndpointWithModelGardenDeploymentArgs.builder()
 *             .publisherModelName("publishers/google/models/gemma}{@literal @}{@code gemma-1.1-2b-it")
 *             .location("us-central1")
 *             .modelConfig(AiEndpointWithModelGardenDeploymentModelConfigArgs.builder()
 *                 .acceptEula(true)
 *                 .build())
 *             .deployConfig(AiEndpointWithModelGardenDeploymentDeployConfigArgs.builder()
 *                 .dedicatedResources(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs.builder()
 *                     .machineSpec(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs.builder()
 *                         .machineType("g2-standard-12")
 *                         .acceleratorType("NVIDIA_L4")
 *                         .acceleratorCount(1)
 *                         .build())
 *                     .minReplicaCount(1)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *         var deploy_qwen3_06b = new AiEndpointWithModelGardenDeployment("deploy-qwen3-06b", AiEndpointWithModelGardenDeploymentArgs.builder()
 *             .huggingFaceModelId("Qwen/Qwen3-0.6B")
 *             .location("us-central1")
 *             .modelConfig(AiEndpointWithModelGardenDeploymentModelConfigArgs.builder()
 *                 .acceptEula(true)
 *                 .build())
 *             .deployConfig(AiEndpointWithModelGardenDeploymentDeployConfigArgs.builder()
 *                 .dedicatedResources(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs.builder()
 *                     .machineSpec(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs.builder()
 *                         .machineType("g2-standard-12")
 *                         .acceleratorType("NVIDIA_L4")
 *                         .acceleratorCount(1)
 *                         .build())
 *                     .minReplicaCount(1)
 *                     .build())
 *                 .build())
 *             .build(), CustomResourceOptions.builder()
 *                 .dependsOn(deploy_gemma_11_2b_it)
 *                 .build());
 * 
 *         var deploy_llama_32_1b = new AiEndpointWithModelGardenDeployment("deploy-llama-32-1b", AiEndpointWithModelGardenDeploymentArgs.builder()
 *             .publisherModelName("publishers/meta/models/llama3-2}{@literal @}{@code llama-3.2-1b")
 *             .location("us-central1")
 *             .modelConfig(AiEndpointWithModelGardenDeploymentModelConfigArgs.builder()
 *                 .acceptEula(true)
 *                 .build())
 *             .deployConfig(AiEndpointWithModelGardenDeploymentDeployConfigArgs.builder()
 *                 .dedicatedResources(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs.builder()
 *                     .machineSpec(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs.builder()
 *                         .machineType("g2-standard-12")
 *                         .acceleratorType("NVIDIA_L4")
 *                         .acceleratorCount(1)
 *                         .build())
 *                     .minReplicaCount(1)
 *                     .build())
 *                 .build())
 *             .build(), CustomResourceOptions.builder()
 *                 .dependsOn(deploy_qwen3_06b)
 *                 .build());
 * 
 *     }}{@code
 * }}{@code
 * }
 * </pre>
 * 
 * ## Import
 * 
 * This resource does not support import.
 * 
 */
@ResourceType(type="gcp:vertex/aiEndpointWithModelGardenDeployment:AiEndpointWithModelGardenDeployment")
public class AiEndpointWithModelGardenDeployment extends com.pulumi.resources.CustomResource {
    /**
     * The deploy config to use for the deployment.
     * Structure is documented below.
     * 
     */
    @Export(name="deployConfig", refs={AiEndpointWithModelGardenDeploymentDeployConfig.class}, tree="[0]")
    private Output</* @Nullable */ AiEndpointWithModelGardenDeploymentDeployConfig> deployConfig;

    /**
     * @return The deploy config to use for the deployment.
     * Structure is documented below.
     * 
     */
    public Output<Optional<AiEndpointWithModelGardenDeploymentDeployConfig>> deployConfig() {
        return Codegen.optional(this.deployConfig);
    }
    /**
     * Output only. The display name assigned to the model deployed to the endpoint.
     * This is not required to delete the resource but is used for debug logging.
     * 
     */
    @Export(name="deployedModelDisplayName", refs={String.class}, tree="[0]")
    private Output<String> deployedModelDisplayName;

    /**
     * @return Output only. The display name assigned to the model deployed to the endpoint.
     * This is not required to delete the resource but is used for debug logging.
     * 
     */
    public Output<String> deployedModelDisplayName() {
        return this.deployedModelDisplayName;
    }
    /**
     * Output only. The unique numeric ID that Vertex AI assigns to the model at the time it is deployed to the endpoint.
     * It is required to undeploy the model from the endpoint during resource deletion as described in
     * https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/undeployModel.
     * 
     */
    @Export(name="deployedModelId", refs={String.class}, tree="[0]")
    private Output<String> deployedModelId;

    /**
     * @return Output only. The unique numeric ID that Vertex AI assigns to the model at the time it is deployed to the endpoint.
     * It is required to undeploy the model from the endpoint during resource deletion as described in
     * https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/undeployModel.
     * 
     */
    public Output<String> deployedModelId() {
        return this.deployedModelId;
    }
    /**
     * Resource ID segment making up resource `endpoint`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
     * 
     */
    @Export(name="endpoint", refs={String.class}, tree="[0]")
    private Output<String> endpoint;

    /**
     * @return Resource ID segment making up resource `endpoint`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
     * 
     */
    public Output<String> endpoint() {
        return this.endpoint;
    }
    /**
     * The endpoint config to use for the deployment.
     * Structure is documented below.
     * 
     */
    @Export(name="endpointConfig", refs={AiEndpointWithModelGardenDeploymentEndpointConfig.class}, tree="[0]")
    private Output</* @Nullable */ AiEndpointWithModelGardenDeploymentEndpointConfig> endpointConfig;

    /**
     * @return The endpoint config to use for the deployment.
     * Structure is documented below.
     * 
     */
    public Output<Optional<AiEndpointWithModelGardenDeploymentEndpointConfig>> endpointConfig() {
        return Codegen.optional(this.endpointConfig);
    }
    /**
     * The Hugging Face model to deploy.
     * Format: Hugging Face model ID like `google/gemma-2-2b-it`.
     * 
     */
    @Export(name="huggingFaceModelId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> huggingFaceModelId;

    /**
     * @return The Hugging Face model to deploy.
     * Format: Hugging Face model ID like `google/gemma-2-2b-it`.
     * 
     */
    public Output<Optional<String>> huggingFaceModelId() {
        return Codegen.optional(this.huggingFaceModelId);
    }
    /**
     * Resource ID segment making up resource `location`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
     * 
     */
    @Export(name="location", refs={String.class}, tree="[0]")
    private Output<String> location;

    /**
     * @return Resource ID segment making up resource `location`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
     * 
     */
    public Output<String> location() {
        return this.location;
    }
    /**
     * The model config to use for the deployment.
     * Structure is documented below.
     * 
     */
    @Export(name="modelConfig", refs={AiEndpointWithModelGardenDeploymentModelConfig.class}, tree="[0]")
    private Output</* @Nullable */ AiEndpointWithModelGardenDeploymentModelConfig> modelConfig;

    /**
     * @return The model config to use for the deployment.
     * Structure is documented below.
     * 
     */
    public Output<Optional<AiEndpointWithModelGardenDeploymentModelConfig>> modelConfig() {
        return Codegen.optional(this.modelConfig);
    }
    /**
     * The ID of the project in which the resource belongs.
     * If it is not provided, the provider project is used.
     * 
     */
    @Export(name="project", refs={String.class}, tree="[0]")
    private Output<String> project;

    /**
     * @return The ID of the project in which the resource belongs.
     * If it is not provided, the provider project is used.
     * 
     */
    public Output<String> project() {
        return this.project;
    }
    /**
     * The Model Garden model to deploy.
     * Format:
     * `publishers/{publisher}/models/{publisher_model}{@literal @}{version_id}`, or
     * `publishers/hf-{hugging-face-author}/models/{hugging-face-model-name}{@literal @}001`.
     * 
     */
    @Export(name="publisherModelName", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> publisherModelName;

    /**
     * @return The Model Garden model to deploy.
     * Format:
     * `publishers/{publisher}/models/{publisher_model}{@literal @}{version_id}`, or
     * `publishers/hf-{hugging-face-author}/models/{hugging-face-model-name}{@literal @}001`.
     * 
     */
    public Output<Optional<String>> publisherModelName() {
        return Codegen.optional(this.publisherModelName);
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public AiEndpointWithModelGardenDeployment(java.lang.String name) {
        this(name, AiEndpointWithModelGardenDeploymentArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public AiEndpointWithModelGardenDeployment(java.lang.String name, AiEndpointWithModelGardenDeploymentArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public AiEndpointWithModelGardenDeployment(java.lang.String name, AiEndpointWithModelGardenDeploymentArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:vertex/aiEndpointWithModelGardenDeployment:AiEndpointWithModelGardenDeployment", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private AiEndpointWithModelGardenDeployment(java.lang.String name, Output<java.lang.String> id, @Nullable AiEndpointWithModelGardenDeploymentState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:vertex/aiEndpointWithModelGardenDeployment:AiEndpointWithModelGardenDeployment", name, state, makeResourceOptions(options, id), false);
    }

    private static AiEndpointWithModelGardenDeploymentArgs makeArgs(AiEndpointWithModelGardenDeploymentArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? AiEndpointWithModelGardenDeploymentArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static AiEndpointWithModelGardenDeployment get(java.lang.String name, Output<java.lang.String> id, @Nullable AiEndpointWithModelGardenDeploymentState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new AiEndpointWithModelGardenDeployment(name, id, state, options);
    }
}
