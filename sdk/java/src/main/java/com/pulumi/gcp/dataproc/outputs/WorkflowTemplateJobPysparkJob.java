// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.dataproc.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import com.pulumi.gcp.dataproc.outputs.WorkflowTemplateJobPysparkJobLoggingConfig;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class WorkflowTemplateJobPysparkJob {
    /**
     * @return HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
     * 
     */
    private @Nullable List<String> archiveUris;
    /**
     * @return The arguments to pass to the driver. Do not include arguments, such as `--conf`, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
     * 
     */
    private @Nullable List<String> args;
    /**
     * @return HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
     * 
     */
    private @Nullable List<String> fileUris;
    /**
     * @return HCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks.
     * 
     */
    private @Nullable List<String> jarFileUris;
    /**
     * @return The runtime log config for job execution.
     * 
     */
    private @Nullable WorkflowTemplateJobPysparkJobLoggingConfig loggingConfig;
    /**
     * @return Required. The HCFS URI of the main Python file to use as the driver. Must be a .py file.
     * 
     */
    private String mainPythonFileUri;
    /**
     * @return A mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
     * 
     */
    private @Nullable Map<String,String> properties;
    /**
     * @return HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
     * 
     */
    private @Nullable List<String> pythonFileUris;

    private WorkflowTemplateJobPysparkJob() {}
    /**
     * @return HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
     * 
     */
    public List<String> archiveUris() {
        return this.archiveUris == null ? List.of() : this.archiveUris;
    }
    /**
     * @return The arguments to pass to the driver. Do not include arguments, such as `--conf`, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
     * 
     */
    public List<String> args() {
        return this.args == null ? List.of() : this.args;
    }
    /**
     * @return HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
     * 
     */
    public List<String> fileUris() {
        return this.fileUris == null ? List.of() : this.fileUris;
    }
    /**
     * @return HCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks.
     * 
     */
    public List<String> jarFileUris() {
        return this.jarFileUris == null ? List.of() : this.jarFileUris;
    }
    /**
     * @return The runtime log config for job execution.
     * 
     */
    public Optional<WorkflowTemplateJobPysparkJobLoggingConfig> loggingConfig() {
        return Optional.ofNullable(this.loggingConfig);
    }
    /**
     * @return Required. The HCFS URI of the main Python file to use as the driver. Must be a .py file.
     * 
     */
    public String mainPythonFileUri() {
        return this.mainPythonFileUri;
    }
    /**
     * @return A mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
     * 
     */
    public Map<String,String> properties() {
        return this.properties == null ? Map.of() : this.properties;
    }
    /**
     * @return HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
     * 
     */
    public List<String> pythonFileUris() {
        return this.pythonFileUris == null ? List.of() : this.pythonFileUris;
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(WorkflowTemplateJobPysparkJob defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable List<String> archiveUris;
        private @Nullable List<String> args;
        private @Nullable List<String> fileUris;
        private @Nullable List<String> jarFileUris;
        private @Nullable WorkflowTemplateJobPysparkJobLoggingConfig loggingConfig;
        private String mainPythonFileUri;
        private @Nullable Map<String,String> properties;
        private @Nullable List<String> pythonFileUris;
        public Builder() {}
        public Builder(WorkflowTemplateJobPysparkJob defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.archiveUris = defaults.archiveUris;
    	      this.args = defaults.args;
    	      this.fileUris = defaults.fileUris;
    	      this.jarFileUris = defaults.jarFileUris;
    	      this.loggingConfig = defaults.loggingConfig;
    	      this.mainPythonFileUri = defaults.mainPythonFileUri;
    	      this.properties = defaults.properties;
    	      this.pythonFileUris = defaults.pythonFileUris;
        }

        @CustomType.Setter
        public Builder archiveUris(@Nullable List<String> archiveUris) {

            this.archiveUris = archiveUris;
            return this;
        }
        public Builder archiveUris(String... archiveUris) {
            return archiveUris(List.of(archiveUris));
        }
        @CustomType.Setter
        public Builder args(@Nullable List<String> args) {

            this.args = args;
            return this;
        }
        public Builder args(String... args) {
            return args(List.of(args));
        }
        @CustomType.Setter
        public Builder fileUris(@Nullable List<String> fileUris) {

            this.fileUris = fileUris;
            return this;
        }
        public Builder fileUris(String... fileUris) {
            return fileUris(List.of(fileUris));
        }
        @CustomType.Setter
        public Builder jarFileUris(@Nullable List<String> jarFileUris) {

            this.jarFileUris = jarFileUris;
            return this;
        }
        public Builder jarFileUris(String... jarFileUris) {
            return jarFileUris(List.of(jarFileUris));
        }
        @CustomType.Setter
        public Builder loggingConfig(@Nullable WorkflowTemplateJobPysparkJobLoggingConfig loggingConfig) {

            this.loggingConfig = loggingConfig;
            return this;
        }
        @CustomType.Setter
        public Builder mainPythonFileUri(String mainPythonFileUri) {
            if (mainPythonFileUri == null) {
              throw new MissingRequiredPropertyException("WorkflowTemplateJobPysparkJob", "mainPythonFileUri");
            }
            this.mainPythonFileUri = mainPythonFileUri;
            return this;
        }
        @CustomType.Setter
        public Builder properties(@Nullable Map<String,String> properties) {

            this.properties = properties;
            return this;
        }
        @CustomType.Setter
        public Builder pythonFileUris(@Nullable List<String> pythonFileUris) {

            this.pythonFileUris = pythonFileUris;
            return this;
        }
        public Builder pythonFileUris(String... pythonFileUris) {
            return pythonFileUris(List.of(pythonFileUris));
        }
        public WorkflowTemplateJobPysparkJob build() {
            final var _resultValue = new WorkflowTemplateJobPysparkJob();
            _resultValue.archiveUris = archiveUris;
            _resultValue.args = args;
            _resultValue.fileUris = fileUris;
            _resultValue.jarFileUris = jarFileUris;
            _resultValue.loggingConfig = loggingConfig;
            _resultValue.mainPythonFileUri = mainPythonFileUri;
            _resultValue.properties = properties;
            _resultValue.pythonFileUris = pythonFileUris;
            return _resultValue;
        }
    }
}
