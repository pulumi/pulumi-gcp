// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.bigquery.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import com.pulumi.gcp.bigquery.inputs.TableExternalDataConfigurationAvroOptionsArgs;
import com.pulumi.gcp.bigquery.inputs.TableExternalDataConfigurationBigtableOptionsArgs;
import com.pulumi.gcp.bigquery.inputs.TableExternalDataConfigurationCsvOptionsArgs;
import com.pulumi.gcp.bigquery.inputs.TableExternalDataConfigurationGoogleSheetsOptionsArgs;
import com.pulumi.gcp.bigquery.inputs.TableExternalDataConfigurationHivePartitioningOptionsArgs;
import com.pulumi.gcp.bigquery.inputs.TableExternalDataConfigurationJsonOptionsArgs;
import com.pulumi.gcp.bigquery.inputs.TableExternalDataConfigurationParquetOptionsArgs;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class TableExternalDataConfigurationArgs extends com.pulumi.resources.ResourceArgs {

    public static final TableExternalDataConfigurationArgs Empty = new TableExternalDataConfigurationArgs();

    /**
     * Let BigQuery try to autodetect the schema
     * and format of the table.
     * 
     */
    @Import(name="autodetect", required=true)
    private Output<Boolean> autodetect;

    /**
     * @return Let BigQuery try to autodetect the schema
     * and format of the table.
     * 
     */
    public Output<Boolean> autodetect() {
        return this.autodetect;
    }

    /**
     * Additional options if `sourceFormat` is set to
     * &#34;AVRO&#34;.  Structure is documented below.
     * 
     */
    @Import(name="avroOptions")
    private @Nullable Output<TableExternalDataConfigurationAvroOptionsArgs> avroOptions;

    /**
     * @return Additional options if `sourceFormat` is set to
     * &#34;AVRO&#34;.  Structure is documented below.
     * 
     */
    public Optional<Output<TableExternalDataConfigurationAvroOptionsArgs>> avroOptions() {
        return Optional.ofNullable(this.avroOptions);
    }

    /**
     * Additional properties to set if
     * `sourceFormat` is set to &#34;BIGTABLE&#34;. Structure is documented below.
     * 
     */
    @Import(name="bigtableOptions")
    private @Nullable Output<TableExternalDataConfigurationBigtableOptionsArgs> bigtableOptions;

    /**
     * @return Additional properties to set if
     * `sourceFormat` is set to &#34;BIGTABLE&#34;. Structure is documented below.
     * 
     */
    public Optional<Output<TableExternalDataConfigurationBigtableOptionsArgs>> bigtableOptions() {
        return Optional.ofNullable(this.bigtableOptions);
    }

    /**
     * The compression type of the data source.
     * Valid values are &#34;NONE&#34; or &#34;GZIP&#34;.
     * 
     */
    @Import(name="compression")
    private @Nullable Output<String> compression;

    /**
     * @return The compression type of the data source.
     * Valid values are &#34;NONE&#34; or &#34;GZIP&#34;.
     * 
     */
    public Optional<Output<String>> compression() {
        return Optional.ofNullable(this.compression);
    }

    /**
     * The connection specifying the credentials to be used to read
     * external storage, such as Azure Blob, Cloud Storage, or S3. The `connectionId` can have
     * the form `{{project}}.{{location}}.{{connection_id}}`
     * or `projects/{{project}}/locations/{{location}}/connections/{{connection_id}}`.
     * 
     * ~&gt;**NOTE:** If you set `external_data_configuration.connection_id`, the
     * table schema must be specified using the top-level `schema` field
     * documented above.
     * 
     */
    @Import(name="connectionId")
    private @Nullable Output<String> connectionId;

    /**
     * @return The connection specifying the credentials to be used to read
     * external storage, such as Azure Blob, Cloud Storage, or S3. The `connectionId` can have
     * the form `{{project}}.{{location}}.{{connection_id}}`
     * or `projects/{{project}}/locations/{{location}}/connections/{{connection_id}}`.
     * 
     * ~&gt;**NOTE:** If you set `external_data_configuration.connection_id`, the
     * table schema must be specified using the top-level `schema` field
     * documented above.
     * 
     */
    public Optional<Output<String>> connectionId() {
        return Optional.ofNullable(this.connectionId);
    }

    /**
     * Additional properties to set if
     * `sourceFormat` is set to &#34;CSV&#34;. Structure is documented below.
     * 
     */
    @Import(name="csvOptions")
    private @Nullable Output<TableExternalDataConfigurationCsvOptionsArgs> csvOptions;

    /**
     * @return Additional properties to set if
     * `sourceFormat` is set to &#34;CSV&#34;. Structure is documented below.
     * 
     */
    public Optional<Output<TableExternalDataConfigurationCsvOptionsArgs>> csvOptions() {
        return Optional.ofNullable(this.csvOptions);
    }

    /**
     * Defines the list of possible SQL data types to which the source decimal values are converted. This list and the precision and the scale parameters of the decimal field determine the target type. In the order of NUMERIC, BIGNUMERIC, and STRING, a type is picked if it is in the specified list and if it supports the precision and the scale. STRING supports all precision and scale values. If none of the listed types supports the precision and the scale, the type supporting the widest range in the specified list is picked, and if a value exceeds the supported range when reading the data, an error will be thrown.
     * 
     * Example: Suppose the value of this field is [&#34;NUMERIC&#34;, &#34;BIGNUMERIC&#34;]. If (precision,scale) is:
     * 
     * (38,9) &gt; NUMERIC;
     * (39,9) &gt; BIGNUMERIC (NUMERIC cannot hold 30 integer digits);
     * (38,10) &gt; BIGNUMERIC (NUMERIC cannot hold 10 fractional digits);
     * (76,38) &gt; BIGNUMERIC;
     * (77,38) &gt; BIGNUMERIC (error if value exceeds supported range).
     * 
     * This field cannot contain duplicate types. The order of the types in this field is ignored. For example, [&#34;BIGNUMERIC&#34;, &#34;NUMERIC&#34;] is the same as [&#34;NUMERIC&#34;, &#34;BIGNUMERIC&#34;] and NUMERIC always takes precedence over BIGNUMERIC.
     * 
     * Defaults to [&#34;NUMERIC&#34;, &#34;STRING&#34;] for ORC and [&#34;NUMERIC&#34;] for the other file formats.
     * 
     */
    @Import(name="decimalTargetTypes")
    private @Nullable Output<List<String>> decimalTargetTypes;

    /**
     * @return Defines the list of possible SQL data types to which the source decimal values are converted. This list and the precision and the scale parameters of the decimal field determine the target type. In the order of NUMERIC, BIGNUMERIC, and STRING, a type is picked if it is in the specified list and if it supports the precision and the scale. STRING supports all precision and scale values. If none of the listed types supports the precision and the scale, the type supporting the widest range in the specified list is picked, and if a value exceeds the supported range when reading the data, an error will be thrown.
     * 
     * Example: Suppose the value of this field is [&#34;NUMERIC&#34;, &#34;BIGNUMERIC&#34;]. If (precision,scale) is:
     * 
     * (38,9) &gt; NUMERIC;
     * (39,9) &gt; BIGNUMERIC (NUMERIC cannot hold 30 integer digits);
     * (38,10) &gt; BIGNUMERIC (NUMERIC cannot hold 10 fractional digits);
     * (76,38) &gt; BIGNUMERIC;
     * (77,38) &gt; BIGNUMERIC (error if value exceeds supported range).
     * 
     * This field cannot contain duplicate types. The order of the types in this field is ignored. For example, [&#34;BIGNUMERIC&#34;, &#34;NUMERIC&#34;] is the same as [&#34;NUMERIC&#34;, &#34;BIGNUMERIC&#34;] and NUMERIC always takes precedence over BIGNUMERIC.
     * 
     * Defaults to [&#34;NUMERIC&#34;, &#34;STRING&#34;] for ORC and [&#34;NUMERIC&#34;] for the other file formats.
     * 
     */
    public Optional<Output<List<String>>> decimalTargetTypes() {
        return Optional.ofNullable(this.decimalTargetTypes);
    }

    /**
     * Specifies how source URIs are interpreted for constructing the file set to load.
     * By default source URIs are expanded against the underlying storage.
     * Other options include specifying manifest files. Only applicable to object storage systems. Docs
     * 
     */
    @Import(name="fileSetSpecType")
    private @Nullable Output<String> fileSetSpecType;

    /**
     * @return Specifies how source URIs are interpreted for constructing the file set to load.
     * By default source URIs are expanded against the underlying storage.
     * Other options include specifying manifest files. Only applicable to object storage systems. Docs
     * 
     */
    public Optional<Output<String>> fileSetSpecType() {
        return Optional.ofNullable(this.fileSetSpecType);
    }

    /**
     * Additional options if
     * `sourceFormat` is set to &#34;GOOGLE_SHEETS&#34;. Structure is
     * documented below.
     * 
     */
    @Import(name="googleSheetsOptions")
    private @Nullable Output<TableExternalDataConfigurationGoogleSheetsOptionsArgs> googleSheetsOptions;

    /**
     * @return Additional options if
     * `sourceFormat` is set to &#34;GOOGLE_SHEETS&#34;. Structure is
     * documented below.
     * 
     */
    public Optional<Output<TableExternalDataConfigurationGoogleSheetsOptionsArgs>> googleSheetsOptions() {
        return Optional.ofNullable(this.googleSheetsOptions);
    }

    /**
     * When set, configures hive partitioning
     * support. Not all storage formats support hive partitioning -- requesting hive
     * partitioning on an unsupported format will lead to an error, as will providing
     * an invalid specification. Structure is documented below.
     * 
     */
    @Import(name="hivePartitioningOptions")
    private @Nullable Output<TableExternalDataConfigurationHivePartitioningOptionsArgs> hivePartitioningOptions;

    /**
     * @return When set, configures hive partitioning
     * support. Not all storage formats support hive partitioning -- requesting hive
     * partitioning on an unsupported format will lead to an error, as will providing
     * an invalid specification. Structure is documented below.
     * 
     */
    public Optional<Output<TableExternalDataConfigurationHivePartitioningOptionsArgs>> hivePartitioningOptions() {
        return Optional.ofNullable(this.hivePartitioningOptions);
    }

    /**
     * Indicates if BigQuery should
     * allow extra values that are not represented in the table schema.
     * If true, the extra values are ignored. If false, records with
     * extra columns are treated as bad records, and if there are too
     * many bad records, an invalid error is returned in the job result.
     * The default value is false.
     * 
     */
    @Import(name="ignoreUnknownValues")
    private @Nullable Output<Boolean> ignoreUnknownValues;

    /**
     * @return Indicates if BigQuery should
     * allow extra values that are not represented in the table schema.
     * If true, the extra values are ignored. If false, records with
     * extra columns are treated as bad records, and if there are too
     * many bad records, an invalid error is returned in the job result.
     * The default value is false.
     * 
     */
    public Optional<Output<Boolean>> ignoreUnknownValues() {
        return Optional.ofNullable(this.ignoreUnknownValues);
    }

    /**
     * Used to indicate that a JSON variant, rather than normal JSON, is being used as the sourceFormat. This should only be used in combination with the `JSON` source format. Valid values are: `GEOJSON`.
     * 
     */
    @Import(name="jsonExtension")
    private @Nullable Output<String> jsonExtension;

    /**
     * @return Used to indicate that a JSON variant, rather than normal JSON, is being used as the sourceFormat. This should only be used in combination with the `JSON` source format. Valid values are: `GEOJSON`.
     * 
     */
    public Optional<Output<String>> jsonExtension() {
        return Optional.ofNullable(this.jsonExtension);
    }

    /**
     * Additional properties to set if
     * `sourceFormat` is set to &#34;JSON&#34;. Structure is documented below.
     * 
     */
    @Import(name="jsonOptions")
    private @Nullable Output<TableExternalDataConfigurationJsonOptionsArgs> jsonOptions;

    /**
     * @return Additional properties to set if
     * `sourceFormat` is set to &#34;JSON&#34;. Structure is documented below.
     * 
     */
    public Optional<Output<TableExternalDataConfigurationJsonOptionsArgs>> jsonOptions() {
        return Optional.ofNullable(this.jsonOptions);
    }

    /**
     * The maximum number of bad records that
     * BigQuery can ignore when reading data.
     * 
     */
    @Import(name="maxBadRecords")
    private @Nullable Output<Integer> maxBadRecords;

    /**
     * @return The maximum number of bad records that
     * BigQuery can ignore when reading data.
     * 
     */
    public Optional<Output<Integer>> maxBadRecords() {
        return Optional.ofNullable(this.maxBadRecords);
    }

    /**
     * Metadata Cache Mode for the table. Set this to enable caching of metadata from external data source. Valid values are `AUTOMATIC` and `MANUAL`.
     * 
     */
    @Import(name="metadataCacheMode")
    private @Nullable Output<String> metadataCacheMode;

    /**
     * @return Metadata Cache Mode for the table. Set this to enable caching of metadata from external data source. Valid values are `AUTOMATIC` and `MANUAL`.
     * 
     */
    public Optional<Output<String>> metadataCacheMode() {
        return Optional.ofNullable(this.metadataCacheMode);
    }

    /**
     * Object Metadata is used to create Object Tables. Object Tables contain a listing of objects (with their metadata) found at the sourceUris. If `objectMetadata` is set, `sourceFormat` should be omitted.
     * 
     */
    @Import(name="objectMetadata")
    private @Nullable Output<String> objectMetadata;

    /**
     * @return Object Metadata is used to create Object Tables. Object Tables contain a listing of objects (with their metadata) found at the sourceUris. If `objectMetadata` is set, `sourceFormat` should be omitted.
     * 
     */
    public Optional<Output<String>> objectMetadata() {
        return Optional.ofNullable(this.objectMetadata);
    }

    /**
     * Additional properties to set if
     * `sourceFormat` is set to &#34;PARQUET&#34;. Structure is documented below.
     * 
     */
    @Import(name="parquetOptions")
    private @Nullable Output<TableExternalDataConfigurationParquetOptionsArgs> parquetOptions;

    /**
     * @return Additional properties to set if
     * `sourceFormat` is set to &#34;PARQUET&#34;. Structure is documented below.
     * 
     */
    public Optional<Output<TableExternalDataConfigurationParquetOptionsArgs>> parquetOptions() {
        return Optional.ofNullable(this.parquetOptions);
    }

    /**
     * When creating an external table, the user can provide a reference file with the table schema. This is enabled for the following formats: AVRO, PARQUET, ORC.
     * 
     */
    @Import(name="referenceFileSchemaUri")
    private @Nullable Output<String> referenceFileSchemaUri;

    /**
     * @return When creating an external table, the user can provide a reference file with the table schema. This is enabled for the following formats: AVRO, PARQUET, ORC.
     * 
     */
    public Optional<Output<String>> referenceFileSchemaUri() {
        return Optional.ofNullable(this.referenceFileSchemaUri);
    }

    /**
     * A JSON schema for the external table. Schema is required
     * for CSV and JSON formats if autodetect is not on. Schema is disallowed
     * for Google Cloud Bigtable, Cloud Datastore backups, Avro, Iceberg, ORC and Parquet formats.
     * ~&gt;**NOTE:** Because this field expects a JSON string, any changes to the
     * string will create a diff, even if the JSON itself hasn&#39;t changed.
     * Furthermore drift for this field cannot not be detected because BigQuery
     * only uses this schema to compute the effective schema for the table, therefore
     * any changes on the configured value will force the table to be recreated.
     * This schema is effectively only applied when creating a table from an external
     * datasource, after creation the computed schema will be stored in
     * `google_bigquery_table.schema`
     * 
     * ~&gt;**NOTE:** If you set `external_data_configuration.connection_id`, the
     * table schema must be specified using the top-level `schema` field
     * documented above.
     * 
     */
    @Import(name="schema")
    private @Nullable Output<String> schema;

    /**
     * @return A JSON schema for the external table. Schema is required
     * for CSV and JSON formats if autodetect is not on. Schema is disallowed
     * for Google Cloud Bigtable, Cloud Datastore backups, Avro, Iceberg, ORC and Parquet formats.
     * ~&gt;**NOTE:** Because this field expects a JSON string, any changes to the
     * string will create a diff, even if the JSON itself hasn&#39;t changed.
     * Furthermore drift for this field cannot not be detected because BigQuery
     * only uses this schema to compute the effective schema for the table, therefore
     * any changes on the configured value will force the table to be recreated.
     * This schema is effectively only applied when creating a table from an external
     * datasource, after creation the computed schema will be stored in
     * `google_bigquery_table.schema`
     * 
     * ~&gt;**NOTE:** If you set `external_data_configuration.connection_id`, the
     * table schema must be specified using the top-level `schema` field
     * documented above.
     * 
     */
    public Optional<Output<String>> schema() {
        return Optional.ofNullable(this.schema);
    }

    /**
     * The data format. Please see sourceFormat under
     * [ExternalDataConfiguration](https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#externaldataconfiguration)
     * in Bigquery&#39;s public API documentation for supported formats. To use &#34;GOOGLE_SHEETS&#34;
     * the `scopes` must include &#34;https://www.googleapis.com/auth/drive.readonly&#34;.
     * 
     */
    @Import(name="sourceFormat")
    private @Nullable Output<String> sourceFormat;

    /**
     * @return The data format. Please see sourceFormat under
     * [ExternalDataConfiguration](https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#externaldataconfiguration)
     * in Bigquery&#39;s public API documentation for supported formats. To use &#34;GOOGLE_SHEETS&#34;
     * the `scopes` must include &#34;https://www.googleapis.com/auth/drive.readonly&#34;.
     * 
     */
    public Optional<Output<String>> sourceFormat() {
        return Optional.ofNullable(this.sourceFormat);
    }

    /**
     * A list of the fully-qualified URIs that point to
     * your data in Google Cloud.
     * 
     */
    @Import(name="sourceUris", required=true)
    private Output<List<String>> sourceUris;

    /**
     * @return A list of the fully-qualified URIs that point to
     * your data in Google Cloud.
     * 
     */
    public Output<List<String>> sourceUris() {
        return this.sourceUris;
    }

    private TableExternalDataConfigurationArgs() {}

    private TableExternalDataConfigurationArgs(TableExternalDataConfigurationArgs $) {
        this.autodetect = $.autodetect;
        this.avroOptions = $.avroOptions;
        this.bigtableOptions = $.bigtableOptions;
        this.compression = $.compression;
        this.connectionId = $.connectionId;
        this.csvOptions = $.csvOptions;
        this.decimalTargetTypes = $.decimalTargetTypes;
        this.fileSetSpecType = $.fileSetSpecType;
        this.googleSheetsOptions = $.googleSheetsOptions;
        this.hivePartitioningOptions = $.hivePartitioningOptions;
        this.ignoreUnknownValues = $.ignoreUnknownValues;
        this.jsonExtension = $.jsonExtension;
        this.jsonOptions = $.jsonOptions;
        this.maxBadRecords = $.maxBadRecords;
        this.metadataCacheMode = $.metadataCacheMode;
        this.objectMetadata = $.objectMetadata;
        this.parquetOptions = $.parquetOptions;
        this.referenceFileSchemaUri = $.referenceFileSchemaUri;
        this.schema = $.schema;
        this.sourceFormat = $.sourceFormat;
        this.sourceUris = $.sourceUris;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(TableExternalDataConfigurationArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private TableExternalDataConfigurationArgs $;

        public Builder() {
            $ = new TableExternalDataConfigurationArgs();
        }

        public Builder(TableExternalDataConfigurationArgs defaults) {
            $ = new TableExternalDataConfigurationArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param autodetect Let BigQuery try to autodetect the schema
         * and format of the table.
         * 
         * @return builder
         * 
         */
        public Builder autodetect(Output<Boolean> autodetect) {
            $.autodetect = autodetect;
            return this;
        }

        /**
         * @param autodetect Let BigQuery try to autodetect the schema
         * and format of the table.
         * 
         * @return builder
         * 
         */
        public Builder autodetect(Boolean autodetect) {
            return autodetect(Output.of(autodetect));
        }

        /**
         * @param avroOptions Additional options if `sourceFormat` is set to
         * &#34;AVRO&#34;.  Structure is documented below.
         * 
         * @return builder
         * 
         */
        public Builder avroOptions(@Nullable Output<TableExternalDataConfigurationAvroOptionsArgs> avroOptions) {
            $.avroOptions = avroOptions;
            return this;
        }

        /**
         * @param avroOptions Additional options if `sourceFormat` is set to
         * &#34;AVRO&#34;.  Structure is documented below.
         * 
         * @return builder
         * 
         */
        public Builder avroOptions(TableExternalDataConfigurationAvroOptionsArgs avroOptions) {
            return avroOptions(Output.of(avroOptions));
        }

        /**
         * @param bigtableOptions Additional properties to set if
         * `sourceFormat` is set to &#34;BIGTABLE&#34;. Structure is documented below.
         * 
         * @return builder
         * 
         */
        public Builder bigtableOptions(@Nullable Output<TableExternalDataConfigurationBigtableOptionsArgs> bigtableOptions) {
            $.bigtableOptions = bigtableOptions;
            return this;
        }

        /**
         * @param bigtableOptions Additional properties to set if
         * `sourceFormat` is set to &#34;BIGTABLE&#34;. Structure is documented below.
         * 
         * @return builder
         * 
         */
        public Builder bigtableOptions(TableExternalDataConfigurationBigtableOptionsArgs bigtableOptions) {
            return bigtableOptions(Output.of(bigtableOptions));
        }

        /**
         * @param compression The compression type of the data source.
         * Valid values are &#34;NONE&#34; or &#34;GZIP&#34;.
         * 
         * @return builder
         * 
         */
        public Builder compression(@Nullable Output<String> compression) {
            $.compression = compression;
            return this;
        }

        /**
         * @param compression The compression type of the data source.
         * Valid values are &#34;NONE&#34; or &#34;GZIP&#34;.
         * 
         * @return builder
         * 
         */
        public Builder compression(String compression) {
            return compression(Output.of(compression));
        }

        /**
         * @param connectionId The connection specifying the credentials to be used to read
         * external storage, such as Azure Blob, Cloud Storage, or S3. The `connectionId` can have
         * the form `{{project}}.{{location}}.{{connection_id}}`
         * or `projects/{{project}}/locations/{{location}}/connections/{{connection_id}}`.
         * 
         * ~&gt;**NOTE:** If you set `external_data_configuration.connection_id`, the
         * table schema must be specified using the top-level `schema` field
         * documented above.
         * 
         * @return builder
         * 
         */
        public Builder connectionId(@Nullable Output<String> connectionId) {
            $.connectionId = connectionId;
            return this;
        }

        /**
         * @param connectionId The connection specifying the credentials to be used to read
         * external storage, such as Azure Blob, Cloud Storage, or S3. The `connectionId` can have
         * the form `{{project}}.{{location}}.{{connection_id}}`
         * or `projects/{{project}}/locations/{{location}}/connections/{{connection_id}}`.
         * 
         * ~&gt;**NOTE:** If you set `external_data_configuration.connection_id`, the
         * table schema must be specified using the top-level `schema` field
         * documented above.
         * 
         * @return builder
         * 
         */
        public Builder connectionId(String connectionId) {
            return connectionId(Output.of(connectionId));
        }

        /**
         * @param csvOptions Additional properties to set if
         * `sourceFormat` is set to &#34;CSV&#34;. Structure is documented below.
         * 
         * @return builder
         * 
         */
        public Builder csvOptions(@Nullable Output<TableExternalDataConfigurationCsvOptionsArgs> csvOptions) {
            $.csvOptions = csvOptions;
            return this;
        }

        /**
         * @param csvOptions Additional properties to set if
         * `sourceFormat` is set to &#34;CSV&#34;. Structure is documented below.
         * 
         * @return builder
         * 
         */
        public Builder csvOptions(TableExternalDataConfigurationCsvOptionsArgs csvOptions) {
            return csvOptions(Output.of(csvOptions));
        }

        /**
         * @param decimalTargetTypes Defines the list of possible SQL data types to which the source decimal values are converted. This list and the precision and the scale parameters of the decimal field determine the target type. In the order of NUMERIC, BIGNUMERIC, and STRING, a type is picked if it is in the specified list and if it supports the precision and the scale. STRING supports all precision and scale values. If none of the listed types supports the precision and the scale, the type supporting the widest range in the specified list is picked, and if a value exceeds the supported range when reading the data, an error will be thrown.
         * 
         * Example: Suppose the value of this field is [&#34;NUMERIC&#34;, &#34;BIGNUMERIC&#34;]. If (precision,scale) is:
         * 
         * (38,9) &gt; NUMERIC;
         * (39,9) &gt; BIGNUMERIC (NUMERIC cannot hold 30 integer digits);
         * (38,10) &gt; BIGNUMERIC (NUMERIC cannot hold 10 fractional digits);
         * (76,38) &gt; BIGNUMERIC;
         * (77,38) &gt; BIGNUMERIC (error if value exceeds supported range).
         * 
         * This field cannot contain duplicate types. The order of the types in this field is ignored. For example, [&#34;BIGNUMERIC&#34;, &#34;NUMERIC&#34;] is the same as [&#34;NUMERIC&#34;, &#34;BIGNUMERIC&#34;] and NUMERIC always takes precedence over BIGNUMERIC.
         * 
         * Defaults to [&#34;NUMERIC&#34;, &#34;STRING&#34;] for ORC and [&#34;NUMERIC&#34;] for the other file formats.
         * 
         * @return builder
         * 
         */
        public Builder decimalTargetTypes(@Nullable Output<List<String>> decimalTargetTypes) {
            $.decimalTargetTypes = decimalTargetTypes;
            return this;
        }

        /**
         * @param decimalTargetTypes Defines the list of possible SQL data types to which the source decimal values are converted. This list and the precision and the scale parameters of the decimal field determine the target type. In the order of NUMERIC, BIGNUMERIC, and STRING, a type is picked if it is in the specified list and if it supports the precision and the scale. STRING supports all precision and scale values. If none of the listed types supports the precision and the scale, the type supporting the widest range in the specified list is picked, and if a value exceeds the supported range when reading the data, an error will be thrown.
         * 
         * Example: Suppose the value of this field is [&#34;NUMERIC&#34;, &#34;BIGNUMERIC&#34;]. If (precision,scale) is:
         * 
         * (38,9) &gt; NUMERIC;
         * (39,9) &gt; BIGNUMERIC (NUMERIC cannot hold 30 integer digits);
         * (38,10) &gt; BIGNUMERIC (NUMERIC cannot hold 10 fractional digits);
         * (76,38) &gt; BIGNUMERIC;
         * (77,38) &gt; BIGNUMERIC (error if value exceeds supported range).
         * 
         * This field cannot contain duplicate types. The order of the types in this field is ignored. For example, [&#34;BIGNUMERIC&#34;, &#34;NUMERIC&#34;] is the same as [&#34;NUMERIC&#34;, &#34;BIGNUMERIC&#34;] and NUMERIC always takes precedence over BIGNUMERIC.
         * 
         * Defaults to [&#34;NUMERIC&#34;, &#34;STRING&#34;] for ORC and [&#34;NUMERIC&#34;] for the other file formats.
         * 
         * @return builder
         * 
         */
        public Builder decimalTargetTypes(List<String> decimalTargetTypes) {
            return decimalTargetTypes(Output.of(decimalTargetTypes));
        }

        /**
         * @param decimalTargetTypes Defines the list of possible SQL data types to which the source decimal values are converted. This list and the precision and the scale parameters of the decimal field determine the target type. In the order of NUMERIC, BIGNUMERIC, and STRING, a type is picked if it is in the specified list and if it supports the precision and the scale. STRING supports all precision and scale values. If none of the listed types supports the precision and the scale, the type supporting the widest range in the specified list is picked, and if a value exceeds the supported range when reading the data, an error will be thrown.
         * 
         * Example: Suppose the value of this field is [&#34;NUMERIC&#34;, &#34;BIGNUMERIC&#34;]. If (precision,scale) is:
         * 
         * (38,9) &gt; NUMERIC;
         * (39,9) &gt; BIGNUMERIC (NUMERIC cannot hold 30 integer digits);
         * (38,10) &gt; BIGNUMERIC (NUMERIC cannot hold 10 fractional digits);
         * (76,38) &gt; BIGNUMERIC;
         * (77,38) &gt; BIGNUMERIC (error if value exceeds supported range).
         * 
         * This field cannot contain duplicate types. The order of the types in this field is ignored. For example, [&#34;BIGNUMERIC&#34;, &#34;NUMERIC&#34;] is the same as [&#34;NUMERIC&#34;, &#34;BIGNUMERIC&#34;] and NUMERIC always takes precedence over BIGNUMERIC.
         * 
         * Defaults to [&#34;NUMERIC&#34;, &#34;STRING&#34;] for ORC and [&#34;NUMERIC&#34;] for the other file formats.
         * 
         * @return builder
         * 
         */
        public Builder decimalTargetTypes(String... decimalTargetTypes) {
            return decimalTargetTypes(List.of(decimalTargetTypes));
        }

        /**
         * @param fileSetSpecType Specifies how source URIs are interpreted for constructing the file set to load.
         * By default source URIs are expanded against the underlying storage.
         * Other options include specifying manifest files. Only applicable to object storage systems. Docs
         * 
         * @return builder
         * 
         */
        public Builder fileSetSpecType(@Nullable Output<String> fileSetSpecType) {
            $.fileSetSpecType = fileSetSpecType;
            return this;
        }

        /**
         * @param fileSetSpecType Specifies how source URIs are interpreted for constructing the file set to load.
         * By default source URIs are expanded against the underlying storage.
         * Other options include specifying manifest files. Only applicable to object storage systems. Docs
         * 
         * @return builder
         * 
         */
        public Builder fileSetSpecType(String fileSetSpecType) {
            return fileSetSpecType(Output.of(fileSetSpecType));
        }

        /**
         * @param googleSheetsOptions Additional options if
         * `sourceFormat` is set to &#34;GOOGLE_SHEETS&#34;. Structure is
         * documented below.
         * 
         * @return builder
         * 
         */
        public Builder googleSheetsOptions(@Nullable Output<TableExternalDataConfigurationGoogleSheetsOptionsArgs> googleSheetsOptions) {
            $.googleSheetsOptions = googleSheetsOptions;
            return this;
        }

        /**
         * @param googleSheetsOptions Additional options if
         * `sourceFormat` is set to &#34;GOOGLE_SHEETS&#34;. Structure is
         * documented below.
         * 
         * @return builder
         * 
         */
        public Builder googleSheetsOptions(TableExternalDataConfigurationGoogleSheetsOptionsArgs googleSheetsOptions) {
            return googleSheetsOptions(Output.of(googleSheetsOptions));
        }

        /**
         * @param hivePartitioningOptions When set, configures hive partitioning
         * support. Not all storage formats support hive partitioning -- requesting hive
         * partitioning on an unsupported format will lead to an error, as will providing
         * an invalid specification. Structure is documented below.
         * 
         * @return builder
         * 
         */
        public Builder hivePartitioningOptions(@Nullable Output<TableExternalDataConfigurationHivePartitioningOptionsArgs> hivePartitioningOptions) {
            $.hivePartitioningOptions = hivePartitioningOptions;
            return this;
        }

        /**
         * @param hivePartitioningOptions When set, configures hive partitioning
         * support. Not all storage formats support hive partitioning -- requesting hive
         * partitioning on an unsupported format will lead to an error, as will providing
         * an invalid specification. Structure is documented below.
         * 
         * @return builder
         * 
         */
        public Builder hivePartitioningOptions(TableExternalDataConfigurationHivePartitioningOptionsArgs hivePartitioningOptions) {
            return hivePartitioningOptions(Output.of(hivePartitioningOptions));
        }

        /**
         * @param ignoreUnknownValues Indicates if BigQuery should
         * allow extra values that are not represented in the table schema.
         * If true, the extra values are ignored. If false, records with
         * extra columns are treated as bad records, and if there are too
         * many bad records, an invalid error is returned in the job result.
         * The default value is false.
         * 
         * @return builder
         * 
         */
        public Builder ignoreUnknownValues(@Nullable Output<Boolean> ignoreUnknownValues) {
            $.ignoreUnknownValues = ignoreUnknownValues;
            return this;
        }

        /**
         * @param ignoreUnknownValues Indicates if BigQuery should
         * allow extra values that are not represented in the table schema.
         * If true, the extra values are ignored. If false, records with
         * extra columns are treated as bad records, and if there are too
         * many bad records, an invalid error is returned in the job result.
         * The default value is false.
         * 
         * @return builder
         * 
         */
        public Builder ignoreUnknownValues(Boolean ignoreUnknownValues) {
            return ignoreUnknownValues(Output.of(ignoreUnknownValues));
        }

        /**
         * @param jsonExtension Used to indicate that a JSON variant, rather than normal JSON, is being used as the sourceFormat. This should only be used in combination with the `JSON` source format. Valid values are: `GEOJSON`.
         * 
         * @return builder
         * 
         */
        public Builder jsonExtension(@Nullable Output<String> jsonExtension) {
            $.jsonExtension = jsonExtension;
            return this;
        }

        /**
         * @param jsonExtension Used to indicate that a JSON variant, rather than normal JSON, is being used as the sourceFormat. This should only be used in combination with the `JSON` source format. Valid values are: `GEOJSON`.
         * 
         * @return builder
         * 
         */
        public Builder jsonExtension(String jsonExtension) {
            return jsonExtension(Output.of(jsonExtension));
        }

        /**
         * @param jsonOptions Additional properties to set if
         * `sourceFormat` is set to &#34;JSON&#34;. Structure is documented below.
         * 
         * @return builder
         * 
         */
        public Builder jsonOptions(@Nullable Output<TableExternalDataConfigurationJsonOptionsArgs> jsonOptions) {
            $.jsonOptions = jsonOptions;
            return this;
        }

        /**
         * @param jsonOptions Additional properties to set if
         * `sourceFormat` is set to &#34;JSON&#34;. Structure is documented below.
         * 
         * @return builder
         * 
         */
        public Builder jsonOptions(TableExternalDataConfigurationJsonOptionsArgs jsonOptions) {
            return jsonOptions(Output.of(jsonOptions));
        }

        /**
         * @param maxBadRecords The maximum number of bad records that
         * BigQuery can ignore when reading data.
         * 
         * @return builder
         * 
         */
        public Builder maxBadRecords(@Nullable Output<Integer> maxBadRecords) {
            $.maxBadRecords = maxBadRecords;
            return this;
        }

        /**
         * @param maxBadRecords The maximum number of bad records that
         * BigQuery can ignore when reading data.
         * 
         * @return builder
         * 
         */
        public Builder maxBadRecords(Integer maxBadRecords) {
            return maxBadRecords(Output.of(maxBadRecords));
        }

        /**
         * @param metadataCacheMode Metadata Cache Mode for the table. Set this to enable caching of metadata from external data source. Valid values are `AUTOMATIC` and `MANUAL`.
         * 
         * @return builder
         * 
         */
        public Builder metadataCacheMode(@Nullable Output<String> metadataCacheMode) {
            $.metadataCacheMode = metadataCacheMode;
            return this;
        }

        /**
         * @param metadataCacheMode Metadata Cache Mode for the table. Set this to enable caching of metadata from external data source. Valid values are `AUTOMATIC` and `MANUAL`.
         * 
         * @return builder
         * 
         */
        public Builder metadataCacheMode(String metadataCacheMode) {
            return metadataCacheMode(Output.of(metadataCacheMode));
        }

        /**
         * @param objectMetadata Object Metadata is used to create Object Tables. Object Tables contain a listing of objects (with their metadata) found at the sourceUris. If `objectMetadata` is set, `sourceFormat` should be omitted.
         * 
         * @return builder
         * 
         */
        public Builder objectMetadata(@Nullable Output<String> objectMetadata) {
            $.objectMetadata = objectMetadata;
            return this;
        }

        /**
         * @param objectMetadata Object Metadata is used to create Object Tables. Object Tables contain a listing of objects (with their metadata) found at the sourceUris. If `objectMetadata` is set, `sourceFormat` should be omitted.
         * 
         * @return builder
         * 
         */
        public Builder objectMetadata(String objectMetadata) {
            return objectMetadata(Output.of(objectMetadata));
        }

        /**
         * @param parquetOptions Additional properties to set if
         * `sourceFormat` is set to &#34;PARQUET&#34;. Structure is documented below.
         * 
         * @return builder
         * 
         */
        public Builder parquetOptions(@Nullable Output<TableExternalDataConfigurationParquetOptionsArgs> parquetOptions) {
            $.parquetOptions = parquetOptions;
            return this;
        }

        /**
         * @param parquetOptions Additional properties to set if
         * `sourceFormat` is set to &#34;PARQUET&#34;. Structure is documented below.
         * 
         * @return builder
         * 
         */
        public Builder parquetOptions(TableExternalDataConfigurationParquetOptionsArgs parquetOptions) {
            return parquetOptions(Output.of(parquetOptions));
        }

        /**
         * @param referenceFileSchemaUri When creating an external table, the user can provide a reference file with the table schema. This is enabled for the following formats: AVRO, PARQUET, ORC.
         * 
         * @return builder
         * 
         */
        public Builder referenceFileSchemaUri(@Nullable Output<String> referenceFileSchemaUri) {
            $.referenceFileSchemaUri = referenceFileSchemaUri;
            return this;
        }

        /**
         * @param referenceFileSchemaUri When creating an external table, the user can provide a reference file with the table schema. This is enabled for the following formats: AVRO, PARQUET, ORC.
         * 
         * @return builder
         * 
         */
        public Builder referenceFileSchemaUri(String referenceFileSchemaUri) {
            return referenceFileSchemaUri(Output.of(referenceFileSchemaUri));
        }

        /**
         * @param schema A JSON schema for the external table. Schema is required
         * for CSV and JSON formats if autodetect is not on. Schema is disallowed
         * for Google Cloud Bigtable, Cloud Datastore backups, Avro, Iceberg, ORC and Parquet formats.
         * ~&gt;**NOTE:** Because this field expects a JSON string, any changes to the
         * string will create a diff, even if the JSON itself hasn&#39;t changed.
         * Furthermore drift for this field cannot not be detected because BigQuery
         * only uses this schema to compute the effective schema for the table, therefore
         * any changes on the configured value will force the table to be recreated.
         * This schema is effectively only applied when creating a table from an external
         * datasource, after creation the computed schema will be stored in
         * `google_bigquery_table.schema`
         * 
         * ~&gt;**NOTE:** If you set `external_data_configuration.connection_id`, the
         * table schema must be specified using the top-level `schema` field
         * documented above.
         * 
         * @return builder
         * 
         */
        public Builder schema(@Nullable Output<String> schema) {
            $.schema = schema;
            return this;
        }

        /**
         * @param schema A JSON schema for the external table. Schema is required
         * for CSV and JSON formats if autodetect is not on. Schema is disallowed
         * for Google Cloud Bigtable, Cloud Datastore backups, Avro, Iceberg, ORC and Parquet formats.
         * ~&gt;**NOTE:** Because this field expects a JSON string, any changes to the
         * string will create a diff, even if the JSON itself hasn&#39;t changed.
         * Furthermore drift for this field cannot not be detected because BigQuery
         * only uses this schema to compute the effective schema for the table, therefore
         * any changes on the configured value will force the table to be recreated.
         * This schema is effectively only applied when creating a table from an external
         * datasource, after creation the computed schema will be stored in
         * `google_bigquery_table.schema`
         * 
         * ~&gt;**NOTE:** If you set `external_data_configuration.connection_id`, the
         * table schema must be specified using the top-level `schema` field
         * documented above.
         * 
         * @return builder
         * 
         */
        public Builder schema(String schema) {
            return schema(Output.of(schema));
        }

        /**
         * @param sourceFormat The data format. Please see sourceFormat under
         * [ExternalDataConfiguration](https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#externaldataconfiguration)
         * in Bigquery&#39;s public API documentation for supported formats. To use &#34;GOOGLE_SHEETS&#34;
         * the `scopes` must include &#34;https://www.googleapis.com/auth/drive.readonly&#34;.
         * 
         * @return builder
         * 
         */
        public Builder sourceFormat(@Nullable Output<String> sourceFormat) {
            $.sourceFormat = sourceFormat;
            return this;
        }

        /**
         * @param sourceFormat The data format. Please see sourceFormat under
         * [ExternalDataConfiguration](https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#externaldataconfiguration)
         * in Bigquery&#39;s public API documentation for supported formats. To use &#34;GOOGLE_SHEETS&#34;
         * the `scopes` must include &#34;https://www.googleapis.com/auth/drive.readonly&#34;.
         * 
         * @return builder
         * 
         */
        public Builder sourceFormat(String sourceFormat) {
            return sourceFormat(Output.of(sourceFormat));
        }

        /**
         * @param sourceUris A list of the fully-qualified URIs that point to
         * your data in Google Cloud.
         * 
         * @return builder
         * 
         */
        public Builder sourceUris(Output<List<String>> sourceUris) {
            $.sourceUris = sourceUris;
            return this;
        }

        /**
         * @param sourceUris A list of the fully-qualified URIs that point to
         * your data in Google Cloud.
         * 
         * @return builder
         * 
         */
        public Builder sourceUris(List<String> sourceUris) {
            return sourceUris(Output.of(sourceUris));
        }

        /**
         * @param sourceUris A list of the fully-qualified URIs that point to
         * your data in Google Cloud.
         * 
         * @return builder
         * 
         */
        public Builder sourceUris(String... sourceUris) {
            return sourceUris(List.of(sourceUris));
        }

        public TableExternalDataConfigurationArgs build() {
            if ($.autodetect == null) {
                throw new MissingRequiredPropertyException("TableExternalDataConfigurationArgs", "autodetect");
            }
            if ($.sourceUris == null) {
                throw new MissingRequiredPropertyException("TableExternalDataConfigurationArgs", "sourceUris");
            }
            return $;
        }
    }

}
