// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.vertex.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import com.pulumi.gcp.vertex.outputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv;
import com.pulumi.gcp.vertex.outputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort;
import com.pulumi.gcp.vertex.outputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe;
import com.pulumi.gcp.vertex.outputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe;
import com.pulumi.gcp.vertex.outputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort;
import com.pulumi.gcp.vertex.outputs.AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class AiEndpointWithModelGardenDeploymentModelConfigContainerSpec {
    /**
     * @return Specifies arguments for the command that runs when the container starts.
     * This overrides the container&#39;s
     * [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify
     * this field as an array of executable and arguments, similar to a Docker
     * `CMD`&#39;s &#34;default parameters&#34; form.
     * If you don&#39;t specify this field but do specify the
     * command field, then the command from the
     * `command` field runs without any additional arguments. See the
     * [Kubernetes documentation about how the
     * `command` and `args` fields interact with a container&#39;s `ENTRYPOINT` and
     * `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
     * If you don&#39;t specify this field and don&#39;t specify the `command` field,
     * then the container&#39;s
     * [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and
     * `CMD` determine what runs based on their default behavior. See the Docker
     * documentation about [how `CMD` and `ENTRYPOINT`
     * interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
     * In this field, you can reference [environment variables
     * set by Vertex
     * AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
     * and environment variables set in the env field.
     * You cannot reference environment variables set in the Docker image. In
     * order for environment variables to be expanded, reference them by using the
     * following syntax:$(VARIABLE_NAME)
     * Note that this differs from Bash variable expansion, which does not use
     * parentheses. If a variable cannot be resolved, the reference in the input
     * string is used unchanged. To avoid variable expansion, you can escape this
     * syntax with `$$`; for example:$$(VARIABLE_NAME)
     * This field corresponds to the `args` field of the Kubernetes Containers
     * [v1 core
     * API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
     * 
     */
    private @Nullable List<String> args;
    /**
     * @return Specifies the command that runs when the container starts. This overrides
     * the container&#39;s
     * [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint).
     * Specify this field as an array of executable and arguments, similar to a
     * Docker `ENTRYPOINT`&#39;s &#34;exec&#34; form, not its &#34;shell&#34; form.
     * If you do not specify this field, then the container&#39;s `ENTRYPOINT` runs,
     * in conjunction with the args field or the
     * container&#39;s [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd),
     * if either exists. If this field is not specified and the container does not
     * have an `ENTRYPOINT`, then refer to the Docker documentation about [how
     * `CMD` and `ENTRYPOINT`
     * interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
     * If you specify this field, then you can also specify the `args` field to
     * provide additional arguments for this command. However, if you specify this
     * field, then the container&#39;s `CMD` is ignored. See the
     * [Kubernetes documentation about how the
     * `command` and `args` fields interact with a container&#39;s `ENTRYPOINT` and
     * `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
     * In this field, you can reference [environment variables set by Vertex
     * AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
     * and environment variables set in the env field.
     * You cannot reference environment variables set in the Docker image. In
     * order for environment variables to be expanded, reference them by using the
     * following syntax:$(VARIABLE_NAME)
     * Note that this differs from Bash variable expansion, which does not use
     * parentheses. If a variable cannot be resolved, the reference in the input
     * string is used unchanged. To avoid variable expansion, you can escape this
     * syntax with `$$`; for example:$$(VARIABLE_NAME)
     * This field corresponds to the `command` field of the Kubernetes Containers
     * [v1 core
     * API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
     * 
     */
    private @Nullable List<String> commands;
    /**
     * @return Deployment timeout.
     * Limit for deployment timeout is 2 hours.
     * 
     */
    private @Nullable String deploymentTimeout;
    /**
     * @return List of environment variables to set in the container. After the container
     * starts running, code running in the container can read these environment
     * variables.
     * Additionally, the command and
     * args fields can reference these variables. Later
     * entries in this list can also reference earlier entries. For example, the
     * following example sets the variable `VAR_2` to have the value `foo bar`:
     * 
     * If you switch the order of the variables in the example, then the expansion
     * does not occur.
     * This field corresponds to the `env` field of the Kubernetes Containers
     * [v1 core
     * API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
     * Structure is documented below.
     * 
     */
    private @Nullable List<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv> envs;
    /**
     * @return List of ports to expose from the container. Vertex AI sends gRPC
     * prediction requests that it receives to the first port on this list. Vertex
     * AI also sends liveness and health checks to this port.
     * If you do not specify this field, gRPC requests to the container will be
     * disabled.
     * Vertex AI does not use ports other than the first one listed. This field
     * corresponds to the `ports` field of the Kubernetes Containers v1 core API.
     * Structure is documented below.
     * 
     */
    private @Nullable List<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort> grpcPorts;
    /**
     * @return Probe describes a health check to be performed against a container to
     * determine whether it is alive or ready to receive traffic.
     * Structure is documented below.
     * 
     */
    private @Nullable AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe healthProbe;
    /**
     * @return HTTP path on the container to send health checks to. Vertex AI
     * intermittently sends GET requests to this path on the container&#39;s IP
     * address and port to check that the container is healthy. Read more about
     * [health
     * checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health).
     * For example, if you set this field to `/bar`, then Vertex AI
     * intermittently sends a GET request to the `/bar` path on the port of your
     * container specified by the first value of this `ModelContainerSpec`&#39;s
     * ports field.
     * If you don&#39;t specify this field, it defaults to the following value when
     * you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
     * The placeholders in this value are replaced as follows:
     * * ENDPOINT: The last segment (following `endpoints/`)of the
     *   Endpoint.name][] field of the Endpoint where this Model has been
     *   deployed. (Vertex AI makes this value available to your container code
     *   as the [`AIP_ENDPOINT_ID` environment
     *   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
     * * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
     *   (Vertex AI makes this value available to your container code as the
     *   [`AIP_DEPLOYED_MODEL_ID` environment
     *   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
     * 
     */
    private @Nullable String healthRoute;
    /**
     * @return URI of the Docker image to be used as the custom container for serving
     * predictions. This URI must identify an image in Artifact Registry or
     * Container Registry. Learn more about the [container publishing
     * requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing),
     * including permissions requirements for the Vertex AI Service Agent.
     * The container image is ingested upon ModelService.UploadModel, stored
     * internally, and this original path is afterwards not used.
     * To learn about the requirements for the Docker image itself, see
     * [Custom container
     * requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#).
     * You can use the URI to one of Vertex AI&#39;s [pre-built container images for
     * prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)
     * in this field.
     * 
     */
    private String imageUri;
    /**
     * @return Probe describes a health check to be performed against a container to
     * determine whether it is alive or ready to receive traffic.
     * Structure is documented below.
     * 
     */
    private @Nullable AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe livenessProbe;
    /**
     * @return List of ports to expose from the container. Vertex AI sends any
     * prediction requests that it receives to the first port on this list. Vertex
     * AI also sends
     * [liveness and health
     * checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness)
     * to this port.
     * If you do not specify this field, it defaults to following value:
     * 
     * Vertex AI does not use ports other than the first one listed. This field
     * corresponds to the `ports` field of the Kubernetes Containers
     * [v1 core
     * API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
     * Structure is documented below.
     * 
     */
    private @Nullable List<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort> ports;
    /**
     * @return HTTP path on the container to send prediction requests to. Vertex AI
     * forwards requests sent using
     * projects.locations.endpoints.predict to this
     * path on the container&#39;s IP address and port. Vertex AI then returns the
     * container&#39;s response in the API response.
     * For example, if you set this field to `/foo`, then when Vertex AI
     * receives a prediction request, it forwards the request body in a POST
     * request to the `/foo` path on the port of your container specified by the
     * first value of this `ModelContainerSpec`&#39;s
     * ports field.
     * If you don&#39;t specify this field, it defaults to the following value when
     * you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
     * The placeholders in this value are replaced as follows:
     * * ENDPOINT: The last segment (following `endpoints/`)of the
     *   Endpoint.name][] field of the Endpoint where this Model has been
     *   deployed. (Vertex AI makes this value available to your container code
     *   as the [`AIP_ENDPOINT_ID` environment
     *   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
     * * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
     *   (Vertex AI makes this value available to your container code
     *   as the [`AIP_DEPLOYED_MODEL_ID` environment
     *   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
     * 
     */
    private @Nullable String predictRoute;
    /**
     * @return The amount of the VM memory to reserve as the shared memory for the model
     * in megabytes.
     * 
     */
    private @Nullable String sharedMemorySizeMb;
    /**
     * @return Probe describes a health check to be performed against a container to
     * determine whether it is alive or ready to receive traffic.
     * Structure is documented below.
     * 
     */
    private @Nullable AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe startupProbe;

    private AiEndpointWithModelGardenDeploymentModelConfigContainerSpec() {}
    /**
     * @return Specifies arguments for the command that runs when the container starts.
     * This overrides the container&#39;s
     * [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify
     * this field as an array of executable and arguments, similar to a Docker
     * `CMD`&#39;s &#34;default parameters&#34; form.
     * If you don&#39;t specify this field but do specify the
     * command field, then the command from the
     * `command` field runs without any additional arguments. See the
     * [Kubernetes documentation about how the
     * `command` and `args` fields interact with a container&#39;s `ENTRYPOINT` and
     * `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
     * If you don&#39;t specify this field and don&#39;t specify the `command` field,
     * then the container&#39;s
     * [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and
     * `CMD` determine what runs based on their default behavior. See the Docker
     * documentation about [how `CMD` and `ENTRYPOINT`
     * interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
     * In this field, you can reference [environment variables
     * set by Vertex
     * AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
     * and environment variables set in the env field.
     * You cannot reference environment variables set in the Docker image. In
     * order for environment variables to be expanded, reference them by using the
     * following syntax:$(VARIABLE_NAME)
     * Note that this differs from Bash variable expansion, which does not use
     * parentheses. If a variable cannot be resolved, the reference in the input
     * string is used unchanged. To avoid variable expansion, you can escape this
     * syntax with `$$`; for example:$$(VARIABLE_NAME)
     * This field corresponds to the `args` field of the Kubernetes Containers
     * [v1 core
     * API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
     * 
     */
    public List<String> args() {
        return this.args == null ? List.of() : this.args;
    }
    /**
     * @return Specifies the command that runs when the container starts. This overrides
     * the container&#39;s
     * [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint).
     * Specify this field as an array of executable and arguments, similar to a
     * Docker `ENTRYPOINT`&#39;s &#34;exec&#34; form, not its &#34;shell&#34; form.
     * If you do not specify this field, then the container&#39;s `ENTRYPOINT` runs,
     * in conjunction with the args field or the
     * container&#39;s [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd),
     * if either exists. If this field is not specified and the container does not
     * have an `ENTRYPOINT`, then refer to the Docker documentation about [how
     * `CMD` and `ENTRYPOINT`
     * interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
     * If you specify this field, then you can also specify the `args` field to
     * provide additional arguments for this command. However, if you specify this
     * field, then the container&#39;s `CMD` is ignored. See the
     * [Kubernetes documentation about how the
     * `command` and `args` fields interact with a container&#39;s `ENTRYPOINT` and
     * `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
     * In this field, you can reference [environment variables set by Vertex
     * AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
     * and environment variables set in the env field.
     * You cannot reference environment variables set in the Docker image. In
     * order for environment variables to be expanded, reference them by using the
     * following syntax:$(VARIABLE_NAME)
     * Note that this differs from Bash variable expansion, which does not use
     * parentheses. If a variable cannot be resolved, the reference in the input
     * string is used unchanged. To avoid variable expansion, you can escape this
     * syntax with `$$`; for example:$$(VARIABLE_NAME)
     * This field corresponds to the `command` field of the Kubernetes Containers
     * [v1 core
     * API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
     * 
     */
    public List<String> commands() {
        return this.commands == null ? List.of() : this.commands;
    }
    /**
     * @return Deployment timeout.
     * Limit for deployment timeout is 2 hours.
     * 
     */
    public Optional<String> deploymentTimeout() {
        return Optional.ofNullable(this.deploymentTimeout);
    }
    /**
     * @return List of environment variables to set in the container. After the container
     * starts running, code running in the container can read these environment
     * variables.
     * Additionally, the command and
     * args fields can reference these variables. Later
     * entries in this list can also reference earlier entries. For example, the
     * following example sets the variable `VAR_2` to have the value `foo bar`:
     * 
     * If you switch the order of the variables in the example, then the expansion
     * does not occur.
     * This field corresponds to the `env` field of the Kubernetes Containers
     * [v1 core
     * API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
     * Structure is documented below.
     * 
     */
    public List<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv> envs() {
        return this.envs == null ? List.of() : this.envs;
    }
    /**
     * @return List of ports to expose from the container. Vertex AI sends gRPC
     * prediction requests that it receives to the first port on this list. Vertex
     * AI also sends liveness and health checks to this port.
     * If you do not specify this field, gRPC requests to the container will be
     * disabled.
     * Vertex AI does not use ports other than the first one listed. This field
     * corresponds to the `ports` field of the Kubernetes Containers v1 core API.
     * Structure is documented below.
     * 
     */
    public List<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort> grpcPorts() {
        return this.grpcPorts == null ? List.of() : this.grpcPorts;
    }
    /**
     * @return Probe describes a health check to be performed against a container to
     * determine whether it is alive or ready to receive traffic.
     * Structure is documented below.
     * 
     */
    public Optional<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe> healthProbe() {
        return Optional.ofNullable(this.healthProbe);
    }
    /**
     * @return HTTP path on the container to send health checks to. Vertex AI
     * intermittently sends GET requests to this path on the container&#39;s IP
     * address and port to check that the container is healthy. Read more about
     * [health
     * checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health).
     * For example, if you set this field to `/bar`, then Vertex AI
     * intermittently sends a GET request to the `/bar` path on the port of your
     * container specified by the first value of this `ModelContainerSpec`&#39;s
     * ports field.
     * If you don&#39;t specify this field, it defaults to the following value when
     * you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
     * The placeholders in this value are replaced as follows:
     * * ENDPOINT: The last segment (following `endpoints/`)of the
     *   Endpoint.name][] field of the Endpoint where this Model has been
     *   deployed. (Vertex AI makes this value available to your container code
     *   as the [`AIP_ENDPOINT_ID` environment
     *   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
     * * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
     *   (Vertex AI makes this value available to your container code as the
     *   [`AIP_DEPLOYED_MODEL_ID` environment
     *   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
     * 
     */
    public Optional<String> healthRoute() {
        return Optional.ofNullable(this.healthRoute);
    }
    /**
     * @return URI of the Docker image to be used as the custom container for serving
     * predictions. This URI must identify an image in Artifact Registry or
     * Container Registry. Learn more about the [container publishing
     * requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing),
     * including permissions requirements for the Vertex AI Service Agent.
     * The container image is ingested upon ModelService.UploadModel, stored
     * internally, and this original path is afterwards not used.
     * To learn about the requirements for the Docker image itself, see
     * [Custom container
     * requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#).
     * You can use the URI to one of Vertex AI&#39;s [pre-built container images for
     * prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)
     * in this field.
     * 
     */
    public String imageUri() {
        return this.imageUri;
    }
    /**
     * @return Probe describes a health check to be performed against a container to
     * determine whether it is alive or ready to receive traffic.
     * Structure is documented below.
     * 
     */
    public Optional<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe> livenessProbe() {
        return Optional.ofNullable(this.livenessProbe);
    }
    /**
     * @return List of ports to expose from the container. Vertex AI sends any
     * prediction requests that it receives to the first port on this list. Vertex
     * AI also sends
     * [liveness and health
     * checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness)
     * to this port.
     * If you do not specify this field, it defaults to following value:
     * 
     * Vertex AI does not use ports other than the first one listed. This field
     * corresponds to the `ports` field of the Kubernetes Containers
     * [v1 core
     * API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
     * Structure is documented below.
     * 
     */
    public List<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort> ports() {
        return this.ports == null ? List.of() : this.ports;
    }
    /**
     * @return HTTP path on the container to send prediction requests to. Vertex AI
     * forwards requests sent using
     * projects.locations.endpoints.predict to this
     * path on the container&#39;s IP address and port. Vertex AI then returns the
     * container&#39;s response in the API response.
     * For example, if you set this field to `/foo`, then when Vertex AI
     * receives a prediction request, it forwards the request body in a POST
     * request to the `/foo` path on the port of your container specified by the
     * first value of this `ModelContainerSpec`&#39;s
     * ports field.
     * If you don&#39;t specify this field, it defaults to the following value when
     * you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
     * The placeholders in this value are replaced as follows:
     * * ENDPOINT: The last segment (following `endpoints/`)of the
     *   Endpoint.name][] field of the Endpoint where this Model has been
     *   deployed. (Vertex AI makes this value available to your container code
     *   as the [`AIP_ENDPOINT_ID` environment
     *   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
     * * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
     *   (Vertex AI makes this value available to your container code
     *   as the [`AIP_DEPLOYED_MODEL_ID` environment
     *   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
     * 
     */
    public Optional<String> predictRoute() {
        return Optional.ofNullable(this.predictRoute);
    }
    /**
     * @return The amount of the VM memory to reserve as the shared memory for the model
     * in megabytes.
     * 
     */
    public Optional<String> sharedMemorySizeMb() {
        return Optional.ofNullable(this.sharedMemorySizeMb);
    }
    /**
     * @return Probe describes a health check to be performed against a container to
     * determine whether it is alive or ready to receive traffic.
     * Structure is documented below.
     * 
     */
    public Optional<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe> startupProbe() {
        return Optional.ofNullable(this.startupProbe);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(AiEndpointWithModelGardenDeploymentModelConfigContainerSpec defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable List<String> args;
        private @Nullable List<String> commands;
        private @Nullable String deploymentTimeout;
        private @Nullable List<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv> envs;
        private @Nullable List<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort> grpcPorts;
        private @Nullable AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe healthProbe;
        private @Nullable String healthRoute;
        private String imageUri;
        private @Nullable AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe livenessProbe;
        private @Nullable List<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort> ports;
        private @Nullable String predictRoute;
        private @Nullable String sharedMemorySizeMb;
        private @Nullable AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe startupProbe;
        public Builder() {}
        public Builder(AiEndpointWithModelGardenDeploymentModelConfigContainerSpec defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.args = defaults.args;
    	      this.commands = defaults.commands;
    	      this.deploymentTimeout = defaults.deploymentTimeout;
    	      this.envs = defaults.envs;
    	      this.grpcPorts = defaults.grpcPorts;
    	      this.healthProbe = defaults.healthProbe;
    	      this.healthRoute = defaults.healthRoute;
    	      this.imageUri = defaults.imageUri;
    	      this.livenessProbe = defaults.livenessProbe;
    	      this.ports = defaults.ports;
    	      this.predictRoute = defaults.predictRoute;
    	      this.sharedMemorySizeMb = defaults.sharedMemorySizeMb;
    	      this.startupProbe = defaults.startupProbe;
        }

        @CustomType.Setter
        public Builder args(@Nullable List<String> args) {

            this.args = args;
            return this;
        }
        public Builder args(String... args) {
            return args(List.of(args));
        }
        @CustomType.Setter
        public Builder commands(@Nullable List<String> commands) {

            this.commands = commands;
            return this;
        }
        public Builder commands(String... commands) {
            return commands(List.of(commands));
        }
        @CustomType.Setter
        public Builder deploymentTimeout(@Nullable String deploymentTimeout) {

            this.deploymentTimeout = deploymentTimeout;
            return this;
        }
        @CustomType.Setter
        public Builder envs(@Nullable List<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv> envs) {

            this.envs = envs;
            return this;
        }
        public Builder envs(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv... envs) {
            return envs(List.of(envs));
        }
        @CustomType.Setter
        public Builder grpcPorts(@Nullable List<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort> grpcPorts) {

            this.grpcPorts = grpcPorts;
            return this;
        }
        public Builder grpcPorts(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort... grpcPorts) {
            return grpcPorts(List.of(grpcPorts));
        }
        @CustomType.Setter
        public Builder healthProbe(@Nullable AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe healthProbe) {

            this.healthProbe = healthProbe;
            return this;
        }
        @CustomType.Setter
        public Builder healthRoute(@Nullable String healthRoute) {

            this.healthRoute = healthRoute;
            return this;
        }
        @CustomType.Setter
        public Builder imageUri(String imageUri) {
            if (imageUri == null) {
              throw new MissingRequiredPropertyException("AiEndpointWithModelGardenDeploymentModelConfigContainerSpec", "imageUri");
            }
            this.imageUri = imageUri;
            return this;
        }
        @CustomType.Setter
        public Builder livenessProbe(@Nullable AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe livenessProbe) {

            this.livenessProbe = livenessProbe;
            return this;
        }
        @CustomType.Setter
        public Builder ports(@Nullable List<AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort> ports) {

            this.ports = ports;
            return this;
        }
        public Builder ports(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort... ports) {
            return ports(List.of(ports));
        }
        @CustomType.Setter
        public Builder predictRoute(@Nullable String predictRoute) {

            this.predictRoute = predictRoute;
            return this;
        }
        @CustomType.Setter
        public Builder sharedMemorySizeMb(@Nullable String sharedMemorySizeMb) {

            this.sharedMemorySizeMb = sharedMemorySizeMb;
            return this;
        }
        @CustomType.Setter
        public Builder startupProbe(@Nullable AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe startupProbe) {

            this.startupProbe = startupProbe;
            return this;
        }
        public AiEndpointWithModelGardenDeploymentModelConfigContainerSpec build() {
            final var _resultValue = new AiEndpointWithModelGardenDeploymentModelConfigContainerSpec();
            _resultValue.args = args;
            _resultValue.commands = commands;
            _resultValue.deploymentTimeout = deploymentTimeout;
            _resultValue.envs = envs;
            _resultValue.grpcPorts = grpcPorts;
            _resultValue.healthProbe = healthProbe;
            _resultValue.healthRoute = healthRoute;
            _resultValue.imageUri = imageUri;
            _resultValue.livenessProbe = livenessProbe;
            _resultValue.ports = ports;
            _resultValue.predictRoute = predictRoute;
            _resultValue.sharedMemorySizeMb = sharedMemorySizeMb;
            _resultValue.startupProbe = startupProbe;
            return _resultValue;
        }
    }
}
