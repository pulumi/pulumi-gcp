// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.healthcare;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.gcp.Utilities;
import com.pulumi.gcp.healthcare.PipelineJobArgs;
import com.pulumi.gcp.healthcare.inputs.PipelineJobState;
import com.pulumi.gcp.healthcare.outputs.PipelineJobBackfillPipelineJob;
import com.pulumi.gcp.healthcare.outputs.PipelineJobMappingPipelineJob;
import com.pulumi.gcp.healthcare.outputs.PipelineJobReconciliationPipelineJob;
import java.lang.Boolean;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * PipelineJobs are Long Running Operations on Healthcare API to Map or Reconcile
 * incoming data into FHIR format
 * 
 * To get more information about PipelineJob, see:
 * 
 * * [API documentation](https://cloud.google.com/healthcare-api/healthcare-data-engine/docs/reference/rest/v1/projects.locations.datasets.pipelineJobs)
 * * How-to Guides
 *     * [Creating a PipelineJob](https://cloud.google.com/healthcare-api/private/healthcare-data-engine/docs/reference/rest/v1/projects.locations.datasets.pipelineJobs#PipelineJob)
 * 
 * ## Example Usage
 * 
 * ### Healthcare Pipeline Job Reconciliation
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.organizations.OrganizationsFunctions;
 * import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
 * import com.pulumi.gcp.healthcare.Dataset;
 * import com.pulumi.gcp.healthcare.DatasetArgs;
 * import com.pulumi.gcp.healthcare.FhirStore;
 * import com.pulumi.gcp.healthcare.FhirStoreArgs;
 * import com.pulumi.gcp.storage.Bucket;
 * import com.pulumi.gcp.storage.BucketArgs;
 * import com.pulumi.gcp.storage.BucketObject;
 * import com.pulumi.gcp.storage.BucketObjectArgs;
 * import com.pulumi.gcp.healthcare.PipelineJob;
 * import com.pulumi.gcp.healthcare.PipelineJobArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobReconciliationPipelineJobArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobReconciliationPipelineJobMergeConfigArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobReconciliationPipelineJobMergeConfigWhistleConfigSourceArgs;
 * import com.pulumi.gcp.storage.BucketIAMMember;
 * import com.pulumi.gcp.storage.BucketIAMMemberArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App }{{@code
 *     public static void main(String[] args) }{{@code
 *         Pulumi.run(App::stack);
 *     }}{@code
 * 
 *     public static void stack(Context ctx) }{{@code
 *         final var project = OrganizationsFunctions.getProject(GetProjectArgs.builder()
 *             .build());
 * 
 *         var dataset = new Dataset("dataset", DatasetArgs.builder()
 *             .name("example_dataset")
 *             .location("us-central1")
 *             .build());
 * 
 *         var fhirstore = new FhirStore("fhirstore", FhirStoreArgs.builder()
 *             .name("fhir_store")
 *             .dataset(dataset.id())
 *             .version("R4")
 *             .enableUpdateCreate(true)
 *             .disableReferentialIntegrity(true)
 *             .build());
 * 
 *         var bucket = new Bucket("bucket", BucketArgs.builder()
 *             .name("example_bucket_name")
 *             .location("us-central1")
 *             .uniformBucketLevelAccess(true)
 *             .build());
 * 
 *         var mergeFile = new BucketObject("mergeFile", BucketObjectArgs.builder()
 *             .name("merge.wstl")
 *             .content(" ")
 *             .bucket(bucket.name())
 *             .build());
 * 
 *         var example_pipeline = new PipelineJob("example-pipeline", PipelineJobArgs.builder()
 *             .name("example_pipeline_job")
 *             .location("us-central1")
 *             .dataset(dataset.id())
 *             .disableLineage(true)
 *             .reconciliationPipelineJob(PipelineJobReconciliationPipelineJobArgs.builder()
 *                 .mergeConfig(PipelineJobReconciliationPipelineJobMergeConfigArgs.builder()
 *                     .description("sample description for reconciliation rules")
 *                     .whistleConfigSource(PipelineJobReconciliationPipelineJobMergeConfigWhistleConfigSourceArgs.builder()
 *                         .uri(Output.tuple(bucket.name(), mergeFile.name()).applyValue(values -> }{{@code
 *                             var bucketName = values.t1;
 *                             var mergeFileName = values.t2;
 *                             return String.format("gs://%s/%s", bucketName,mergeFileName);
 *                         }}{@code ))
 *                         .importUriPrefix(bucket.name().applyValue(_name -> String.format("gs://%s", _name)))
 *                         .build())
 *                     .build())
 *                 .matchingUriPrefix(bucket.name().applyValue(_name -> String.format("gs://%s", _name)))
 *                 .fhirStoreDestination(Output.tuple(dataset.id(), fhirstore.name()).applyValue(values -> }{{@code
 *                     var id = values.t1;
 *                     var name = values.t2;
 *                     return String.format("%s/fhirStores/%s", id,name);
 *                 }}{@code ))
 *                 .build())
 *             .build());
 * 
 *         var hsa = new BucketIAMMember("hsa", BucketIAMMemberArgs.builder()
 *             .bucket(bucket.name())
 *             .role("roles/storage.objectUser")
 *             .member(String.format("serviceAccount:service-%s}{@literal @}{@code gcp-sa-healthcare.iam.gserviceaccount.com", project.number()))
 *             .build());
 * 
 *     }}{@code
 * }}{@code
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * ### Healthcare Pipeline Job Backfill
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.healthcare.Dataset;
 * import com.pulumi.gcp.healthcare.DatasetArgs;
 * import com.pulumi.gcp.healthcare.PipelineJob;
 * import com.pulumi.gcp.healthcare.PipelineJobArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobBackfillPipelineJobArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var dataset = new Dataset("dataset", DatasetArgs.builder()
 *             .name("example_dataset")
 *             .location("us-central1")
 *             .build());
 * 
 *         var example_pipeline = new PipelineJob("example-pipeline", PipelineJobArgs.builder()
 *             .name("example_backfill_pipeline")
 *             .location("us-central1")
 *             .dataset(dataset.id())
 *             .backfillPipelineJob(PipelineJobBackfillPipelineJobArgs.builder()
 *                 .mappingPipelineJob(dataset.id().applyValue(_id -> String.format("%s/pipelineJobs/example_mapping_pipeline_job", _id)))
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * ### Healthcare Pipeline Job Whistle Mapping
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.organizations.OrganizationsFunctions;
 * import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
 * import com.pulumi.gcp.healthcare.Dataset;
 * import com.pulumi.gcp.healthcare.DatasetArgs;
 * import com.pulumi.gcp.healthcare.FhirStore;
 * import com.pulumi.gcp.healthcare.FhirStoreArgs;
 * import com.pulumi.gcp.storage.Bucket;
 * import com.pulumi.gcp.storage.BucketArgs;
 * import com.pulumi.gcp.storage.BucketObject;
 * import com.pulumi.gcp.storage.BucketObjectArgs;
 * import com.pulumi.gcp.healthcare.PipelineJob;
 * import com.pulumi.gcp.healthcare.PipelineJobArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobMappingPipelineJobArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobMappingPipelineJobMappingConfigArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobMappingPipelineJobMappingConfigWhistleConfigSourceArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobMappingPipelineJobFhirStreamingSourceArgs;
 * import com.pulumi.gcp.storage.BucketIAMMember;
 * import com.pulumi.gcp.storage.BucketIAMMemberArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App }{{@code
 *     public static void main(String[] args) }{{@code
 *         Pulumi.run(App::stack);
 *     }}{@code
 * 
 *     public static void stack(Context ctx) }{{@code
 *         final var project = OrganizationsFunctions.getProject(GetProjectArgs.builder()
 *             .build());
 * 
 *         var dataset = new Dataset("dataset", DatasetArgs.builder()
 *             .name("example_dataset")
 *             .location("us-central1")
 *             .build());
 * 
 *         var sourceFhirstore = new FhirStore("sourceFhirstore", FhirStoreArgs.builder()
 *             .name("source_fhir_store")
 *             .dataset(dataset.id())
 *             .version("R4")
 *             .enableUpdateCreate(true)
 *             .disableReferentialIntegrity(true)
 *             .build());
 * 
 *         var destFhirstore = new FhirStore("destFhirstore", FhirStoreArgs.builder()
 *             .name("dest_fhir_store")
 *             .dataset(dataset.id())
 *             .version("R4")
 *             .enableUpdateCreate(true)
 *             .disableReferentialIntegrity(true)
 *             .build());
 * 
 *         var bucket = new Bucket("bucket", BucketArgs.builder()
 *             .name("example_bucket_name")
 *             .location("us-central1")
 *             .uniformBucketLevelAccess(true)
 *             .build());
 * 
 *         var mappingFile = new BucketObject("mappingFile", BucketObjectArgs.builder()
 *             .name("mapping.wstl")
 *             .content(" ")
 *             .bucket(bucket.name())
 *             .build());
 * 
 *         var example_mapping_pipeline = new PipelineJob("example-mapping-pipeline", PipelineJobArgs.builder()
 *             .name("example_mapping_pipeline_job")
 *             .location("us-central1")
 *             .dataset(dataset.id())
 *             .disableLineage(true)
 *             .labels(Map.of("example_label_key", "example_label_value"))
 *             .mappingPipelineJob(PipelineJobMappingPipelineJobArgs.builder()
 *                 .mappingConfig(PipelineJobMappingPipelineJobMappingConfigArgs.builder()
 *                     .whistleConfigSource(PipelineJobMappingPipelineJobMappingConfigWhistleConfigSourceArgs.builder()
 *                         .uri(Output.tuple(bucket.name(), mappingFile.name()).applyValue(values -> }{{@code
 *                             var bucketName = values.t1;
 *                             var mappingFileName = values.t2;
 *                             return String.format("gs://%s/%s", bucketName,mappingFileName);
 *                         }}{@code ))
 *                         .importUriPrefix(bucket.name().applyValue(_name -> String.format("gs://%s", _name)))
 *                         .build())
 *                     .description("example description for mapping configuration")
 *                     .build())
 *                 .fhirStreamingSource(PipelineJobMappingPipelineJobFhirStreamingSourceArgs.builder()
 *                     .fhirStore(Output.tuple(dataset.id(), sourceFhirstore.name()).applyValue(values -> }{{@code
 *                         var id = values.t1;
 *                         var name = values.t2;
 *                         return String.format("%s/fhirStores/%s", id,name);
 *                     }}{@code ))
 *                     .description("example description for streaming fhirstore")
 *                     .build())
 *                 .fhirStoreDestination(Output.tuple(dataset.id(), destFhirstore.name()).applyValue(values -> }{{@code
 *                     var id = values.t1;
 *                     var name = values.t2;
 *                     return String.format("%s/fhirStores/%s", id,name);
 *                 }}{@code ))
 *                 .build())
 *             .build());
 * 
 *         var hsa = new BucketIAMMember("hsa", BucketIAMMemberArgs.builder()
 *             .bucket(bucket.name())
 *             .role("roles/storage.objectUser")
 *             .member(String.format("serviceAccount:service-%s}{@literal @}{@code gcp-sa-healthcare.iam.gserviceaccount.com", project.number()))
 *             .build());
 * 
 *     }}{@code
 * }}{@code
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * ### Healthcare Pipeline Job Mapping Recon Dest
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.organizations.OrganizationsFunctions;
 * import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
 * import com.pulumi.gcp.healthcare.Dataset;
 * import com.pulumi.gcp.healthcare.DatasetArgs;
 * import com.pulumi.gcp.healthcare.FhirStore;
 * import com.pulumi.gcp.healthcare.FhirStoreArgs;
 * import com.pulumi.gcp.storage.Bucket;
 * import com.pulumi.gcp.storage.BucketArgs;
 * import com.pulumi.gcp.storage.BucketObject;
 * import com.pulumi.gcp.storage.BucketObjectArgs;
 * import com.pulumi.gcp.healthcare.PipelineJob;
 * import com.pulumi.gcp.healthcare.PipelineJobArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobReconciliationPipelineJobArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobReconciliationPipelineJobMergeConfigArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobReconciliationPipelineJobMergeConfigWhistleConfigSourceArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobMappingPipelineJobArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobMappingPipelineJobMappingConfigArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobMappingPipelineJobMappingConfigWhistleConfigSourceArgs;
 * import com.pulumi.gcp.healthcare.inputs.PipelineJobMappingPipelineJobFhirStreamingSourceArgs;
 * import com.pulumi.gcp.storage.BucketIAMMember;
 * import com.pulumi.gcp.storage.BucketIAMMemberArgs;
 * import com.pulumi.resources.CustomResourceOptions;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App }{{@code
 *     public static void main(String[] args) }{{@code
 *         Pulumi.run(App::stack);
 *     }}{@code
 * 
 *     public static void stack(Context ctx) }{{@code
 *         final var project = OrganizationsFunctions.getProject(GetProjectArgs.builder()
 *             .build());
 * 
 *         var dataset = new Dataset("dataset", DatasetArgs.builder()
 *             .name("example_dataset")
 *             .location("us-central1")
 *             .build());
 * 
 *         var destFhirstore = new FhirStore("destFhirstore", FhirStoreArgs.builder()
 *             .name("dest_fhir_store")
 *             .dataset(dataset.id())
 *             .version("R4")
 *             .enableUpdateCreate(true)
 *             .disableReferentialIntegrity(true)
 *             .build());
 * 
 *         var bucket = new Bucket("bucket", BucketArgs.builder()
 *             .name("example_bucket_name")
 *             .location("us-central1")
 *             .uniformBucketLevelAccess(true)
 *             .build());
 * 
 *         var mergeFile = new BucketObject("mergeFile", BucketObjectArgs.builder()
 *             .name("merge.wstl")
 *             .content(" ")
 *             .bucket(bucket.name())
 *             .build());
 * 
 *         var recon = new PipelineJob("recon", PipelineJobArgs.builder()
 *             .name("example_recon_pipeline_job")
 *             .location("us-central1")
 *             .dataset(dataset.id())
 *             .disableLineage(true)
 *             .reconciliationPipelineJob(PipelineJobReconciliationPipelineJobArgs.builder()
 *                 .mergeConfig(PipelineJobReconciliationPipelineJobMergeConfigArgs.builder()
 *                     .description("sample description for reconciliation rules")
 *                     .whistleConfigSource(PipelineJobReconciliationPipelineJobMergeConfigWhistleConfigSourceArgs.builder()
 *                         .uri(Output.tuple(bucket.name(), mergeFile.name()).applyValue(values -> }{{@code
 *                             var bucketName = values.t1;
 *                             var mergeFileName = values.t2;
 *                             return String.format("gs://%s/%s", bucketName,mergeFileName);
 *                         }}{@code ))
 *                         .importUriPrefix(bucket.name().applyValue(_name -> String.format("gs://%s", _name)))
 *                         .build())
 *                     .build())
 *                 .matchingUriPrefix(bucket.name().applyValue(_name -> String.format("gs://%s", _name)))
 *                 .fhirStoreDestination(Output.tuple(dataset.id(), destFhirstore.name()).applyValue(values -> }{{@code
 *                     var id = values.t1;
 *                     var name = values.t2;
 *                     return String.format("%s/fhirStores/%s", id,name);
 *                 }}{@code ))
 *                 .build())
 *             .build());
 * 
 *         var sourceFhirstore = new FhirStore("sourceFhirstore", FhirStoreArgs.builder()
 *             .name("source_fhir_store")
 *             .dataset(dataset.id())
 *             .version("R4")
 *             .enableUpdateCreate(true)
 *             .disableReferentialIntegrity(true)
 *             .build());
 * 
 *         var mappingFile = new BucketObject("mappingFile", BucketObjectArgs.builder()
 *             .name("mapping.wstl")
 *             .content(" ")
 *             .bucket(bucket.name())
 *             .build());
 * 
 *         var example_mapping_pipeline = new PipelineJob("example-mapping-pipeline", PipelineJobArgs.builder()
 *             .name("example_mapping_pipeline_job")
 *             .location("us-central1")
 *             .dataset(dataset.id())
 *             .disableLineage(true)
 *             .labels(Map.of("example_label_key", "example_label_value"))
 *             .mappingPipelineJob(PipelineJobMappingPipelineJobArgs.builder()
 *                 .mappingConfig(PipelineJobMappingPipelineJobMappingConfigArgs.builder()
 *                     .whistleConfigSource(PipelineJobMappingPipelineJobMappingConfigWhistleConfigSourceArgs.builder()
 *                         .uri(Output.tuple(bucket.name(), mappingFile.name()).applyValue(values -> }{{@code
 *                             var bucketName = values.t1;
 *                             var mappingFileName = values.t2;
 *                             return String.format("gs://%s/%s", bucketName,mappingFileName);
 *                         }}{@code ))
 *                         .importUriPrefix(bucket.name().applyValue(_name -> String.format("gs://%s", _name)))
 *                         .build())
 *                     .description("example description for mapping configuration")
 *                     .build())
 *                 .fhirStreamingSource(PipelineJobMappingPipelineJobFhirStreamingSourceArgs.builder()
 *                     .fhirStore(Output.tuple(dataset.id(), sourceFhirstore.name()).applyValue(values -> }{{@code
 *                         var id = values.t1;
 *                         var name = values.t2;
 *                         return String.format("%s/fhirStores/%s", id,name);
 *                     }}{@code ))
 *                     .description("example description for streaming fhirstore")
 *                     .build())
 *                 .reconciliationDestination(true)
 *                 .build())
 *             .build(), CustomResourceOptions.builder()
 *                 .dependsOn(recon)
 *                 .build());
 * 
 *         var hsa = new BucketIAMMember("hsa", BucketIAMMemberArgs.builder()
 *             .bucket(bucket.name())
 *             .role("roles/storage.objectUser")
 *             .member(String.format("serviceAccount:service-%s}{@literal @}{@code gcp-sa-healthcare.iam.gserviceaccount.com", project.number()))
 *             .build());
 * 
 *     }}{@code
 * }}{@code
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * ## Import
 * 
 * PipelineJob can be imported using any of these accepted formats:
 * 
 * * `{{dataset}}/pipelineJobs/{{name}}`
 * 
 * * `{{dataset}}/pipelineJobs?pipelineJobId={{name}}`
 * 
 * * `{{name}}`
 * 
 * When using the `pulumi import` command, PipelineJob can be imported using one of the formats above. For example:
 * 
 * ```sh
 * $ pulumi import gcp:healthcare/pipelineJob:PipelineJob default {{dataset}}/pipelineJobs/{{name}}
 * ```
 * 
 * ```sh
 * $ pulumi import gcp:healthcare/pipelineJob:PipelineJob default {{dataset}}/pipelineJobs?pipelineJobId={{name}}
 * ```
 * 
 * ```sh
 * $ pulumi import gcp:healthcare/pipelineJob:PipelineJob default {{name}}
 * ```
 * 
 */
@ResourceType(type="gcp:healthcare/pipelineJob:PipelineJob")
public class PipelineJob extends com.pulumi.resources.CustomResource {
    /**
     * Specifies the backfill configuration.
     * Structure is documented below.
     * 
     */
    @Export(name="backfillPipelineJob", refs={PipelineJobBackfillPipelineJob.class}, tree="[0]")
    private Output</* @Nullable */ PipelineJobBackfillPipelineJob> backfillPipelineJob;

    /**
     * @return Specifies the backfill configuration.
     * Structure is documented below.
     * 
     */
    public Output<Optional<PipelineJobBackfillPipelineJob>> backfillPipelineJob() {
        return Codegen.optional(this.backfillPipelineJob);
    }
    /**
     * Healthcare Dataset under which the Pipeline Job is to run
     * 
     * ***
     * 
     */
    @Export(name="dataset", refs={String.class}, tree="[0]")
    private Output<String> dataset;

    /**
     * @return Healthcare Dataset under which the Pipeline Job is to run
     * 
     * ***
     * 
     */
    public Output<String> dataset() {
        return this.dataset;
    }
    /**
     * If true, disables writing lineage for the pipeline.
     * 
     */
    @Export(name="disableLineage", refs={Boolean.class}, tree="[0]")
    private Output</* @Nullable */ Boolean> disableLineage;

    /**
     * @return If true, disables writing lineage for the pipeline.
     * 
     */
    public Output<Optional<Boolean>> disableLineage() {
        return Codegen.optional(this.disableLineage);
    }
    /**
     * All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
     * 
     */
    @Export(name="effectiveLabels", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> effectiveLabels;

    /**
     * @return All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
     * 
     */
    public Output<Map<String,String>> effectiveLabels() {
        return this.effectiveLabels;
    }
    /**
     * User-supplied key-value pairs used to organize Pipeline Jobs.
     * Label keys must be between 1 and 63 characters long, have a UTF-8 encoding of
     * maximum 128 bytes, and must conform to the following PCRE regular expression:
     * [\p{Ll}\p{Lo}][\p{Ll}\p{Lo}\p{N}_-]{0,62}
     * Label values are optional, must be between 1 and 63 characters long, have a
     * UTF-8 encoding of maximum 128 bytes, and must conform to the following PCRE
     * regular expression: [\p{Ll}\p{Lo}\p{N}_-]{0,63}
     * No more than 64 labels can be associated with a given pipeline.
     * An object containing a list of &#34;key&#34;: value pairs.
     * Example: { &#34;name&#34;: &#34;wrench&#34;, &#34;mass&#34;: &#34;1.3kg&#34;, &#34;count&#34;: &#34;3&#34; }.
     * 
     * **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
     * Please refer to the field `effective_labels` for all of the labels present on the resource.
     * 
     */
    @Export(name="labels", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> labels;

    /**
     * @return User-supplied key-value pairs used to organize Pipeline Jobs.
     * Label keys must be between 1 and 63 characters long, have a UTF-8 encoding of
     * maximum 128 bytes, and must conform to the following PCRE regular expression:
     * [\p{Ll}\p{Lo}][\p{Ll}\p{Lo}\p{N}_-]{0,62}
     * Label values are optional, must be between 1 and 63 characters long, have a
     * UTF-8 encoding of maximum 128 bytes, and must conform to the following PCRE
     * regular expression: [\p{Ll}\p{Lo}\p{N}_-]{0,63}
     * No more than 64 labels can be associated with a given pipeline.
     * An object containing a list of &#34;key&#34;: value pairs.
     * Example: { &#34;name&#34;: &#34;wrench&#34;, &#34;mass&#34;: &#34;1.3kg&#34;, &#34;count&#34;: &#34;3&#34; }.
     * 
     * **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
     * Please refer to the field `effective_labels` for all of the labels present on the resource.
     * 
     */
    public Output<Optional<Map<String,String>>> labels() {
        return Codegen.optional(this.labels);
    }
    /**
     * Location where the Pipeline Job is to run
     * 
     */
    @Export(name="location", refs={String.class}, tree="[0]")
    private Output<String> location;

    /**
     * @return Location where the Pipeline Job is to run
     * 
     */
    public Output<String> location() {
        return this.location;
    }
    /**
     * Specifies mapping configuration.
     * Structure is documented below.
     * 
     */
    @Export(name="mappingPipelineJob", refs={PipelineJobMappingPipelineJob.class}, tree="[0]")
    private Output</* @Nullable */ PipelineJobMappingPipelineJob> mappingPipelineJob;

    /**
     * @return Specifies mapping configuration.
     * Structure is documented below.
     * 
     */
    public Output<Optional<PipelineJobMappingPipelineJob>> mappingPipelineJob() {
        return Codegen.optional(this.mappingPipelineJob);
    }
    /**
     * Specifies the name of the pipeline job. This field is user-assigned.
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return Specifies the name of the pipeline job. This field is user-assigned.
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * The combination of labels configured directly on the resource
     * and default labels configured on the provider.
     * 
     */
    @Export(name="pulumiLabels", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> pulumiLabels;

    /**
     * @return The combination of labels configured directly on the resource
     * and default labels configured on the provider.
     * 
     */
    public Output<Map<String,String>> pulumiLabels() {
        return this.pulumiLabels;
    }
    /**
     * Specifies reconciliation configuration.
     * Structure is documented below.
     * 
     */
    @Export(name="reconciliationPipelineJob", refs={PipelineJobReconciliationPipelineJob.class}, tree="[0]")
    private Output</* @Nullable */ PipelineJobReconciliationPipelineJob> reconciliationPipelineJob;

    /**
     * @return Specifies reconciliation configuration.
     * Structure is documented below.
     * 
     */
    public Output<Optional<PipelineJobReconciliationPipelineJob>> reconciliationPipelineJob() {
        return Codegen.optional(this.reconciliationPipelineJob);
    }
    /**
     * The fully qualified name of this dataset
     * 
     */
    @Export(name="selfLink", refs={String.class}, tree="[0]")
    private Output<String> selfLink;

    /**
     * @return The fully qualified name of this dataset
     * 
     */
    public Output<String> selfLink() {
        return this.selfLink;
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public PipelineJob(java.lang.String name) {
        this(name, PipelineJobArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public PipelineJob(java.lang.String name, PipelineJobArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public PipelineJob(java.lang.String name, PipelineJobArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:healthcare/pipelineJob:PipelineJob", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private PipelineJob(java.lang.String name, Output<java.lang.String> id, @Nullable PipelineJobState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:healthcare/pipelineJob:PipelineJob", name, state, makeResourceOptions(options, id), false);
    }

    private static PipelineJobArgs makeArgs(PipelineJobArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? PipelineJobArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .additionalSecretOutputs(List.of(
                "effectiveLabels",
                "pulumiLabels"
            ))
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static PipelineJob get(java.lang.String name, Output<java.lang.String> id, @Nullable PipelineJobState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new PipelineJob(name, id, state, options);
    }
}
