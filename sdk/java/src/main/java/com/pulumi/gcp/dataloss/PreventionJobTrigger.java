// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.gcp.dataloss;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.gcp.Utilities;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerState;
import com.pulumi.gcp.dataloss.outputs.PreventionJobTriggerInspectJob;
import com.pulumi.gcp.dataloss.outputs.PreventionJobTriggerTrigger;
import java.lang.String;
import java.util.List;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * A job trigger configuration.
 * 
 * To get more information about JobTrigger, see:
 * 
 * * [API documentation](https://cloud.google.com/dlp/docs/reference/rest/v2/projects.jobTriggers)
 * * How-to Guides
 *     * [Official Documentation](https://cloud.google.com/dlp/docs/creating-job-triggers)
 * 
 * ## Example Usage
 * ### Dlp Job Trigger Basic
 * ```java
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.dataloss.PreventionJobTrigger;
 * import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var basic = new PreventionJobTrigger(&#34;basic&#34;, PreventionJobTriggerArgs.builder()        
 *             .description(&#34;Description&#34;)
 *             .displayName(&#34;Displayname&#34;)
 *             .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
 *                 .actions(PreventionJobTriggerInspectJobActionArgs.builder()
 *                     .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
 *                         .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
 *                             .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
 *                                 .datasetId(&#34;dataset&#34;)
 *                                 .projectId(&#34;project&#34;)
 *                                 .build())
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .inspectTemplateName(&#34;fake&#34;)
 *                 .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
 *                     .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
 *                         .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
 *                             .url(&#34;gs://mybucket/directory/&#34;)
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .parent(&#34;projects/my-project-name&#34;)
 *             .triggers(PreventionJobTriggerTriggerArgs.builder()
 *                 .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
 *                     .recurrencePeriodDuration(&#34;86400s&#34;)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * ```
 * ### Dlp Job Trigger Bigquery Row Limit
 * ```java
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.dataloss.PreventionJobTrigger;
 * import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var bigqueryRowLimit = new PreventionJobTrigger(&#34;bigqueryRowLimit&#34;, PreventionJobTriggerArgs.builder()        
 *             .description(&#34;Description&#34;)
 *             .displayName(&#34;Displayname&#34;)
 *             .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
 *                 .actions(PreventionJobTriggerInspectJobActionArgs.builder()
 *                     .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
 *                         .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
 *                             .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
 *                                 .datasetId(&#34;dataset&#34;)
 *                                 .projectId(&#34;project&#34;)
 *                                 .build())
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .inspectTemplateName(&#34;fake&#34;)
 *                 .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
 *                     .bigQueryOptions(PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs.builder()
 *                         .rowsLimit(1000)
 *                         .sampleMethod(&#34;RANDOM_START&#34;)
 *                         .tableReference(PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs.builder()
 *                             .datasetId(&#34;dataset&#34;)
 *                             .projectId(&#34;project&#34;)
 *                             .tableId(&#34;table_to_scan&#34;)
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .parent(&#34;projects/my-project-name&#34;)
 *             .triggers(PreventionJobTriggerTriggerArgs.builder()
 *                 .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
 *                     .recurrencePeriodDuration(&#34;86400s&#34;)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * ```
 * ### Dlp Job Trigger Bigquery Row Limit Percentage
 * ```java
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.dataloss.PreventionJobTrigger;
 * import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var bigqueryRowLimitPercentage = new PreventionJobTrigger(&#34;bigqueryRowLimitPercentage&#34;, PreventionJobTriggerArgs.builder()        
 *             .description(&#34;Description&#34;)
 *             .displayName(&#34;Displayname&#34;)
 *             .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
 *                 .actions(PreventionJobTriggerInspectJobActionArgs.builder()
 *                     .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
 *                         .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
 *                             .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
 *                                 .datasetId(&#34;dataset&#34;)
 *                                 .projectId(&#34;project&#34;)
 *                                 .build())
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .inspectTemplateName(&#34;fake&#34;)
 *                 .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
 *                     .bigQueryOptions(PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs.builder()
 *                         .rowsLimitPercent(50)
 *                         .sampleMethod(&#34;RANDOM_START&#34;)
 *                         .tableReference(PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs.builder()
 *                             .datasetId(&#34;dataset&#34;)
 *                             .projectId(&#34;project&#34;)
 *                             .tableId(&#34;table_to_scan&#34;)
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .parent(&#34;projects/my-project-name&#34;)
 *             .triggers(PreventionJobTriggerTriggerArgs.builder()
 *                 .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
 *                     .recurrencePeriodDuration(&#34;86400s&#34;)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * ```
 * ### Dlp Job Trigger Job Notification Emails
 * ```java
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.dataloss.PreventionJobTrigger;
 * import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var jobNotificationEmails = new PreventionJobTrigger(&#34;jobNotificationEmails&#34;, PreventionJobTriggerArgs.builder()        
 *             .description(&#34;Description for the job_trigger created by terraform&#34;)
 *             .displayName(&#34;TerraformDisplayName&#34;)
 *             .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
 *                 .actions(PreventionJobTriggerInspectJobActionArgs.builder()
 *                     .jobNotificationEmails()
 *                     .build())
 *                 .inspectTemplateName(&#34;sample-inspect-template&#34;)
 *                 .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
 *                     .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
 *                         .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
 *                             .url(&#34;gs://mybucket/directory/&#34;)
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .parent(&#34;projects/my-project-name&#34;)
 *             .triggers(PreventionJobTriggerTriggerArgs.builder()
 *                 .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
 *                     .recurrencePeriodDuration(&#34;86400s&#34;)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * ```
 * ### Dlp Job Trigger Deidentify
 * ```java
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.bigquery.Dataset;
 * import com.pulumi.gcp.bigquery.DatasetArgs;
 * import com.pulumi.gcp.bigquery.Table;
 * import com.pulumi.gcp.bigquery.TableArgs;
 * import com.pulumi.gcp.bigquery.inputs.TableTimePartitioningArgs;
 * import com.pulumi.gcp.dataloss.PreventionJobTrigger;
 * import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var defaultDataset = new Dataset(&#34;defaultDataset&#34;, DatasetArgs.builder()        
 *             .datasetId(&#34;tf_test&#34;)
 *             .friendlyName(&#34;terraform-test&#34;)
 *             .description(&#34;Description for the dataset created by terraform&#34;)
 *             .location(&#34;US&#34;)
 *             .defaultTableExpirationMs(3600000)
 *             .labels(Map.of(&#34;env&#34;, &#34;default&#34;))
 *             .build());
 * 
 *         var defaultTable = new Table(&#34;defaultTable&#34;, TableArgs.builder()        
 *             .datasetId(defaultDataset.datasetId())
 *             .tableId(&#34;tf_test&#34;)
 *             .deletionProtection(false)
 *             .timePartitioning(TableTimePartitioningArgs.builder()
 *                 .type(&#34;DAY&#34;)
 *                 .build())
 *             .labels(Map.of(&#34;env&#34;, &#34;default&#34;))
 *             .schema(&#34;&#34;&#34;
 *     [
 *     {
 *       &#34;name&#34;: &#34;quantity&#34;,
 *       &#34;type&#34;: &#34;NUMERIC&#34;,
 *       &#34;mode&#34;: &#34;NULLABLE&#34;,
 *       &#34;description&#34;: &#34;The quantity&#34;
 *     },
 *     {
 *       &#34;name&#34;: &#34;name&#34;,
 *       &#34;type&#34;: &#34;STRING&#34;,
 *       &#34;mode&#34;: &#34;NULLABLE&#34;,
 *       &#34;description&#34;: &#34;Name of the object&#34;
 *     }
 *     ]
 *             &#34;&#34;&#34;)
 *             .build());
 * 
 *         var deidentify = new PreventionJobTrigger(&#34;deidentify&#34;, PreventionJobTriggerArgs.builder()        
 *             .parent(&#34;projects/my-project-name&#34;)
 *             .description(&#34;Description for the job_trigger created by terraform&#34;)
 *             .displayName(&#34;TerraformDisplayName&#34;)
 *             .triggers(PreventionJobTriggerTriggerArgs.builder()
 *                 .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
 *                     .recurrencePeriodDuration(&#34;86400s&#34;)
 *                     .build())
 *                 .build())
 *             .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
 *                 .inspectTemplateName(&#34;sample-inspect-template&#34;)
 *                 .actions(PreventionJobTriggerInspectJobActionArgs.builder()
 *                     .deidentify(PreventionJobTriggerInspectJobActionDeidentifyArgs.builder()
 *                         .cloudStorageOutput(&#34;gs://samplebucket/dir/&#34;)
 *                         .fileTypesToTransforms(                        
 *                             &#34;CSV&#34;,
 *                             &#34;TSV&#34;)
 *                         .transformationDetailsStorageConfig(PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigArgs.builder()
 *                             .table(PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigTableArgs.builder()
 *                                 .projectId(&#34;my-project-name&#34;)
 *                                 .datasetId(defaultDataset.datasetId())
 *                                 .tableId(defaultTable.tableId())
 *                                 .build())
 *                             .build())
 *                         .transformationConfig(PreventionJobTriggerInspectJobActionDeidentifyTransformationConfigArgs.builder()
 *                             .deidentifyTemplate(&#34;sample-deidentify-template&#34;)
 *                             .imageRedactTemplate(&#34;sample-image-redact-template&#34;)
 *                             .structuredDeidentifyTemplate(&#34;sample-structured-deidentify-template&#34;)
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
 *                     .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
 *                         .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
 *                             .url(&#34;gs://mybucket/directory/&#34;)
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * ```
 * ### Dlp Job Trigger Hybrid
 * ```java
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.dataloss.PreventionJobTrigger;
 * import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigHybridOptionsArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerManualArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var hybridTrigger = new PreventionJobTrigger(&#34;hybridTrigger&#34;, PreventionJobTriggerArgs.builder()        
 *             .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
 *                 .actions(PreventionJobTriggerInspectJobActionArgs.builder()
 *                     .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
 *                         .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
 *                             .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
 *                                 .datasetId(&#34;dataset&#34;)
 *                                 .projectId(&#34;project&#34;)
 *                                 .build())
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .inspectTemplateName(&#34;fake&#34;)
 *                 .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
 *                     .hybridOptions(PreventionJobTriggerInspectJobStorageConfigHybridOptionsArgs.builder()
 *                         .description(&#34;Hybrid job trigger for data from the comments field of a table that contains customer appointment bookings&#34;)
 *                         .labels(Map.of(&#34;env&#34;, &#34;prod&#34;))
 *                         .requiredFindingLabelKeys(&#34;appointment-bookings-comments&#34;)
 *                         .tableOptions(PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsArgs.builder()
 *                             .identifyingFields(PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsIdentifyingFieldArgs.builder()
 *                                 .name(&#34;booking_id&#34;)
 *                                 .build())
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .parent(&#34;projects/my-project-name&#34;)
 *             .triggers(PreventionJobTriggerTriggerArgs.builder()
 *                 .manual()
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * ```
 * ### Dlp Job Trigger Inspect
 * 
 * ```java
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.dataloss.PreventionJobTrigger;
 * import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobInspectConfigArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobInspectConfigLimitsArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var inspect = new PreventionJobTrigger(&#34;inspect&#34;, PreventionJobTriggerArgs.builder()        
 *             .description(&#34;Description&#34;)
 *             .displayName(&#34;Displayname&#34;)
 *             .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
 *                 .actions(PreventionJobTriggerInspectJobActionArgs.builder()
 *                     .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
 *                         .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
 *                             .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
 *                                 .datasetId(&#34;dataset&#34;)
 *                                 .projectId(&#34;project&#34;)
 *                                 .build())
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .inspectConfig(PreventionJobTriggerInspectJobInspectConfigArgs.builder()
 *                     .customInfoTypes(PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeArgs.builder()
 *                         .infoType(PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypeArgs.builder()
 *                             .name(&#34;MY_CUSTOM_TYPE&#34;)
 *                             .build())
 *                         .likelihood(&#34;UNLIKELY&#34;)
 *                         .regex(PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeRegexArgs.builder()
 *                             .pattern(&#34;test*&#34;)
 *                             .build())
 *                         .build())
 *                     .infoTypes(PreventionJobTriggerInspectJobInspectConfigInfoTypeArgs.builder()
 *                         .name(&#34;EMAIL_ADDRESS&#34;)
 *                         .build())
 *                     .limits(PreventionJobTriggerInspectJobInspectConfigLimitsArgs.builder()
 *                         .maxFindingsPerItem(10)
 *                         .maxFindingsPerRequest(50)
 *                         .build())
 *                     .minLikelihood(&#34;UNLIKELY&#34;)
 *                     .ruleSet(                    
 *                         %!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference),
 *                         %!v(PANIC=Format method: runtime error: invalid memory address or nil pointer dereference))
 *                     .build())
 *                 .inspectTemplateName(&#34;fake&#34;)
 *                 .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
 *                     .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
 *                         .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
 *                             .url(&#34;gs://mybucket/directory/&#34;)
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .parent(&#34;projects/my-project-name&#34;)
 *             .triggers(PreventionJobTriggerTriggerArgs.builder()
 *                 .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
 *                     .recurrencePeriodDuration(&#34;86400s&#34;)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * ```
 * ### Dlp Job Trigger Publish To Stackdriver
 * ```java
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.dataloss.PreventionJobTrigger;
 * import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var publishToStackdriver = new PreventionJobTrigger(&#34;publishToStackdriver&#34;, PreventionJobTriggerArgs.builder()        
 *             .description(&#34;Description for the job_trigger created by terraform&#34;)
 *             .displayName(&#34;TerraformDisplayName&#34;)
 *             .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
 *                 .actions(PreventionJobTriggerInspectJobActionArgs.builder()
 *                     .publishToStackdriver()
 *                     .build())
 *                 .inspectTemplateName(&#34;sample-inspect-template&#34;)
 *                 .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
 *                     .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
 *                         .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
 *                             .url(&#34;gs://mybucket/directory/&#34;)
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .parent(&#34;projects/my-project-name&#34;)
 *             .triggers(PreventionJobTriggerTriggerArgs.builder()
 *                 .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
 *                     .recurrencePeriodDuration(&#34;86400s&#34;)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * ```
 * ### Dlp Job Trigger With Id
 * ```java
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.gcp.dataloss.PreventionJobTrigger;
 * import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
 * import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var withTriggerId = new PreventionJobTrigger(&#34;withTriggerId&#34;, PreventionJobTriggerArgs.builder()        
 *             .description(&#34;Starting description&#34;)
 *             .displayName(&#34;display&#34;)
 *             .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
 *                 .actions(PreventionJobTriggerInspectJobActionArgs.builder()
 *                     .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
 *                         .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
 *                             .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
 *                                 .datasetId(&#34;dataset123&#34;)
 *                                 .projectId(&#34;project&#34;)
 *                                 .build())
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .inspectTemplateName(&#34;fake&#34;)
 *                 .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
 *                     .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
 *                         .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
 *                             .url(&#34;gs://mybucket/directory/&#34;)
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .parent(&#34;projects/my-project-name&#34;)
 *             .triggerId(&#34;id-&#34;)
 *             .triggers(PreventionJobTriggerTriggerArgs.builder()
 *                 .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
 *                     .recurrencePeriodDuration(&#34;86400s&#34;)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * ```
 * 
 * ## Import
 * 
 * JobTrigger can be imported using any of these accepted formats
 * 
 * ```sh
 *  $ pulumi import gcp:dataloss/preventionJobTrigger:PreventionJobTrigger default {{parent}}/jobTriggers/{{name}}
 * ```
 * 
 * ```sh
 *  $ pulumi import gcp:dataloss/preventionJobTrigger:PreventionJobTrigger default {{parent}}/{{name}}
 * ```
 * 
 */
@ResourceType(type="gcp:dataloss/preventionJobTrigger:PreventionJobTrigger")
public class PreventionJobTrigger extends com.pulumi.resources.CustomResource {
    /**
     * (Output)
     * The creation timestamp of an inspectTemplate. Set by the server.
     * 
     */
    @Export(name="createTime", type=String.class, parameters={})
    private Output<String> createTime;

    /**
     * @return (Output)
     * The creation timestamp of an inspectTemplate. Set by the server.
     * 
     */
    public Output<String> createTime() {
        return this.createTime;
    }
    /**
     * A description of the job trigger.
     * 
     * (Optional)
     * A short description of where the data is coming from. Will be stored once in the job. 256 max length.
     * 
     */
    @Export(name="description", type=String.class, parameters={})
    private Output</* @Nullable */ String> description;

    /**
     * @return A description of the job trigger.
     * 
     * (Optional)
     * A short description of where the data is coming from. Will be stored once in the job. 256 max length.
     * 
     */
    public Output<Optional<String>> description() {
        return Codegen.optional(this.description);
    }
    /**
     * User set display name of the job trigger.
     * 
     */
    @Export(name="displayName", type=String.class, parameters={})
    private Output</* @Nullable */ String> displayName;

    /**
     * @return User set display name of the job trigger.
     * 
     */
    public Output<Optional<String>> displayName() {
        return Codegen.optional(this.displayName);
    }
    /**
     * Controls what and how to inspect for findings.
     * Structure is documented below.
     * 
     */
    @Export(name="inspectJob", type=PreventionJobTriggerInspectJob.class, parameters={})
    private Output</* @Nullable */ PreventionJobTriggerInspectJob> inspectJob;

    /**
     * @return Controls what and how to inspect for findings.
     * Structure is documented below.
     * 
     */
    public Output<Optional<PreventionJobTriggerInspectJob>> inspectJob() {
        return Codegen.optional(this.inspectJob);
    }
    /**
     * The timestamp of the last time this trigger executed.
     * 
     */
    @Export(name="lastRunTime", type=String.class, parameters={})
    private Output<String> lastRunTime;

    /**
     * @return The timestamp of the last time this trigger executed.
     * 
     */
    public Output<String> lastRunTime() {
        return this.lastRunTime;
    }
    /**
     * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
     * at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
     * 
     * (Required)
     * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
     * at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
     * 
     * (Required)
     * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
     * at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
     * 
     * (Required)
     * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
     * at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
     * 
     * (Required)
     * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names
     * listed at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
     * 
     * (Required)
     * Resource name of the requested StoredInfoType, for example `organizations/433245324/storedInfoTypes/432452342`
     * or `projects/project-id/storedInfoTypes/432452342`.
     * 
     * (Required)
     * Specification of the field containing the timestamp of scanned items. Used for data sources like Datastore and BigQuery.
     * For BigQuery: Required to filter out rows based on the given start and end times. If not specified and the table was
     * modified between the given start and end times, the entire table will be scanned. The valid data types of the timestamp
     * field are: INTEGER, DATE, TIMESTAMP, or DATETIME BigQuery column.
     * For Datastore. Valid data types of the timestamp field are: TIMESTAMP. Datastore entity will be scanned if the
     * timestamp property does not exist or its value is empty or invalid.
     * 
     * (Required)
     * The name of the Datastore kind.
     * 
     * (Required)
     * Name of a BigQuery field to be returned with the findings.
     * 
     * (Required)
     * Name describing the field to which scanning is limited.
     * 
     * (Required)
     * Name describing the field excluded from scanning.
     * 
     * (Required)
     * Name describing the field.
     * 
     */
    @Export(name="name", type=String.class, parameters={})
    private Output<String> name;

    /**
     * @return Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
     * at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
     * 
     * (Required)
     * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
     * at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
     * 
     * (Required)
     * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
     * at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
     * 
     * (Required)
     * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
     * at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
     * 
     * (Required)
     * Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names
     * listed at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
     * 
     * (Required)
     * Resource name of the requested StoredInfoType, for example `organizations/433245324/storedInfoTypes/432452342`
     * or `projects/project-id/storedInfoTypes/432452342`.
     * 
     * (Required)
     * Specification of the field containing the timestamp of scanned items. Used for data sources like Datastore and BigQuery.
     * For BigQuery: Required to filter out rows based on the given start and end times. If not specified and the table was
     * modified between the given start and end times, the entire table will be scanned. The valid data types of the timestamp
     * field are: INTEGER, DATE, TIMESTAMP, or DATETIME BigQuery column.
     * For Datastore. Valid data types of the timestamp field are: TIMESTAMP. Datastore entity will be scanned if the
     * timestamp property does not exist or its value is empty or invalid.
     * 
     * (Required)
     * The name of the Datastore kind.
     * 
     * (Required)
     * Name of a BigQuery field to be returned with the findings.
     * 
     * (Required)
     * Name describing the field to which scanning is limited.
     * 
     * (Required)
     * Name describing the field excluded from scanning.
     * 
     * (Required)
     * Name describing the field.
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * The parent of the trigger, either in the format `projects/{{project}}`
     * or `projects/{{project}}/locations/{{location}}`
     * 
     */
    @Export(name="parent", type=String.class, parameters={})
    private Output<String> parent;

    /**
     * @return The parent of the trigger, either in the format `projects/{{project}}`
     * or `projects/{{project}}/locations/{{location}}`
     * 
     */
    public Output<String> parent() {
        return this.parent;
    }
    /**
     * Whether the trigger is currently active.
     * Default value is `HEALTHY`.
     * Possible values are: `PAUSED`, `HEALTHY`, `CANCELLED`.
     * 
     */
    @Export(name="status", type=String.class, parameters={})
    private Output</* @Nullable */ String> status;

    /**
     * @return Whether the trigger is currently active.
     * Default value is `HEALTHY`.
     * Possible values are: `PAUSED`, `HEALTHY`, `CANCELLED`.
     * 
     */
    public Output<Optional<String>> status() {
        return Codegen.optional(this.status);
    }
    /**
     * The trigger id can contain uppercase and lowercase letters, numbers, and hyphens;
     * that is, it must match the regular expression: [a-zA-Z\d-_]+.
     * The maximum length is 100 characters. Can be empty to allow the system to generate one.
     * 
     */
    @Export(name="triggerId", type=String.class, parameters={})
    private Output<String> triggerId;

    /**
     * @return The trigger id can contain uppercase and lowercase letters, numbers, and hyphens;
     * that is, it must match the regular expression: [a-zA-Z\d-_]+.
     * The maximum length is 100 characters. Can be empty to allow the system to generate one.
     * 
     */
    public Output<String> triggerId() {
        return this.triggerId;
    }
    /**
     * What event needs to occur for a new job to be started.
     * Structure is documented below.
     * 
     */
    @Export(name="triggers", type=List.class, parameters={PreventionJobTriggerTrigger.class})
    private Output<List<PreventionJobTriggerTrigger>> triggers;

    /**
     * @return What event needs to occur for a new job to be started.
     * Structure is documented below.
     * 
     */
    public Output<List<PreventionJobTriggerTrigger>> triggers() {
        return this.triggers;
    }
    /**
     * The last update timestamp of an inspectTemplate. Set by the server.
     * 
     */
    @Export(name="updateTime", type=String.class, parameters={})
    private Output<String> updateTime;

    /**
     * @return The last update timestamp of an inspectTemplate. Set by the server.
     * 
     */
    public Output<String> updateTime() {
        return this.updateTime;
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public PreventionJobTrigger(String name) {
        this(name, PreventionJobTriggerArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public PreventionJobTrigger(String name, PreventionJobTriggerArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public PreventionJobTrigger(String name, PreventionJobTriggerArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:dataloss/preventionJobTrigger:PreventionJobTrigger", name, args == null ? PreventionJobTriggerArgs.Empty : args, makeResourceOptions(options, Codegen.empty()));
    }

    private PreventionJobTrigger(String name, Output<String> id, @Nullable PreventionJobTriggerState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("gcp:dataloss/preventionJobTrigger:PreventionJobTrigger", name, state, makeResourceOptions(options, id));
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static PreventionJobTrigger get(String name, Output<String> id, @Nullable PreventionJobTriggerState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new PreventionJobTrigger(name, id, state, options);
    }
}
