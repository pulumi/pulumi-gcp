# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins
import copy
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities
from . import outputs
from ._inputs import *

__all__ = ['AiEndpointArgs', 'AiEndpoint']

@pulumi.input_type
class AiEndpointArgs:
    def __init__(__self__, *,
                 display_name: pulumi.Input[builtins.str],
                 location: pulumi.Input[builtins.str],
                 dedicated_endpoint_enabled: Optional[pulumi.Input[builtins.bool]] = None,
                 description: Optional[pulumi.Input[builtins.str]] = None,
                 encryption_spec: Optional[pulumi.Input['AiEndpointEncryptionSpecArgs']] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 name: Optional[pulumi.Input[builtins.str]] = None,
                 network: Optional[pulumi.Input[builtins.str]] = None,
                 predict_request_response_logging_config: Optional[pulumi.Input['AiEndpointPredictRequestResponseLoggingConfigArgs']] = None,
                 private_service_connect_config: Optional[pulumi.Input['AiEndpointPrivateServiceConnectConfigArgs']] = None,
                 project: Optional[pulumi.Input[builtins.str]] = None,
                 region: Optional[pulumi.Input[builtins.str]] = None,
                 traffic_split: Optional[pulumi.Input[builtins.str]] = None):
        """
        The set of arguments for constructing a AiEndpoint resource.
        :param pulumi.Input[builtins.str] display_name: Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        :param pulumi.Input[builtins.str] location: The location for the resource
               
               
               - - -
        :param pulumi.Input[builtins.bool] dedicated_endpoint_enabled: If true, the endpoint will be exposed through a dedicated DNS [Endpoint.dedicated_endpoint_dns]. Your request to the dedicated DNS will be isolated from other users' traffic and will have better performance and reliability. Note: Once you enabled dedicated endpoint, you won't be able to send request to the shared DNS {region}-aiplatform.googleapis.com. The limitation will be removed soon.
        :param pulumi.Input[builtins.str] description: The description of the Endpoint.
        :param pulumi.Input['AiEndpointEncryptionSpecArgs'] encryption_spec: Customer-managed encryption key spec for an Endpoint. If set, this Endpoint and all sub-resources of this Endpoint will be secured by this key.
               Structure is documented below.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] labels: The labels with user-defined metadata to organize your Endpoints. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
               **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
               Please refer to the field `effective_labels` for all of the labels present on the resource.
        :param pulumi.Input[builtins.str] name: The resource name of the Endpoint. The name must be numeric with no leading zeros and can be at most 10 digits.
        :param pulumi.Input[builtins.str] network: The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks) to which the Endpoint should be peered. Private services access must already be configured for the network. If left unspecified, the Endpoint is not peered with any network. Only one of the fields, network or enable_private_service_connect, can be set. [Format](https://cloud.google.com/compute/docs/reference/rest/v1/networks/insert): `projects/{project}/global/networks/{network}`. Where `{project}` is a project number, as in `12345`, and `{network}` is network name. Only one of the fields, `network` or `privateServiceConnectConfig`, can be set.
        :param pulumi.Input['AiEndpointPredictRequestResponseLoggingConfigArgs'] predict_request_response_logging_config: Configures the request-response logging for online prediction.
               Structure is documented below.
        :param pulumi.Input['AiEndpointPrivateServiceConnectConfigArgs'] private_service_connect_config: Configuration for private service connect. `network` and `privateServiceConnectConfig` are mutually exclusive.
               Structure is documented below.
        :param pulumi.Input[builtins.str] project: The ID of the project in which the resource belongs.
               If it is not provided, the provider project is used.
        :param pulumi.Input[builtins.str] region: The region for the resource
        :param pulumi.Input[builtins.str] traffic_split: A map from a DeployedModel's id to the percentage of this Endpoint's traffic that should be forwarded to that DeployedModel.
               If a DeployedModel's id is not listed in this map, then it receives no traffic.
               The traffic percentage values must add up to 100, or map must be empty if the Endpoint is to not accept any traffic at a moment. See
               the `deployModel` [example](https://cloud.google.com/vertex-ai/docs/general/deployment#deploy_a_model_to_an_endpoint) and
               [documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/deployModel) for more information.
               > **Note:** To set the map to empty, set `"{}"`, apply, and then remove the field from your config.
        """
        pulumi.set(__self__, "display_name", display_name)
        pulumi.set(__self__, "location", location)
        if dedicated_endpoint_enabled is not None:
            pulumi.set(__self__, "dedicated_endpoint_enabled", dedicated_endpoint_enabled)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if encryption_spec is not None:
            pulumi.set(__self__, "encryption_spec", encryption_spec)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if network is not None:
            pulumi.set(__self__, "network", network)
        if predict_request_response_logging_config is not None:
            pulumi.set(__self__, "predict_request_response_logging_config", predict_request_response_logging_config)
        if private_service_connect_config is not None:
            pulumi.set(__self__, "private_service_connect_config", private_service_connect_config)
        if project is not None:
            pulumi.set(__self__, "project", project)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if traffic_split is not None:
            pulumi.set(__self__, "traffic_split", traffic_split)

    @property
    @pulumi.getter(name="displayName")
    def display_name(self) -> pulumi.Input[builtins.str]:
        """
        Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        """
        return pulumi.get(self, "display_name")

    @display_name.setter
    def display_name(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "display_name", value)

    @property
    @pulumi.getter
    def location(self) -> pulumi.Input[builtins.str]:
        """
        The location for the resource


        - - -
        """
        return pulumi.get(self, "location")

    @location.setter
    def location(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "location", value)

    @property
    @pulumi.getter(name="dedicatedEndpointEnabled")
    def dedicated_endpoint_enabled(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        If true, the endpoint will be exposed through a dedicated DNS [Endpoint.dedicated_endpoint_dns]. Your request to the dedicated DNS will be isolated from other users' traffic and will have better performance and reliability. Note: Once you enabled dedicated endpoint, you won't be able to send request to the shared DNS {region}-aiplatform.googleapis.com. The limitation will be removed soon.
        """
        return pulumi.get(self, "dedicated_endpoint_enabled")

    @dedicated_endpoint_enabled.setter
    def dedicated_endpoint_enabled(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "dedicated_endpoint_enabled", value)

    @property
    @pulumi.getter
    def description(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The description of the Endpoint.
        """
        return pulumi.get(self, "description")

    @description.setter
    def description(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "description", value)

    @property
    @pulumi.getter(name="encryptionSpec")
    def encryption_spec(self) -> Optional[pulumi.Input['AiEndpointEncryptionSpecArgs']]:
        """
        Customer-managed encryption key spec for an Endpoint. If set, this Endpoint and all sub-resources of this Endpoint will be secured by this key.
        Structure is documented below.
        """
        return pulumi.get(self, "encryption_spec")

    @encryption_spec.setter
    def encryption_spec(self, value: Optional[pulumi.Input['AiEndpointEncryptionSpecArgs']]):
        pulumi.set(self, "encryption_spec", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The labels with user-defined metadata to organize your Endpoints. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
        **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
        Please refer to the field `effective_labels` for all of the labels present on the resource.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The resource name of the Endpoint. The name must be numeric with no leading zeros and can be at most 10 digits.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter
    def network(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks) to which the Endpoint should be peered. Private services access must already be configured for the network. If left unspecified, the Endpoint is not peered with any network. Only one of the fields, network or enable_private_service_connect, can be set. [Format](https://cloud.google.com/compute/docs/reference/rest/v1/networks/insert): `projects/{project}/global/networks/{network}`. Where `{project}` is a project number, as in `12345`, and `{network}` is network name. Only one of the fields, `network` or `privateServiceConnectConfig`, can be set.
        """
        return pulumi.get(self, "network")

    @network.setter
    def network(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "network", value)

    @property
    @pulumi.getter(name="predictRequestResponseLoggingConfig")
    def predict_request_response_logging_config(self) -> Optional[pulumi.Input['AiEndpointPredictRequestResponseLoggingConfigArgs']]:
        """
        Configures the request-response logging for online prediction.
        Structure is documented below.
        """
        return pulumi.get(self, "predict_request_response_logging_config")

    @predict_request_response_logging_config.setter
    def predict_request_response_logging_config(self, value: Optional[pulumi.Input['AiEndpointPredictRequestResponseLoggingConfigArgs']]):
        pulumi.set(self, "predict_request_response_logging_config", value)

    @property
    @pulumi.getter(name="privateServiceConnectConfig")
    def private_service_connect_config(self) -> Optional[pulumi.Input['AiEndpointPrivateServiceConnectConfigArgs']]:
        """
        Configuration for private service connect. `network` and `privateServiceConnectConfig` are mutually exclusive.
        Structure is documented below.
        """
        return pulumi.get(self, "private_service_connect_config")

    @private_service_connect_config.setter
    def private_service_connect_config(self, value: Optional[pulumi.Input['AiEndpointPrivateServiceConnectConfigArgs']]):
        pulumi.set(self, "private_service_connect_config", value)

    @property
    @pulumi.getter
    def project(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The ID of the project in which the resource belongs.
        If it is not provided, the provider project is used.
        """
        return pulumi.get(self, "project")

    @project.setter
    def project(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "project", value)

    @property
    @pulumi.getter
    def region(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The region for the resource
        """
        return pulumi.get(self, "region")

    @region.setter
    def region(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "region", value)

    @property
    @pulumi.getter(name="trafficSplit")
    def traffic_split(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        A map from a DeployedModel's id to the percentage of this Endpoint's traffic that should be forwarded to that DeployedModel.
        If a DeployedModel's id is not listed in this map, then it receives no traffic.
        The traffic percentage values must add up to 100, or map must be empty if the Endpoint is to not accept any traffic at a moment. See
        the `deployModel` [example](https://cloud.google.com/vertex-ai/docs/general/deployment#deploy_a_model_to_an_endpoint) and
        [documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/deployModel) for more information.
        > **Note:** To set the map to empty, set `"{}"`, apply, and then remove the field from your config.
        """
        return pulumi.get(self, "traffic_split")

    @traffic_split.setter
    def traffic_split(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "traffic_split", value)


@pulumi.input_type
class _AiEndpointState:
    def __init__(__self__, *,
                 create_time: Optional[pulumi.Input[builtins.str]] = None,
                 dedicated_endpoint_dns: Optional[pulumi.Input[builtins.str]] = None,
                 dedicated_endpoint_enabled: Optional[pulumi.Input[builtins.bool]] = None,
                 deployed_models: Optional[pulumi.Input[Sequence[pulumi.Input['AiEndpointDeployedModelArgs']]]] = None,
                 description: Optional[pulumi.Input[builtins.str]] = None,
                 display_name: Optional[pulumi.Input[builtins.str]] = None,
                 effective_labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 encryption_spec: Optional[pulumi.Input['AiEndpointEncryptionSpecArgs']] = None,
                 etag: Optional[pulumi.Input[builtins.str]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 location: Optional[pulumi.Input[builtins.str]] = None,
                 model_deployment_monitoring_job: Optional[pulumi.Input[builtins.str]] = None,
                 name: Optional[pulumi.Input[builtins.str]] = None,
                 network: Optional[pulumi.Input[builtins.str]] = None,
                 predict_request_response_logging_config: Optional[pulumi.Input['AiEndpointPredictRequestResponseLoggingConfigArgs']] = None,
                 private_service_connect_config: Optional[pulumi.Input['AiEndpointPrivateServiceConnectConfigArgs']] = None,
                 project: Optional[pulumi.Input[builtins.str]] = None,
                 pulumi_labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 region: Optional[pulumi.Input[builtins.str]] = None,
                 traffic_split: Optional[pulumi.Input[builtins.str]] = None,
                 update_time: Optional[pulumi.Input[builtins.str]] = None):
        """
        Input properties used for looking up and filtering AiEndpoint resources.
        :param pulumi.Input[builtins.str] create_time: (Output)
               Output only. Timestamp when the DeployedModel was created.
        :param pulumi.Input[builtins.str] dedicated_endpoint_dns: Output only. DNS of the dedicated endpoint. Will only be populated if dedicatedEndpointEnabled is true. Format: `https://{endpointId}.{region}-{projectNumber}.prediction.vertexai.goog`.
        :param pulumi.Input[builtins.bool] dedicated_endpoint_enabled: If true, the endpoint will be exposed through a dedicated DNS [Endpoint.dedicated_endpoint_dns]. Your request to the dedicated DNS will be isolated from other users' traffic and will have better performance and reliability. Note: Once you enabled dedicated endpoint, you won't be able to send request to the shared DNS {region}-aiplatform.googleapis.com. The limitation will be removed soon.
        :param pulumi.Input[Sequence[pulumi.Input['AiEndpointDeployedModelArgs']]] deployed_models: Output only. The models deployed in this Endpoint. To add or remove DeployedModels use EndpointService.DeployModel and EndpointService.UndeployModel respectively. Models can also be deployed and undeployed using the [Cloud Console](https://console.cloud.google.com/vertex-ai/).
               Structure is documented below.
        :param pulumi.Input[builtins.str] description: The description of the Endpoint.
        :param pulumi.Input[builtins.str] display_name: Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] effective_labels: All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
        :param pulumi.Input['AiEndpointEncryptionSpecArgs'] encryption_spec: Customer-managed encryption key spec for an Endpoint. If set, this Endpoint and all sub-resources of this Endpoint will be secured by this key.
               Structure is documented below.
        :param pulumi.Input[builtins.str] etag: Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] labels: The labels with user-defined metadata to organize your Endpoints. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
               **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
               Please refer to the field `effective_labels` for all of the labels present on the resource.
        :param pulumi.Input[builtins.str] location: The location for the resource
               
               
               - - -
        :param pulumi.Input[builtins.str] model_deployment_monitoring_job: Output only. Resource name of the Model Monitoring job associated with this Endpoint if monitoring is enabled by CreateModelDeploymentMonitoringJob. Format: `projects/{project}/locations/{location}/modelDeploymentMonitoringJobs/{model_deployment_monitoring_job}`
        :param pulumi.Input[builtins.str] name: The resource name of the Endpoint. The name must be numeric with no leading zeros and can be at most 10 digits.
        :param pulumi.Input[builtins.str] network: The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks) to which the Endpoint should be peered. Private services access must already be configured for the network. If left unspecified, the Endpoint is not peered with any network. Only one of the fields, network or enable_private_service_connect, can be set. [Format](https://cloud.google.com/compute/docs/reference/rest/v1/networks/insert): `projects/{project}/global/networks/{network}`. Where `{project}` is a project number, as in `12345`, and `{network}` is network name. Only one of the fields, `network` or `privateServiceConnectConfig`, can be set.
        :param pulumi.Input['AiEndpointPredictRequestResponseLoggingConfigArgs'] predict_request_response_logging_config: Configures the request-response logging for online prediction.
               Structure is documented below.
        :param pulumi.Input['AiEndpointPrivateServiceConnectConfigArgs'] private_service_connect_config: Configuration for private service connect. `network` and `privateServiceConnectConfig` are mutually exclusive.
               Structure is documented below.
        :param pulumi.Input[builtins.str] project: The ID of the project in which the resource belongs.
               If it is not provided, the provider project is used.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] pulumi_labels: The combination of labels configured directly on the resource
               and default labels configured on the provider.
        :param pulumi.Input[builtins.str] region: The region for the resource
        :param pulumi.Input[builtins.str] traffic_split: A map from a DeployedModel's id to the percentage of this Endpoint's traffic that should be forwarded to that DeployedModel.
               If a DeployedModel's id is not listed in this map, then it receives no traffic.
               The traffic percentage values must add up to 100, or map must be empty if the Endpoint is to not accept any traffic at a moment. See
               the `deployModel` [example](https://cloud.google.com/vertex-ai/docs/general/deployment#deploy_a_model_to_an_endpoint) and
               [documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/deployModel) for more information.
               > **Note:** To set the map to empty, set `"{}"`, apply, and then remove the field from your config.
        :param pulumi.Input[builtins.str] update_time: Output only. Timestamp when this Endpoint was last updated.
        """
        if create_time is not None:
            pulumi.set(__self__, "create_time", create_time)
        if dedicated_endpoint_dns is not None:
            pulumi.set(__self__, "dedicated_endpoint_dns", dedicated_endpoint_dns)
        if dedicated_endpoint_enabled is not None:
            pulumi.set(__self__, "dedicated_endpoint_enabled", dedicated_endpoint_enabled)
        if deployed_models is not None:
            pulumi.set(__self__, "deployed_models", deployed_models)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if display_name is not None:
            pulumi.set(__self__, "display_name", display_name)
        if effective_labels is not None:
            pulumi.set(__self__, "effective_labels", effective_labels)
        if encryption_spec is not None:
            pulumi.set(__self__, "encryption_spec", encryption_spec)
        if etag is not None:
            pulumi.set(__self__, "etag", etag)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if location is not None:
            pulumi.set(__self__, "location", location)
        if model_deployment_monitoring_job is not None:
            pulumi.set(__self__, "model_deployment_monitoring_job", model_deployment_monitoring_job)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if network is not None:
            pulumi.set(__self__, "network", network)
        if predict_request_response_logging_config is not None:
            pulumi.set(__self__, "predict_request_response_logging_config", predict_request_response_logging_config)
        if private_service_connect_config is not None:
            pulumi.set(__self__, "private_service_connect_config", private_service_connect_config)
        if project is not None:
            pulumi.set(__self__, "project", project)
        if pulumi_labels is not None:
            pulumi.set(__self__, "pulumi_labels", pulumi_labels)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if traffic_split is not None:
            pulumi.set(__self__, "traffic_split", traffic_split)
        if update_time is not None:
            pulumi.set(__self__, "update_time", update_time)

    @property
    @pulumi.getter(name="createTime")
    def create_time(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        (Output)
        Output only. Timestamp when the DeployedModel was created.
        """
        return pulumi.get(self, "create_time")

    @create_time.setter
    def create_time(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "create_time", value)

    @property
    @pulumi.getter(name="dedicatedEndpointDns")
    def dedicated_endpoint_dns(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Output only. DNS of the dedicated endpoint. Will only be populated if dedicatedEndpointEnabled is true. Format: `https://{endpointId}.{region}-{projectNumber}.prediction.vertexai.goog`.
        """
        return pulumi.get(self, "dedicated_endpoint_dns")

    @dedicated_endpoint_dns.setter
    def dedicated_endpoint_dns(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "dedicated_endpoint_dns", value)

    @property
    @pulumi.getter(name="dedicatedEndpointEnabled")
    def dedicated_endpoint_enabled(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        If true, the endpoint will be exposed through a dedicated DNS [Endpoint.dedicated_endpoint_dns]. Your request to the dedicated DNS will be isolated from other users' traffic and will have better performance and reliability. Note: Once you enabled dedicated endpoint, you won't be able to send request to the shared DNS {region}-aiplatform.googleapis.com. The limitation will be removed soon.
        """
        return pulumi.get(self, "dedicated_endpoint_enabled")

    @dedicated_endpoint_enabled.setter
    def dedicated_endpoint_enabled(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "dedicated_endpoint_enabled", value)

    @property
    @pulumi.getter(name="deployedModels")
    def deployed_models(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['AiEndpointDeployedModelArgs']]]]:
        """
        Output only. The models deployed in this Endpoint. To add or remove DeployedModels use EndpointService.DeployModel and EndpointService.UndeployModel respectively. Models can also be deployed and undeployed using the [Cloud Console](https://console.cloud.google.com/vertex-ai/).
        Structure is documented below.
        """
        return pulumi.get(self, "deployed_models")

    @deployed_models.setter
    def deployed_models(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['AiEndpointDeployedModelArgs']]]]):
        pulumi.set(self, "deployed_models", value)

    @property
    @pulumi.getter
    def description(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The description of the Endpoint.
        """
        return pulumi.get(self, "description")

    @description.setter
    def description(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "description", value)

    @property
    @pulumi.getter(name="displayName")
    def display_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        """
        return pulumi.get(self, "display_name")

    @display_name.setter
    def display_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "display_name", value)

    @property
    @pulumi.getter(name="effectiveLabels")
    def effective_labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
        """
        return pulumi.get(self, "effective_labels")

    @effective_labels.setter
    def effective_labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "effective_labels", value)

    @property
    @pulumi.getter(name="encryptionSpec")
    def encryption_spec(self) -> Optional[pulumi.Input['AiEndpointEncryptionSpecArgs']]:
        """
        Customer-managed encryption key spec for an Endpoint. If set, this Endpoint and all sub-resources of this Endpoint will be secured by this key.
        Structure is documented below.
        """
        return pulumi.get(self, "encryption_spec")

    @encryption_spec.setter
    def encryption_spec(self, value: Optional[pulumi.Input['AiEndpointEncryptionSpecArgs']]):
        pulumi.set(self, "encryption_spec", value)

    @property
    @pulumi.getter
    def etag(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
        """
        return pulumi.get(self, "etag")

    @etag.setter
    def etag(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "etag", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The labels with user-defined metadata to organize your Endpoints. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
        **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
        Please refer to the field `effective_labels` for all of the labels present on the resource.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter
    def location(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The location for the resource


        - - -
        """
        return pulumi.get(self, "location")

    @location.setter
    def location(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "location", value)

    @property
    @pulumi.getter(name="modelDeploymentMonitoringJob")
    def model_deployment_monitoring_job(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Output only. Resource name of the Model Monitoring job associated with this Endpoint if monitoring is enabled by CreateModelDeploymentMonitoringJob. Format: `projects/{project}/locations/{location}/modelDeploymentMonitoringJobs/{model_deployment_monitoring_job}`
        """
        return pulumi.get(self, "model_deployment_monitoring_job")

    @model_deployment_monitoring_job.setter
    def model_deployment_monitoring_job(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "model_deployment_monitoring_job", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The resource name of the Endpoint. The name must be numeric with no leading zeros and can be at most 10 digits.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter
    def network(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks) to which the Endpoint should be peered. Private services access must already be configured for the network. If left unspecified, the Endpoint is not peered with any network. Only one of the fields, network or enable_private_service_connect, can be set. [Format](https://cloud.google.com/compute/docs/reference/rest/v1/networks/insert): `projects/{project}/global/networks/{network}`. Where `{project}` is a project number, as in `12345`, and `{network}` is network name. Only one of the fields, `network` or `privateServiceConnectConfig`, can be set.
        """
        return pulumi.get(self, "network")

    @network.setter
    def network(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "network", value)

    @property
    @pulumi.getter(name="predictRequestResponseLoggingConfig")
    def predict_request_response_logging_config(self) -> Optional[pulumi.Input['AiEndpointPredictRequestResponseLoggingConfigArgs']]:
        """
        Configures the request-response logging for online prediction.
        Structure is documented below.
        """
        return pulumi.get(self, "predict_request_response_logging_config")

    @predict_request_response_logging_config.setter
    def predict_request_response_logging_config(self, value: Optional[pulumi.Input['AiEndpointPredictRequestResponseLoggingConfigArgs']]):
        pulumi.set(self, "predict_request_response_logging_config", value)

    @property
    @pulumi.getter(name="privateServiceConnectConfig")
    def private_service_connect_config(self) -> Optional[pulumi.Input['AiEndpointPrivateServiceConnectConfigArgs']]:
        """
        Configuration for private service connect. `network` and `privateServiceConnectConfig` are mutually exclusive.
        Structure is documented below.
        """
        return pulumi.get(self, "private_service_connect_config")

    @private_service_connect_config.setter
    def private_service_connect_config(self, value: Optional[pulumi.Input['AiEndpointPrivateServiceConnectConfigArgs']]):
        pulumi.set(self, "private_service_connect_config", value)

    @property
    @pulumi.getter
    def project(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The ID of the project in which the resource belongs.
        If it is not provided, the provider project is used.
        """
        return pulumi.get(self, "project")

    @project.setter
    def project(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "project", value)

    @property
    @pulumi.getter(name="pulumiLabels")
    def pulumi_labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The combination of labels configured directly on the resource
        and default labels configured on the provider.
        """
        return pulumi.get(self, "pulumi_labels")

    @pulumi_labels.setter
    def pulumi_labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "pulumi_labels", value)

    @property
    @pulumi.getter
    def region(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The region for the resource
        """
        return pulumi.get(self, "region")

    @region.setter
    def region(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "region", value)

    @property
    @pulumi.getter(name="trafficSplit")
    def traffic_split(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        A map from a DeployedModel's id to the percentage of this Endpoint's traffic that should be forwarded to that DeployedModel.
        If a DeployedModel's id is not listed in this map, then it receives no traffic.
        The traffic percentage values must add up to 100, or map must be empty if the Endpoint is to not accept any traffic at a moment. See
        the `deployModel` [example](https://cloud.google.com/vertex-ai/docs/general/deployment#deploy_a_model_to_an_endpoint) and
        [documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/deployModel) for more information.
        > **Note:** To set the map to empty, set `"{}"`, apply, and then remove the field from your config.
        """
        return pulumi.get(self, "traffic_split")

    @traffic_split.setter
    def traffic_split(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "traffic_split", value)

    @property
    @pulumi.getter(name="updateTime")
    def update_time(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Output only. Timestamp when this Endpoint was last updated.
        """
        return pulumi.get(self, "update_time")

    @update_time.setter
    def update_time(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "update_time", value)


@pulumi.type_token("gcp:vertex/aiEndpoint:AiEndpoint")
class AiEndpoint(pulumi.CustomResource):
    @overload
    def __init__(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 dedicated_endpoint_enabled: Optional[pulumi.Input[builtins.bool]] = None,
                 description: Optional[pulumi.Input[builtins.str]] = None,
                 display_name: Optional[pulumi.Input[builtins.str]] = None,
                 encryption_spec: Optional[pulumi.Input[Union['AiEndpointEncryptionSpecArgs', 'AiEndpointEncryptionSpecArgsDict']]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 location: Optional[pulumi.Input[builtins.str]] = None,
                 name: Optional[pulumi.Input[builtins.str]] = None,
                 network: Optional[pulumi.Input[builtins.str]] = None,
                 predict_request_response_logging_config: Optional[pulumi.Input[Union['AiEndpointPredictRequestResponseLoggingConfigArgs', 'AiEndpointPredictRequestResponseLoggingConfigArgsDict']]] = None,
                 private_service_connect_config: Optional[pulumi.Input[Union['AiEndpointPrivateServiceConnectConfigArgs', 'AiEndpointPrivateServiceConnectConfigArgsDict']]] = None,
                 project: Optional[pulumi.Input[builtins.str]] = None,
                 region: Optional[pulumi.Input[builtins.str]] = None,
                 traffic_split: Optional[pulumi.Input[builtins.str]] = None,
                 __props__=None):
        """
        Models are deployed into it, and afterwards Endpoint is called to obtain predictions and explanations.

        To get more information about Endpoint, see:

        * [API documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints)
        * How-to Guides
            * [Official Documentation](https://cloud.google.com/vertex-ai/docs)

        ## Example Usage

        ### Vertex Ai Endpoint Network

        ```python
        import pulumi
        import json
        import pulumi_gcp as gcp

        vertex_network = gcp.compute.Network("vertex_network", name="network-name")
        vertex_range = gcp.compute.GlobalAddress("vertex_range",
            name="address-name",
            purpose="VPC_PEERING",
            address_type="INTERNAL",
            prefix_length=24,
            network=vertex_network.id)
        vertex_vpc_connection = gcp.servicenetworking.Connection("vertex_vpc_connection",
            network=vertex_network.id,
            service="servicenetworking.googleapis.com",
            reserved_peering_ranges=[vertex_range.name])
        bq_dataset = gcp.bigquery.Dataset("bq_dataset",
            dataset_id="some_dataset",
            friendly_name="logging dataset",
            description="This is a dataset that requests are logged to",
            location="US",
            delete_contents_on_destroy=True)
        project = gcp.organizations.get_project()
        endpoint = gcp.vertex.AiEndpoint("endpoint",
            name="endpoint-name",
            display_name="sample-endpoint",
            description="A sample vertex endpoint",
            location="us-central1",
            region="us-central1",
            labels={
                "label-one": "value-one",
            },
            network=vertex_network.name.apply(lambda name: f"projects/{project.number}/global/networks/{name}"),
            encryption_spec={
                "kms_key_name": "kms-name",
            },
            predict_request_response_logging_config={
                "bigquery_destination": {
                    "output_uri": bq_dataset.dataset_id.apply(lambda dataset_id: f"bq://{project.project_id}.{dataset_id}.request_response_logging"),
                },
                "enabled": True,
                "sampling_rate": 0.1,
            },
            traffic_split=json.dumps({
                "12345": 100,
            }),
            opts = pulumi.ResourceOptions(depends_on=[vertex_vpc_connection]))
        crypto_key = gcp.kms.CryptoKeyIAMMember("crypto_key",
            crypto_key_id="kms-name",
            role="roles/cloudkms.cryptoKeyEncrypterDecrypter",
            member=f"serviceAccount:service-{project.number}@gcp-sa-aiplatform.iam.gserviceaccount.com")
        ```
        ### Vertex Ai Endpoint Private Service Connect

        ```python
        import pulumi
        import pulumi_gcp as gcp

        project = gcp.organizations.get_project()
        endpoint = gcp.vertex.AiEndpoint("endpoint",
            name="endpoint-name_33052",
            display_name="sample-endpoint",
            description="A sample vertex endpoint",
            location="us-central1",
            region="us-central1",
            labels={
                "label-one": "value-one",
            },
            private_service_connect_config={
                "enable_private_service_connect": True,
                "project_allowlists": [project.project_id],
                "enable_secure_private_service_connect": False,
            })
        ```
        ### Vertex Ai Endpoint Dedicated Endpoint

        ```python
        import pulumi
        import pulumi_gcp as gcp

        endpoint = gcp.vertex.AiEndpoint("endpoint",
            name="endpoint-name_3684",
            display_name="sample-endpoint",
            description="A sample vertex endpoint",
            location="us-central1",
            region="us-central1",
            labels={
                "label-one": "value-one",
            },
            dedicated_endpoint_enabled=True)
        project = gcp.organizations.get_project()
        ```

        ## Import

        Endpoint can be imported using any of these accepted formats:

        * `projects/{{project}}/locations/{{location}}/endpoints/{{name}}`

        * `{{project}}/{{location}}/{{name}}`

        * `{{location}}/{{name}}`

        When using the `pulumi import` command, Endpoint can be imported using one of the formats above. For example:

        ```sh
        $ pulumi import gcp:vertex/aiEndpoint:AiEndpoint default projects/{{project}}/locations/{{location}}/endpoints/{{name}}
        ```

        ```sh
        $ pulumi import gcp:vertex/aiEndpoint:AiEndpoint default {{project}}/{{location}}/{{name}}
        ```

        ```sh
        $ pulumi import gcp:vertex/aiEndpoint:AiEndpoint default {{location}}/{{name}}
        ```

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[builtins.bool] dedicated_endpoint_enabled: If true, the endpoint will be exposed through a dedicated DNS [Endpoint.dedicated_endpoint_dns]. Your request to the dedicated DNS will be isolated from other users' traffic and will have better performance and reliability. Note: Once you enabled dedicated endpoint, you won't be able to send request to the shared DNS {region}-aiplatform.googleapis.com. The limitation will be removed soon.
        :param pulumi.Input[builtins.str] description: The description of the Endpoint.
        :param pulumi.Input[builtins.str] display_name: Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        :param pulumi.Input[Union['AiEndpointEncryptionSpecArgs', 'AiEndpointEncryptionSpecArgsDict']] encryption_spec: Customer-managed encryption key spec for an Endpoint. If set, this Endpoint and all sub-resources of this Endpoint will be secured by this key.
               Structure is documented below.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] labels: The labels with user-defined metadata to organize your Endpoints. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
               **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
               Please refer to the field `effective_labels` for all of the labels present on the resource.
        :param pulumi.Input[builtins.str] location: The location for the resource
               
               
               - - -
        :param pulumi.Input[builtins.str] name: The resource name of the Endpoint. The name must be numeric with no leading zeros and can be at most 10 digits.
        :param pulumi.Input[builtins.str] network: The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks) to which the Endpoint should be peered. Private services access must already be configured for the network. If left unspecified, the Endpoint is not peered with any network. Only one of the fields, network or enable_private_service_connect, can be set. [Format](https://cloud.google.com/compute/docs/reference/rest/v1/networks/insert): `projects/{project}/global/networks/{network}`. Where `{project}` is a project number, as in `12345`, and `{network}` is network name. Only one of the fields, `network` or `privateServiceConnectConfig`, can be set.
        :param pulumi.Input[Union['AiEndpointPredictRequestResponseLoggingConfigArgs', 'AiEndpointPredictRequestResponseLoggingConfigArgsDict']] predict_request_response_logging_config: Configures the request-response logging for online prediction.
               Structure is documented below.
        :param pulumi.Input[Union['AiEndpointPrivateServiceConnectConfigArgs', 'AiEndpointPrivateServiceConnectConfigArgsDict']] private_service_connect_config: Configuration for private service connect. `network` and `privateServiceConnectConfig` are mutually exclusive.
               Structure is documented below.
        :param pulumi.Input[builtins.str] project: The ID of the project in which the resource belongs.
               If it is not provided, the provider project is used.
        :param pulumi.Input[builtins.str] region: The region for the resource
        :param pulumi.Input[builtins.str] traffic_split: A map from a DeployedModel's id to the percentage of this Endpoint's traffic that should be forwarded to that DeployedModel.
               If a DeployedModel's id is not listed in this map, then it receives no traffic.
               The traffic percentage values must add up to 100, or map must be empty if the Endpoint is to not accept any traffic at a moment. See
               the `deployModel` [example](https://cloud.google.com/vertex-ai/docs/general/deployment#deploy_a_model_to_an_endpoint) and
               [documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/deployModel) for more information.
               > **Note:** To set the map to empty, set `"{}"`, apply, and then remove the field from your config.
        """
        ...
    @overload
    def __init__(__self__,
                 resource_name: str,
                 args: AiEndpointArgs,
                 opts: Optional[pulumi.ResourceOptions] = None):
        """
        Models are deployed into it, and afterwards Endpoint is called to obtain predictions and explanations.

        To get more information about Endpoint, see:

        * [API documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints)
        * How-to Guides
            * [Official Documentation](https://cloud.google.com/vertex-ai/docs)

        ## Example Usage

        ### Vertex Ai Endpoint Network

        ```python
        import pulumi
        import json
        import pulumi_gcp as gcp

        vertex_network = gcp.compute.Network("vertex_network", name="network-name")
        vertex_range = gcp.compute.GlobalAddress("vertex_range",
            name="address-name",
            purpose="VPC_PEERING",
            address_type="INTERNAL",
            prefix_length=24,
            network=vertex_network.id)
        vertex_vpc_connection = gcp.servicenetworking.Connection("vertex_vpc_connection",
            network=vertex_network.id,
            service="servicenetworking.googleapis.com",
            reserved_peering_ranges=[vertex_range.name])
        bq_dataset = gcp.bigquery.Dataset("bq_dataset",
            dataset_id="some_dataset",
            friendly_name="logging dataset",
            description="This is a dataset that requests are logged to",
            location="US",
            delete_contents_on_destroy=True)
        project = gcp.organizations.get_project()
        endpoint = gcp.vertex.AiEndpoint("endpoint",
            name="endpoint-name",
            display_name="sample-endpoint",
            description="A sample vertex endpoint",
            location="us-central1",
            region="us-central1",
            labels={
                "label-one": "value-one",
            },
            network=vertex_network.name.apply(lambda name: f"projects/{project.number}/global/networks/{name}"),
            encryption_spec={
                "kms_key_name": "kms-name",
            },
            predict_request_response_logging_config={
                "bigquery_destination": {
                    "output_uri": bq_dataset.dataset_id.apply(lambda dataset_id: f"bq://{project.project_id}.{dataset_id}.request_response_logging"),
                },
                "enabled": True,
                "sampling_rate": 0.1,
            },
            traffic_split=json.dumps({
                "12345": 100,
            }),
            opts = pulumi.ResourceOptions(depends_on=[vertex_vpc_connection]))
        crypto_key = gcp.kms.CryptoKeyIAMMember("crypto_key",
            crypto_key_id="kms-name",
            role="roles/cloudkms.cryptoKeyEncrypterDecrypter",
            member=f"serviceAccount:service-{project.number}@gcp-sa-aiplatform.iam.gserviceaccount.com")
        ```
        ### Vertex Ai Endpoint Private Service Connect

        ```python
        import pulumi
        import pulumi_gcp as gcp

        project = gcp.organizations.get_project()
        endpoint = gcp.vertex.AiEndpoint("endpoint",
            name="endpoint-name_33052",
            display_name="sample-endpoint",
            description="A sample vertex endpoint",
            location="us-central1",
            region="us-central1",
            labels={
                "label-one": "value-one",
            },
            private_service_connect_config={
                "enable_private_service_connect": True,
                "project_allowlists": [project.project_id],
                "enable_secure_private_service_connect": False,
            })
        ```
        ### Vertex Ai Endpoint Dedicated Endpoint

        ```python
        import pulumi
        import pulumi_gcp as gcp

        endpoint = gcp.vertex.AiEndpoint("endpoint",
            name="endpoint-name_3684",
            display_name="sample-endpoint",
            description="A sample vertex endpoint",
            location="us-central1",
            region="us-central1",
            labels={
                "label-one": "value-one",
            },
            dedicated_endpoint_enabled=True)
        project = gcp.organizations.get_project()
        ```

        ## Import

        Endpoint can be imported using any of these accepted formats:

        * `projects/{{project}}/locations/{{location}}/endpoints/{{name}}`

        * `{{project}}/{{location}}/{{name}}`

        * `{{location}}/{{name}}`

        When using the `pulumi import` command, Endpoint can be imported using one of the formats above. For example:

        ```sh
        $ pulumi import gcp:vertex/aiEndpoint:AiEndpoint default projects/{{project}}/locations/{{location}}/endpoints/{{name}}
        ```

        ```sh
        $ pulumi import gcp:vertex/aiEndpoint:AiEndpoint default {{project}}/{{location}}/{{name}}
        ```

        ```sh
        $ pulumi import gcp:vertex/aiEndpoint:AiEndpoint default {{location}}/{{name}}
        ```

        :param str resource_name: The name of the resource.
        :param AiEndpointArgs args: The arguments to use to populate this resource's properties.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        ...
    def __init__(__self__, resource_name: str, *args, **kwargs):
        resource_args, opts = _utilities.get_resource_args_opts(AiEndpointArgs, pulumi.ResourceOptions, *args, **kwargs)
        if resource_args is not None:
            __self__._internal_init(resource_name, opts, **resource_args.__dict__)
        else:
            __self__._internal_init(resource_name, *args, **kwargs)

    def _internal_init(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 dedicated_endpoint_enabled: Optional[pulumi.Input[builtins.bool]] = None,
                 description: Optional[pulumi.Input[builtins.str]] = None,
                 display_name: Optional[pulumi.Input[builtins.str]] = None,
                 encryption_spec: Optional[pulumi.Input[Union['AiEndpointEncryptionSpecArgs', 'AiEndpointEncryptionSpecArgsDict']]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 location: Optional[pulumi.Input[builtins.str]] = None,
                 name: Optional[pulumi.Input[builtins.str]] = None,
                 network: Optional[pulumi.Input[builtins.str]] = None,
                 predict_request_response_logging_config: Optional[pulumi.Input[Union['AiEndpointPredictRequestResponseLoggingConfigArgs', 'AiEndpointPredictRequestResponseLoggingConfigArgsDict']]] = None,
                 private_service_connect_config: Optional[pulumi.Input[Union['AiEndpointPrivateServiceConnectConfigArgs', 'AiEndpointPrivateServiceConnectConfigArgsDict']]] = None,
                 project: Optional[pulumi.Input[builtins.str]] = None,
                 region: Optional[pulumi.Input[builtins.str]] = None,
                 traffic_split: Optional[pulumi.Input[builtins.str]] = None,
                 __props__=None):
        opts = pulumi.ResourceOptions.merge(_utilities.get_resource_opts_defaults(), opts)
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = AiEndpointArgs.__new__(AiEndpointArgs)

            __props__.__dict__["dedicated_endpoint_enabled"] = dedicated_endpoint_enabled
            __props__.__dict__["description"] = description
            if display_name is None and not opts.urn:
                raise TypeError("Missing required property 'display_name'")
            __props__.__dict__["display_name"] = display_name
            __props__.__dict__["encryption_spec"] = encryption_spec
            __props__.__dict__["labels"] = labels
            if location is None and not opts.urn:
                raise TypeError("Missing required property 'location'")
            __props__.__dict__["location"] = location
            __props__.__dict__["name"] = name
            __props__.__dict__["network"] = network
            __props__.__dict__["predict_request_response_logging_config"] = predict_request_response_logging_config
            __props__.__dict__["private_service_connect_config"] = private_service_connect_config
            __props__.__dict__["project"] = project
            __props__.__dict__["region"] = region
            __props__.__dict__["traffic_split"] = traffic_split
            __props__.__dict__["create_time"] = None
            __props__.__dict__["dedicated_endpoint_dns"] = None
            __props__.__dict__["deployed_models"] = None
            __props__.__dict__["effective_labels"] = None
            __props__.__dict__["etag"] = None
            __props__.__dict__["model_deployment_monitoring_job"] = None
            __props__.__dict__["pulumi_labels"] = None
            __props__.__dict__["update_time"] = None
        secret_opts = pulumi.ResourceOptions(additional_secret_outputs=["effectiveLabels", "pulumiLabels"])
        opts = pulumi.ResourceOptions.merge(opts, secret_opts)
        super(AiEndpoint, __self__).__init__(
            'gcp:vertex/aiEndpoint:AiEndpoint',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: pulumi.Input[str],
            opts: Optional[pulumi.ResourceOptions] = None,
            create_time: Optional[pulumi.Input[builtins.str]] = None,
            dedicated_endpoint_dns: Optional[pulumi.Input[builtins.str]] = None,
            dedicated_endpoint_enabled: Optional[pulumi.Input[builtins.bool]] = None,
            deployed_models: Optional[pulumi.Input[Sequence[pulumi.Input[Union['AiEndpointDeployedModelArgs', 'AiEndpointDeployedModelArgsDict']]]]] = None,
            description: Optional[pulumi.Input[builtins.str]] = None,
            display_name: Optional[pulumi.Input[builtins.str]] = None,
            effective_labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
            encryption_spec: Optional[pulumi.Input[Union['AiEndpointEncryptionSpecArgs', 'AiEndpointEncryptionSpecArgsDict']]] = None,
            etag: Optional[pulumi.Input[builtins.str]] = None,
            labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
            location: Optional[pulumi.Input[builtins.str]] = None,
            model_deployment_monitoring_job: Optional[pulumi.Input[builtins.str]] = None,
            name: Optional[pulumi.Input[builtins.str]] = None,
            network: Optional[pulumi.Input[builtins.str]] = None,
            predict_request_response_logging_config: Optional[pulumi.Input[Union['AiEndpointPredictRequestResponseLoggingConfigArgs', 'AiEndpointPredictRequestResponseLoggingConfigArgsDict']]] = None,
            private_service_connect_config: Optional[pulumi.Input[Union['AiEndpointPrivateServiceConnectConfigArgs', 'AiEndpointPrivateServiceConnectConfigArgsDict']]] = None,
            project: Optional[pulumi.Input[builtins.str]] = None,
            pulumi_labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
            region: Optional[pulumi.Input[builtins.str]] = None,
            traffic_split: Optional[pulumi.Input[builtins.str]] = None,
            update_time: Optional[pulumi.Input[builtins.str]] = None) -> 'AiEndpoint':
        """
        Get an existing AiEndpoint resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param pulumi.Input[str] id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[builtins.str] create_time: (Output)
               Output only. Timestamp when the DeployedModel was created.
        :param pulumi.Input[builtins.str] dedicated_endpoint_dns: Output only. DNS of the dedicated endpoint. Will only be populated if dedicatedEndpointEnabled is true. Format: `https://{endpointId}.{region}-{projectNumber}.prediction.vertexai.goog`.
        :param pulumi.Input[builtins.bool] dedicated_endpoint_enabled: If true, the endpoint will be exposed through a dedicated DNS [Endpoint.dedicated_endpoint_dns]. Your request to the dedicated DNS will be isolated from other users' traffic and will have better performance and reliability. Note: Once you enabled dedicated endpoint, you won't be able to send request to the shared DNS {region}-aiplatform.googleapis.com. The limitation will be removed soon.
        :param pulumi.Input[Sequence[pulumi.Input[Union['AiEndpointDeployedModelArgs', 'AiEndpointDeployedModelArgsDict']]]] deployed_models: Output only. The models deployed in this Endpoint. To add or remove DeployedModels use EndpointService.DeployModel and EndpointService.UndeployModel respectively. Models can also be deployed and undeployed using the [Cloud Console](https://console.cloud.google.com/vertex-ai/).
               Structure is documented below.
        :param pulumi.Input[builtins.str] description: The description of the Endpoint.
        :param pulumi.Input[builtins.str] display_name: Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] effective_labels: All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
        :param pulumi.Input[Union['AiEndpointEncryptionSpecArgs', 'AiEndpointEncryptionSpecArgsDict']] encryption_spec: Customer-managed encryption key spec for an Endpoint. If set, this Endpoint and all sub-resources of this Endpoint will be secured by this key.
               Structure is documented below.
        :param pulumi.Input[builtins.str] etag: Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] labels: The labels with user-defined metadata to organize your Endpoints. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
               **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
               Please refer to the field `effective_labels` for all of the labels present on the resource.
        :param pulumi.Input[builtins.str] location: The location for the resource
               
               
               - - -
        :param pulumi.Input[builtins.str] model_deployment_monitoring_job: Output only. Resource name of the Model Monitoring job associated with this Endpoint if monitoring is enabled by CreateModelDeploymentMonitoringJob. Format: `projects/{project}/locations/{location}/modelDeploymentMonitoringJobs/{model_deployment_monitoring_job}`
        :param pulumi.Input[builtins.str] name: The resource name of the Endpoint. The name must be numeric with no leading zeros and can be at most 10 digits.
        :param pulumi.Input[builtins.str] network: The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks) to which the Endpoint should be peered. Private services access must already be configured for the network. If left unspecified, the Endpoint is not peered with any network. Only one of the fields, network or enable_private_service_connect, can be set. [Format](https://cloud.google.com/compute/docs/reference/rest/v1/networks/insert): `projects/{project}/global/networks/{network}`. Where `{project}` is a project number, as in `12345`, and `{network}` is network name. Only one of the fields, `network` or `privateServiceConnectConfig`, can be set.
        :param pulumi.Input[Union['AiEndpointPredictRequestResponseLoggingConfigArgs', 'AiEndpointPredictRequestResponseLoggingConfigArgsDict']] predict_request_response_logging_config: Configures the request-response logging for online prediction.
               Structure is documented below.
        :param pulumi.Input[Union['AiEndpointPrivateServiceConnectConfigArgs', 'AiEndpointPrivateServiceConnectConfigArgsDict']] private_service_connect_config: Configuration for private service connect. `network` and `privateServiceConnectConfig` are mutually exclusive.
               Structure is documented below.
        :param pulumi.Input[builtins.str] project: The ID of the project in which the resource belongs.
               If it is not provided, the provider project is used.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] pulumi_labels: The combination of labels configured directly on the resource
               and default labels configured on the provider.
        :param pulumi.Input[builtins.str] region: The region for the resource
        :param pulumi.Input[builtins.str] traffic_split: A map from a DeployedModel's id to the percentage of this Endpoint's traffic that should be forwarded to that DeployedModel.
               If a DeployedModel's id is not listed in this map, then it receives no traffic.
               The traffic percentage values must add up to 100, or map must be empty if the Endpoint is to not accept any traffic at a moment. See
               the `deployModel` [example](https://cloud.google.com/vertex-ai/docs/general/deployment#deploy_a_model_to_an_endpoint) and
               [documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/deployModel) for more information.
               > **Note:** To set the map to empty, set `"{}"`, apply, and then remove the field from your config.
        :param pulumi.Input[builtins.str] update_time: Output only. Timestamp when this Endpoint was last updated.
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = _AiEndpointState.__new__(_AiEndpointState)

        __props__.__dict__["create_time"] = create_time
        __props__.__dict__["dedicated_endpoint_dns"] = dedicated_endpoint_dns
        __props__.__dict__["dedicated_endpoint_enabled"] = dedicated_endpoint_enabled
        __props__.__dict__["deployed_models"] = deployed_models
        __props__.__dict__["description"] = description
        __props__.__dict__["display_name"] = display_name
        __props__.__dict__["effective_labels"] = effective_labels
        __props__.__dict__["encryption_spec"] = encryption_spec
        __props__.__dict__["etag"] = etag
        __props__.__dict__["labels"] = labels
        __props__.__dict__["location"] = location
        __props__.__dict__["model_deployment_monitoring_job"] = model_deployment_monitoring_job
        __props__.__dict__["name"] = name
        __props__.__dict__["network"] = network
        __props__.__dict__["predict_request_response_logging_config"] = predict_request_response_logging_config
        __props__.__dict__["private_service_connect_config"] = private_service_connect_config
        __props__.__dict__["project"] = project
        __props__.__dict__["pulumi_labels"] = pulumi_labels
        __props__.__dict__["region"] = region
        __props__.__dict__["traffic_split"] = traffic_split
        __props__.__dict__["update_time"] = update_time
        return AiEndpoint(resource_name, opts=opts, __props__=__props__)

    @property
    @pulumi.getter(name="createTime")
    def create_time(self) -> pulumi.Output[builtins.str]:
        """
        (Output)
        Output only. Timestamp when the DeployedModel was created.
        """
        return pulumi.get(self, "create_time")

    @property
    @pulumi.getter(name="dedicatedEndpointDns")
    def dedicated_endpoint_dns(self) -> pulumi.Output[builtins.str]:
        """
        Output only. DNS of the dedicated endpoint. Will only be populated if dedicatedEndpointEnabled is true. Format: `https://{endpointId}.{region}-{projectNumber}.prediction.vertexai.goog`.
        """
        return pulumi.get(self, "dedicated_endpoint_dns")

    @property
    @pulumi.getter(name="dedicatedEndpointEnabled")
    def dedicated_endpoint_enabled(self) -> pulumi.Output[Optional[builtins.bool]]:
        """
        If true, the endpoint will be exposed through a dedicated DNS [Endpoint.dedicated_endpoint_dns]. Your request to the dedicated DNS will be isolated from other users' traffic and will have better performance and reliability. Note: Once you enabled dedicated endpoint, you won't be able to send request to the shared DNS {region}-aiplatform.googleapis.com. The limitation will be removed soon.
        """
        return pulumi.get(self, "dedicated_endpoint_enabled")

    @property
    @pulumi.getter(name="deployedModels")
    def deployed_models(self) -> pulumi.Output[Sequence['outputs.AiEndpointDeployedModel']]:
        """
        Output only. The models deployed in this Endpoint. To add or remove DeployedModels use EndpointService.DeployModel and EndpointService.UndeployModel respectively. Models can also be deployed and undeployed using the [Cloud Console](https://console.cloud.google.com/vertex-ai/).
        Structure is documented below.
        """
        return pulumi.get(self, "deployed_models")

    @property
    @pulumi.getter
    def description(self) -> pulumi.Output[Optional[builtins.str]]:
        """
        The description of the Endpoint.
        """
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="displayName")
    def display_name(self) -> pulumi.Output[builtins.str]:
        """
        Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        """
        return pulumi.get(self, "display_name")

    @property
    @pulumi.getter(name="effectiveLabels")
    def effective_labels(self) -> pulumi.Output[Mapping[str, builtins.str]]:
        """
        All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
        """
        return pulumi.get(self, "effective_labels")

    @property
    @pulumi.getter(name="encryptionSpec")
    def encryption_spec(self) -> pulumi.Output[Optional['outputs.AiEndpointEncryptionSpec']]:
        """
        Customer-managed encryption key spec for an Endpoint. If set, this Endpoint and all sub-resources of this Endpoint will be secured by this key.
        Structure is documented below.
        """
        return pulumi.get(self, "encryption_spec")

    @property
    @pulumi.getter
    def etag(self) -> pulumi.Output[builtins.str]:
        """
        Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
        """
        return pulumi.get(self, "etag")

    @property
    @pulumi.getter
    def labels(self) -> pulumi.Output[Optional[Mapping[str, builtins.str]]]:
        """
        The labels with user-defined metadata to organize your Endpoints. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
        **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
        Please refer to the field `effective_labels` for all of the labels present on the resource.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter
    def location(self) -> pulumi.Output[builtins.str]:
        """
        The location for the resource


        - - -
        """
        return pulumi.get(self, "location")

    @property
    @pulumi.getter(name="modelDeploymentMonitoringJob")
    def model_deployment_monitoring_job(self) -> pulumi.Output[builtins.str]:
        """
        Output only. Resource name of the Model Monitoring job associated with this Endpoint if monitoring is enabled by CreateModelDeploymentMonitoringJob. Format: `projects/{project}/locations/{location}/modelDeploymentMonitoringJobs/{model_deployment_monitoring_job}`
        """
        return pulumi.get(self, "model_deployment_monitoring_job")

    @property
    @pulumi.getter
    def name(self) -> pulumi.Output[builtins.str]:
        """
        The resource name of the Endpoint. The name must be numeric with no leading zeros and can be at most 10 digits.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def network(self) -> pulumi.Output[Optional[builtins.str]]:
        """
        The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks) to which the Endpoint should be peered. Private services access must already be configured for the network. If left unspecified, the Endpoint is not peered with any network. Only one of the fields, network or enable_private_service_connect, can be set. [Format](https://cloud.google.com/compute/docs/reference/rest/v1/networks/insert): `projects/{project}/global/networks/{network}`. Where `{project}` is a project number, as in `12345`, and `{network}` is network name. Only one of the fields, `network` or `privateServiceConnectConfig`, can be set.
        """
        return pulumi.get(self, "network")

    @property
    @pulumi.getter(name="predictRequestResponseLoggingConfig")
    def predict_request_response_logging_config(self) -> pulumi.Output[Optional['outputs.AiEndpointPredictRequestResponseLoggingConfig']]:
        """
        Configures the request-response logging for online prediction.
        Structure is documented below.
        """
        return pulumi.get(self, "predict_request_response_logging_config")

    @property
    @pulumi.getter(name="privateServiceConnectConfig")
    def private_service_connect_config(self) -> pulumi.Output[Optional['outputs.AiEndpointPrivateServiceConnectConfig']]:
        """
        Configuration for private service connect. `network` and `privateServiceConnectConfig` are mutually exclusive.
        Structure is documented below.
        """
        return pulumi.get(self, "private_service_connect_config")

    @property
    @pulumi.getter
    def project(self) -> pulumi.Output[builtins.str]:
        """
        The ID of the project in which the resource belongs.
        If it is not provided, the provider project is used.
        """
        return pulumi.get(self, "project")

    @property
    @pulumi.getter(name="pulumiLabels")
    def pulumi_labels(self) -> pulumi.Output[Mapping[str, builtins.str]]:
        """
        The combination of labels configured directly on the resource
        and default labels configured on the provider.
        """
        return pulumi.get(self, "pulumi_labels")

    @property
    @pulumi.getter
    def region(self) -> pulumi.Output[Optional[builtins.str]]:
        """
        The region for the resource
        """
        return pulumi.get(self, "region")

    @property
    @pulumi.getter(name="trafficSplit")
    def traffic_split(self) -> pulumi.Output[builtins.str]:
        """
        A map from a DeployedModel's id to the percentage of this Endpoint's traffic that should be forwarded to that DeployedModel.
        If a DeployedModel's id is not listed in this map, then it receives no traffic.
        The traffic percentage values must add up to 100, or map must be empty if the Endpoint is to not accept any traffic at a moment. See
        the `deployModel` [example](https://cloud.google.com/vertex-ai/docs/general/deployment#deploy_a_model_to_an_endpoint) and
        [documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/deployModel) for more information.
        > **Note:** To set the map to empty, set `"{}"`, apply, and then remove the field from your config.
        """
        return pulumi.get(self, "traffic_split")

    @property
    @pulumi.getter(name="updateTime")
    def update_time(self) -> pulumi.Output[builtins.str]:
        """
        Output only. Timestamp when this Endpoint was last updated.
        """
        return pulumi.get(self, "update_time")

