# coding=utf-8
# *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import copy
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities
from . import outputs

__all__ = [
    'AttachedClusterAuthorization',
    'AttachedClusterBinaryAuthorization',
    'AttachedClusterError',
    'AttachedClusterFleet',
    'AttachedClusterLoggingConfig',
    'AttachedClusterLoggingConfigComponentConfig',
    'AttachedClusterMonitoringConfig',
    'AttachedClusterMonitoringConfigManagedPrometheusConfig',
    'AttachedClusterOidcConfig',
    'AttachedClusterProxyConfig',
    'AttachedClusterProxyConfigKubernetesSecret',
    'AttachedClusterSecurityPostureConfig',
    'AttachedClusterWorkloadIdentityConfig',
    'AwsClusterAuthorization',
    'AwsClusterAuthorizationAdminGroup',
    'AwsClusterAuthorizationAdminUser',
    'AwsClusterBinaryAuthorization',
    'AwsClusterControlPlane',
    'AwsClusterControlPlaneAwsServicesAuthentication',
    'AwsClusterControlPlaneConfigEncryption',
    'AwsClusterControlPlaneDatabaseEncryption',
    'AwsClusterControlPlaneInstancePlacement',
    'AwsClusterControlPlaneMainVolume',
    'AwsClusterControlPlaneProxyConfig',
    'AwsClusterControlPlaneRootVolume',
    'AwsClusterControlPlaneSshConfig',
    'AwsClusterFleet',
    'AwsClusterLoggingConfig',
    'AwsClusterLoggingConfigComponentConfig',
    'AwsClusterNetworking',
    'AwsClusterWorkloadIdentityConfig',
    'AwsNodePoolAutoscaling',
    'AwsNodePoolConfig',
    'AwsNodePoolConfigAutoscalingMetricsCollection',
    'AwsNodePoolConfigConfigEncryption',
    'AwsNodePoolConfigInstancePlacement',
    'AwsNodePoolConfigProxyConfig',
    'AwsNodePoolConfigRootVolume',
    'AwsNodePoolConfigSpotConfig',
    'AwsNodePoolConfigSshConfig',
    'AwsNodePoolConfigTaint',
    'AwsNodePoolKubeletConfig',
    'AwsNodePoolManagement',
    'AwsNodePoolMaxPodsConstraint',
    'AwsNodePoolUpdateSettings',
    'AwsNodePoolUpdateSettingsSurgeSettings',
    'AzureClusterAuthorization',
    'AzureClusterAuthorizationAdminGroup',
    'AzureClusterAuthorizationAdminUser',
    'AzureClusterAzureServicesAuthentication',
    'AzureClusterControlPlane',
    'AzureClusterControlPlaneDatabaseEncryption',
    'AzureClusterControlPlaneMainVolume',
    'AzureClusterControlPlaneProxyConfig',
    'AzureClusterControlPlaneReplicaPlacement',
    'AzureClusterControlPlaneRootVolume',
    'AzureClusterControlPlaneSshConfig',
    'AzureClusterFleet',
    'AzureClusterLoggingConfig',
    'AzureClusterLoggingConfigComponentConfig',
    'AzureClusterNetworking',
    'AzureClusterWorkloadIdentityConfig',
    'AzureNodePoolAutoscaling',
    'AzureNodePoolConfig',
    'AzureNodePoolConfigProxyConfig',
    'AzureNodePoolConfigRootVolume',
    'AzureNodePoolConfigSshConfig',
    'AzureNodePoolManagement',
    'AzureNodePoolMaxPodsConstraint',
    'ClusterAddonsConfig',
    'ClusterAddonsConfigCloudrunConfig',
    'ClusterAddonsConfigConfigConnectorConfig',
    'ClusterAddonsConfigDnsCacheConfig',
    'ClusterAddonsConfigGcePersistentDiskCsiDriverConfig',
    'ClusterAddonsConfigGcpFilestoreCsiDriverConfig',
    'ClusterAddonsConfigGcsFuseCsiDriverConfig',
    'ClusterAddonsConfigGkeBackupAgentConfig',
    'ClusterAddonsConfigHorizontalPodAutoscaling',
    'ClusterAddonsConfigHttpLoadBalancing',
    'ClusterAddonsConfigIstioConfig',
    'ClusterAddonsConfigKalmConfig',
    'ClusterAddonsConfigNetworkPolicyConfig',
    'ClusterAddonsConfigRayOperatorConfig',
    'ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfig',
    'ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfig',
    'ClusterAddonsConfigStatefulHaConfig',
    'ClusterAuthenticatorGroupsConfig',
    'ClusterBinaryAuthorization',
    'ClusterClusterAutoscaling',
    'ClusterClusterAutoscalingAutoProvisioningDefaults',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsManagement',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
    'ClusterClusterAutoscalingResourceLimit',
    'ClusterClusterTelemetry',
    'ClusterConfidentialNodes',
    'ClusterCostManagementConfig',
    'ClusterDatabaseEncryption',
    'ClusterDefaultSnatStatus',
    'ClusterDnsConfig',
    'ClusterEnableK8sBetaApis',
    'ClusterFleet',
    'ClusterGatewayApiConfig',
    'ClusterIdentityServiceConfig',
    'ClusterIpAllocationPolicy',
    'ClusterIpAllocationPolicyAdditionalPodRangesConfig',
    'ClusterIpAllocationPolicyPodCidrOverprovisionConfig',
    'ClusterLoggingConfig',
    'ClusterMaintenancePolicy',
    'ClusterMaintenancePolicyDailyMaintenanceWindow',
    'ClusterMaintenancePolicyMaintenanceExclusion',
    'ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions',
    'ClusterMaintenancePolicyRecurringWindow',
    'ClusterMasterAuth',
    'ClusterMasterAuthClientCertificateConfig',
    'ClusterMasterAuthorizedNetworksConfig',
    'ClusterMasterAuthorizedNetworksConfigCidrBlock',
    'ClusterMeshCertificates',
    'ClusterMonitoringConfig',
    'ClusterMonitoringConfigAdvancedDatapathObservabilityConfig',
    'ClusterMonitoringConfigManagedPrometheus',
    'ClusterNetworkPolicy',
    'ClusterNodeConfig',
    'ClusterNodeConfigAdvancedMachineFeatures',
    'ClusterNodeConfigConfidentialNodes',
    'ClusterNodeConfigContainerdConfig',
    'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig',
    'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig',
    'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig',
    'ClusterNodeConfigEffectiveTaint',
    'ClusterNodeConfigEphemeralStorageConfig',
    'ClusterNodeConfigEphemeralStorageLocalSsdConfig',
    'ClusterNodeConfigFastSocket',
    'ClusterNodeConfigGcfsConfig',
    'ClusterNodeConfigGuestAccelerator',
    'ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig',
    'ClusterNodeConfigGuestAcceleratorGpuSharingConfig',
    'ClusterNodeConfigGvnic',
    'ClusterNodeConfigHostMaintenancePolicy',
    'ClusterNodeConfigKubeletConfig',
    'ClusterNodeConfigLinuxNodeConfig',
    'ClusterNodeConfigLinuxNodeConfigHugepagesConfig',
    'ClusterNodeConfigLocalNvmeSsdBlockConfig',
    'ClusterNodeConfigReservationAffinity',
    'ClusterNodeConfigSandboxConfig',
    'ClusterNodeConfigSecondaryBootDisk',
    'ClusterNodeConfigShieldedInstanceConfig',
    'ClusterNodeConfigSoleTenantConfig',
    'ClusterNodeConfigSoleTenantConfigNodeAffinity',
    'ClusterNodeConfigTaint',
    'ClusterNodeConfigWorkloadMetadataConfig',
    'ClusterNodePool',
    'ClusterNodePoolAutoConfig',
    'ClusterNodePoolAutoConfigNetworkTags',
    'ClusterNodePoolAutoConfigNodeKubeletConfig',
    'ClusterNodePoolAutoscaling',
    'ClusterNodePoolDefaults',
    'ClusterNodePoolDefaultsNodeConfigDefaults',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig',
    'ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfig',
    'ClusterNodePoolManagement',
    'ClusterNodePoolNetworkConfig',
    'ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfig',
    'ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig',
    'ClusterNodePoolNetworkConfigNetworkPerformanceConfig',
    'ClusterNodePoolNetworkConfigPodCidrOverprovisionConfig',
    'ClusterNodePoolNodeConfig',
    'ClusterNodePoolNodeConfigAdvancedMachineFeatures',
    'ClusterNodePoolNodeConfigConfidentialNodes',
    'ClusterNodePoolNodeConfigContainerdConfig',
    'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig',
    'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig',
    'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig',
    'ClusterNodePoolNodeConfigEffectiveTaint',
    'ClusterNodePoolNodeConfigEphemeralStorageConfig',
    'ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig',
    'ClusterNodePoolNodeConfigFastSocket',
    'ClusterNodePoolNodeConfigGcfsConfig',
    'ClusterNodePoolNodeConfigGuestAccelerator',
    'ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig',
    'ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig',
    'ClusterNodePoolNodeConfigGvnic',
    'ClusterNodePoolNodeConfigHostMaintenancePolicy',
    'ClusterNodePoolNodeConfigKubeletConfig',
    'ClusterNodePoolNodeConfigLinuxNodeConfig',
    'ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig',
    'ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig',
    'ClusterNodePoolNodeConfigReservationAffinity',
    'ClusterNodePoolNodeConfigSandboxConfig',
    'ClusterNodePoolNodeConfigSecondaryBootDisk',
    'ClusterNodePoolNodeConfigShieldedInstanceConfig',
    'ClusterNodePoolNodeConfigSoleTenantConfig',
    'ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinity',
    'ClusterNodePoolNodeConfigTaint',
    'ClusterNodePoolNodeConfigWorkloadMetadataConfig',
    'ClusterNodePoolPlacementPolicy',
    'ClusterNodePoolQueuedProvisioning',
    'ClusterNodePoolUpgradeSettings',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettings',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
    'ClusterNotificationConfig',
    'ClusterNotificationConfigPubsub',
    'ClusterNotificationConfigPubsubFilter',
    'ClusterPodSecurityPolicyConfig',
    'ClusterPrivateClusterConfig',
    'ClusterPrivateClusterConfigMasterGlobalAccessConfig',
    'ClusterProtectConfig',
    'ClusterProtectConfigWorkloadConfig',
    'ClusterReleaseChannel',
    'ClusterResourceUsageExportConfig',
    'ClusterResourceUsageExportConfigBigqueryDestination',
    'ClusterSecretManagerConfig',
    'ClusterSecurityPostureConfig',
    'ClusterServiceExternalIpsConfig',
    'ClusterTpuConfig',
    'ClusterVerticalPodAutoscaling',
    'ClusterWorkloadAltsConfig',
    'ClusterWorkloadIdentityConfig',
    'NodePoolAutoscaling',
    'NodePoolManagement',
    'NodePoolNetworkConfig',
    'NodePoolNetworkConfigAdditionalNodeNetworkConfig',
    'NodePoolNetworkConfigAdditionalPodNetworkConfig',
    'NodePoolNetworkConfigNetworkPerformanceConfig',
    'NodePoolNetworkConfigPodCidrOverprovisionConfig',
    'NodePoolNodeConfig',
    'NodePoolNodeConfigAdvancedMachineFeatures',
    'NodePoolNodeConfigConfidentialNodes',
    'NodePoolNodeConfigContainerdConfig',
    'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig',
    'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig',
    'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig',
    'NodePoolNodeConfigEffectiveTaint',
    'NodePoolNodeConfigEphemeralStorageConfig',
    'NodePoolNodeConfigEphemeralStorageLocalSsdConfig',
    'NodePoolNodeConfigFastSocket',
    'NodePoolNodeConfigGcfsConfig',
    'NodePoolNodeConfigGuestAccelerator',
    'NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig',
    'NodePoolNodeConfigGuestAcceleratorGpuSharingConfig',
    'NodePoolNodeConfigGvnic',
    'NodePoolNodeConfigHostMaintenancePolicy',
    'NodePoolNodeConfigKubeletConfig',
    'NodePoolNodeConfigLinuxNodeConfig',
    'NodePoolNodeConfigLinuxNodeConfigHugepagesConfig',
    'NodePoolNodeConfigLocalNvmeSsdBlockConfig',
    'NodePoolNodeConfigReservationAffinity',
    'NodePoolNodeConfigSandboxConfig',
    'NodePoolNodeConfigSecondaryBootDisk',
    'NodePoolNodeConfigShieldedInstanceConfig',
    'NodePoolNodeConfigSoleTenantConfig',
    'NodePoolNodeConfigSoleTenantConfigNodeAffinity',
    'NodePoolNodeConfigTaint',
    'NodePoolNodeConfigWorkloadMetadataConfig',
    'NodePoolPlacementPolicy',
    'NodePoolQueuedProvisioning',
    'NodePoolUpgradeSettings',
    'NodePoolUpgradeSettingsBlueGreenSettings',
    'NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
    'GetClusterAddonsConfigResult',
    'GetClusterAddonsConfigCloudrunConfigResult',
    'GetClusterAddonsConfigConfigConnectorConfigResult',
    'GetClusterAddonsConfigDnsCacheConfigResult',
    'GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigResult',
    'GetClusterAddonsConfigGcpFilestoreCsiDriverConfigResult',
    'GetClusterAddonsConfigGcsFuseCsiDriverConfigResult',
    'GetClusterAddonsConfigGkeBackupAgentConfigResult',
    'GetClusterAddonsConfigHorizontalPodAutoscalingResult',
    'GetClusterAddonsConfigHttpLoadBalancingResult',
    'GetClusterAddonsConfigIstioConfigResult',
    'GetClusterAddonsConfigKalmConfigResult',
    'GetClusterAddonsConfigNetworkPolicyConfigResult',
    'GetClusterAddonsConfigRayOperatorConfigResult',
    'GetClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigResult',
    'GetClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigResult',
    'GetClusterAddonsConfigStatefulHaConfigResult',
    'GetClusterAuthenticatorGroupsConfigResult',
    'GetClusterBinaryAuthorizationResult',
    'GetClusterClusterAutoscalingResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultManagementResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult',
    'GetClusterClusterAutoscalingResourceLimitResult',
    'GetClusterClusterTelemetryResult',
    'GetClusterConfidentialNodeResult',
    'GetClusterCostManagementConfigResult',
    'GetClusterDatabaseEncryptionResult',
    'GetClusterDefaultSnatStatusResult',
    'GetClusterDnsConfigResult',
    'GetClusterEnableK8sBetaApiResult',
    'GetClusterFleetResult',
    'GetClusterGatewayApiConfigResult',
    'GetClusterIdentityServiceConfigResult',
    'GetClusterIpAllocationPolicyResult',
    'GetClusterIpAllocationPolicyAdditionalPodRangesConfigResult',
    'GetClusterIpAllocationPolicyPodCidrOverprovisionConfigResult',
    'GetClusterLoggingConfigResult',
    'GetClusterMaintenancePolicyResult',
    'GetClusterMaintenancePolicyDailyMaintenanceWindowResult',
    'GetClusterMaintenancePolicyMaintenanceExclusionResult',
    'GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionResult',
    'GetClusterMaintenancePolicyRecurringWindowResult',
    'GetClusterMasterAuthResult',
    'GetClusterMasterAuthClientCertificateConfigResult',
    'GetClusterMasterAuthorizedNetworksConfigResult',
    'GetClusterMasterAuthorizedNetworksConfigCidrBlockResult',
    'GetClusterMeshCertificateResult',
    'GetClusterMonitoringConfigResult',
    'GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigResult',
    'GetClusterMonitoringConfigManagedPrometheusResult',
    'GetClusterNetworkPolicyResult',
    'GetClusterNodeConfigResult',
    'GetClusterNodeConfigAdvancedMachineFeatureResult',
    'GetClusterNodeConfigConfidentialNodeResult',
    'GetClusterNodeConfigContainerdConfigResult',
    'GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigResult',
    'GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult',
    'GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult',
    'GetClusterNodeConfigEffectiveTaintResult',
    'GetClusterNodeConfigEphemeralStorageConfigResult',
    'GetClusterNodeConfigEphemeralStorageLocalSsdConfigResult',
    'GetClusterNodeConfigFastSocketResult',
    'GetClusterNodeConfigGcfsConfigResult',
    'GetClusterNodeConfigGuestAcceleratorResult',
    'GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult',
    'GetClusterNodeConfigGuestAcceleratorGpuSharingConfigResult',
    'GetClusterNodeConfigGvnicResult',
    'GetClusterNodeConfigHostMaintenancePolicyResult',
    'GetClusterNodeConfigKubeletConfigResult',
    'GetClusterNodeConfigLinuxNodeConfigResult',
    'GetClusterNodeConfigLinuxNodeConfigHugepagesConfigResult',
    'GetClusterNodeConfigLocalNvmeSsdBlockConfigResult',
    'GetClusterNodeConfigReservationAffinityResult',
    'GetClusterNodeConfigSandboxConfigResult',
    'GetClusterNodeConfigSecondaryBootDiskResult',
    'GetClusterNodeConfigShieldedInstanceConfigResult',
    'GetClusterNodeConfigSoleTenantConfigResult',
    'GetClusterNodeConfigSoleTenantConfigNodeAffinityResult',
    'GetClusterNodeConfigTaintResult',
    'GetClusterNodeConfigWorkloadMetadataConfigResult',
    'GetClusterNodePoolResult',
    'GetClusterNodePoolAutoConfigResult',
    'GetClusterNodePoolAutoConfigNetworkTagResult',
    'GetClusterNodePoolAutoConfigNodeKubeletConfigResult',
    'GetClusterNodePoolAutoscalingResult',
    'GetClusterNodePoolDefaultResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigResult',
    'GetClusterNodePoolManagementResult',
    'GetClusterNodePoolNetworkConfigResult',
    'GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigResult',
    'GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigResult',
    'GetClusterNodePoolNetworkConfigNetworkPerformanceConfigResult',
    'GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigResult',
    'GetClusterNodePoolNodeConfigResult',
    'GetClusterNodePoolNodeConfigAdvancedMachineFeatureResult',
    'GetClusterNodePoolNodeConfigConfidentialNodeResult',
    'GetClusterNodePoolNodeConfigContainerdConfigResult',
    'GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigResult',
    'GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult',
    'GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult',
    'GetClusterNodePoolNodeConfigEffectiveTaintResult',
    'GetClusterNodePoolNodeConfigEphemeralStorageConfigResult',
    'GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigResult',
    'GetClusterNodePoolNodeConfigFastSocketResult',
    'GetClusterNodePoolNodeConfigGcfsConfigResult',
    'GetClusterNodePoolNodeConfigGuestAcceleratorResult',
    'GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult',
    'GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigResult',
    'GetClusterNodePoolNodeConfigGvnicResult',
    'GetClusterNodePoolNodeConfigHostMaintenancePolicyResult',
    'GetClusterNodePoolNodeConfigKubeletConfigResult',
    'GetClusterNodePoolNodeConfigLinuxNodeConfigResult',
    'GetClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigResult',
    'GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigResult',
    'GetClusterNodePoolNodeConfigReservationAffinityResult',
    'GetClusterNodePoolNodeConfigSandboxConfigResult',
    'GetClusterNodePoolNodeConfigSecondaryBootDiskResult',
    'GetClusterNodePoolNodeConfigShieldedInstanceConfigResult',
    'GetClusterNodePoolNodeConfigSoleTenantConfigResult',
    'GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityResult',
    'GetClusterNodePoolNodeConfigTaintResult',
    'GetClusterNodePoolNodeConfigWorkloadMetadataConfigResult',
    'GetClusterNodePoolPlacementPolicyResult',
    'GetClusterNodePoolQueuedProvisioningResult',
    'GetClusterNodePoolUpgradeSettingResult',
    'GetClusterNodePoolUpgradeSettingBlueGreenSettingResult',
    'GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult',
    'GetClusterNotificationConfigResult',
    'GetClusterNotificationConfigPubsubResult',
    'GetClusterNotificationConfigPubsubFilterResult',
    'GetClusterPodSecurityPolicyConfigResult',
    'GetClusterPrivateClusterConfigResult',
    'GetClusterPrivateClusterConfigMasterGlobalAccessConfigResult',
    'GetClusterProtectConfigResult',
    'GetClusterProtectConfigWorkloadConfigResult',
    'GetClusterReleaseChannelResult',
    'GetClusterResourceUsageExportConfigResult',
    'GetClusterResourceUsageExportConfigBigqueryDestinationResult',
    'GetClusterSecretManagerConfigResult',
    'GetClusterSecurityPostureConfigResult',
    'GetClusterServiceExternalIpsConfigResult',
    'GetClusterTpuConfigResult',
    'GetClusterVerticalPodAutoscalingResult',
    'GetClusterWorkloadAltsConfigResult',
    'GetClusterWorkloadIdentityConfigResult',
]

@pulumi.output_type
class AttachedClusterAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminGroups":
            suggest = "admin_groups"
        elif key == "adminUsers":
            suggest = "admin_users"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_groups: Optional[Sequence[str]] = None,
                 admin_users: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] admin_groups: Groups that can perform operations as a cluster admin. A managed
               ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
               to the groups. Up to ten admin groups can be provided.
               For more info on RBAC, see
               https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        :param Sequence[str] admin_users: Users that can perform operations as a cluster admin. A managed
               ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
               to the users. Up to ten admin users can be provided.
               For more info on RBAC, see
               https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        if admin_groups is not None:
            pulumi.set(__self__, "admin_groups", admin_groups)
        if admin_users is not None:
            pulumi.set(__self__, "admin_users", admin_users)

    @property
    @pulumi.getter(name="adminGroups")
    def admin_groups(self) -> Optional[Sequence[str]]:
        """
        Groups that can perform operations as a cluster admin. A managed
        ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
        to the groups. Up to ten admin groups can be provided.
        For more info on RBAC, see
        https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_groups")

    @property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> Optional[Sequence[str]]:
        """
        Users that can perform operations as a cluster admin. A managed
        ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
        to the users. Up to ten admin users can be provided.
        For more info on RBAC, see
        https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")


@pulumi.output_type
class AttachedClusterBinaryAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "evaluationMode":
            suggest = "evaluation_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterBinaryAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterBinaryAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterBinaryAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 evaluation_mode: Optional[str] = None):
        """
        :param str evaluation_mode: Configure Binary Authorization evaluation mode.
               Possible values are: `DISABLED`, `PROJECT_SINGLETON_POLICY_ENFORCE`.
        """
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[str]:
        """
        Configure Binary Authorization evaluation mode.
        Possible values are: `DISABLED`, `PROJECT_SINGLETON_POLICY_ENFORCE`.
        """
        return pulumi.get(self, "evaluation_mode")


@pulumi.output_type
class AttachedClusterError(dict):
    def __init__(__self__, *,
                 message: Optional[str] = None):
        """
        :param str message: Human-friendly description of the error.
        """
        if message is not None:
            pulumi.set(__self__, "message", message)

    @property
    @pulumi.getter
    def message(self) -> Optional[str]:
        """
        Human-friendly description of the error.
        """
        return pulumi.get(self, "message")


@pulumi.output_type
class AttachedClusterFleet(dict):
    def __init__(__self__, *,
                 project: str,
                 membership: Optional[str] = None):
        """
        :param str project: The ID of the project in which the resource belongs.
               If it is not provided, the provider project is used.
        :param str membership: (Output)
               The name of the managed Hub Membership resource associated to this
               cluster. Membership names are formatted as
               projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        pulumi.set(__self__, "project", project)
        if membership is not None:
            pulumi.set(__self__, "membership", membership)

    @property
    @pulumi.getter
    def project(self) -> str:
        """
        The ID of the project in which the resource belongs.
        If it is not provided, the provider project is used.
        """
        return pulumi.get(self, "project")

    @property
    @pulumi.getter
    def membership(self) -> Optional[str]:
        """
        (Output)
        The name of the managed Hub Membership resource associated to this
        cluster. Membership names are formatted as
        projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")


@pulumi.output_type
class AttachedClusterLoggingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "componentConfig":
            suggest = "component_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterLoggingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterLoggingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterLoggingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component_config: Optional['outputs.AttachedClusterLoggingConfigComponentConfig'] = None):
        """
        :param 'AttachedClusterLoggingConfigComponentConfigArgs' component_config: The configuration of the logging components
               Structure is documented below.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional['outputs.AttachedClusterLoggingConfigComponentConfig']:
        """
        The configuration of the logging components
        Structure is documented below.
        """
        return pulumi.get(self, "component_config")


@pulumi.output_type
class AttachedClusterLoggingConfigComponentConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableComponents":
            suggest = "enable_components"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterLoggingConfigComponentConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_components: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] enable_components: The components to be enabled.
               Each value may be one of: `SYSTEM_COMPONENTS`, `WORKLOADS`.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[Sequence[str]]:
        """
        The components to be enabled.
        Each value may be one of: `SYSTEM_COMPONENTS`, `WORKLOADS`.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class AttachedClusterMonitoringConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "managedPrometheusConfig":
            suggest = "managed_prometheus_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterMonitoringConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterMonitoringConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterMonitoringConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 managed_prometheus_config: Optional['outputs.AttachedClusterMonitoringConfigManagedPrometheusConfig'] = None):
        """
        :param 'AttachedClusterMonitoringConfigManagedPrometheusConfigArgs' managed_prometheus_config: Enable Google Cloud Managed Service for Prometheus in the cluster.
               Structure is documented below.
        """
        if managed_prometheus_config is not None:
            pulumi.set(__self__, "managed_prometheus_config", managed_prometheus_config)

    @property
    @pulumi.getter(name="managedPrometheusConfig")
    def managed_prometheus_config(self) -> Optional['outputs.AttachedClusterMonitoringConfigManagedPrometheusConfig']:
        """
        Enable Google Cloud Managed Service for Prometheus in the cluster.
        Structure is documented below.
        """
        return pulumi.get(self, "managed_prometheus_config")


@pulumi.output_type
class AttachedClusterMonitoringConfigManagedPrometheusConfig(dict):
    def __init__(__self__, *,
                 enabled: Optional[bool] = None):
        """
        :param bool enabled: Enable Managed Collection.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[bool]:
        """
        Enable Managed Collection.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class AttachedClusterOidcConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "issuerUrl":
            suggest = "issuer_url"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterOidcConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterOidcConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterOidcConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 issuer_url: str,
                 jwks: Optional[str] = None):
        """
        :param str issuer_url: A JSON Web Token (JWT) issuer URI. `issuer` must start with `https://`
        :param str jwks: OIDC verification keys in JWKS format (RFC 7517).
        """
        pulumi.set(__self__, "issuer_url", issuer_url)
        if jwks is not None:
            pulumi.set(__self__, "jwks", jwks)

    @property
    @pulumi.getter(name="issuerUrl")
    def issuer_url(self) -> str:
        """
        A JSON Web Token (JWT) issuer URI. `issuer` must start with `https://`
        """
        return pulumi.get(self, "issuer_url")

    @property
    @pulumi.getter
    def jwks(self) -> Optional[str]:
        """
        OIDC verification keys in JWKS format (RFC 7517).
        """
        return pulumi.get(self, "jwks")


@pulumi.output_type
class AttachedClusterProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kubernetesSecret":
            suggest = "kubernetes_secret"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kubernetes_secret: Optional['outputs.AttachedClusterProxyConfigKubernetesSecret'] = None):
        """
        :param 'AttachedClusterProxyConfigKubernetesSecretArgs' kubernetes_secret: The Kubernetes Secret resource that contains the HTTP(S) proxy configuration.
               Structure is documented below.
        """
        if kubernetes_secret is not None:
            pulumi.set(__self__, "kubernetes_secret", kubernetes_secret)

    @property
    @pulumi.getter(name="kubernetesSecret")
    def kubernetes_secret(self) -> Optional['outputs.AttachedClusterProxyConfigKubernetesSecret']:
        """
        The Kubernetes Secret resource that contains the HTTP(S) proxy configuration.
        Structure is documented below.
        """
        return pulumi.get(self, "kubernetes_secret")


@pulumi.output_type
class AttachedClusterProxyConfigKubernetesSecret(dict):
    def __init__(__self__, *,
                 name: str,
                 namespace: str):
        """
        :param str name: Name of the kubernetes secret containing the proxy config.
        :param str namespace: Namespace of the kubernetes secret containing the proxy config.
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "namespace", namespace)

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        Name of the kubernetes secret containing the proxy config.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def namespace(self) -> str:
        """
        Namespace of the kubernetes secret containing the proxy config.
        """
        return pulumi.get(self, "namespace")


@pulumi.output_type
class AttachedClusterSecurityPostureConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "vulnerabilityMode":
            suggest = "vulnerability_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterSecurityPostureConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterSecurityPostureConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterSecurityPostureConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 vulnerability_mode: str):
        """
        :param str vulnerability_mode: Sets the mode of the Kubernetes security posture API's workload vulnerability scanning.
               Possible values are: `VULNERABILITY_DISABLED`, `VULNERABILITY_ENTERPRISE`.
        """
        pulumi.set(__self__, "vulnerability_mode", vulnerability_mode)

    @property
    @pulumi.getter(name="vulnerabilityMode")
    def vulnerability_mode(self) -> str:
        """
        Sets the mode of the Kubernetes security posture API's workload vulnerability scanning.
        Possible values are: `VULNERABILITY_DISABLED`, `VULNERABILITY_ENTERPRISE`.
        """
        return pulumi.get(self, "vulnerability_mode")


@pulumi.output_type
class AttachedClusterWorkloadIdentityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "identityProvider":
            suggest = "identity_provider"
        elif key == "issuerUri":
            suggest = "issuer_uri"
        elif key == "workloadPool":
            suggest = "workload_pool"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterWorkloadIdentityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterWorkloadIdentityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterWorkloadIdentityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 identity_provider: Optional[str] = None,
                 issuer_uri: Optional[str] = None,
                 workload_pool: Optional[str] = None):
        """
        :param str identity_provider: The ID of the OIDC Identity Provider (IdP) associated to
               the Workload Identity Pool.
        :param str issuer_uri: The OIDC issuer URL for this cluster.
        :param str workload_pool: The Workload Identity Pool associated to the cluster.
        """
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[str]:
        """
        The ID of the OIDC Identity Provider (IdP) associated to
        the Workload Identity Pool.
        """
        return pulumi.get(self, "identity_provider")

    @property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[str]:
        """
        The OIDC issuer URL for this cluster.
        """
        return pulumi.get(self, "issuer_uri")

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[str]:
        """
        The Workload Identity Pool associated to the cluster.
        """
        return pulumi.get(self, "workload_pool")


@pulumi.output_type
class AwsClusterAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminUsers":
            suggest = "admin_users"
        elif key == "adminGroups":
            suggest = "admin_groups"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_users: Sequence['outputs.AwsClusterAuthorizationAdminUser'],
                 admin_groups: Optional[Sequence['outputs.AwsClusterAuthorizationAdminGroup']] = None):
        """
        :param Sequence['AwsClusterAuthorizationAdminUserArgs'] admin_users: Users to perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        :param Sequence['AwsClusterAuthorizationAdminGroupArgs'] admin_groups: Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        pulumi.set(__self__, "admin_users", admin_users)
        if admin_groups is not None:
            pulumi.set(__self__, "admin_groups", admin_groups)

    @property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> Sequence['outputs.AwsClusterAuthorizationAdminUser']:
        """
        Users to perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")

    @property
    @pulumi.getter(name="adminGroups")
    def admin_groups(self) -> Optional[Sequence['outputs.AwsClusterAuthorizationAdminGroup']]:
        """
        Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_groups")


@pulumi.output_type
class AwsClusterAuthorizationAdminGroup(dict):
    def __init__(__self__, *,
                 group: str):
        """
        :param str group: The name of the group, e.g. `my-group@domain.com`.
        """
        pulumi.set(__self__, "group", group)

    @property
    @pulumi.getter
    def group(self) -> str:
        """
        The name of the group, e.g. `my-group@domain.com`.
        """
        return pulumi.get(self, "group")


@pulumi.output_type
class AwsClusterAuthorizationAdminUser(dict):
    def __init__(__self__, *,
                 username: str):
        """
        :param str username: The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def username(self) -> str:
        """
        The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class AwsClusterBinaryAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "evaluationMode":
            suggest = "evaluation_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterBinaryAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterBinaryAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterBinaryAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 evaluation_mode: Optional[str] = None):
        """
        :param str evaluation_mode: Mode of operation for Binary Authorization policy evaluation. Possible values: DISABLED, PROJECT_SINGLETON_POLICY_ENFORCE
        """
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[str]:
        """
        Mode of operation for Binary Authorization policy evaluation. Possible values: DISABLED, PROJECT_SINGLETON_POLICY_ENFORCE
        """
        return pulumi.get(self, "evaluation_mode")


@pulumi.output_type
class AwsClusterControlPlane(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "awsServicesAuthentication":
            suggest = "aws_services_authentication"
        elif key == "configEncryption":
            suggest = "config_encryption"
        elif key == "databaseEncryption":
            suggest = "database_encryption"
        elif key == "iamInstanceProfile":
            suggest = "iam_instance_profile"
        elif key == "subnetIds":
            suggest = "subnet_ids"
        elif key == "instancePlacement":
            suggest = "instance_placement"
        elif key == "instanceType":
            suggest = "instance_type"
        elif key == "mainVolume":
            suggest = "main_volume"
        elif key == "proxyConfig":
            suggest = "proxy_config"
        elif key == "rootVolume":
            suggest = "root_volume"
        elif key == "securityGroupIds":
            suggest = "security_group_ids"
        elif key == "sshConfig":
            suggest = "ssh_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlane. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlane.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlane.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 aws_services_authentication: 'outputs.AwsClusterControlPlaneAwsServicesAuthentication',
                 config_encryption: 'outputs.AwsClusterControlPlaneConfigEncryption',
                 database_encryption: 'outputs.AwsClusterControlPlaneDatabaseEncryption',
                 iam_instance_profile: str,
                 subnet_ids: Sequence[str],
                 version: str,
                 instance_placement: Optional['outputs.AwsClusterControlPlaneInstancePlacement'] = None,
                 instance_type: Optional[str] = None,
                 main_volume: Optional['outputs.AwsClusterControlPlaneMainVolume'] = None,
                 proxy_config: Optional['outputs.AwsClusterControlPlaneProxyConfig'] = None,
                 root_volume: Optional['outputs.AwsClusterControlPlaneRootVolume'] = None,
                 security_group_ids: Optional[Sequence[str]] = None,
                 ssh_config: Optional['outputs.AwsClusterControlPlaneSshConfig'] = None,
                 tags: Optional[Mapping[str, str]] = None):
        """
        :param 'AwsClusterControlPlaneAwsServicesAuthenticationArgs' aws_services_authentication: Authentication configuration for management of AWS resources.
        :param 'AwsClusterControlPlaneConfigEncryptionArgs' config_encryption: The ARN of the AWS KMS key used to encrypt cluster configuration.
        :param 'AwsClusterControlPlaneDatabaseEncryptionArgs' database_encryption: The ARN of the AWS KMS key used to encrypt cluster secrets.
        :param str iam_instance_profile: The name of the AWS IAM instance pofile to assign to each control plane replica.
        :param Sequence[str] subnet_ids: The list of subnets where control plane replicas will run. A replica will be provisioned on each subnet and up to three values can be provided. Each subnet must be in a different AWS Availability Zone (AZ).
        :param str version: The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling .
        :param 'AwsClusterControlPlaneInstancePlacementArgs' instance_placement: Details of placement information for an instance.
        :param str instance_type: Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        :param 'AwsClusterControlPlaneMainVolumeArgs' main_volume: Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 8 GiB with the GP2 volume type.
        :param 'AwsClusterControlPlaneProxyConfigArgs' proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param 'AwsClusterControlPlaneRootVolumeArgs' root_volume: Optional. Configuration related to the root volume provisioned for each control plane replica. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        :param Sequence[str] security_group_ids: Optional. The IDs of additional security groups to add to control plane replicas. The Anthos Multi-Cloud API will automatically create and manage security groups with the minimum rules needed for a functioning cluster.
        :param 'AwsClusterControlPlaneSshConfigArgs' ssh_config: Optional. SSH configuration for how to access the underlying control plane machines.
        :param Mapping[str, str] tags: Optional. A set of AWS resource tags to propagate to all underlying managed AWS resources. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        pulumi.set(__self__, "aws_services_authentication", aws_services_authentication)
        pulumi.set(__self__, "config_encryption", config_encryption)
        pulumi.set(__self__, "database_encryption", database_encryption)
        pulumi.set(__self__, "iam_instance_profile", iam_instance_profile)
        pulumi.set(__self__, "subnet_ids", subnet_ids)
        pulumi.set(__self__, "version", version)
        if instance_placement is not None:
            pulumi.set(__self__, "instance_placement", instance_placement)
        if instance_type is not None:
            pulumi.set(__self__, "instance_type", instance_type)
        if main_volume is not None:
            pulumi.set(__self__, "main_volume", main_volume)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if security_group_ids is not None:
            pulumi.set(__self__, "security_group_ids", security_group_ids)
        if ssh_config is not None:
            pulumi.set(__self__, "ssh_config", ssh_config)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @property
    @pulumi.getter(name="awsServicesAuthentication")
    def aws_services_authentication(self) -> 'outputs.AwsClusterControlPlaneAwsServicesAuthentication':
        """
        Authentication configuration for management of AWS resources.
        """
        return pulumi.get(self, "aws_services_authentication")

    @property
    @pulumi.getter(name="configEncryption")
    def config_encryption(self) -> 'outputs.AwsClusterControlPlaneConfigEncryption':
        """
        The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        return pulumi.get(self, "config_encryption")

    @property
    @pulumi.getter(name="databaseEncryption")
    def database_encryption(self) -> 'outputs.AwsClusterControlPlaneDatabaseEncryption':
        """
        The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        return pulumi.get(self, "database_encryption")

    @property
    @pulumi.getter(name="iamInstanceProfile")
    def iam_instance_profile(self) -> str:
        """
        The name of the AWS IAM instance pofile to assign to each control plane replica.
        """
        return pulumi.get(self, "iam_instance_profile")

    @property
    @pulumi.getter(name="subnetIds")
    def subnet_ids(self) -> Sequence[str]:
        """
        The list of subnets where control plane replicas will run. A replica will be provisioned on each subnet and up to three values can be provided. Each subnet must be in a different AWS Availability Zone (AZ).
        """
        return pulumi.get(self, "subnet_ids")

    @property
    @pulumi.getter
    def version(self) -> str:
        """
        The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling .
        """
        return pulumi.get(self, "version")

    @property
    @pulumi.getter(name="instancePlacement")
    def instance_placement(self) -> Optional['outputs.AwsClusterControlPlaneInstancePlacement']:
        """
        Details of placement information for an instance.
        """
        return pulumi.get(self, "instance_placement")

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> Optional[str]:
        """
        Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        """
        return pulumi.get(self, "instance_type")

    @property
    @pulumi.getter(name="mainVolume")
    def main_volume(self) -> Optional['outputs.AwsClusterControlPlaneMainVolume']:
        """
        Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 8 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "main_volume")

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional['outputs.AwsClusterControlPlaneProxyConfig']:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional['outputs.AwsClusterControlPlaneRootVolume']:
        """
        Optional. Configuration related to the root volume provisioned for each control plane replica. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "root_volume")

    @property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> Optional[Sequence[str]]:
        """
        Optional. The IDs of additional security groups to add to control plane replicas. The Anthos Multi-Cloud API will automatically create and manage security groups with the minimum rules needed for a functioning cluster.
        """
        return pulumi.get(self, "security_group_ids")

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> Optional['outputs.AwsClusterControlPlaneSshConfig']:
        """
        Optional. SSH configuration for how to access the underlying control plane machines.
        """
        return pulumi.get(self, "ssh_config")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, str]]:
        """
        Optional. A set of AWS resource tags to propagate to all underlying managed AWS resources. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")


@pulumi.output_type
class AwsClusterControlPlaneAwsServicesAuthentication(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "roleArn":
            suggest = "role_arn"
        elif key == "roleSessionName":
            suggest = "role_session_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneAwsServicesAuthentication. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneAwsServicesAuthentication.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneAwsServicesAuthentication.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 role_arn: str,
                 role_session_name: Optional[str] = None):
        """
        :param str role_arn: The Amazon Resource Name (ARN) of the role that the Anthos Multi-Cloud API will assume when managing AWS resources on your account.
        :param str role_session_name: Optional. An identifier for the assumed role session. When unspecified, it defaults to `multicloud-service-agent`.
        """
        pulumi.set(__self__, "role_arn", role_arn)
        if role_session_name is not None:
            pulumi.set(__self__, "role_session_name", role_session_name)

    @property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> str:
        """
        The Amazon Resource Name (ARN) of the role that the Anthos Multi-Cloud API will assume when managing AWS resources on your account.
        """
        return pulumi.get(self, "role_arn")

    @property
    @pulumi.getter(name="roleSessionName")
    def role_session_name(self) -> Optional[str]:
        """
        Optional. An identifier for the assumed role session. When unspecified, it defaults to `multicloud-service-agent`.
        """
        return pulumi.get(self, "role_session_name")


@pulumi.output_type
class AwsClusterControlPlaneConfigEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneConfigEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneConfigEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneConfigEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kms_key_arn: str):
        """
        :param str kms_key_arn: The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> str:
        """
        The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        return pulumi.get(self, "kms_key_arn")


@pulumi.output_type
class AwsClusterControlPlaneDatabaseEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneDatabaseEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneDatabaseEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneDatabaseEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kms_key_arn: str):
        """
        :param str kms_key_arn: The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> str:
        """
        The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        return pulumi.get(self, "kms_key_arn")


@pulumi.output_type
class AwsClusterControlPlaneInstancePlacement(dict):
    def __init__(__self__, *,
                 tenancy: Optional[str] = None):
        """
        :param str tenancy: The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        if tenancy is not None:
            pulumi.set(__self__, "tenancy", tenancy)

    @property
    @pulumi.getter
    def tenancy(self) -> Optional[str]:
        """
        The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        return pulumi.get(self, "tenancy")


@pulumi.output_type
class AwsClusterControlPlaneMainVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"
        elif key == "sizeGib":
            suggest = "size_gib"
        elif key == "volumeType":
            suggest = "volume_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneMainVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneMainVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneMainVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 iops: Optional[int] = None,
                 kms_key_arn: Optional[str] = None,
                 size_gib: Optional[int] = None,
                 throughput: Optional[int] = None,
                 volume_type: Optional[str] = None):
        """
        :param int iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param str kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param int size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param int throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        :param str volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter
    def iops(self) -> Optional[int]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[str]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[int]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @property
    @pulumi.getter
    def throughput(self) -> Optional[int]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        """
        return pulumi.get(self, "throughput")

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[str]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")


@pulumi.output_type
class AwsClusterControlPlaneProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretArn":
            suggest = "secret_arn"
        elif key == "secretVersion":
            suggest = "secret_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_arn: str,
                 secret_version: str):
        """
        :param str secret_arn: The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        :param str secret_version: The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        pulumi.set(__self__, "secret_arn", secret_arn)
        pulumi.set(__self__, "secret_version", secret_version)

    @property
    @pulumi.getter(name="secretArn")
    def secret_arn(self) -> str:
        """
        The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_arn")

    @property
    @pulumi.getter(name="secretVersion")
    def secret_version(self) -> str:
        """
        The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_version")


@pulumi.output_type
class AwsClusterControlPlaneRootVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"
        elif key == "sizeGib":
            suggest = "size_gib"
        elif key == "volumeType":
            suggest = "volume_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneRootVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneRootVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneRootVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 iops: Optional[int] = None,
                 kms_key_arn: Optional[str] = None,
                 size_gib: Optional[int] = None,
                 throughput: Optional[int] = None,
                 volume_type: Optional[str] = None):
        """
        :param int iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param str kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param int size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param int throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        :param str volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter
    def iops(self) -> Optional[int]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[str]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[int]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @property
    @pulumi.getter
    def throughput(self) -> Optional[int]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        """
        return pulumi.get(self, "throughput")

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[str]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")


@pulumi.output_type
class AwsClusterControlPlaneSshConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ec2KeyPair":
            suggest = "ec2_key_pair"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneSshConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneSshConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneSshConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ec2_key_pair: str):
        """
        :param str ec2_key_pair: The name of the EC2 key pair used to login into cluster machines.
        """
        pulumi.set(__self__, "ec2_key_pair", ec2_key_pair)

    @property
    @pulumi.getter(name="ec2KeyPair")
    def ec2_key_pair(self) -> str:
        """
        The name of the EC2 key pair used to login into cluster machines.
        """
        return pulumi.get(self, "ec2_key_pair")


@pulumi.output_type
class AwsClusterFleet(dict):
    def __init__(__self__, *,
                 membership: Optional[str] = None,
                 project: Optional[str] = None):
        """
        :param str membership: The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        :param str project: The number of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @property
    @pulumi.getter
    def membership(self) -> Optional[str]:
        """
        The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")

    @property
    @pulumi.getter
    def project(self) -> Optional[str]:
        """
        The number of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")


@pulumi.output_type
class AwsClusterLoggingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "componentConfig":
            suggest = "component_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterLoggingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterLoggingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterLoggingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component_config: Optional['outputs.AwsClusterLoggingConfigComponentConfig'] = None):
        """
        :param 'AwsClusterLoggingConfigComponentConfigArgs' component_config: Configuration of the logging components.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional['outputs.AwsClusterLoggingConfigComponentConfig']:
        """
        Configuration of the logging components.
        """
        return pulumi.get(self, "component_config")


@pulumi.output_type
class AwsClusterLoggingConfigComponentConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableComponents":
            suggest = "enable_components"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterLoggingConfigComponentConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_components: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] enable_components: Components of the logging configuration to be enabled.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[Sequence[str]]:
        """
        Components of the logging configuration to be enabled.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class AwsClusterNetworking(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "podAddressCidrBlocks":
            suggest = "pod_address_cidr_blocks"
        elif key == "serviceAddressCidrBlocks":
            suggest = "service_address_cidr_blocks"
        elif key == "vpcId":
            suggest = "vpc_id"
        elif key == "perNodePoolSgRulesDisabled":
            suggest = "per_node_pool_sg_rules_disabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterNetworking. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterNetworking.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterNetworking.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pod_address_cidr_blocks: Sequence[str],
                 service_address_cidr_blocks: Sequence[str],
                 vpc_id: str,
                 per_node_pool_sg_rules_disabled: Optional[bool] = None):
        """
        :param Sequence[str] pod_address_cidr_blocks: All pods in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param Sequence[str] service_address_cidr_blocks: All services in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param str vpc_id: The VPC associated with the cluster. All component clusters (i.e. control plane and node pools) run on a single VPC. This field cannot be changed after creation.
               
               - - -
        :param bool per_node_pool_sg_rules_disabled: Disable the per node pool subnet security group rules on the control plane security group. When set to true, you must also provide one or more security groups that ensure node pools are able to send requests to the control plane on TCP/443 and TCP/8132. Failure to do so may result in unavailable node pools.
        """
        pulumi.set(__self__, "pod_address_cidr_blocks", pod_address_cidr_blocks)
        pulumi.set(__self__, "service_address_cidr_blocks", service_address_cidr_blocks)
        pulumi.set(__self__, "vpc_id", vpc_id)
        if per_node_pool_sg_rules_disabled is not None:
            pulumi.set(__self__, "per_node_pool_sg_rules_disabled", per_node_pool_sg_rules_disabled)

    @property
    @pulumi.getter(name="podAddressCidrBlocks")
    def pod_address_cidr_blocks(self) -> Sequence[str]:
        """
        All pods in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "pod_address_cidr_blocks")

    @property
    @pulumi.getter(name="serviceAddressCidrBlocks")
    def service_address_cidr_blocks(self) -> Sequence[str]:
        """
        All services in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "service_address_cidr_blocks")

    @property
    @pulumi.getter(name="vpcId")
    def vpc_id(self) -> str:
        """
        The VPC associated with the cluster. All component clusters (i.e. control plane and node pools) run on a single VPC. This field cannot be changed after creation.

        - - -
        """
        return pulumi.get(self, "vpc_id")

    @property
    @pulumi.getter(name="perNodePoolSgRulesDisabled")
    def per_node_pool_sg_rules_disabled(self) -> Optional[bool]:
        """
        Disable the per node pool subnet security group rules on the control plane security group. When set to true, you must also provide one or more security groups that ensure node pools are able to send requests to the control plane on TCP/443 and TCP/8132. Failure to do so may result in unavailable node pools.
        """
        return pulumi.get(self, "per_node_pool_sg_rules_disabled")


@pulumi.output_type
class AwsClusterWorkloadIdentityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "identityProvider":
            suggest = "identity_provider"
        elif key == "issuerUri":
            suggest = "issuer_uri"
        elif key == "workloadPool":
            suggest = "workload_pool"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterWorkloadIdentityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterWorkloadIdentityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterWorkloadIdentityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 identity_provider: Optional[str] = None,
                 issuer_uri: Optional[str] = None,
                 workload_pool: Optional[str] = None):
        """
        :param str identity_provider: The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        :param str issuer_uri: The OIDC issuer URL for this cluster.
        :param str workload_pool: The Workload Identity Pool associated to the cluster.
        """
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[str]:
        """
        The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        """
        return pulumi.get(self, "identity_provider")

    @property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[str]:
        """
        The OIDC issuer URL for this cluster.
        """
        return pulumi.get(self, "issuer_uri")

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[str]:
        """
        The Workload Identity Pool associated to the cluster.
        """
        return pulumi.get(self, "workload_pool")


@pulumi.output_type
class AwsNodePoolAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxNodeCount":
            suggest = "max_node_count"
        elif key == "minNodeCount":
            suggest = "min_node_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_node_count: int,
                 min_node_count: int):
        """
        :param int max_node_count: Maximum number of nodes in the NodePool. Must be >= min_node_count.
        :param int min_node_count: Minimum number of nodes in the NodePool. Must be >= 1 and <= max_node_count.
        """
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> int:
        """
        Maximum number of nodes in the NodePool. Must be >= min_node_count.
        """
        return pulumi.get(self, "max_node_count")

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> int:
        """
        Minimum number of nodes in the NodePool. Must be >= 1 and <= max_node_count.
        """
        return pulumi.get(self, "min_node_count")


@pulumi.output_type
class AwsNodePoolConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "configEncryption":
            suggest = "config_encryption"
        elif key == "iamInstanceProfile":
            suggest = "iam_instance_profile"
        elif key == "autoscalingMetricsCollection":
            suggest = "autoscaling_metrics_collection"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "instancePlacement":
            suggest = "instance_placement"
        elif key == "instanceType":
            suggest = "instance_type"
        elif key == "proxyConfig":
            suggest = "proxy_config"
        elif key == "rootVolume":
            suggest = "root_volume"
        elif key == "securityGroupIds":
            suggest = "security_group_ids"
        elif key == "spotConfig":
            suggest = "spot_config"
        elif key == "sshConfig":
            suggest = "ssh_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 config_encryption: 'outputs.AwsNodePoolConfigConfigEncryption',
                 iam_instance_profile: str,
                 autoscaling_metrics_collection: Optional['outputs.AwsNodePoolConfigAutoscalingMetricsCollection'] = None,
                 image_type: Optional[str] = None,
                 instance_placement: Optional['outputs.AwsNodePoolConfigInstancePlacement'] = None,
                 instance_type: Optional[str] = None,
                 labels: Optional[Mapping[str, str]] = None,
                 proxy_config: Optional['outputs.AwsNodePoolConfigProxyConfig'] = None,
                 root_volume: Optional['outputs.AwsNodePoolConfigRootVolume'] = None,
                 security_group_ids: Optional[Sequence[str]] = None,
                 spot_config: Optional['outputs.AwsNodePoolConfigSpotConfig'] = None,
                 ssh_config: Optional['outputs.AwsNodePoolConfigSshConfig'] = None,
                 tags: Optional[Mapping[str, str]] = None,
                 taints: Optional[Sequence['outputs.AwsNodePoolConfigTaint']] = None):
        """
        :param 'AwsNodePoolConfigConfigEncryptionArgs' config_encryption: The ARN of the AWS KMS key used to encrypt node pool configuration.
        :param str iam_instance_profile: The name of the AWS IAM role assigned to nodes in the pool.
        :param 'AwsNodePoolConfigAutoscalingMetricsCollectionArgs' autoscaling_metrics_collection: Optional. Configuration related to CloudWatch metrics collection on the Auto Scaling group of the node pool. When unspecified, metrics collection is disabled.
        :param str image_type: The OS image type to use on node pool instances.
        :param 'AwsNodePoolConfigInstancePlacementArgs' instance_placement: Details of placement information for an instance.
        :param str instance_type: Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        :param Mapping[str, str] labels: Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        :param 'AwsNodePoolConfigProxyConfigArgs' proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param 'AwsNodePoolConfigRootVolumeArgs' root_volume: Optional. Template for the root volume provisioned for node pool nodes. Volumes will be provisioned in the availability zone assigned to the node pool subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        :param Sequence[str] security_group_ids: Optional. The IDs of additional security groups to add to nodes in this pool. The manager will automatically create security groups with minimum rules needed for a functioning cluster.
        :param 'AwsNodePoolConfigSpotConfigArgs' spot_config: Optional. When specified, the node pool will provision Spot instances from the set of spot_config.instance_types. This field is mutually exclusive with `instance_type`
        :param 'AwsNodePoolConfigSshConfigArgs' ssh_config: Optional. The SSH configuration.
        :param Mapping[str, str] tags: Optional. Key/value metadata to assign to each underlying AWS resource. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        :param Sequence['AwsNodePoolConfigTaintArgs'] taints: Optional. The initial taints assigned to nodes of this node pool.
        """
        pulumi.set(__self__, "config_encryption", config_encryption)
        pulumi.set(__self__, "iam_instance_profile", iam_instance_profile)
        if autoscaling_metrics_collection is not None:
            pulumi.set(__self__, "autoscaling_metrics_collection", autoscaling_metrics_collection)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if instance_placement is not None:
            pulumi.set(__self__, "instance_placement", instance_placement)
        if instance_type is not None:
            pulumi.set(__self__, "instance_type", instance_type)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if security_group_ids is not None:
            pulumi.set(__self__, "security_group_ids", security_group_ids)
        if spot_config is not None:
            pulumi.set(__self__, "spot_config", spot_config)
        if ssh_config is not None:
            pulumi.set(__self__, "ssh_config", ssh_config)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)

    @property
    @pulumi.getter(name="configEncryption")
    def config_encryption(self) -> 'outputs.AwsNodePoolConfigConfigEncryption':
        """
        The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        return pulumi.get(self, "config_encryption")

    @property
    @pulumi.getter(name="iamInstanceProfile")
    def iam_instance_profile(self) -> str:
        """
        The name of the AWS IAM role assigned to nodes in the pool.
        """
        return pulumi.get(self, "iam_instance_profile")

    @property
    @pulumi.getter(name="autoscalingMetricsCollection")
    def autoscaling_metrics_collection(self) -> Optional['outputs.AwsNodePoolConfigAutoscalingMetricsCollection']:
        """
        Optional. Configuration related to CloudWatch metrics collection on the Auto Scaling group of the node pool. When unspecified, metrics collection is disabled.
        """
        return pulumi.get(self, "autoscaling_metrics_collection")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[str]:
        """
        The OS image type to use on node pool instances.
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="instancePlacement")
    def instance_placement(self) -> Optional['outputs.AwsNodePoolConfigInstancePlacement']:
        """
        Details of placement information for an instance.
        """
        return pulumi.get(self, "instance_placement")

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> Optional[str]:
        """
        Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        """
        return pulumi.get(self, "instance_type")

    @property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, str]]:
        """
        Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional['outputs.AwsNodePoolConfigProxyConfig']:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional['outputs.AwsNodePoolConfigRootVolume']:
        """
        Optional. Template for the root volume provisioned for node pool nodes. Volumes will be provisioned in the availability zone assigned to the node pool subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "root_volume")

    @property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> Optional[Sequence[str]]:
        """
        Optional. The IDs of additional security groups to add to nodes in this pool. The manager will automatically create security groups with minimum rules needed for a functioning cluster.
        """
        return pulumi.get(self, "security_group_ids")

    @property
    @pulumi.getter(name="spotConfig")
    def spot_config(self) -> Optional['outputs.AwsNodePoolConfigSpotConfig']:
        """
        Optional. When specified, the node pool will provision Spot instances from the set of spot_config.instance_types. This field is mutually exclusive with `instance_type`
        """
        return pulumi.get(self, "spot_config")

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> Optional['outputs.AwsNodePoolConfigSshConfig']:
        """
        Optional. The SSH configuration.
        """
        return pulumi.get(self, "ssh_config")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, str]]:
        """
        Optional. Key/value metadata to assign to each underlying AWS resource. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def taints(self) -> Optional[Sequence['outputs.AwsNodePoolConfigTaint']]:
        """
        Optional. The initial taints assigned to nodes of this node pool.
        """
        return pulumi.get(self, "taints")


@pulumi.output_type
class AwsNodePoolConfigAutoscalingMetricsCollection(dict):
    def __init__(__self__, *,
                 granularity: str,
                 metrics: Optional[Sequence[str]] = None):
        """
        :param str granularity: The frequency at which EC2 Auto Scaling sends aggregated data to AWS CloudWatch. The only valid value is "1Minute".
        :param Sequence[str] metrics: The metrics to enable. For a list of valid metrics, see https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html. If you specify granularity and don't specify any metrics, all metrics are enabled.
        """
        pulumi.set(__self__, "granularity", granularity)
        if metrics is not None:
            pulumi.set(__self__, "metrics", metrics)

    @property
    @pulumi.getter
    def granularity(self) -> str:
        """
        The frequency at which EC2 Auto Scaling sends aggregated data to AWS CloudWatch. The only valid value is "1Minute".
        """
        return pulumi.get(self, "granularity")

    @property
    @pulumi.getter
    def metrics(self) -> Optional[Sequence[str]]:
        """
        The metrics to enable. For a list of valid metrics, see https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html. If you specify granularity and don't specify any metrics, all metrics are enabled.
        """
        return pulumi.get(self, "metrics")


@pulumi.output_type
class AwsNodePoolConfigConfigEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigConfigEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigConfigEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigConfigEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kms_key_arn: str):
        """
        :param str kms_key_arn: The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> str:
        """
        The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        return pulumi.get(self, "kms_key_arn")


@pulumi.output_type
class AwsNodePoolConfigInstancePlacement(dict):
    def __init__(__self__, *,
                 tenancy: Optional[str] = None):
        """
        :param str tenancy: The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        if tenancy is not None:
            pulumi.set(__self__, "tenancy", tenancy)

    @property
    @pulumi.getter
    def tenancy(self) -> Optional[str]:
        """
        The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        return pulumi.get(self, "tenancy")


@pulumi.output_type
class AwsNodePoolConfigProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretArn":
            suggest = "secret_arn"
        elif key == "secretVersion":
            suggest = "secret_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_arn: str,
                 secret_version: str):
        """
        :param str secret_arn: The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        :param str secret_version: The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        pulumi.set(__self__, "secret_arn", secret_arn)
        pulumi.set(__self__, "secret_version", secret_version)

    @property
    @pulumi.getter(name="secretArn")
    def secret_arn(self) -> str:
        """
        The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_arn")

    @property
    @pulumi.getter(name="secretVersion")
    def secret_version(self) -> str:
        """
        The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_version")


@pulumi.output_type
class AwsNodePoolConfigRootVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"
        elif key == "sizeGib":
            suggest = "size_gib"
        elif key == "volumeType":
            suggest = "volume_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigRootVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigRootVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigRootVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 iops: Optional[int] = None,
                 kms_key_arn: Optional[str] = None,
                 size_gib: Optional[int] = None,
                 throughput: Optional[int] = None,
                 volume_type: Optional[str] = None):
        """
        :param int iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param str kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param int size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param int throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        :param str volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter
    def iops(self) -> Optional[int]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[str]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[int]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @property
    @pulumi.getter
    def throughput(self) -> Optional[int]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        """
        return pulumi.get(self, "throughput")

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[str]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")


@pulumi.output_type
class AwsNodePoolConfigSpotConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "instanceTypes":
            suggest = "instance_types"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigSpotConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigSpotConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigSpotConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 instance_types: Sequence[str]):
        """
        :param Sequence[str] instance_types: List of AWS EC2 instance types for creating a spot node pool's nodes. The specified instance types must have the same number of CPUs and memory. You can use the Amazon EC2 Instance Selector tool (https://github.com/aws/amazon-ec2-instance-selector) to choose instance types with matching CPU and memory
        """
        pulumi.set(__self__, "instance_types", instance_types)

    @property
    @pulumi.getter(name="instanceTypes")
    def instance_types(self) -> Sequence[str]:
        """
        List of AWS EC2 instance types for creating a spot node pool's nodes. The specified instance types must have the same number of CPUs and memory. You can use the Amazon EC2 Instance Selector tool (https://github.com/aws/amazon-ec2-instance-selector) to choose instance types with matching CPU and memory
        """
        return pulumi.get(self, "instance_types")


@pulumi.output_type
class AwsNodePoolConfigSshConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ec2KeyPair":
            suggest = "ec2_key_pair"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigSshConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigSshConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigSshConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ec2_key_pair: str):
        """
        :param str ec2_key_pair: The name of the EC2 key pair used to login into cluster machines.
        """
        pulumi.set(__self__, "ec2_key_pair", ec2_key_pair)

    @property
    @pulumi.getter(name="ec2KeyPair")
    def ec2_key_pair(self) -> str:
        """
        The name of the EC2 key pair used to login into cluster machines.
        """
        return pulumi.get(self, "ec2_key_pair")


@pulumi.output_type
class AwsNodePoolConfigTaint(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        """
        :param str effect: The taint effect. Possible values: EFFECT_UNSPECIFIED, NO_SCHEDULE, PREFER_NO_SCHEDULE, NO_EXECUTE
        :param str key: Key for the taint.
        :param str value: Value for the taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        """
        The taint effect. Possible values: EFFECT_UNSPECIFIED, NO_SCHEDULE, PREFER_NO_SCHEDULE, NO_EXECUTE
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        Key for the taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value for the taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class AwsNodePoolKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cpuCfsQuota":
            suggest = "cpu_cfs_quota"
        elif key == "cpuCfsQuotaPeriod":
            suggest = "cpu_cfs_quota_period"
        elif key == "cpuManagerPolicy":
            suggest = "cpu_manager_policy"
        elif key == "podPidsLimit":
            suggest = "pod_pids_limit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cpu_cfs_quota: Optional[bool] = None,
                 cpu_cfs_quota_period: Optional[str] = None,
                 cpu_manager_policy: Optional[str] = None,
                 pod_pids_limit: Optional[int] = None):
        """
        :param bool cpu_cfs_quota: Whether or not to enable CPU CFS quota. Defaults to true.
        :param str cpu_cfs_quota_period: Optional. The CPU CFS quota period to use for the node. Defaults to "100ms".
        :param str cpu_manager_policy: The CpuManagerPolicy to use for the node. Defaults to "none".
        :param int pod_pids_limit: Optional. The maximum number of PIDs in each pod running on the node. The limit scales automatically based on underlying machine size if left unset.
        """
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if cpu_manager_policy is not None:
            pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[bool]:
        """
        Whether or not to enable CPU CFS quota. Defaults to true.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[str]:
        """
        Optional. The CPU CFS quota period to use for the node. Defaults to "100ms".
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> Optional[str]:
        """
        The CpuManagerPolicy to use for the node. Defaults to "none".
        """
        return pulumi.get(self, "cpu_manager_policy")

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[int]:
        """
        Optional. The maximum number of PIDs in each pod running on the node. The limit scales automatically based on underlying machine size if left unset.
        """
        return pulumi.get(self, "pod_pids_limit")


@pulumi.output_type
class AwsNodePoolManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[bool] = None):
        """
        :param bool auto_repair: Optional. Whether or not the nodes will be automatically repaired.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[bool]:
        """
        Optional. Whether or not the nodes will be automatically repaired.
        """
        return pulumi.get(self, "auto_repair")


@pulumi.output_type
class AwsNodePoolMaxPodsConstraint(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxPodsPerNode":
            suggest = "max_pods_per_node"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolMaxPodsConstraint. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolMaxPodsConstraint.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolMaxPodsConstraint.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_pods_per_node: int):
        """
        :param int max_pods_per_node: The maximum number of pods to schedule on a single node.
               
               - - -
        """
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> int:
        """
        The maximum number of pods to schedule on a single node.

        - - -
        """
        return pulumi.get(self, "max_pods_per_node")


@pulumi.output_type
class AwsNodePoolUpdateSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "surgeSettings":
            suggest = "surge_settings"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolUpdateSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolUpdateSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolUpdateSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 surge_settings: Optional['outputs.AwsNodePoolUpdateSettingsSurgeSettings'] = None):
        """
        :param 'AwsNodePoolUpdateSettingsSurgeSettingsArgs' surge_settings: Optional. Settings for surge update.
        """
        if surge_settings is not None:
            pulumi.set(__self__, "surge_settings", surge_settings)

    @property
    @pulumi.getter(name="surgeSettings")
    def surge_settings(self) -> Optional['outputs.AwsNodePoolUpdateSettingsSurgeSettings']:
        """
        Optional. Settings for surge update.
        """
        return pulumi.get(self, "surge_settings")


@pulumi.output_type
class AwsNodePoolUpdateSettingsSurgeSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxSurge":
            suggest = "max_surge"
        elif key == "maxUnavailable":
            suggest = "max_unavailable"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolUpdateSettingsSurgeSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolUpdateSettingsSurgeSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolUpdateSettingsSurgeSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_surge: Optional[int] = None,
                 max_unavailable: Optional[int] = None):
        """
        :param int max_surge: Optional. The maximum number of nodes that can be created beyond the current size of the node pool during the update process.
        :param int max_unavailable: Optional. The maximum number of nodes that can be simultaneously unavailable during the update process. A node is considered unavailable if its status is not Ready.
        """
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[int]:
        """
        Optional. The maximum number of nodes that can be created beyond the current size of the node pool during the update process.
        """
        return pulumi.get(self, "max_surge")

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[int]:
        """
        Optional. The maximum number of nodes that can be simultaneously unavailable during the update process. A node is considered unavailable if its status is not Ready.
        """
        return pulumi.get(self, "max_unavailable")


@pulumi.output_type
class AzureClusterAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminUsers":
            suggest = "admin_users"
        elif key == "adminGroups":
            suggest = "admin_groups"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_users: Sequence['outputs.AzureClusterAuthorizationAdminUser'],
                 admin_groups: Optional[Sequence['outputs.AzureClusterAuthorizationAdminGroup']] = None):
        """
        :param Sequence['AzureClusterAuthorizationAdminUserArgs'] admin_users: Users that can perform operations as a cluster admin. A new ClusterRoleBinding will be created to grant the cluster-admin ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        :param Sequence['AzureClusterAuthorizationAdminGroupArgs'] admin_groups: Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        pulumi.set(__self__, "admin_users", admin_users)
        if admin_groups is not None:
            pulumi.set(__self__, "admin_groups", admin_groups)

    @property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> Sequence['outputs.AzureClusterAuthorizationAdminUser']:
        """
        Users that can perform operations as a cluster admin. A new ClusterRoleBinding will be created to grant the cluster-admin ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")

    @property
    @pulumi.getter(name="adminGroups")
    def admin_groups(self) -> Optional[Sequence['outputs.AzureClusterAuthorizationAdminGroup']]:
        """
        Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_groups")


@pulumi.output_type
class AzureClusterAuthorizationAdminGroup(dict):
    def __init__(__self__, *,
                 group: str):
        """
        :param str group: The name of the group, e.g. `my-group@domain.com`.
        """
        pulumi.set(__self__, "group", group)

    @property
    @pulumi.getter
    def group(self) -> str:
        """
        The name of the group, e.g. `my-group@domain.com`.
        """
        return pulumi.get(self, "group")


@pulumi.output_type
class AzureClusterAuthorizationAdminUser(dict):
    def __init__(__self__, *,
                 username: str):
        """
        :param str username: The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def username(self) -> str:
        """
        The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class AzureClusterAzureServicesAuthentication(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "applicationId":
            suggest = "application_id"
        elif key == "tenantId":
            suggest = "tenant_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterAzureServicesAuthentication. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterAzureServicesAuthentication.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterAzureServicesAuthentication.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 application_id: str,
                 tenant_id: str):
        """
        :param str application_id: The Azure Active Directory Application ID for Authentication configuration.
        :param str tenant_id: The Azure Active Directory Tenant ID for Authentication configuration.
        """
        pulumi.set(__self__, "application_id", application_id)
        pulumi.set(__self__, "tenant_id", tenant_id)

    @property
    @pulumi.getter(name="applicationId")
    def application_id(self) -> str:
        """
        The Azure Active Directory Application ID for Authentication configuration.
        """
        return pulumi.get(self, "application_id")

    @property
    @pulumi.getter(name="tenantId")
    def tenant_id(self) -> str:
        """
        The Azure Active Directory Tenant ID for Authentication configuration.
        """
        return pulumi.get(self, "tenant_id")


@pulumi.output_type
class AzureClusterControlPlane(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sshConfig":
            suggest = "ssh_config"
        elif key == "subnetId":
            suggest = "subnet_id"
        elif key == "databaseEncryption":
            suggest = "database_encryption"
        elif key == "mainVolume":
            suggest = "main_volume"
        elif key == "proxyConfig":
            suggest = "proxy_config"
        elif key == "replicaPlacements":
            suggest = "replica_placements"
        elif key == "rootVolume":
            suggest = "root_volume"
        elif key == "vmSize":
            suggest = "vm_size"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlane. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlane.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlane.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ssh_config: 'outputs.AzureClusterControlPlaneSshConfig',
                 subnet_id: str,
                 version: str,
                 database_encryption: Optional['outputs.AzureClusterControlPlaneDatabaseEncryption'] = None,
                 main_volume: Optional['outputs.AzureClusterControlPlaneMainVolume'] = None,
                 proxy_config: Optional['outputs.AzureClusterControlPlaneProxyConfig'] = None,
                 replica_placements: Optional[Sequence['outputs.AzureClusterControlPlaneReplicaPlacement']] = None,
                 root_volume: Optional['outputs.AzureClusterControlPlaneRootVolume'] = None,
                 tags: Optional[Mapping[str, str]] = None,
                 vm_size: Optional[str] = None):
        """
        :param 'AzureClusterControlPlaneSshConfigArgs' ssh_config: SSH configuration for how to access the underlying control plane machines.
        :param str subnet_id: The ARM ID of the subnet where the control plane VMs are deployed. Example: `/subscriptions//resourceGroups//providers/Microsoft.Network/virtualNetworks//subnets/default`.
        :param str version: The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling GetAzureServerConfig.
        :param 'AzureClusterControlPlaneDatabaseEncryptionArgs' database_encryption: Optional. Configuration related to application-layer secrets encryption.
        :param 'AzureClusterControlPlaneMainVolumeArgs' main_volume: Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. When unspecified, it defaults to a 8-GiB Azure Disk.
        :param 'AzureClusterControlPlaneProxyConfigArgs' proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param Sequence['AzureClusterControlPlaneReplicaPlacementArgs'] replica_placements: Configuration for where to place the control plane replicas. Up to three replica placement instances can be specified. If replica_placements is set, the replica placement instances will be applied to the three control plane replicas as evenly as possible.
        :param 'AzureClusterControlPlaneRootVolumeArgs' root_volume: Optional. Configuration related to the root volume provisioned for each control plane replica. When unspecified, it defaults to 32-GiB Azure Disk.
        :param Mapping[str, str] tags: Optional. A set of tags to apply to all underlying control plane Azure resources.
        :param str vm_size: Optional. The Azure VM size name. Example: `Standard_DS2_v2`. For available VM sizes, see https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        pulumi.set(__self__, "ssh_config", ssh_config)
        pulumi.set(__self__, "subnet_id", subnet_id)
        pulumi.set(__self__, "version", version)
        if database_encryption is not None:
            pulumi.set(__self__, "database_encryption", database_encryption)
        if main_volume is not None:
            pulumi.set(__self__, "main_volume", main_volume)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if replica_placements is not None:
            pulumi.set(__self__, "replica_placements", replica_placements)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if vm_size is not None:
            pulumi.set(__self__, "vm_size", vm_size)

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> 'outputs.AzureClusterControlPlaneSshConfig':
        """
        SSH configuration for how to access the underlying control plane machines.
        """
        return pulumi.get(self, "ssh_config")

    @property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> str:
        """
        The ARM ID of the subnet where the control plane VMs are deployed. Example: `/subscriptions//resourceGroups//providers/Microsoft.Network/virtualNetworks//subnets/default`.
        """
        return pulumi.get(self, "subnet_id")

    @property
    @pulumi.getter
    def version(self) -> str:
        """
        The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling GetAzureServerConfig.
        """
        return pulumi.get(self, "version")

    @property
    @pulumi.getter(name="databaseEncryption")
    def database_encryption(self) -> Optional['outputs.AzureClusterControlPlaneDatabaseEncryption']:
        """
        Optional. Configuration related to application-layer secrets encryption.
        """
        return pulumi.get(self, "database_encryption")

    @property
    @pulumi.getter(name="mainVolume")
    def main_volume(self) -> Optional['outputs.AzureClusterControlPlaneMainVolume']:
        """
        Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. When unspecified, it defaults to a 8-GiB Azure Disk.
        """
        return pulumi.get(self, "main_volume")

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional['outputs.AzureClusterControlPlaneProxyConfig']:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @property
    @pulumi.getter(name="replicaPlacements")
    def replica_placements(self) -> Optional[Sequence['outputs.AzureClusterControlPlaneReplicaPlacement']]:
        """
        Configuration for where to place the control plane replicas. Up to three replica placement instances can be specified. If replica_placements is set, the replica placement instances will be applied to the three control plane replicas as evenly as possible.
        """
        return pulumi.get(self, "replica_placements")

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional['outputs.AzureClusterControlPlaneRootVolume']:
        """
        Optional. Configuration related to the root volume provisioned for each control plane replica. When unspecified, it defaults to 32-GiB Azure Disk.
        """
        return pulumi.get(self, "root_volume")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, str]]:
        """
        Optional. A set of tags to apply to all underlying control plane Azure resources.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter(name="vmSize")
    def vm_size(self) -> Optional[str]:
        """
        Optional. The Azure VM size name. Example: `Standard_DS2_v2`. For available VM sizes, see https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        return pulumi.get(self, "vm_size")


@pulumi.output_type
class AzureClusterControlPlaneDatabaseEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "keyId":
            suggest = "key_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneDatabaseEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneDatabaseEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneDatabaseEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 key_id: str):
        """
        :param str key_id: The ARM ID of the Azure Key Vault key to encrypt / decrypt data. For example: `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>` Encryption will always take the latest version of the key and hence specific version is not supported.
        """
        pulumi.set(__self__, "key_id", key_id)

    @property
    @pulumi.getter(name="keyId")
    def key_id(self) -> str:
        """
        The ARM ID of the Azure Key Vault key to encrypt / decrypt data. For example: `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>` Encryption will always take the latest version of the key and hence specific version is not supported.
        """
        return pulumi.get(self, "key_id")


@pulumi.output_type
class AzureClusterControlPlaneMainVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sizeGib":
            suggest = "size_gib"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneMainVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneMainVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneMainVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 size_gib: Optional[int] = None):
        """
        :param int size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[int]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")


@pulumi.output_type
class AzureClusterControlPlaneProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "resourceGroupId":
            suggest = "resource_group_id"
        elif key == "secretId":
            suggest = "secret_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 resource_group_id: str,
                 secret_id: str):
        """
        :param str resource_group_id: The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        :param str secret_id: The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        pulumi.set(__self__, "resource_group_id", resource_group_id)
        pulumi.set(__self__, "secret_id", secret_id)

    @property
    @pulumi.getter(name="resourceGroupId")
    def resource_group_id(self) -> str:
        """
        The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        """
        return pulumi.get(self, "resource_group_id")

    @property
    @pulumi.getter(name="secretId")
    def secret_id(self) -> str:
        """
        The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        return pulumi.get(self, "secret_id")


@pulumi.output_type
class AzureClusterControlPlaneReplicaPlacement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "azureAvailabilityZone":
            suggest = "azure_availability_zone"
        elif key == "subnetId":
            suggest = "subnet_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneReplicaPlacement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneReplicaPlacement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneReplicaPlacement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 azure_availability_zone: str,
                 subnet_id: str):
        """
        :param str azure_availability_zone: For a given replica, the Azure availability zone where to provision the control plane VM and the ETCD disk.
        :param str subnet_id: For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
        """
        pulumi.set(__self__, "azure_availability_zone", azure_availability_zone)
        pulumi.set(__self__, "subnet_id", subnet_id)

    @property
    @pulumi.getter(name="azureAvailabilityZone")
    def azure_availability_zone(self) -> str:
        """
        For a given replica, the Azure availability zone where to provision the control plane VM and the ETCD disk.
        """
        return pulumi.get(self, "azure_availability_zone")

    @property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> str:
        """
        For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
        """
        return pulumi.get(self, "subnet_id")


@pulumi.output_type
class AzureClusterControlPlaneRootVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sizeGib":
            suggest = "size_gib"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneRootVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneRootVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneRootVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 size_gib: Optional[int] = None):
        """
        :param int size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[int]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")


@pulumi.output_type
class AzureClusterControlPlaneSshConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "authorizedKey":
            suggest = "authorized_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneSshConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneSshConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneSshConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 authorized_key: str):
        """
        :param str authorized_key: The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        pulumi.set(__self__, "authorized_key", authorized_key)

    @property
    @pulumi.getter(name="authorizedKey")
    def authorized_key(self) -> str:
        """
        The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        return pulumi.get(self, "authorized_key")


@pulumi.output_type
class AzureClusterFleet(dict):
    def __init__(__self__, *,
                 membership: Optional[str] = None,
                 project: Optional[str] = None):
        """
        :param str membership: The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        :param str project: The number of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @property
    @pulumi.getter
    def membership(self) -> Optional[str]:
        """
        The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")

    @property
    @pulumi.getter
    def project(self) -> Optional[str]:
        """
        The number of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")


@pulumi.output_type
class AzureClusterLoggingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "componentConfig":
            suggest = "component_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterLoggingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterLoggingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterLoggingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component_config: Optional['outputs.AzureClusterLoggingConfigComponentConfig'] = None):
        """
        :param 'AzureClusterLoggingConfigComponentConfigArgs' component_config: Configuration of the logging components.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional['outputs.AzureClusterLoggingConfigComponentConfig']:
        """
        Configuration of the logging components.
        """
        return pulumi.get(self, "component_config")


@pulumi.output_type
class AzureClusterLoggingConfigComponentConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableComponents":
            suggest = "enable_components"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterLoggingConfigComponentConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_components: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] enable_components: Components of the logging configuration to be enabled.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[Sequence[str]]:
        """
        Components of the logging configuration to be enabled.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class AzureClusterNetworking(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "podAddressCidrBlocks":
            suggest = "pod_address_cidr_blocks"
        elif key == "serviceAddressCidrBlocks":
            suggest = "service_address_cidr_blocks"
        elif key == "virtualNetworkId":
            suggest = "virtual_network_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterNetworking. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterNetworking.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterNetworking.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pod_address_cidr_blocks: Sequence[str],
                 service_address_cidr_blocks: Sequence[str],
                 virtual_network_id: str):
        """
        :param Sequence[str] pod_address_cidr_blocks: The IP address range of the pods in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All pods in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param Sequence[str] service_address_cidr_blocks: The IP address range for services in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All services in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creating a cluster.
        :param str virtual_network_id: The Azure Resource Manager (ARM) ID of the VNet associated with your cluster. All components in the cluster (i.e. control plane and node pools) run on a single VNet. Example: `/subscriptions/*/resourceGroups/*/providers/Microsoft.Network/virtualNetworks/*` This field cannot be changed after creation.
               
               - - -
        """
        pulumi.set(__self__, "pod_address_cidr_blocks", pod_address_cidr_blocks)
        pulumi.set(__self__, "service_address_cidr_blocks", service_address_cidr_blocks)
        pulumi.set(__self__, "virtual_network_id", virtual_network_id)

    @property
    @pulumi.getter(name="podAddressCidrBlocks")
    def pod_address_cidr_blocks(self) -> Sequence[str]:
        """
        The IP address range of the pods in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All pods in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "pod_address_cidr_blocks")

    @property
    @pulumi.getter(name="serviceAddressCidrBlocks")
    def service_address_cidr_blocks(self) -> Sequence[str]:
        """
        The IP address range for services in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All services in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creating a cluster.
        """
        return pulumi.get(self, "service_address_cidr_blocks")

    @property
    @pulumi.getter(name="virtualNetworkId")
    def virtual_network_id(self) -> str:
        """
        The Azure Resource Manager (ARM) ID of the VNet associated with your cluster. All components in the cluster (i.e. control plane and node pools) run on a single VNet. Example: `/subscriptions/*/resourceGroups/*/providers/Microsoft.Network/virtualNetworks/*` This field cannot be changed after creation.

        - - -
        """
        return pulumi.get(self, "virtual_network_id")


@pulumi.output_type
class AzureClusterWorkloadIdentityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "identityProvider":
            suggest = "identity_provider"
        elif key == "issuerUri":
            suggest = "issuer_uri"
        elif key == "workloadPool":
            suggest = "workload_pool"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterWorkloadIdentityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterWorkloadIdentityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterWorkloadIdentityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 identity_provider: Optional[str] = None,
                 issuer_uri: Optional[str] = None,
                 workload_pool: Optional[str] = None):
        """
        :param str identity_provider: The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        :param str issuer_uri: The OIDC issuer URL for this cluster.
        :param str workload_pool: The Workload Identity Pool associated to the cluster.
        """
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[str]:
        """
        The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        """
        return pulumi.get(self, "identity_provider")

    @property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[str]:
        """
        The OIDC issuer URL for this cluster.
        """
        return pulumi.get(self, "issuer_uri")

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[str]:
        """
        The Workload Identity Pool associated to the cluster.
        """
        return pulumi.get(self, "workload_pool")


@pulumi.output_type
class AzureNodePoolAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxNodeCount":
            suggest = "max_node_count"
        elif key == "minNodeCount":
            suggest = "min_node_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_node_count: int,
                 min_node_count: int):
        """
        :param int max_node_count: Maximum number of nodes in the node pool. Must be >= min_node_count.
        :param int min_node_count: Minimum number of nodes in the node pool. Must be >= 1 and <= max_node_count.
        """
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> int:
        """
        Maximum number of nodes in the node pool. Must be >= min_node_count.
        """
        return pulumi.get(self, "max_node_count")

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> int:
        """
        Minimum number of nodes in the node pool. Must be >= 1 and <= max_node_count.
        """
        return pulumi.get(self, "min_node_count")


@pulumi.output_type
class AzureNodePoolConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sshConfig":
            suggest = "ssh_config"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "proxyConfig":
            suggest = "proxy_config"
        elif key == "rootVolume":
            suggest = "root_volume"
        elif key == "vmSize":
            suggest = "vm_size"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ssh_config: 'outputs.AzureNodePoolConfigSshConfig',
                 image_type: Optional[str] = None,
                 labels: Optional[Mapping[str, str]] = None,
                 proxy_config: Optional['outputs.AzureNodePoolConfigProxyConfig'] = None,
                 root_volume: Optional['outputs.AzureNodePoolConfigRootVolume'] = None,
                 tags: Optional[Mapping[str, str]] = None,
                 vm_size: Optional[str] = None):
        """
        :param 'AzureNodePoolConfigSshConfigArgs' ssh_config: SSH configuration for how to access the node pool machines.
        :param str image_type: The OS image type to use on node pool instances.
        :param Mapping[str, str] labels: Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        :param 'AzureNodePoolConfigProxyConfigArgs' proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param 'AzureNodePoolConfigRootVolumeArgs' root_volume: Optional. Configuration related to the root volume provisioned for each node pool machine. When unspecified, it defaults to a 32-GiB Azure Disk.
        :param Mapping[str, str] tags: Optional. A set of tags to apply to all underlying Azure resources for this node pool. This currently only includes Virtual Machine Scale Sets. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        :param str vm_size: Optional. The Azure VM size name. Example: `Standard_DS2_v2`. See (/anthos/clusters/docs/azure/reference/supported-vms) for options. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        pulumi.set(__self__, "ssh_config", ssh_config)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if vm_size is not None:
            pulumi.set(__self__, "vm_size", vm_size)

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> 'outputs.AzureNodePoolConfigSshConfig':
        """
        SSH configuration for how to access the node pool machines.
        """
        return pulumi.get(self, "ssh_config")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[str]:
        """
        The OS image type to use on node pool instances.
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, str]]:
        """
        Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional['outputs.AzureNodePoolConfigProxyConfig']:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional['outputs.AzureNodePoolConfigRootVolume']:
        """
        Optional. Configuration related to the root volume provisioned for each node pool machine. When unspecified, it defaults to a 32-GiB Azure Disk.
        """
        return pulumi.get(self, "root_volume")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, str]]:
        """
        Optional. A set of tags to apply to all underlying Azure resources for this node pool. This currently only includes Virtual Machine Scale Sets. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter(name="vmSize")
    def vm_size(self) -> Optional[str]:
        """
        Optional. The Azure VM size name. Example: `Standard_DS2_v2`. See (/anthos/clusters/docs/azure/reference/supported-vms) for options. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        return pulumi.get(self, "vm_size")


@pulumi.output_type
class AzureNodePoolConfigProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "resourceGroupId":
            suggest = "resource_group_id"
        elif key == "secretId":
            suggest = "secret_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolConfigProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolConfigProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolConfigProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 resource_group_id: str,
                 secret_id: str):
        """
        :param str resource_group_id: The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        :param str secret_id: The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        pulumi.set(__self__, "resource_group_id", resource_group_id)
        pulumi.set(__self__, "secret_id", secret_id)

    @property
    @pulumi.getter(name="resourceGroupId")
    def resource_group_id(self) -> str:
        """
        The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        """
        return pulumi.get(self, "resource_group_id")

    @property
    @pulumi.getter(name="secretId")
    def secret_id(self) -> str:
        """
        The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        return pulumi.get(self, "secret_id")


@pulumi.output_type
class AzureNodePoolConfigRootVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sizeGib":
            suggest = "size_gib"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolConfigRootVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolConfigRootVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolConfigRootVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 size_gib: Optional[int] = None):
        """
        :param int size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[int]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")


@pulumi.output_type
class AzureNodePoolConfigSshConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "authorizedKey":
            suggest = "authorized_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolConfigSshConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolConfigSshConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolConfigSshConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 authorized_key: str):
        """
        :param str authorized_key: The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        pulumi.set(__self__, "authorized_key", authorized_key)

    @property
    @pulumi.getter(name="authorizedKey")
    def authorized_key(self) -> str:
        """
        The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        return pulumi.get(self, "authorized_key")


@pulumi.output_type
class AzureNodePoolManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[bool] = None):
        """
        :param bool auto_repair: Optional. Whether or not the nodes will be automatically repaired.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[bool]:
        """
        Optional. Whether or not the nodes will be automatically repaired.
        """
        return pulumi.get(self, "auto_repair")


@pulumi.output_type
class AzureNodePoolMaxPodsConstraint(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxPodsPerNode":
            suggest = "max_pods_per_node"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolMaxPodsConstraint. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolMaxPodsConstraint.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolMaxPodsConstraint.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_pods_per_node: int):
        """
        :param int max_pods_per_node: The maximum number of pods to schedule on a single node.
               
               - - -
        """
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> int:
        """
        The maximum number of pods to schedule on a single node.

        - - -
        """
        return pulumi.get(self, "max_pods_per_node")


@pulumi.output_type
class ClusterAddonsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cloudrunConfig":
            suggest = "cloudrun_config"
        elif key == "configConnectorConfig":
            suggest = "config_connector_config"
        elif key == "dnsCacheConfig":
            suggest = "dns_cache_config"
        elif key == "gcePersistentDiskCsiDriverConfig":
            suggest = "gce_persistent_disk_csi_driver_config"
        elif key == "gcpFilestoreCsiDriverConfig":
            suggest = "gcp_filestore_csi_driver_config"
        elif key == "gcsFuseCsiDriverConfig":
            suggest = "gcs_fuse_csi_driver_config"
        elif key == "gkeBackupAgentConfig":
            suggest = "gke_backup_agent_config"
        elif key == "horizontalPodAutoscaling":
            suggest = "horizontal_pod_autoscaling"
        elif key == "httpLoadBalancing":
            suggest = "http_load_balancing"
        elif key == "istioConfig":
            suggest = "istio_config"
        elif key == "kalmConfig":
            suggest = "kalm_config"
        elif key == "networkPolicyConfig":
            suggest = "network_policy_config"
        elif key == "rayOperatorConfigs":
            suggest = "ray_operator_configs"
        elif key == "statefulHaConfig":
            suggest = "stateful_ha_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAddonsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAddonsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAddonsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cloudrun_config: Optional['outputs.ClusterAddonsConfigCloudrunConfig'] = None,
                 config_connector_config: Optional['outputs.ClusterAddonsConfigConfigConnectorConfig'] = None,
                 dns_cache_config: Optional['outputs.ClusterAddonsConfigDnsCacheConfig'] = None,
                 gce_persistent_disk_csi_driver_config: Optional['outputs.ClusterAddonsConfigGcePersistentDiskCsiDriverConfig'] = None,
                 gcp_filestore_csi_driver_config: Optional['outputs.ClusterAddonsConfigGcpFilestoreCsiDriverConfig'] = None,
                 gcs_fuse_csi_driver_config: Optional['outputs.ClusterAddonsConfigGcsFuseCsiDriverConfig'] = None,
                 gke_backup_agent_config: Optional['outputs.ClusterAddonsConfigGkeBackupAgentConfig'] = None,
                 horizontal_pod_autoscaling: Optional['outputs.ClusterAddonsConfigHorizontalPodAutoscaling'] = None,
                 http_load_balancing: Optional['outputs.ClusterAddonsConfigHttpLoadBalancing'] = None,
                 istio_config: Optional['outputs.ClusterAddonsConfigIstioConfig'] = None,
                 kalm_config: Optional['outputs.ClusterAddonsConfigKalmConfig'] = None,
                 network_policy_config: Optional['outputs.ClusterAddonsConfigNetworkPolicyConfig'] = None,
                 ray_operator_configs: Optional[Sequence['outputs.ClusterAddonsConfigRayOperatorConfig']] = None,
                 stateful_ha_config: Optional['outputs.ClusterAddonsConfigStatefulHaConfig'] = None):
        """
        :param 'ClusterAddonsConfigCloudrunConfigArgs' cloudrun_config: . Structure is documented below.
        :param 'ClusterAddonsConfigConfigConnectorConfigArgs' config_connector_config: .
               The status of the ConfigConnector addon. It is disabled by default; Set `enabled = true` to enable.
        :param 'ClusterAddonsConfigDnsCacheConfigArgs' dns_cache_config: .
               The status of the NodeLocal DNSCache addon. It is disabled by default.
               Set `enabled = true` to enable.
               
               **Enabling/Disabling NodeLocal DNSCache in an existing cluster is a disruptive operation.
               All cluster nodes running GKE 1.15 and higher are recreated.**
        :param 'ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs' gce_persistent_disk_csi_driver_config: .
               Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set `enabled = true` to enable.
               
               **Note:** The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        :param 'ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs' gcp_filestore_csi_driver_config: The status of the Filestore CSI driver addon,
               which allows the usage of filestore instance as volumes.
               It is disabled by default; set `enabled = true` to enable.
        :param 'ClusterAddonsConfigGcsFuseCsiDriverConfigArgs' gcs_fuse_csi_driver_config: The status of the GCSFuse CSI driver addon,
               which allows the usage of a gcs bucket as volumes.
               It is disabled by default for Standard clusters; set `enabled = true` to enable.
               It is enabled by default for Autopilot clusters with version 1.24 or later; set `enabled = true` to enable it explicitly.
               See [Enable the Cloud Storage FUSE CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver#enable) for more information.
        :param 'ClusterAddonsConfigGkeBackupAgentConfigArgs' gke_backup_agent_config: .
               The status of the Backup for GKE agent addon. It is disabled by default; Set `enabled = true` to enable.
        :param 'ClusterAddonsConfigHorizontalPodAutoscalingArgs' horizontal_pod_autoscaling: The status of the Horizontal Pod Autoscaling
               addon, which increases or decreases the number of replica pods a replication controller
               has based on the resource usage of the existing pods.
               It is enabled by default;
               set `disabled = true` to disable.
        :param 'ClusterAddonsConfigHttpLoadBalancingArgs' http_load_balancing: The status of the HTTP (L7) load balancing
               controller addon, which makes it easy to set up HTTP load balancers for services in a
               cluster. It is enabled by default; set `disabled = true` to disable.
        :param 'ClusterAddonsConfigIstioConfigArgs' istio_config: .
               Structure is documented below.
        :param 'ClusterAddonsConfigKalmConfigArgs' kalm_config: .
               Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set `enabled = true` to enable.
        :param 'ClusterAddonsConfigNetworkPolicyConfigArgs' network_policy_config: Whether we should enable the network policy addon
               for the master.  This must be enabled in order to enable network policy for the nodes.
               To enable this, you must also define a `network_policy` block,
               otherwise nothing will happen.
               It can only be disabled if the nodes already do not have network policies enabled.
               Defaults to disabled; set `disabled = false` to enable.
        :param Sequence['ClusterAddonsConfigRayOperatorConfigArgs'] ray_operator_configs: . The status of the [Ray Operator
               addon](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/concepts/overview).
               It is disabled by default. Set `enabled = true` to enable. The minimum
               cluster version to enable Ray is 1.30.0-gke.1747000.
               
               Ray Operator config has optional subfields
               `ray_cluster_logging_config.enabled` and
               `ray_cluster_monitoring_config.enabled` which control Ray Cluster logging
               and monitoring respectively. See [Collect and view logs and metrics for Ray
               clusters on
               GKE](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/how-to/collect-view-logs-metrics)
               for more information.
               
               
               This example `addons_config` disables two addons:
        :param 'ClusterAddonsConfigStatefulHaConfigArgs' stateful_ha_config: .
               The status of the Stateful HA addon, which provides automatic configurable failover for stateful applications.
               It is disabled by default for Standard clusters. Set `enabled = true` to enable.
        """
        if cloudrun_config is not None:
            pulumi.set(__self__, "cloudrun_config", cloudrun_config)
        if config_connector_config is not None:
            pulumi.set(__self__, "config_connector_config", config_connector_config)
        if dns_cache_config is not None:
            pulumi.set(__self__, "dns_cache_config", dns_cache_config)
        if gce_persistent_disk_csi_driver_config is not None:
            pulumi.set(__self__, "gce_persistent_disk_csi_driver_config", gce_persistent_disk_csi_driver_config)
        if gcp_filestore_csi_driver_config is not None:
            pulumi.set(__self__, "gcp_filestore_csi_driver_config", gcp_filestore_csi_driver_config)
        if gcs_fuse_csi_driver_config is not None:
            pulumi.set(__self__, "gcs_fuse_csi_driver_config", gcs_fuse_csi_driver_config)
        if gke_backup_agent_config is not None:
            pulumi.set(__self__, "gke_backup_agent_config", gke_backup_agent_config)
        if horizontal_pod_autoscaling is not None:
            pulumi.set(__self__, "horizontal_pod_autoscaling", horizontal_pod_autoscaling)
        if http_load_balancing is not None:
            pulumi.set(__self__, "http_load_balancing", http_load_balancing)
        if istio_config is not None:
            pulumi.set(__self__, "istio_config", istio_config)
        if kalm_config is not None:
            pulumi.set(__self__, "kalm_config", kalm_config)
        if network_policy_config is not None:
            pulumi.set(__self__, "network_policy_config", network_policy_config)
        if ray_operator_configs is not None:
            pulumi.set(__self__, "ray_operator_configs", ray_operator_configs)
        if stateful_ha_config is not None:
            pulumi.set(__self__, "stateful_ha_config", stateful_ha_config)

    @property
    @pulumi.getter(name="cloudrunConfig")
    def cloudrun_config(self) -> Optional['outputs.ClusterAddonsConfigCloudrunConfig']:
        """
        . Structure is documented below.
        """
        return pulumi.get(self, "cloudrun_config")

    @property
    @pulumi.getter(name="configConnectorConfig")
    def config_connector_config(self) -> Optional['outputs.ClusterAddonsConfigConfigConnectorConfig']:
        """
        .
        The status of the ConfigConnector addon. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "config_connector_config")

    @property
    @pulumi.getter(name="dnsCacheConfig")
    def dns_cache_config(self) -> Optional['outputs.ClusterAddonsConfigDnsCacheConfig']:
        """
        .
        The status of the NodeLocal DNSCache addon. It is disabled by default.
        Set `enabled = true` to enable.

        **Enabling/Disabling NodeLocal DNSCache in an existing cluster is a disruptive operation.
        All cluster nodes running GKE 1.15 and higher are recreated.**
        """
        return pulumi.get(self, "dns_cache_config")

    @property
    @pulumi.getter(name="gcePersistentDiskCsiDriverConfig")
    def gce_persistent_disk_csi_driver_config(self) -> Optional['outputs.ClusterAddonsConfigGcePersistentDiskCsiDriverConfig']:
        """
        .
        Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set `enabled = true` to enable.

        **Note:** The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        """
        return pulumi.get(self, "gce_persistent_disk_csi_driver_config")

    @property
    @pulumi.getter(name="gcpFilestoreCsiDriverConfig")
    def gcp_filestore_csi_driver_config(self) -> Optional['outputs.ClusterAddonsConfigGcpFilestoreCsiDriverConfig']:
        """
        The status of the Filestore CSI driver addon,
        which allows the usage of filestore instance as volumes.
        It is disabled by default; set `enabled = true` to enable.
        """
        return pulumi.get(self, "gcp_filestore_csi_driver_config")

    @property
    @pulumi.getter(name="gcsFuseCsiDriverConfig")
    def gcs_fuse_csi_driver_config(self) -> Optional['outputs.ClusterAddonsConfigGcsFuseCsiDriverConfig']:
        """
        The status of the GCSFuse CSI driver addon,
        which allows the usage of a gcs bucket as volumes.
        It is disabled by default for Standard clusters; set `enabled = true` to enable.
        It is enabled by default for Autopilot clusters with version 1.24 or later; set `enabled = true` to enable it explicitly.
        See [Enable the Cloud Storage FUSE CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver#enable) for more information.
        """
        return pulumi.get(self, "gcs_fuse_csi_driver_config")

    @property
    @pulumi.getter(name="gkeBackupAgentConfig")
    def gke_backup_agent_config(self) -> Optional['outputs.ClusterAddonsConfigGkeBackupAgentConfig']:
        """
        .
        The status of the Backup for GKE agent addon. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "gke_backup_agent_config")

    @property
    @pulumi.getter(name="horizontalPodAutoscaling")
    def horizontal_pod_autoscaling(self) -> Optional['outputs.ClusterAddonsConfigHorizontalPodAutoscaling']:
        """
        The status of the Horizontal Pod Autoscaling
        addon, which increases or decreases the number of replica pods a replication controller
        has based on the resource usage of the existing pods.
        It is enabled by default;
        set `disabled = true` to disable.
        """
        return pulumi.get(self, "horizontal_pod_autoscaling")

    @property
    @pulumi.getter(name="httpLoadBalancing")
    def http_load_balancing(self) -> Optional['outputs.ClusterAddonsConfigHttpLoadBalancing']:
        """
        The status of the HTTP (L7) load balancing
        controller addon, which makes it easy to set up HTTP load balancers for services in a
        cluster. It is enabled by default; set `disabled = true` to disable.
        """
        return pulumi.get(self, "http_load_balancing")

    @property
    @pulumi.getter(name="istioConfig")
    def istio_config(self) -> Optional['outputs.ClusterAddonsConfigIstioConfig']:
        """
        .
        Structure is documented below.
        """
        return pulumi.get(self, "istio_config")

    @property
    @pulumi.getter(name="kalmConfig")
    def kalm_config(self) -> Optional['outputs.ClusterAddonsConfigKalmConfig']:
        """
        .
        Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "kalm_config")

    @property
    @pulumi.getter(name="networkPolicyConfig")
    def network_policy_config(self) -> Optional['outputs.ClusterAddonsConfigNetworkPolicyConfig']:
        """
        Whether we should enable the network policy addon
        for the master.  This must be enabled in order to enable network policy for the nodes.
        To enable this, you must also define a `network_policy` block,
        otherwise nothing will happen.
        It can only be disabled if the nodes already do not have network policies enabled.
        Defaults to disabled; set `disabled = false` to enable.
        """
        return pulumi.get(self, "network_policy_config")

    @property
    @pulumi.getter(name="rayOperatorConfigs")
    def ray_operator_configs(self) -> Optional[Sequence['outputs.ClusterAddonsConfigRayOperatorConfig']]:
        """
        . The status of the [Ray Operator
        addon](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/concepts/overview).
        It is disabled by default. Set `enabled = true` to enable. The minimum
        cluster version to enable Ray is 1.30.0-gke.1747000.

        Ray Operator config has optional subfields
        `ray_cluster_logging_config.enabled` and
        `ray_cluster_monitoring_config.enabled` which control Ray Cluster logging
        and monitoring respectively. See [Collect and view logs and metrics for Ray
        clusters on
        GKE](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/how-to/collect-view-logs-metrics)
        for more information.


        This example `addons_config` disables two addons:
        """
        return pulumi.get(self, "ray_operator_configs")

    @property
    @pulumi.getter(name="statefulHaConfig")
    def stateful_ha_config(self) -> Optional['outputs.ClusterAddonsConfigStatefulHaConfig']:
        """
        .
        The status of the Stateful HA addon, which provides automatic configurable failover for stateful applications.
        It is disabled by default for Standard clusters. Set `enabled = true` to enable.
        """
        return pulumi.get(self, "stateful_ha_config")


@pulumi.output_type
class ClusterAddonsConfigCloudrunConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "loadBalancerType":
            suggest = "load_balancer_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAddonsConfigCloudrunConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAddonsConfigCloudrunConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAddonsConfigCloudrunConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disabled: bool,
                 load_balancer_type: Optional[str] = None):
        """
        :param bool disabled: The status of the CloudRun addon. It is disabled by default. Set `disabled=false` to enable.
        :param str load_balancer_type: The load balancer type of CloudRun ingress service. It is external load balancer by default.
               Set `load_balancer_type=LOAD_BALANCER_TYPE_INTERNAL` to configure it as internal load balancer.
        """
        pulumi.set(__self__, "disabled", disabled)
        if load_balancer_type is not None:
            pulumi.set(__self__, "load_balancer_type", load_balancer_type)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        The status of the CloudRun addon. It is disabled by default. Set `disabled=false` to enable.
        """
        return pulumi.get(self, "disabled")

    @property
    @pulumi.getter(name="loadBalancerType")
    def load_balancer_type(self) -> Optional[str]:
        """
        The load balancer type of CloudRun ingress service. It is external load balancer by default.
        Set `load_balancer_type=LOAD_BALANCER_TYPE_INTERNAL` to configure it as internal load balancer.
        """
        return pulumi.get(self, "load_balancer_type")


@pulumi.output_type
class ClusterAddonsConfigConfigConnectorConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigDnsCacheConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigGcePersistentDiskCsiDriverConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigGcpFilestoreCsiDriverConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigGcsFuseCsiDriverConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigGkeBackupAgentConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigHorizontalPodAutoscaling(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterAddonsConfigHttpLoadBalancing(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterAddonsConfigIstioConfig(dict):
    def __init__(__self__, *,
                 disabled: bool,
                 auth: Optional[str] = None):
        """
        :param bool disabled: The status of the Istio addon, which makes it easy to set up Istio for services in a
               cluster. It is disabled by default. Set `disabled = false` to enable.
        :param str auth: The authentication type between services in Istio. Available options include `AUTH_MUTUAL_TLS`.
        """
        pulumi.set(__self__, "disabled", disabled)
        if auth is not None:
            pulumi.set(__self__, "auth", auth)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        The status of the Istio addon, which makes it easy to set up Istio for services in a
        cluster. It is disabled by default. Set `disabled = false` to enable.
        """
        return pulumi.get(self, "disabled")

    @property
    @pulumi.getter
    def auth(self) -> Optional[str]:
        """
        The authentication type between services in Istio. Available options include `AUTH_MUTUAL_TLS`.
        """
        return pulumi.get(self, "auth")


@pulumi.output_type
class ClusterAddonsConfigKalmConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigNetworkPolicyConfig(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterAddonsConfigRayOperatorConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "rayClusterLoggingConfig":
            suggest = "ray_cluster_logging_config"
        elif key == "rayClusterMonitoringConfig":
            suggest = "ray_cluster_monitoring_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAddonsConfigRayOperatorConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAddonsConfigRayOperatorConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAddonsConfigRayOperatorConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: bool,
                 ray_cluster_logging_config: Optional['outputs.ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfig'] = None,
                 ray_cluster_monitoring_config: Optional['outputs.ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfig'] = None):
        """
        :param 'ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgs' ray_cluster_logging_config: The status of Ray Logging, which scrapes Ray cluster logs to Cloud Logging. Defaults to disabled; set enabled = true to enable.
        :param 'ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgs' ray_cluster_monitoring_config: The status of Ray Cluster monitoring, which shows Ray cluster metrics in Cloud Console. Defaults to disabled; set enabled = true to enable.
        """
        pulumi.set(__self__, "enabled", enabled)
        if ray_cluster_logging_config is not None:
            pulumi.set(__self__, "ray_cluster_logging_config", ray_cluster_logging_config)
        if ray_cluster_monitoring_config is not None:
            pulumi.set(__self__, "ray_cluster_monitoring_config", ray_cluster_monitoring_config)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="rayClusterLoggingConfig")
    def ray_cluster_logging_config(self) -> Optional['outputs.ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfig']:
        """
        The status of Ray Logging, which scrapes Ray cluster logs to Cloud Logging. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "ray_cluster_logging_config")

    @property
    @pulumi.getter(name="rayClusterMonitoringConfig")
    def ray_cluster_monitoring_config(self) -> Optional['outputs.ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfig']:
        """
        The status of Ray Cluster monitoring, which shows Ray cluster metrics in Cloud Console. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "ray_cluster_monitoring_config")


@pulumi.output_type
class ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigStatefulHaConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAuthenticatorGroupsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "securityGroup":
            suggest = "security_group"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAuthenticatorGroupsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAuthenticatorGroupsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAuthenticatorGroupsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 security_group: str):
        """
        :param str security_group: The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format `gke-security-groups@yourdomain.com`.
        """
        pulumi.set(__self__, "security_group", security_group)

    @property
    @pulumi.getter(name="securityGroup")
    def security_group(self) -> str:
        """
        The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format `gke-security-groups@yourdomain.com`.
        """
        return pulumi.get(self, "security_group")


@pulumi.output_type
class ClusterBinaryAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "evaluationMode":
            suggest = "evaluation_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterBinaryAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterBinaryAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterBinaryAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: Optional[bool] = None,
                 evaluation_mode: Optional[str] = None):
        """
        :param bool enabled: Enable Binary Authorization for this cluster.
        :param str evaluation_mode: Mode of operation for Binary Authorization policy evaluation.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @property
    @pulumi.getter
    @_utilities.deprecated("""Deprecated in favor of evaluation_mode.""")
    def enabled(self) -> Optional[bool]:
        """
        Enable Binary Authorization for this cluster.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[str]:
        """
        Mode of operation for Binary Authorization policy evaluation.
        """
        return pulumi.get(self, "evaluation_mode")


@pulumi.output_type
class ClusterClusterAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoProvisioningDefaults":
            suggest = "auto_provisioning_defaults"
        elif key == "autoProvisioningLocations":
            suggest = "auto_provisioning_locations"
        elif key == "autoscalingProfile":
            suggest = "autoscaling_profile"
        elif key == "resourceLimits":
            suggest = "resource_limits"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_provisioning_defaults: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaults'] = None,
                 auto_provisioning_locations: Optional[Sequence[str]] = None,
                 autoscaling_profile: Optional[str] = None,
                 enabled: Optional[bool] = None,
                 resource_limits: Optional[Sequence['outputs.ClusterClusterAutoscalingResourceLimit']] = None):
        """
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsArgs' auto_provisioning_defaults: Contains defaults for a node pool created by NAP. A subset of fields also apply to
               GKE Autopilot clusters.
               Structure is documented below.
        :param Sequence[str] auto_provisioning_locations: The list of Google Compute Engine 
               [zones](https://cloud.google.com/compute/docs/zones#available) in which the
               NodePool's nodes can be created by NAP.
        :param str autoscaling_profile: Configuration
               options for the [Autoscaling profile](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler#autoscaling_profiles)
               feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability
               when deciding to remove nodes from a cluster. Can be `BALANCED` or `OPTIMIZE_UTILIZATION`. Defaults to `BALANCED`.
        :param bool enabled: Whether node auto-provisioning is enabled. Must be supplied for GKE Standard clusters, `true` is implied
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
        :param Sequence['ClusterClusterAutoscalingResourceLimitArgs'] resource_limits: Global constraints for machine resources in the
               cluster. Configuring the `cpu` and `memory` types is required if node
               auto-provisioning is enabled. These limits will apply to node pool autoscaling
               in addition to node auto-provisioning. Structure is documented below.
        """
        if auto_provisioning_defaults is not None:
            pulumi.set(__self__, "auto_provisioning_defaults", auto_provisioning_defaults)
        if auto_provisioning_locations is not None:
            pulumi.set(__self__, "auto_provisioning_locations", auto_provisioning_locations)
        if autoscaling_profile is not None:
            pulumi.set(__self__, "autoscaling_profile", autoscaling_profile)
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if resource_limits is not None:
            pulumi.set(__self__, "resource_limits", resource_limits)

    @property
    @pulumi.getter(name="autoProvisioningDefaults")
    def auto_provisioning_defaults(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaults']:
        """
        Contains defaults for a node pool created by NAP. A subset of fields also apply to
        GKE Autopilot clusters.
        Structure is documented below.
        """
        return pulumi.get(self, "auto_provisioning_defaults")

    @property
    @pulumi.getter(name="autoProvisioningLocations")
    def auto_provisioning_locations(self) -> Optional[Sequence[str]]:
        """
        The list of Google Compute Engine 
        [zones](https://cloud.google.com/compute/docs/zones#available) in which the
        NodePool's nodes can be created by NAP.
        """
        return pulumi.get(self, "auto_provisioning_locations")

    @property
    @pulumi.getter(name="autoscalingProfile")
    def autoscaling_profile(self) -> Optional[str]:
        """
        Configuration
        options for the [Autoscaling profile](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler#autoscaling_profiles)
        feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability
        when deciding to remove nodes from a cluster. Can be `BALANCED` or `OPTIMIZE_UTILIZATION`. Defaults to `BALANCED`.
        """
        return pulumi.get(self, "autoscaling_profile")

    @property
    @pulumi.getter
    def enabled(self) -> Optional[bool]:
        """
        Whether node auto-provisioning is enabled. Must be supplied for GKE Standard clusters, `true` is implied
        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="resourceLimits")
    def resource_limits(self) -> Optional[Sequence['outputs.ClusterClusterAutoscalingResourceLimit']]:
        """
        Global constraints for machine resources in the
        cluster. Configuring the `cpu` and `memory` types is required if node
        auto-provisioning is enabled. These limits will apply to node pool autoscaling
        in addition to node auto-provisioning. Structure is documented below.
        """
        return pulumi.get(self, "resource_limits")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaults(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskKmsKey":
            suggest = "boot_disk_kms_key"
        elif key == "diskSize":
            suggest = "disk_size"
        elif key == "diskType":
            suggest = "disk_type"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "minCpuPlatform":
            suggest = "min_cpu_platform"
        elif key == "oauthScopes":
            suggest = "oauth_scopes"
        elif key == "serviceAccount":
            suggest = "service_account"
        elif key == "shieldedInstanceConfig":
            suggest = "shielded_instance_config"
        elif key == "upgradeSettings":
            suggest = "upgrade_settings"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaults. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaults.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaults.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 boot_disk_kms_key: Optional[str] = None,
                 disk_size: Optional[int] = None,
                 disk_type: Optional[str] = None,
                 image_type: Optional[str] = None,
                 management: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsManagement'] = None,
                 min_cpu_platform: Optional[str] = None,
                 oauth_scopes: Optional[Sequence[str]] = None,
                 service_account: Optional[str] = None,
                 shielded_instance_config: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig'] = None,
                 upgrade_settings: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings'] = None):
        """
        :param str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
        :param int disk_size: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. Defaults to `100`
        :param str disk_type: Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd' or 'pd-balanced'). Defaults to `pd-standard`
        :param str image_type: The default image type used by NAP once a new node pool is being created. Please note that according to the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning#default-image-type) the value must be one of the [COS_CONTAINERD, COS, UBUNTU_CONTAINERD, UBUNTU]. __NOTE__ : COS AND UBUNTU are deprecated as of `GKE 1.24`
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs' management: NodeManagement configuration for this NodePool. Structure is documented below.
        :param str min_cpu_platform: Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the
               specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such
               as "Intel Haswell" or "Intel Sandy Bridge".
        :param Sequence[str] oauth_scopes: Scopes that are used by NAP and GKE Autopilot when creating node pools. Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               > `monitoring.write` is always enabled regardless of user input.  `monitoring` and `logging.write` may also be enabled depending on the values for `monitoring_service` and `logging_service`.
        :param str service_account: The Google Cloud Platform Service Account to be used by the node VMs created by GKE Autopilot or NAP.
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs' shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs' upgrade_settings: Specifies the upgrade settings for NAP created node pools
        """
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if disk_size is not None:
            pulumi.set(__self__, "disk_size", disk_size)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if management is not None:
            pulumi.set(__self__, "management", management)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if upgrade_settings is not None:
            pulumi.set(__self__, "upgrade_settings", upgrade_settings)

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[str]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="diskSize")
    def disk_size(self) -> Optional[int]:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. Defaults to `100`
        """
        return pulumi.get(self, "disk_size")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[str]:
        """
        Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd' or 'pd-balanced'). Defaults to `pd-standard`
        """
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[str]:
        """
        The default image type used by NAP once a new node pool is being created. Please note that according to the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning#default-image-type) the value must be one of the [COS_CONTAINERD, COS, UBUNTU_CONTAINERD, UBUNTU]. __NOTE__ : COS AND UBUNTU are deprecated as of `GKE 1.24`
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter
    def management(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsManagement']:
        """
        NodeManagement configuration for this NodePool. Structure is documented below.
        """
        return pulumi.get(self, "management")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[str]:
        """
        Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the
        specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such
        as "Intel Haswell" or "Intel Sandy Bridge".
        """
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[Sequence[str]]:
        """
        Scopes that are used by NAP and GKE Autopilot when creating node pools. Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        > `monitoring.write` is always enabled regardless of user input.  `monitoring` and `logging.write` may also be enabled depending on the values for `monitoring_service` and `logging_service`.
        """
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[str]:
        """
        The Google Cloud Platform Service Account to be used by the node VMs created by GKE Autopilot or NAP.
        """
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig']:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings']:
        """
        Specifies the upgrade settings for NAP created node pools
        """
        return pulumi.get(self, "upgrade_settings")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"
        elif key == "autoUpgrade":
            suggest = "auto_upgrade"
        elif key == "upgradeOptions":
            suggest = "upgrade_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[bool] = None,
                 auto_upgrade: Optional[bool] = None,
                 upgrade_options: Optional[Sequence['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption']] = None):
        """
        :param bool auto_repair: Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
               
               This block also contains several computed attributes, documented below.
        :param bool auto_upgrade: Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        :param Sequence['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs'] upgrade_options: Specifies the [Auto Upgrade knobs](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/NodeManagement#AutoUpgradeOptions) for the node pool.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)
        if upgrade_options is not None:
            pulumi.set(__self__, "upgrade_options", upgrade_options)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[bool]:
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.

        This block also contains several computed attributes, documented below.
        """
        return pulumi.get(self, "auto_repair")

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[bool]:
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        return pulumi.get(self, "auto_upgrade")

    @property
    @pulumi.getter(name="upgradeOptions")
    def upgrade_options(self) -> Optional[Sequence['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption']]:
        """
        Specifies the [Auto Upgrade knobs](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/NodeManagement#AutoUpgradeOptions) for the node pool.
        """
        return pulumi.get(self, "upgrade_options")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoUpgradeStartTime":
            suggest = "auto_upgrade_start_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_upgrade_start_time: Optional[str] = None,
                 description: Optional[str] = None):
        """
        :param str auto_upgrade_start_time: This field is set when upgrades are about to commence with the approximate start time for the upgrades, in RFC3339 text format.
        :param str description: Description of the cluster.
        """
        if auto_upgrade_start_time is not None:
            pulumi.set(__self__, "auto_upgrade_start_time", auto_upgrade_start_time)
        if description is not None:
            pulumi.set(__self__, "description", description)

    @property
    @pulumi.getter(name="autoUpgradeStartTime")
    def auto_upgrade_start_time(self) -> Optional[str]:
        """
        This field is set when upgrades are about to commence with the approximate start time for the upgrades, in RFC3339 text format.
        """
        return pulumi.get(self, "auto_upgrade_start_time")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        """
        Description of the cluster.
        """
        return pulumi.get(self, "description")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableIntegrityMonitoring":
            suggest = "enable_integrity_monitoring"
        elif key == "enableSecureBoot":
            suggest = "enable_secure_boot"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[bool] = None,
                 enable_secure_boot: Optional[bool] = None):
        """
        :param bool enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param bool enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[bool]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[bool]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "blueGreenSettings":
            suggest = "blue_green_settings"
        elif key == "maxSurge":
            suggest = "max_surge"
        elif key == "maxUnavailable":
            suggest = "max_unavailable"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 blue_green_settings: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings'] = None,
                 max_surge: Optional[int] = None,
                 max_unavailable: Optional[int] = None,
                 strategy: Optional[str] = None):
        """
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs' blue_green_settings: Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param int max_surge: The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param int max_unavailable: The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param str strategy: Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings']:
        """
        Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "blue_green_settings")

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[int]:
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_surge")

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[int]:
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_unavailable")

    @property
    @pulumi.getter
    def strategy(self) -> Optional[str]:
        """
        Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodePoolSoakDuration":
            suggest = "node_pool_soak_duration"
        elif key == "standardRolloutPolicy":
            suggest = "standard_rollout_policy"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_pool_soak_duration: Optional[str] = None,
                 standard_rollout_policy: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy'] = None):
        """
        :param str node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs' standard_rollout_policy: Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        if standard_rollout_policy is not None:
            pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[str]:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy']:
        """
        Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "standard_rollout_policy")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "batchNodeCount":
            suggest = "batch_node_count"
        elif key == "batchPercentage":
            suggest = "batch_percentage"
        elif key == "batchSoakDuration":
            suggest = "batch_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 batch_node_count: Optional[int] = None,
                 batch_percentage: Optional[float] = None,
                 batch_soak_duration: Optional[str] = None):
        """
        :param int batch_node_count: Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        :param float batch_percentage: Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        :param str batch_soak_duration: Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[int]:
        """
        Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_node_count")

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[float]:
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_percentage")

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[str]:
        """
        Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class ClusterClusterAutoscalingResourceLimit(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "resourceType":
            suggest = "resource_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingResourceLimit. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingResourceLimit.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingResourceLimit.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 resource_type: str,
                 maximum: Optional[int] = None,
                 minimum: Optional[int] = None):
        """
        :param str resource_type: The type of the resource. For example, `cpu` and
               `memory`.  See the [guide to using Node Auto-Provisioning](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)
               for a list of types.
        :param int maximum: Maximum amount of the resource in the cluster.
        :param int minimum: Minimum amount of the resource in the cluster.
        """
        pulumi.set(__self__, "resource_type", resource_type)
        if maximum is not None:
            pulumi.set(__self__, "maximum", maximum)
        if minimum is not None:
            pulumi.set(__self__, "minimum", minimum)

    @property
    @pulumi.getter(name="resourceType")
    def resource_type(self) -> str:
        """
        The type of the resource. For example, `cpu` and
        `memory`.  See the [guide to using Node Auto-Provisioning](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)
        for a list of types.
        """
        return pulumi.get(self, "resource_type")

    @property
    @pulumi.getter
    def maximum(self) -> Optional[int]:
        """
        Maximum amount of the resource in the cluster.
        """
        return pulumi.get(self, "maximum")

    @property
    @pulumi.getter
    def minimum(self) -> Optional[int]:
        """
        Minimum amount of the resource in the cluster.
        """
        return pulumi.get(self, "minimum")


@pulumi.output_type
class ClusterClusterTelemetry(dict):
    def __init__(__self__, *,
                 type: str):
        """
        :param str type: Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
               `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
        `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class ClusterConfidentialNodes(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterCostManagementConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether to enable the [cost allocation](https://cloud.google.com/kubernetes-engine/docs/how-to/cost-allocations) feature.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether to enable the [cost allocation](https://cloud.google.com/kubernetes-engine/docs/how-to/cost-allocations) feature.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterDatabaseEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "keyName":
            suggest = "key_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterDatabaseEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterDatabaseEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterDatabaseEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 state: str,
                 key_name: Optional[str] = None):
        """
        :param str state: `ENCRYPTED` or `DECRYPTED`
        :param str key_name: the key to use to encrypt/decrypt secrets.  See the [DatabaseEncryption definition](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.DatabaseEncryption) for more information.
               
               <a name="nested_enable_k8s_beta_apis"></a>The `enable_k8s_beta_apis` block supports:
        """
        pulumi.set(__self__, "state", state)
        if key_name is not None:
            pulumi.set(__self__, "key_name", key_name)

    @property
    @pulumi.getter
    def state(self) -> str:
        """
        `ENCRYPTED` or `DECRYPTED`
        """
        return pulumi.get(self, "state")

    @property
    @pulumi.getter(name="keyName")
    def key_name(self) -> Optional[str]:
        """
        the key to use to encrypt/decrypt secrets.  See the [DatabaseEncryption definition](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.DatabaseEncryption) for more information.

        <a name="nested_enable_k8s_beta_apis"></a>The `enable_k8s_beta_apis` block supports:
        """
        return pulumi.get(self, "key_name")


@pulumi.output_type
class ClusterDefaultSnatStatus(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterDnsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "additiveVpcScopeDnsDomain":
            suggest = "additive_vpc_scope_dns_domain"
        elif key == "clusterDns":
            suggest = "cluster_dns"
        elif key == "clusterDnsDomain":
            suggest = "cluster_dns_domain"
        elif key == "clusterDnsScope":
            suggest = "cluster_dns_scope"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterDnsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterDnsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterDnsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 additive_vpc_scope_dns_domain: Optional[str] = None,
                 cluster_dns: Optional[str] = None,
                 cluster_dns_domain: Optional[str] = None,
                 cluster_dns_scope: Optional[str] = None):
        """
        :param str additive_vpc_scope_dns_domain: This will enable Cloud DNS additive VPC scope. Must provide a domain name that is unique within the VPC. For this to work `cluster_dns = "CLOUD_DNS"` and `cluster_dns_scope = "CLUSTER_SCOPE"` must both be set as well.
        :param str cluster_dns: Which in-cluster DNS provider should be used. `PROVIDER_UNSPECIFIED` (default) or `PLATFORM_DEFAULT` or `CLOUD_DNS`.
        :param str cluster_dns_domain: The suffix used for all cluster service records.
        :param str cluster_dns_scope: The scope of access to cluster DNS records. `DNS_SCOPE_UNSPECIFIED` (default) or `CLUSTER_SCOPE` or `VPC_SCOPE`.
        """
        if additive_vpc_scope_dns_domain is not None:
            pulumi.set(__self__, "additive_vpc_scope_dns_domain", additive_vpc_scope_dns_domain)
        if cluster_dns is not None:
            pulumi.set(__self__, "cluster_dns", cluster_dns)
        if cluster_dns_domain is not None:
            pulumi.set(__self__, "cluster_dns_domain", cluster_dns_domain)
        if cluster_dns_scope is not None:
            pulumi.set(__self__, "cluster_dns_scope", cluster_dns_scope)

    @property
    @pulumi.getter(name="additiveVpcScopeDnsDomain")
    def additive_vpc_scope_dns_domain(self) -> Optional[str]:
        """
        This will enable Cloud DNS additive VPC scope. Must provide a domain name that is unique within the VPC. For this to work `cluster_dns = "CLOUD_DNS"` and `cluster_dns_scope = "CLUSTER_SCOPE"` must both be set as well.
        """
        return pulumi.get(self, "additive_vpc_scope_dns_domain")

    @property
    @pulumi.getter(name="clusterDns")
    def cluster_dns(self) -> Optional[str]:
        """
        Which in-cluster DNS provider should be used. `PROVIDER_UNSPECIFIED` (default) or `PLATFORM_DEFAULT` or `CLOUD_DNS`.
        """
        return pulumi.get(self, "cluster_dns")

    @property
    @pulumi.getter(name="clusterDnsDomain")
    def cluster_dns_domain(self) -> Optional[str]:
        """
        The suffix used for all cluster service records.
        """
        return pulumi.get(self, "cluster_dns_domain")

    @property
    @pulumi.getter(name="clusterDnsScope")
    def cluster_dns_scope(self) -> Optional[str]:
        """
        The scope of access to cluster DNS records. `DNS_SCOPE_UNSPECIFIED` (default) or `CLUSTER_SCOPE` or `VPC_SCOPE`.
        """
        return pulumi.get(self, "cluster_dns_scope")


@pulumi.output_type
class ClusterEnableK8sBetaApis(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enabledApis":
            suggest = "enabled_apis"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterEnableK8sBetaApis. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterEnableK8sBetaApis.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterEnableK8sBetaApis.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled_apis: Sequence[str]):
        """
        :param Sequence[str] enabled_apis: Enabled Kubernetes Beta APIs.
        """
        pulumi.set(__self__, "enabled_apis", enabled_apis)

    @property
    @pulumi.getter(name="enabledApis")
    def enabled_apis(self) -> Sequence[str]:
        """
        Enabled Kubernetes Beta APIs.
        """
        return pulumi.get(self, "enabled_apis")


@pulumi.output_type
class ClusterFleet(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "membershipId":
            suggest = "membership_id"
        elif key == "membershipLocation":
            suggest = "membership_location"
        elif key == "preRegistered":
            suggest = "pre_registered"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterFleet. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterFleet.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterFleet.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 membership: Optional[str] = None,
                 membership_id: Optional[str] = None,
                 membership_location: Optional[str] = None,
                 pre_registered: Optional[bool] = None,
                 project: Optional[str] = None):
        """
        :param str membership: The resource name of the fleet Membership resource associated to this cluster with format `//gkehub.googleapis.com/projects/{{project}}/locations/{{location}}/memberships/{{name}}`. See the official doc for [fleet management](https://cloud.google.com/kubernetes-engine/docs/fleets-overview).
        :param str membership_id: The short name of the fleet membership, extracted from `fleet.0.membership`. You can use this field to configure `membership_id` under google_gkehub_feature_membership.
        :param str membership_location: The location of the fleet membership,  extracted from `fleet.0.membership`. You can use this field to configure `membership_location` under google_gkehub_feature_membership.
        :param bool pre_registered: Whether the cluster has been registered via the fleet API.
        :param str project: The name of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if membership_id is not None:
            pulumi.set(__self__, "membership_id", membership_id)
        if membership_location is not None:
            pulumi.set(__self__, "membership_location", membership_location)
        if pre_registered is not None:
            pulumi.set(__self__, "pre_registered", pre_registered)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @property
    @pulumi.getter
    def membership(self) -> Optional[str]:
        """
        The resource name of the fleet Membership resource associated to this cluster with format `//gkehub.googleapis.com/projects/{{project}}/locations/{{location}}/memberships/{{name}}`. See the official doc for [fleet management](https://cloud.google.com/kubernetes-engine/docs/fleets-overview).
        """
        return pulumi.get(self, "membership")

    @property
    @pulumi.getter(name="membershipId")
    def membership_id(self) -> Optional[str]:
        """
        The short name of the fleet membership, extracted from `fleet.0.membership`. You can use this field to configure `membership_id` under google_gkehub_feature_membership.
        """
        return pulumi.get(self, "membership_id")

    @property
    @pulumi.getter(name="membershipLocation")
    def membership_location(self) -> Optional[str]:
        """
        The location of the fleet membership,  extracted from `fleet.0.membership`. You can use this field to configure `membership_location` under google_gkehub_feature_membership.
        """
        return pulumi.get(self, "membership_location")

    @property
    @pulumi.getter(name="preRegistered")
    def pre_registered(self) -> Optional[bool]:
        """
        Whether the cluster has been registered via the fleet API.
        """
        return pulumi.get(self, "pre_registered")

    @property
    @pulumi.getter
    def project(self) -> Optional[str]:
        """
        The name of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")


@pulumi.output_type
class ClusterGatewayApiConfig(dict):
    def __init__(__self__, *,
                 channel: str):
        """
        :param str channel: Which Gateway Api channel should be used. `CHANNEL_DISABLED`, `CHANNEL_EXPERIMENTAL` or `CHANNEL_STANDARD`.
        """
        pulumi.set(__self__, "channel", channel)

    @property
    @pulumi.getter
    def channel(self) -> str:
        """
        Which Gateway Api channel should be used. `CHANNEL_DISABLED`, `CHANNEL_EXPERIMENTAL` or `CHANNEL_STANDARD`.
        """
        return pulumi.get(self, "channel")


@pulumi.output_type
class ClusterIdentityServiceConfig(dict):
    def __init__(__self__, *,
                 enabled: Optional[bool] = None):
        """
        :param bool enabled: Whether to enable the Identity Service component. It is disabled by default. Set `enabled=true` to enable.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[bool]:
        """
        Whether to enable the Identity Service component. It is disabled by default. Set `enabled=true` to enable.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterIpAllocationPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "additionalPodRangesConfig":
            suggest = "additional_pod_ranges_config"
        elif key == "clusterIpv4CidrBlock":
            suggest = "cluster_ipv4_cidr_block"
        elif key == "clusterSecondaryRangeName":
            suggest = "cluster_secondary_range_name"
        elif key == "podCidrOverprovisionConfig":
            suggest = "pod_cidr_overprovision_config"
        elif key == "servicesIpv4CidrBlock":
            suggest = "services_ipv4_cidr_block"
        elif key == "servicesSecondaryRangeName":
            suggest = "services_secondary_range_name"
        elif key == "stackType":
            suggest = "stack_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterIpAllocationPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterIpAllocationPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterIpAllocationPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 additional_pod_ranges_config: Optional['outputs.ClusterIpAllocationPolicyAdditionalPodRangesConfig'] = None,
                 cluster_ipv4_cidr_block: Optional[str] = None,
                 cluster_secondary_range_name: Optional[str] = None,
                 pod_cidr_overprovision_config: Optional['outputs.ClusterIpAllocationPolicyPodCidrOverprovisionConfig'] = None,
                 services_ipv4_cidr_block: Optional[str] = None,
                 services_secondary_range_name: Optional[str] = None,
                 stack_type: Optional[str] = None):
        """
        :param 'ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs' additional_pod_ranges_config: The configuration for additional pod secondary ranges at
               the cluster level. Used for Autopilot clusters and Standard clusters with which control of the
               secondary Pod IP address assignment to node pools isn't needed. Structure is documented below.
        :param str cluster_ipv4_cidr_block: The IP address range for the cluster pod IPs.
               Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
               to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
               from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
               pick a specific range to use.
        :param str cluster_secondary_range_name: The name of the existing secondary
               range in the cluster's subnetwork to use for pod IP addresses. Alternatively,
               `cluster_ipv4_cidr_block` can be used to automatically create a GKE-managed one.
        :param 'ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs' pod_cidr_overprovision_config: Configuration for cluster level pod cidr overprovision. Default is disabled=false.
        :param str services_ipv4_cidr_block: The IP address range of the services IPs in this cluster.
               Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
               to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
               from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
               pick a specific range to use.
        :param str services_secondary_range_name: The name of the existing
               secondary range in the cluster's subnetwork to use for service `ClusterIP`s.
               Alternatively, `services_ipv4_cidr_block` can be used to automatically create a
               GKE-managed one.
        :param str stack_type: The IP Stack Type of the cluster.
               Default value is `IPV4`.
               Possible values are `IPV4` and `IPV4_IPV6`.
        """
        if additional_pod_ranges_config is not None:
            pulumi.set(__self__, "additional_pod_ranges_config", additional_pod_ranges_config)
        if cluster_ipv4_cidr_block is not None:
            pulumi.set(__self__, "cluster_ipv4_cidr_block", cluster_ipv4_cidr_block)
        if cluster_secondary_range_name is not None:
            pulumi.set(__self__, "cluster_secondary_range_name", cluster_secondary_range_name)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if services_ipv4_cidr_block is not None:
            pulumi.set(__self__, "services_ipv4_cidr_block", services_ipv4_cidr_block)
        if services_secondary_range_name is not None:
            pulumi.set(__self__, "services_secondary_range_name", services_secondary_range_name)
        if stack_type is not None:
            pulumi.set(__self__, "stack_type", stack_type)

    @property
    @pulumi.getter(name="additionalPodRangesConfig")
    def additional_pod_ranges_config(self) -> Optional['outputs.ClusterIpAllocationPolicyAdditionalPodRangesConfig']:
        """
        The configuration for additional pod secondary ranges at
        the cluster level. Used for Autopilot clusters and Standard clusters with which control of the
        secondary Pod IP address assignment to node pools isn't needed. Structure is documented below.
        """
        return pulumi.get(self, "additional_pod_ranges_config")

    @property
    @pulumi.getter(name="clusterIpv4CidrBlock")
    def cluster_ipv4_cidr_block(self) -> Optional[str]:
        """
        The IP address range for the cluster pod IPs.
        Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
        to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
        from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
        pick a specific range to use.
        """
        return pulumi.get(self, "cluster_ipv4_cidr_block")

    @property
    @pulumi.getter(name="clusterSecondaryRangeName")
    def cluster_secondary_range_name(self) -> Optional[str]:
        """
        The name of the existing secondary
        range in the cluster's subnetwork to use for pod IP addresses. Alternatively,
        `cluster_ipv4_cidr_block` can be used to automatically create a GKE-managed one.
        """
        return pulumi.get(self, "cluster_secondary_range_name")

    @property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional['outputs.ClusterIpAllocationPolicyPodCidrOverprovisionConfig']:
        """
        Configuration for cluster level pod cidr overprovision. Default is disabled=false.
        """
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @property
    @pulumi.getter(name="servicesIpv4CidrBlock")
    def services_ipv4_cidr_block(self) -> Optional[str]:
        """
        The IP address range of the services IPs in this cluster.
        Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
        to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
        from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
        pick a specific range to use.
        """
        return pulumi.get(self, "services_ipv4_cidr_block")

    @property
    @pulumi.getter(name="servicesSecondaryRangeName")
    def services_secondary_range_name(self) -> Optional[str]:
        """
        The name of the existing
        secondary range in the cluster's subnetwork to use for service `ClusterIP`s.
        Alternatively, `services_ipv4_cidr_block` can be used to automatically create a
        GKE-managed one.
        """
        return pulumi.get(self, "services_secondary_range_name")

    @property
    @pulumi.getter(name="stackType")
    def stack_type(self) -> Optional[str]:
        """
        The IP Stack Type of the cluster.
        Default value is `IPV4`.
        Possible values are `IPV4` and `IPV4_IPV6`.
        """
        return pulumi.get(self, "stack_type")


@pulumi.output_type
class ClusterIpAllocationPolicyAdditionalPodRangesConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "podRangeNames":
            suggest = "pod_range_names"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterIpAllocationPolicyAdditionalPodRangesConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterIpAllocationPolicyAdditionalPodRangesConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterIpAllocationPolicyAdditionalPodRangesConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pod_range_names: Sequence[str]):
        """
        :param Sequence[str] pod_range_names: The names of the Pod ranges to add to the cluster.
        """
        pulumi.set(__self__, "pod_range_names", pod_range_names)

    @property
    @pulumi.getter(name="podRangeNames")
    def pod_range_names(self) -> Sequence[str]:
        """
        The names of the Pod ranges to add to the cluster.
        """
        return pulumi.get(self, "pod_range_names")


@pulumi.output_type
class ClusterIpAllocationPolicyPodCidrOverprovisionConfig(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterLoggingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableComponents":
            suggest = "enable_components"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterLoggingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterLoggingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterLoggingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_components: Sequence[str]):
        """
        :param Sequence[str] enable_components: The GKE components exposing logs. Supported values include:
               `SYSTEM_COMPONENTS`, `APISERVER`, `CONTROLLER_MANAGER`, `SCHEDULER`, and `WORKLOADS`.
        """
        pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Sequence[str]:
        """
        The GKE components exposing logs. Supported values include:
        `SYSTEM_COMPONENTS`, `APISERVER`, `CONTROLLER_MANAGER`, `SCHEDULER`, and `WORKLOADS`.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class ClusterMaintenancePolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dailyMaintenanceWindow":
            suggest = "daily_maintenance_window"
        elif key == "maintenanceExclusions":
            suggest = "maintenance_exclusions"
        elif key == "recurringWindow":
            suggest = "recurring_window"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 daily_maintenance_window: Optional['outputs.ClusterMaintenancePolicyDailyMaintenanceWindow'] = None,
                 maintenance_exclusions: Optional[Sequence['outputs.ClusterMaintenancePolicyMaintenanceExclusion']] = None,
                 recurring_window: Optional['outputs.ClusterMaintenancePolicyRecurringWindow'] = None):
        """
        :param 'ClusterMaintenancePolicyDailyMaintenanceWindowArgs' daily_maintenance_window: Time window specified for daily maintenance operations.
               Specify `start_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM,
               where HH : \\[00-23\\] and MM : \\[00-59\\] GMT. For example:
               
               Examples:
        :param Sequence['ClusterMaintenancePolicyMaintenanceExclusionArgs'] maintenance_exclusions: Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows. A cluster can have up to 20 maintenance exclusions at a time [Maintenance Window and Exclusions](https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions)
        :param 'ClusterMaintenancePolicyRecurringWindowArgs' recurring_window: Time window for recurring maintenance operations.
               
               Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
               the initial date that the window starts, and the end time is used for calculating duration.  Specify `recurrence` in
               [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
               Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.
               
               Examples:
               ```
               maintenance_policy {
               recurring_window {
               start_time = "2019-08-01T02:00:00Z"
               end_time = "2019-08-01T06:00:00Z"
               recurrence = "FREQ=DAILY"
               }
               }
               ```
               
               ```
               maintenance_policy {
               recurring_window {
               start_time = "2019-01-01T09:00:00Z"
               end_time = "2019-01-01T17:00:00Z"
               recurrence = "FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR"
               }
               }
               ```
        """
        if daily_maintenance_window is not None:
            pulumi.set(__self__, "daily_maintenance_window", daily_maintenance_window)
        if maintenance_exclusions is not None:
            pulumi.set(__self__, "maintenance_exclusions", maintenance_exclusions)
        if recurring_window is not None:
            pulumi.set(__self__, "recurring_window", recurring_window)

    @property
    @pulumi.getter(name="dailyMaintenanceWindow")
    def daily_maintenance_window(self) -> Optional['outputs.ClusterMaintenancePolicyDailyMaintenanceWindow']:
        """
        Time window specified for daily maintenance operations.
        Specify `start_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM,
        where HH : \\[00-23\\] and MM : \\[00-59\\] GMT. For example:

        Examples:
        """
        return pulumi.get(self, "daily_maintenance_window")

    @property
    @pulumi.getter(name="maintenanceExclusions")
    def maintenance_exclusions(self) -> Optional[Sequence['outputs.ClusterMaintenancePolicyMaintenanceExclusion']]:
        """
        Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows. A cluster can have up to 20 maintenance exclusions at a time [Maintenance Window and Exclusions](https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions)
        """
        return pulumi.get(self, "maintenance_exclusions")

    @property
    @pulumi.getter(name="recurringWindow")
    def recurring_window(self) -> Optional['outputs.ClusterMaintenancePolicyRecurringWindow']:
        """
        Time window for recurring maintenance operations.

        Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
        the initial date that the window starts, and the end time is used for calculating duration.  Specify `recurrence` in
        [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
        Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.

        Examples:
        ```
        maintenance_policy {
        recurring_window {
        start_time = "2019-08-01T02:00:00Z"
        end_time = "2019-08-01T06:00:00Z"
        recurrence = "FREQ=DAILY"
        }
        }
        ```

        ```
        maintenance_policy {
        recurring_window {
        start_time = "2019-01-01T09:00:00Z"
        end_time = "2019-01-01T17:00:00Z"
        recurrence = "FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR"
        }
        }
        ```
        """
        return pulumi.get(self, "recurring_window")


@pulumi.output_type
class ClusterMaintenancePolicyDailyMaintenanceWindow(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "startTime":
            suggest = "start_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicyDailyMaintenanceWindow. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicyDailyMaintenanceWindow.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicyDailyMaintenanceWindow.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 start_time: str,
                 duration: Optional[str] = None):
        """
        :param str duration: Duration of the time window, automatically chosen to be
               smallest possible in the given scenario.
               Duration will be in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "PTnHnMnS".
        """
        pulumi.set(__self__, "start_time", start_time)
        if duration is not None:
            pulumi.set(__self__, "duration", duration)

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> str:
        return pulumi.get(self, "start_time")

    @property
    @pulumi.getter
    def duration(self) -> Optional[str]:
        """
        Duration of the time window, automatically chosen to be
        smallest possible in the given scenario.
        Duration will be in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "PTnHnMnS".
        """
        return pulumi.get(self, "duration")


@pulumi.output_type
class ClusterMaintenancePolicyMaintenanceExclusion(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "endTime":
            suggest = "end_time"
        elif key == "exclusionName":
            suggest = "exclusion_name"
        elif key == "startTime":
            suggest = "start_time"
        elif key == "exclusionOptions":
            suggest = "exclusion_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicyMaintenanceExclusion. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicyMaintenanceExclusion.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicyMaintenanceExclusion.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 end_time: str,
                 exclusion_name: str,
                 start_time: str,
                 exclusion_options: Optional['outputs.ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions'] = None):
        """
        :param 'ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs' exclusion_options: MaintenanceExclusionOptions provides maintenance exclusion related options.
        """
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "exclusion_name", exclusion_name)
        pulumi.set(__self__, "start_time", start_time)
        if exclusion_options is not None:
            pulumi.set(__self__, "exclusion_options", exclusion_options)

    @property
    @pulumi.getter(name="endTime")
    def end_time(self) -> str:
        return pulumi.get(self, "end_time")

    @property
    @pulumi.getter(name="exclusionName")
    def exclusion_name(self) -> str:
        return pulumi.get(self, "exclusion_name")

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> str:
        return pulumi.get(self, "start_time")

    @property
    @pulumi.getter(name="exclusionOptions")
    def exclusion_options(self) -> Optional['outputs.ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions']:
        """
        MaintenanceExclusionOptions provides maintenance exclusion related options.
        """
        return pulumi.get(self, "exclusion_options")


@pulumi.output_type
class ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions(dict):
    def __init__(__self__, *,
                 scope: str):
        """
        :param str scope: The scope of automatic upgrades to restrict in the exclusion window. One of: **NO_UPGRADES | NO_MINOR_UPGRADES | NO_MINOR_OR_NODE_UPGRADES**
               
               Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
               the initial date that the window starts, and the end time is used for calculating duration.Specify `recurrence` in
               [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
               Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.
               
               Examples:
               
               ```
               maintenance_policy {
               recurring_window {
               start_time = "2019-01-01T00:00:00Z"
               end_time = "2019-01-02T00:00:00Z"
               recurrence = "FREQ=DAILY"
               }
               maintenance_exclusion{
               exclusion_name = "batch job"
               start_time = "2019-01-01T00:00:00Z"
               end_time = "2019-01-02T00:00:00Z"
               exclusion_options {
               scope = "NO_UPGRADES"
               }
               }
               maintenance_exclusion{
               exclusion_name = "holiday data load"
               start_time = "2019-05-01T00:00:00Z"
               end_time = "2019-05-02T00:00:00Z"
               exclusion_options {
               scope = "NO_MINOR_UPGRADES"
               }
               }
               }
               ```
        """
        pulumi.set(__self__, "scope", scope)

    @property
    @pulumi.getter
    def scope(self) -> str:
        """
        The scope of automatic upgrades to restrict in the exclusion window. One of: **NO_UPGRADES | NO_MINOR_UPGRADES | NO_MINOR_OR_NODE_UPGRADES**

        Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
        the initial date that the window starts, and the end time is used for calculating duration.Specify `recurrence` in
        [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
        Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.

        Examples:

        ```
        maintenance_policy {
        recurring_window {
        start_time = "2019-01-01T00:00:00Z"
        end_time = "2019-01-02T00:00:00Z"
        recurrence = "FREQ=DAILY"
        }
        maintenance_exclusion{
        exclusion_name = "batch job"
        start_time = "2019-01-01T00:00:00Z"
        end_time = "2019-01-02T00:00:00Z"
        exclusion_options {
        scope = "NO_UPGRADES"
        }
        }
        maintenance_exclusion{
        exclusion_name = "holiday data load"
        start_time = "2019-05-01T00:00:00Z"
        end_time = "2019-05-02T00:00:00Z"
        exclusion_options {
        scope = "NO_MINOR_UPGRADES"
        }
        }
        }
        ```
        """
        return pulumi.get(self, "scope")


@pulumi.output_type
class ClusterMaintenancePolicyRecurringWindow(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "endTime":
            suggest = "end_time"
        elif key == "startTime":
            suggest = "start_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicyRecurringWindow. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicyRecurringWindow.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicyRecurringWindow.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 end_time: str,
                 recurrence: str,
                 start_time: str):
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "recurrence", recurrence)
        pulumi.set(__self__, "start_time", start_time)

    @property
    @pulumi.getter(name="endTime")
    def end_time(self) -> str:
        return pulumi.get(self, "end_time")

    @property
    @pulumi.getter
    def recurrence(self) -> str:
        return pulumi.get(self, "recurrence")

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> str:
        return pulumi.get(self, "start_time")


@pulumi.output_type
class ClusterMasterAuth(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "clientCertificateConfig":
            suggest = "client_certificate_config"
        elif key == "clientCertificate":
            suggest = "client_certificate"
        elif key == "clientKey":
            suggest = "client_key"
        elif key == "clusterCaCertificate":
            suggest = "cluster_ca_certificate"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterAuth. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterAuth.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterAuth.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 client_certificate_config: 'outputs.ClusterMasterAuthClientCertificateConfig',
                 client_certificate: Optional[str] = None,
                 client_key: Optional[str] = None,
                 cluster_ca_certificate: Optional[str] = None):
        """
        :param 'ClusterMasterAuthClientCertificateConfigArgs' client_certificate_config: Whether client certificate authorization is enabled for this cluster.  For example:
        :param str client_certificate: Base64 encoded public certificate
               used by clients to authenticate to the cluster endpoint.
        :param str client_key: Base64 encoded private key used by clients
               to authenticate to the cluster endpoint.
        :param str cluster_ca_certificate: Base64 encoded public certificate
               that is the root certificate of the cluster.
        """
        pulumi.set(__self__, "client_certificate_config", client_certificate_config)
        if client_certificate is not None:
            pulumi.set(__self__, "client_certificate", client_certificate)
        if client_key is not None:
            pulumi.set(__self__, "client_key", client_key)
        if cluster_ca_certificate is not None:
            pulumi.set(__self__, "cluster_ca_certificate", cluster_ca_certificate)

    @property
    @pulumi.getter(name="clientCertificateConfig")
    def client_certificate_config(self) -> 'outputs.ClusterMasterAuthClientCertificateConfig':
        """
        Whether client certificate authorization is enabled for this cluster.  For example:
        """
        return pulumi.get(self, "client_certificate_config")

    @property
    @pulumi.getter(name="clientCertificate")
    def client_certificate(self) -> Optional[str]:
        """
        Base64 encoded public certificate
        used by clients to authenticate to the cluster endpoint.
        """
        return pulumi.get(self, "client_certificate")

    @property
    @pulumi.getter(name="clientKey")
    def client_key(self) -> Optional[str]:
        """
        Base64 encoded private key used by clients
        to authenticate to the cluster endpoint.
        """
        return pulumi.get(self, "client_key")

    @property
    @pulumi.getter(name="clusterCaCertificate")
    def cluster_ca_certificate(self) -> Optional[str]:
        """
        Base64 encoded public certificate
        that is the root certificate of the cluster.
        """
        return pulumi.get(self, "cluster_ca_certificate")


@pulumi.output_type
class ClusterMasterAuthClientCertificateConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "issueClientCertificate":
            suggest = "issue_client_certificate"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterAuthClientCertificateConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterAuthClientCertificateConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterAuthClientCertificateConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 issue_client_certificate: bool):
        """
        :param bool issue_client_certificate: Whether client certificate authorization is enabled for this cluster.
        """
        pulumi.set(__self__, "issue_client_certificate", issue_client_certificate)

    @property
    @pulumi.getter(name="issueClientCertificate")
    def issue_client_certificate(self) -> bool:
        """
        Whether client certificate authorization is enabled for this cluster.
        """
        return pulumi.get(self, "issue_client_certificate")


@pulumi.output_type
class ClusterMasterAuthorizedNetworksConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cidrBlocks":
            suggest = "cidr_blocks"
        elif key == "gcpPublicCidrsAccessEnabled":
            suggest = "gcp_public_cidrs_access_enabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterAuthorizedNetworksConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterAuthorizedNetworksConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterAuthorizedNetworksConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cidr_blocks: Optional[Sequence['outputs.ClusterMasterAuthorizedNetworksConfigCidrBlock']] = None,
                 gcp_public_cidrs_access_enabled: Optional[bool] = None):
        """
        :param Sequence['ClusterMasterAuthorizedNetworksConfigCidrBlockArgs'] cidr_blocks: External networks that can access the
               Kubernetes cluster master through HTTPS.
        :param bool gcp_public_cidrs_access_enabled: Whether Kubernetes master is
               accessible via Google Compute Engine Public IPs.
        """
        if cidr_blocks is not None:
            pulumi.set(__self__, "cidr_blocks", cidr_blocks)
        if gcp_public_cidrs_access_enabled is not None:
            pulumi.set(__self__, "gcp_public_cidrs_access_enabled", gcp_public_cidrs_access_enabled)

    @property
    @pulumi.getter(name="cidrBlocks")
    def cidr_blocks(self) -> Optional[Sequence['outputs.ClusterMasterAuthorizedNetworksConfigCidrBlock']]:
        """
        External networks that can access the
        Kubernetes cluster master through HTTPS.
        """
        return pulumi.get(self, "cidr_blocks")

    @property
    @pulumi.getter(name="gcpPublicCidrsAccessEnabled")
    def gcp_public_cidrs_access_enabled(self) -> Optional[bool]:
        """
        Whether Kubernetes master is
        accessible via Google Compute Engine Public IPs.
        """
        return pulumi.get(self, "gcp_public_cidrs_access_enabled")


@pulumi.output_type
class ClusterMasterAuthorizedNetworksConfigCidrBlock(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cidrBlock":
            suggest = "cidr_block"
        elif key == "displayName":
            suggest = "display_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterAuthorizedNetworksConfigCidrBlock. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterAuthorizedNetworksConfigCidrBlock.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterAuthorizedNetworksConfigCidrBlock.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cidr_block: str,
                 display_name: Optional[str] = None):
        """
        :param str cidr_block: External network that can access Kubernetes master through HTTPS.
               Must be specified in CIDR notation.
        :param str display_name: Field for users to identify CIDR blocks.
        """
        pulumi.set(__self__, "cidr_block", cidr_block)
        if display_name is not None:
            pulumi.set(__self__, "display_name", display_name)

    @property
    @pulumi.getter(name="cidrBlock")
    def cidr_block(self) -> str:
        """
        External network that can access Kubernetes master through HTTPS.
        Must be specified in CIDR notation.
        """
        return pulumi.get(self, "cidr_block")

    @property
    @pulumi.getter(name="displayName")
    def display_name(self) -> Optional[str]:
        """
        Field for users to identify CIDR blocks.
        """
        return pulumi.get(self, "display_name")


@pulumi.output_type
class ClusterMeshCertificates(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableCertificates":
            suggest = "enable_certificates"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMeshCertificates. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMeshCertificates.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMeshCertificates.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_certificates: bool):
        """
        :param bool enable_certificates: Controls the issuance of workload mTLS certificates. It is enabled by default. Workload Identity is required, see workload_config.
        """
        pulumi.set(__self__, "enable_certificates", enable_certificates)

    @property
    @pulumi.getter(name="enableCertificates")
    def enable_certificates(self) -> bool:
        """
        Controls the issuance of workload mTLS certificates. It is enabled by default. Workload Identity is required, see workload_config.
        """
        return pulumi.get(self, "enable_certificates")


@pulumi.output_type
class ClusterMonitoringConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "advancedDatapathObservabilityConfig":
            suggest = "advanced_datapath_observability_config"
        elif key == "enableComponents":
            suggest = "enable_components"
        elif key == "managedPrometheus":
            suggest = "managed_prometheus"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMonitoringConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMonitoringConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMonitoringConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 advanced_datapath_observability_config: Optional['outputs.ClusterMonitoringConfigAdvancedDatapathObservabilityConfig'] = None,
                 enable_components: Optional[Sequence[str]] = None,
                 managed_prometheus: Optional['outputs.ClusterMonitoringConfigManagedPrometheus'] = None):
        """
        :param 'ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs' advanced_datapath_observability_config: Configuration for Advanced Datapath Monitoring. Structure is documented below.
        :param Sequence[str] enable_components: The GKE components exposing metrics. Supported values include: `SYSTEM_COMPONENTS`, `APISERVER`, `SCHEDULER`, `CONTROLLER_MANAGER`, `STORAGE`, `HPA`, `POD`, `DAEMONSET`, `DEPLOYMENT`, `STATEFULSET`, `KUBELET`, `CADVISOR` and `DCGM`. In beta provider, `WORKLOADS` is supported on top of those 12 values. (`WORKLOADS` is deprecated and removed in GKE 1.24.) `KUBELET` and `CADVISOR` are only supported in GKE 1.29.3-gke.1093000 and above.
        :param 'ClusterMonitoringConfigManagedPrometheusArgs' managed_prometheus: Configuration for Managed Service for Prometheus. Structure is documented below.
        """
        if advanced_datapath_observability_config is not None:
            pulumi.set(__self__, "advanced_datapath_observability_config", advanced_datapath_observability_config)
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)
        if managed_prometheus is not None:
            pulumi.set(__self__, "managed_prometheus", managed_prometheus)

    @property
    @pulumi.getter(name="advancedDatapathObservabilityConfig")
    def advanced_datapath_observability_config(self) -> Optional['outputs.ClusterMonitoringConfigAdvancedDatapathObservabilityConfig']:
        """
        Configuration for Advanced Datapath Monitoring. Structure is documented below.
        """
        return pulumi.get(self, "advanced_datapath_observability_config")

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[Sequence[str]]:
        """
        The GKE components exposing metrics. Supported values include: `SYSTEM_COMPONENTS`, `APISERVER`, `SCHEDULER`, `CONTROLLER_MANAGER`, `STORAGE`, `HPA`, `POD`, `DAEMONSET`, `DEPLOYMENT`, `STATEFULSET`, `KUBELET`, `CADVISOR` and `DCGM`. In beta provider, `WORKLOADS` is supported on top of those 12 values. (`WORKLOADS` is deprecated and removed in GKE 1.24.) `KUBELET` and `CADVISOR` are only supported in GKE 1.29.3-gke.1093000 and above.
        """
        return pulumi.get(self, "enable_components")

    @property
    @pulumi.getter(name="managedPrometheus")
    def managed_prometheus(self) -> Optional['outputs.ClusterMonitoringConfigManagedPrometheus']:
        """
        Configuration for Managed Service for Prometheus. Structure is documented below.
        """
        return pulumi.get(self, "managed_prometheus")


@pulumi.output_type
class ClusterMonitoringConfigAdvancedDatapathObservabilityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableMetrics":
            suggest = "enable_metrics"
        elif key == "enableRelay":
            suggest = "enable_relay"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMonitoringConfigAdvancedDatapathObservabilityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMonitoringConfigAdvancedDatapathObservabilityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMonitoringConfigAdvancedDatapathObservabilityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_metrics: bool,
                 enable_relay: bool):
        """
        :param bool enable_metrics: Whether or not to enable advanced datapath metrics.
        :param bool enable_relay: Whether or not Relay is enabled.
        """
        pulumi.set(__self__, "enable_metrics", enable_metrics)
        pulumi.set(__self__, "enable_relay", enable_relay)

    @property
    @pulumi.getter(name="enableMetrics")
    def enable_metrics(self) -> bool:
        """
        Whether or not to enable advanced datapath metrics.
        """
        return pulumi.get(self, "enable_metrics")

    @property
    @pulumi.getter(name="enableRelay")
    def enable_relay(self) -> bool:
        """
        Whether or not Relay is enabled.
        """
        return pulumi.get(self, "enable_relay")


@pulumi.output_type
class ClusterMonitoringConfigManagedPrometheus(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the managed collection is enabled.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the managed collection is enabled.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNetworkPolicy(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 provider: Optional[str] = None):
        """
        :param bool enabled: Whether network policy is enabled on the cluster.
        :param str provider: The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.
        """
        pulumi.set(__self__, "enabled", enabled)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether network policy is enabled on the cluster.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter
    def provider(self) -> Optional[str]:
        """
        The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.
        """
        return pulumi.get(self, "provider")


@pulumi.output_type
class ClusterNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "advancedMachineFeatures":
            suggest = "advanced_machine_features"
        elif key == "bootDiskKmsKey":
            suggest = "boot_disk_kms_key"
        elif key == "confidentialNodes":
            suggest = "confidential_nodes"
        elif key == "containerdConfig":
            suggest = "containerd_config"
        elif key == "diskSizeGb":
            suggest = "disk_size_gb"
        elif key == "diskType":
            suggest = "disk_type"
        elif key == "effectiveTaints":
            suggest = "effective_taints"
        elif key == "enableConfidentialStorage":
            suggest = "enable_confidential_storage"
        elif key == "ephemeralStorageConfig":
            suggest = "ephemeral_storage_config"
        elif key == "ephemeralStorageLocalSsdConfig":
            suggest = "ephemeral_storage_local_ssd_config"
        elif key == "fastSocket":
            suggest = "fast_socket"
        elif key == "gcfsConfig":
            suggest = "gcfs_config"
        elif key == "guestAccelerators":
            suggest = "guest_accelerators"
        elif key == "hostMaintenancePolicy":
            suggest = "host_maintenance_policy"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "kubeletConfig":
            suggest = "kubelet_config"
        elif key == "linuxNodeConfig":
            suggest = "linux_node_config"
        elif key == "localNvmeSsdBlockConfig":
            suggest = "local_nvme_ssd_block_config"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "loggingVariant":
            suggest = "logging_variant"
        elif key == "machineType":
            suggest = "machine_type"
        elif key == "minCpuPlatform":
            suggest = "min_cpu_platform"
        elif key == "nodeGroup":
            suggest = "node_group"
        elif key == "oauthScopes":
            suggest = "oauth_scopes"
        elif key == "reservationAffinity":
            suggest = "reservation_affinity"
        elif key == "resourceLabels":
            suggest = "resource_labels"
        elif key == "resourceManagerTags":
            suggest = "resource_manager_tags"
        elif key == "sandboxConfig":
            suggest = "sandbox_config"
        elif key == "secondaryBootDisks":
            suggest = "secondary_boot_disks"
        elif key == "serviceAccount":
            suggest = "service_account"
        elif key == "shieldedInstanceConfig":
            suggest = "shielded_instance_config"
        elif key == "soleTenantConfig":
            suggest = "sole_tenant_config"
        elif key == "storagePools":
            suggest = "storage_pools"
        elif key == "workloadMetadataConfig":
            suggest = "workload_metadata_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 advanced_machine_features: Optional['outputs.ClusterNodeConfigAdvancedMachineFeatures'] = None,
                 boot_disk_kms_key: Optional[str] = None,
                 confidential_nodes: Optional['outputs.ClusterNodeConfigConfidentialNodes'] = None,
                 containerd_config: Optional['outputs.ClusterNodeConfigContainerdConfig'] = None,
                 disk_size_gb: Optional[int] = None,
                 disk_type: Optional[str] = None,
                 effective_taints: Optional[Sequence['outputs.ClusterNodeConfigEffectiveTaint']] = None,
                 enable_confidential_storage: Optional[bool] = None,
                 ephemeral_storage_config: Optional['outputs.ClusterNodeConfigEphemeralStorageConfig'] = None,
                 ephemeral_storage_local_ssd_config: Optional['outputs.ClusterNodeConfigEphemeralStorageLocalSsdConfig'] = None,
                 fast_socket: Optional['outputs.ClusterNodeConfigFastSocket'] = None,
                 gcfs_config: Optional['outputs.ClusterNodeConfigGcfsConfig'] = None,
                 guest_accelerators: Optional[Sequence['outputs.ClusterNodeConfigGuestAccelerator']] = None,
                 gvnic: Optional['outputs.ClusterNodeConfigGvnic'] = None,
                 host_maintenance_policy: Optional['outputs.ClusterNodeConfigHostMaintenancePolicy'] = None,
                 image_type: Optional[str] = None,
                 kubelet_config: Optional['outputs.ClusterNodeConfigKubeletConfig'] = None,
                 labels: Optional[Mapping[str, str]] = None,
                 linux_node_config: Optional['outputs.ClusterNodeConfigLinuxNodeConfig'] = None,
                 local_nvme_ssd_block_config: Optional['outputs.ClusterNodeConfigLocalNvmeSsdBlockConfig'] = None,
                 local_ssd_count: Optional[int] = None,
                 logging_variant: Optional[str] = None,
                 machine_type: Optional[str] = None,
                 metadata: Optional[Mapping[str, str]] = None,
                 min_cpu_platform: Optional[str] = None,
                 node_group: Optional[str] = None,
                 oauth_scopes: Optional[Sequence[str]] = None,
                 preemptible: Optional[bool] = None,
                 reservation_affinity: Optional['outputs.ClusterNodeConfigReservationAffinity'] = None,
                 resource_labels: Optional[Mapping[str, str]] = None,
                 resource_manager_tags: Optional[Mapping[str, str]] = None,
                 sandbox_config: Optional['outputs.ClusterNodeConfigSandboxConfig'] = None,
                 secondary_boot_disks: Optional[Sequence['outputs.ClusterNodeConfigSecondaryBootDisk']] = None,
                 service_account: Optional[str] = None,
                 shielded_instance_config: Optional['outputs.ClusterNodeConfigShieldedInstanceConfig'] = None,
                 sole_tenant_config: Optional['outputs.ClusterNodeConfigSoleTenantConfig'] = None,
                 spot: Optional[bool] = None,
                 storage_pools: Optional[Sequence[str]] = None,
                 tags: Optional[Sequence[str]] = None,
                 taints: Optional[Sequence['outputs.ClusterNodeConfigTaint']] = None,
                 workload_metadata_config: Optional['outputs.ClusterNodeConfigWorkloadMetadataConfig'] = None):
        """
        :param 'ClusterNodeConfigAdvancedMachineFeaturesArgs' advanced_machine_features: Specifies options for controlling
               advanced machine features. Structure is documented below.
        :param str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        :param 'ClusterNodeConfigConfidentialNodesArgs' confidential_nodes: Configuration for Confidential Nodes feature. Structure is documented below.
        :param 'ClusterNodeConfigContainerdConfigArgs' containerd_config: Parameters to customize containerd runtime. Structure is documented below.
        :param int disk_size_gb: Size of the disk attached to each node, specified
               in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        :param str disk_type: Type of the disk attached to each node
               (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        :param Sequence['ClusterNodeConfigEffectiveTaintArgs'] effective_taints: List of kubernetes taints applied to each node. Structure is documented above.
        :param bool enable_confidential_storage: Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        :param 'ClusterNodeConfigEphemeralStorageConfigArgs' ephemeral_storage_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        :param 'ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs' ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        :param 'ClusterNodeConfigFastSocketArgs' fast_socket: Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
               Node Pool must enable gvnic.
               GKE version 1.25.2-gke.1700 or later.
               Structure is documented below.
        :param 'ClusterNodeConfigGcfsConfigArgs' gcfs_config: Parameters for the Google Container Filesystem (GCFS).
               If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
               For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
               A `machine_type` that has more than 16 GiB of memory is also recommended.
               GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
               Structure is documented below.
        :param Sequence['ClusterNodeConfigGuestAcceleratorArgs'] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
               Structure documented below.
        :param 'ClusterNodeConfigGvnicArgs' gvnic: Google Virtual NIC (gVNIC) is a virtual network interface.
               Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
               gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
               GKE node version 1.15.11-gke.15 or later
               Structure is documented below.
        :param 'ClusterNodeConfigHostMaintenancePolicyArgs' host_maintenance_policy: The maintenance policy for the hosts on which the GKE VMs run on.
        :param str image_type: The image type to use for this node. Note that changing the image type
               will delete and recreate all nodes in the node pool.
        :param 'ClusterNodeConfigKubeletConfigArgs' kubelet_config: Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Structure is documented below.
               
               ```
               kubelet_config {
               cpu_manager_policy   = "static"
               cpu_cfs_quota        = true
               cpu_cfs_quota_period = "100us"
               pod_pids_limit       = 1024
               }
               ```
        :param Mapping[str, str] labels: The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
               reserved by Kubernetes Core components and cannot be specified.
        :param 'ClusterNodeConfigLinuxNodeConfigArgs' linux_node_config: Parameters that can be configured on Linux nodes. Structure is documented below.
        :param 'ClusterNodeConfigLocalNvmeSsdBlockConfigArgs' local_nvme_ssd_block_config: Parameters for the local NVMe SSDs. Structure is documented below.
        :param int local_ssd_count: The amount of local SSD disks that will be
               attached to each cluster node. Defaults to 0.
        :param str logging_variant: Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        :param str machine_type: The name of a Google Compute Engine machine type.
               Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
               [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        :param Mapping[str, str] metadata: The metadata key/value pairs assigned to instances in
               the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
               `true` by the API; if `metadata` is set but that default value is not
               included, the provider will attempt to unset the value. To avoid this, set the
               value in your config.
        :param str min_cpu_platform: Minimum CPU platform to be used by this instance.
               The instance may be scheduled on the specified or newer CPU platform. Applicable
               values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
               [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
               for more information.
        :param str node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        :param Sequence[str] oauth_scopes: The set of Google API scopes to be made available
               on all of the node VMs under the "default" service account.
               Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        :param bool preemptible: A boolean that represents whether or not the underlying node VMs
               are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
               for more information. Defaults to false.
        :param 'ClusterNodeConfigReservationAffinityArgs' reservation_affinity: The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        :param Mapping[str, str] resource_labels: The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
               for how these labels are applied to clusters, node pools and nodes.
        :param Mapping[str, str] resource_manager_tags: A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        :param 'ClusterNodeConfigSandboxConfigArgs' sandbox_config: Sandbox configuration for this node.
        :param Sequence['ClusterNodeConfigSecondaryBootDiskArgs'] secondary_boot_disks: Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        :param str service_account: The service account to be used by the Node VMs.
               If not specified, the "default" service account is used.
        :param 'ClusterNodeConfigShieldedInstanceConfigArgs' shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param 'ClusterNodeConfigSoleTenantConfigArgs' sole_tenant_config: Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
        :param bool spot: A boolean that represents whether the underlying node VMs are spot.
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
               for more information. Defaults to false.
        :param Sequence[str] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param Sequence[str] tags: The list of instance tags applied to all nodes. Tags are used to identify
               valid sources or targets for network firewalls.
        :param Sequence['ClusterNodeConfigTaintArgs'] taints: A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
               to apply to nodes. GKE's API can only set this field on cluster creation.
               However, GKE will add taints to your nodes if you enable certain features such
               as GPUs. If this field is set, any diffs on this field will cause the provider to
               recreate the underlying resource. Taint values can be updated safely in
               Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
               this field to manage taints. If you do, `lifecycle.ignore_changes` is
               recommended. Structure is documented below.
        :param 'ClusterNodeConfigWorkloadMetadataConfigArgs' workload_metadata_config: Metadata configuration to expose to workloads on the node pool.
               Structure is documented below.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if containerd_config is not None:
            pulumi.set(__self__, "containerd_config", containerd_config)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if effective_taints is not None:
            pulumi.set(__self__, "effective_taints", effective_taints)
        if enable_confidential_storage is not None:
            pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if resource_manager_tags is not None:
            pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if secondary_boot_disks is not None:
            pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if storage_pools is not None:
            pulumi.set(__self__, "storage_pools", storage_pools)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional['outputs.ClusterNodeConfigAdvancedMachineFeatures']:
        """
        Specifies options for controlling
        advanced machine features. Structure is documented below.
        """
        return pulumi.get(self, "advanced_machine_features")

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[str]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional['outputs.ClusterNodeConfigConfidentialNodes']:
        """
        Configuration for Confidential Nodes feature. Structure is documented below.
        """
        return pulumi.get(self, "confidential_nodes")

    @property
    @pulumi.getter(name="containerdConfig")
    def containerd_config(self) -> Optional['outputs.ClusterNodeConfigContainerdConfig']:
        """
        Parameters to customize containerd runtime. Structure is documented below.
        """
        return pulumi.get(self, "containerd_config")

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[int]:
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[str]:
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        """
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Optional[Sequence['outputs.ClusterNodeConfigEffectiveTaint']]:
        """
        List of kubernetes taints applied to each node. Structure is documented above.
        """
        return pulumi.get(self, "effective_taints")

    @property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> Optional[bool]:
        """
        Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional['outputs.ClusterNodeConfigEphemeralStorageConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional['outputs.ClusterNodeConfigEphemeralStorageLocalSsdConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional['outputs.ClusterNodeConfigFastSocket']:
        """
        Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
        Node Pool must enable gvnic.
        GKE version 1.25.2-gke.1700 or later.
        Structure is documented below.
        """
        return pulumi.get(self, "fast_socket")

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional['outputs.ClusterNodeConfigGcfsConfig']:
        """
        Parameters for the Google Container Filesystem (GCFS).
        If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
        For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
        A `machine_type` that has more than 16 GiB of memory is also recommended.
        GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
        Structure is documented below.
        """
        return pulumi.get(self, "gcfs_config")

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[Sequence['outputs.ClusterNodeConfigGuestAccelerator']]:
        """
        List of the type and count of accelerator cards attached to the instance.
        Structure documented below.
        """
        return pulumi.get(self, "guest_accelerators")

    @property
    @pulumi.getter
    def gvnic(self) -> Optional['outputs.ClusterNodeConfigGvnic']:
        """
        Google Virtual NIC (gVNIC) is a virtual network interface.
        Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
        gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
        GKE node version 1.15.11-gke.15 or later
        Structure is documented below.
        """
        return pulumi.get(self, "gvnic")

    @property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional['outputs.ClusterNodeConfigHostMaintenancePolicy']:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policy")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[str]:
        """
        The image type to use for this node. Note that changing the image type
        will delete and recreate all nodes in the node pool.
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional['outputs.ClusterNodeConfigKubeletConfig']:
        """
        Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Structure is documented below.

        ```
        kubelet_config {
        cpu_manager_policy   = "static"
        cpu_cfs_quota        = true
        cpu_cfs_quota_period = "100us"
        pod_pids_limit       = 1024
        }
        ```
        """
        return pulumi.get(self, "kubelet_config")

    @property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, str]]:
        """
        The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
        reserved by Kubernetes Core components and cannot be specified.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional['outputs.ClusterNodeConfigLinuxNodeConfig']:
        """
        Parameters that can be configured on Linux nodes. Structure is documented below.
        """
        return pulumi.get(self, "linux_node_config")

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional['outputs.ClusterNodeConfigLocalNvmeSsdBlockConfig']:
        """
        Parameters for the local NVMe SSDs. Structure is documented below.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        """
        The amount of local SSD disks that will be
        attached to each cluster node. Defaults to 0.
        """
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[str]:
        """
        Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[str]:
        """
        The name of a Google Compute Engine machine type.
        Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
        [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        """
        return pulumi.get(self, "machine_type")

    @property
    @pulumi.getter
    def metadata(self) -> Optional[Mapping[str, str]]:
        """
        The metadata key/value pairs assigned to instances in
        the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
        `true` by the API; if `metadata` is set but that default value is not
        included, the provider will attempt to unset the value. To avoid this, set the
        value in your config.
        """
        return pulumi.get(self, "metadata")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[str]:
        """
        Minimum CPU platform to be used by this instance.
        The instance may be scheduled on the specified or newer CPU platform. Applicable
        values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
        [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
        for more information.
        """
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[str]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        """
        return pulumi.get(self, "node_group")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[Sequence[str]]:
        """
        The set of Google API scopes to be made available
        on all of the node VMs under the "default" service account.
        Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        """
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter
    def preemptible(self) -> Optional[bool]:
        """
        A boolean that represents whether or not the underlying node VMs
        are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "preemptible")

    @property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional['outputs.ClusterNodeConfigReservationAffinity']:
        """
        The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        """
        return pulumi.get(self, "reservation_affinity")

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[Mapping[str, str]]:
        """
        The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
        for how these labels are applied to clusters, node pools and nodes.
        """
        return pulumi.get(self, "resource_labels")

    @property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Optional[Mapping[str, str]]:
        """
        A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        return pulumi.get(self, "resource_manager_tags")

    @property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional['outputs.ClusterNodeConfigSandboxConfig']:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_config")

    @property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Optional[Sequence['outputs.ClusterNodeConfigSecondaryBootDisk']]:
        """
        Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[str]:
        """
        The service account to be used by the Node VMs.
        If not specified, the "default" service account is used.
        """
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional['outputs.ClusterNodeConfigShieldedInstanceConfig']:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional['outputs.ClusterNodeConfigSoleTenantConfig']:
        """
        Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
        """
        return pulumi.get(self, "sole_tenant_config")

    @property
    @pulumi.getter
    def spot(self) -> Optional[bool]:
        """
        A boolean that represents whether the underlying node VMs are spot.
        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "spot")

    @property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Optional[Sequence[str]]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Sequence[str]]:
        """
        The list of instance tags applied to all nodes. Tags are used to identify
        valid sources or targets for network firewalls.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def taints(self) -> Optional[Sequence['outputs.ClusterNodeConfigTaint']]:
        """
        A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
        to apply to nodes. GKE's API can only set this field on cluster creation.
        However, GKE will add taints to your nodes if you enable certain features such
        as GPUs. If this field is set, any diffs on this field will cause the provider to
        recreate the underlying resource. Taint values can be updated safely in
        Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
        this field to manage taints. If you do, `lifecycle.ignore_changes` is
        recommended. Structure is documented below.
        """
        return pulumi.get(self, "taints")

    @property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional['outputs.ClusterNodeConfigWorkloadMetadataConfig']:
        """
        Metadata configuration to expose to workloads on the node pool.
        Structure is documented below.
        """
        return pulumi.get(self, "workload_metadata_config")


@pulumi.output_type
class ClusterNodeConfigAdvancedMachineFeatures(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "threadsPerCore":
            suggest = "threads_per_core"
        elif key == "enableNestedVirtualization":
            suggest = "enable_nested_virtualization"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigAdvancedMachineFeatures. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 threads_per_core: int,
                 enable_nested_virtualization: Optional[bool] = None):
        """
        :param int threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        :param bool enable_nested_virtualization: Defines whether the instance should have nested virtualization enabled. Defaults to false.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)
        if enable_nested_virtualization is not None:
            pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> int:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")

    @property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> Optional[bool]:
        """
        Defines whether the instance should have nested virtualization enabled. Defaults to false.
        """
        return pulumi.get(self, "enable_nested_virtualization")


@pulumi.output_type
class ClusterNodeConfigConfidentialNodes(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodeConfigContainerdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateRegistryAccessConfig":
            suggest = "private_registry_access_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigContainerdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigContainerdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigContainerdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 private_registry_access_config: Optional['outputs.ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig'] = None):
        """
        :param 'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs' private_registry_access_config: Configuration for private container registries. There are two fields in this config:
        """
        if private_registry_access_config is not None:
            pulumi.set(__self__, "private_registry_access_config", private_registry_access_config)

    @property
    @pulumi.getter(name="privateRegistryAccessConfig")
    def private_registry_access_config(self) -> Optional['outputs.ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig']:
        """
        Configuration for private container registries. There are two fields in this config:
        """
        return pulumi.get(self, "private_registry_access_config")


@pulumi.output_type
class ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "certificateAuthorityDomainConfigs":
            suggest = "certificate_authority_domain_configs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: bool,
                 certificate_authority_domain_configs: Optional[Sequence['outputs.ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']] = None):
        """
        :param bool enabled: Enables private registry config. If set to false, all other fields in this object must not be set.
        :param Sequence['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example: 
        """
        pulumi.set(__self__, "enabled", enabled)
        if certificate_authority_domain_configs is not None:
            pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enables private registry config. If set to false, all other fields in this object must not be set.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Optional[Sequence['outputs.ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']]:
        """
        List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example: 
        """
        return pulumi.get(self, "certificate_authority_domain_configs")


@pulumi.output_type
class ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gcpSecretManagerCertificateConfig":
            suggest = "gcp_secret_manager_certificate_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 fqdns: Sequence[str],
                 gcp_secret_manager_certificate_config: 'outputs.ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig'):
        """
        :param Sequence[str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param 'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs' gcp_secret_manager_certificate_config: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_config", gcp_secret_manager_certificate_config)

    @property
    @pulumi.getter
    def fqdns(self) -> Sequence[str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @property
    @pulumi.getter(name="gcpSecretManagerCertificateConfig")
    def gcp_secret_manager_certificate_config(self) -> 'outputs.ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig':
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_config")


@pulumi.output_type
class ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretUri":
            suggest = "secret_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_uri: str):
        """
        :param str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class ClusterNodeConfigEffectiveTaint(dict):
    def __init__(__self__, *,
                 effect: Optional[str] = None,
                 key: Optional[str] = None,
                 value: Optional[str] = None):
        """
        :param str effect: Effect for taint.
        :param str key: Key for taint.
        :param str value: Value for taint.
        """
        if effect is not None:
            pulumi.set(__self__, "effect", effect)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> Optional[str]:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class ClusterNodeConfigEphemeralStorageConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigEphemeralStorageConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodeConfigEphemeralStorageLocalSsdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigEphemeralStorageLocalSsdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodeConfigFastSocket(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodeConfigGcfsConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodeConfigGuestAccelerator(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverInstallationConfig":
            suggest = "gpu_driver_installation_config"
        elif key == "gpuPartitionSize":
            suggest = "gpu_partition_size"
        elif key == "gpuSharingConfig":
            suggest = "gpu_sharing_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigGuestAccelerator. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigGuestAccelerator.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigGuestAccelerator.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 count: int,
                 type: str,
                 gpu_driver_installation_config: Optional['outputs.ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig'] = None,
                 gpu_partition_size: Optional[str] = None,
                 gpu_sharing_config: Optional['outputs.ClusterNodeConfigGuestAcceleratorGpuSharingConfig'] = None):
        """
        :param int count: The number of the guest accelerator cards exposed to this instance.
        :param str type: The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        :param 'ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs' gpu_driver_installation_config: Configuration for auto installation of GPU driver. Structure is documented below.
        :param str gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        :param 'ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs' gpu_sharing_config: Configuration for GPU sharing. Structure is documented below.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @property
    @pulumi.getter
    def count(self) -> int:
        """
        The number of the guest accelerator cards exposed to this instance.
        """
        return pulumi.get(self, "count")

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        """
        return pulumi.get(self, "type")

    @property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional['outputs.ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig']:
        """
        Configuration for auto installation of GPU driver. Structure is documented below.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[str]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        """
        return pulumi.get(self, "gpu_partition_size")

    @property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional['outputs.ClusterNodeConfigGuestAcceleratorGpuSharingConfig']:
        """
        Configuration for GPU sharing. Structure is documented below.
        """
        return pulumi.get(self, "gpu_sharing_config")


@pulumi.output_type
class ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverVersion":
            suggest = "gpu_driver_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_driver_version: str):
        """
        :param str gpu_driver_version: Mode for how the GPU driver is installed.
               Accepted values are:
               * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to not install any GPU driver.
               * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
               * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
               * `"LATEST"`: "Latest" GPU driver in COS.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> str:
        """
        Mode for how the GPU driver is installed.
        Accepted values are:
        * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to not install any GPU driver.
        * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
        * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
        * `"LATEST"`: "Latest" GPU driver in COS.
        """
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class ClusterNodeConfigGuestAcceleratorGpuSharingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuSharingStrategy":
            suggest = "gpu_sharing_strategy"
        elif key == "maxSharedClientsPerGpu":
            suggest = "max_shared_clients_per_gpu"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigGuestAcceleratorGpuSharingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_sharing_strategy: str,
                 max_shared_clients_per_gpu: int):
        """
        :param str gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node.
               Accepted values are:
               * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
               * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        :param int max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> str:
        """
        The type of GPU sharing strategy to enable on the GPU node.
        Accepted values are:
        * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> int:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class ClusterNodeConfigGvnic(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodeConfigHostMaintenancePolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maintenanceInterval":
            suggest = "maintenance_interval"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigHostMaintenancePolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 maintenance_interval: str):
        """
        :param str maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> str:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class ClusterNodeConfigKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cpuCfsQuota":
            suggest = "cpu_cfs_quota"
        elif key == "cpuCfsQuotaPeriod":
            suggest = "cpu_cfs_quota_period"
        elif key == "cpuManagerPolicy":
            suggest = "cpu_manager_policy"
        elif key == "insecureKubeletReadonlyPortEnabled":
            suggest = "insecure_kubelet_readonly_port_enabled"
        elif key == "podPidsLimit":
            suggest = "pod_pids_limit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cpu_cfs_quota: Optional[bool] = None,
                 cpu_cfs_quota_period: Optional[str] = None,
                 cpu_manager_policy: Optional[str] = None,
                 insecure_kubelet_readonly_port_enabled: Optional[str] = None,
                 pod_pids_limit: Optional[int] = None):
        """
        :param bool cpu_cfs_quota: If true, enables CPU CFS quota enforcement for
               containers that specify CPU limits.
        :param str cpu_cfs_quota_period: The CPU CFS quota period value. Specified
               as a sequence of decimal numbers, each with optional fraction and a unit suffix,
               such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
               "h". The value must be a positive duration.
        :param str cpu_manager_policy: The CPU management policy on the node. See
               [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
               One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
               Prior to the 6.4.0 this field was marked as required. The workaround for the required field
               is setting the empty string `""`, which will function identically to not setting this field.
        :param str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param int pod_pids_limit: Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if cpu_manager_policy is not None:
            pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[bool]:
        """
        If true, enables CPU CFS quota enforcement for
        containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[str]:
        """
        The CPU CFS quota period value. Specified
        as a sequence of decimal numbers, each with optional fraction and a unit suffix,
        such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
        "h". The value must be a positive duration.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> Optional[str]:
        """
        The CPU management policy on the node. See
        [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
        One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
        Prior to the 6.4.0 this field was marked as required. The workaround for the required field
        is setting the empty string `""`, which will function identically to not setting this field.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[str]:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[int]:
        """
        Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        return pulumi.get(self, "pod_pids_limit")


@pulumi.output_type
class ClusterNodeConfigLinuxNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cgroupMode":
            suggest = "cgroup_mode"
        elif key == "hugepagesConfig":
            suggest = "hugepages_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigLinuxNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigLinuxNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigLinuxNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cgroup_mode: Optional[str] = None,
                 hugepages_config: Optional['outputs.ClusterNodeConfigLinuxNodeConfigHugepagesConfig'] = None,
                 sysctls: Optional[Mapping[str, str]] = None):
        """
        :param str cgroup_mode: Possible cgroup modes that can be used.
               Accepted values are:
               * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
               * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
               * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        :param 'ClusterNodeConfigLinuxNodeConfigHugepagesConfigArgs' hugepages_config: Amounts for 2M and 1G hugepages. Structure is documented below.
        :param Mapping[str, str] sysctls: The Linux kernel parameters to be applied to the nodes
               and all pods running on the nodes. Specified as a map from the key, such as
               `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Note that validations happen all server side. All attributes are optional.
        """
        if cgroup_mode is not None:
            pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        if hugepages_config is not None:
            pulumi.set(__self__, "hugepages_config", hugepages_config)
        if sysctls is not None:
            pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> Optional[str]:
        """
        Possible cgroup modes that can be used.
        Accepted values are:
        * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
        * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
        * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        """
        return pulumi.get(self, "cgroup_mode")

    @property
    @pulumi.getter(name="hugepagesConfig")
    def hugepages_config(self) -> Optional['outputs.ClusterNodeConfigLinuxNodeConfigHugepagesConfig']:
        """
        Amounts for 2M and 1G hugepages. Structure is documented below.
        """
        return pulumi.get(self, "hugepages_config")

    @property
    @pulumi.getter
    def sysctls(self) -> Optional[Mapping[str, str]]:
        """
        The Linux kernel parameters to be applied to the nodes
        and all pods running on the nodes. Specified as a map from the key, such as
        `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Note that validations happen all server side. All attributes are optional.
        """
        return pulumi.get(self, "sysctls")


@pulumi.output_type
class ClusterNodeConfigLinuxNodeConfigHugepagesConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "hugepageSize1g":
            suggest = "hugepage_size1g"
        elif key == "hugepageSize2m":
            suggest = "hugepage_size2m"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigLinuxNodeConfigHugepagesConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigLinuxNodeConfigHugepagesConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigLinuxNodeConfigHugepagesConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 hugepage_size1g: Optional[int] = None,
                 hugepage_size2m: Optional[int] = None):
        """
        :param int hugepage_size1g: Amount of 1G hugepages.
        :param int hugepage_size2m: Amount of 2M hugepages.
        """
        if hugepage_size1g is not None:
            pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        if hugepage_size2m is not None:
            pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> Optional[int]:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> Optional[int]:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")


@pulumi.output_type
class ClusterNodeConfigLocalNvmeSsdBlockConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigLocalNvmeSsdBlockConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
               > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
        > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodeConfigReservationAffinity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "consumeReservationType":
            suggest = "consume_reservation_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigReservationAffinity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigReservationAffinity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigReservationAffinity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 consume_reservation_type: str,
                 key: Optional[str] = None,
                 values: Optional[Sequence[str]] = None):
        """
        :param str consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param str key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param Sequence[str] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> str:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def values(self) -> Optional[Sequence[str]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ClusterNodeConfigSandboxConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sandboxType":
            suggest = "sandbox_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigSandboxConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigSandboxConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigSandboxConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 sandbox_type: str):
        """
        :param str sandbox_type: Which sandbox to use for pods in the node pool.
               Accepted values are:
               
               * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> str:
        """
        Which sandbox to use for pods in the node pool.
        Accepted values are:

        * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class ClusterNodeConfigSecondaryBootDisk(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "diskImage":
            suggest = "disk_image"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigSecondaryBootDisk. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigSecondaryBootDisk.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigSecondaryBootDisk.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disk_image: str,
                 mode: Optional[str] = None):
        """
        :param str disk_image: Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        :param str mode: Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        if mode is not None:
            pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> str:
        """
        Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        """
        return pulumi.get(self, "disk_image")

    @property
    @pulumi.getter
    def mode(self) -> Optional[str]:
        """
        Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class ClusterNodeConfigShieldedInstanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableIntegrityMonitoring":
            suggest = "enable_integrity_monitoring"
        elif key == "enableSecureBoot":
            suggest = "enable_secure_boot"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigShieldedInstanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[bool] = None,
                 enable_secure_boot: Optional[bool] = None):
        """
        :param bool enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param bool enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[bool]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[bool]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class ClusterNodeConfigSoleTenantConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodeAffinities":
            suggest = "node_affinities"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigSoleTenantConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigSoleTenantConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigSoleTenantConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.ClusterNodeConfigSoleTenantConfigNodeAffinity']):
        """
        :param Sequence['ClusterNodeConfigSoleTenantConfigNodeAffinityArgs'] node_affinities: .
        """
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.ClusterNodeConfigSoleTenantConfigNodeAffinity']:
        """
        .
        """
        return pulumi.get(self, "node_affinities")


@pulumi.output_type
class ClusterNodeConfigSoleTenantConfigNodeAffinity(dict):
    def __init__(__self__, *,
                 key: str,
                 operator: str,
                 values: Sequence[str]):
        """
        :param str key: The default or custom node affinity label key name.
        :param str operator: Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        :param Sequence[str] values: List of node affinity label values as strings.
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        The default or custom node affinity label key name.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def operator(self) -> str:
        """
        Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        """
        return pulumi.get(self, "operator")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        """
        List of node affinity label values as strings.
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ClusterNodeConfigTaint(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        """
        :param str effect: Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        :param str key: Key for taint.
        :param str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        """
        Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class ClusterNodeConfigWorkloadMetadataConfig(dict):
    def __init__(__self__, *,
                 mode: str):
        """
        :param str mode: How to expose the node metadata to the workload running on the node.
               Accepted values are:
               * UNSPECIFIED: Not Set
               * GCE_METADATA: Expose all Compute Engine metadata to pods.
               * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> str:
        """
        How to expose the node metadata to the workload running on the node.
        Accepted values are:
        * UNSPECIFIED: Not Set
        * GCE_METADATA: Expose all Compute Engine metadata to pods.
        * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class ClusterNodePool(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "initialNodeCount":
            suggest = "initial_node_count"
        elif key == "instanceGroupUrls":
            suggest = "instance_group_urls"
        elif key == "managedInstanceGroupUrls":
            suggest = "managed_instance_group_urls"
        elif key == "maxPodsPerNode":
            suggest = "max_pods_per_node"
        elif key == "namePrefix":
            suggest = "name_prefix"
        elif key == "networkConfig":
            suggest = "network_config"
        elif key == "nodeConfig":
            suggest = "node_config"
        elif key == "nodeCount":
            suggest = "node_count"
        elif key == "nodeLocations":
            suggest = "node_locations"
        elif key == "placementPolicy":
            suggest = "placement_policy"
        elif key == "queuedProvisioning":
            suggest = "queued_provisioning"
        elif key == "upgradeSettings":
            suggest = "upgrade_settings"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePool. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePool.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePool.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 autoscaling: Optional['outputs.ClusterNodePoolAutoscaling'] = None,
                 initial_node_count: Optional[int] = None,
                 instance_group_urls: Optional[Sequence[str]] = None,
                 managed_instance_group_urls: Optional[Sequence[str]] = None,
                 management: Optional['outputs.ClusterNodePoolManagement'] = None,
                 max_pods_per_node: Optional[int] = None,
                 name: Optional[str] = None,
                 name_prefix: Optional[str] = None,
                 network_config: Optional['outputs.ClusterNodePoolNetworkConfig'] = None,
                 node_config: Optional['outputs.ClusterNodePoolNodeConfig'] = None,
                 node_count: Optional[int] = None,
                 node_locations: Optional[Sequence[str]] = None,
                 placement_policy: Optional['outputs.ClusterNodePoolPlacementPolicy'] = None,
                 queued_provisioning: Optional['outputs.ClusterNodePoolQueuedProvisioning'] = None,
                 upgrade_settings: Optional['outputs.ClusterNodePoolUpgradeSettings'] = None,
                 version: Optional[str] = None):
        """
        :param 'ClusterNodePoolAutoscalingArgs' autoscaling: Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
        :param int initial_node_count: The number of nodes to create in this
               cluster's default node pool. In regional or multi-zonal clusters, this is the
               number of nodes per zone. Must be set if `node_pool` is not set. If you're using
               `container.NodePool` objects with no default node pool, you'll need to
               set this to a value of at least `1`, alongside setting
               `remove_default_node_pool` to `true`.
        :param Sequence[str] instance_group_urls: The resource URLs of the managed instance groups associated with this node pool.
        :param Sequence[str] managed_instance_group_urls: List of instance group URLs which have been assigned to this node pool.
        :param 'ClusterNodePoolManagementArgs' management: Node management configuration, wherein auto-repair and auto-upgrade is configured.
        :param int max_pods_per_node: The maximum number of pods per node in this node pool. Note that this does not work on node pools which are "route-based" - that is, node pools belonging to clusters that do not have IP Aliasing enabled.
        :param str name: The name of the cluster, unique within the project and
               location.
               
               - - -
        :param str name_prefix: Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.
        :param 'ClusterNodePoolNetworkConfigArgs' network_config: Configuration for
               [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
        :param 'ClusterNodePoolNodeConfigArgs' node_config: Parameters used in creating the default node pool.
               Generally, this field should not be used at the same time as a
               `container.NodePool` or a `node_pool` block; this configuration
               manages the default node pool, which isn't recommended to be used.
               Structure is documented below.
        :param int node_count: The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.
        :param Sequence[str] node_locations: The list of zones in which the cluster's nodes
               are located. Nodes must be in the region of their regional cluster or in the
               same region as their cluster's zone for zonal clusters. If this is specified for
               a zonal cluster, omit the cluster's zone.
               
               > A "multi-zonal" cluster is a zonal cluster with at least one additional zone
               defined; in a multi-zonal cluster, the cluster master is only present in a
               single zone while nodes are present in each of the primary zone and the node
               locations. In contrast, in a regional cluster, cluster master nodes are present
               in multiple zones in the region. For that reason, regional clusters should be
               preferred.
        :param 'ClusterNodePoolPlacementPolicyArgs' placement_policy: Specifies the node placement policy
        :param 'ClusterNodePoolQueuedProvisioningArgs' queued_provisioning: Specifies the configuration of queued provisioning
        :param 'ClusterNodePoolUpgradeSettingsArgs' upgrade_settings: Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of max_surge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.
        """
        if autoscaling is not None:
            pulumi.set(__self__, "autoscaling", autoscaling)
        if initial_node_count is not None:
            pulumi.set(__self__, "initial_node_count", initial_node_count)
        if instance_group_urls is not None:
            pulumi.set(__self__, "instance_group_urls", instance_group_urls)
        if managed_instance_group_urls is not None:
            pulumi.set(__self__, "managed_instance_group_urls", managed_instance_group_urls)
        if management is not None:
            pulumi.set(__self__, "management", management)
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if name_prefix is not None:
            pulumi.set(__self__, "name_prefix", name_prefix)
        if network_config is not None:
            pulumi.set(__self__, "network_config", network_config)
        if node_config is not None:
            pulumi.set(__self__, "node_config", node_config)
        if node_count is not None:
            pulumi.set(__self__, "node_count", node_count)
        if node_locations is not None:
            pulumi.set(__self__, "node_locations", node_locations)
        if placement_policy is not None:
            pulumi.set(__self__, "placement_policy", placement_policy)
        if queued_provisioning is not None:
            pulumi.set(__self__, "queued_provisioning", queued_provisioning)
        if upgrade_settings is not None:
            pulumi.set(__self__, "upgrade_settings", upgrade_settings)
        if version is not None:
            pulumi.set(__self__, "version", version)

    @property
    @pulumi.getter
    def autoscaling(self) -> Optional['outputs.ClusterNodePoolAutoscaling']:
        """
        Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
        """
        return pulumi.get(self, "autoscaling")

    @property
    @pulumi.getter(name="initialNodeCount")
    def initial_node_count(self) -> Optional[int]:
        """
        The number of nodes to create in this
        cluster's default node pool. In regional or multi-zonal clusters, this is the
        number of nodes per zone. Must be set if `node_pool` is not set. If you're using
        `container.NodePool` objects with no default node pool, you'll need to
        set this to a value of at least `1`, alongside setting
        `remove_default_node_pool` to `true`.
        """
        return pulumi.get(self, "initial_node_count")

    @property
    @pulumi.getter(name="instanceGroupUrls")
    def instance_group_urls(self) -> Optional[Sequence[str]]:
        """
        The resource URLs of the managed instance groups associated with this node pool.
        """
        return pulumi.get(self, "instance_group_urls")

    @property
    @pulumi.getter(name="managedInstanceGroupUrls")
    def managed_instance_group_urls(self) -> Optional[Sequence[str]]:
        """
        List of instance group URLs which have been assigned to this node pool.
        """
        return pulumi.get(self, "managed_instance_group_urls")

    @property
    @pulumi.getter
    def management(self) -> Optional['outputs.ClusterNodePoolManagement']:
        """
        Node management configuration, wherein auto-repair and auto-upgrade is configured.
        """
        return pulumi.get(self, "management")

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[int]:
        """
        The maximum number of pods per node in this node pool. Note that this does not work on node pools which are "route-based" - that is, node pools belonging to clusters that do not have IP Aliasing enabled.
        """
        return pulumi.get(self, "max_pods_per_node")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of the cluster, unique within the project and
        location.

        - - -
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="namePrefix")
    def name_prefix(self) -> Optional[str]:
        """
        Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.
        """
        return pulumi.get(self, "name_prefix")

    @property
    @pulumi.getter(name="networkConfig")
    def network_config(self) -> Optional['outputs.ClusterNodePoolNetworkConfig']:
        """
        Configuration for
        [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
        """
        return pulumi.get(self, "network_config")

    @property
    @pulumi.getter(name="nodeConfig")
    def node_config(self) -> Optional['outputs.ClusterNodePoolNodeConfig']:
        """
        Parameters used in creating the default node pool.
        Generally, this field should not be used at the same time as a
        `container.NodePool` or a `node_pool` block; this configuration
        manages the default node pool, which isn't recommended to be used.
        Structure is documented below.
        """
        return pulumi.get(self, "node_config")

    @property
    @pulumi.getter(name="nodeCount")
    def node_count(self) -> Optional[int]:
        """
        The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.
        """
        return pulumi.get(self, "node_count")

    @property
    @pulumi.getter(name="nodeLocations")
    def node_locations(self) -> Optional[Sequence[str]]:
        """
        The list of zones in which the cluster's nodes
        are located. Nodes must be in the region of their regional cluster or in the
        same region as their cluster's zone for zonal clusters. If this is specified for
        a zonal cluster, omit the cluster's zone.

        > A "multi-zonal" cluster is a zonal cluster with at least one additional zone
        defined; in a multi-zonal cluster, the cluster master is only present in a
        single zone while nodes are present in each of the primary zone and the node
        locations. In contrast, in a regional cluster, cluster master nodes are present
        in multiple zones in the region. For that reason, regional clusters should be
        preferred.
        """
        return pulumi.get(self, "node_locations")

    @property
    @pulumi.getter(name="placementPolicy")
    def placement_policy(self) -> Optional['outputs.ClusterNodePoolPlacementPolicy']:
        """
        Specifies the node placement policy
        """
        return pulumi.get(self, "placement_policy")

    @property
    @pulumi.getter(name="queuedProvisioning")
    def queued_provisioning(self) -> Optional['outputs.ClusterNodePoolQueuedProvisioning']:
        """
        Specifies the configuration of queued provisioning
        """
        return pulumi.get(self, "queued_provisioning")

    @property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Optional['outputs.ClusterNodePoolUpgradeSettings']:
        """
        Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of max_surge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.
        """
        return pulumi.get(self, "upgrade_settings")

    @property
    @pulumi.getter
    def version(self) -> Optional[str]:
        return pulumi.get(self, "version")


@pulumi.output_type
class ClusterNodePoolAutoConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "networkTags":
            suggest = "network_tags"
        elif key == "nodeKubeletConfig":
            suggest = "node_kubelet_config"
        elif key == "resourceManagerTags":
            suggest = "resource_manager_tags"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolAutoConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolAutoConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolAutoConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 network_tags: Optional['outputs.ClusterNodePoolAutoConfigNetworkTags'] = None,
                 node_kubelet_config: Optional['outputs.ClusterNodePoolAutoConfigNodeKubeletConfig'] = None,
                 resource_manager_tags: Optional[Mapping[str, str]] = None):
        """
        :param 'ClusterNodePoolAutoConfigNetworkTagsArgs' network_tags: The network tag config for the cluster's automatically provisioned node pools. Structure is documented below.
        :param 'ClusterNodePoolAutoConfigNodeKubeletConfigArgs' node_kubelet_config: Kubelet configuration for Autopilot clusters. Currently, only `insecure_kubelet_readonly_port_enabled` is supported here.
               Structure is documented below.
        :param Mapping[str, str] resource_manager_tags: A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        if network_tags is not None:
            pulumi.set(__self__, "network_tags", network_tags)
        if node_kubelet_config is not None:
            pulumi.set(__self__, "node_kubelet_config", node_kubelet_config)
        if resource_manager_tags is not None:
            pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)

    @property
    @pulumi.getter(name="networkTags")
    def network_tags(self) -> Optional['outputs.ClusterNodePoolAutoConfigNetworkTags']:
        """
        The network tag config for the cluster's automatically provisioned node pools. Structure is documented below.
        """
        return pulumi.get(self, "network_tags")

    @property
    @pulumi.getter(name="nodeKubeletConfig")
    def node_kubelet_config(self) -> Optional['outputs.ClusterNodePoolAutoConfigNodeKubeletConfig']:
        """
        Kubelet configuration for Autopilot clusters. Currently, only `insecure_kubelet_readonly_port_enabled` is supported here.
        Structure is documented below.
        """
        return pulumi.get(self, "node_kubelet_config")

    @property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Optional[Mapping[str, str]]:
        """
        A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        return pulumi.get(self, "resource_manager_tags")


@pulumi.output_type
class ClusterNodePoolAutoConfigNetworkTags(dict):
    def __init__(__self__, *,
                 tags: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] tags: List of network tags applied to auto-provisioned node pools.
        """
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @property
    @pulumi.getter
    def tags(self) -> Optional[Sequence[str]]:
        """
        List of network tags applied to auto-provisioned node pools.
        """
        return pulumi.get(self, "tags")


@pulumi.output_type
class ClusterNodePoolAutoConfigNodeKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "insecureKubeletReadonlyPortEnabled":
            suggest = "insecure_kubelet_readonly_port_enabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolAutoConfigNodeKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolAutoConfigNodeKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolAutoConfigNodeKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 insecure_kubelet_readonly_port_enabled: Optional[str] = None):
        """
        :param str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[str]:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")


@pulumi.output_type
class ClusterNodePoolAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "locationPolicy":
            suggest = "location_policy"
        elif key == "maxNodeCount":
            suggest = "max_node_count"
        elif key == "minNodeCount":
            suggest = "min_node_count"
        elif key == "totalMaxNodeCount":
            suggest = "total_max_node_count"
        elif key == "totalMinNodeCount":
            suggest = "total_min_node_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 location_policy: Optional[str] = None,
                 max_node_count: Optional[int] = None,
                 min_node_count: Optional[int] = None,
                 total_max_node_count: Optional[int] = None,
                 total_min_node_count: Optional[int] = None):
        """
        :param str location_policy: Location policy specifies the algorithm used when scaling-up the node pool. "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones. "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations, and reduces preemption risk for Spot VMs.
        :param int max_node_count: Maximum number of nodes per zone in the node pool. Must be >= min_node_count. Cannot be used with total limits.
        :param int min_node_count: Minimum number of nodes per zone in the node pool. Must be >=0 and <= max_node_count. Cannot be used with total limits.
        :param int total_max_node_count: Maximum number of all nodes in the node pool. Must be >= total_min_node_count. Cannot be used with per zone limits.
        :param int total_min_node_count: Minimum number of all nodes in the node pool. Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
        """
        if location_policy is not None:
            pulumi.set(__self__, "location_policy", location_policy)
        if max_node_count is not None:
            pulumi.set(__self__, "max_node_count", max_node_count)
        if min_node_count is not None:
            pulumi.set(__self__, "min_node_count", min_node_count)
        if total_max_node_count is not None:
            pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        if total_min_node_count is not None:
            pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> Optional[str]:
        """
        Location policy specifies the algorithm used when scaling-up the node pool. "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones. "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations, and reduces preemption risk for Spot VMs.
        """
        return pulumi.get(self, "location_policy")

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> Optional[int]:
        """
        Maximum number of nodes per zone in the node pool. Must be >= min_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "max_node_count")

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> Optional[int]:
        """
        Minimum number of nodes per zone in the node pool. Must be >=0 and <= max_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "min_node_count")

    @property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> Optional[int]:
        """
        Maximum number of all nodes in the node pool. Must be >= total_min_node_count. Cannot be used with per zone limits.
        """
        return pulumi.get(self, "total_max_node_count")

    @property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> Optional[int]:
        """
        Minimum number of all nodes in the node pool. Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
        """
        return pulumi.get(self, "total_min_node_count")


@pulumi.output_type
class ClusterNodePoolDefaults(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodeConfigDefaults":
            suggest = "node_config_defaults"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaults. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaults.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaults.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_config_defaults: Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaults'] = None):
        """
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsArgs' node_config_defaults: Subset of NodeConfig message that has defaults.
        """
        if node_config_defaults is not None:
            pulumi.set(__self__, "node_config_defaults", node_config_defaults)

    @property
    @pulumi.getter(name="nodeConfigDefaults")
    def node_config_defaults(self) -> Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaults']:
        """
        Subset of NodeConfig message that has defaults.
        """
        return pulumi.get(self, "node_config_defaults")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaults(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "containerdConfig":
            suggest = "containerd_config"
        elif key == "gcfsConfig":
            suggest = "gcfs_config"
        elif key == "insecureKubeletReadonlyPortEnabled":
            suggest = "insecure_kubelet_readonly_port_enabled"
        elif key == "loggingVariant":
            suggest = "logging_variant"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaultsNodeConfigDefaults. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaults.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaults.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 containerd_config: Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig'] = None,
                 gcfs_config: Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfig'] = None,
                 insecure_kubelet_readonly_port_enabled: Optional[str] = None,
                 logging_variant: Optional[str] = None):
        """
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigArgs' containerd_config: Parameters for containerd configuration.
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs' gcfs_config: The default Google Container Filesystem (GCFS) configuration at the cluster level. e.g. enable [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming) across all the node pools within the cluster. Structure is documented below.
        :param str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled for newly created node pools in the cluster. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param str logging_variant: The type of logging agent that is deployed by default for newly created node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        if containerd_config is not None:
            pulumi.set(__self__, "containerd_config", containerd_config)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)

    @property
    @pulumi.getter(name="containerdConfig")
    def containerd_config(self) -> Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig']:
        """
        Parameters for containerd configuration.
        """
        return pulumi.get(self, "containerd_config")

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfig']:
        """
        The default Google Container Filesystem (GCFS) configuration at the cluster level. e.g. enable [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming) across all the node pools within the cluster. Structure is documented below.
        """
        return pulumi.get(self, "gcfs_config")

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[str]:
        """
        Controls whether the kubelet read-only port is enabled for newly created node pools in the cluster. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[str]:
        """
        The type of logging agent that is deployed by default for newly created node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateRegistryAccessConfig":
            suggest = "private_registry_access_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 private_registry_access_config: Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig'] = None):
        """
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigArgs' private_registry_access_config: Configuration for private container registries. There are two fields in this config:
        """
        if private_registry_access_config is not None:
            pulumi.set(__self__, "private_registry_access_config", private_registry_access_config)

    @property
    @pulumi.getter(name="privateRegistryAccessConfig")
    def private_registry_access_config(self) -> Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig']:
        """
        Configuration for private container registries. There are two fields in this config:
        """
        return pulumi.get(self, "private_registry_access_config")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "certificateAuthorityDomainConfigs":
            suggest = "certificate_authority_domain_configs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: bool,
                 certificate_authority_domain_configs: Optional[Sequence['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']] = None):
        """
        :param bool enabled: Enables private registry config. If set to false, all other fields in this object must not be set.
        :param Sequence['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example: 
        """
        pulumi.set(__self__, "enabled", enabled)
        if certificate_authority_domain_configs is not None:
            pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enables private registry config. If set to false, all other fields in this object must not be set.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Optional[Sequence['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']]:
        """
        List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example: 
        """
        return pulumi.get(self, "certificate_authority_domain_configs")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gcpSecretManagerCertificateConfig":
            suggest = "gcp_secret_manager_certificate_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 fqdns: Sequence[str],
                 gcp_secret_manager_certificate_config: 'outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig'):
        """
        :param Sequence[str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs' gcp_secret_manager_certificate_config: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_config", gcp_secret_manager_certificate_config)

    @property
    @pulumi.getter
    def fqdns(self) -> Sequence[str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @property
    @pulumi.getter(name="gcpSecretManagerCertificateConfig")
    def gcp_secret_manager_certificate_config(self) -> 'outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig':
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_config")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretUri":
            suggest = "secret_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_uri: str):
        """
        :param str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"
        elif key == "autoUpgrade":
            suggest = "auto_upgrade"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[bool] = None,
                 auto_upgrade: Optional[bool] = None):
        """
        :param bool auto_repair: Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
               
               This block also contains several computed attributes, documented below.
        :param bool auto_upgrade: Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[bool]:
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.

        This block also contains several computed attributes, documented below.
        """
        return pulumi.get(self, "auto_repair")

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[bool]:
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        return pulumi.get(self, "auto_upgrade")


@pulumi.output_type
class ClusterNodePoolNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "additionalNodeNetworkConfigs":
            suggest = "additional_node_network_configs"
        elif key == "additionalPodNetworkConfigs":
            suggest = "additional_pod_network_configs"
        elif key == "createPodRange":
            suggest = "create_pod_range"
        elif key == "enablePrivateNodes":
            suggest = "enable_private_nodes"
        elif key == "networkPerformanceConfig":
            suggest = "network_performance_config"
        elif key == "podCidrOverprovisionConfig":
            suggest = "pod_cidr_overprovision_config"
        elif key == "podIpv4CidrBlock":
            suggest = "pod_ipv4_cidr_block"
        elif key == "podRange":
            suggest = "pod_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 additional_node_network_configs: Optional[Sequence['outputs.ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfig']] = None,
                 additional_pod_network_configs: Optional[Sequence['outputs.ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig']] = None,
                 create_pod_range: Optional[bool] = None,
                 enable_private_nodes: Optional[bool] = None,
                 network_performance_config: Optional['outputs.ClusterNodePoolNetworkConfigNetworkPerformanceConfig'] = None,
                 pod_cidr_overprovision_config: Optional['outputs.ClusterNodePoolNetworkConfigPodCidrOverprovisionConfig'] = None,
                 pod_ipv4_cidr_block: Optional[str] = None,
                 pod_range: Optional[str] = None):
        """
        :param Sequence['ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs'] additional_node_network_configs: We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface
        :param Sequence['ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs'] additional_pod_network_configs: We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node
        :param bool create_pod_range: Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        :param bool enable_private_nodes: Whether nodes have internal IP addresses only.
        :param 'ClusterNodePoolNetworkConfigNetworkPerformanceConfigArgs' network_performance_config: Network bandwidth tier configuration.
        :param 'ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs' pod_cidr_overprovision_config: Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited
        :param str pod_ipv4_cidr_block: The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        :param str pod_range: The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        if additional_node_network_configs is not None:
            pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        if additional_pod_network_configs is not None:
            pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        if create_pod_range is not None:
            pulumi.set(__self__, "create_pod_range", create_pod_range)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if network_performance_config is not None:
            pulumi.set(__self__, "network_performance_config", network_performance_config)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if pod_ipv4_cidr_block is not None:
            pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        if pod_range is not None:
            pulumi.set(__self__, "pod_range", pod_range)

    @property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Optional[Sequence['outputs.ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfig']]:
        """
        We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface
        """
        return pulumi.get(self, "additional_node_network_configs")

    @property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Optional[Sequence['outputs.ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig']]:
        """
        We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node
        """
        return pulumi.get(self, "additional_pod_network_configs")

    @property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> Optional[bool]:
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        """
        return pulumi.get(self, "create_pod_range")

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[bool]:
        """
        Whether nodes have internal IP addresses only.
        """
        return pulumi.get(self, "enable_private_nodes")

    @property
    @pulumi.getter(name="networkPerformanceConfig")
    def network_performance_config(self) -> Optional['outputs.ClusterNodePoolNetworkConfigNetworkPerformanceConfig']:
        """
        Network bandwidth tier configuration.
        """
        return pulumi.get(self, "network_performance_config")

    @property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional['outputs.ClusterNodePoolNetworkConfigPodCidrOverprovisionConfig']:
        """
        Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited
        """
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> Optional[str]:
        """
        The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> Optional[str]:
        """
        The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        return pulumi.get(self, "pod_range")


@pulumi.output_type
class ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfig(dict):
    def __init__(__self__, *,
                 network: Optional[str] = None,
                 subnetwork: Optional[str] = None):
        """
        :param str network: The name or self_link of the Google Compute Engine
               network to which the cluster is connected. For Shared VPC, set this to the self link of the
               shared network.
        :param str subnetwork: The name or self_link of the Google Compute Engine
               subnetwork in which the cluster's instances are launched.
        """
        if network is not None:
            pulumi.set(__self__, "network", network)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter
    def network(self) -> Optional[str]:
        """
        The name or self_link of the Google Compute Engine
        network to which the cluster is connected. For Shared VPC, set this to the self link of the
        shared network.
        """
        return pulumi.get(self, "network")

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[str]:
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxPodsPerNode":
            suggest = "max_pods_per_node"
        elif key == "secondaryPodRange":
            suggest = "secondary_pod_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_pods_per_node: Optional[int] = None,
                 secondary_pod_range: Optional[str] = None,
                 subnetwork: Optional[str] = None):
        """
        :param int max_pods_per_node: The maximum number of pods per node which use this pod network.
        :param str secondary_pod_range: The name of the secondary range on the subnet which provides IP address for this pod range.
        :param str subnetwork: The name or self_link of the Google Compute Engine
               subnetwork in which the cluster's instances are launched.
        """
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if secondary_pod_range is not None:
            pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[int]:
        """
        The maximum number of pods per node which use this pod network.
        """
        return pulumi.get(self, "max_pods_per_node")

    @property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> Optional[str]:
        """
        The name of the secondary range on the subnet which provides IP address for this pod range.
        """
        return pulumi.get(self, "secondary_pod_range")

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[str]:
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class ClusterNodePoolNetworkConfigNetworkPerformanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "totalEgressBandwidthTier":
            suggest = "total_egress_bandwidth_tier"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNetworkConfigNetworkPerformanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNetworkConfigNetworkPerformanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNetworkConfigNetworkPerformanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 total_egress_bandwidth_tier: str):
        """
        :param str total_egress_bandwidth_tier: Specifies the total network bandwidth tier for the NodePool.
        """
        pulumi.set(__self__, "total_egress_bandwidth_tier", total_egress_bandwidth_tier)

    @property
    @pulumi.getter(name="totalEgressBandwidthTier")
    def total_egress_bandwidth_tier(self) -> str:
        """
        Specifies the total network bandwidth tier for the NodePool.
        """
        return pulumi.get(self, "total_egress_bandwidth_tier")


@pulumi.output_type
class ClusterNodePoolNetworkConfigPodCidrOverprovisionConfig(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterNodePoolNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "advancedMachineFeatures":
            suggest = "advanced_machine_features"
        elif key == "bootDiskKmsKey":
            suggest = "boot_disk_kms_key"
        elif key == "confidentialNodes":
            suggest = "confidential_nodes"
        elif key == "containerdConfig":
            suggest = "containerd_config"
        elif key == "diskSizeGb":
            suggest = "disk_size_gb"
        elif key == "diskType":
            suggest = "disk_type"
        elif key == "effectiveTaints":
            suggest = "effective_taints"
        elif key == "enableConfidentialStorage":
            suggest = "enable_confidential_storage"
        elif key == "ephemeralStorageConfig":
            suggest = "ephemeral_storage_config"
        elif key == "ephemeralStorageLocalSsdConfig":
            suggest = "ephemeral_storage_local_ssd_config"
        elif key == "fastSocket":
            suggest = "fast_socket"
        elif key == "gcfsConfig":
            suggest = "gcfs_config"
        elif key == "guestAccelerators":
            suggest = "guest_accelerators"
        elif key == "hostMaintenancePolicy":
            suggest = "host_maintenance_policy"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "kubeletConfig":
            suggest = "kubelet_config"
        elif key == "linuxNodeConfig":
            suggest = "linux_node_config"
        elif key == "localNvmeSsdBlockConfig":
            suggest = "local_nvme_ssd_block_config"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "loggingVariant":
            suggest = "logging_variant"
        elif key == "machineType":
            suggest = "machine_type"
        elif key == "minCpuPlatform":
            suggest = "min_cpu_platform"
        elif key == "nodeGroup":
            suggest = "node_group"
        elif key == "oauthScopes":
            suggest = "oauth_scopes"
        elif key == "reservationAffinity":
            suggest = "reservation_affinity"
        elif key == "resourceLabels":
            suggest = "resource_labels"
        elif key == "resourceManagerTags":
            suggest = "resource_manager_tags"
        elif key == "sandboxConfig":
            suggest = "sandbox_config"
        elif key == "secondaryBootDisks":
            suggest = "secondary_boot_disks"
        elif key == "serviceAccount":
            suggest = "service_account"
        elif key == "shieldedInstanceConfig":
            suggest = "shielded_instance_config"
        elif key == "soleTenantConfig":
            suggest = "sole_tenant_config"
        elif key == "storagePools":
            suggest = "storage_pools"
        elif key == "workloadMetadataConfig":
            suggest = "workload_metadata_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 advanced_machine_features: Optional['outputs.ClusterNodePoolNodeConfigAdvancedMachineFeatures'] = None,
                 boot_disk_kms_key: Optional[str] = None,
                 confidential_nodes: Optional['outputs.ClusterNodePoolNodeConfigConfidentialNodes'] = None,
                 containerd_config: Optional['outputs.ClusterNodePoolNodeConfigContainerdConfig'] = None,
                 disk_size_gb: Optional[int] = None,
                 disk_type: Optional[str] = None,
                 effective_taints: Optional[Sequence['outputs.ClusterNodePoolNodeConfigEffectiveTaint']] = None,
                 enable_confidential_storage: Optional[bool] = None,
                 ephemeral_storage_config: Optional['outputs.ClusterNodePoolNodeConfigEphemeralStorageConfig'] = None,
                 ephemeral_storage_local_ssd_config: Optional['outputs.ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig'] = None,
                 fast_socket: Optional['outputs.ClusterNodePoolNodeConfigFastSocket'] = None,
                 gcfs_config: Optional['outputs.ClusterNodePoolNodeConfigGcfsConfig'] = None,
                 guest_accelerators: Optional[Sequence['outputs.ClusterNodePoolNodeConfigGuestAccelerator']] = None,
                 gvnic: Optional['outputs.ClusterNodePoolNodeConfigGvnic'] = None,
                 host_maintenance_policy: Optional['outputs.ClusterNodePoolNodeConfigHostMaintenancePolicy'] = None,
                 image_type: Optional[str] = None,
                 kubelet_config: Optional['outputs.ClusterNodePoolNodeConfigKubeletConfig'] = None,
                 labels: Optional[Mapping[str, str]] = None,
                 linux_node_config: Optional['outputs.ClusterNodePoolNodeConfigLinuxNodeConfig'] = None,
                 local_nvme_ssd_block_config: Optional['outputs.ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig'] = None,
                 local_ssd_count: Optional[int] = None,
                 logging_variant: Optional[str] = None,
                 machine_type: Optional[str] = None,
                 metadata: Optional[Mapping[str, str]] = None,
                 min_cpu_platform: Optional[str] = None,
                 node_group: Optional[str] = None,
                 oauth_scopes: Optional[Sequence[str]] = None,
                 preemptible: Optional[bool] = None,
                 reservation_affinity: Optional['outputs.ClusterNodePoolNodeConfigReservationAffinity'] = None,
                 resource_labels: Optional[Mapping[str, str]] = None,
                 resource_manager_tags: Optional[Mapping[str, str]] = None,
                 sandbox_config: Optional['outputs.ClusterNodePoolNodeConfigSandboxConfig'] = None,
                 secondary_boot_disks: Optional[Sequence['outputs.ClusterNodePoolNodeConfigSecondaryBootDisk']] = None,
                 service_account: Optional[str] = None,
                 shielded_instance_config: Optional['outputs.ClusterNodePoolNodeConfigShieldedInstanceConfig'] = None,
                 sole_tenant_config: Optional['outputs.ClusterNodePoolNodeConfigSoleTenantConfig'] = None,
                 spot: Optional[bool] = None,
                 storage_pools: Optional[Sequence[str]] = None,
                 tags: Optional[Sequence[str]] = None,
                 taints: Optional[Sequence['outputs.ClusterNodePoolNodeConfigTaint']] = None,
                 workload_metadata_config: Optional['outputs.ClusterNodePoolNodeConfigWorkloadMetadataConfig'] = None):
        """
        :param 'ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs' advanced_machine_features: Specifies options for controlling
               advanced machine features. Structure is documented below.
        :param str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        :param 'ClusterNodePoolNodeConfigConfidentialNodesArgs' confidential_nodes: Configuration for Confidential Nodes feature. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigContainerdConfigArgs' containerd_config: Parameters to customize containerd runtime. Structure is documented below.
        :param int disk_size_gb: Size of the disk attached to each node, specified
               in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        :param str disk_type: Type of the disk attached to each node
               (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        :param Sequence['ClusterNodePoolNodeConfigEffectiveTaintArgs'] effective_taints: List of kubernetes taints applied to each node. Structure is documented above.
        :param bool enable_confidential_storage: Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        :param 'ClusterNodePoolNodeConfigEphemeralStorageConfigArgs' ephemeral_storage_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs' ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigFastSocketArgs' fast_socket: Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
               Node Pool must enable gvnic.
               GKE version 1.25.2-gke.1700 or later.
               Structure is documented below.
        :param 'ClusterNodePoolNodeConfigGcfsConfigArgs' gcfs_config: Parameters for the Google Container Filesystem (GCFS).
               If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
               For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
               A `machine_type` that has more than 16 GiB of memory is also recommended.
               GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
               Structure is documented below.
        :param Sequence['ClusterNodePoolNodeConfigGuestAcceleratorArgs'] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
               Structure documented below.
        :param 'ClusterNodePoolNodeConfigGvnicArgs' gvnic: Google Virtual NIC (gVNIC) is a virtual network interface.
               Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
               gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
               GKE node version 1.15.11-gke.15 or later
               Structure is documented below.
        :param 'ClusterNodePoolNodeConfigHostMaintenancePolicyArgs' host_maintenance_policy: The maintenance policy for the hosts on which the GKE VMs run on.
        :param str image_type: The image type to use for this node. Note that changing the image type
               will delete and recreate all nodes in the node pool.
        :param 'ClusterNodePoolNodeConfigKubeletConfigArgs' kubelet_config: Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Structure is documented below.
               
               ```
               kubelet_config {
               cpu_manager_policy   = "static"
               cpu_cfs_quota        = true
               cpu_cfs_quota_period = "100us"
               pod_pids_limit       = 1024
               }
               ```
        :param Mapping[str, str] labels: The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
               reserved by Kubernetes Core components and cannot be specified.
        :param 'ClusterNodePoolNodeConfigLinuxNodeConfigArgs' linux_node_config: Parameters that can be configured on Linux nodes. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs' local_nvme_ssd_block_config: Parameters for the local NVMe SSDs. Structure is documented below.
        :param int local_ssd_count: The amount of local SSD disks that will be
               attached to each cluster node. Defaults to 0.
        :param str logging_variant: Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        :param str machine_type: The name of a Google Compute Engine machine type.
               Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
               [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        :param Mapping[str, str] metadata: The metadata key/value pairs assigned to instances in
               the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
               `true` by the API; if `metadata` is set but that default value is not
               included, the provider will attempt to unset the value. To avoid this, set the
               value in your config.
        :param str min_cpu_platform: Minimum CPU platform to be used by this instance.
               The instance may be scheduled on the specified or newer CPU platform. Applicable
               values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
               [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
               for more information.
        :param str node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        :param Sequence[str] oauth_scopes: The set of Google API scopes to be made available
               on all of the node VMs under the "default" service account.
               Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        :param bool preemptible: A boolean that represents whether or not the underlying node VMs
               are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
               for more information. Defaults to false.
        :param 'ClusterNodePoolNodeConfigReservationAffinityArgs' reservation_affinity: The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        :param Mapping[str, str] resource_labels: The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
               for how these labels are applied to clusters, node pools and nodes.
        :param Mapping[str, str] resource_manager_tags: A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        :param 'ClusterNodePoolNodeConfigSandboxConfigArgs' sandbox_config: Sandbox configuration for this node.
        :param Sequence['ClusterNodePoolNodeConfigSecondaryBootDiskArgs'] secondary_boot_disks: Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        :param str service_account: The service account to be used by the Node VMs.
               If not specified, the "default" service account is used.
        :param 'ClusterNodePoolNodeConfigShieldedInstanceConfigArgs' shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigSoleTenantConfigArgs' sole_tenant_config: Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
        :param bool spot: A boolean that represents whether the underlying node VMs are spot.
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
               for more information. Defaults to false.
        :param Sequence[str] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param Sequence[str] tags: The list of instance tags applied to all nodes. Tags are used to identify
               valid sources or targets for network firewalls.
        :param Sequence['ClusterNodePoolNodeConfigTaintArgs'] taints: A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
               to apply to nodes. GKE's API can only set this field on cluster creation.
               However, GKE will add taints to your nodes if you enable certain features such
               as GPUs. If this field is set, any diffs on this field will cause the provider to
               recreate the underlying resource. Taint values can be updated safely in
               Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
               this field to manage taints. If you do, `lifecycle.ignore_changes` is
               recommended. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs' workload_metadata_config: Metadata configuration to expose to workloads on the node pool.
               Structure is documented below.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if containerd_config is not None:
            pulumi.set(__self__, "containerd_config", containerd_config)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if effective_taints is not None:
            pulumi.set(__self__, "effective_taints", effective_taints)
        if enable_confidential_storage is not None:
            pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if resource_manager_tags is not None:
            pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if secondary_boot_disks is not None:
            pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if storage_pools is not None:
            pulumi.set(__self__, "storage_pools", storage_pools)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional['outputs.ClusterNodePoolNodeConfigAdvancedMachineFeatures']:
        """
        Specifies options for controlling
        advanced machine features. Structure is documented below.
        """
        return pulumi.get(self, "advanced_machine_features")

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[str]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional['outputs.ClusterNodePoolNodeConfigConfidentialNodes']:
        """
        Configuration for Confidential Nodes feature. Structure is documented below.
        """
        return pulumi.get(self, "confidential_nodes")

    @property
    @pulumi.getter(name="containerdConfig")
    def containerd_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigContainerdConfig']:
        """
        Parameters to customize containerd runtime. Structure is documented below.
        """
        return pulumi.get(self, "containerd_config")

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[int]:
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[str]:
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        """
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Optional[Sequence['outputs.ClusterNodePoolNodeConfigEffectiveTaint']]:
        """
        List of kubernetes taints applied to each node. Structure is documented above.
        """
        return pulumi.get(self, "effective_taints")

    @property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> Optional[bool]:
        """
        Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigEphemeralStorageConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional['outputs.ClusterNodePoolNodeConfigFastSocket']:
        """
        Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
        Node Pool must enable gvnic.
        GKE version 1.25.2-gke.1700 or later.
        Structure is documented below.
        """
        return pulumi.get(self, "fast_socket")

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigGcfsConfig']:
        """
        Parameters for the Google Container Filesystem (GCFS).
        If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
        For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
        A `machine_type` that has more than 16 GiB of memory is also recommended.
        GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
        Structure is documented below.
        """
        return pulumi.get(self, "gcfs_config")

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[Sequence['outputs.ClusterNodePoolNodeConfigGuestAccelerator']]:
        """
        List of the type and count of accelerator cards attached to the instance.
        Structure documented below.
        """
        return pulumi.get(self, "guest_accelerators")

    @property
    @pulumi.getter
    def gvnic(self) -> Optional['outputs.ClusterNodePoolNodeConfigGvnic']:
        """
        Google Virtual NIC (gVNIC) is a virtual network interface.
        Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
        gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
        GKE node version 1.15.11-gke.15 or later
        Structure is documented below.
        """
        return pulumi.get(self, "gvnic")

    @property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional['outputs.ClusterNodePoolNodeConfigHostMaintenancePolicy']:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policy")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[str]:
        """
        The image type to use for this node. Note that changing the image type
        will delete and recreate all nodes in the node pool.
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigKubeletConfig']:
        """
        Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Structure is documented below.

        ```
        kubelet_config {
        cpu_manager_policy   = "static"
        cpu_cfs_quota        = true
        cpu_cfs_quota_period = "100us"
        pod_pids_limit       = 1024
        }
        ```
        """
        return pulumi.get(self, "kubelet_config")

    @property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, str]]:
        """
        The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
        reserved by Kubernetes Core components and cannot be specified.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigLinuxNodeConfig']:
        """
        Parameters that can be configured on Linux nodes. Structure is documented below.
        """
        return pulumi.get(self, "linux_node_config")

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig']:
        """
        Parameters for the local NVMe SSDs. Structure is documented below.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        """
        The amount of local SSD disks that will be
        attached to each cluster node. Defaults to 0.
        """
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[str]:
        """
        Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[str]:
        """
        The name of a Google Compute Engine machine type.
        Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
        [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        """
        return pulumi.get(self, "machine_type")

    @property
    @pulumi.getter
    def metadata(self) -> Optional[Mapping[str, str]]:
        """
        The metadata key/value pairs assigned to instances in
        the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
        `true` by the API; if `metadata` is set but that default value is not
        included, the provider will attempt to unset the value. To avoid this, set the
        value in your config.
        """
        return pulumi.get(self, "metadata")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[str]:
        """
        Minimum CPU platform to be used by this instance.
        The instance may be scheduled on the specified or newer CPU platform. Applicable
        values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
        [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
        for more information.
        """
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[str]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        """
        return pulumi.get(self, "node_group")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[Sequence[str]]:
        """
        The set of Google API scopes to be made available
        on all of the node VMs under the "default" service account.
        Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        """
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter
    def preemptible(self) -> Optional[bool]:
        """
        A boolean that represents whether or not the underlying node VMs
        are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "preemptible")

    @property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional['outputs.ClusterNodePoolNodeConfigReservationAffinity']:
        """
        The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        """
        return pulumi.get(self, "reservation_affinity")

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[Mapping[str, str]]:
        """
        The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
        for how these labels are applied to clusters, node pools and nodes.
        """
        return pulumi.get(self, "resource_labels")

    @property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Optional[Mapping[str, str]]:
        """
        A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        return pulumi.get(self, "resource_manager_tags")

    @property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigSandboxConfig']:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_config")

    @property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Optional[Sequence['outputs.ClusterNodePoolNodeConfigSecondaryBootDisk']]:
        """
        Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[str]:
        """
        The service account to be used by the Node VMs.
        If not specified, the "default" service account is used.
        """
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigShieldedInstanceConfig']:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigSoleTenantConfig']:
        """
        Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
        """
        return pulumi.get(self, "sole_tenant_config")

    @property
    @pulumi.getter
    def spot(self) -> Optional[bool]:
        """
        A boolean that represents whether the underlying node VMs are spot.
        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "spot")

    @property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Optional[Sequence[str]]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Sequence[str]]:
        """
        The list of instance tags applied to all nodes. Tags are used to identify
        valid sources or targets for network firewalls.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def taints(self) -> Optional[Sequence['outputs.ClusterNodePoolNodeConfigTaint']]:
        """
        A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
        to apply to nodes. GKE's API can only set this field on cluster creation.
        However, GKE will add taints to your nodes if you enable certain features such
        as GPUs. If this field is set, any diffs on this field will cause the provider to
        recreate the underlying resource. Taint values can be updated safely in
        Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
        this field to manage taints. If you do, `lifecycle.ignore_changes` is
        recommended. Structure is documented below.
        """
        return pulumi.get(self, "taints")

    @property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigWorkloadMetadataConfig']:
        """
        Metadata configuration to expose to workloads on the node pool.
        Structure is documented below.
        """
        return pulumi.get(self, "workload_metadata_config")


@pulumi.output_type
class ClusterNodePoolNodeConfigAdvancedMachineFeatures(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "threadsPerCore":
            suggest = "threads_per_core"
        elif key == "enableNestedVirtualization":
            suggest = "enable_nested_virtualization"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigAdvancedMachineFeatures. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 threads_per_core: int,
                 enable_nested_virtualization: Optional[bool] = None):
        """
        :param int threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        :param bool enable_nested_virtualization: Defines whether the instance should have nested virtualization enabled. Defaults to false.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)
        if enable_nested_virtualization is not None:
            pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> int:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")

    @property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> Optional[bool]:
        """
        Defines whether the instance should have nested virtualization enabled. Defaults to false.
        """
        return pulumi.get(self, "enable_nested_virtualization")


@pulumi.output_type
class ClusterNodePoolNodeConfigConfidentialNodes(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigContainerdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateRegistryAccessConfig":
            suggest = "private_registry_access_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigContainerdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigContainerdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigContainerdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 private_registry_access_config: Optional['outputs.ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig'] = None):
        """
        :param 'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs' private_registry_access_config: Configuration for private container registries. There are two fields in this config:
        """
        if private_registry_access_config is not None:
            pulumi.set(__self__, "private_registry_access_config", private_registry_access_config)

    @property
    @pulumi.getter(name="privateRegistryAccessConfig")
    def private_registry_access_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig']:
        """
        Configuration for private container registries. There are two fields in this config:
        """
        return pulumi.get(self, "private_registry_access_config")


@pulumi.output_type
class ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "certificateAuthorityDomainConfigs":
            suggest = "certificate_authority_domain_configs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: bool,
                 certificate_authority_domain_configs: Optional[Sequence['outputs.ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']] = None):
        """
        :param bool enabled: Enables private registry config. If set to false, all other fields in this object must not be set.
        :param Sequence['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example: 
        """
        pulumi.set(__self__, "enabled", enabled)
        if certificate_authority_domain_configs is not None:
            pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enables private registry config. If set to false, all other fields in this object must not be set.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Optional[Sequence['outputs.ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']]:
        """
        List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example: 
        """
        return pulumi.get(self, "certificate_authority_domain_configs")


@pulumi.output_type
class ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gcpSecretManagerCertificateConfig":
            suggest = "gcp_secret_manager_certificate_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 fqdns: Sequence[str],
                 gcp_secret_manager_certificate_config: 'outputs.ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig'):
        """
        :param Sequence[str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param 'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs' gcp_secret_manager_certificate_config: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_config", gcp_secret_manager_certificate_config)

    @property
    @pulumi.getter
    def fqdns(self) -> Sequence[str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @property
    @pulumi.getter(name="gcpSecretManagerCertificateConfig")
    def gcp_secret_manager_certificate_config(self) -> 'outputs.ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig':
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_config")


@pulumi.output_type
class ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretUri":
            suggest = "secret_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_uri: str):
        """
        :param str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class ClusterNodePoolNodeConfigEffectiveTaint(dict):
    def __init__(__self__, *,
                 effect: Optional[str] = None,
                 key: Optional[str] = None,
                 value: Optional[str] = None):
        """
        :param str effect: Effect for taint.
        :param str key: Key for taint.
        :param str value: Value for taint.
        """
        if effect is not None:
            pulumi.set(__self__, "effect", effect)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> Optional[str]:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class ClusterNodePoolNodeConfigEphemeralStorageConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigEphemeralStorageConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodePoolNodeConfigFastSocket(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigGcfsConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigGuestAccelerator(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverInstallationConfig":
            suggest = "gpu_driver_installation_config"
        elif key == "gpuPartitionSize":
            suggest = "gpu_partition_size"
        elif key == "gpuSharingConfig":
            suggest = "gpu_sharing_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigGuestAccelerator. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigGuestAccelerator.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigGuestAccelerator.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 count: int,
                 type: str,
                 gpu_driver_installation_config: Optional['outputs.ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig'] = None,
                 gpu_partition_size: Optional[str] = None,
                 gpu_sharing_config: Optional['outputs.ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig'] = None):
        """
        :param int count: The number of the guest accelerator cards exposed to this instance.
        :param str type: The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        :param 'ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs' gpu_driver_installation_config: Configuration for auto installation of GPU driver. Structure is documented below.
        :param str gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        :param 'ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs' gpu_sharing_config: Configuration for GPU sharing. Structure is documented below.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @property
    @pulumi.getter
    def count(self) -> int:
        """
        The number of the guest accelerator cards exposed to this instance.
        """
        return pulumi.get(self, "count")

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        """
        return pulumi.get(self, "type")

    @property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig']:
        """
        Configuration for auto installation of GPU driver. Structure is documented below.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[str]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        """
        return pulumi.get(self, "gpu_partition_size")

    @property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig']:
        """
        Configuration for GPU sharing. Structure is documented below.
        """
        return pulumi.get(self, "gpu_sharing_config")


@pulumi.output_type
class ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverVersion":
            suggest = "gpu_driver_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_driver_version: str):
        """
        :param str gpu_driver_version: Mode for how the GPU driver is installed.
               Accepted values are:
               * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to not install any GPU driver.
               * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
               * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
               * `"LATEST"`: "Latest" GPU driver in COS.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> str:
        """
        Mode for how the GPU driver is installed.
        Accepted values are:
        * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to not install any GPU driver.
        * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
        * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
        * `"LATEST"`: "Latest" GPU driver in COS.
        """
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuSharingStrategy":
            suggest = "gpu_sharing_strategy"
        elif key == "maxSharedClientsPerGpu":
            suggest = "max_shared_clients_per_gpu"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_sharing_strategy: str,
                 max_shared_clients_per_gpu: int):
        """
        :param str gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node.
               Accepted values are:
               * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
               * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        :param int max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> str:
        """
        The type of GPU sharing strategy to enable on the GPU node.
        Accepted values are:
        * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> int:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class ClusterNodePoolNodeConfigGvnic(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigHostMaintenancePolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maintenanceInterval":
            suggest = "maintenance_interval"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigHostMaintenancePolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 maintenance_interval: str):
        """
        :param str maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> str:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class ClusterNodePoolNodeConfigKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cpuCfsQuota":
            suggest = "cpu_cfs_quota"
        elif key == "cpuCfsQuotaPeriod":
            suggest = "cpu_cfs_quota_period"
        elif key == "cpuManagerPolicy":
            suggest = "cpu_manager_policy"
        elif key == "insecureKubeletReadonlyPortEnabled":
            suggest = "insecure_kubelet_readonly_port_enabled"
        elif key == "podPidsLimit":
            suggest = "pod_pids_limit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cpu_cfs_quota: Optional[bool] = None,
                 cpu_cfs_quota_period: Optional[str] = None,
                 cpu_manager_policy: Optional[str] = None,
                 insecure_kubelet_readonly_port_enabled: Optional[str] = None,
                 pod_pids_limit: Optional[int] = None):
        """
        :param bool cpu_cfs_quota: If true, enables CPU CFS quota enforcement for
               containers that specify CPU limits.
        :param str cpu_cfs_quota_period: The CPU CFS quota period value. Specified
               as a sequence of decimal numbers, each with optional fraction and a unit suffix,
               such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
               "h". The value must be a positive duration.
        :param str cpu_manager_policy: The CPU management policy on the node. See
               [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
               One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
               Prior to the 6.4.0 this field was marked as required. The workaround for the required field
               is setting the empty string `""`, which will function identically to not setting this field.
        :param str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param int pod_pids_limit: Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if cpu_manager_policy is not None:
            pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[bool]:
        """
        If true, enables CPU CFS quota enforcement for
        containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[str]:
        """
        The CPU CFS quota period value. Specified
        as a sequence of decimal numbers, each with optional fraction and a unit suffix,
        such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
        "h". The value must be a positive duration.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> Optional[str]:
        """
        The CPU management policy on the node. See
        [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
        One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
        Prior to the 6.4.0 this field was marked as required. The workaround for the required field
        is setting the empty string `""`, which will function identically to not setting this field.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[str]:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[int]:
        """
        Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        return pulumi.get(self, "pod_pids_limit")


@pulumi.output_type
class ClusterNodePoolNodeConfigLinuxNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cgroupMode":
            suggest = "cgroup_mode"
        elif key == "hugepagesConfig":
            suggest = "hugepages_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigLinuxNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigLinuxNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigLinuxNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cgroup_mode: Optional[str] = None,
                 hugepages_config: Optional['outputs.ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig'] = None,
                 sysctls: Optional[Mapping[str, str]] = None):
        """
        :param str cgroup_mode: Possible cgroup modes that can be used.
               Accepted values are:
               * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
               * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
               * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        :param 'ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs' hugepages_config: Amounts for 2M and 1G hugepages. Structure is documented below.
        :param Mapping[str, str] sysctls: The Linux kernel parameters to be applied to the nodes
               and all pods running on the nodes. Specified as a map from the key, such as
               `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Note that validations happen all server side. All attributes are optional.
        """
        if cgroup_mode is not None:
            pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        if hugepages_config is not None:
            pulumi.set(__self__, "hugepages_config", hugepages_config)
        if sysctls is not None:
            pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> Optional[str]:
        """
        Possible cgroup modes that can be used.
        Accepted values are:
        * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
        * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
        * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        """
        return pulumi.get(self, "cgroup_mode")

    @property
    @pulumi.getter(name="hugepagesConfig")
    def hugepages_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig']:
        """
        Amounts for 2M and 1G hugepages. Structure is documented below.
        """
        return pulumi.get(self, "hugepages_config")

    @property
    @pulumi.getter
    def sysctls(self) -> Optional[Mapping[str, str]]:
        """
        The Linux kernel parameters to be applied to the nodes
        and all pods running on the nodes. Specified as a map from the key, such as
        `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Note that validations happen all server side. All attributes are optional.
        """
        return pulumi.get(self, "sysctls")


@pulumi.output_type
class ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "hugepageSize1g":
            suggest = "hugepage_size1g"
        elif key == "hugepageSize2m":
            suggest = "hugepage_size2m"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 hugepage_size1g: Optional[int] = None,
                 hugepage_size2m: Optional[int] = None):
        """
        :param int hugepage_size1g: Amount of 1G hugepages.
        :param int hugepage_size2m: Amount of 2M hugepages.
        """
        if hugepage_size1g is not None:
            pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        if hugepage_size2m is not None:
            pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> Optional[int]:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> Optional[int]:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")


@pulumi.output_type
class ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
               > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
        > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodePoolNodeConfigReservationAffinity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "consumeReservationType":
            suggest = "consume_reservation_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigReservationAffinity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigReservationAffinity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigReservationAffinity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 consume_reservation_type: str,
                 key: Optional[str] = None,
                 values: Optional[Sequence[str]] = None):
        """
        :param str consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param str key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param Sequence[str] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> str:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def values(self) -> Optional[Sequence[str]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ClusterNodePoolNodeConfigSandboxConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sandboxType":
            suggest = "sandbox_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigSandboxConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigSandboxConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigSandboxConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 sandbox_type: str):
        """
        :param str sandbox_type: Which sandbox to use for pods in the node pool.
               Accepted values are:
               
               * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> str:
        """
        Which sandbox to use for pods in the node pool.
        Accepted values are:

        * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class ClusterNodePoolNodeConfigSecondaryBootDisk(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "diskImage":
            suggest = "disk_image"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigSecondaryBootDisk. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigSecondaryBootDisk.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigSecondaryBootDisk.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disk_image: str,
                 mode: Optional[str] = None):
        """
        :param str disk_image: Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        :param str mode: Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        if mode is not None:
            pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> str:
        """
        Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        """
        return pulumi.get(self, "disk_image")

    @property
    @pulumi.getter
    def mode(self) -> Optional[str]:
        """
        Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class ClusterNodePoolNodeConfigShieldedInstanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableIntegrityMonitoring":
            suggest = "enable_integrity_monitoring"
        elif key == "enableSecureBoot":
            suggest = "enable_secure_boot"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigShieldedInstanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[bool] = None,
                 enable_secure_boot: Optional[bool] = None):
        """
        :param bool enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param bool enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[bool]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[bool]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class ClusterNodePoolNodeConfigSoleTenantConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodeAffinities":
            suggest = "node_affinities"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigSoleTenantConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigSoleTenantConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigSoleTenantConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinity']):
        """
        :param Sequence['ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs'] node_affinities: .
        """
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinity']:
        """
        .
        """
        return pulumi.get(self, "node_affinities")


@pulumi.output_type
class ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinity(dict):
    def __init__(__self__, *,
                 key: str,
                 operator: str,
                 values: Sequence[str]):
        """
        :param str key: The default or custom node affinity label key name.
        :param str operator: Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        :param Sequence[str] values: List of node affinity label values as strings.
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        The default or custom node affinity label key name.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def operator(self) -> str:
        """
        Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        """
        return pulumi.get(self, "operator")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        """
        List of node affinity label values as strings.
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ClusterNodePoolNodeConfigTaint(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        """
        :param str effect: Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        :param str key: Key for taint.
        :param str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        """
        Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class ClusterNodePoolNodeConfigWorkloadMetadataConfig(dict):
    def __init__(__self__, *,
                 mode: str):
        """
        :param str mode: How to expose the node metadata to the workload running on the node.
               Accepted values are:
               * UNSPECIFIED: Not Set
               * GCE_METADATA: Expose all Compute Engine metadata to pods.
               * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> str:
        """
        How to expose the node metadata to the workload running on the node.
        Accepted values are:
        * UNSPECIFIED: Not Set
        * GCE_METADATA: Expose all Compute Engine metadata to pods.
        * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class ClusterNodePoolPlacementPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "policyName":
            suggest = "policy_name"
        elif key == "tpuTopology":
            suggest = "tpu_topology"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolPlacementPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolPlacementPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolPlacementPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 type: str,
                 policy_name: Optional[str] = None,
                 tpu_topology: Optional[str] = None):
        """
        :param str type: Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
               `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        :param str policy_name: If set, refers to the name of a custom resource policy supplied by the user. The resource policy must be in the same project and region as the node pool. If not found, InvalidArgument error is returned.
        :param str tpu_topology: TPU placement topology for pod slice node pool. https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies
        """
        pulumi.set(__self__, "type", type)
        if policy_name is not None:
            pulumi.set(__self__, "policy_name", policy_name)
        if tpu_topology is not None:
            pulumi.set(__self__, "tpu_topology", tpu_topology)

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
        `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        return pulumi.get(self, "type")

    @property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> Optional[str]:
        """
        If set, refers to the name of a custom resource policy supplied by the user. The resource policy must be in the same project and region as the node pool. If not found, InvalidArgument error is returned.
        """
        return pulumi.get(self, "policy_name")

    @property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> Optional[str]:
        """
        TPU placement topology for pod slice node pool. https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies
        """
        return pulumi.get(self, "tpu_topology")


@pulumi.output_type
class ClusterNodePoolQueuedProvisioning(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether nodes in this node pool are obtainable solely through the ProvisioningRequest API
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether nodes in this node pool are obtainable solely through the ProvisioningRequest API
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolUpgradeSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "blueGreenSettings":
            suggest = "blue_green_settings"
        elif key == "maxSurge":
            suggest = "max_surge"
        elif key == "maxUnavailable":
            suggest = "max_unavailable"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolUpgradeSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolUpgradeSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolUpgradeSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 blue_green_settings: Optional['outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettings'] = None,
                 max_surge: Optional[int] = None,
                 max_unavailable: Optional[int] = None,
                 strategy: Optional[str] = None):
        """
        :param 'ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs' blue_green_settings: Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param int max_surge: The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param int max_unavailable: The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param str strategy: Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional['outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettings']:
        """
        Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "blue_green_settings")

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[int]:
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_surge")

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[int]:
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_unavailable")

    @property
    @pulumi.getter
    def strategy(self) -> Optional[str]:
        """
        Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class ClusterNodePoolUpgradeSettingsBlueGreenSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "standardRolloutPolicy":
            suggest = "standard_rollout_policy"
        elif key == "nodePoolSoakDuration":
            suggest = "node_pool_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolUpgradeSettingsBlueGreenSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 standard_rollout_policy: 'outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
                 node_pool_soak_duration: Optional[str] = None):
        """
        :param 'ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs' standard_rollout_policy: Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param str node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)

    @property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> 'outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy':
        """
        Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "standard_rollout_policy")

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[str]:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "node_pool_soak_duration")


@pulumi.output_type
class ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "batchNodeCount":
            suggest = "batch_node_count"
        elif key == "batchPercentage":
            suggest = "batch_percentage"
        elif key == "batchSoakDuration":
            suggest = "batch_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 batch_node_count: Optional[int] = None,
                 batch_percentage: Optional[float] = None,
                 batch_soak_duration: Optional[str] = None):
        """
        :param int batch_node_count: Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        :param float batch_percentage: Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        :param str batch_soak_duration: Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[int]:
        """
        Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_node_count")

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[float]:
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_percentage")

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[str]:
        """
        Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class ClusterNotificationConfig(dict):
    def __init__(__self__, *,
                 pubsub: 'outputs.ClusterNotificationConfigPubsub'):
        """
        :param 'ClusterNotificationConfigPubsubArgs' pubsub: The pubsub config for the cluster's upgrade notifications.
        """
        pulumi.set(__self__, "pubsub", pubsub)

    @property
    @pulumi.getter
    def pubsub(self) -> 'outputs.ClusterNotificationConfigPubsub':
        """
        The pubsub config for the cluster's upgrade notifications.
        """
        return pulumi.get(self, "pubsub")


@pulumi.output_type
class ClusterNotificationConfigPubsub(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 filter: Optional['outputs.ClusterNotificationConfigPubsubFilter'] = None,
                 topic: Optional[str] = None):
        """
        :param bool enabled: Whether or not the notification config is enabled
        :param 'ClusterNotificationConfigPubsubFilterArgs' filter: Choose what type of notifications you want to receive. If no filters are applied, you'll receive all notification types. Structure is documented below.
        :param str topic: The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: `projects/{project}/topics/{topic}`.
        """
        pulumi.set(__self__, "enabled", enabled)
        if filter is not None:
            pulumi.set(__self__, "filter", filter)
        if topic is not None:
            pulumi.set(__self__, "topic", topic)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the notification config is enabled
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter
    def filter(self) -> Optional['outputs.ClusterNotificationConfigPubsubFilter']:
        """
        Choose what type of notifications you want to receive. If no filters are applied, you'll receive all notification types. Structure is documented below.
        """
        return pulumi.get(self, "filter")

    @property
    @pulumi.getter
    def topic(self) -> Optional[str]:
        """
        The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: `projects/{project}/topics/{topic}`.
        """
        return pulumi.get(self, "topic")


@pulumi.output_type
class ClusterNotificationConfigPubsubFilter(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "eventTypes":
            suggest = "event_types"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNotificationConfigPubsubFilter. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNotificationConfigPubsubFilter.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNotificationConfigPubsubFilter.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 event_types: Sequence[str]):
        """
        :param Sequence[str] event_types: Can be used to filter what notifications are sent. Accepted values are `UPGRADE_AVAILABLE_EVENT`, `UPGRADE_EVENT` and `SECURITY_BULLETIN_EVENT`. See [Filtering notifications](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-notifications#filtering) for more details.
        """
        pulumi.set(__self__, "event_types", event_types)

    @property
    @pulumi.getter(name="eventTypes")
    def event_types(self) -> Sequence[str]:
        """
        Can be used to filter what notifications are sent. Accepted values are `UPGRADE_AVAILABLE_EVENT`, `UPGRADE_EVENT` and `SECURITY_BULLETIN_EVENT`. See [Filtering notifications](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-notifications#filtering) for more details.
        """
        return pulumi.get(self, "event_types")


@pulumi.output_type
class ClusterPodSecurityPolicyConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable the PodSecurityPolicy controller for this cluster.
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable the PodSecurityPolicy controller for this cluster.
        If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterPrivateClusterConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enablePrivateEndpoint":
            suggest = "enable_private_endpoint"
        elif key == "enablePrivateNodes":
            suggest = "enable_private_nodes"
        elif key == "masterGlobalAccessConfig":
            suggest = "master_global_access_config"
        elif key == "masterIpv4CidrBlock":
            suggest = "master_ipv4_cidr_block"
        elif key == "peeringName":
            suggest = "peering_name"
        elif key == "privateEndpoint":
            suggest = "private_endpoint"
        elif key == "privateEndpointSubnetwork":
            suggest = "private_endpoint_subnetwork"
        elif key == "publicEndpoint":
            suggest = "public_endpoint"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterPrivateClusterConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterPrivateClusterConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterPrivateClusterConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_private_endpoint: Optional[bool] = None,
                 enable_private_nodes: Optional[bool] = None,
                 master_global_access_config: Optional['outputs.ClusterPrivateClusterConfigMasterGlobalAccessConfig'] = None,
                 master_ipv4_cidr_block: Optional[str] = None,
                 peering_name: Optional[str] = None,
                 private_endpoint: Optional[str] = None,
                 private_endpoint_subnetwork: Optional[str] = None,
                 public_endpoint: Optional[str] = None):
        """
        :param bool enable_private_endpoint: When `true`, the cluster's private
               endpoint is used as the cluster endpoint and access through the public endpoint
               is disabled. When `false`, either endpoint can be used. This field only applies
               to private clusters, when `enable_private_nodes` is `true`.
        :param bool enable_private_nodes: Enables the private cluster feature,
               creating a private endpoint on the cluster. In a private cluster, nodes only
               have RFC 1918 private addresses and communicate with the master's private
               endpoint via private networking.
        :param 'ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs' master_global_access_config: Controls cluster master global
               access settings. If unset, the provider will no longer manage this field and will
               not modify the previously-set value. Structure is documented below.
        :param str master_ipv4_cidr_block: The IP range in CIDR notation to use for
               the hosted master network. This range will be used for assigning private IP
               addresses to the cluster master(s) and the ILB VIP. This range must not overlap
               with any other ranges in use within the cluster's network, and it must be a /28
               subnet. See [Private Cluster Limitations](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#req_res_lim)
               for more details. This field only applies to private clusters, when
               `enable_private_nodes` is `true`.
        :param str peering_name: The name of the peering between this cluster and the Google owned VPC.
        :param str private_endpoint: The internal IP address of this cluster's master endpoint.
        :param str private_endpoint_subnetwork: Subnetwork in cluster's network where master's endpoint will be provisioned.
        :param str public_endpoint: The external IP address of this cluster's master endpoint.
               
               !> The Google provider is unable to validate certain configurations of
               `private_cluster_config` when `enable_private_nodes` is `false`. It's
               recommended that you omit the block entirely if the field is not set to `true`.
        """
        if enable_private_endpoint is not None:
            pulumi.set(__self__, "enable_private_endpoint", enable_private_endpoint)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if master_global_access_config is not None:
            pulumi.set(__self__, "master_global_access_config", master_global_access_config)
        if master_ipv4_cidr_block is not None:
            pulumi.set(__self__, "master_ipv4_cidr_block", master_ipv4_cidr_block)
        if peering_name is not None:
            pulumi.set(__self__, "peering_name", peering_name)
        if private_endpoint is not None:
            pulumi.set(__self__, "private_endpoint", private_endpoint)
        if private_endpoint_subnetwork is not None:
            pulumi.set(__self__, "private_endpoint_subnetwork", private_endpoint_subnetwork)
        if public_endpoint is not None:
            pulumi.set(__self__, "public_endpoint", public_endpoint)

    @property
    @pulumi.getter(name="enablePrivateEndpoint")
    def enable_private_endpoint(self) -> Optional[bool]:
        """
        When `true`, the cluster's private
        endpoint is used as the cluster endpoint and access through the public endpoint
        is disabled. When `false`, either endpoint can be used. This field only applies
        to private clusters, when `enable_private_nodes` is `true`.
        """
        return pulumi.get(self, "enable_private_endpoint")

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[bool]:
        """
        Enables the private cluster feature,
        creating a private endpoint on the cluster. In a private cluster, nodes only
        have RFC 1918 private addresses and communicate with the master's private
        endpoint via private networking.
        """
        return pulumi.get(self, "enable_private_nodes")

    @property
    @pulumi.getter(name="masterGlobalAccessConfig")
    def master_global_access_config(self) -> Optional['outputs.ClusterPrivateClusterConfigMasterGlobalAccessConfig']:
        """
        Controls cluster master global
        access settings. If unset, the provider will no longer manage this field and will
        not modify the previously-set value. Structure is documented below.
        """
        return pulumi.get(self, "master_global_access_config")

    @property
    @pulumi.getter(name="masterIpv4CidrBlock")
    def master_ipv4_cidr_block(self) -> Optional[str]:
        """
        The IP range in CIDR notation to use for
        the hosted master network. This range will be used for assigning private IP
        addresses to the cluster master(s) and the ILB VIP. This range must not overlap
        with any other ranges in use within the cluster's network, and it must be a /28
        subnet. See [Private Cluster Limitations](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#req_res_lim)
        for more details. This field only applies to private clusters, when
        `enable_private_nodes` is `true`.
        """
        return pulumi.get(self, "master_ipv4_cidr_block")

    @property
    @pulumi.getter(name="peeringName")
    def peering_name(self) -> Optional[str]:
        """
        The name of the peering between this cluster and the Google owned VPC.
        """
        return pulumi.get(self, "peering_name")

    @property
    @pulumi.getter(name="privateEndpoint")
    def private_endpoint(self) -> Optional[str]:
        """
        The internal IP address of this cluster's master endpoint.
        """
        return pulumi.get(self, "private_endpoint")

    @property
    @pulumi.getter(name="privateEndpointSubnetwork")
    def private_endpoint_subnetwork(self) -> Optional[str]:
        """
        Subnetwork in cluster's network where master's endpoint will be provisioned.
        """
        return pulumi.get(self, "private_endpoint_subnetwork")

    @property
    @pulumi.getter(name="publicEndpoint")
    def public_endpoint(self) -> Optional[str]:
        """
        The external IP address of this cluster's master endpoint.

        !> The Google provider is unable to validate certain configurations of
        `private_cluster_config` when `enable_private_nodes` is `false`. It's
        recommended that you omit the block entirely if the field is not set to `true`.
        """
        return pulumi.get(self, "public_endpoint")


@pulumi.output_type
class ClusterPrivateClusterConfigMasterGlobalAccessConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether the cluster master is accessible globally or
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether the cluster master is accessible globally or
        not.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterProtectConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "workloadConfig":
            suggest = "workload_config"
        elif key == "workloadVulnerabilityMode":
            suggest = "workload_vulnerability_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterProtectConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterProtectConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterProtectConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 workload_config: Optional['outputs.ClusterProtectConfigWorkloadConfig'] = None,
                 workload_vulnerability_mode: Optional[str] = None):
        """
        :param 'ClusterProtectConfigWorkloadConfigArgs' workload_config: WorkloadConfig defines which actions are enabled for a cluster's workload configurations. Structure is documented below
        :param str workload_vulnerability_mode: Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        if workload_config is not None:
            pulumi.set(__self__, "workload_config", workload_config)
        if workload_vulnerability_mode is not None:
            pulumi.set(__self__, "workload_vulnerability_mode", workload_vulnerability_mode)

    @property
    @pulumi.getter(name="workloadConfig")
    def workload_config(self) -> Optional['outputs.ClusterProtectConfigWorkloadConfig']:
        """
        WorkloadConfig defines which actions are enabled for a cluster's workload configurations. Structure is documented below
        """
        return pulumi.get(self, "workload_config")

    @property
    @pulumi.getter(name="workloadVulnerabilityMode")
    def workload_vulnerability_mode(self) -> Optional[str]:
        """
        Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "workload_vulnerability_mode")


@pulumi.output_type
class ClusterProtectConfigWorkloadConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "auditMode":
            suggest = "audit_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterProtectConfigWorkloadConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterProtectConfigWorkloadConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterProtectConfigWorkloadConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 audit_mode: str):
        """
        :param str audit_mode: Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        pulumi.set(__self__, "audit_mode", audit_mode)

    @property
    @pulumi.getter(name="auditMode")
    def audit_mode(self) -> str:
        """
        Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "audit_mode")


@pulumi.output_type
class ClusterReleaseChannel(dict):
    def __init__(__self__, *,
                 channel: str):
        """
        :param str channel: The selected release channel.
               Accepted values are:
               * UNSPECIFIED: Not set.
               * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
               * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
               * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
               * EXTENDED: GKE provides extended support for Kubernetes minor versions through the Extended channel. With this channel, you can stay on a minor version for up to 24 months.
        """
        pulumi.set(__self__, "channel", channel)

    @property
    @pulumi.getter
    def channel(self) -> str:
        """
        The selected release channel.
        Accepted values are:
        * UNSPECIFIED: Not set.
        * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
        * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
        * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
        * EXTENDED: GKE provides extended support for Kubernetes minor versions through the Extended channel. With this channel, you can stay on a minor version for up to 24 months.
        """
        return pulumi.get(self, "channel")


@pulumi.output_type
class ClusterResourceUsageExportConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bigqueryDestination":
            suggest = "bigquery_destination"
        elif key == "enableNetworkEgressMetering":
            suggest = "enable_network_egress_metering"
        elif key == "enableResourceConsumptionMetering":
            suggest = "enable_resource_consumption_metering"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterResourceUsageExportConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterResourceUsageExportConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterResourceUsageExportConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 bigquery_destination: 'outputs.ClusterResourceUsageExportConfigBigqueryDestination',
                 enable_network_egress_metering: Optional[bool] = None,
                 enable_resource_consumption_metering: Optional[bool] = None):
        """
        :param 'ClusterResourceUsageExportConfigBigqueryDestinationArgs' bigquery_destination: Parameters for using BigQuery as the destination of resource usage export.
               
               * `bigquery_destination.dataset_id` (Required) - The ID of a BigQuery Dataset. For Example:
        :param bool enable_network_egress_metering: Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created
               in the cluster to meter network egress traffic.
        :param bool enable_resource_consumption_metering: Whether to enable resource
               consumption metering on this cluster. When enabled, a table will be created in
               the resource export BigQuery dataset to store resource consumption data. The
               resulting table can be joined with the resource usage table or with BigQuery
               billing export. Defaults to `true`.
        """
        pulumi.set(__self__, "bigquery_destination", bigquery_destination)
        if enable_network_egress_metering is not None:
            pulumi.set(__self__, "enable_network_egress_metering", enable_network_egress_metering)
        if enable_resource_consumption_metering is not None:
            pulumi.set(__self__, "enable_resource_consumption_metering", enable_resource_consumption_metering)

    @property
    @pulumi.getter(name="bigqueryDestination")
    def bigquery_destination(self) -> 'outputs.ClusterResourceUsageExportConfigBigqueryDestination':
        """
        Parameters for using BigQuery as the destination of resource usage export.

        * `bigquery_destination.dataset_id` (Required) - The ID of a BigQuery Dataset. For Example:
        """
        return pulumi.get(self, "bigquery_destination")

    @property
    @pulumi.getter(name="enableNetworkEgressMetering")
    def enable_network_egress_metering(self) -> Optional[bool]:
        """
        Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created
        in the cluster to meter network egress traffic.
        """
        return pulumi.get(self, "enable_network_egress_metering")

    @property
    @pulumi.getter(name="enableResourceConsumptionMetering")
    def enable_resource_consumption_metering(self) -> Optional[bool]:
        """
        Whether to enable resource
        consumption metering on this cluster. When enabled, a table will be created in
        the resource export BigQuery dataset to store resource consumption data. The
        resulting table can be joined with the resource usage table or with BigQuery
        billing export. Defaults to `true`.
        """
        return pulumi.get(self, "enable_resource_consumption_metering")


@pulumi.output_type
class ClusterResourceUsageExportConfigBigqueryDestination(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "datasetId":
            suggest = "dataset_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterResourceUsageExportConfigBigqueryDestination. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterResourceUsageExportConfigBigqueryDestination.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterResourceUsageExportConfigBigqueryDestination.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dataset_id: str):
        """
        :param str dataset_id: The ID of a BigQuery Dataset.
        """
        pulumi.set(__self__, "dataset_id", dataset_id)

    @property
    @pulumi.getter(name="datasetId")
    def dataset_id(self) -> str:
        """
        The ID of a BigQuery Dataset.
        """
        return pulumi.get(self, "dataset_id")


@pulumi.output_type
class ClusterSecretManagerConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable the Secret Manager add-on for this cluster.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable the Secret Manager add-on for this cluster.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterSecurityPostureConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "vulnerabilityMode":
            suggest = "vulnerability_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterSecurityPostureConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterSecurityPostureConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterSecurityPostureConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 mode: Optional[str] = None,
                 vulnerability_mode: Optional[str] = None):
        """
        :param str mode: Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include `DISABLED`, `BASIC`, and `ENTERPRISE`.
        :param str vulnerability_mode: Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include `VULNERABILITY_DISABLED`, `VULNERABILITY_BASIC` and `VULNERABILITY_ENTERPRISE`.
        """
        if mode is not None:
            pulumi.set(__self__, "mode", mode)
        if vulnerability_mode is not None:
            pulumi.set(__self__, "vulnerability_mode", vulnerability_mode)

    @property
    @pulumi.getter
    def mode(self) -> Optional[str]:
        """
        Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include `DISABLED`, `BASIC`, and `ENTERPRISE`.
        """
        return pulumi.get(self, "mode")

    @property
    @pulumi.getter(name="vulnerabilityMode")
    def vulnerability_mode(self) -> Optional[str]:
        """
        Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include `VULNERABILITY_DISABLED`, `VULNERABILITY_BASIC` and `VULNERABILITY_ENTERPRISE`.
        """
        return pulumi.get(self, "vulnerability_mode")


@pulumi.output_type
class ClusterServiceExternalIpsConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Controls whether external ips specified by a service will be allowed. It is enabled by default.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Controls whether external ips specified by a service will be allowed. It is enabled by default.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterTpuConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ipv4CidrBlock":
            suggest = "ipv4_cidr_block"
        elif key == "useServiceNetworking":
            suggest = "use_service_networking"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterTpuConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterTpuConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterTpuConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: bool,
                 ipv4_cidr_block: Optional[str] = None,
                 use_service_networking: Optional[bool] = None):
        """
        :param bool enabled: Whether Cloud TPU integration is enabled or not
        :param str ipv4_cidr_block: IPv4 CIDR block reserved for Cloud TPU in the VPC.
        :param bool use_service_networking: Whether to use service networking for Cloud TPU or not
        """
        pulumi.set(__self__, "enabled", enabled)
        if ipv4_cidr_block is not None:
            pulumi.set(__self__, "ipv4_cidr_block", ipv4_cidr_block)
        if use_service_networking is not None:
            pulumi.set(__self__, "use_service_networking", use_service_networking)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether Cloud TPU integration is enabled or not
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="ipv4CidrBlock")
    def ipv4_cidr_block(self) -> Optional[str]:
        """
        IPv4 CIDR block reserved for Cloud TPU in the VPC.
        """
        return pulumi.get(self, "ipv4_cidr_block")

    @property
    @pulumi.getter(name="useServiceNetworking")
    def use_service_networking(self) -> Optional[bool]:
        """
        Whether to use service networking for Cloud TPU or not
        """
        return pulumi.get(self, "use_service_networking")


@pulumi.output_type
class ClusterVerticalPodAutoscaling(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enables vertical pod autoscaling
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enables vertical pod autoscaling
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterWorkloadAltsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableAlts":
            suggest = "enable_alts"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterWorkloadAltsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterWorkloadAltsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterWorkloadAltsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_alts: bool):
        """
        :param bool enable_alts: Whether the alts handshaker should be enabled or not for direct-path. Requires Workload Identity (workloadPool) must be non-empty).
        """
        pulumi.set(__self__, "enable_alts", enable_alts)

    @property
    @pulumi.getter(name="enableAlts")
    def enable_alts(self) -> bool:
        """
        Whether the alts handshaker should be enabled or not for direct-path. Requires Workload Identity (workloadPool) must be non-empty).
        """
        return pulumi.get(self, "enable_alts")


@pulumi.output_type
class ClusterWorkloadIdentityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "workloadPool":
            suggest = "workload_pool"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterWorkloadIdentityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterWorkloadIdentityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterWorkloadIdentityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 workload_pool: Optional[str] = None):
        """
        :param str workload_pool: The workload pool to attach all Kubernetes service accounts to.
        """
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[str]:
        """
        The workload pool to attach all Kubernetes service accounts to.
        """
        return pulumi.get(self, "workload_pool")


@pulumi.output_type
class NodePoolAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "locationPolicy":
            suggest = "location_policy"
        elif key == "maxNodeCount":
            suggest = "max_node_count"
        elif key == "minNodeCount":
            suggest = "min_node_count"
        elif key == "totalMaxNodeCount":
            suggest = "total_max_node_count"
        elif key == "totalMinNodeCount":
            suggest = "total_min_node_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 location_policy: Optional[str] = None,
                 max_node_count: Optional[int] = None,
                 min_node_count: Optional[int] = None,
                 total_max_node_count: Optional[int] = None,
                 total_min_node_count: Optional[int] = None):
        """
        :param str location_policy: Location policy specifies the algorithm used when
               scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
               * "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones.
               * "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations,
               and reduce preemption risk for Spot VMs.
        :param int max_node_count: Maximum number of nodes per zone in the NodePool.
               Must be >= min_node_count. Cannot be used with total limits.
        :param int min_node_count: Minimum number of nodes per zone in the NodePool.
               Must be >=0 and <= `max_node_count`. Cannot be used with total limits.
        :param int total_max_node_count: Total maximum number of nodes in the NodePool.
               Must be >= total_min_node_count. Cannot be used with per zone limits.
               Total size limits are supported only in 1.24.1+ clusters.
        :param int total_min_node_count: Total minimum number of nodes in the NodePool.
               Must be >=0 and <= `total_max_node_count`. Cannot be used with per zone limits.
               Total size limits are supported only in 1.24.1+ clusters.
        """
        if location_policy is not None:
            pulumi.set(__self__, "location_policy", location_policy)
        if max_node_count is not None:
            pulumi.set(__self__, "max_node_count", max_node_count)
        if min_node_count is not None:
            pulumi.set(__self__, "min_node_count", min_node_count)
        if total_max_node_count is not None:
            pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        if total_min_node_count is not None:
            pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> Optional[str]:
        """
        Location policy specifies the algorithm used when
        scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
        * "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones.
        * "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations,
        and reduce preemption risk for Spot VMs.
        """
        return pulumi.get(self, "location_policy")

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> Optional[int]:
        """
        Maximum number of nodes per zone in the NodePool.
        Must be >= min_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "max_node_count")

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> Optional[int]:
        """
        Minimum number of nodes per zone in the NodePool.
        Must be >=0 and <= `max_node_count`. Cannot be used with total limits.
        """
        return pulumi.get(self, "min_node_count")

    @property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> Optional[int]:
        """
        Total maximum number of nodes in the NodePool.
        Must be >= total_min_node_count. Cannot be used with per zone limits.
        Total size limits are supported only in 1.24.1+ clusters.
        """
        return pulumi.get(self, "total_max_node_count")

    @property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> Optional[int]:
        """
        Total minimum number of nodes in the NodePool.
        Must be >=0 and <= `total_max_node_count`. Cannot be used with per zone limits.
        Total size limits are supported only in 1.24.1+ clusters.
        """
        return pulumi.get(self, "total_min_node_count")


@pulumi.output_type
class NodePoolManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"
        elif key == "autoUpgrade":
            suggest = "auto_upgrade"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[bool] = None,
                 auto_upgrade: Optional[bool] = None):
        """
        :param bool auto_repair: Whether the nodes will be automatically repaired. Enabled by default.
        :param bool auto_upgrade: Whether the nodes will be automatically upgraded. Enabled by default.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[bool]:
        """
        Whether the nodes will be automatically repaired. Enabled by default.
        """
        return pulumi.get(self, "auto_repair")

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[bool]:
        """
        Whether the nodes will be automatically upgraded. Enabled by default.
        """
        return pulumi.get(self, "auto_upgrade")


@pulumi.output_type
class NodePoolNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "additionalNodeNetworkConfigs":
            suggest = "additional_node_network_configs"
        elif key == "additionalPodNetworkConfigs":
            suggest = "additional_pod_network_configs"
        elif key == "createPodRange":
            suggest = "create_pod_range"
        elif key == "enablePrivateNodes":
            suggest = "enable_private_nodes"
        elif key == "networkPerformanceConfig":
            suggest = "network_performance_config"
        elif key == "podCidrOverprovisionConfig":
            suggest = "pod_cidr_overprovision_config"
        elif key == "podIpv4CidrBlock":
            suggest = "pod_ipv4_cidr_block"
        elif key == "podRange":
            suggest = "pod_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 additional_node_network_configs: Optional[Sequence['outputs.NodePoolNetworkConfigAdditionalNodeNetworkConfig']] = None,
                 additional_pod_network_configs: Optional[Sequence['outputs.NodePoolNetworkConfigAdditionalPodNetworkConfig']] = None,
                 create_pod_range: Optional[bool] = None,
                 enable_private_nodes: Optional[bool] = None,
                 network_performance_config: Optional['outputs.NodePoolNetworkConfigNetworkPerformanceConfig'] = None,
                 pod_cidr_overprovision_config: Optional['outputs.NodePoolNetworkConfigPodCidrOverprovisionConfig'] = None,
                 pod_ipv4_cidr_block: Optional[str] = None,
                 pod_range: Optional[str] = None):
        """
        :param Sequence['NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs'] additional_node_network_configs: We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface.
               Structure is documented below
        :param Sequence['NodePoolNetworkConfigAdditionalPodNetworkConfigArgs'] additional_pod_network_configs: We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node.
               Structure is documented below
        :param bool create_pod_range: Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        :param bool enable_private_nodes: Whether nodes have internal IP addresses only.
        :param 'NodePoolNetworkConfigNetworkPerformanceConfigArgs' network_performance_config: Network bandwidth tier configuration. Structure is documented below.
        :param 'NodePoolNetworkConfigPodCidrOverprovisionConfigArgs' pod_cidr_overprovision_config: Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited. Structure is documented below.
        :param str pod_ipv4_cidr_block: The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        :param str pod_range: The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        if additional_node_network_configs is not None:
            pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        if additional_pod_network_configs is not None:
            pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        if create_pod_range is not None:
            pulumi.set(__self__, "create_pod_range", create_pod_range)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if network_performance_config is not None:
            pulumi.set(__self__, "network_performance_config", network_performance_config)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if pod_ipv4_cidr_block is not None:
            pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        if pod_range is not None:
            pulumi.set(__self__, "pod_range", pod_range)

    @property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Optional[Sequence['outputs.NodePoolNetworkConfigAdditionalNodeNetworkConfig']]:
        """
        We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface.
        Structure is documented below
        """
        return pulumi.get(self, "additional_node_network_configs")

    @property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Optional[Sequence['outputs.NodePoolNetworkConfigAdditionalPodNetworkConfig']]:
        """
        We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node.
        Structure is documented below
        """
        return pulumi.get(self, "additional_pod_network_configs")

    @property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> Optional[bool]:
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        """
        return pulumi.get(self, "create_pod_range")

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[bool]:
        """
        Whether nodes have internal IP addresses only.
        """
        return pulumi.get(self, "enable_private_nodes")

    @property
    @pulumi.getter(name="networkPerformanceConfig")
    def network_performance_config(self) -> Optional['outputs.NodePoolNetworkConfigNetworkPerformanceConfig']:
        """
        Network bandwidth tier configuration. Structure is documented below.
        """
        return pulumi.get(self, "network_performance_config")

    @property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional['outputs.NodePoolNetworkConfigPodCidrOverprovisionConfig']:
        """
        Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited. Structure is documented below.
        """
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> Optional[str]:
        """
        The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> Optional[str]:
        """
        The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        return pulumi.get(self, "pod_range")


@pulumi.output_type
class NodePoolNetworkConfigAdditionalNodeNetworkConfig(dict):
    def __init__(__self__, *,
                 network: Optional[str] = None,
                 subnetwork: Optional[str] = None):
        """
        :param str network: Name of the VPC where the additional interface belongs.
        :param str subnetwork: Name of the subnetwork where the additional interface belongs.
        """
        if network is not None:
            pulumi.set(__self__, "network", network)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter
    def network(self) -> Optional[str]:
        """
        Name of the VPC where the additional interface belongs.
        """
        return pulumi.get(self, "network")

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[str]:
        """
        Name of the subnetwork where the additional interface belongs.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class NodePoolNetworkConfigAdditionalPodNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxPodsPerNode":
            suggest = "max_pods_per_node"
        elif key == "secondaryPodRange":
            suggest = "secondary_pod_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNetworkConfigAdditionalPodNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNetworkConfigAdditionalPodNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNetworkConfigAdditionalPodNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_pods_per_node: Optional[int] = None,
                 secondary_pod_range: Optional[str] = None,
                 subnetwork: Optional[str] = None):
        """
        :param int max_pods_per_node: The maximum number of pods per node which use this pod network.
        :param str secondary_pod_range: The name of the secondary range on the subnet which provides IP address for this pod range.
        :param str subnetwork: Name of the subnetwork where the additional pod network belongs.
        """
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if secondary_pod_range is not None:
            pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[int]:
        """
        The maximum number of pods per node which use this pod network.
        """
        return pulumi.get(self, "max_pods_per_node")

    @property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> Optional[str]:
        """
        The name of the secondary range on the subnet which provides IP address for this pod range.
        """
        return pulumi.get(self, "secondary_pod_range")

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[str]:
        """
        Name of the subnetwork where the additional pod network belongs.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class NodePoolNetworkConfigNetworkPerformanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "totalEgressBandwidthTier":
            suggest = "total_egress_bandwidth_tier"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNetworkConfigNetworkPerformanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNetworkConfigNetworkPerformanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNetworkConfigNetworkPerformanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 total_egress_bandwidth_tier: str):
        """
        :param str total_egress_bandwidth_tier: Specifies the total network bandwidth tier for the NodePool.
        """
        pulumi.set(__self__, "total_egress_bandwidth_tier", total_egress_bandwidth_tier)

    @property
    @pulumi.getter(name="totalEgressBandwidthTier")
    def total_egress_bandwidth_tier(self) -> str:
        """
        Specifies the total network bandwidth tier for the NodePool.
        """
        return pulumi.get(self, "total_egress_bandwidth_tier")


@pulumi.output_type
class NodePoolNetworkConfigPodCidrOverprovisionConfig(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether pod cidr overprovision is disabled.
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether pod cidr overprovision is disabled.
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class NodePoolNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "advancedMachineFeatures":
            suggest = "advanced_machine_features"
        elif key == "bootDiskKmsKey":
            suggest = "boot_disk_kms_key"
        elif key == "confidentialNodes":
            suggest = "confidential_nodes"
        elif key == "containerdConfig":
            suggest = "containerd_config"
        elif key == "diskSizeGb":
            suggest = "disk_size_gb"
        elif key == "diskType":
            suggest = "disk_type"
        elif key == "effectiveTaints":
            suggest = "effective_taints"
        elif key == "enableConfidentialStorage":
            suggest = "enable_confidential_storage"
        elif key == "ephemeralStorageConfig":
            suggest = "ephemeral_storage_config"
        elif key == "ephemeralStorageLocalSsdConfig":
            suggest = "ephemeral_storage_local_ssd_config"
        elif key == "fastSocket":
            suggest = "fast_socket"
        elif key == "gcfsConfig":
            suggest = "gcfs_config"
        elif key == "guestAccelerators":
            suggest = "guest_accelerators"
        elif key == "hostMaintenancePolicy":
            suggest = "host_maintenance_policy"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "kubeletConfig":
            suggest = "kubelet_config"
        elif key == "linuxNodeConfig":
            suggest = "linux_node_config"
        elif key == "localNvmeSsdBlockConfig":
            suggest = "local_nvme_ssd_block_config"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "loggingVariant":
            suggest = "logging_variant"
        elif key == "machineType":
            suggest = "machine_type"
        elif key == "minCpuPlatform":
            suggest = "min_cpu_platform"
        elif key == "nodeGroup":
            suggest = "node_group"
        elif key == "oauthScopes":
            suggest = "oauth_scopes"
        elif key == "reservationAffinity":
            suggest = "reservation_affinity"
        elif key == "resourceLabels":
            suggest = "resource_labels"
        elif key == "resourceManagerTags":
            suggest = "resource_manager_tags"
        elif key == "sandboxConfig":
            suggest = "sandbox_config"
        elif key == "secondaryBootDisks":
            suggest = "secondary_boot_disks"
        elif key == "serviceAccount":
            suggest = "service_account"
        elif key == "shieldedInstanceConfig":
            suggest = "shielded_instance_config"
        elif key == "soleTenantConfig":
            suggest = "sole_tenant_config"
        elif key == "storagePools":
            suggest = "storage_pools"
        elif key == "workloadMetadataConfig":
            suggest = "workload_metadata_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 advanced_machine_features: Optional['outputs.NodePoolNodeConfigAdvancedMachineFeatures'] = None,
                 boot_disk_kms_key: Optional[str] = None,
                 confidential_nodes: Optional['outputs.NodePoolNodeConfigConfidentialNodes'] = None,
                 containerd_config: Optional['outputs.NodePoolNodeConfigContainerdConfig'] = None,
                 disk_size_gb: Optional[int] = None,
                 disk_type: Optional[str] = None,
                 effective_taints: Optional[Sequence['outputs.NodePoolNodeConfigEffectiveTaint']] = None,
                 enable_confidential_storage: Optional[bool] = None,
                 ephemeral_storage_config: Optional['outputs.NodePoolNodeConfigEphemeralStorageConfig'] = None,
                 ephemeral_storage_local_ssd_config: Optional['outputs.NodePoolNodeConfigEphemeralStorageLocalSsdConfig'] = None,
                 fast_socket: Optional['outputs.NodePoolNodeConfigFastSocket'] = None,
                 gcfs_config: Optional['outputs.NodePoolNodeConfigGcfsConfig'] = None,
                 guest_accelerators: Optional[Sequence['outputs.NodePoolNodeConfigGuestAccelerator']] = None,
                 gvnic: Optional['outputs.NodePoolNodeConfigGvnic'] = None,
                 host_maintenance_policy: Optional['outputs.NodePoolNodeConfigHostMaintenancePolicy'] = None,
                 image_type: Optional[str] = None,
                 kubelet_config: Optional['outputs.NodePoolNodeConfigKubeletConfig'] = None,
                 labels: Optional[Mapping[str, str]] = None,
                 linux_node_config: Optional['outputs.NodePoolNodeConfigLinuxNodeConfig'] = None,
                 local_nvme_ssd_block_config: Optional['outputs.NodePoolNodeConfigLocalNvmeSsdBlockConfig'] = None,
                 local_ssd_count: Optional[int] = None,
                 logging_variant: Optional[str] = None,
                 machine_type: Optional[str] = None,
                 metadata: Optional[Mapping[str, str]] = None,
                 min_cpu_platform: Optional[str] = None,
                 node_group: Optional[str] = None,
                 oauth_scopes: Optional[Sequence[str]] = None,
                 preemptible: Optional[bool] = None,
                 reservation_affinity: Optional['outputs.NodePoolNodeConfigReservationAffinity'] = None,
                 resource_labels: Optional[Mapping[str, str]] = None,
                 resource_manager_tags: Optional[Mapping[str, str]] = None,
                 sandbox_config: Optional['outputs.NodePoolNodeConfigSandboxConfig'] = None,
                 secondary_boot_disks: Optional[Sequence['outputs.NodePoolNodeConfigSecondaryBootDisk']] = None,
                 service_account: Optional[str] = None,
                 shielded_instance_config: Optional['outputs.NodePoolNodeConfigShieldedInstanceConfig'] = None,
                 sole_tenant_config: Optional['outputs.NodePoolNodeConfigSoleTenantConfig'] = None,
                 spot: Optional[bool] = None,
                 storage_pools: Optional[Sequence[str]] = None,
                 tags: Optional[Sequence[str]] = None,
                 taints: Optional[Sequence['outputs.NodePoolNodeConfigTaint']] = None,
                 workload_metadata_config: Optional['outputs.NodePoolNodeConfigWorkloadMetadataConfig'] = None):
        """
        :param 'NodePoolNodeConfigAdvancedMachineFeaturesArgs' advanced_machine_features: Specifies options for controlling advanced machine features.
        :param str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        :param 'NodePoolNodeConfigConfidentialNodesArgs' confidential_nodes: Configuration for the confidential nodes feature, which makes nodes run on confidential VMs. Warning: This configuration can't be changed (or added/removed) after pool creation without deleting and recreating the entire pool.
        :param 'NodePoolNodeConfigContainerdConfigArgs' containerd_config: Parameters for containerd configuration.
        :param int disk_size_gb: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        :param str disk_type: Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        :param Sequence['NodePoolNodeConfigEffectiveTaintArgs'] effective_taints: List of kubernetes taints applied to each node.
        :param bool enable_confidential_storage: If enabled boot disks are configured with confidential mode.
        :param 'NodePoolNodeConfigEphemeralStorageConfigArgs' ephemeral_storage_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param 'NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs' ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param 'NodePoolNodeConfigFastSocketArgs' fast_socket: Enable or disable NCCL Fast Socket in the node pool.
        :param 'NodePoolNodeConfigGcfsConfigArgs' gcfs_config: GCFS configuration for this node.
        :param Sequence['NodePoolNodeConfigGuestAcceleratorArgs'] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
        :param 'NodePoolNodeConfigGvnicArgs' gvnic: Enable or disable gvnic in the node pool.
        :param 'NodePoolNodeConfigHostMaintenancePolicyArgs' host_maintenance_policy: The maintenance policy for the hosts on which the GKE VMs run on.
        :param str image_type: The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        :param 'NodePoolNodeConfigKubeletConfigArgs' kubelet_config: Node kubelet configs.
        :param Mapping[str, str] labels: The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        :param 'NodePoolNodeConfigLinuxNodeConfigArgs' linux_node_config: Parameters that can be configured on Linux nodes.
        :param 'NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs' local_nvme_ssd_block_config: Parameters for raw-block local NVMe SSDs.
        :param int local_ssd_count: The number of local SSD disks to be attached to the node.
        :param str logging_variant: Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        :param str machine_type: The name of a Google Compute Engine machine type.
        :param Mapping[str, str] metadata: The metadata key/value pairs assigned to instances in the cluster.
        :param str min_cpu_platform: Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        :param str node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        :param Sequence[str] oauth_scopes: The set of Google API scopes to be made available on all of the node VMs.
        :param bool preemptible: Whether the nodes are created as preemptible VM instances.
        :param 'NodePoolNodeConfigReservationAffinityArgs' reservation_affinity: The configuration of the desired reservation which instances could take capacity from.
               Structure is documented below.
               
               <a name="nested_autoscaling"></a>The `autoscaling` block supports (either total or per zone limits are required):
        :param Mapping[str, str] resource_labels: The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        :param Mapping[str, str] resource_manager_tags: A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        :param 'NodePoolNodeConfigSandboxConfigArgs' sandbox_config: Sandbox configuration for this node.
        :param Sequence['NodePoolNodeConfigSecondaryBootDiskArgs'] secondary_boot_disks: Secondary boot disks for preloading data or container images.
        :param str service_account: The Google Cloud Platform Service Account to be used by the node VMs.
        :param 'NodePoolNodeConfigShieldedInstanceConfigArgs' shielded_instance_config: Shielded Instance options.
        :param 'NodePoolNodeConfigSoleTenantConfigArgs' sole_tenant_config: Node affinity options for sole tenant node pools.
        :param bool spot: Whether the nodes are created as spot VM instances.
        :param Sequence[str] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param Sequence[str] tags: The list of instance tags applied to all nodes.
        :param Sequence['NodePoolNodeConfigTaintArgs'] taints: List of Kubernetes taints to be applied to each node.
        :param 'NodePoolNodeConfigWorkloadMetadataConfigArgs' workload_metadata_config: The workload metadata configuration for this node.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if containerd_config is not None:
            pulumi.set(__self__, "containerd_config", containerd_config)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if effective_taints is not None:
            pulumi.set(__self__, "effective_taints", effective_taints)
        if enable_confidential_storage is not None:
            pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if resource_manager_tags is not None:
            pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if secondary_boot_disks is not None:
            pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if storage_pools is not None:
            pulumi.set(__self__, "storage_pools", storage_pools)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional['outputs.NodePoolNodeConfigAdvancedMachineFeatures']:
        """
        Specifies options for controlling advanced machine features.
        """
        return pulumi.get(self, "advanced_machine_features")

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[str]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional['outputs.NodePoolNodeConfigConfidentialNodes']:
        """
        Configuration for the confidential nodes feature, which makes nodes run on confidential VMs. Warning: This configuration can't be changed (or added/removed) after pool creation without deleting and recreating the entire pool.
        """
        return pulumi.get(self, "confidential_nodes")

    @property
    @pulumi.getter(name="containerdConfig")
    def containerd_config(self) -> Optional['outputs.NodePoolNodeConfigContainerdConfig']:
        """
        Parameters for containerd configuration.
        """
        return pulumi.get(self, "containerd_config")

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[int]:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[str]:
        """
        Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        """
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Optional[Sequence['outputs.NodePoolNodeConfigEffectiveTaint']]:
        """
        List of kubernetes taints applied to each node.
        """
        return pulumi.get(self, "effective_taints")

    @property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> Optional[bool]:
        """
        If enabled boot disks are configured with confidential mode.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional['outputs.NodePoolNodeConfigEphemeralStorageConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional['outputs.NodePoolNodeConfigEphemeralStorageLocalSsdConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional['outputs.NodePoolNodeConfigFastSocket']:
        """
        Enable or disable NCCL Fast Socket in the node pool.
        """
        return pulumi.get(self, "fast_socket")

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional['outputs.NodePoolNodeConfigGcfsConfig']:
        """
        GCFS configuration for this node.
        """
        return pulumi.get(self, "gcfs_config")

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[Sequence['outputs.NodePoolNodeConfigGuestAccelerator']]:
        """
        List of the type and count of accelerator cards attached to the instance.
        """
        return pulumi.get(self, "guest_accelerators")

    @property
    @pulumi.getter
    def gvnic(self) -> Optional['outputs.NodePoolNodeConfigGvnic']:
        """
        Enable or disable gvnic in the node pool.
        """
        return pulumi.get(self, "gvnic")

    @property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional['outputs.NodePoolNodeConfigHostMaintenancePolicy']:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policy")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[str]:
        """
        The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional['outputs.NodePoolNodeConfigKubeletConfig']:
        """
        Node kubelet configs.
        """
        return pulumi.get(self, "kubelet_config")

    @property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, str]]:
        """
        The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional['outputs.NodePoolNodeConfigLinuxNodeConfig']:
        """
        Parameters that can be configured on Linux nodes.
        """
        return pulumi.get(self, "linux_node_config")

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional['outputs.NodePoolNodeConfigLocalNvmeSsdBlockConfig']:
        """
        Parameters for raw-block local NVMe SSDs.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        """
        The number of local SSD disks to be attached to the node.
        """
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[str]:
        """
        Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        """
        return pulumi.get(self, "logging_variant")

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[str]:
        """
        The name of a Google Compute Engine machine type.
        """
        return pulumi.get(self, "machine_type")

    @property
    @pulumi.getter
    def metadata(self) -> Optional[Mapping[str, str]]:
        """
        The metadata key/value pairs assigned to instances in the cluster.
        """
        return pulumi.get(self, "metadata")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[str]:
        """
        Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        """
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[str]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        """
        return pulumi.get(self, "node_group")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[Sequence[str]]:
        """
        The set of Google API scopes to be made available on all of the node VMs.
        """
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter
    def preemptible(self) -> Optional[bool]:
        """
        Whether the nodes are created as preemptible VM instances.
        """
        return pulumi.get(self, "preemptible")

    @property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional['outputs.NodePoolNodeConfigReservationAffinity']:
        """
        The configuration of the desired reservation which instances could take capacity from.
        Structure is documented below.

        <a name="nested_autoscaling"></a>The `autoscaling` block supports (either total or per zone limits are required):
        """
        return pulumi.get(self, "reservation_affinity")

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[Mapping[str, str]]:
        """
        The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        """
        return pulumi.get(self, "resource_labels")

    @property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Optional[Mapping[str, str]]:
        """
        A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        """
        return pulumi.get(self, "resource_manager_tags")

    @property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional['outputs.NodePoolNodeConfigSandboxConfig']:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_config")

    @property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Optional[Sequence['outputs.NodePoolNodeConfigSecondaryBootDisk']]:
        """
        Secondary boot disks for preloading data or container images.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[str]:
        """
        The Google Cloud Platform Service Account to be used by the node VMs.
        """
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional['outputs.NodePoolNodeConfigShieldedInstanceConfig']:
        """
        Shielded Instance options.
        """
        return pulumi.get(self, "shielded_instance_config")

    @property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional['outputs.NodePoolNodeConfigSoleTenantConfig']:
        """
        Node affinity options for sole tenant node pools.
        """
        return pulumi.get(self, "sole_tenant_config")

    @property
    @pulumi.getter
    def spot(self) -> Optional[bool]:
        """
        Whether the nodes are created as spot VM instances.
        """
        return pulumi.get(self, "spot")

    @property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Optional[Sequence[str]]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Sequence[str]]:
        """
        The list of instance tags applied to all nodes.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def taints(self) -> Optional[Sequence['outputs.NodePoolNodeConfigTaint']]:
        """
        List of Kubernetes taints to be applied to each node.
        """
        return pulumi.get(self, "taints")

    @property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional['outputs.NodePoolNodeConfigWorkloadMetadataConfig']:
        """
        The workload metadata configuration for this node.
        """
        return pulumi.get(self, "workload_metadata_config")


@pulumi.output_type
class NodePoolNodeConfigAdvancedMachineFeatures(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "threadsPerCore":
            suggest = "threads_per_core"
        elif key == "enableNestedVirtualization":
            suggest = "enable_nested_virtualization"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigAdvancedMachineFeatures. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 threads_per_core: int,
                 enable_nested_virtualization: Optional[bool] = None):
        """
        :param int threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        :param bool enable_nested_virtualization: Whether the node should have nested virtualization enabled.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)
        if enable_nested_virtualization is not None:
            pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> int:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")

    @property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> Optional[bool]:
        """
        Whether the node should have nested virtualization enabled.
        """
        return pulumi.get(self, "enable_nested_virtualization")


@pulumi.output_type
class NodePoolNodeConfigConfidentialNodes(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolNodeConfigContainerdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateRegistryAccessConfig":
            suggest = "private_registry_access_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigContainerdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigContainerdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigContainerdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 private_registry_access_config: Optional['outputs.NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig'] = None):
        """
        :param 'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs' private_registry_access_config: Parameters for private container registries configuration.
        """
        if private_registry_access_config is not None:
            pulumi.set(__self__, "private_registry_access_config", private_registry_access_config)

    @property
    @pulumi.getter(name="privateRegistryAccessConfig")
    def private_registry_access_config(self) -> Optional['outputs.NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig']:
        """
        Parameters for private container registries configuration.
        """
        return pulumi.get(self, "private_registry_access_config")


@pulumi.output_type
class NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "certificateAuthorityDomainConfigs":
            suggest = "certificate_authority_domain_configs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: bool,
                 certificate_authority_domain_configs: Optional[Sequence['outputs.NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']] = None):
        """
        :param bool enabled: Whether or not private registries are configured.
        :param Sequence['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: Parameters for configuring CA certificate and domains.
        """
        pulumi.set(__self__, "enabled", enabled)
        if certificate_authority_domain_configs is not None:
            pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not private registries are configured.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Optional[Sequence['outputs.NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']]:
        """
        Parameters for configuring CA certificate and domains.
        """
        return pulumi.get(self, "certificate_authority_domain_configs")


@pulumi.output_type
class NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gcpSecretManagerCertificateConfig":
            suggest = "gcp_secret_manager_certificate_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 fqdns: Sequence[str],
                 gcp_secret_manager_certificate_config: 'outputs.NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig'):
        """
        :param Sequence[str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param 'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs' gcp_secret_manager_certificate_config: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_config", gcp_secret_manager_certificate_config)

    @property
    @pulumi.getter
    def fqdns(self) -> Sequence[str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @property
    @pulumi.getter(name="gcpSecretManagerCertificateConfig")
    def gcp_secret_manager_certificate_config(self) -> 'outputs.NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig':
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_config")


@pulumi.output_type
class NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretUri":
            suggest = "secret_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_uri: str):
        """
        :param str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class NodePoolNodeConfigEffectiveTaint(dict):
    def __init__(__self__, *,
                 effect: Optional[str] = None,
                 key: Optional[str] = None,
                 value: Optional[str] = None):
        """
        :param str effect: Effect for taint.
        :param str key: Key for taint.
        :param str value: Value for taint.
        """
        if effect is not None:
            pulumi.set(__self__, "effect", effect)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> Optional[str]:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class NodePoolNodeConfigEphemeralStorageConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigEphemeralStorageConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class NodePoolNodeConfigEphemeralStorageLocalSsdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigEphemeralStorageLocalSsdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class NodePoolNodeConfigFastSocket(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolNodeConfigGcfsConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not GCFS is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not GCFS is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolNodeConfigGuestAccelerator(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverInstallationConfig":
            suggest = "gpu_driver_installation_config"
        elif key == "gpuPartitionSize":
            suggest = "gpu_partition_size"
        elif key == "gpuSharingConfig":
            suggest = "gpu_sharing_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigGuestAccelerator. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigGuestAccelerator.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigGuestAccelerator.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 count: int,
                 type: str,
                 gpu_driver_installation_config: Optional['outputs.NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig'] = None,
                 gpu_partition_size: Optional[str] = None,
                 gpu_sharing_config: Optional['outputs.NodePoolNodeConfigGuestAcceleratorGpuSharingConfig'] = None):
        """
        :param int count: The number of the accelerator cards exposed to an instance.
        :param str type: The accelerator type resource name.
        :param 'NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs' gpu_driver_installation_config: Configuration for auto installation of GPU driver.
        :param str gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        :param 'NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs' gpu_sharing_config: Configuration for GPU sharing.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @property
    @pulumi.getter
    def count(self) -> int:
        """
        The number of the accelerator cards exposed to an instance.
        """
        return pulumi.get(self, "count")

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        The accelerator type resource name.
        """
        return pulumi.get(self, "type")

    @property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional['outputs.NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig']:
        """
        Configuration for auto installation of GPU driver.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[str]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        """
        return pulumi.get(self, "gpu_partition_size")

    @property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional['outputs.NodePoolNodeConfigGuestAcceleratorGpuSharingConfig']:
        """
        Configuration for GPU sharing.
        """
        return pulumi.get(self, "gpu_sharing_config")


@pulumi.output_type
class NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverVersion":
            suggest = "gpu_driver_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_driver_version: str):
        """
        :param str gpu_driver_version: Mode for how the GPU driver is installed.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> str:
        """
        Mode for how the GPU driver is installed.
        """
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class NodePoolNodeConfigGuestAcceleratorGpuSharingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuSharingStrategy":
            suggest = "gpu_sharing_strategy"
        elif key == "maxSharedClientsPerGpu":
            suggest = "max_shared_clients_per_gpu"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigGuestAcceleratorGpuSharingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_sharing_strategy: str,
                 max_shared_clients_per_gpu: int):
        """
        :param str gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        :param int max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> str:
        """
        The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> int:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class NodePoolNodeConfigGvnic(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not gvnic is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not gvnic is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolNodeConfigHostMaintenancePolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maintenanceInterval":
            suggest = "maintenance_interval"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigHostMaintenancePolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 maintenance_interval: str):
        """
        :param str maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> str:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class NodePoolNodeConfigKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cpuCfsQuota":
            suggest = "cpu_cfs_quota"
        elif key == "cpuCfsQuotaPeriod":
            suggest = "cpu_cfs_quota_period"
        elif key == "cpuManagerPolicy":
            suggest = "cpu_manager_policy"
        elif key == "insecureKubeletReadonlyPortEnabled":
            suggest = "insecure_kubelet_readonly_port_enabled"
        elif key == "podPidsLimit":
            suggest = "pod_pids_limit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cpu_cfs_quota: Optional[bool] = None,
                 cpu_cfs_quota_period: Optional[str] = None,
                 cpu_manager_policy: Optional[str] = None,
                 insecure_kubelet_readonly_port_enabled: Optional[str] = None,
                 pod_pids_limit: Optional[int] = None):
        """
        :param bool cpu_cfs_quota: Enable CPU CFS quota enforcement for containers that specify CPU limits.
        :param str cpu_cfs_quota_period: Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        :param str cpu_manager_policy: Control the CPU management policy on the node.
        :param str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param int pod_pids_limit: Controls the maximum number of processes allowed to run in a pod.
        """
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if cpu_manager_policy is not None:
            pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[bool]:
        """
        Enable CPU CFS quota enforcement for containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[str]:
        """
        Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> Optional[str]:
        """
        Control the CPU management policy on the node.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[str]:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[int]:
        """
        Controls the maximum number of processes allowed to run in a pod.
        """
        return pulumi.get(self, "pod_pids_limit")


@pulumi.output_type
class NodePoolNodeConfigLinuxNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cgroupMode":
            suggest = "cgroup_mode"
        elif key == "hugepagesConfig":
            suggest = "hugepages_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigLinuxNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigLinuxNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigLinuxNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cgroup_mode: Optional[str] = None,
                 hugepages_config: Optional['outputs.NodePoolNodeConfigLinuxNodeConfigHugepagesConfig'] = None,
                 sysctls: Optional[Mapping[str, str]] = None):
        """
        :param str cgroup_mode: cgroupMode specifies the cgroup mode to be used on the node.
        :param 'NodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs' hugepages_config: Amounts for 2M and 1G hugepages.
        :param Mapping[str, str] sysctls: The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        """
        if cgroup_mode is not None:
            pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        if hugepages_config is not None:
            pulumi.set(__self__, "hugepages_config", hugepages_config)
        if sysctls is not None:
            pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> Optional[str]:
        """
        cgroupMode specifies the cgroup mode to be used on the node.
        """
        return pulumi.get(self, "cgroup_mode")

    @property
    @pulumi.getter(name="hugepagesConfig")
    def hugepages_config(self) -> Optional['outputs.NodePoolNodeConfigLinuxNodeConfigHugepagesConfig']:
        """
        Amounts for 2M and 1G hugepages.
        """
        return pulumi.get(self, "hugepages_config")

    @property
    @pulumi.getter
    def sysctls(self) -> Optional[Mapping[str, str]]:
        """
        The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        """
        return pulumi.get(self, "sysctls")


@pulumi.output_type
class NodePoolNodeConfigLinuxNodeConfigHugepagesConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "hugepageSize1g":
            suggest = "hugepage_size1g"
        elif key == "hugepageSize2m":
            suggest = "hugepage_size2m"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigLinuxNodeConfigHugepagesConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigLinuxNodeConfigHugepagesConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigLinuxNodeConfigHugepagesConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 hugepage_size1g: Optional[int] = None,
                 hugepage_size2m: Optional[int] = None):
        """
        :param int hugepage_size1g: Amount of 1G hugepages.
        :param int hugepage_size2m: Amount of 2M hugepages.
        """
        if hugepage_size1g is not None:
            pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        if hugepage_size2m is not None:
            pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> Optional[int]:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> Optional[int]:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")


@pulumi.output_type
class NodePoolNodeConfigLocalNvmeSsdBlockConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigLocalNvmeSsdBlockConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class NodePoolNodeConfigReservationAffinity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "consumeReservationType":
            suggest = "consume_reservation_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigReservationAffinity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigReservationAffinity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigReservationAffinity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 consume_reservation_type: str,
                 key: Optional[str] = None,
                 values: Optional[Sequence[str]] = None):
        """
        :param str consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param str key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param Sequence[str] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> str:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def values(self) -> Optional[Sequence[str]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class NodePoolNodeConfigSandboxConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sandboxType":
            suggest = "sandbox_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigSandboxConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigSandboxConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigSandboxConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 sandbox_type: str):
        """
        :param str sandbox_type: Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> str:
        """
        Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class NodePoolNodeConfigSecondaryBootDisk(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "diskImage":
            suggest = "disk_image"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigSecondaryBootDisk. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigSecondaryBootDisk.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigSecondaryBootDisk.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disk_image: str,
                 mode: Optional[str] = None):
        """
        :param str disk_image: Disk image to create the secondary boot disk from
        :param str mode: Mode for how the secondary boot disk is used.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        if mode is not None:
            pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> str:
        """
        Disk image to create the secondary boot disk from
        """
        return pulumi.get(self, "disk_image")

    @property
    @pulumi.getter
    def mode(self) -> Optional[str]:
        """
        Mode for how the secondary boot disk is used.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class NodePoolNodeConfigShieldedInstanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableIntegrityMonitoring":
            suggest = "enable_integrity_monitoring"
        elif key == "enableSecureBoot":
            suggest = "enable_secure_boot"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigShieldedInstanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[bool] = None,
                 enable_secure_boot: Optional[bool] = None):
        """
        :param bool enable_integrity_monitoring: Defines whether the instance has integrity monitoring enabled.
        :param bool enable_secure_boot: Defines whether the instance has Secure Boot enabled.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[bool]:
        """
        Defines whether the instance has integrity monitoring enabled.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[bool]:
        """
        Defines whether the instance has Secure Boot enabled.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class NodePoolNodeConfigSoleTenantConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodeAffinities":
            suggest = "node_affinities"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigSoleTenantConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigSoleTenantConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigSoleTenantConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.NodePoolNodeConfigSoleTenantConfigNodeAffinity']):
        """
        :param Sequence['NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs'] node_affinities: .
        """
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.NodePoolNodeConfigSoleTenantConfigNodeAffinity']:
        """
        .
        """
        return pulumi.get(self, "node_affinities")


@pulumi.output_type
class NodePoolNodeConfigSoleTenantConfigNodeAffinity(dict):
    def __init__(__self__, *,
                 key: str,
                 operator: str,
                 values: Sequence[str]):
        """
        :param str key: .
        :param str operator: .
        :param Sequence[str] values: .
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        .
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def operator(self) -> str:
        """
        .
        """
        return pulumi.get(self, "operator")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        """
        .
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class NodePoolNodeConfigTaint(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        """
        :param str effect: Effect for taint.
        :param str key: Key for taint.
        :param str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class NodePoolNodeConfigWorkloadMetadataConfig(dict):
    def __init__(__self__, *,
                 mode: str):
        """
        :param str mode: Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> str:
        """
        Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class NodePoolPlacementPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "policyName":
            suggest = "policy_name"
        elif key == "tpuTopology":
            suggest = "tpu_topology"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolPlacementPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolPlacementPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolPlacementPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 type: str,
                 policy_name: Optional[str] = None,
                 tpu_topology: Optional[str] = None):
        """
        :param str type: The type of the policy. Supports a single value: COMPACT.
               Specifying COMPACT placement policy type places node pool's nodes in a closer
               physical proximity in order to reduce network latency between nodes.
        :param str policy_name: If set, refers to the name of a custom resource policy supplied by the user.
               The resource policy must be in the same project and region as the node pool.
               If not found, InvalidArgument error is returned.
        :param str tpu_topology: The [TPU placement topology](https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies) for pod slice node pool.
        """
        pulumi.set(__self__, "type", type)
        if policy_name is not None:
            pulumi.set(__self__, "policy_name", policy_name)
        if tpu_topology is not None:
            pulumi.set(__self__, "tpu_topology", tpu_topology)

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        The type of the policy. Supports a single value: COMPACT.
        Specifying COMPACT placement policy type places node pool's nodes in a closer
        physical proximity in order to reduce network latency between nodes.
        """
        return pulumi.get(self, "type")

    @property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> Optional[str]:
        """
        If set, refers to the name of a custom resource policy supplied by the user.
        The resource policy must be in the same project and region as the node pool.
        If not found, InvalidArgument error is returned.
        """
        return pulumi.get(self, "policy_name")

    @property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> Optional[str]:
        """
        The [TPU placement topology](https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies) for pod slice node pool.
        """
        return pulumi.get(self, "tpu_topology")


@pulumi.output_type
class NodePoolQueuedProvisioning(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Makes nodes obtainable through the [ProvisioningRequest API](https://cloud.google.com/kubernetes-engine/docs/how-to/provisioningrequest) exclusively.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Makes nodes obtainable through the [ProvisioningRequest API](https://cloud.google.com/kubernetes-engine/docs/how-to/provisioningrequest) exclusively.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolUpgradeSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "blueGreenSettings":
            suggest = "blue_green_settings"
        elif key == "maxSurge":
            suggest = "max_surge"
        elif key == "maxUnavailable":
            suggest = "max_unavailable"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolUpgradeSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolUpgradeSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolUpgradeSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 blue_green_settings: Optional['outputs.NodePoolUpgradeSettingsBlueGreenSettings'] = None,
                 max_surge: Optional[int] = None,
                 max_unavailable: Optional[int] = None,
                 strategy: Optional[str] = None):
        """
        :param 'NodePoolUpgradeSettingsBlueGreenSettingsArgs' blue_green_settings: The settings to adjust [blue green upgrades](https://cloud.google.com/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy).
               Structure is documented below
        :param int max_surge: The number of additional nodes that can be added to the node pool during
               an upgrade. Increasing `max_surge` raises the number of nodes that can be upgraded simultaneously.
               Can be set to 0 or greater.
        :param int max_unavailable: The number of nodes that can be simultaneously unavailable during
               an upgrade. Increasing `max_unavailable` raises the number of nodes that can be upgraded in
               parallel. Can be set to 0 or greater.
               
               `max_surge` and `max_unavailable` must not be negative and at least one of them must be greater than zero.
        :param str strategy: The upgrade strategy to be used for upgrading the nodes.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional['outputs.NodePoolUpgradeSettingsBlueGreenSettings']:
        """
        The settings to adjust [blue green upgrades](https://cloud.google.com/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy).
        Structure is documented below
        """
        return pulumi.get(self, "blue_green_settings")

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[int]:
        """
        The number of additional nodes that can be added to the node pool during
        an upgrade. Increasing `max_surge` raises the number of nodes that can be upgraded simultaneously.
        Can be set to 0 or greater.
        """
        return pulumi.get(self, "max_surge")

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[int]:
        """
        The number of nodes that can be simultaneously unavailable during
        an upgrade. Increasing `max_unavailable` raises the number of nodes that can be upgraded in
        parallel. Can be set to 0 or greater.

        `max_surge` and `max_unavailable` must not be negative and at least one of them must be greater than zero.
        """
        return pulumi.get(self, "max_unavailable")

    @property
    @pulumi.getter
    def strategy(self) -> Optional[str]:
        """
        The upgrade strategy to be used for upgrading the nodes.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class NodePoolUpgradeSettingsBlueGreenSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "standardRolloutPolicy":
            suggest = "standard_rollout_policy"
        elif key == "nodePoolSoakDuration":
            suggest = "node_pool_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolUpgradeSettingsBlueGreenSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 standard_rollout_policy: 'outputs.NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
                 node_pool_soak_duration: Optional[str] = None):
        """
        :param 'NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs' standard_rollout_policy: Specifies the standard policy settings for blue-green upgrades.
        :param str node_pool_soak_duration: Time needed after draining the entire blue pool.
               After this period, the blue pool will be cleaned up.
        """
        pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)

    @property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> 'outputs.NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy':
        """
        Specifies the standard policy settings for blue-green upgrades.
        """
        return pulumi.get(self, "standard_rollout_policy")

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[str]:
        """
        Time needed after draining the entire blue pool.
        After this period, the blue pool will be cleaned up.
        """
        return pulumi.get(self, "node_pool_soak_duration")


@pulumi.output_type
class NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "batchNodeCount":
            suggest = "batch_node_count"
        elif key == "batchPercentage":
            suggest = "batch_percentage"
        elif key == "batchSoakDuration":
            suggest = "batch_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 batch_node_count: Optional[int] = None,
                 batch_percentage: Optional[float] = None,
                 batch_soak_duration: Optional[str] = None):
        """
        :param int batch_node_count: Number of blue nodes to drain in a batch.
        :param float batch_percentage: Percentage of the blue pool nodes to drain in a batch.
        :param str batch_soak_duration: Soak time after each batch gets drained.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[int]:
        """
        Number of blue nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_node_count")

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[float]:
        """
        Percentage of the blue pool nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_percentage")

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[str]:
        """
        Soak time after each batch gets drained.
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class GetClusterAddonsConfigResult(dict):
    def __init__(__self__, *,
                 cloudrun_configs: Sequence['outputs.GetClusterAddonsConfigCloudrunConfigResult'],
                 config_connector_configs: Sequence['outputs.GetClusterAddonsConfigConfigConnectorConfigResult'],
                 dns_cache_configs: Sequence['outputs.GetClusterAddonsConfigDnsCacheConfigResult'],
                 gce_persistent_disk_csi_driver_configs: Sequence['outputs.GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigResult'],
                 gcp_filestore_csi_driver_configs: Sequence['outputs.GetClusterAddonsConfigGcpFilestoreCsiDriverConfigResult'],
                 gcs_fuse_csi_driver_configs: Sequence['outputs.GetClusterAddonsConfigGcsFuseCsiDriverConfigResult'],
                 gke_backup_agent_configs: Sequence['outputs.GetClusterAddonsConfigGkeBackupAgentConfigResult'],
                 horizontal_pod_autoscalings: Sequence['outputs.GetClusterAddonsConfigHorizontalPodAutoscalingResult'],
                 http_load_balancings: Sequence['outputs.GetClusterAddonsConfigHttpLoadBalancingResult'],
                 istio_configs: Sequence['outputs.GetClusterAddonsConfigIstioConfigResult'],
                 kalm_configs: Sequence['outputs.GetClusterAddonsConfigKalmConfigResult'],
                 network_policy_configs: Sequence['outputs.GetClusterAddonsConfigNetworkPolicyConfigResult'],
                 ray_operator_configs: Sequence['outputs.GetClusterAddonsConfigRayOperatorConfigResult'],
                 stateful_ha_configs: Sequence['outputs.GetClusterAddonsConfigStatefulHaConfigResult']):
        """
        :param Sequence['GetClusterAddonsConfigCloudrunConfigArgs'] cloudrun_configs: The status of the CloudRun addon. It is disabled by default. Set disabled = false to enable.
        :param Sequence['GetClusterAddonsConfigConfigConnectorConfigArgs'] config_connector_configs: The of the Config Connector addon.
        :param Sequence['GetClusterAddonsConfigDnsCacheConfigArgs'] dns_cache_configs: The status of the NodeLocal DNSCache addon. It is disabled by default. Set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs'] gce_persistent_disk_csi_driver_configs: Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set enabled = true to enable. The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        :param Sequence['GetClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs'] gcp_filestore_csi_driver_configs: The status of the Filestore CSI driver addon, which allows the usage of filestore instance as volumes. Defaults to disabled for Standard clusters; set enabled = true to enable. It is enabled by default for Autopilot clusters; set enabled = true to enable it explicitly.
        :param Sequence['GetClusterAddonsConfigGcsFuseCsiDriverConfigArgs'] gcs_fuse_csi_driver_configs: The status of the GCS Fuse CSI driver addon, which allows the usage of gcs bucket as volumes. Defaults to disabled; set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigGkeBackupAgentConfigArgs'] gke_backup_agent_configs: The status of the Backup for GKE Agent addon. It is disabled by default. Set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigHorizontalPodAutoscalingArgs'] horizontal_pod_autoscalings: The status of the Horizontal Pod Autoscaling addon, which increases or decreases the number of replica pods a replication controller has based on the resource usage of the existing pods. It ensures that a Heapster pod is running in the cluster, which is also used by the Cloud Monitoring service. It is enabled by default; set disabled = true to disable.
        :param Sequence['GetClusterAddonsConfigHttpLoadBalancingArgs'] http_load_balancings: The status of the HTTP (L7) load balancing controller addon, which makes it easy to set up HTTP load balancers for services in a cluster. It is enabled by default; set disabled = true to disable.
        :param Sequence['GetClusterAddonsConfigIstioConfigArgs'] istio_configs: The status of the Istio addon.
        :param Sequence['GetClusterAddonsConfigKalmConfigArgs'] kalm_configs: Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigNetworkPolicyConfigArgs'] network_policy_configs: Whether we should enable the network policy addon for the master. This must be enabled in order to enable network policy for the nodes. To enable this, you must also define a network_policy block, otherwise nothing will happen. It can only be disabled if the nodes already do not have network policies enabled. Defaults to disabled; set disabled = false to enable.
        :param Sequence['GetClusterAddonsConfigRayOperatorConfigArgs'] ray_operator_configs: The status of the Ray Operator addon, which enabled management of Ray AI/ML jobs on GKE. Defaults to disabled; set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigStatefulHaConfigArgs'] stateful_ha_configs: The status of the Stateful HA addon, which provides automatic configurable failover for stateful applications. Defaults to disabled; set enabled = true to enable.
        """
        pulumi.set(__self__, "cloudrun_configs", cloudrun_configs)
        pulumi.set(__self__, "config_connector_configs", config_connector_configs)
        pulumi.set(__self__, "dns_cache_configs", dns_cache_configs)
        pulumi.set(__self__, "gce_persistent_disk_csi_driver_configs", gce_persistent_disk_csi_driver_configs)
        pulumi.set(__self__, "gcp_filestore_csi_driver_configs", gcp_filestore_csi_driver_configs)
        pulumi.set(__self__, "gcs_fuse_csi_driver_configs", gcs_fuse_csi_driver_configs)
        pulumi.set(__self__, "gke_backup_agent_configs", gke_backup_agent_configs)
        pulumi.set(__self__, "horizontal_pod_autoscalings", horizontal_pod_autoscalings)
        pulumi.set(__self__, "http_load_balancings", http_load_balancings)
        pulumi.set(__self__, "istio_configs", istio_configs)
        pulumi.set(__self__, "kalm_configs", kalm_configs)
        pulumi.set(__self__, "network_policy_configs", network_policy_configs)
        pulumi.set(__self__, "ray_operator_configs", ray_operator_configs)
        pulumi.set(__self__, "stateful_ha_configs", stateful_ha_configs)

    @property
    @pulumi.getter(name="cloudrunConfigs")
    def cloudrun_configs(self) -> Sequence['outputs.GetClusterAddonsConfigCloudrunConfigResult']:
        """
        The status of the CloudRun addon. It is disabled by default. Set disabled = false to enable.
        """
        return pulumi.get(self, "cloudrun_configs")

    @property
    @pulumi.getter(name="configConnectorConfigs")
    def config_connector_configs(self) -> Sequence['outputs.GetClusterAddonsConfigConfigConnectorConfigResult']:
        """
        The of the Config Connector addon.
        """
        return pulumi.get(self, "config_connector_configs")

    @property
    @pulumi.getter(name="dnsCacheConfigs")
    def dns_cache_configs(self) -> Sequence['outputs.GetClusterAddonsConfigDnsCacheConfigResult']:
        """
        The status of the NodeLocal DNSCache addon. It is disabled by default. Set enabled = true to enable.
        """
        return pulumi.get(self, "dns_cache_configs")

    @property
    @pulumi.getter(name="gcePersistentDiskCsiDriverConfigs")
    def gce_persistent_disk_csi_driver_configs(self) -> Sequence['outputs.GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigResult']:
        """
        Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set enabled = true to enable. The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        """
        return pulumi.get(self, "gce_persistent_disk_csi_driver_configs")

    @property
    @pulumi.getter(name="gcpFilestoreCsiDriverConfigs")
    def gcp_filestore_csi_driver_configs(self) -> Sequence['outputs.GetClusterAddonsConfigGcpFilestoreCsiDriverConfigResult']:
        """
        The status of the Filestore CSI driver addon, which allows the usage of filestore instance as volumes. Defaults to disabled for Standard clusters; set enabled = true to enable. It is enabled by default for Autopilot clusters; set enabled = true to enable it explicitly.
        """
        return pulumi.get(self, "gcp_filestore_csi_driver_configs")

    @property
    @pulumi.getter(name="gcsFuseCsiDriverConfigs")
    def gcs_fuse_csi_driver_configs(self) -> Sequence['outputs.GetClusterAddonsConfigGcsFuseCsiDriverConfigResult']:
        """
        The status of the GCS Fuse CSI driver addon, which allows the usage of gcs bucket as volumes. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "gcs_fuse_csi_driver_configs")

    @property
    @pulumi.getter(name="gkeBackupAgentConfigs")
    def gke_backup_agent_configs(self) -> Sequence['outputs.GetClusterAddonsConfigGkeBackupAgentConfigResult']:
        """
        The status of the Backup for GKE Agent addon. It is disabled by default. Set enabled = true to enable.
        """
        return pulumi.get(self, "gke_backup_agent_configs")

    @property
    @pulumi.getter(name="horizontalPodAutoscalings")
    def horizontal_pod_autoscalings(self) -> Sequence['outputs.GetClusterAddonsConfigHorizontalPodAutoscalingResult']:
        """
        The status of the Horizontal Pod Autoscaling addon, which increases or decreases the number of replica pods a replication controller has based on the resource usage of the existing pods. It ensures that a Heapster pod is running in the cluster, which is also used by the Cloud Monitoring service. It is enabled by default; set disabled = true to disable.
        """
        return pulumi.get(self, "horizontal_pod_autoscalings")

    @property
    @pulumi.getter(name="httpLoadBalancings")
    def http_load_balancings(self) -> Sequence['outputs.GetClusterAddonsConfigHttpLoadBalancingResult']:
        """
        The status of the HTTP (L7) load balancing controller addon, which makes it easy to set up HTTP load balancers for services in a cluster. It is enabled by default; set disabled = true to disable.
        """
        return pulumi.get(self, "http_load_balancings")

    @property
    @pulumi.getter(name="istioConfigs")
    def istio_configs(self) -> Sequence['outputs.GetClusterAddonsConfigIstioConfigResult']:
        """
        The status of the Istio addon.
        """
        return pulumi.get(self, "istio_configs")

    @property
    @pulumi.getter(name="kalmConfigs")
    def kalm_configs(self) -> Sequence['outputs.GetClusterAddonsConfigKalmConfigResult']:
        """
        Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set enabled = true to enable.
        """
        return pulumi.get(self, "kalm_configs")

    @property
    @pulumi.getter(name="networkPolicyConfigs")
    def network_policy_configs(self) -> Sequence['outputs.GetClusterAddonsConfigNetworkPolicyConfigResult']:
        """
        Whether we should enable the network policy addon for the master. This must be enabled in order to enable network policy for the nodes. To enable this, you must also define a network_policy block, otherwise nothing will happen. It can only be disabled if the nodes already do not have network policies enabled. Defaults to disabled; set disabled = false to enable.
        """
        return pulumi.get(self, "network_policy_configs")

    @property
    @pulumi.getter(name="rayOperatorConfigs")
    def ray_operator_configs(self) -> Sequence['outputs.GetClusterAddonsConfigRayOperatorConfigResult']:
        """
        The status of the Ray Operator addon, which enabled management of Ray AI/ML jobs on GKE. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "ray_operator_configs")

    @property
    @pulumi.getter(name="statefulHaConfigs")
    def stateful_ha_configs(self) -> Sequence['outputs.GetClusterAddonsConfigStatefulHaConfigResult']:
        """
        The status of the Stateful HA addon, which provides automatic configurable failover for stateful applications. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "stateful_ha_configs")


@pulumi.output_type
class GetClusterAddonsConfigCloudrunConfigResult(dict):
    def __init__(__self__, *,
                 disabled: bool,
                 load_balancer_type: str):
        pulumi.set(__self__, "disabled", disabled)
        pulumi.set(__self__, "load_balancer_type", load_balancer_type)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")

    @property
    @pulumi.getter(name="loadBalancerType")
    def load_balancer_type(self) -> str:
        return pulumi.get(self, "load_balancer_type")


@pulumi.output_type
class GetClusterAddonsConfigConfigConnectorConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigDnsCacheConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigGcpFilestoreCsiDriverConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigGcsFuseCsiDriverConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigGkeBackupAgentConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigHorizontalPodAutoscalingResult(dict):
    def __init__(__self__, *,
                 disabled: bool):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterAddonsConfigHttpLoadBalancingResult(dict):
    def __init__(__self__, *,
                 disabled: bool):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterAddonsConfigIstioConfigResult(dict):
    def __init__(__self__, *,
                 auth: str,
                 disabled: bool):
        """
        :param str auth: The authentication type between services in Istio. Available options include AUTH_MUTUAL_TLS.
        :param bool disabled: The status of the Istio addon, which makes it easy to set up Istio for services in a cluster. It is disabled by default. Set disabled = false to enable.
        """
        pulumi.set(__self__, "auth", auth)
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def auth(self) -> str:
        """
        The authentication type between services in Istio. Available options include AUTH_MUTUAL_TLS.
        """
        return pulumi.get(self, "auth")

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        The status of the Istio addon, which makes it easy to set up Istio for services in a cluster. It is disabled by default. Set disabled = false to enable.
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterAddonsConfigKalmConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigNetworkPolicyConfigResult(dict):
    def __init__(__self__, *,
                 disabled: bool):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterAddonsConfigRayOperatorConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 ray_cluster_logging_configs: Sequence['outputs.GetClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigResult'],
                 ray_cluster_monitoring_configs: Sequence['outputs.GetClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigResult']):
        """
        :param Sequence['GetClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgs'] ray_cluster_logging_configs: The status of Ray Logging, which scrapes Ray cluster logs to Cloud Logging. Defaults to disabled; set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgs'] ray_cluster_monitoring_configs: The status of Ray Cluster monitoring, which shows Ray cluster metrics in Cloud Console. Defaults to disabled; set enabled = true to enable.
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "ray_cluster_logging_configs", ray_cluster_logging_configs)
        pulumi.set(__self__, "ray_cluster_monitoring_configs", ray_cluster_monitoring_configs)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="rayClusterLoggingConfigs")
    def ray_cluster_logging_configs(self) -> Sequence['outputs.GetClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigResult']:
        """
        The status of Ray Logging, which scrapes Ray cluster logs to Cloud Logging. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "ray_cluster_logging_configs")

    @property
    @pulumi.getter(name="rayClusterMonitoringConfigs")
    def ray_cluster_monitoring_configs(self) -> Sequence['outputs.GetClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigResult']:
        """
        The status of Ray Cluster monitoring, which shows Ray cluster metrics in Cloud Console. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "ray_cluster_monitoring_configs")


@pulumi.output_type
class GetClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigStatefulHaConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAuthenticatorGroupsConfigResult(dict):
    def __init__(__self__, *,
                 security_group: str):
        """
        :param str security_group: The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format gke-security-groups@yourdomain.com.
        """
        pulumi.set(__self__, "security_group", security_group)

    @property
    @pulumi.getter(name="securityGroup")
    def security_group(self) -> str:
        """
        The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format gke-security-groups@yourdomain.com.
        """
        return pulumi.get(self, "security_group")


@pulumi.output_type
class GetClusterBinaryAuthorizationResult(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 evaluation_mode: str):
        """
        :param bool enabled: Enable Binary Authorization for this cluster.
        :param str evaluation_mode: Mode of operation for Binary Authorization policy evaluation.
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Binary Authorization for this cluster.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> str:
        """
        Mode of operation for Binary Authorization policy evaluation.
        """
        return pulumi.get(self, "evaluation_mode")


@pulumi.output_type
class GetClusterClusterAutoscalingResult(dict):
    def __init__(__self__, *,
                 auto_provisioning_defaults: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultResult'],
                 auto_provisioning_locations: Sequence[str],
                 autoscaling_profile: str,
                 enabled: bool,
                 resource_limits: Sequence['outputs.GetClusterClusterAutoscalingResourceLimitResult']):
        """
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultArgs'] auto_provisioning_defaults: Contains defaults for a node pool created by NAP.
        :param Sequence[str] auto_provisioning_locations: The list of Google Compute Engine zones in which the NodePool's nodes can be created by NAP.
        :param str autoscaling_profile: Configuration options for the Autoscaling profile feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability when deciding to remove nodes from a cluster. Can be BALANCED or OPTIMIZE_UTILIZATION. Defaults to BALANCED.
        :param bool enabled: Whether node auto-provisioning is enabled. Resource limits for cpu and memory must be defined to enable node auto-provisioning.
        :param Sequence['GetClusterClusterAutoscalingResourceLimitArgs'] resource_limits: Global constraints for machine resources in the cluster. Configuring the cpu and memory types is required if node auto-provisioning is enabled. These limits will apply to node pool autoscaling in addition to node auto-provisioning.
        """
        pulumi.set(__self__, "auto_provisioning_defaults", auto_provisioning_defaults)
        pulumi.set(__self__, "auto_provisioning_locations", auto_provisioning_locations)
        pulumi.set(__self__, "autoscaling_profile", autoscaling_profile)
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "resource_limits", resource_limits)

    @property
    @pulumi.getter(name="autoProvisioningDefaults")
    def auto_provisioning_defaults(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultResult']:
        """
        Contains defaults for a node pool created by NAP.
        """
        return pulumi.get(self, "auto_provisioning_defaults")

    @property
    @pulumi.getter(name="autoProvisioningLocations")
    def auto_provisioning_locations(self) -> Sequence[str]:
        """
        The list of Google Compute Engine zones in which the NodePool's nodes can be created by NAP.
        """
        return pulumi.get(self, "auto_provisioning_locations")

    @property
    @pulumi.getter(name="autoscalingProfile")
    def autoscaling_profile(self) -> str:
        """
        Configuration options for the Autoscaling profile feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability when deciding to remove nodes from a cluster. Can be BALANCED or OPTIMIZE_UTILIZATION. Defaults to BALANCED.
        """
        return pulumi.get(self, "autoscaling_profile")

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether node auto-provisioning is enabled. Resource limits for cpu and memory must be defined to enable node auto-provisioning.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="resourceLimits")
    def resource_limits(self) -> Sequence['outputs.GetClusterClusterAutoscalingResourceLimitResult']:
        """
        Global constraints for machine resources in the cluster. Configuring the cpu and memory types is required if node auto-provisioning is enabled. These limits will apply to node pool autoscaling in addition to node auto-provisioning.
        """
        return pulumi.get(self, "resource_limits")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultResult(dict):
    def __init__(__self__, *,
                 boot_disk_kms_key: str,
                 disk_size: int,
                 disk_type: str,
                 image_type: str,
                 managements: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultManagementResult'],
                 min_cpu_platform: str,
                 oauth_scopes: Sequence[str],
                 service_account: str,
                 shielded_instance_configs: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigResult'],
                 upgrade_settings: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingResult']):
        """
        :param str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        :param int disk_size: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        :param str disk_type: Type of the disk attached to each node.
        :param str image_type: The default image type used by NAP once a new node pool is being created.
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultManagementArgs'] managements: NodeManagement configuration for this NodePool.
        :param str min_cpu_platform: Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such as Intel Haswell.
        :param Sequence[str] oauth_scopes: Scopes that are used by NAP when creating node pools.
        :param str service_account: The Google Cloud Platform Service Account to be used by the node VMs.
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigArgs'] shielded_instance_configs: Shielded Instance options.
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingArgs'] upgrade_settings: Specifies the upgrade settings for NAP created node pools
        """
        pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        pulumi.set(__self__, "disk_size", disk_size)
        pulumi.set(__self__, "disk_type", disk_type)
        pulumi.set(__self__, "image_type", image_type)
        pulumi.set(__self__, "managements", managements)
        pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        pulumi.set(__self__, "service_account", service_account)
        pulumi.set(__self__, "shielded_instance_configs", shielded_instance_configs)
        pulumi.set(__self__, "upgrade_settings", upgrade_settings)

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> str:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="diskSize")
    def disk_size(self) -> int:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        return pulumi.get(self, "disk_size")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> str:
        """
        Type of the disk attached to each node.
        """
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> str:
        """
        The default image type used by NAP once a new node pool is being created.
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter
    def managements(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultManagementResult']:
        """
        NodeManagement configuration for this NodePool.
        """
        return pulumi.get(self, "managements")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> str:
        """
        Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such as Intel Haswell.
        """
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Sequence[str]:
        """
        Scopes that are used by NAP when creating node pools.
        """
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> str:
        """
        The Google Cloud Platform Service Account to be used by the node VMs.
        """
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfigs")
    def shielded_instance_configs(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigResult']:
        """
        Shielded Instance options.
        """
        return pulumi.get(self, "shielded_instance_configs")

    @property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingResult']:
        """
        Specifies the upgrade settings for NAP created node pools
        """
        return pulumi.get(self, "upgrade_settings")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultManagementResult(dict):
    def __init__(__self__, *,
                 auto_repair: bool,
                 auto_upgrade: bool,
                 upgrade_options: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionResult']):
        """
        :param bool auto_repair: Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
        :param bool auto_upgrade: Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionArgs'] upgrade_options: Specifies the Auto Upgrade knobs for the node pool.
        """
        pulumi.set(__self__, "auto_repair", auto_repair)
        pulumi.set(__self__, "auto_upgrade", auto_upgrade)
        pulumi.set(__self__, "upgrade_options", upgrade_options)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> bool:
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
        """
        return pulumi.get(self, "auto_repair")

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> bool:
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        return pulumi.get(self, "auto_upgrade")

    @property
    @pulumi.getter(name="upgradeOptions")
    def upgrade_options(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionResult']:
        """
        Specifies the Auto Upgrade knobs for the node pool.
        """
        return pulumi.get(self, "upgrade_options")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionResult(dict):
    def __init__(__self__, *,
                 auto_upgrade_start_time: str,
                 description: str):
        """
        :param str auto_upgrade_start_time: This field is set when upgrades are about to commence with the approximate start time for the upgrades, in RFC3339 text format.
        :param str description: This field is set when upgrades are about to commence with the description of the upgrade.
        """
        pulumi.set(__self__, "auto_upgrade_start_time", auto_upgrade_start_time)
        pulumi.set(__self__, "description", description)

    @property
    @pulumi.getter(name="autoUpgradeStartTime")
    def auto_upgrade_start_time(self) -> str:
        """
        This field is set when upgrades are about to commence with the approximate start time for the upgrades, in RFC3339 text format.
        """
        return pulumi.get(self, "auto_upgrade_start_time")

    @property
    @pulumi.getter
    def description(self) -> str:
        """
        This field is set when upgrades are about to commence with the description of the upgrade.
        """
        return pulumi.get(self, "description")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigResult(dict):
    def __init__(__self__, *,
                 enable_integrity_monitoring: bool,
                 enable_secure_boot: bool):
        """
        :param bool enable_integrity_monitoring: Defines whether the instance has integrity monitoring enabled.
        :param bool enable_secure_boot: Defines whether the instance has Secure Boot enabled.
        """
        pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> bool:
        """
        Defines whether the instance has integrity monitoring enabled.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> bool:
        """
        Defines whether the instance has Secure Boot enabled.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingResult(dict):
    def __init__(__self__, *,
                 blue_green_settings: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingResult'],
                 max_surge: int,
                 max_unavailable: int,
                 strategy: str):
        """
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingArgs'] blue_green_settings: Settings for blue-green upgrade strategy.
        :param int max_surge: The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process.
        :param int max_unavailable: The maximum number of nodes that can be simultaneously unavailable during the upgrade process.
        :param str strategy: Update strategy of the node pool.
        """
        pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        pulumi.set(__self__, "max_surge", max_surge)
        pulumi.set(__self__, "max_unavailable", max_unavailable)
        pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingResult']:
        """
        Settings for blue-green upgrade strategy.
        """
        return pulumi.get(self, "blue_green_settings")

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> int:
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process.
        """
        return pulumi.get(self, "max_surge")

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> int:
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process.
        """
        return pulumi.get(self, "max_unavailable")

    @property
    @pulumi.getter
    def strategy(self) -> str:
        """
        Update strategy of the node pool.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingResult(dict):
    def __init__(__self__, *,
                 node_pool_soak_duration: str,
                 standard_rollout_policies: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult']):
        """
        :param str node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up.
               
               																A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyArgs'] standard_rollout_policies: Standard policy for the blue-green upgrade.
        """
        pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        pulumi.set(__self__, "standard_rollout_policies", standard_rollout_policies)

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> str:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up.

        																A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @property
    @pulumi.getter(name="standardRolloutPolicies")
    def standard_rollout_policies(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult']:
        """
        Standard policy for the blue-green upgrade.
        """
        return pulumi.get(self, "standard_rollout_policies")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult(dict):
    def __init__(__self__, *,
                 batch_node_count: int,
                 batch_percentage: float,
                 batch_soak_duration: str):
        """
        :param int batch_node_count: Number of blue nodes to drain in a batch.
        :param float batch_percentage: Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0].
        :param str batch_soak_duration: Soak time after each batch gets drained.
               
               																			A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        pulumi.set(__self__, "batch_node_count", batch_node_count)
        pulumi.set(__self__, "batch_percentage", batch_percentage)
        pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> int:
        """
        Number of blue nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_node_count")

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> float:
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0].
        """
        return pulumi.get(self, "batch_percentage")

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> str:
        """
        Soak time after each batch gets drained.

        																			A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class GetClusterClusterAutoscalingResourceLimitResult(dict):
    def __init__(__self__, *,
                 maximum: int,
                 minimum: int,
                 resource_type: str):
        """
        :param int maximum: Maximum amount of the resource in the cluster.
        :param int minimum: Minimum amount of the resource in the cluster.
        :param str resource_type: The type of the resource. For example, cpu and memory. See the guide to using Node Auto-Provisioning for a list of types.
        """
        pulumi.set(__self__, "maximum", maximum)
        pulumi.set(__self__, "minimum", minimum)
        pulumi.set(__self__, "resource_type", resource_type)

    @property
    @pulumi.getter
    def maximum(self) -> int:
        """
        Maximum amount of the resource in the cluster.
        """
        return pulumi.get(self, "maximum")

    @property
    @pulumi.getter
    def minimum(self) -> int:
        """
        Minimum amount of the resource in the cluster.
        """
        return pulumi.get(self, "minimum")

    @property
    @pulumi.getter(name="resourceType")
    def resource_type(self) -> str:
        """
        The type of the resource. For example, cpu and memory. See the guide to using Node Auto-Provisioning for a list of types.
        """
        return pulumi.get(self, "resource_type")


@pulumi.output_type
class GetClusterClusterTelemetryResult(dict):
    def __init__(__self__, *,
                 type: str):
        """
        :param str type: Type of the integration.
        """
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        Type of the integration.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterConfidentialNodeResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether Confidential Nodes feature is enabled for all nodes in this cluster.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether Confidential Nodes feature is enabled for all nodes in this cluster.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterCostManagementConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether to enable GKE cost allocation. When you enable GKE cost allocation, the cluster name and namespace of your GKE workloads appear in the labels field of the billing export to BigQuery. Defaults to false.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether to enable GKE cost allocation. When you enable GKE cost allocation, the cluster name and namespace of your GKE workloads appear in the labels field of the billing export to BigQuery. Defaults to false.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterDatabaseEncryptionResult(dict):
    def __init__(__self__, *,
                 key_name: str,
                 state: str):
        """
        :param str key_name: The key to use to encrypt/decrypt secrets.
        :param str state: ENCRYPTED or DECRYPTED.
        """
        pulumi.set(__self__, "key_name", key_name)
        pulumi.set(__self__, "state", state)

    @property
    @pulumi.getter(name="keyName")
    def key_name(self) -> str:
        """
        The key to use to encrypt/decrypt secrets.
        """
        return pulumi.get(self, "key_name")

    @property
    @pulumi.getter
    def state(self) -> str:
        """
        ENCRYPTED or DECRYPTED.
        """
        return pulumi.get(self, "state")


@pulumi.output_type
class GetClusterDefaultSnatStatusResult(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic.
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic.
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterDnsConfigResult(dict):
    def __init__(__self__, *,
                 additive_vpc_scope_dns_domain: str,
                 cluster_dns: str,
                 cluster_dns_domain: str,
                 cluster_dns_scope: str):
        """
        :param str additive_vpc_scope_dns_domain: Enable additive VPC scope DNS in a GKE cluster.
        :param str cluster_dns: Which in-cluster DNS provider should be used.
        :param str cluster_dns_domain: The suffix used for all cluster service records.
        :param str cluster_dns_scope: The scope of access to cluster DNS records.
        """
        pulumi.set(__self__, "additive_vpc_scope_dns_domain", additive_vpc_scope_dns_domain)
        pulumi.set(__self__, "cluster_dns", cluster_dns)
        pulumi.set(__self__, "cluster_dns_domain", cluster_dns_domain)
        pulumi.set(__self__, "cluster_dns_scope", cluster_dns_scope)

    @property
    @pulumi.getter(name="additiveVpcScopeDnsDomain")
    def additive_vpc_scope_dns_domain(self) -> str:
        """
        Enable additive VPC scope DNS in a GKE cluster.
        """
        return pulumi.get(self, "additive_vpc_scope_dns_domain")

    @property
    @pulumi.getter(name="clusterDns")
    def cluster_dns(self) -> str:
        """
        Which in-cluster DNS provider should be used.
        """
        return pulumi.get(self, "cluster_dns")

    @property
    @pulumi.getter(name="clusterDnsDomain")
    def cluster_dns_domain(self) -> str:
        """
        The suffix used for all cluster service records.
        """
        return pulumi.get(self, "cluster_dns_domain")

    @property
    @pulumi.getter(name="clusterDnsScope")
    def cluster_dns_scope(self) -> str:
        """
        The scope of access to cluster DNS records.
        """
        return pulumi.get(self, "cluster_dns_scope")


@pulumi.output_type
class GetClusterEnableK8sBetaApiResult(dict):
    def __init__(__self__, *,
                 enabled_apis: Sequence[str]):
        """
        :param Sequence[str] enabled_apis: Enabled Kubernetes Beta APIs.
        """
        pulumi.set(__self__, "enabled_apis", enabled_apis)

    @property
    @pulumi.getter(name="enabledApis")
    def enabled_apis(self) -> Sequence[str]:
        """
        Enabled Kubernetes Beta APIs.
        """
        return pulumi.get(self, "enabled_apis")


@pulumi.output_type
class GetClusterFleetResult(dict):
    def __init__(__self__, *,
                 membership: str,
                 membership_id: str,
                 membership_location: str,
                 pre_registered: bool,
                 project: str):
        """
        :param str membership: Full resource name of the registered fleet membership of the cluster.
        :param str membership_id: Short name of the fleet membership, for example "member-1".
        :param str membership_location: Location of the fleet membership, for example "us-central1".
        :param bool pre_registered: Whether the cluster has been registered via the fleet API.
        :param str project: The project in which the resource belongs. If it
               is not provided, the provider project is used.
        """
        pulumi.set(__self__, "membership", membership)
        pulumi.set(__self__, "membership_id", membership_id)
        pulumi.set(__self__, "membership_location", membership_location)
        pulumi.set(__self__, "pre_registered", pre_registered)
        pulumi.set(__self__, "project", project)

    @property
    @pulumi.getter
    def membership(self) -> str:
        """
        Full resource name of the registered fleet membership of the cluster.
        """
        return pulumi.get(self, "membership")

    @property
    @pulumi.getter(name="membershipId")
    def membership_id(self) -> str:
        """
        Short name of the fleet membership, for example "member-1".
        """
        return pulumi.get(self, "membership_id")

    @property
    @pulumi.getter(name="membershipLocation")
    def membership_location(self) -> str:
        """
        Location of the fleet membership, for example "us-central1".
        """
        return pulumi.get(self, "membership_location")

    @property
    @pulumi.getter(name="preRegistered")
    def pre_registered(self) -> bool:
        """
        Whether the cluster has been registered via the fleet API.
        """
        return pulumi.get(self, "pre_registered")

    @property
    @pulumi.getter
    def project(self) -> str:
        """
        The project in which the resource belongs. If it
        is not provided, the provider project is used.
        """
        return pulumi.get(self, "project")


@pulumi.output_type
class GetClusterGatewayApiConfigResult(dict):
    def __init__(__self__, *,
                 channel: str):
        """
        :param str channel: The Gateway API release channel to use for Gateway API.
        """
        pulumi.set(__self__, "channel", channel)

    @property
    @pulumi.getter
    def channel(self) -> str:
        """
        The Gateway API release channel to use for Gateway API.
        """
        return pulumi.get(self, "channel")


@pulumi.output_type
class GetClusterIdentityServiceConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether to enable the Identity Service component.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether to enable the Identity Service component.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterIpAllocationPolicyResult(dict):
    def __init__(__self__, *,
                 additional_pod_ranges_configs: Sequence['outputs.GetClusterIpAllocationPolicyAdditionalPodRangesConfigResult'],
                 cluster_ipv4_cidr_block: str,
                 cluster_secondary_range_name: str,
                 pod_cidr_overprovision_configs: Sequence['outputs.GetClusterIpAllocationPolicyPodCidrOverprovisionConfigResult'],
                 services_ipv4_cidr_block: str,
                 services_secondary_range_name: str,
                 stack_type: str):
        """
        :param Sequence['GetClusterIpAllocationPolicyAdditionalPodRangesConfigArgs'] additional_pod_ranges_configs: AdditionalPodRangesConfig is the configuration for additional pod secondary ranges supporting the ClusterUpdate message.
        :param str cluster_ipv4_cidr_block: The IP address range for the cluster pod IPs. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to pick a specific range to use.
        :param str cluster_secondary_range_name: The name of the existing secondary range in the cluster's subnetwork to use for pod IP addresses. Alternatively, cluster_ipv4_cidr_block can be used to automatically create a GKE-managed one.
        :param Sequence['GetClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs'] pod_cidr_overprovision_configs: Configuration for cluster level pod cidr overprovision. Default is disabled=false.
        :param str services_ipv4_cidr_block: The IP address range of the services IPs in this cluster. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to pick a specific range to use.
        :param str services_secondary_range_name: The name of the existing secondary range in the cluster's subnetwork to use for service ClusterIPs. Alternatively, services_ipv4_cidr_block can be used to automatically create a GKE-managed one.
        :param str stack_type: The IP Stack type of the cluster. Choose between IPV4 and IPV4_IPV6. Default type is IPV4 Only if not set
        """
        pulumi.set(__self__, "additional_pod_ranges_configs", additional_pod_ranges_configs)
        pulumi.set(__self__, "cluster_ipv4_cidr_block", cluster_ipv4_cidr_block)
        pulumi.set(__self__, "cluster_secondary_range_name", cluster_secondary_range_name)
        pulumi.set(__self__, "pod_cidr_overprovision_configs", pod_cidr_overprovision_configs)
        pulumi.set(__self__, "services_ipv4_cidr_block", services_ipv4_cidr_block)
        pulumi.set(__self__, "services_secondary_range_name", services_secondary_range_name)
        pulumi.set(__self__, "stack_type", stack_type)

    @property
    @pulumi.getter(name="additionalPodRangesConfigs")
    def additional_pod_ranges_configs(self) -> Sequence['outputs.GetClusterIpAllocationPolicyAdditionalPodRangesConfigResult']:
        """
        AdditionalPodRangesConfig is the configuration for additional pod secondary ranges supporting the ClusterUpdate message.
        """
        return pulumi.get(self, "additional_pod_ranges_configs")

    @property
    @pulumi.getter(name="clusterIpv4CidrBlock")
    def cluster_ipv4_cidr_block(self) -> str:
        """
        The IP address range for the cluster pod IPs. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to pick a specific range to use.
        """
        return pulumi.get(self, "cluster_ipv4_cidr_block")

    @property
    @pulumi.getter(name="clusterSecondaryRangeName")
    def cluster_secondary_range_name(self) -> str:
        """
        The name of the existing secondary range in the cluster's subnetwork to use for pod IP addresses. Alternatively, cluster_ipv4_cidr_block can be used to automatically create a GKE-managed one.
        """
        return pulumi.get(self, "cluster_secondary_range_name")

    @property
    @pulumi.getter(name="podCidrOverprovisionConfigs")
    def pod_cidr_overprovision_configs(self) -> Sequence['outputs.GetClusterIpAllocationPolicyPodCidrOverprovisionConfigResult']:
        """
        Configuration for cluster level pod cidr overprovision. Default is disabled=false.
        """
        return pulumi.get(self, "pod_cidr_overprovision_configs")

    @property
    @pulumi.getter(name="servicesIpv4CidrBlock")
    def services_ipv4_cidr_block(self) -> str:
        """
        The IP address range of the services IPs in this cluster. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to pick a specific range to use.
        """
        return pulumi.get(self, "services_ipv4_cidr_block")

    @property
    @pulumi.getter(name="servicesSecondaryRangeName")
    def services_secondary_range_name(self) -> str:
        """
        The name of the existing secondary range in the cluster's subnetwork to use for service ClusterIPs. Alternatively, services_ipv4_cidr_block can be used to automatically create a GKE-managed one.
        """
        return pulumi.get(self, "services_secondary_range_name")

    @property
    @pulumi.getter(name="stackType")
    def stack_type(self) -> str:
        """
        The IP Stack type of the cluster. Choose between IPV4 and IPV4_IPV6. Default type is IPV4 Only if not set
        """
        return pulumi.get(self, "stack_type")


@pulumi.output_type
class GetClusterIpAllocationPolicyAdditionalPodRangesConfigResult(dict):
    def __init__(__self__, *,
                 pod_range_names: Sequence[str]):
        """
        :param Sequence[str] pod_range_names: Name for pod secondary ipv4 range which has the actual range defined ahead.
        """
        pulumi.set(__self__, "pod_range_names", pod_range_names)

    @property
    @pulumi.getter(name="podRangeNames")
    def pod_range_names(self) -> Sequence[str]:
        """
        Name for pod secondary ipv4 range which has the actual range defined ahead.
        """
        return pulumi.get(self, "pod_range_names")


@pulumi.output_type
class GetClusterIpAllocationPolicyPodCidrOverprovisionConfigResult(dict):
    def __init__(__self__, *,
                 disabled: bool):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterLoggingConfigResult(dict):
    def __init__(__self__, *,
                 enable_components: Sequence[str]):
        """
        :param Sequence[str] enable_components: GKE components exposing logs. Valid values include SYSTEM_COMPONENTS, APISERVER, CONTROLLER_MANAGER, KCP_CONNECTION, KCP_SSHD, SCHEDULER, and WORKLOADS.
        """
        pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Sequence[str]:
        """
        GKE components exposing logs. Valid values include SYSTEM_COMPONENTS, APISERVER, CONTROLLER_MANAGER, KCP_CONNECTION, KCP_SSHD, SCHEDULER, and WORKLOADS.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class GetClusterMaintenancePolicyResult(dict):
    def __init__(__self__, *,
                 daily_maintenance_windows: Sequence['outputs.GetClusterMaintenancePolicyDailyMaintenanceWindowResult'],
                 maintenance_exclusions: Sequence['outputs.GetClusterMaintenancePolicyMaintenanceExclusionResult'],
                 recurring_windows: Sequence['outputs.GetClusterMaintenancePolicyRecurringWindowResult']):
        """
        :param Sequence['GetClusterMaintenancePolicyDailyMaintenanceWindowArgs'] daily_maintenance_windows: Time window specified for daily maintenance operations. Specify start_time in RFC3339 format "HH:MM, where HH : [00-23] and MM : [00-59] GMT.
        :param Sequence['GetClusterMaintenancePolicyMaintenanceExclusionArgs'] maintenance_exclusions: Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows.
        :param Sequence['GetClusterMaintenancePolicyRecurringWindowArgs'] recurring_windows: Time window for recurring maintenance operations.
        """
        pulumi.set(__self__, "daily_maintenance_windows", daily_maintenance_windows)
        pulumi.set(__self__, "maintenance_exclusions", maintenance_exclusions)
        pulumi.set(__self__, "recurring_windows", recurring_windows)

    @property
    @pulumi.getter(name="dailyMaintenanceWindows")
    def daily_maintenance_windows(self) -> Sequence['outputs.GetClusterMaintenancePolicyDailyMaintenanceWindowResult']:
        """
        Time window specified for daily maintenance operations. Specify start_time in RFC3339 format "HH:MM, where HH : [00-23] and MM : [00-59] GMT.
        """
        return pulumi.get(self, "daily_maintenance_windows")

    @property
    @pulumi.getter(name="maintenanceExclusions")
    def maintenance_exclusions(self) -> Sequence['outputs.GetClusterMaintenancePolicyMaintenanceExclusionResult']:
        """
        Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows.
        """
        return pulumi.get(self, "maintenance_exclusions")

    @property
    @pulumi.getter(name="recurringWindows")
    def recurring_windows(self) -> Sequence['outputs.GetClusterMaintenancePolicyRecurringWindowResult']:
        """
        Time window for recurring maintenance operations.
        """
        return pulumi.get(self, "recurring_windows")


@pulumi.output_type
class GetClusterMaintenancePolicyDailyMaintenanceWindowResult(dict):
    def __init__(__self__, *,
                 duration: str,
                 start_time: str):
        pulumi.set(__self__, "duration", duration)
        pulumi.set(__self__, "start_time", start_time)

    @property
    @pulumi.getter
    def duration(self) -> str:
        return pulumi.get(self, "duration")

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> str:
        return pulumi.get(self, "start_time")


@pulumi.output_type
class GetClusterMaintenancePolicyMaintenanceExclusionResult(dict):
    def __init__(__self__, *,
                 end_time: str,
                 exclusion_name: str,
                 exclusion_options: Sequence['outputs.GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionResult'],
                 start_time: str):
        """
        :param Sequence['GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionArgs'] exclusion_options: Maintenance exclusion related options.
        """
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "exclusion_name", exclusion_name)
        pulumi.set(__self__, "exclusion_options", exclusion_options)
        pulumi.set(__self__, "start_time", start_time)

    @property
    @pulumi.getter(name="endTime")
    def end_time(self) -> str:
        return pulumi.get(self, "end_time")

    @property
    @pulumi.getter(name="exclusionName")
    def exclusion_name(self) -> str:
        return pulumi.get(self, "exclusion_name")

    @property
    @pulumi.getter(name="exclusionOptions")
    def exclusion_options(self) -> Sequence['outputs.GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionResult']:
        """
        Maintenance exclusion related options.
        """
        return pulumi.get(self, "exclusion_options")

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> str:
        return pulumi.get(self, "start_time")


@pulumi.output_type
class GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionResult(dict):
    def __init__(__self__, *,
                 scope: str):
        """
        :param str scope: The scope of automatic upgrades to restrict in the exclusion window.
        """
        pulumi.set(__self__, "scope", scope)

    @property
    @pulumi.getter
    def scope(self) -> str:
        """
        The scope of automatic upgrades to restrict in the exclusion window.
        """
        return pulumi.get(self, "scope")


@pulumi.output_type
class GetClusterMaintenancePolicyRecurringWindowResult(dict):
    def __init__(__self__, *,
                 end_time: str,
                 recurrence: str,
                 start_time: str):
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "recurrence", recurrence)
        pulumi.set(__self__, "start_time", start_time)

    @property
    @pulumi.getter(name="endTime")
    def end_time(self) -> str:
        return pulumi.get(self, "end_time")

    @property
    @pulumi.getter
    def recurrence(self) -> str:
        return pulumi.get(self, "recurrence")

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> str:
        return pulumi.get(self, "start_time")


@pulumi.output_type
class GetClusterMasterAuthResult(dict):
    def __init__(__self__, *,
                 client_certificate: str,
                 client_certificate_configs: Sequence['outputs.GetClusterMasterAuthClientCertificateConfigResult'],
                 client_key: str,
                 cluster_ca_certificate: str):
        """
        :param str client_certificate: Base64 encoded public certificate used by clients to authenticate to the cluster endpoint.
        :param Sequence['GetClusterMasterAuthClientCertificateConfigArgs'] client_certificate_configs: Whether client certificate authorization is enabled for this cluster.
        :param str client_key: Base64 encoded private key used by clients to authenticate to the cluster endpoint.
        :param str cluster_ca_certificate: Base64 encoded public certificate that is the root of trust for the cluster.
        """
        pulumi.set(__self__, "client_certificate", client_certificate)
        pulumi.set(__self__, "client_certificate_configs", client_certificate_configs)
        pulumi.set(__self__, "client_key", client_key)
        pulumi.set(__self__, "cluster_ca_certificate", cluster_ca_certificate)

    @property
    @pulumi.getter(name="clientCertificate")
    def client_certificate(self) -> str:
        """
        Base64 encoded public certificate used by clients to authenticate to the cluster endpoint.
        """
        return pulumi.get(self, "client_certificate")

    @property
    @pulumi.getter(name="clientCertificateConfigs")
    def client_certificate_configs(self) -> Sequence['outputs.GetClusterMasterAuthClientCertificateConfigResult']:
        """
        Whether client certificate authorization is enabled for this cluster.
        """
        return pulumi.get(self, "client_certificate_configs")

    @property
    @pulumi.getter(name="clientKey")
    def client_key(self) -> str:
        """
        Base64 encoded private key used by clients to authenticate to the cluster endpoint.
        """
        return pulumi.get(self, "client_key")

    @property
    @pulumi.getter(name="clusterCaCertificate")
    def cluster_ca_certificate(self) -> str:
        """
        Base64 encoded public certificate that is the root of trust for the cluster.
        """
        return pulumi.get(self, "cluster_ca_certificate")


@pulumi.output_type
class GetClusterMasterAuthClientCertificateConfigResult(dict):
    def __init__(__self__, *,
                 issue_client_certificate: bool):
        """
        :param bool issue_client_certificate: Whether client certificate authorization is enabled for this cluster.
        """
        pulumi.set(__self__, "issue_client_certificate", issue_client_certificate)

    @property
    @pulumi.getter(name="issueClientCertificate")
    def issue_client_certificate(self) -> bool:
        """
        Whether client certificate authorization is enabled for this cluster.
        """
        return pulumi.get(self, "issue_client_certificate")


@pulumi.output_type
class GetClusterMasterAuthorizedNetworksConfigResult(dict):
    def __init__(__self__, *,
                 cidr_blocks: Sequence['outputs.GetClusterMasterAuthorizedNetworksConfigCidrBlockResult'],
                 gcp_public_cidrs_access_enabled: bool):
        """
        :param Sequence['GetClusterMasterAuthorizedNetworksConfigCidrBlockArgs'] cidr_blocks: External networks that can access the Kubernetes cluster master through HTTPS.
        :param bool gcp_public_cidrs_access_enabled: Whether Kubernetes master is accessible via Google Compute Engine Public IPs.
        """
        pulumi.set(__self__, "cidr_blocks", cidr_blocks)
        pulumi.set(__self__, "gcp_public_cidrs_access_enabled", gcp_public_cidrs_access_enabled)

    @property
    @pulumi.getter(name="cidrBlocks")
    def cidr_blocks(self) -> Sequence['outputs.GetClusterMasterAuthorizedNetworksConfigCidrBlockResult']:
        """
        External networks that can access the Kubernetes cluster master through HTTPS.
        """
        return pulumi.get(self, "cidr_blocks")

    @property
    @pulumi.getter(name="gcpPublicCidrsAccessEnabled")
    def gcp_public_cidrs_access_enabled(self) -> bool:
        """
        Whether Kubernetes master is accessible via Google Compute Engine Public IPs.
        """
        return pulumi.get(self, "gcp_public_cidrs_access_enabled")


@pulumi.output_type
class GetClusterMasterAuthorizedNetworksConfigCidrBlockResult(dict):
    def __init__(__self__, *,
                 cidr_block: str,
                 display_name: str):
        """
        :param str cidr_block: External network that can access Kubernetes master through HTTPS. Must be specified in CIDR notation.
        :param str display_name: Field for users to identify CIDR blocks.
        """
        pulumi.set(__self__, "cidr_block", cidr_block)
        pulumi.set(__self__, "display_name", display_name)

    @property
    @pulumi.getter(name="cidrBlock")
    def cidr_block(self) -> str:
        """
        External network that can access Kubernetes master through HTTPS. Must be specified in CIDR notation.
        """
        return pulumi.get(self, "cidr_block")

    @property
    @pulumi.getter(name="displayName")
    def display_name(self) -> str:
        """
        Field for users to identify CIDR blocks.
        """
        return pulumi.get(self, "display_name")


@pulumi.output_type
class GetClusterMeshCertificateResult(dict):
    def __init__(__self__, *,
                 enable_certificates: bool):
        """
        :param bool enable_certificates: When enabled the GKE Workload Identity Certificates controller and node agent will be deployed in the cluster.
        """
        pulumi.set(__self__, "enable_certificates", enable_certificates)

    @property
    @pulumi.getter(name="enableCertificates")
    def enable_certificates(self) -> bool:
        """
        When enabled the GKE Workload Identity Certificates controller and node agent will be deployed in the cluster.
        """
        return pulumi.get(self, "enable_certificates")


@pulumi.output_type
class GetClusterMonitoringConfigResult(dict):
    def __init__(__self__, *,
                 advanced_datapath_observability_configs: Sequence['outputs.GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigResult'],
                 enable_components: Sequence[str],
                 managed_prometheuses: Sequence['outputs.GetClusterMonitoringConfigManagedPrometheusResult']):
        """
        :param Sequence['GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs'] advanced_datapath_observability_configs: Configuration of Advanced Datapath Observability features.
        :param Sequence[str] enable_components: GKE components exposing metrics. Valid values include SYSTEM_COMPONENTS, APISERVER, SCHEDULER, CONTROLLER_MANAGER, STORAGE, HPA, POD, DAEMONSET, DEPLOYMENT, STATEFULSET, WORKLOADS, KUBELET, CADVISOR and DCGM.
        :param Sequence['GetClusterMonitoringConfigManagedPrometheusArgs'] managed_prometheuses: Configuration for Google Cloud Managed Services for Prometheus.
        """
        pulumi.set(__self__, "advanced_datapath_observability_configs", advanced_datapath_observability_configs)
        pulumi.set(__self__, "enable_components", enable_components)
        pulumi.set(__self__, "managed_prometheuses", managed_prometheuses)

    @property
    @pulumi.getter(name="advancedDatapathObservabilityConfigs")
    def advanced_datapath_observability_configs(self) -> Sequence['outputs.GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigResult']:
        """
        Configuration of Advanced Datapath Observability features.
        """
        return pulumi.get(self, "advanced_datapath_observability_configs")

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Sequence[str]:
        """
        GKE components exposing metrics. Valid values include SYSTEM_COMPONENTS, APISERVER, SCHEDULER, CONTROLLER_MANAGER, STORAGE, HPA, POD, DAEMONSET, DEPLOYMENT, STATEFULSET, WORKLOADS, KUBELET, CADVISOR and DCGM.
        """
        return pulumi.get(self, "enable_components")

    @property
    @pulumi.getter(name="managedPrometheuses")
    def managed_prometheuses(self) -> Sequence['outputs.GetClusterMonitoringConfigManagedPrometheusResult']:
        """
        Configuration for Google Cloud Managed Services for Prometheus.
        """
        return pulumi.get(self, "managed_prometheuses")


@pulumi.output_type
class GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigResult(dict):
    def __init__(__self__, *,
                 enable_metrics: bool,
                 enable_relay: bool):
        """
        :param bool enable_metrics: Whether or not the advanced datapath metrics are enabled.
        :param bool enable_relay: Whether or not Relay is enabled.
        """
        pulumi.set(__self__, "enable_metrics", enable_metrics)
        pulumi.set(__self__, "enable_relay", enable_relay)

    @property
    @pulumi.getter(name="enableMetrics")
    def enable_metrics(self) -> bool:
        """
        Whether or not the advanced datapath metrics are enabled.
        """
        return pulumi.get(self, "enable_metrics")

    @property
    @pulumi.getter(name="enableRelay")
    def enable_relay(self) -> bool:
        """
        Whether or not Relay is enabled.
        """
        return pulumi.get(self, "enable_relay")


@pulumi.output_type
class GetClusterMonitoringConfigManagedPrometheusResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the managed collection is enabled.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the managed collection is enabled.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNetworkPolicyResult(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 provider: str):
        """
        :param bool enabled: Whether network policy is enabled on the cluster.
        :param str provider: The selected network policy provider.
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "provider", provider)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether network policy is enabled on the cluster.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter
    def provider(self) -> str:
        """
        The selected network policy provider.
        """
        return pulumi.get(self, "provider")


@pulumi.output_type
class GetClusterNodeConfigResult(dict):
    def __init__(__self__, *,
                 advanced_machine_features: Sequence['outputs.GetClusterNodeConfigAdvancedMachineFeatureResult'],
                 boot_disk_kms_key: str,
                 confidential_nodes: Sequence['outputs.GetClusterNodeConfigConfidentialNodeResult'],
                 containerd_configs: Sequence['outputs.GetClusterNodeConfigContainerdConfigResult'],
                 disk_size_gb: int,
                 disk_type: str,
                 effective_taints: Sequence['outputs.GetClusterNodeConfigEffectiveTaintResult'],
                 enable_confidential_storage: bool,
                 ephemeral_storage_configs: Sequence['outputs.GetClusterNodeConfigEphemeralStorageConfigResult'],
                 ephemeral_storage_local_ssd_configs: Sequence['outputs.GetClusterNodeConfigEphemeralStorageLocalSsdConfigResult'],
                 fast_sockets: Sequence['outputs.GetClusterNodeConfigFastSocketResult'],
                 gcfs_configs: Sequence['outputs.GetClusterNodeConfigGcfsConfigResult'],
                 guest_accelerators: Sequence['outputs.GetClusterNodeConfigGuestAcceleratorResult'],
                 gvnics: Sequence['outputs.GetClusterNodeConfigGvnicResult'],
                 host_maintenance_policies: Sequence['outputs.GetClusterNodeConfigHostMaintenancePolicyResult'],
                 image_type: str,
                 kubelet_configs: Sequence['outputs.GetClusterNodeConfigKubeletConfigResult'],
                 labels: Mapping[str, str],
                 linux_node_configs: Sequence['outputs.GetClusterNodeConfigLinuxNodeConfigResult'],
                 local_nvme_ssd_block_configs: Sequence['outputs.GetClusterNodeConfigLocalNvmeSsdBlockConfigResult'],
                 local_ssd_count: int,
                 logging_variant: str,
                 machine_type: str,
                 metadata: Mapping[str, str],
                 min_cpu_platform: str,
                 node_group: str,
                 oauth_scopes: Sequence[str],
                 preemptible: bool,
                 reservation_affinities: Sequence['outputs.GetClusterNodeConfigReservationAffinityResult'],
                 resource_labels: Mapping[str, str],
                 resource_manager_tags: Mapping[str, str],
                 sandbox_configs: Sequence['outputs.GetClusterNodeConfigSandboxConfigResult'],
                 secondary_boot_disks: Sequence['outputs.GetClusterNodeConfigSecondaryBootDiskResult'],
                 service_account: str,
                 shielded_instance_configs: Sequence['outputs.GetClusterNodeConfigShieldedInstanceConfigResult'],
                 sole_tenant_configs: Sequence['outputs.GetClusterNodeConfigSoleTenantConfigResult'],
                 spot: bool,
                 storage_pools: Sequence[str],
                 tags: Sequence[str],
                 taints: Sequence['outputs.GetClusterNodeConfigTaintResult'],
                 workload_metadata_configs: Sequence['outputs.GetClusterNodeConfigWorkloadMetadataConfigResult']):
        """
        :param Sequence['GetClusterNodeConfigAdvancedMachineFeatureArgs'] advanced_machine_features: Specifies options for controlling advanced machine features.
        :param str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        :param Sequence['GetClusterNodeConfigConfidentialNodeArgs'] confidential_nodes: Configuration for the confidential nodes feature, which makes nodes run on confidential VMs. Warning: This configuration can't be changed (or added/removed) after pool creation without deleting and recreating the entire pool.
        :param Sequence['GetClusterNodeConfigContainerdConfigArgs'] containerd_configs: Parameters for containerd configuration.
        :param int disk_size_gb: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        :param str disk_type: Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        :param Sequence['GetClusterNodeConfigEffectiveTaintArgs'] effective_taints: List of kubernetes taints applied to each node.
        :param bool enable_confidential_storage: If enabled boot disks are configured with confidential mode.
        :param Sequence['GetClusterNodeConfigEphemeralStorageConfigArgs'] ephemeral_storage_configs: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param Sequence['GetClusterNodeConfigEphemeralStorageLocalSsdConfigArgs'] ephemeral_storage_local_ssd_configs: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param Sequence['GetClusterNodeConfigFastSocketArgs'] fast_sockets: Enable or disable NCCL Fast Socket in the node pool.
        :param Sequence['GetClusterNodeConfigGcfsConfigArgs'] gcfs_configs: GCFS configuration for this node.
        :param Sequence['GetClusterNodeConfigGuestAcceleratorArgs'] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
        :param Sequence['GetClusterNodeConfigGvnicArgs'] gvnics: Enable or disable gvnic in the node pool.
        :param Sequence['GetClusterNodeConfigHostMaintenancePolicyArgs'] host_maintenance_policies: The maintenance policy for the hosts on which the GKE VMs run on.
        :param str image_type: The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        :param Sequence['GetClusterNodeConfigKubeletConfigArgs'] kubelet_configs: Node kubelet configs.
        :param Mapping[str, str] labels: The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        :param Sequence['GetClusterNodeConfigLinuxNodeConfigArgs'] linux_node_configs: Parameters that can be configured on Linux nodes.
        :param Sequence['GetClusterNodeConfigLocalNvmeSsdBlockConfigArgs'] local_nvme_ssd_block_configs: Parameters for raw-block local NVMe SSDs.
        :param int local_ssd_count: The number of local SSD disks to be attached to the node.
        :param str logging_variant: Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        :param str machine_type: The name of a Google Compute Engine machine type.
        :param Mapping[str, str] metadata: The metadata key/value pairs assigned to instances in the cluster.
        :param str min_cpu_platform: Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        :param str node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        :param Sequence[str] oauth_scopes: The set of Google API scopes to be made available on all of the node VMs.
        :param bool preemptible: Whether the nodes are created as preemptible VM instances.
        :param Sequence['GetClusterNodeConfigReservationAffinityArgs'] reservation_affinities: The reservation affinity configuration for the node pool.
        :param Mapping[str, str] resource_labels: The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        :param Mapping[str, str] resource_manager_tags: A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        :param Sequence['GetClusterNodeConfigSandboxConfigArgs'] sandbox_configs: Sandbox configuration for this node.
        :param Sequence['GetClusterNodeConfigSecondaryBootDiskArgs'] secondary_boot_disks: Secondary boot disks for preloading data or container images.
        :param str service_account: The Google Cloud Platform Service Account to be used by the node VMs.
        :param Sequence['GetClusterNodeConfigShieldedInstanceConfigArgs'] shielded_instance_configs: Shielded Instance options.
        :param Sequence['GetClusterNodeConfigSoleTenantConfigArgs'] sole_tenant_configs: Node affinity options for sole tenant node pools.
        :param bool spot: Whether the nodes are created as spot VM instances.
        :param Sequence[str] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param Sequence[str] tags: The list of instance tags applied to all nodes.
        :param Sequence['GetClusterNodeConfigTaintArgs'] taints: List of Kubernetes taints to be applied to each node.
        :param Sequence['GetClusterNodeConfigWorkloadMetadataConfigArgs'] workload_metadata_configs: The workload metadata configuration for this node.
        """
        pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        pulumi.set(__self__, "containerd_configs", containerd_configs)
        pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        pulumi.set(__self__, "disk_type", disk_type)
        pulumi.set(__self__, "effective_taints", effective_taints)
        pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        pulumi.set(__self__, "ephemeral_storage_configs", ephemeral_storage_configs)
        pulumi.set(__self__, "ephemeral_storage_local_ssd_configs", ephemeral_storage_local_ssd_configs)
        pulumi.set(__self__, "fast_sockets", fast_sockets)
        pulumi.set(__self__, "gcfs_configs", gcfs_configs)
        pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        pulumi.set(__self__, "gvnics", gvnics)
        pulumi.set(__self__, "host_maintenance_policies", host_maintenance_policies)
        pulumi.set(__self__, "image_type", image_type)
        pulumi.set(__self__, "kubelet_configs", kubelet_configs)
        pulumi.set(__self__, "labels", labels)
        pulumi.set(__self__, "linux_node_configs", linux_node_configs)
        pulumi.set(__self__, "local_nvme_ssd_block_configs", local_nvme_ssd_block_configs)
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        pulumi.set(__self__, "logging_variant", logging_variant)
        pulumi.set(__self__, "machine_type", machine_type)
        pulumi.set(__self__, "metadata", metadata)
        pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        pulumi.set(__self__, "node_group", node_group)
        pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        pulumi.set(__self__, "preemptible", preemptible)
        pulumi.set(__self__, "reservation_affinities", reservation_affinities)
        pulumi.set(__self__, "resource_labels", resource_labels)
        pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        pulumi.set(__self__, "sandbox_configs", sandbox_configs)
        pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        pulumi.set(__self__, "service_account", service_account)
        pulumi.set(__self__, "shielded_instance_configs", shielded_instance_configs)
        pulumi.set(__self__, "sole_tenant_configs", sole_tenant_configs)
        pulumi.set(__self__, "spot", spot)
        pulumi.set(__self__, "storage_pools", storage_pools)
        pulumi.set(__self__, "tags", tags)
        pulumi.set(__self__, "taints", taints)
        pulumi.set(__self__, "workload_metadata_configs", workload_metadata_configs)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Sequence['outputs.GetClusterNodeConfigAdvancedMachineFeatureResult']:
        """
        Specifies options for controlling advanced machine features.
        """
        return pulumi.get(self, "advanced_machine_features")

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> str:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Sequence['outputs.GetClusterNodeConfigConfidentialNodeResult']:
        """
        Configuration for the confidential nodes feature, which makes nodes run on confidential VMs. Warning: This configuration can't be changed (or added/removed) after pool creation without deleting and recreating the entire pool.
        """
        return pulumi.get(self, "confidential_nodes")

    @property
    @pulumi.getter(name="containerdConfigs")
    def containerd_configs(self) -> Sequence['outputs.GetClusterNodeConfigContainerdConfigResult']:
        """
        Parameters for containerd configuration.
        """
        return pulumi.get(self, "containerd_configs")

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> int:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> str:
        """
        Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        """
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Sequence['outputs.GetClusterNodeConfigEffectiveTaintResult']:
        """
        List of kubernetes taints applied to each node.
        """
        return pulumi.get(self, "effective_taints")

    @property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> bool:
        """
        If enabled boot disks are configured with confidential mode.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @property
    @pulumi.getter(name="ephemeralStorageConfigs")
    def ephemeral_storage_configs(self) -> Sequence['outputs.GetClusterNodeConfigEphemeralStorageConfigResult']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_configs")

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfigs")
    def ephemeral_storage_local_ssd_configs(self) -> Sequence['outputs.GetClusterNodeConfigEphemeralStorageLocalSsdConfigResult']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_configs")

    @property
    @pulumi.getter(name="fastSockets")
    def fast_sockets(self) -> Sequence['outputs.GetClusterNodeConfigFastSocketResult']:
        """
        Enable or disable NCCL Fast Socket in the node pool.
        """
        return pulumi.get(self, "fast_sockets")

    @property
    @pulumi.getter(name="gcfsConfigs")
    def gcfs_configs(self) -> Sequence['outputs.GetClusterNodeConfigGcfsConfigResult']:
        """
        GCFS configuration for this node.
        """
        return pulumi.get(self, "gcfs_configs")

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Sequence['outputs.GetClusterNodeConfigGuestAcceleratorResult']:
        """
        List of the type and count of accelerator cards attached to the instance.
        """
        return pulumi.get(self, "guest_accelerators")

    @property
    @pulumi.getter
    def gvnics(self) -> Sequence['outputs.GetClusterNodeConfigGvnicResult']:
        """
        Enable or disable gvnic in the node pool.
        """
        return pulumi.get(self, "gvnics")

    @property
    @pulumi.getter(name="hostMaintenancePolicies")
    def host_maintenance_policies(self) -> Sequence['outputs.GetClusterNodeConfigHostMaintenancePolicyResult']:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policies")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> str:
        """
        The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="kubeletConfigs")
    def kubelet_configs(self) -> Sequence['outputs.GetClusterNodeConfigKubeletConfigResult']:
        """
        Node kubelet configs.
        """
        return pulumi.get(self, "kubelet_configs")

    @property
    @pulumi.getter
    def labels(self) -> Mapping[str, str]:
        """
        The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="linuxNodeConfigs")
    def linux_node_configs(self) -> Sequence['outputs.GetClusterNodeConfigLinuxNodeConfigResult']:
        """
        Parameters that can be configured on Linux nodes.
        """
        return pulumi.get(self, "linux_node_configs")

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfigs")
    def local_nvme_ssd_block_configs(self) -> Sequence['outputs.GetClusterNodeConfigLocalNvmeSsdBlockConfigResult']:
        """
        Parameters for raw-block local NVMe SSDs.
        """
        return pulumi.get(self, "local_nvme_ssd_block_configs")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        The number of local SSD disks to be attached to the node.
        """
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> str:
        """
        Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        """
        return pulumi.get(self, "logging_variant")

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> str:
        """
        The name of a Google Compute Engine machine type.
        """
        return pulumi.get(self, "machine_type")

    @property
    @pulumi.getter
    def metadata(self) -> Mapping[str, str]:
        """
        The metadata key/value pairs assigned to instances in the cluster.
        """
        return pulumi.get(self, "metadata")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> str:
        """
        Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        """
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> str:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        """
        return pulumi.get(self, "node_group")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Sequence[str]:
        """
        The set of Google API scopes to be made available on all of the node VMs.
        """
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter
    def preemptible(self) -> bool:
        """
        Whether the nodes are created as preemptible VM instances.
        """
        return pulumi.get(self, "preemptible")

    @property
    @pulumi.getter(name="reservationAffinities")
    def reservation_affinities(self) -> Sequence['outputs.GetClusterNodeConfigReservationAffinityResult']:
        """
        The reservation affinity configuration for the node pool.
        """
        return pulumi.get(self, "reservation_affinities")

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Mapping[str, str]:
        """
        The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        """
        return pulumi.get(self, "resource_labels")

    @property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Mapping[str, str]:
        """
        A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        """
        return pulumi.get(self, "resource_manager_tags")

    @property
    @pulumi.getter(name="sandboxConfigs")
    def sandbox_configs(self) -> Sequence['outputs.GetClusterNodeConfigSandboxConfigResult']:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_configs")

    @property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Sequence['outputs.GetClusterNodeConfigSecondaryBootDiskResult']:
        """
        Secondary boot disks for preloading data or container images.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> str:
        """
        The Google Cloud Platform Service Account to be used by the node VMs.
        """
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfigs")
    def shielded_instance_configs(self) -> Sequence['outputs.GetClusterNodeConfigShieldedInstanceConfigResult']:
        """
        Shielded Instance options.
        """
        return pulumi.get(self, "shielded_instance_configs")

    @property
    @pulumi.getter(name="soleTenantConfigs")
    def sole_tenant_configs(self) -> Sequence['outputs.GetClusterNodeConfigSoleTenantConfigResult']:
        """
        Node affinity options for sole tenant node pools.
        """
        return pulumi.get(self, "sole_tenant_configs")

    @property
    @pulumi.getter
    def spot(self) -> bool:
        """
        Whether the nodes are created as spot VM instances.
        """
        return pulumi.get(self, "spot")

    @property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Sequence[str]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @property
    @pulumi.getter
    def tags(self) -> Sequence[str]:
        """
        The list of instance tags applied to all nodes.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def taints(self) -> Sequence['outputs.GetClusterNodeConfigTaintResult']:
        """
        List of Kubernetes taints to be applied to each node.
        """
        return pulumi.get(self, "taints")

    @property
    @pulumi.getter(name="workloadMetadataConfigs")
    def workload_metadata_configs(self) -> Sequence['outputs.GetClusterNodeConfigWorkloadMetadataConfigResult']:
        """
        The workload metadata configuration for this node.
        """
        return pulumi.get(self, "workload_metadata_configs")


@pulumi.output_type
class GetClusterNodeConfigAdvancedMachineFeatureResult(dict):
    def __init__(__self__, *,
                 enable_nested_virtualization: bool,
                 threads_per_core: int):
        """
        :param bool enable_nested_virtualization: Whether the node should have nested virtualization enabled.
        :param int threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)
        pulumi.set(__self__, "threads_per_core", threads_per_core)

    @property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> bool:
        """
        Whether the node should have nested virtualization enabled.
        """
        return pulumi.get(self, "enable_nested_virtualization")

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> int:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")


@pulumi.output_type
class GetClusterNodeConfigConfidentialNodeResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigContainerdConfigResult(dict):
    def __init__(__self__, *,
                 private_registry_access_configs: Sequence['outputs.GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigResult']):
        """
        :param Sequence['GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs'] private_registry_access_configs: Parameters for private container registries configuration.
        """
        pulumi.set(__self__, "private_registry_access_configs", private_registry_access_configs)

    @property
    @pulumi.getter(name="privateRegistryAccessConfigs")
    def private_registry_access_configs(self) -> Sequence['outputs.GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigResult']:
        """
        Parameters for private container registries configuration.
        """
        return pulumi.get(self, "private_registry_access_configs")


@pulumi.output_type
class GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigResult(dict):
    def __init__(__self__, *,
                 certificate_authority_domain_configs: Sequence['outputs.GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult'],
                 enabled: bool):
        """
        :param Sequence['GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: Parameters for configuring CA certificate and domains.
        :param bool enabled: Whether or not private registries are configured.
        """
        pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Sequence['outputs.GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult']:
        """
        Parameters for configuring CA certificate and domains.
        """
        return pulumi.get(self, "certificate_authority_domain_configs")

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not private registries are configured.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult(dict):
    def __init__(__self__, *,
                 fqdns: Sequence[str],
                 gcp_secret_manager_certificate_configs: Sequence['outputs.GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult']):
        """
        :param Sequence[str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param Sequence['GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs'] gcp_secret_manager_certificate_configs: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_configs", gcp_secret_manager_certificate_configs)

    @property
    @pulumi.getter
    def fqdns(self) -> Sequence[str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @property
    @pulumi.getter(name="gcpSecretManagerCertificateConfigs")
    def gcp_secret_manager_certificate_configs(self) -> Sequence['outputs.GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult']:
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_configs")


@pulumi.output_type
class GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult(dict):
    def __init__(__self__, *,
                 secret_uri: str):
        """
        :param str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class GetClusterNodeConfigEffectiveTaintResult(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        """
        :param str effect: Effect for taint.
        :param str key: Key for taint.
        :param str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class GetClusterNodeConfigEphemeralStorageConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodeConfigEphemeralStorageLocalSsdConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodeConfigFastSocketResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigGcfsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not GCFS is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not GCFS is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigGuestAcceleratorResult(dict):
    def __init__(__self__, *,
                 count: int,
                 gpu_driver_installation_configs: Sequence['outputs.GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult'],
                 gpu_partition_size: str,
                 gpu_sharing_configs: Sequence['outputs.GetClusterNodeConfigGuestAcceleratorGpuSharingConfigResult'],
                 type: str):
        """
        :param int count: The number of the accelerator cards exposed to an instance.
        :param Sequence['GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs'] gpu_driver_installation_configs: Configuration for auto installation of GPU driver.
        :param str gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        :param Sequence['GetClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs'] gpu_sharing_configs: Configuration for GPU sharing.
        :param str type: The accelerator type resource name.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "gpu_driver_installation_configs", gpu_driver_installation_configs)
        pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        pulumi.set(__self__, "gpu_sharing_configs", gpu_sharing_configs)
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def count(self) -> int:
        """
        The number of the accelerator cards exposed to an instance.
        """
        return pulumi.get(self, "count")

    @property
    @pulumi.getter(name="gpuDriverInstallationConfigs")
    def gpu_driver_installation_configs(self) -> Sequence['outputs.GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult']:
        """
        Configuration for auto installation of GPU driver.
        """
        return pulumi.get(self, "gpu_driver_installation_configs")

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> str:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        """
        return pulumi.get(self, "gpu_partition_size")

    @property
    @pulumi.getter(name="gpuSharingConfigs")
    def gpu_sharing_configs(self) -> Sequence['outputs.GetClusterNodeConfigGuestAcceleratorGpuSharingConfigResult']:
        """
        Configuration for GPU sharing.
        """
        return pulumi.get(self, "gpu_sharing_configs")

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        The accelerator type resource name.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult(dict):
    def __init__(__self__, *,
                 gpu_driver_version: str):
        """
        :param str gpu_driver_version: Mode for how the GPU driver is installed.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> str:
        """
        Mode for how the GPU driver is installed.
        """
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class GetClusterNodeConfigGuestAcceleratorGpuSharingConfigResult(dict):
    def __init__(__self__, *,
                 gpu_sharing_strategy: str,
                 max_shared_clients_per_gpu: int):
        """
        :param str gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        :param int max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> str:
        """
        The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> int:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class GetClusterNodeConfigGvnicResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not gvnic is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not gvnic is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigHostMaintenancePolicyResult(dict):
    def __init__(__self__, *,
                 maintenance_interval: str):
        """
        :param str maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> str:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class GetClusterNodeConfigKubeletConfigResult(dict):
    def __init__(__self__, *,
                 cpu_cfs_quota: bool,
                 cpu_cfs_quota_period: str,
                 cpu_manager_policy: str,
                 insecure_kubelet_readonly_port_enabled: str,
                 pod_pids_limit: int):
        """
        :param bool cpu_cfs_quota: Enable CPU CFS quota enforcement for containers that specify CPU limits.
        :param str cpu_cfs_quota_period: Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        :param str cpu_manager_policy: Control the CPU management policy on the node.
        :param str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param int pod_pids_limit: Controls the maximum number of processes allowed to run in a pod.
        """
        pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> bool:
        """
        Enable CPU CFS quota enforcement for containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> str:
        """
        Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> str:
        """
        Control the CPU management policy on the node.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> str:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> int:
        """
        Controls the maximum number of processes allowed to run in a pod.
        """
        return pulumi.get(self, "pod_pids_limit")


@pulumi.output_type
class GetClusterNodeConfigLinuxNodeConfigResult(dict):
    def __init__(__self__, *,
                 cgroup_mode: str,
                 hugepages_configs: Sequence['outputs.GetClusterNodeConfigLinuxNodeConfigHugepagesConfigResult'],
                 sysctls: Mapping[str, str]):
        """
        :param str cgroup_mode: cgroupMode specifies the cgroup mode to be used on the node.
        :param Sequence['GetClusterNodeConfigLinuxNodeConfigHugepagesConfigArgs'] hugepages_configs: Amounts for 2M and 1G hugepages.
        :param Mapping[str, str] sysctls: The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        """
        pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        pulumi.set(__self__, "hugepages_configs", hugepages_configs)
        pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> str:
        """
        cgroupMode specifies the cgroup mode to be used on the node.
        """
        return pulumi.get(self, "cgroup_mode")

    @property
    @pulumi.getter(name="hugepagesConfigs")
    def hugepages_configs(self) -> Sequence['outputs.GetClusterNodeConfigLinuxNodeConfigHugepagesConfigResult']:
        """
        Amounts for 2M and 1G hugepages.
        """
        return pulumi.get(self, "hugepages_configs")

    @property
    @pulumi.getter
    def sysctls(self) -> Mapping[str, str]:
        """
        The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        """
        return pulumi.get(self, "sysctls")


@pulumi.output_type
class GetClusterNodeConfigLinuxNodeConfigHugepagesConfigResult(dict):
    def __init__(__self__, *,
                 hugepage_size1g: int,
                 hugepage_size2m: int):
        """
        :param int hugepage_size1g: Amount of 1G hugepages.
        :param int hugepage_size2m: Amount of 2M hugepages.
        """
        pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> int:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> int:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")


@pulumi.output_type
class GetClusterNodeConfigLocalNvmeSsdBlockConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodeConfigReservationAffinityResult(dict):
    def __init__(__self__, *,
                 consume_reservation_type: str,
                 key: str,
                 values: Sequence[str]):
        """
        :param str consume_reservation_type: Corresponds to the type of reservation consumption.
        :param str key: The label key of a reservation resource.
        :param Sequence[str] values: The label values of the reservation resource.
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> str:
        """
        Corresponds to the type of reservation consumption.
        """
        return pulumi.get(self, "consume_reservation_type")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        The label key of a reservation resource.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        """
        The label values of the reservation resource.
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class GetClusterNodeConfigSandboxConfigResult(dict):
    def __init__(__self__, *,
                 sandbox_type: str):
        """
        :param str sandbox_type: Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> str:
        """
        Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class GetClusterNodeConfigSecondaryBootDiskResult(dict):
    def __init__(__self__, *,
                 disk_image: str,
                 mode: str):
        """
        :param str disk_image: Disk image to create the secondary boot disk from
        :param str mode: Mode for how the secondary boot disk is used.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> str:
        """
        Disk image to create the secondary boot disk from
        """
        return pulumi.get(self, "disk_image")

    @property
    @pulumi.getter
    def mode(self) -> str:
        """
        Mode for how the secondary boot disk is used.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class GetClusterNodeConfigShieldedInstanceConfigResult(dict):
    def __init__(__self__, *,
                 enable_integrity_monitoring: bool,
                 enable_secure_boot: bool):
        """
        :param bool enable_integrity_monitoring: Defines whether the instance has integrity monitoring enabled.
        :param bool enable_secure_boot: Defines whether the instance has Secure Boot enabled.
        """
        pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> bool:
        """
        Defines whether the instance has integrity monitoring enabled.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> bool:
        """
        Defines whether the instance has Secure Boot enabled.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class GetClusterNodeConfigSoleTenantConfigResult(dict):
    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.GetClusterNodeConfigSoleTenantConfigNodeAffinityResult']):
        """
        :param Sequence['GetClusterNodeConfigSoleTenantConfigNodeAffinityArgs'] node_affinities: .
        """
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.GetClusterNodeConfigSoleTenantConfigNodeAffinityResult']:
        """
        .
        """
        return pulumi.get(self, "node_affinities")


@pulumi.output_type
class GetClusterNodeConfigSoleTenantConfigNodeAffinityResult(dict):
    def __init__(__self__, *,
                 key: str,
                 operator: str,
                 values: Sequence[str]):
        """
        :param str key: .
        :param str operator: .
        :param Sequence[str] values: .
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        .
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def operator(self) -> str:
        """
        .
        """
        return pulumi.get(self, "operator")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        """
        .
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class GetClusterNodeConfigTaintResult(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        """
        :param str effect: Effect for taint.
        :param str key: Key for taint.
        :param str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class GetClusterNodeConfigWorkloadMetadataConfigResult(dict):
    def __init__(__self__, *,
                 mode: str):
        """
        :param str mode: Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> str:
        """
        Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class GetClusterNodePoolResult(dict):
    def __init__(__self__, *,
                 autoscalings: Sequence['outputs.GetClusterNodePoolAutoscalingResult'],
                 initial_node_count: int,
                 instance_group_urls: Sequence[str],
                 managed_instance_group_urls: Sequence[str],
                 managements: Sequence['outputs.GetClusterNodePoolManagementResult'],
                 max_pods_per_node: int,
                 name: str,
                 name_prefix: str,
                 network_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigResult'],
                 node_configs: Sequence['outputs.GetClusterNodePoolNodeConfigResult'],
                 node_count: int,
                 node_locations: Sequence[str],
                 placement_policies: Sequence['outputs.GetClusterNodePoolPlacementPolicyResult'],
                 queued_provisionings: Sequence['outputs.GetClusterNodePoolQueuedProvisioningResult'],
                 upgrade_settings: Sequence['outputs.GetClusterNodePoolUpgradeSettingResult'],
                 version: str):
        """
        :param Sequence['GetClusterNodePoolAutoscalingArgs'] autoscalings: Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
        :param int initial_node_count: The initial number of nodes for the pool. In regional or multi-zonal clusters, this is the number of nodes per zone. Changing this will force recreation of the resource.
        :param Sequence[str] instance_group_urls: The resource URLs of the managed instance groups associated with this node pool.
        :param Sequence[str] managed_instance_group_urls: List of instance group URLs which have been assigned to this node pool.
        :param Sequence['GetClusterNodePoolManagementArgs'] managements: Node management configuration, wherein auto-repair and auto-upgrade is configured.
        :param int max_pods_per_node: The maximum number of pods per node in this node pool. Note that this does not work on node pools which are "route-based" - that is, node pools belonging to clusters that do not have IP Aliasing enabled.
        :param str name: The name of the cluster.
        :param str name_prefix: Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.
        :param Sequence['GetClusterNodePoolNetworkConfigArgs'] network_configs: Networking configuration for this NodePool. If specified, it overrides the cluster-level defaults.
        :param Sequence['GetClusterNodePoolNodeConfigArgs'] node_configs: The configuration of the nodepool
        :param int node_count: The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.
        :param Sequence[str] node_locations: The list of zones in which the node pool's nodes should be located. Nodes must be in the region of their regional cluster or in the same region as their cluster's zone for zonal clusters. If unspecified, the cluster-level node_locations will be used.
        :param Sequence['GetClusterNodePoolPlacementPolicyArgs'] placement_policies: Specifies the node placement policy
        :param Sequence['GetClusterNodePoolQueuedProvisioningArgs'] queued_provisionings: Specifies the configuration of queued provisioning
        :param Sequence['GetClusterNodePoolUpgradeSettingArgs'] upgrade_settings: Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of max_surge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.
        """
        pulumi.set(__self__, "autoscalings", autoscalings)
        pulumi.set(__self__, "initial_node_count", initial_node_count)
        pulumi.set(__self__, "instance_group_urls", instance_group_urls)
        pulumi.set(__self__, "managed_instance_group_urls", managed_instance_group_urls)
        pulumi.set(__self__, "managements", managements)
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "name_prefix", name_prefix)
        pulumi.set(__self__, "network_configs", network_configs)
        pulumi.set(__self__, "node_configs", node_configs)
        pulumi.set(__self__, "node_count", node_count)
        pulumi.set(__self__, "node_locations", node_locations)
        pulumi.set(__self__, "placement_policies", placement_policies)
        pulumi.set(__self__, "queued_provisionings", queued_provisionings)
        pulumi.set(__self__, "upgrade_settings", upgrade_settings)
        pulumi.set(__self__, "version", version)

    @property
    @pulumi.getter
    def autoscalings(self) -> Sequence['outputs.GetClusterNodePoolAutoscalingResult']:
        """
        Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
        """
        return pulumi.get(self, "autoscalings")

    @property
    @pulumi.getter(name="initialNodeCount")
    def initial_node_count(self) -> int:
        """
        The initial number of nodes for the pool. In regional or multi-zonal clusters, this is the number of nodes per zone. Changing this will force recreation of the resource.
        """
        return pulumi.get(self, "initial_node_count")

    @property
    @pulumi.getter(name="instanceGroupUrls")
    def instance_group_urls(self) -> Sequence[str]:
        """
        The resource URLs of the managed instance groups associated with this node pool.
        """
        return pulumi.get(self, "instance_group_urls")

    @property
    @pulumi.getter(name="managedInstanceGroupUrls")
    def managed_instance_group_urls(self) -> Sequence[str]:
        """
        List of instance group URLs which have been assigned to this node pool.
        """
        return pulumi.get(self, "managed_instance_group_urls")

    @property
    @pulumi.getter
    def managements(self) -> Sequence['outputs.GetClusterNodePoolManagementResult']:
        """
        Node management configuration, wherein auto-repair and auto-upgrade is configured.
        """
        return pulumi.get(self, "managements")

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> int:
        """
        The maximum number of pods per node in this node pool. Note that this does not work on node pools which are "route-based" - that is, node pools belonging to clusters that do not have IP Aliasing enabled.
        """
        return pulumi.get(self, "max_pods_per_node")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The name of the cluster.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="namePrefix")
    def name_prefix(self) -> str:
        """
        Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.
        """
        return pulumi.get(self, "name_prefix")

    @property
    @pulumi.getter(name="networkConfigs")
    def network_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigResult']:
        """
        Networking configuration for this NodePool. If specified, it overrides the cluster-level defaults.
        """
        return pulumi.get(self, "network_configs")

    @property
    @pulumi.getter(name="nodeConfigs")
    def node_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigResult']:
        """
        The configuration of the nodepool
        """
        return pulumi.get(self, "node_configs")

    @property
    @pulumi.getter(name="nodeCount")
    def node_count(self) -> int:
        """
        The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.
        """
        return pulumi.get(self, "node_count")

    @property
    @pulumi.getter(name="nodeLocations")
    def node_locations(self) -> Sequence[str]:
        """
        The list of zones in which the node pool's nodes should be located. Nodes must be in the region of their regional cluster or in the same region as their cluster's zone for zonal clusters. If unspecified, the cluster-level node_locations will be used.
        """
        return pulumi.get(self, "node_locations")

    @property
    @pulumi.getter(name="placementPolicies")
    def placement_policies(self) -> Sequence['outputs.GetClusterNodePoolPlacementPolicyResult']:
        """
        Specifies the node placement policy
        """
        return pulumi.get(self, "placement_policies")

    @property
    @pulumi.getter(name="queuedProvisionings")
    def queued_provisionings(self) -> Sequence['outputs.GetClusterNodePoolQueuedProvisioningResult']:
        """
        Specifies the configuration of queued provisioning
        """
        return pulumi.get(self, "queued_provisionings")

    @property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Sequence['outputs.GetClusterNodePoolUpgradeSettingResult']:
        """
        Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of max_surge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.
        """
        return pulumi.get(self, "upgrade_settings")

    @property
    @pulumi.getter
    def version(self) -> str:
        return pulumi.get(self, "version")


@pulumi.output_type
class GetClusterNodePoolAutoConfigResult(dict):
    def __init__(__self__, *,
                 network_tags: Sequence['outputs.GetClusterNodePoolAutoConfigNetworkTagResult'],
                 node_kubelet_configs: Sequence['outputs.GetClusterNodePoolAutoConfigNodeKubeletConfigResult'],
                 resource_manager_tags: Mapping[str, str]):
        """
        :param Sequence['GetClusterNodePoolAutoConfigNetworkTagArgs'] network_tags: Collection of Compute Engine network tags that can be applied to a node's underlying VM instance.
        :param Sequence['GetClusterNodePoolAutoConfigNodeKubeletConfigArgs'] node_kubelet_configs: Node kubelet configs.
        :param Mapping[str, str] resource_manager_tags: A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        """
        pulumi.set(__self__, "network_tags", network_tags)
        pulumi.set(__self__, "node_kubelet_configs", node_kubelet_configs)
        pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)

    @property
    @pulumi.getter(name="networkTags")
    def network_tags(self) -> Sequence['outputs.GetClusterNodePoolAutoConfigNetworkTagResult']:
        """
        Collection of Compute Engine network tags that can be applied to a node's underlying VM instance.
        """
        return pulumi.get(self, "network_tags")

    @property
    @pulumi.getter(name="nodeKubeletConfigs")
    def node_kubelet_configs(self) -> Sequence['outputs.GetClusterNodePoolAutoConfigNodeKubeletConfigResult']:
        """
        Node kubelet configs.
        """
        return pulumi.get(self, "node_kubelet_configs")

    @property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Mapping[str, str]:
        """
        A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        """
        return pulumi.get(self, "resource_manager_tags")


@pulumi.output_type
class GetClusterNodePoolAutoConfigNetworkTagResult(dict):
    def __init__(__self__, *,
                 tags: Sequence[str]):
        """
        :param Sequence[str] tags: List of network tags applied to auto-provisioned node pools.
        """
        pulumi.set(__self__, "tags", tags)

    @property
    @pulumi.getter
    def tags(self) -> Sequence[str]:
        """
        List of network tags applied to auto-provisioned node pools.
        """
        return pulumi.get(self, "tags")


@pulumi.output_type
class GetClusterNodePoolAutoConfigNodeKubeletConfigResult(dict):
    def __init__(__self__, *,
                 insecure_kubelet_readonly_port_enabled: str):
        """
        :param str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> str:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")


@pulumi.output_type
class GetClusterNodePoolAutoscalingResult(dict):
    def __init__(__self__, *,
                 location_policy: str,
                 max_node_count: int,
                 min_node_count: int,
                 total_max_node_count: int,
                 total_min_node_count: int):
        """
        :param str location_policy: Location policy specifies the algorithm used when scaling-up the node pool. "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones. "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations, and reduces preemption risk for Spot VMs.
        :param int max_node_count: Maximum number of nodes per zone in the node pool. Must be >= min_node_count. Cannot be used with total limits.
        :param int min_node_count: Minimum number of nodes per zone in the node pool. Must be >=0 and <= max_node_count. Cannot be used with total limits.
        :param int total_max_node_count: Maximum number of all nodes in the node pool. Must be >= total_min_node_count. Cannot be used with per zone limits.
        :param int total_min_node_count: Minimum number of all nodes in the node pool. Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
        """
        pulumi.set(__self__, "location_policy", location_policy)
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)
        pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> str:
        """
        Location policy specifies the algorithm used when scaling-up the node pool. "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones. "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations, and reduces preemption risk for Spot VMs.
        """
        return pulumi.get(self, "location_policy")

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> int:
        """
        Maximum number of nodes per zone in the node pool. Must be >= min_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "max_node_count")

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> int:
        """
        Minimum number of nodes per zone in the node pool. Must be >=0 and <= max_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "min_node_count")

    @property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> int:
        """
        Maximum number of all nodes in the node pool. Must be >= total_min_node_count. Cannot be used with per zone limits.
        """
        return pulumi.get(self, "total_max_node_count")

    @property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> int:
        """
        Minimum number of all nodes in the node pool. Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
        """
        return pulumi.get(self, "total_min_node_count")


@pulumi.output_type
class GetClusterNodePoolDefaultResult(dict):
    def __init__(__self__, *,
                 node_config_defaults: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultResult']):
        """
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultArgs'] node_config_defaults: Subset of NodeConfig message that has defaults.
        """
        pulumi.set(__self__, "node_config_defaults", node_config_defaults)

    @property
    @pulumi.getter(name="nodeConfigDefaults")
    def node_config_defaults(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultResult']:
        """
        Subset of NodeConfig message that has defaults.
        """
        return pulumi.get(self, "node_config_defaults")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultResult(dict):
    def __init__(__self__, *,
                 containerd_configs: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigResult'],
                 gcfs_configs: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigResult'],
                 insecure_kubelet_readonly_port_enabled: str,
                 logging_variant: str):
        """
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigArgs'] containerd_configs: Parameters for containerd configuration.
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigArgs'] gcfs_configs: GCFS configuration for this node.
        :param str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param str logging_variant: Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        """
        pulumi.set(__self__, "containerd_configs", containerd_configs)
        pulumi.set(__self__, "gcfs_configs", gcfs_configs)
        pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        pulumi.set(__self__, "logging_variant", logging_variant)

    @property
    @pulumi.getter(name="containerdConfigs")
    def containerd_configs(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigResult']:
        """
        Parameters for containerd configuration.
        """
        return pulumi.get(self, "containerd_configs")

    @property
    @pulumi.getter(name="gcfsConfigs")
    def gcfs_configs(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigResult']:
        """
        GCFS configuration for this node.
        """
        return pulumi.get(self, "gcfs_configs")

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> str:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> str:
        """
        Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        """
        return pulumi.get(self, "logging_variant")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigResult(dict):
    def __init__(__self__, *,
                 private_registry_access_configs: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigResult']):
        """
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigArgs'] private_registry_access_configs: Parameters for private container registries configuration.
        """
        pulumi.set(__self__, "private_registry_access_configs", private_registry_access_configs)

    @property
    @pulumi.getter(name="privateRegistryAccessConfigs")
    def private_registry_access_configs(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigResult']:
        """
        Parameters for private container registries configuration.
        """
        return pulumi.get(self, "private_registry_access_configs")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigResult(dict):
    def __init__(__self__, *,
                 certificate_authority_domain_configs: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult'],
                 enabled: bool):
        """
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: Parameters for configuring CA certificate and domains.
        :param bool enabled: Whether or not private registries are configured.
        """
        pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult']:
        """
        Parameters for configuring CA certificate and domains.
        """
        return pulumi.get(self, "certificate_authority_domain_configs")

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not private registries are configured.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult(dict):
    def __init__(__self__, *,
                 fqdns: Sequence[str],
                 gcp_secret_manager_certificate_configs: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult']):
        """
        :param Sequence[str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs'] gcp_secret_manager_certificate_configs: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_configs", gcp_secret_manager_certificate_configs)

    @property
    @pulumi.getter
    def fqdns(self) -> Sequence[str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @property
    @pulumi.getter(name="gcpSecretManagerCertificateConfigs")
    def gcp_secret_manager_certificate_configs(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult']:
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_configs")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult(dict):
    def __init__(__self__, *,
                 secret_uri: str):
        """
        :param str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not GCFS is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not GCFS is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolManagementResult(dict):
    def __init__(__self__, *,
                 auto_repair: bool,
                 auto_upgrade: bool):
        """
        :param bool auto_repair: Whether the nodes will be automatically repaired. Enabled by default.
        :param bool auto_upgrade: Whether the nodes will be automatically upgraded. Enabled by default.
        """
        pulumi.set(__self__, "auto_repair", auto_repair)
        pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> bool:
        """
        Whether the nodes will be automatically repaired. Enabled by default.
        """
        return pulumi.get(self, "auto_repair")

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> bool:
        """
        Whether the nodes will be automatically upgraded. Enabled by default.
        """
        return pulumi.get(self, "auto_upgrade")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigResult(dict):
    def __init__(__self__, *,
                 additional_node_network_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigResult'],
                 additional_pod_network_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigResult'],
                 create_pod_range: bool,
                 enable_private_nodes: bool,
                 network_performance_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigNetworkPerformanceConfigResult'],
                 pod_cidr_overprovision_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigResult'],
                 pod_ipv4_cidr_block: str,
                 pod_range: str):
        """
        :param Sequence['GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs'] additional_node_network_configs: We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface
        :param Sequence['GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs'] additional_pod_network_configs: We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node
        :param bool create_pod_range: Whether to create a new range for pod IPs in this node pool. Defaults are provided for pod_range and pod_ipv4_cidr_block if they are not specified.
        :param bool enable_private_nodes: Whether nodes have internal IP addresses only.
        :param Sequence['GetClusterNodePoolNetworkConfigNetworkPerformanceConfigArgs'] network_performance_configs: Network bandwidth tier configuration.
        :param Sequence['GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs'] pod_cidr_overprovision_configs: Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited
        :param str pod_ipv4_cidr_block: The IP address range for pod IPs in this node pool. Only applicable if create_pod_range is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        :param str pod_range: The ID of the secondary range for pod IPs. If create_pod_range is true, this ID is used for the new range. If create_pod_range is false, uses an existing secondary range with this ID.
        """
        pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        pulumi.set(__self__, "create_pod_range", create_pod_range)
        pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        pulumi.set(__self__, "network_performance_configs", network_performance_configs)
        pulumi.set(__self__, "pod_cidr_overprovision_configs", pod_cidr_overprovision_configs)
        pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        pulumi.set(__self__, "pod_range", pod_range)

    @property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigResult']:
        """
        We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface
        """
        return pulumi.get(self, "additional_node_network_configs")

    @property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigResult']:
        """
        We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node
        """
        return pulumi.get(self, "additional_pod_network_configs")

    @property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> bool:
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for pod_range and pod_ipv4_cidr_block if they are not specified.
        """
        return pulumi.get(self, "create_pod_range")

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> bool:
        """
        Whether nodes have internal IP addresses only.
        """
        return pulumi.get(self, "enable_private_nodes")

    @property
    @pulumi.getter(name="networkPerformanceConfigs")
    def network_performance_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigNetworkPerformanceConfigResult']:
        """
        Network bandwidth tier configuration.
        """
        return pulumi.get(self, "network_performance_configs")

    @property
    @pulumi.getter(name="podCidrOverprovisionConfigs")
    def pod_cidr_overprovision_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigResult']:
        """
        Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited
        """
        return pulumi.get(self, "pod_cidr_overprovision_configs")

    @property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> str:
        """
        The IP address range for pod IPs in this node pool. Only applicable if create_pod_range is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> str:
        """
        The ID of the secondary range for pod IPs. If create_pod_range is true, this ID is used for the new range. If create_pod_range is false, uses an existing secondary range with this ID.
        """
        return pulumi.get(self, "pod_range")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigResult(dict):
    def __init__(__self__, *,
                 network: str,
                 subnetwork: str):
        """
        :param str network: Name of the VPC where the additional interface belongs.
        :param str subnetwork: Name of the subnetwork where the additional interface belongs.
        """
        pulumi.set(__self__, "network", network)
        pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter
    def network(self) -> str:
        """
        Name of the VPC where the additional interface belongs.
        """
        return pulumi.get(self, "network")

    @property
    @pulumi.getter
    def subnetwork(self) -> str:
        """
        Name of the subnetwork where the additional interface belongs.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigResult(dict):
    def __init__(__self__, *,
                 max_pods_per_node: int,
                 secondary_pod_range: str,
                 subnetwork: str):
        """
        :param int max_pods_per_node: The maximum number of pods per node which use this pod network.
        :param str secondary_pod_range: The name of the secondary range on the subnet which provides IP address for this pod range.
        :param str subnetwork: Name of the subnetwork where the additional pod network belongs.
        """
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> int:
        """
        The maximum number of pods per node which use this pod network.
        """
        return pulumi.get(self, "max_pods_per_node")

    @property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> str:
        """
        The name of the secondary range on the subnet which provides IP address for this pod range.
        """
        return pulumi.get(self, "secondary_pod_range")

    @property
    @pulumi.getter
    def subnetwork(self) -> str:
        """
        Name of the subnetwork where the additional pod network belongs.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigNetworkPerformanceConfigResult(dict):
    def __init__(__self__, *,
                 total_egress_bandwidth_tier: str):
        """
        :param str total_egress_bandwidth_tier: Specifies the total network bandwidth tier for the NodePool.
        """
        pulumi.set(__self__, "total_egress_bandwidth_tier", total_egress_bandwidth_tier)

    @property
    @pulumi.getter(name="totalEgressBandwidthTier")
    def total_egress_bandwidth_tier(self) -> str:
        """
        Specifies the total network bandwidth tier for the NodePool.
        """
        return pulumi.get(self, "total_egress_bandwidth_tier")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigResult(dict):
    def __init__(__self__, *,
                 disabled: bool):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigResult(dict):
    def __init__(__self__, *,
                 advanced_machine_features: Sequence['outputs.GetClusterNodePoolNodeConfigAdvancedMachineFeatureResult'],
                 boot_disk_kms_key: str,
                 confidential_nodes: Sequence['outputs.GetClusterNodePoolNodeConfigConfidentialNodeResult'],
                 containerd_configs: Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigResult'],
                 disk_size_gb: int,
                 disk_type: str,
                 effective_taints: Sequence['outputs.GetClusterNodePoolNodeConfigEffectiveTaintResult'],
                 enable_confidential_storage: bool,
                 ephemeral_storage_configs: Sequence['outputs.GetClusterNodePoolNodeConfigEphemeralStorageConfigResult'],
                 ephemeral_storage_local_ssd_configs: Sequence['outputs.GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigResult'],
                 fast_sockets: Sequence['outputs.GetClusterNodePoolNodeConfigFastSocketResult'],
                 gcfs_configs: Sequence['outputs.GetClusterNodePoolNodeConfigGcfsConfigResult'],
                 guest_accelerators: Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorResult'],
                 gvnics: Sequence['outputs.GetClusterNodePoolNodeConfigGvnicResult'],
                 host_maintenance_policies: Sequence['outputs.GetClusterNodePoolNodeConfigHostMaintenancePolicyResult'],
                 image_type: str,
                 kubelet_configs: Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigResult'],
                 labels: Mapping[str, str],
                 linux_node_configs: Sequence['outputs.GetClusterNodePoolNodeConfigLinuxNodeConfigResult'],
                 local_nvme_ssd_block_configs: Sequence['outputs.GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigResult'],
                 local_ssd_count: int,
                 logging_variant: str,
                 machine_type: str,
                 metadata: Mapping[str, str],
                 min_cpu_platform: str,
                 node_group: str,
                 oauth_scopes: Sequence[str],
                 preemptible: bool,
                 reservation_affinities: Sequence['outputs.GetClusterNodePoolNodeConfigReservationAffinityResult'],
                 resource_labels: Mapping[str, str],
                 resource_manager_tags: Mapping[str, str],
                 sandbox_configs: Sequence['outputs.GetClusterNodePoolNodeConfigSandboxConfigResult'],
                 secondary_boot_disks: Sequence['outputs.GetClusterNodePoolNodeConfigSecondaryBootDiskResult'],
                 service_account: str,
                 shielded_instance_configs: Sequence['outputs.GetClusterNodePoolNodeConfigShieldedInstanceConfigResult'],
                 sole_tenant_configs: Sequence['outputs.GetClusterNodePoolNodeConfigSoleTenantConfigResult'],
                 spot: bool,
                 storage_pools: Sequence[str],
                 tags: Sequence[str],
                 taints: Sequence['outputs.GetClusterNodePoolNodeConfigTaintResult'],
                 workload_metadata_configs: Sequence['outputs.GetClusterNodePoolNodeConfigWorkloadMetadataConfigResult']):
        """
        :param Sequence['GetClusterNodePoolNodeConfigAdvancedMachineFeatureArgs'] advanced_machine_features: Specifies options for controlling advanced machine features.
        :param str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        :param Sequence['GetClusterNodePoolNodeConfigConfidentialNodeArgs'] confidential_nodes: Configuration for the confidential nodes feature, which makes nodes run on confidential VMs. Warning: This configuration can't be changed (or added/removed) after pool creation without deleting and recreating the entire pool.
        :param Sequence['GetClusterNodePoolNodeConfigContainerdConfigArgs'] containerd_configs: Parameters for containerd configuration.
        :param int disk_size_gb: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        :param str disk_type: Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        :param Sequence['GetClusterNodePoolNodeConfigEffectiveTaintArgs'] effective_taints: List of kubernetes taints applied to each node.
        :param bool enable_confidential_storage: If enabled boot disks are configured with confidential mode.
        :param Sequence['GetClusterNodePoolNodeConfigEphemeralStorageConfigArgs'] ephemeral_storage_configs: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param Sequence['GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs'] ephemeral_storage_local_ssd_configs: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param Sequence['GetClusterNodePoolNodeConfigFastSocketArgs'] fast_sockets: Enable or disable NCCL Fast Socket in the node pool.
        :param Sequence['GetClusterNodePoolNodeConfigGcfsConfigArgs'] gcfs_configs: GCFS configuration for this node.
        :param Sequence['GetClusterNodePoolNodeConfigGuestAcceleratorArgs'] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
        :param Sequence['GetClusterNodePoolNodeConfigGvnicArgs'] gvnics: Enable or disable gvnic in the node pool.
        :param Sequence['GetClusterNodePoolNodeConfigHostMaintenancePolicyArgs'] host_maintenance_policies: The maintenance policy for the hosts on which the GKE VMs run on.
        :param str image_type: The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        :param Sequence['GetClusterNodePoolNodeConfigKubeletConfigArgs'] kubelet_configs: Node kubelet configs.
        :param Mapping[str, str] labels: The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        :param Sequence['GetClusterNodePoolNodeConfigLinuxNodeConfigArgs'] linux_node_configs: Parameters that can be configured on Linux nodes.
        :param Sequence['GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs'] local_nvme_ssd_block_configs: Parameters for raw-block local NVMe SSDs.
        :param int local_ssd_count: The number of local SSD disks to be attached to the node.
        :param str logging_variant: Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        :param str machine_type: The name of a Google Compute Engine machine type.
        :param Mapping[str, str] metadata: The metadata key/value pairs assigned to instances in the cluster.
        :param str min_cpu_platform: Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        :param str node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        :param Sequence[str] oauth_scopes: The set of Google API scopes to be made available on all of the node VMs.
        :param bool preemptible: Whether the nodes are created as preemptible VM instances.
        :param Sequence['GetClusterNodePoolNodeConfigReservationAffinityArgs'] reservation_affinities: The reservation affinity configuration for the node pool.
        :param Mapping[str, str] resource_labels: The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        :param Mapping[str, str] resource_manager_tags: A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        :param Sequence['GetClusterNodePoolNodeConfigSandboxConfigArgs'] sandbox_configs: Sandbox configuration for this node.
        :param Sequence['GetClusterNodePoolNodeConfigSecondaryBootDiskArgs'] secondary_boot_disks: Secondary boot disks for preloading data or container images.
        :param str service_account: The Google Cloud Platform Service Account to be used by the node VMs.
        :param Sequence['GetClusterNodePoolNodeConfigShieldedInstanceConfigArgs'] shielded_instance_configs: Shielded Instance options.
        :param Sequence['GetClusterNodePoolNodeConfigSoleTenantConfigArgs'] sole_tenant_configs: Node affinity options for sole tenant node pools.
        :param bool spot: Whether the nodes are created as spot VM instances.
        :param Sequence[str] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param Sequence[str] tags: The list of instance tags applied to all nodes.
        :param Sequence['GetClusterNodePoolNodeConfigTaintArgs'] taints: List of Kubernetes taints to be applied to each node.
        :param Sequence['GetClusterNodePoolNodeConfigWorkloadMetadataConfigArgs'] workload_metadata_configs: The workload metadata configuration for this node.
        """
        pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        pulumi.set(__self__, "containerd_configs", containerd_configs)
        pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        pulumi.set(__self__, "disk_type", disk_type)
        pulumi.set(__self__, "effective_taints", effective_taints)
        pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        pulumi.set(__self__, "ephemeral_storage_configs", ephemeral_storage_configs)
        pulumi.set(__self__, "ephemeral_storage_local_ssd_configs", ephemeral_storage_local_ssd_configs)
        pulumi.set(__self__, "fast_sockets", fast_sockets)
        pulumi.set(__self__, "gcfs_configs", gcfs_configs)
        pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        pulumi.set(__self__, "gvnics", gvnics)
        pulumi.set(__self__, "host_maintenance_policies", host_maintenance_policies)
        pulumi.set(__self__, "image_type", image_type)
        pulumi.set(__self__, "kubelet_configs", kubelet_configs)
        pulumi.set(__self__, "labels", labels)
        pulumi.set(__self__, "linux_node_configs", linux_node_configs)
        pulumi.set(__self__, "local_nvme_ssd_block_configs", local_nvme_ssd_block_configs)
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        pulumi.set(__self__, "logging_variant", logging_variant)
        pulumi.set(__self__, "machine_type", machine_type)
        pulumi.set(__self__, "metadata", metadata)
        pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        pulumi.set(__self__, "node_group", node_group)
        pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        pulumi.set(__self__, "preemptible", preemptible)
        pulumi.set(__self__, "reservation_affinities", reservation_affinities)
        pulumi.set(__self__, "resource_labels", resource_labels)
        pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        pulumi.set(__self__, "sandbox_configs", sandbox_configs)
        pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        pulumi.set(__self__, "service_account", service_account)
        pulumi.set(__self__, "shielded_instance_configs", shielded_instance_configs)
        pulumi.set(__self__, "sole_tenant_configs", sole_tenant_configs)
        pulumi.set(__self__, "spot", spot)
        pulumi.set(__self__, "storage_pools", storage_pools)
        pulumi.set(__self__, "tags", tags)
        pulumi.set(__self__, "taints", taints)
        pulumi.set(__self__, "workload_metadata_configs", workload_metadata_configs)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigAdvancedMachineFeatureResult']:
        """
        Specifies options for controlling advanced machine features.
        """
        return pulumi.get(self, "advanced_machine_features")

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> str:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigConfidentialNodeResult']:
        """
        Configuration for the confidential nodes feature, which makes nodes run on confidential VMs. Warning: This configuration can't be changed (or added/removed) after pool creation without deleting and recreating the entire pool.
        """
        return pulumi.get(self, "confidential_nodes")

    @property
    @pulumi.getter(name="containerdConfigs")
    def containerd_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigResult']:
        """
        Parameters for containerd configuration.
        """
        return pulumi.get(self, "containerd_configs")

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> int:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> str:
        """
        Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        """
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigEffectiveTaintResult']:
        """
        List of kubernetes taints applied to each node.
        """
        return pulumi.get(self, "effective_taints")

    @property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> bool:
        """
        If enabled boot disks are configured with confidential mode.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @property
    @pulumi.getter(name="ephemeralStorageConfigs")
    def ephemeral_storage_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigEphemeralStorageConfigResult']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_configs")

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfigs")
    def ephemeral_storage_local_ssd_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigResult']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_configs")

    @property
    @pulumi.getter(name="fastSockets")
    def fast_sockets(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigFastSocketResult']:
        """
        Enable or disable NCCL Fast Socket in the node pool.
        """
        return pulumi.get(self, "fast_sockets")

    @property
    @pulumi.getter(name="gcfsConfigs")
    def gcfs_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGcfsConfigResult']:
        """
        GCFS configuration for this node.
        """
        return pulumi.get(self, "gcfs_configs")

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorResult']:
        """
        List of the type and count of accelerator cards attached to the instance.
        """
        return pulumi.get(self, "guest_accelerators")

    @property
    @pulumi.getter
    def gvnics(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGvnicResult']:
        """
        Enable or disable gvnic in the node pool.
        """
        return pulumi.get(self, "gvnics")

    @property
    @pulumi.getter(name="hostMaintenancePolicies")
    def host_maintenance_policies(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigHostMaintenancePolicyResult']:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policies")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> str:
        """
        The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="kubeletConfigs")
    def kubelet_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigResult']:
        """
        Node kubelet configs.
        """
        return pulumi.get(self, "kubelet_configs")

    @property
    @pulumi.getter
    def labels(self) -> Mapping[str, str]:
        """
        The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="linuxNodeConfigs")
    def linux_node_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigLinuxNodeConfigResult']:
        """
        Parameters that can be configured on Linux nodes.
        """
        return pulumi.get(self, "linux_node_configs")

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfigs")
    def local_nvme_ssd_block_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigResult']:
        """
        Parameters for raw-block local NVMe SSDs.
        """
        return pulumi.get(self, "local_nvme_ssd_block_configs")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        The number of local SSD disks to be attached to the node.
        """
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> str:
        """
        Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        """
        return pulumi.get(self, "logging_variant")

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> str:
        """
        The name of a Google Compute Engine machine type.
        """
        return pulumi.get(self, "machine_type")

    @property
    @pulumi.getter
    def metadata(self) -> Mapping[str, str]:
        """
        The metadata key/value pairs assigned to instances in the cluster.
        """
        return pulumi.get(self, "metadata")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> str:
        """
        Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        """
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> str:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        """
        return pulumi.get(self, "node_group")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Sequence[str]:
        """
        The set of Google API scopes to be made available on all of the node VMs.
        """
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter
    def preemptible(self) -> bool:
        """
        Whether the nodes are created as preemptible VM instances.
        """
        return pulumi.get(self, "preemptible")

    @property
    @pulumi.getter(name="reservationAffinities")
    def reservation_affinities(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigReservationAffinityResult']:
        """
        The reservation affinity configuration for the node pool.
        """
        return pulumi.get(self, "reservation_affinities")

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Mapping[str, str]:
        """
        The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        """
        return pulumi.get(self, "resource_labels")

    @property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Mapping[str, str]:
        """
        A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        """
        return pulumi.get(self, "resource_manager_tags")

    @property
    @pulumi.getter(name="sandboxConfigs")
    def sandbox_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigSandboxConfigResult']:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_configs")

    @property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigSecondaryBootDiskResult']:
        """
        Secondary boot disks for preloading data or container images.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> str:
        """
        The Google Cloud Platform Service Account to be used by the node VMs.
        """
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfigs")
    def shielded_instance_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigShieldedInstanceConfigResult']:
        """
        Shielded Instance options.
        """
        return pulumi.get(self, "shielded_instance_configs")

    @property
    @pulumi.getter(name="soleTenantConfigs")
    def sole_tenant_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigSoleTenantConfigResult']:
        """
        Node affinity options for sole tenant node pools.
        """
        return pulumi.get(self, "sole_tenant_configs")

    @property
    @pulumi.getter
    def spot(self) -> bool:
        """
        Whether the nodes are created as spot VM instances.
        """
        return pulumi.get(self, "spot")

    @property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Sequence[str]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @property
    @pulumi.getter
    def tags(self) -> Sequence[str]:
        """
        The list of instance tags applied to all nodes.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def taints(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigTaintResult']:
        """
        List of Kubernetes taints to be applied to each node.
        """
        return pulumi.get(self, "taints")

    @property
    @pulumi.getter(name="workloadMetadataConfigs")
    def workload_metadata_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigWorkloadMetadataConfigResult']:
        """
        The workload metadata configuration for this node.
        """
        return pulumi.get(self, "workload_metadata_configs")


@pulumi.output_type
class GetClusterNodePoolNodeConfigAdvancedMachineFeatureResult(dict):
    def __init__(__self__, *,
                 enable_nested_virtualization: bool,
                 threads_per_core: int):
        """
        :param bool enable_nested_virtualization: Whether the node should have nested virtualization enabled.
        :param int threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)
        pulumi.set(__self__, "threads_per_core", threads_per_core)

    @property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> bool:
        """
        Whether the node should have nested virtualization enabled.
        """
        return pulumi.get(self, "enable_nested_virtualization")

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> int:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")


@pulumi.output_type
class GetClusterNodePoolNodeConfigConfidentialNodeResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigContainerdConfigResult(dict):
    def __init__(__self__, *,
                 private_registry_access_configs: Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigResult']):
        """
        :param Sequence['GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs'] private_registry_access_configs: Parameters for private container registries configuration.
        """
        pulumi.set(__self__, "private_registry_access_configs", private_registry_access_configs)

    @property
    @pulumi.getter(name="privateRegistryAccessConfigs")
    def private_registry_access_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigResult']:
        """
        Parameters for private container registries configuration.
        """
        return pulumi.get(self, "private_registry_access_configs")


@pulumi.output_type
class GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigResult(dict):
    def __init__(__self__, *,
                 certificate_authority_domain_configs: Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult'],
                 enabled: bool):
        """
        :param Sequence['GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: Parameters for configuring CA certificate and domains.
        :param bool enabled: Whether or not private registries are configured.
        """
        pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult']:
        """
        Parameters for configuring CA certificate and domains.
        """
        return pulumi.get(self, "certificate_authority_domain_configs")

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not private registries are configured.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult(dict):
    def __init__(__self__, *,
                 fqdns: Sequence[str],
                 gcp_secret_manager_certificate_configs: Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult']):
        """
        :param Sequence[str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param Sequence['GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs'] gcp_secret_manager_certificate_configs: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_configs", gcp_secret_manager_certificate_configs)

    @property
    @pulumi.getter
    def fqdns(self) -> Sequence[str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @property
    @pulumi.getter(name="gcpSecretManagerCertificateConfigs")
    def gcp_secret_manager_certificate_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult']:
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_configs")


@pulumi.output_type
class GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult(dict):
    def __init__(__self__, *,
                 secret_uri: str):
        """
        :param str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class GetClusterNodePoolNodeConfigEffectiveTaintResult(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        """
        :param str effect: Effect for taint.
        :param str key: Key for taint.
        :param str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class GetClusterNodePoolNodeConfigEphemeralStorageConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodePoolNodeConfigFastSocketResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGcfsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not GCFS is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not GCFS is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGuestAcceleratorResult(dict):
    def __init__(__self__, *,
                 count: int,
                 gpu_driver_installation_configs: Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult'],
                 gpu_partition_size: str,
                 gpu_sharing_configs: Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigResult'],
                 type: str):
        """
        :param int count: The number of the accelerator cards exposed to an instance.
        :param Sequence['GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs'] gpu_driver_installation_configs: Configuration for auto installation of GPU driver.
        :param str gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        :param Sequence['GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs'] gpu_sharing_configs: Configuration for GPU sharing.
        :param str type: The accelerator type resource name.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "gpu_driver_installation_configs", gpu_driver_installation_configs)
        pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        pulumi.set(__self__, "gpu_sharing_configs", gpu_sharing_configs)
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def count(self) -> int:
        """
        The number of the accelerator cards exposed to an instance.
        """
        return pulumi.get(self, "count")

    @property
    @pulumi.getter(name="gpuDriverInstallationConfigs")
    def gpu_driver_installation_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult']:
        """
        Configuration for auto installation of GPU driver.
        """
        return pulumi.get(self, "gpu_driver_installation_configs")

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> str:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        """
        return pulumi.get(self, "gpu_partition_size")

    @property
    @pulumi.getter(name="gpuSharingConfigs")
    def gpu_sharing_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigResult']:
        """
        Configuration for GPU sharing.
        """
        return pulumi.get(self, "gpu_sharing_configs")

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        The accelerator type resource name.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult(dict):
    def __init__(__self__, *,
                 gpu_driver_version: str):
        """
        :param str gpu_driver_version: Mode for how the GPU driver is installed.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> str:
        """
        Mode for how the GPU driver is installed.
        """
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigResult(dict):
    def __init__(__self__, *,
                 gpu_sharing_strategy: str,
                 max_shared_clients_per_gpu: int):
        """
        :param str gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        :param int max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> str:
        """
        The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> int:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGvnicResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not gvnic is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not gvnic is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigHostMaintenancePolicyResult(dict):
    def __init__(__self__, *,
                 maintenance_interval: str):
        """
        :param str maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> str:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class GetClusterNodePoolNodeConfigKubeletConfigResult(dict):
    def __init__(__self__, *,
                 cpu_cfs_quota: bool,
                 cpu_cfs_quota_period: str,
                 cpu_manager_policy: str,
                 insecure_kubelet_readonly_port_enabled: str,
                 pod_pids_limit: int):
        """
        :param bool cpu_cfs_quota: Enable CPU CFS quota enforcement for containers that specify CPU limits.
        :param str cpu_cfs_quota_period: Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        :param str cpu_manager_policy: Control the CPU management policy on the node.
        :param str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param int pod_pids_limit: Controls the maximum number of processes allowed to run in a pod.
        """
        pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> bool:
        """
        Enable CPU CFS quota enforcement for containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> str:
        """
        Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> str:
        """
        Control the CPU management policy on the node.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> str:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> int:
        """
        Controls the maximum number of processes allowed to run in a pod.
        """
        return pulumi.get(self, "pod_pids_limit")


@pulumi.output_type
class GetClusterNodePoolNodeConfigLinuxNodeConfigResult(dict):
    def __init__(__self__, *,
                 cgroup_mode: str,
                 hugepages_configs: Sequence['outputs.GetClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigResult'],
                 sysctls: Mapping[str, str]):
        """
        :param str cgroup_mode: cgroupMode specifies the cgroup mode to be used on the node.
        :param Sequence['GetClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs'] hugepages_configs: Amounts for 2M and 1G hugepages.
        :param Mapping[str, str] sysctls: The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        """
        pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        pulumi.set(__self__, "hugepages_configs", hugepages_configs)
        pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> str:
        """
        cgroupMode specifies the cgroup mode to be used on the node.
        """
        return pulumi.get(self, "cgroup_mode")

    @property
    @pulumi.getter(name="hugepagesConfigs")
    def hugepages_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigResult']:
        """
        Amounts for 2M and 1G hugepages.
        """
        return pulumi.get(self, "hugepages_configs")

    @property
    @pulumi.getter
    def sysctls(self) -> Mapping[str, str]:
        """
        The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        """
        return pulumi.get(self, "sysctls")


@pulumi.output_type
class GetClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigResult(dict):
    def __init__(__self__, *,
                 hugepage_size1g: int,
                 hugepage_size2m: int):
        """
        :param int hugepage_size1g: Amount of 1G hugepages.
        :param int hugepage_size2m: Amount of 2M hugepages.
        """
        pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> int:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> int:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")


@pulumi.output_type
class GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodePoolNodeConfigReservationAffinityResult(dict):
    def __init__(__self__, *,
                 consume_reservation_type: str,
                 key: str,
                 values: Sequence[str]):
        """
        :param str consume_reservation_type: Corresponds to the type of reservation consumption.
        :param str key: The label key of a reservation resource.
        :param Sequence[str] values: The label values of the reservation resource.
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> str:
        """
        Corresponds to the type of reservation consumption.
        """
        return pulumi.get(self, "consume_reservation_type")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        The label key of a reservation resource.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        """
        The label values of the reservation resource.
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class GetClusterNodePoolNodeConfigSandboxConfigResult(dict):
    def __init__(__self__, *,
                 sandbox_type: str):
        """
        :param str sandbox_type: Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> str:
        """
        Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class GetClusterNodePoolNodeConfigSecondaryBootDiskResult(dict):
    def __init__(__self__, *,
                 disk_image: str,
                 mode: str):
        """
        :param str disk_image: Disk image to create the secondary boot disk from
        :param str mode: Mode for how the secondary boot disk is used.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> str:
        """
        Disk image to create the secondary boot disk from
        """
        return pulumi.get(self, "disk_image")

    @property
    @pulumi.getter
    def mode(self) -> str:
        """
        Mode for how the secondary boot disk is used.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class GetClusterNodePoolNodeConfigShieldedInstanceConfigResult(dict):
    def __init__(__self__, *,
                 enable_integrity_monitoring: bool,
                 enable_secure_boot: bool):
        """
        :param bool enable_integrity_monitoring: Defines whether the instance has integrity monitoring enabled.
        :param bool enable_secure_boot: Defines whether the instance has Secure Boot enabled.
        """
        pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> bool:
        """
        Defines whether the instance has integrity monitoring enabled.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> bool:
        """
        Defines whether the instance has Secure Boot enabled.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class GetClusterNodePoolNodeConfigSoleTenantConfigResult(dict):
    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityResult']):
        """
        :param Sequence['GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs'] node_affinities: .
        """
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityResult']:
        """
        .
        """
        return pulumi.get(self, "node_affinities")


@pulumi.output_type
class GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityResult(dict):
    def __init__(__self__, *,
                 key: str,
                 operator: str,
                 values: Sequence[str]):
        """
        :param str key: .
        :param str operator: .
        :param Sequence[str] values: .
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        .
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def operator(self) -> str:
        """
        .
        """
        return pulumi.get(self, "operator")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        """
        .
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class GetClusterNodePoolNodeConfigTaintResult(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        """
        :param str effect: Effect for taint.
        :param str key: Key for taint.
        :param str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class GetClusterNodePoolNodeConfigWorkloadMetadataConfigResult(dict):
    def __init__(__self__, *,
                 mode: str):
        """
        :param str mode: Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> str:
        """
        Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class GetClusterNodePoolPlacementPolicyResult(dict):
    def __init__(__self__, *,
                 policy_name: str,
                 tpu_topology: str,
                 type: str):
        """
        :param str policy_name: If set, refers to the name of a custom resource policy supplied by the user. The resource policy must be in the same project and region as the node pool. If not found, InvalidArgument error is returned.
        :param str tpu_topology: TPU placement topology for pod slice node pool. https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies
        :param str type: Type defines the type of placement policy
        """
        pulumi.set(__self__, "policy_name", policy_name)
        pulumi.set(__self__, "tpu_topology", tpu_topology)
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> str:
        """
        If set, refers to the name of a custom resource policy supplied by the user. The resource policy must be in the same project and region as the node pool. If not found, InvalidArgument error is returned.
        """
        return pulumi.get(self, "policy_name")

    @property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> str:
        """
        TPU placement topology for pod slice node pool. https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies
        """
        return pulumi.get(self, "tpu_topology")

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        Type defines the type of placement policy
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterNodePoolQueuedProvisioningResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether nodes in this node pool are obtainable solely through the ProvisioningRequest API
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether nodes in this node pool are obtainable solely through the ProvisioningRequest API
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolUpgradeSettingResult(dict):
    def __init__(__self__, *,
                 blue_green_settings: Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingResult'],
                 max_surge: int,
                 max_unavailable: int,
                 strategy: str):
        """
        :param Sequence['GetClusterNodePoolUpgradeSettingBlueGreenSettingArgs'] blue_green_settings: Settings for BlueGreen node pool upgrade.
        :param int max_surge: The number of additional nodes that can be added to the node pool during an upgrade. Increasing max_surge raises the number of nodes that can be upgraded simultaneously. Can be set to 0 or greater.
        :param int max_unavailable: The number of nodes that can be simultaneously unavailable during an upgrade. Increasing max_unavailable raises the number of nodes that can be upgraded in parallel. Can be set to 0 or greater.
        :param str strategy: Update strategy for the given nodepool.
        """
        pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        pulumi.set(__self__, "max_surge", max_surge)
        pulumi.set(__self__, "max_unavailable", max_unavailable)
        pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingResult']:
        """
        Settings for BlueGreen node pool upgrade.
        """
        return pulumi.get(self, "blue_green_settings")

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> int:
        """
        The number of additional nodes that can be added to the node pool during an upgrade. Increasing max_surge raises the number of nodes that can be upgraded simultaneously. Can be set to 0 or greater.
        """
        return pulumi.get(self, "max_surge")

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> int:
        """
        The number of nodes that can be simultaneously unavailable during an upgrade. Increasing max_unavailable raises the number of nodes that can be upgraded in parallel. Can be set to 0 or greater.
        """
        return pulumi.get(self, "max_unavailable")

    @property
    @pulumi.getter
    def strategy(self) -> str:
        """
        Update strategy for the given nodepool.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class GetClusterNodePoolUpgradeSettingBlueGreenSettingResult(dict):
    def __init__(__self__, *,
                 node_pool_soak_duration: str,
                 standard_rollout_policies: Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult']):
        """
        :param str node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up.
        :param Sequence['GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyArgs'] standard_rollout_policies: Standard rollout policy is the default policy for blue-green.
        """
        pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        pulumi.set(__self__, "standard_rollout_policies", standard_rollout_policies)

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> str:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up.
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @property
    @pulumi.getter(name="standardRolloutPolicies")
    def standard_rollout_policies(self) -> Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult']:
        """
        Standard rollout policy is the default policy for blue-green.
        """
        return pulumi.get(self, "standard_rollout_policies")


@pulumi.output_type
class GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult(dict):
    def __init__(__self__, *,
                 batch_node_count: int,
                 batch_percentage: float,
                 batch_soak_duration: str):
        """
        :param int batch_node_count: Number of blue nodes to drain in a batch.
        :param float batch_percentage: Percentage of the blue pool nodes to drain in a batch.
        :param str batch_soak_duration: Soak time after each batch gets drained.
        """
        pulumi.set(__self__, "batch_node_count", batch_node_count)
        pulumi.set(__self__, "batch_percentage", batch_percentage)
        pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> int:
        """
        Number of blue nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_node_count")

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> float:
        """
        Percentage of the blue pool nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_percentage")

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> str:
        """
        Soak time after each batch gets drained.
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class GetClusterNotificationConfigResult(dict):
    def __init__(__self__, *,
                 pubsubs: Sequence['outputs.GetClusterNotificationConfigPubsubResult']):
        """
        :param Sequence['GetClusterNotificationConfigPubsubArgs'] pubsubs: Notification config for Cloud Pub/Sub
        """
        pulumi.set(__self__, "pubsubs", pubsubs)

    @property
    @pulumi.getter
    def pubsubs(self) -> Sequence['outputs.GetClusterNotificationConfigPubsubResult']:
        """
        Notification config for Cloud Pub/Sub
        """
        return pulumi.get(self, "pubsubs")


@pulumi.output_type
class GetClusterNotificationConfigPubsubResult(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 filters: Sequence['outputs.GetClusterNotificationConfigPubsubFilterResult'],
                 topic: str):
        """
        :param bool enabled: Whether or not the notification config is enabled
        :param Sequence['GetClusterNotificationConfigPubsubFilterArgs'] filters: Allows filtering to one or more specific event types. If event types are present, those and only those event types will be transmitted to the cluster. Other types will be skipped. If no filter is specified, or no event types are present, all event types will be sent
        :param str topic: The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: projects/{project}/topics/{topic}.
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "filters", filters)
        pulumi.set(__self__, "topic", topic)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the notification config is enabled
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter
    def filters(self) -> Sequence['outputs.GetClusterNotificationConfigPubsubFilterResult']:
        """
        Allows filtering to one or more specific event types. If event types are present, those and only those event types will be transmitted to the cluster. Other types will be skipped. If no filter is specified, or no event types are present, all event types will be sent
        """
        return pulumi.get(self, "filters")

    @property
    @pulumi.getter
    def topic(self) -> str:
        """
        The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: projects/{project}/topics/{topic}.
        """
        return pulumi.get(self, "topic")


@pulumi.output_type
class GetClusterNotificationConfigPubsubFilterResult(dict):
    def __init__(__self__, *,
                 event_types: Sequence[str]):
        """
        :param Sequence[str] event_types: Can be used to filter what notifications are sent. Valid values include include UPGRADE_AVAILABLE_EVENT, UPGRADE_EVENT and SECURITY_BULLETIN_EVENT
        """
        pulumi.set(__self__, "event_types", event_types)

    @property
    @pulumi.getter(name="eventTypes")
    def event_types(self) -> Sequence[str]:
        """
        Can be used to filter what notifications are sent. Valid values include include UPGRADE_AVAILABLE_EVENT, UPGRADE_EVENT and SECURITY_BULLETIN_EVENT
        """
        return pulumi.get(self, "event_types")


@pulumi.output_type
class GetClusterPodSecurityPolicyConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable the PodSecurityPolicy controller for this cluster. If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable the PodSecurityPolicy controller for this cluster. If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterPrivateClusterConfigResult(dict):
    def __init__(__self__, *,
                 enable_private_endpoint: bool,
                 enable_private_nodes: bool,
                 master_global_access_configs: Sequence['outputs.GetClusterPrivateClusterConfigMasterGlobalAccessConfigResult'],
                 master_ipv4_cidr_block: str,
                 peering_name: str,
                 private_endpoint: str,
                 private_endpoint_subnetwork: str,
                 public_endpoint: str):
        """
        :param bool enable_private_endpoint: When true, the cluster's private endpoint is used as the cluster endpoint and access through the public endpoint is disabled. When false, either endpoint can be used.
        :param bool enable_private_nodes: Enables the private cluster feature, creating a private endpoint on the cluster. In a private cluster, nodes only have RFC 1918 private addresses and communicate with the master's private endpoint via private networking.
        :param Sequence['GetClusterPrivateClusterConfigMasterGlobalAccessConfigArgs'] master_global_access_configs: Controls cluster master global access settings.
        :param str master_ipv4_cidr_block: The IP range in CIDR notation to use for the hosted master network. This range will be used for assigning private IP addresses to the cluster master(s) and the ILB VIP. This range must not overlap with any other ranges in use within the cluster's network, and it must be a /28 subnet. See Private Cluster Limitations for more details. This field only applies to private clusters, when enable_private_nodes is true.
        :param str peering_name: The name of the peering between this cluster and the Google owned VPC.
        :param str private_endpoint: The internal IP address of this cluster's master endpoint.
        :param str private_endpoint_subnetwork: Subnetwork in cluster's network where master's endpoint will be provisioned.
        :param str public_endpoint: The external IP address of this cluster's master endpoint.
        """
        pulumi.set(__self__, "enable_private_endpoint", enable_private_endpoint)
        pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        pulumi.set(__self__, "master_global_access_configs", master_global_access_configs)
        pulumi.set(__self__, "master_ipv4_cidr_block", master_ipv4_cidr_block)
        pulumi.set(__self__, "peering_name", peering_name)
        pulumi.set(__self__, "private_endpoint", private_endpoint)
        pulumi.set(__self__, "private_endpoint_subnetwork", private_endpoint_subnetwork)
        pulumi.set(__self__, "public_endpoint", public_endpoint)

    @property
    @pulumi.getter(name="enablePrivateEndpoint")
    def enable_private_endpoint(self) -> bool:
        """
        When true, the cluster's private endpoint is used as the cluster endpoint and access through the public endpoint is disabled. When false, either endpoint can be used.
        """
        return pulumi.get(self, "enable_private_endpoint")

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> bool:
        """
        Enables the private cluster feature, creating a private endpoint on the cluster. In a private cluster, nodes only have RFC 1918 private addresses and communicate with the master's private endpoint via private networking.
        """
        return pulumi.get(self, "enable_private_nodes")

    @property
    @pulumi.getter(name="masterGlobalAccessConfigs")
    def master_global_access_configs(self) -> Sequence['outputs.GetClusterPrivateClusterConfigMasterGlobalAccessConfigResult']:
        """
        Controls cluster master global access settings.
        """
        return pulumi.get(self, "master_global_access_configs")

    @property
    @pulumi.getter(name="masterIpv4CidrBlock")
    def master_ipv4_cidr_block(self) -> str:
        """
        The IP range in CIDR notation to use for the hosted master network. This range will be used for assigning private IP addresses to the cluster master(s) and the ILB VIP. This range must not overlap with any other ranges in use within the cluster's network, and it must be a /28 subnet. See Private Cluster Limitations for more details. This field only applies to private clusters, when enable_private_nodes is true.
        """
        return pulumi.get(self, "master_ipv4_cidr_block")

    @property
    @pulumi.getter(name="peeringName")
    def peering_name(self) -> str:
        """
        The name of the peering between this cluster and the Google owned VPC.
        """
        return pulumi.get(self, "peering_name")

    @property
    @pulumi.getter(name="privateEndpoint")
    def private_endpoint(self) -> str:
        """
        The internal IP address of this cluster's master endpoint.
        """
        return pulumi.get(self, "private_endpoint")

    @property
    @pulumi.getter(name="privateEndpointSubnetwork")
    def private_endpoint_subnetwork(self) -> str:
        """
        Subnetwork in cluster's network where master's endpoint will be provisioned.
        """
        return pulumi.get(self, "private_endpoint_subnetwork")

    @property
    @pulumi.getter(name="publicEndpoint")
    def public_endpoint(self) -> str:
        """
        The external IP address of this cluster's master endpoint.
        """
        return pulumi.get(self, "public_endpoint")


@pulumi.output_type
class GetClusterPrivateClusterConfigMasterGlobalAccessConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether the cluster master is accessible globally or not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether the cluster master is accessible globally or not.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterProtectConfigResult(dict):
    def __init__(__self__, *,
                 workload_configs: Sequence['outputs.GetClusterProtectConfigWorkloadConfigResult'],
                 workload_vulnerability_mode: str):
        """
        :param Sequence['GetClusterProtectConfigWorkloadConfigArgs'] workload_configs: WorkloadConfig defines which actions are enabled for a cluster's workload configurations.
        :param str workload_vulnerability_mode: Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        pulumi.set(__self__, "workload_configs", workload_configs)
        pulumi.set(__self__, "workload_vulnerability_mode", workload_vulnerability_mode)

    @property
    @pulumi.getter(name="workloadConfigs")
    def workload_configs(self) -> Sequence['outputs.GetClusterProtectConfigWorkloadConfigResult']:
        """
        WorkloadConfig defines which actions are enabled for a cluster's workload configurations.
        """
        return pulumi.get(self, "workload_configs")

    @property
    @pulumi.getter(name="workloadVulnerabilityMode")
    def workload_vulnerability_mode(self) -> str:
        """
        Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "workload_vulnerability_mode")


@pulumi.output_type
class GetClusterProtectConfigWorkloadConfigResult(dict):
    def __init__(__self__, *,
                 audit_mode: str):
        """
        :param str audit_mode: Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        pulumi.set(__self__, "audit_mode", audit_mode)

    @property
    @pulumi.getter(name="auditMode")
    def audit_mode(self) -> str:
        """
        Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "audit_mode")


@pulumi.output_type
class GetClusterReleaseChannelResult(dict):
    def __init__(__self__, *,
                 channel: str):
        """
        :param str channel: The selected release channel. Accepted values are:
               * UNSPECIFIED: Not set.
               * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
               * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
               * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
               * EXTENDED: GKE provides extended support for Kubernetes minor versions through the Extended channel. With this channel, you can stay on a minor version for up to 24 months.
        """
        pulumi.set(__self__, "channel", channel)

    @property
    @pulumi.getter
    def channel(self) -> str:
        """
        The selected release channel. Accepted values are:
        * UNSPECIFIED: Not set.
        * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
        * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
        * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
        * EXTENDED: GKE provides extended support for Kubernetes minor versions through the Extended channel. With this channel, you can stay on a minor version for up to 24 months.
        """
        return pulumi.get(self, "channel")


@pulumi.output_type
class GetClusterResourceUsageExportConfigResult(dict):
    def __init__(__self__, *,
                 bigquery_destinations: Sequence['outputs.GetClusterResourceUsageExportConfigBigqueryDestinationResult'],
                 enable_network_egress_metering: bool,
                 enable_resource_consumption_metering: bool):
        """
        :param Sequence['GetClusterResourceUsageExportConfigBigqueryDestinationArgs'] bigquery_destinations: Parameters for using BigQuery as the destination of resource usage export.
        :param bool enable_network_egress_metering: Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created in the cluster to meter network egress traffic.
        :param bool enable_resource_consumption_metering: Whether to enable resource consumption metering on this cluster. When enabled, a table will be created in the resource export BigQuery dataset to store resource consumption data. The resulting table can be joined with the resource usage table or with BigQuery billing export. Defaults to true.
        """
        pulumi.set(__self__, "bigquery_destinations", bigquery_destinations)
        pulumi.set(__self__, "enable_network_egress_metering", enable_network_egress_metering)
        pulumi.set(__self__, "enable_resource_consumption_metering", enable_resource_consumption_metering)

    @property
    @pulumi.getter(name="bigqueryDestinations")
    def bigquery_destinations(self) -> Sequence['outputs.GetClusterResourceUsageExportConfigBigqueryDestinationResult']:
        """
        Parameters for using BigQuery as the destination of resource usage export.
        """
        return pulumi.get(self, "bigquery_destinations")

    @property
    @pulumi.getter(name="enableNetworkEgressMetering")
    def enable_network_egress_metering(self) -> bool:
        """
        Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created in the cluster to meter network egress traffic.
        """
        return pulumi.get(self, "enable_network_egress_metering")

    @property
    @pulumi.getter(name="enableResourceConsumptionMetering")
    def enable_resource_consumption_metering(self) -> bool:
        """
        Whether to enable resource consumption metering on this cluster. When enabled, a table will be created in the resource export BigQuery dataset to store resource consumption data. The resulting table can be joined with the resource usage table or with BigQuery billing export. Defaults to true.
        """
        return pulumi.get(self, "enable_resource_consumption_metering")


@pulumi.output_type
class GetClusterResourceUsageExportConfigBigqueryDestinationResult(dict):
    def __init__(__self__, *,
                 dataset_id: str):
        """
        :param str dataset_id: The ID of a BigQuery Dataset.
        """
        pulumi.set(__self__, "dataset_id", dataset_id)

    @property
    @pulumi.getter(name="datasetId")
    def dataset_id(self) -> str:
        """
        The ID of a BigQuery Dataset.
        """
        return pulumi.get(self, "dataset_id")


@pulumi.output_type
class GetClusterSecretManagerConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable the Secret manager csi component.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable the Secret manager csi component.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterSecurityPostureConfigResult(dict):
    def __init__(__self__, *,
                 mode: str,
                 vulnerability_mode: str):
        """
        :param str mode: Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include DISABLED, BASIC, and ENTERPRISE.
        :param str vulnerability_mode: Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include VULNERABILITY_DISABLED, VULNERABILITY_BASIC and VULNERABILITY_ENTERPRISE.
        """
        pulumi.set(__self__, "mode", mode)
        pulumi.set(__self__, "vulnerability_mode", vulnerability_mode)

    @property
    @pulumi.getter
    def mode(self) -> str:
        """
        Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include DISABLED, BASIC, and ENTERPRISE.
        """
        return pulumi.get(self, "mode")

    @property
    @pulumi.getter(name="vulnerabilityMode")
    def vulnerability_mode(self) -> str:
        """
        Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include VULNERABILITY_DISABLED, VULNERABILITY_BASIC and VULNERABILITY_ENTERPRISE.
        """
        return pulumi.get(self, "vulnerability_mode")


@pulumi.output_type
class GetClusterServiceExternalIpsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: When enabled, services with external ips specified will be allowed.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        When enabled, services with external ips specified will be allowed.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterTpuConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 ipv4_cidr_block: str,
                 use_service_networking: bool):
        """
        :param bool enabled: Whether Cloud TPU integration is enabled or not
        :param str ipv4_cidr_block: IPv4 CIDR block reserved for Cloud TPU in the VPC.
        :param bool use_service_networking: Whether to use service networking for Cloud TPU or not
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "ipv4_cidr_block", ipv4_cidr_block)
        pulumi.set(__self__, "use_service_networking", use_service_networking)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether Cloud TPU integration is enabled or not
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="ipv4CidrBlock")
    def ipv4_cidr_block(self) -> str:
        """
        IPv4 CIDR block reserved for Cloud TPU in the VPC.
        """
        return pulumi.get(self, "ipv4_cidr_block")

    @property
    @pulumi.getter(name="useServiceNetworking")
    def use_service_networking(self) -> bool:
        """
        Whether to use service networking for Cloud TPU or not
        """
        return pulumi.get(self, "use_service_networking")


@pulumi.output_type
class GetClusterVerticalPodAutoscalingResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enables vertical pod autoscaling.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enables vertical pod autoscaling.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterWorkloadAltsConfigResult(dict):
    def __init__(__self__, *,
                 enable_alts: bool):
        """
        :param bool enable_alts: Whether the alts handshaker should be enabled or not for direct-path. Requires Workload Identity (workloadPool must be non-empty).
        """
        pulumi.set(__self__, "enable_alts", enable_alts)

    @property
    @pulumi.getter(name="enableAlts")
    def enable_alts(self) -> bool:
        """
        Whether the alts handshaker should be enabled or not for direct-path. Requires Workload Identity (workloadPool must be non-empty).
        """
        return pulumi.get(self, "enable_alts")


@pulumi.output_type
class GetClusterWorkloadIdentityConfigResult(dict):
    def __init__(__self__, *,
                 workload_pool: str):
        """
        :param str workload_pool: The workload pool to attach all Kubernetes service accounts to.
        """
        pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> str:
        """
        The workload pool to attach all Kubernetes service accounts to.
        """
        return pulumi.get(self, "workload_pool")


