# coding=utf-8
# *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import copy
import warnings
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
from .. import _utilities
from . import outputs

__all__ = [
    'AttachedClusterAuthorization',
    'AttachedClusterBinaryAuthorization',
    'AttachedClusterError',
    'AttachedClusterFleet',
    'AttachedClusterLoggingConfig',
    'AttachedClusterLoggingConfigComponentConfig',
    'AttachedClusterMonitoringConfig',
    'AttachedClusterMonitoringConfigManagedPrometheusConfig',
    'AttachedClusterOidcConfig',
    'AttachedClusterWorkloadIdentityConfig',
    'AwsClusterAuthorization',
    'AwsClusterAuthorizationAdminUser',
    'AwsClusterControlPlane',
    'AwsClusterControlPlaneAwsServicesAuthentication',
    'AwsClusterControlPlaneConfigEncryption',
    'AwsClusterControlPlaneDatabaseEncryption',
    'AwsClusterControlPlaneInstancePlacement',
    'AwsClusterControlPlaneMainVolume',
    'AwsClusterControlPlaneProxyConfig',
    'AwsClusterControlPlaneRootVolume',
    'AwsClusterControlPlaneSshConfig',
    'AwsClusterFleet',
    'AwsClusterLoggingConfig',
    'AwsClusterLoggingConfigComponentConfig',
    'AwsClusterNetworking',
    'AwsClusterWorkloadIdentityConfig',
    'AwsNodePoolAutoscaling',
    'AwsNodePoolConfig',
    'AwsNodePoolConfigAutoscalingMetricsCollection',
    'AwsNodePoolConfigConfigEncryption',
    'AwsNodePoolConfigInstancePlacement',
    'AwsNodePoolConfigProxyConfig',
    'AwsNodePoolConfigRootVolume',
    'AwsNodePoolConfigSpotConfig',
    'AwsNodePoolConfigSshConfig',
    'AwsNodePoolConfigTaint',
    'AwsNodePoolManagement',
    'AwsNodePoolMaxPodsConstraint',
    'AzureClusterAuthorization',
    'AzureClusterAuthorizationAdminUser',
    'AzureClusterAzureServicesAuthentication',
    'AzureClusterControlPlane',
    'AzureClusterControlPlaneDatabaseEncryption',
    'AzureClusterControlPlaneMainVolume',
    'AzureClusterControlPlaneProxyConfig',
    'AzureClusterControlPlaneReplicaPlacement',
    'AzureClusterControlPlaneRootVolume',
    'AzureClusterControlPlaneSshConfig',
    'AzureClusterFleet',
    'AzureClusterLoggingConfig',
    'AzureClusterLoggingConfigComponentConfig',
    'AzureClusterNetworking',
    'AzureClusterWorkloadIdentityConfig',
    'AzureNodePoolAutoscaling',
    'AzureNodePoolConfig',
    'AzureNodePoolConfigProxyConfig',
    'AzureNodePoolConfigRootVolume',
    'AzureNodePoolConfigSshConfig',
    'AzureNodePoolManagement',
    'AzureNodePoolMaxPodsConstraint',
    'ClusterAddonsConfig',
    'ClusterAddonsConfigCloudrunConfig',
    'ClusterAddonsConfigConfigConnectorConfig',
    'ClusterAddonsConfigDnsCacheConfig',
    'ClusterAddonsConfigGcePersistentDiskCsiDriverConfig',
    'ClusterAddonsConfigGcpFilestoreCsiDriverConfig',
    'ClusterAddonsConfigGcsFuseCsiDriverConfig',
    'ClusterAddonsConfigGkeBackupAgentConfig',
    'ClusterAddonsConfigHorizontalPodAutoscaling',
    'ClusterAddonsConfigHttpLoadBalancing',
    'ClusterAddonsConfigIstioConfig',
    'ClusterAddonsConfigKalmConfig',
    'ClusterAddonsConfigNetworkPolicyConfig',
    'ClusterAuthenticatorGroupsConfig',
    'ClusterBinaryAuthorization',
    'ClusterClusterAutoscaling',
    'ClusterClusterAutoscalingAutoProvisioningDefaults',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsManagement',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
    'ClusterClusterAutoscalingResourceLimit',
    'ClusterClusterTelemetry',
    'ClusterConfidentialNodes',
    'ClusterCostManagementConfig',
    'ClusterDatabaseEncryption',
    'ClusterDefaultSnatStatus',
    'ClusterDnsConfig',
    'ClusterEnableK8sBetaApis',
    'ClusterGatewayApiConfig',
    'ClusterIdentityServiceConfig',
    'ClusterIpAllocationPolicy',
    'ClusterIpAllocationPolicyAdditionalPodRangesConfig',
    'ClusterIpAllocationPolicyPodCidrOverprovisionConfig',
    'ClusterLoggingConfig',
    'ClusterMaintenancePolicy',
    'ClusterMaintenancePolicyDailyMaintenanceWindow',
    'ClusterMaintenancePolicyMaintenanceExclusion',
    'ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions',
    'ClusterMaintenancePolicyRecurringWindow',
    'ClusterMasterAuth',
    'ClusterMasterAuthClientCertificateConfig',
    'ClusterMasterAuthorizedNetworksConfig',
    'ClusterMasterAuthorizedNetworksConfigCidrBlock',
    'ClusterMeshCertificates',
    'ClusterMonitoringConfig',
    'ClusterMonitoringConfigAdvancedDatapathObservabilityConfig',
    'ClusterMonitoringConfigManagedPrometheus',
    'ClusterNetworkPolicy',
    'ClusterNodeConfig',
    'ClusterNodeConfigAdvancedMachineFeatures',
    'ClusterNodeConfigConfidentialNodes',
    'ClusterNodeConfigEphemeralStorageConfig',
    'ClusterNodeConfigEphemeralStorageLocalSsdConfig',
    'ClusterNodeConfigFastSocket',
    'ClusterNodeConfigGcfsConfig',
    'ClusterNodeConfigGuestAccelerator',
    'ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig',
    'ClusterNodeConfigGuestAcceleratorGpuSharingConfig',
    'ClusterNodeConfigGvnic',
    'ClusterNodeConfigHostMaintenancePolicy',
    'ClusterNodeConfigKubeletConfig',
    'ClusterNodeConfigLinuxNodeConfig',
    'ClusterNodeConfigLocalNvmeSsdBlockConfig',
    'ClusterNodeConfigReservationAffinity',
    'ClusterNodeConfigSandboxConfig',
    'ClusterNodeConfigShieldedInstanceConfig',
    'ClusterNodeConfigSoleTenantConfig',
    'ClusterNodeConfigSoleTenantConfigNodeAffinity',
    'ClusterNodeConfigTaint',
    'ClusterNodeConfigWorkloadMetadataConfig',
    'ClusterNodePool',
    'ClusterNodePoolAutoConfig',
    'ClusterNodePoolAutoConfigNetworkTags',
    'ClusterNodePoolAutoscaling',
    'ClusterNodePoolDefaults',
    'ClusterNodePoolDefaultsNodeConfigDefaults',
    'ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfig',
    'ClusterNodePoolManagement',
    'ClusterNodePoolNetworkConfig',
    'ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfig',
    'ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig',
    'ClusterNodePoolNetworkConfigPodCidrOverprovisionConfig',
    'ClusterNodePoolNodeConfig',
    'ClusterNodePoolNodeConfigAdvancedMachineFeatures',
    'ClusterNodePoolNodeConfigConfidentialNodes',
    'ClusterNodePoolNodeConfigEphemeralStorageConfig',
    'ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig',
    'ClusterNodePoolNodeConfigFastSocket',
    'ClusterNodePoolNodeConfigGcfsConfig',
    'ClusterNodePoolNodeConfigGuestAccelerator',
    'ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig',
    'ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig',
    'ClusterNodePoolNodeConfigGvnic',
    'ClusterNodePoolNodeConfigHostMaintenancePolicy',
    'ClusterNodePoolNodeConfigKubeletConfig',
    'ClusterNodePoolNodeConfigLinuxNodeConfig',
    'ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig',
    'ClusterNodePoolNodeConfigReservationAffinity',
    'ClusterNodePoolNodeConfigSandboxConfig',
    'ClusterNodePoolNodeConfigShieldedInstanceConfig',
    'ClusterNodePoolNodeConfigSoleTenantConfig',
    'ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinity',
    'ClusterNodePoolNodeConfigTaint',
    'ClusterNodePoolNodeConfigWorkloadMetadataConfig',
    'ClusterNodePoolPlacementPolicy',
    'ClusterNodePoolUpgradeSettings',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettings',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
    'ClusterNotificationConfig',
    'ClusterNotificationConfigPubsub',
    'ClusterNotificationConfigPubsubFilter',
    'ClusterPodSecurityPolicyConfig',
    'ClusterPrivateClusterConfig',
    'ClusterPrivateClusterConfigMasterGlobalAccessConfig',
    'ClusterProtectConfig',
    'ClusterProtectConfigWorkloadConfig',
    'ClusterReleaseChannel',
    'ClusterResourceUsageExportConfig',
    'ClusterResourceUsageExportConfigBigqueryDestination',
    'ClusterSecurityPostureConfig',
    'ClusterServiceExternalIpsConfig',
    'ClusterTpuConfig',
    'ClusterVerticalPodAutoscaling',
    'ClusterWorkloadIdentityConfig',
    'NodePoolAutoscaling',
    'NodePoolManagement',
    'NodePoolNetworkConfig',
    'NodePoolNetworkConfigAdditionalNodeNetworkConfig',
    'NodePoolNetworkConfigAdditionalPodNetworkConfig',
    'NodePoolNetworkConfigPodCidrOverprovisionConfig',
    'NodePoolNodeConfig',
    'NodePoolNodeConfigAdvancedMachineFeatures',
    'NodePoolNodeConfigConfidentialNodes',
    'NodePoolNodeConfigEphemeralStorageConfig',
    'NodePoolNodeConfigEphemeralStorageLocalSsdConfig',
    'NodePoolNodeConfigFastSocket',
    'NodePoolNodeConfigGcfsConfig',
    'NodePoolNodeConfigGuestAccelerator',
    'NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig',
    'NodePoolNodeConfigGuestAcceleratorGpuSharingConfig',
    'NodePoolNodeConfigGvnic',
    'NodePoolNodeConfigHostMaintenancePolicy',
    'NodePoolNodeConfigKubeletConfig',
    'NodePoolNodeConfigLinuxNodeConfig',
    'NodePoolNodeConfigLocalNvmeSsdBlockConfig',
    'NodePoolNodeConfigReservationAffinity',
    'NodePoolNodeConfigSandboxConfig',
    'NodePoolNodeConfigShieldedInstanceConfig',
    'NodePoolNodeConfigSoleTenantConfig',
    'NodePoolNodeConfigSoleTenantConfigNodeAffinity',
    'NodePoolNodeConfigTaint',
    'NodePoolNodeConfigWorkloadMetadataConfig',
    'NodePoolPlacementPolicy',
    'NodePoolUpgradeSettings',
    'NodePoolUpgradeSettingsBlueGreenSettings',
    'NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
    'GetClusterAddonsConfigResult',
    'GetClusterAddonsConfigCloudrunConfigResult',
    'GetClusterAddonsConfigConfigConnectorConfigResult',
    'GetClusterAddonsConfigDnsCacheConfigResult',
    'GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigResult',
    'GetClusterAddonsConfigGcpFilestoreCsiDriverConfigResult',
    'GetClusterAddonsConfigGcsFuseCsiDriverConfigResult',
    'GetClusterAddonsConfigGkeBackupAgentConfigResult',
    'GetClusterAddonsConfigHorizontalPodAutoscalingResult',
    'GetClusterAddonsConfigHttpLoadBalancingResult',
    'GetClusterAddonsConfigIstioConfigResult',
    'GetClusterAddonsConfigKalmConfigResult',
    'GetClusterAddonsConfigNetworkPolicyConfigResult',
    'GetClusterAuthenticatorGroupsConfigResult',
    'GetClusterBinaryAuthorizationResult',
    'GetClusterClusterAutoscalingResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultManagementResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult',
    'GetClusterClusterAutoscalingResourceLimitResult',
    'GetClusterClusterTelemetryResult',
    'GetClusterConfidentialNodeResult',
    'GetClusterCostManagementConfigResult',
    'GetClusterDatabaseEncryptionResult',
    'GetClusterDefaultSnatStatusResult',
    'GetClusterDnsConfigResult',
    'GetClusterEnableK8sBetaApiResult',
    'GetClusterGatewayApiConfigResult',
    'GetClusterIdentityServiceConfigResult',
    'GetClusterIpAllocationPolicyResult',
    'GetClusterIpAllocationPolicyAdditionalPodRangesConfigResult',
    'GetClusterIpAllocationPolicyPodCidrOverprovisionConfigResult',
    'GetClusterLoggingConfigResult',
    'GetClusterMaintenancePolicyResult',
    'GetClusterMaintenancePolicyDailyMaintenanceWindowResult',
    'GetClusterMaintenancePolicyMaintenanceExclusionResult',
    'GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionResult',
    'GetClusterMaintenancePolicyRecurringWindowResult',
    'GetClusterMasterAuthResult',
    'GetClusterMasterAuthClientCertificateConfigResult',
    'GetClusterMasterAuthorizedNetworksConfigResult',
    'GetClusterMasterAuthorizedNetworksConfigCidrBlockResult',
    'GetClusterMeshCertificateResult',
    'GetClusterMonitoringConfigResult',
    'GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigResult',
    'GetClusterMonitoringConfigManagedPrometheusResult',
    'GetClusterNetworkPolicyResult',
    'GetClusterNodeConfigResult',
    'GetClusterNodeConfigAdvancedMachineFeatureResult',
    'GetClusterNodeConfigConfidentialNodeResult',
    'GetClusterNodeConfigEphemeralStorageConfigResult',
    'GetClusterNodeConfigEphemeralStorageLocalSsdConfigResult',
    'GetClusterNodeConfigFastSocketResult',
    'GetClusterNodeConfigGcfsConfigResult',
    'GetClusterNodeConfigGuestAcceleratorResult',
    'GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult',
    'GetClusterNodeConfigGuestAcceleratorGpuSharingConfigResult',
    'GetClusterNodeConfigGvnicResult',
    'GetClusterNodeConfigHostMaintenancePolicyResult',
    'GetClusterNodeConfigKubeletConfigResult',
    'GetClusterNodeConfigLinuxNodeConfigResult',
    'GetClusterNodeConfigLocalNvmeSsdBlockConfigResult',
    'GetClusterNodeConfigReservationAffinityResult',
    'GetClusterNodeConfigSandboxConfigResult',
    'GetClusterNodeConfigShieldedInstanceConfigResult',
    'GetClusterNodeConfigSoleTenantConfigResult',
    'GetClusterNodeConfigSoleTenantConfigNodeAffinityResult',
    'GetClusterNodeConfigTaintResult',
    'GetClusterNodeConfigWorkloadMetadataConfigResult',
    'GetClusterNodePoolResult',
    'GetClusterNodePoolAutoConfigResult',
    'GetClusterNodePoolAutoConfigNetworkTagResult',
    'GetClusterNodePoolAutoscalingResult',
    'GetClusterNodePoolDefaultResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigResult',
    'GetClusterNodePoolManagementResult',
    'GetClusterNodePoolNetworkConfigResult',
    'GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigResult',
    'GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigResult',
    'GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigResult',
    'GetClusterNodePoolNodeConfigResult',
    'GetClusterNodePoolNodeConfigAdvancedMachineFeatureResult',
    'GetClusterNodePoolNodeConfigConfidentialNodeResult',
    'GetClusterNodePoolNodeConfigEphemeralStorageConfigResult',
    'GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigResult',
    'GetClusterNodePoolNodeConfigFastSocketResult',
    'GetClusterNodePoolNodeConfigGcfsConfigResult',
    'GetClusterNodePoolNodeConfigGuestAcceleratorResult',
    'GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult',
    'GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigResult',
    'GetClusterNodePoolNodeConfigGvnicResult',
    'GetClusterNodePoolNodeConfigHostMaintenancePolicyResult',
    'GetClusterNodePoolNodeConfigKubeletConfigResult',
    'GetClusterNodePoolNodeConfigLinuxNodeConfigResult',
    'GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigResult',
    'GetClusterNodePoolNodeConfigReservationAffinityResult',
    'GetClusterNodePoolNodeConfigSandboxConfigResult',
    'GetClusterNodePoolNodeConfigShieldedInstanceConfigResult',
    'GetClusterNodePoolNodeConfigSoleTenantConfigResult',
    'GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityResult',
    'GetClusterNodePoolNodeConfigTaintResult',
    'GetClusterNodePoolNodeConfigWorkloadMetadataConfigResult',
    'GetClusterNodePoolPlacementPolicyResult',
    'GetClusterNodePoolUpgradeSettingResult',
    'GetClusterNodePoolUpgradeSettingBlueGreenSettingResult',
    'GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult',
    'GetClusterNotificationConfigResult',
    'GetClusterNotificationConfigPubsubResult',
    'GetClusterNotificationConfigPubsubFilterResult',
    'GetClusterPodSecurityPolicyConfigResult',
    'GetClusterPrivateClusterConfigResult',
    'GetClusterPrivateClusterConfigMasterGlobalAccessConfigResult',
    'GetClusterProtectConfigResult',
    'GetClusterProtectConfigWorkloadConfigResult',
    'GetClusterReleaseChannelResult',
    'GetClusterResourceUsageExportConfigResult',
    'GetClusterResourceUsageExportConfigBigqueryDestinationResult',
    'GetClusterSecurityPostureConfigResult',
    'GetClusterServiceExternalIpsConfigResult',
    'GetClusterTpuConfigResult',
    'GetClusterVerticalPodAutoscalingResult',
    'GetClusterWorkloadIdentityConfigResult',
]

@pulumi.output_type
class AttachedClusterAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminUsers":
            suggest = "admin_users"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_users: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] admin_users: Users that can perform operations as a cluster admin. A managed
               ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
               to the users. Up to ten admin users can be provided.
               For more info on RBAC, see
               https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        if admin_users is not None:
            pulumi.set(__self__, "admin_users", admin_users)

    @property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> Optional[Sequence[str]]:
        """
        Users that can perform operations as a cluster admin. A managed
        ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
        to the users. Up to ten admin users can be provided.
        For more info on RBAC, see
        https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")


@pulumi.output_type
class AttachedClusterBinaryAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "evaluationMode":
            suggest = "evaluation_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterBinaryAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterBinaryAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterBinaryAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 evaluation_mode: Optional[str] = None):
        """
        :param str evaluation_mode: Configure Binary Authorization evaluation mode.
               Possible values are: `DISABLED`, `PROJECT_SINGLETON_POLICY_ENFORCE`.
        """
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[str]:
        """
        Configure Binary Authorization evaluation mode.
        Possible values are: `DISABLED`, `PROJECT_SINGLETON_POLICY_ENFORCE`.
        """
        return pulumi.get(self, "evaluation_mode")


@pulumi.output_type
class AttachedClusterError(dict):
    def __init__(__self__, *,
                 message: Optional[str] = None):
        """
        :param str message: Human-friendly description of the error.
        """
        if message is not None:
            pulumi.set(__self__, "message", message)

    @property
    @pulumi.getter
    def message(self) -> Optional[str]:
        """
        Human-friendly description of the error.
        """
        return pulumi.get(self, "message")


@pulumi.output_type
class AttachedClusterFleet(dict):
    def __init__(__self__, *,
                 project: str,
                 membership: Optional[str] = None):
        """
        :param str project: The ID of the project in which the resource belongs.
               If it is not provided, the provider project is used.
        :param str membership: (Output)
               The name of the managed Hub Membership resource associated to this
               cluster. Membership names are formatted as
               projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        pulumi.set(__self__, "project", project)
        if membership is not None:
            pulumi.set(__self__, "membership", membership)

    @property
    @pulumi.getter
    def project(self) -> str:
        """
        The ID of the project in which the resource belongs.
        If it is not provided, the provider project is used.
        """
        return pulumi.get(self, "project")

    @property
    @pulumi.getter
    def membership(self) -> Optional[str]:
        """
        (Output)
        The name of the managed Hub Membership resource associated to this
        cluster. Membership names are formatted as
        projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")


@pulumi.output_type
class AttachedClusterLoggingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "componentConfig":
            suggest = "component_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterLoggingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterLoggingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterLoggingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component_config: Optional['outputs.AttachedClusterLoggingConfigComponentConfig'] = None):
        """
        :param 'AttachedClusterLoggingConfigComponentConfigArgs' component_config: The configuration of the logging components
               Structure is documented below.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional['outputs.AttachedClusterLoggingConfigComponentConfig']:
        """
        The configuration of the logging components
        Structure is documented below.
        """
        return pulumi.get(self, "component_config")


@pulumi.output_type
class AttachedClusterLoggingConfigComponentConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableComponents":
            suggest = "enable_components"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterLoggingConfigComponentConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_components: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] enable_components: The components to be enabled.
               Each value may be one of: `SYSTEM_COMPONENTS`, `WORKLOADS`.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[Sequence[str]]:
        """
        The components to be enabled.
        Each value may be one of: `SYSTEM_COMPONENTS`, `WORKLOADS`.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class AttachedClusterMonitoringConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "managedPrometheusConfig":
            suggest = "managed_prometheus_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterMonitoringConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterMonitoringConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterMonitoringConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 managed_prometheus_config: Optional['outputs.AttachedClusterMonitoringConfigManagedPrometheusConfig'] = None):
        """
        :param 'AttachedClusterMonitoringConfigManagedPrometheusConfigArgs' managed_prometheus_config: Enable Google Cloud Managed Service for Prometheus in the cluster.
               Structure is documented below.
        """
        if managed_prometheus_config is not None:
            pulumi.set(__self__, "managed_prometheus_config", managed_prometheus_config)

    @property
    @pulumi.getter(name="managedPrometheusConfig")
    def managed_prometheus_config(self) -> Optional['outputs.AttachedClusterMonitoringConfigManagedPrometheusConfig']:
        """
        Enable Google Cloud Managed Service for Prometheus in the cluster.
        Structure is documented below.
        """
        return pulumi.get(self, "managed_prometheus_config")


@pulumi.output_type
class AttachedClusterMonitoringConfigManagedPrometheusConfig(dict):
    def __init__(__self__, *,
                 enabled: Optional[bool] = None):
        """
        :param bool enabled: Enable Managed Collection.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[bool]:
        """
        Enable Managed Collection.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class AttachedClusterOidcConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "issuerUrl":
            suggest = "issuer_url"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterOidcConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterOidcConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterOidcConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 issuer_url: str,
                 jwks: Optional[str] = None):
        """
        :param str issuer_url: A JSON Web Token (JWT) issuer URI. `issuer` must start with `https://`
        :param str jwks: OIDC verification keys in JWKS format (RFC 7517).
        """
        pulumi.set(__self__, "issuer_url", issuer_url)
        if jwks is not None:
            pulumi.set(__self__, "jwks", jwks)

    @property
    @pulumi.getter(name="issuerUrl")
    def issuer_url(self) -> str:
        """
        A JSON Web Token (JWT) issuer URI. `issuer` must start with `https://`
        """
        return pulumi.get(self, "issuer_url")

    @property
    @pulumi.getter
    def jwks(self) -> Optional[str]:
        """
        OIDC verification keys in JWKS format (RFC 7517).
        """
        return pulumi.get(self, "jwks")


@pulumi.output_type
class AttachedClusterWorkloadIdentityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "identityProvider":
            suggest = "identity_provider"
        elif key == "issuerUri":
            suggest = "issuer_uri"
        elif key == "workloadPool":
            suggest = "workload_pool"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterWorkloadIdentityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterWorkloadIdentityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterWorkloadIdentityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 identity_provider: Optional[str] = None,
                 issuer_uri: Optional[str] = None,
                 workload_pool: Optional[str] = None):
        """
        :param str identity_provider: The ID of the OIDC Identity Provider (IdP) associated to
               the Workload Identity Pool.
        :param str issuer_uri: The OIDC issuer URL for this cluster.
        :param str workload_pool: The Workload Identity Pool associated to the cluster.
        """
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[str]:
        """
        The ID of the OIDC Identity Provider (IdP) associated to
        the Workload Identity Pool.
        """
        return pulumi.get(self, "identity_provider")

    @property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[str]:
        """
        The OIDC issuer URL for this cluster.
        """
        return pulumi.get(self, "issuer_uri")

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[str]:
        """
        The Workload Identity Pool associated to the cluster.
        """
        return pulumi.get(self, "workload_pool")


@pulumi.output_type
class AwsClusterAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminUsers":
            suggest = "admin_users"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_users: Sequence['outputs.AwsClusterAuthorizationAdminUser']):
        """
        :param Sequence['AwsClusterAuthorizationAdminUserArgs'] admin_users: Users to perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        pulumi.set(__self__, "admin_users", admin_users)

    @property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> Sequence['outputs.AwsClusterAuthorizationAdminUser']:
        """
        Users to perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")


@pulumi.output_type
class AwsClusterAuthorizationAdminUser(dict):
    def __init__(__self__, *,
                 username: str):
        """
        :param str username: The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def username(self) -> str:
        """
        The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class AwsClusterControlPlane(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "awsServicesAuthentication":
            suggest = "aws_services_authentication"
        elif key == "configEncryption":
            suggest = "config_encryption"
        elif key == "databaseEncryption":
            suggest = "database_encryption"
        elif key == "iamInstanceProfile":
            suggest = "iam_instance_profile"
        elif key == "subnetIds":
            suggest = "subnet_ids"
        elif key == "instancePlacement":
            suggest = "instance_placement"
        elif key == "instanceType":
            suggest = "instance_type"
        elif key == "mainVolume":
            suggest = "main_volume"
        elif key == "proxyConfig":
            suggest = "proxy_config"
        elif key == "rootVolume":
            suggest = "root_volume"
        elif key == "securityGroupIds":
            suggest = "security_group_ids"
        elif key == "sshConfig":
            suggest = "ssh_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlane. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlane.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlane.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 aws_services_authentication: 'outputs.AwsClusterControlPlaneAwsServicesAuthentication',
                 config_encryption: 'outputs.AwsClusterControlPlaneConfigEncryption',
                 database_encryption: 'outputs.AwsClusterControlPlaneDatabaseEncryption',
                 iam_instance_profile: str,
                 subnet_ids: Sequence[str],
                 version: str,
                 instance_placement: Optional['outputs.AwsClusterControlPlaneInstancePlacement'] = None,
                 instance_type: Optional[str] = None,
                 main_volume: Optional['outputs.AwsClusterControlPlaneMainVolume'] = None,
                 proxy_config: Optional['outputs.AwsClusterControlPlaneProxyConfig'] = None,
                 root_volume: Optional['outputs.AwsClusterControlPlaneRootVolume'] = None,
                 security_group_ids: Optional[Sequence[str]] = None,
                 ssh_config: Optional['outputs.AwsClusterControlPlaneSshConfig'] = None,
                 tags: Optional[Mapping[str, str]] = None):
        """
        :param 'AwsClusterControlPlaneAwsServicesAuthenticationArgs' aws_services_authentication: Authentication configuration for management of AWS resources.
        :param 'AwsClusterControlPlaneConfigEncryptionArgs' config_encryption: The ARN of the AWS KMS key used to encrypt cluster configuration.
        :param 'AwsClusterControlPlaneDatabaseEncryptionArgs' database_encryption: The ARN of the AWS KMS key used to encrypt cluster secrets.
        :param str iam_instance_profile: The name of the AWS IAM instance pofile to assign to each control plane replica.
        :param Sequence[str] subnet_ids: The list of subnets where control plane replicas will run. A replica will be provisioned on each subnet and up to three values can be provided. Each subnet must be in a different AWS Availability Zone (AZ).
        :param str version: The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling .
        :param 'AwsClusterControlPlaneInstancePlacementArgs' instance_placement: (Beta only) Details of placement information for an instance.
        :param str instance_type: Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        :param 'AwsClusterControlPlaneMainVolumeArgs' main_volume: Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 8 GiB with the GP2 volume type.
        :param 'AwsClusterControlPlaneProxyConfigArgs' proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param 'AwsClusterControlPlaneRootVolumeArgs' root_volume: Optional. Configuration related to the root volume provisioned for each control plane replica. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        :param Sequence[str] security_group_ids: Optional. The IDs of additional security groups to add to control plane replicas. The Anthos Multi-Cloud API will automatically create and manage security groups with the minimum rules needed for a functioning cluster.
        :param 'AwsClusterControlPlaneSshConfigArgs' ssh_config: Optional. SSH configuration for how to access the underlying control plane machines.
        :param Mapping[str, str] tags: Optional. A set of AWS resource tags to propagate to all underlying managed AWS resources. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        pulumi.set(__self__, "aws_services_authentication", aws_services_authentication)
        pulumi.set(__self__, "config_encryption", config_encryption)
        pulumi.set(__self__, "database_encryption", database_encryption)
        pulumi.set(__self__, "iam_instance_profile", iam_instance_profile)
        pulumi.set(__self__, "subnet_ids", subnet_ids)
        pulumi.set(__self__, "version", version)
        if instance_placement is not None:
            pulumi.set(__self__, "instance_placement", instance_placement)
        if instance_type is not None:
            pulumi.set(__self__, "instance_type", instance_type)
        if main_volume is not None:
            pulumi.set(__self__, "main_volume", main_volume)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if security_group_ids is not None:
            pulumi.set(__self__, "security_group_ids", security_group_ids)
        if ssh_config is not None:
            pulumi.set(__self__, "ssh_config", ssh_config)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @property
    @pulumi.getter(name="awsServicesAuthentication")
    def aws_services_authentication(self) -> 'outputs.AwsClusterControlPlaneAwsServicesAuthentication':
        """
        Authentication configuration for management of AWS resources.
        """
        return pulumi.get(self, "aws_services_authentication")

    @property
    @pulumi.getter(name="configEncryption")
    def config_encryption(self) -> 'outputs.AwsClusterControlPlaneConfigEncryption':
        """
        The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        return pulumi.get(self, "config_encryption")

    @property
    @pulumi.getter(name="databaseEncryption")
    def database_encryption(self) -> 'outputs.AwsClusterControlPlaneDatabaseEncryption':
        """
        The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        return pulumi.get(self, "database_encryption")

    @property
    @pulumi.getter(name="iamInstanceProfile")
    def iam_instance_profile(self) -> str:
        """
        The name of the AWS IAM instance pofile to assign to each control plane replica.
        """
        return pulumi.get(self, "iam_instance_profile")

    @property
    @pulumi.getter(name="subnetIds")
    def subnet_ids(self) -> Sequence[str]:
        """
        The list of subnets where control plane replicas will run. A replica will be provisioned on each subnet and up to three values can be provided. Each subnet must be in a different AWS Availability Zone (AZ).
        """
        return pulumi.get(self, "subnet_ids")

    @property
    @pulumi.getter
    def version(self) -> str:
        """
        The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling .
        """
        return pulumi.get(self, "version")

    @property
    @pulumi.getter(name="instancePlacement")
    def instance_placement(self) -> Optional['outputs.AwsClusterControlPlaneInstancePlacement']:
        """
        (Beta only) Details of placement information for an instance.
        """
        return pulumi.get(self, "instance_placement")

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> Optional[str]:
        """
        Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        """
        return pulumi.get(self, "instance_type")

    @property
    @pulumi.getter(name="mainVolume")
    def main_volume(self) -> Optional['outputs.AwsClusterControlPlaneMainVolume']:
        """
        Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 8 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "main_volume")

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional['outputs.AwsClusterControlPlaneProxyConfig']:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional['outputs.AwsClusterControlPlaneRootVolume']:
        """
        Optional. Configuration related to the root volume provisioned for each control plane replica. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "root_volume")

    @property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> Optional[Sequence[str]]:
        """
        Optional. The IDs of additional security groups to add to control plane replicas. The Anthos Multi-Cloud API will automatically create and manage security groups with the minimum rules needed for a functioning cluster.
        """
        return pulumi.get(self, "security_group_ids")

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> Optional['outputs.AwsClusterControlPlaneSshConfig']:
        """
        Optional. SSH configuration for how to access the underlying control plane machines.
        """
        return pulumi.get(self, "ssh_config")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, str]]:
        """
        Optional. A set of AWS resource tags to propagate to all underlying managed AWS resources. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")


@pulumi.output_type
class AwsClusterControlPlaneAwsServicesAuthentication(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "roleArn":
            suggest = "role_arn"
        elif key == "roleSessionName":
            suggest = "role_session_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneAwsServicesAuthentication. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneAwsServicesAuthentication.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneAwsServicesAuthentication.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 role_arn: str,
                 role_session_name: Optional[str] = None):
        """
        :param str role_arn: The Amazon Resource Name (ARN) of the role that the Anthos Multi-Cloud API will assume when managing AWS resources on your account.
        :param str role_session_name: Optional. An identifier for the assumed role session. When unspecified, it defaults to `multicloud-service-agent`.
        """
        pulumi.set(__self__, "role_arn", role_arn)
        if role_session_name is not None:
            pulumi.set(__self__, "role_session_name", role_session_name)

    @property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> str:
        """
        The Amazon Resource Name (ARN) of the role that the Anthos Multi-Cloud API will assume when managing AWS resources on your account.
        """
        return pulumi.get(self, "role_arn")

    @property
    @pulumi.getter(name="roleSessionName")
    def role_session_name(self) -> Optional[str]:
        """
        Optional. An identifier for the assumed role session. When unspecified, it defaults to `multicloud-service-agent`.
        """
        return pulumi.get(self, "role_session_name")


@pulumi.output_type
class AwsClusterControlPlaneConfigEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneConfigEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneConfigEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneConfigEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kms_key_arn: str):
        """
        :param str kms_key_arn: The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> str:
        """
        The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        return pulumi.get(self, "kms_key_arn")


@pulumi.output_type
class AwsClusterControlPlaneDatabaseEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneDatabaseEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneDatabaseEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneDatabaseEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kms_key_arn: str):
        """
        :param str kms_key_arn: The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> str:
        """
        The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        return pulumi.get(self, "kms_key_arn")


@pulumi.output_type
class AwsClusterControlPlaneInstancePlacement(dict):
    def __init__(__self__, *,
                 tenancy: Optional[str] = None):
        """
        :param str tenancy: The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        if tenancy is not None:
            pulumi.set(__self__, "tenancy", tenancy)

    @property
    @pulumi.getter
    def tenancy(self) -> Optional[str]:
        """
        The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        return pulumi.get(self, "tenancy")


@pulumi.output_type
class AwsClusterControlPlaneMainVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"
        elif key == "sizeGib":
            suggest = "size_gib"
        elif key == "volumeType":
            suggest = "volume_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneMainVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneMainVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneMainVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 iops: Optional[int] = None,
                 kms_key_arn: Optional[str] = None,
                 size_gib: Optional[int] = None,
                 throughput: Optional[int] = None,
                 volume_type: Optional[str] = None):
        """
        :param int iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param str kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param int size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param int throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3.
        :param str volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter
    def iops(self) -> Optional[int]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[str]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[int]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @property
    @pulumi.getter
    def throughput(self) -> Optional[int]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3.
        """
        return pulumi.get(self, "throughput")

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[str]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")


@pulumi.output_type
class AwsClusterControlPlaneProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretArn":
            suggest = "secret_arn"
        elif key == "secretVersion":
            suggest = "secret_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_arn: str,
                 secret_version: str):
        """
        :param str secret_arn: The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        :param str secret_version: The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        pulumi.set(__self__, "secret_arn", secret_arn)
        pulumi.set(__self__, "secret_version", secret_version)

    @property
    @pulumi.getter(name="secretArn")
    def secret_arn(self) -> str:
        """
        The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_arn")

    @property
    @pulumi.getter(name="secretVersion")
    def secret_version(self) -> str:
        """
        The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_version")


@pulumi.output_type
class AwsClusterControlPlaneRootVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"
        elif key == "sizeGib":
            suggest = "size_gib"
        elif key == "volumeType":
            suggest = "volume_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneRootVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneRootVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneRootVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 iops: Optional[int] = None,
                 kms_key_arn: Optional[str] = None,
                 size_gib: Optional[int] = None,
                 throughput: Optional[int] = None,
                 volume_type: Optional[str] = None):
        """
        :param int iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param str kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param int size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param int throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3.
        :param str volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter
    def iops(self) -> Optional[int]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[str]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[int]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @property
    @pulumi.getter
    def throughput(self) -> Optional[int]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3.
        """
        return pulumi.get(self, "throughput")

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[str]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")


@pulumi.output_type
class AwsClusterControlPlaneSshConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ec2KeyPair":
            suggest = "ec2_key_pair"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneSshConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneSshConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneSshConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ec2_key_pair: str):
        """
        :param str ec2_key_pair: The name of the EC2 key pair used to login into cluster machines.
        """
        pulumi.set(__self__, "ec2_key_pair", ec2_key_pair)

    @property
    @pulumi.getter(name="ec2KeyPair")
    def ec2_key_pair(self) -> str:
        """
        The name of the EC2 key pair used to login into cluster machines.
        """
        return pulumi.get(self, "ec2_key_pair")


@pulumi.output_type
class AwsClusterFleet(dict):
    def __init__(__self__, *,
                 membership: Optional[str] = None,
                 project: Optional[str] = None):
        """
        :param str membership: The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        :param str project: The number of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @property
    @pulumi.getter
    def membership(self) -> Optional[str]:
        """
        The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")

    @property
    @pulumi.getter
    def project(self) -> Optional[str]:
        """
        The number of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")


@pulumi.output_type
class AwsClusterLoggingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "componentConfig":
            suggest = "component_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterLoggingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterLoggingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterLoggingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component_config: Optional['outputs.AwsClusterLoggingConfigComponentConfig'] = None):
        """
        :param 'AwsClusterLoggingConfigComponentConfigArgs' component_config: Configuration of the logging components.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional['outputs.AwsClusterLoggingConfigComponentConfig']:
        """
        Configuration of the logging components.
        """
        return pulumi.get(self, "component_config")


@pulumi.output_type
class AwsClusterLoggingConfigComponentConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableComponents":
            suggest = "enable_components"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterLoggingConfigComponentConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_components: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] enable_components: Components of the logging configuration to be enabled.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[Sequence[str]]:
        """
        Components of the logging configuration to be enabled.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class AwsClusterNetworking(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "podAddressCidrBlocks":
            suggest = "pod_address_cidr_blocks"
        elif key == "serviceAddressCidrBlocks":
            suggest = "service_address_cidr_blocks"
        elif key == "vpcId":
            suggest = "vpc_id"
        elif key == "perNodePoolSgRulesDisabled":
            suggest = "per_node_pool_sg_rules_disabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterNetworking. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterNetworking.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterNetworking.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pod_address_cidr_blocks: Sequence[str],
                 service_address_cidr_blocks: Sequence[str],
                 vpc_id: str,
                 per_node_pool_sg_rules_disabled: Optional[bool] = None):
        """
        :param Sequence[str] pod_address_cidr_blocks: All pods in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param Sequence[str] service_address_cidr_blocks: All services in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param str vpc_id: The VPC associated with the cluster. All component clusters (i.e. control plane and node pools) run on a single VPC. This field cannot be changed after creation.
               
               - - -
        :param bool per_node_pool_sg_rules_disabled: Disable the per node pool subnet security group rules on the control plane security group. When set to true, you must also provide one or more security groups that ensure node pools are able to send requests to the control plane on TCP/443 and TCP/8132. Failure to do so may result in unavailable node pools.
        """
        pulumi.set(__self__, "pod_address_cidr_blocks", pod_address_cidr_blocks)
        pulumi.set(__self__, "service_address_cidr_blocks", service_address_cidr_blocks)
        pulumi.set(__self__, "vpc_id", vpc_id)
        if per_node_pool_sg_rules_disabled is not None:
            pulumi.set(__self__, "per_node_pool_sg_rules_disabled", per_node_pool_sg_rules_disabled)

    @property
    @pulumi.getter(name="podAddressCidrBlocks")
    def pod_address_cidr_blocks(self) -> Sequence[str]:
        """
        All pods in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "pod_address_cidr_blocks")

    @property
    @pulumi.getter(name="serviceAddressCidrBlocks")
    def service_address_cidr_blocks(self) -> Sequence[str]:
        """
        All services in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "service_address_cidr_blocks")

    @property
    @pulumi.getter(name="vpcId")
    def vpc_id(self) -> str:
        """
        The VPC associated with the cluster. All component clusters (i.e. control plane and node pools) run on a single VPC. This field cannot be changed after creation.

        - - -
        """
        return pulumi.get(self, "vpc_id")

    @property
    @pulumi.getter(name="perNodePoolSgRulesDisabled")
    def per_node_pool_sg_rules_disabled(self) -> Optional[bool]:
        """
        Disable the per node pool subnet security group rules on the control plane security group. When set to true, you must also provide one or more security groups that ensure node pools are able to send requests to the control plane on TCP/443 and TCP/8132. Failure to do so may result in unavailable node pools.
        """
        return pulumi.get(self, "per_node_pool_sg_rules_disabled")


@pulumi.output_type
class AwsClusterWorkloadIdentityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "identityProvider":
            suggest = "identity_provider"
        elif key == "issuerUri":
            suggest = "issuer_uri"
        elif key == "workloadPool":
            suggest = "workload_pool"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterWorkloadIdentityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterWorkloadIdentityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterWorkloadIdentityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 identity_provider: Optional[str] = None,
                 issuer_uri: Optional[str] = None,
                 workload_pool: Optional[str] = None):
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[str]:
        return pulumi.get(self, "identity_provider")

    @property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[str]:
        return pulumi.get(self, "issuer_uri")

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[str]:
        return pulumi.get(self, "workload_pool")


@pulumi.output_type
class AwsNodePoolAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxNodeCount":
            suggest = "max_node_count"
        elif key == "minNodeCount":
            suggest = "min_node_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_node_count: int,
                 min_node_count: int):
        """
        :param int max_node_count: Maximum number of nodes in the NodePool. Must be >= min_node_count.
        :param int min_node_count: Minimum number of nodes in the NodePool. Must be >= 1 and <= max_node_count.
        """
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> int:
        """
        Maximum number of nodes in the NodePool. Must be >= min_node_count.
        """
        return pulumi.get(self, "max_node_count")

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> int:
        """
        Minimum number of nodes in the NodePool. Must be >= 1 and <= max_node_count.
        """
        return pulumi.get(self, "min_node_count")


@pulumi.output_type
class AwsNodePoolConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "configEncryption":
            suggest = "config_encryption"
        elif key == "iamInstanceProfile":
            suggest = "iam_instance_profile"
        elif key == "autoscalingMetricsCollection":
            suggest = "autoscaling_metrics_collection"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "instancePlacement":
            suggest = "instance_placement"
        elif key == "instanceType":
            suggest = "instance_type"
        elif key == "proxyConfig":
            suggest = "proxy_config"
        elif key == "rootVolume":
            suggest = "root_volume"
        elif key == "securityGroupIds":
            suggest = "security_group_ids"
        elif key == "spotConfig":
            suggest = "spot_config"
        elif key == "sshConfig":
            suggest = "ssh_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 config_encryption: 'outputs.AwsNodePoolConfigConfigEncryption',
                 iam_instance_profile: str,
                 autoscaling_metrics_collection: Optional['outputs.AwsNodePoolConfigAutoscalingMetricsCollection'] = None,
                 image_type: Optional[str] = None,
                 instance_placement: Optional['outputs.AwsNodePoolConfigInstancePlacement'] = None,
                 instance_type: Optional[str] = None,
                 labels: Optional[Mapping[str, str]] = None,
                 proxy_config: Optional['outputs.AwsNodePoolConfigProxyConfig'] = None,
                 root_volume: Optional['outputs.AwsNodePoolConfigRootVolume'] = None,
                 security_group_ids: Optional[Sequence[str]] = None,
                 spot_config: Optional['outputs.AwsNodePoolConfigSpotConfig'] = None,
                 ssh_config: Optional['outputs.AwsNodePoolConfigSshConfig'] = None,
                 tags: Optional[Mapping[str, str]] = None,
                 taints: Optional[Sequence['outputs.AwsNodePoolConfigTaint']] = None):
        """
        :param 'AwsNodePoolConfigConfigEncryptionArgs' config_encryption: The ARN of the AWS KMS key used to encrypt node pool configuration.
        :param str iam_instance_profile: The name of the AWS IAM role assigned to nodes in the pool.
        :param 'AwsNodePoolConfigAutoscalingMetricsCollectionArgs' autoscaling_metrics_collection: Optional. Configuration related to CloudWatch metrics collection on the Auto Scaling group of the node pool. When unspecified, metrics collection is disabled.
        :param str image_type: (Beta only) The OS image type to use on node pool instances.
        :param 'AwsNodePoolConfigInstancePlacementArgs' instance_placement: (Beta only) Details of placement information for an instance.
        :param str instance_type: Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        :param Mapping[str, str] labels: Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        :param 'AwsNodePoolConfigProxyConfigArgs' proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param 'AwsNodePoolConfigRootVolumeArgs' root_volume: Optional. Template for the root volume provisioned for node pool nodes. Volumes will be provisioned in the availability zone assigned to the node pool subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        :param Sequence[str] security_group_ids: Optional. The IDs of additional security groups to add to nodes in this pool. The manager will automatically create security groups with minimum rules needed for a functioning cluster.
        :param 'AwsNodePoolConfigSpotConfigArgs' spot_config: (Beta only) Optional. When specified, the node pool will provision Spot instances from the set of spot_config.instance_types. This field is mutually exclusive with `instance_type`
        :param 'AwsNodePoolConfigSshConfigArgs' ssh_config: Optional. The SSH configuration.
        :param Mapping[str, str] tags: Optional. Key/value metadata to assign to each underlying AWS resource. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        :param Sequence['AwsNodePoolConfigTaintArgs'] taints: Optional. The initial taints assigned to nodes of this node pool.
        """
        pulumi.set(__self__, "config_encryption", config_encryption)
        pulumi.set(__self__, "iam_instance_profile", iam_instance_profile)
        if autoscaling_metrics_collection is not None:
            pulumi.set(__self__, "autoscaling_metrics_collection", autoscaling_metrics_collection)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if instance_placement is not None:
            pulumi.set(__self__, "instance_placement", instance_placement)
        if instance_type is not None:
            pulumi.set(__self__, "instance_type", instance_type)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if security_group_ids is not None:
            pulumi.set(__self__, "security_group_ids", security_group_ids)
        if spot_config is not None:
            pulumi.set(__self__, "spot_config", spot_config)
        if ssh_config is not None:
            pulumi.set(__self__, "ssh_config", ssh_config)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)

    @property
    @pulumi.getter(name="configEncryption")
    def config_encryption(self) -> 'outputs.AwsNodePoolConfigConfigEncryption':
        """
        The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        return pulumi.get(self, "config_encryption")

    @property
    @pulumi.getter(name="iamInstanceProfile")
    def iam_instance_profile(self) -> str:
        """
        The name of the AWS IAM role assigned to nodes in the pool.
        """
        return pulumi.get(self, "iam_instance_profile")

    @property
    @pulumi.getter(name="autoscalingMetricsCollection")
    def autoscaling_metrics_collection(self) -> Optional['outputs.AwsNodePoolConfigAutoscalingMetricsCollection']:
        """
        Optional. Configuration related to CloudWatch metrics collection on the Auto Scaling group of the node pool. When unspecified, metrics collection is disabled.
        """
        return pulumi.get(self, "autoscaling_metrics_collection")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[str]:
        """
        (Beta only) The OS image type to use on node pool instances.
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="instancePlacement")
    def instance_placement(self) -> Optional['outputs.AwsNodePoolConfigInstancePlacement']:
        """
        (Beta only) Details of placement information for an instance.
        """
        return pulumi.get(self, "instance_placement")

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> Optional[str]:
        """
        Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        """
        return pulumi.get(self, "instance_type")

    @property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, str]]:
        """
        Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional['outputs.AwsNodePoolConfigProxyConfig']:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional['outputs.AwsNodePoolConfigRootVolume']:
        """
        Optional. Template for the root volume provisioned for node pool nodes. Volumes will be provisioned in the availability zone assigned to the node pool subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "root_volume")

    @property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> Optional[Sequence[str]]:
        """
        Optional. The IDs of additional security groups to add to nodes in this pool. The manager will automatically create security groups with minimum rules needed for a functioning cluster.
        """
        return pulumi.get(self, "security_group_ids")

    @property
    @pulumi.getter(name="spotConfig")
    def spot_config(self) -> Optional['outputs.AwsNodePoolConfigSpotConfig']:
        """
        (Beta only) Optional. When specified, the node pool will provision Spot instances from the set of spot_config.instance_types. This field is mutually exclusive with `instance_type`
        """
        return pulumi.get(self, "spot_config")

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> Optional['outputs.AwsNodePoolConfigSshConfig']:
        """
        Optional. The SSH configuration.
        """
        return pulumi.get(self, "ssh_config")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, str]]:
        """
        Optional. Key/value metadata to assign to each underlying AWS resource. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def taints(self) -> Optional[Sequence['outputs.AwsNodePoolConfigTaint']]:
        """
        Optional. The initial taints assigned to nodes of this node pool.
        """
        return pulumi.get(self, "taints")


@pulumi.output_type
class AwsNodePoolConfigAutoscalingMetricsCollection(dict):
    def __init__(__self__, *,
                 granularity: str,
                 metrics: Optional[Sequence[str]] = None):
        """
        :param str granularity: The frequency at which EC2 Auto Scaling sends aggregated data to AWS CloudWatch. The only valid value is "1Minute".
        :param Sequence[str] metrics: The metrics to enable. For a list of valid metrics, see https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html. If you specify granularity and don't specify any metrics, all metrics are enabled.
        """
        pulumi.set(__self__, "granularity", granularity)
        if metrics is not None:
            pulumi.set(__self__, "metrics", metrics)

    @property
    @pulumi.getter
    def granularity(self) -> str:
        """
        The frequency at which EC2 Auto Scaling sends aggregated data to AWS CloudWatch. The only valid value is "1Minute".
        """
        return pulumi.get(self, "granularity")

    @property
    @pulumi.getter
    def metrics(self) -> Optional[Sequence[str]]:
        """
        The metrics to enable. For a list of valid metrics, see https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html. If you specify granularity and don't specify any metrics, all metrics are enabled.
        """
        return pulumi.get(self, "metrics")


@pulumi.output_type
class AwsNodePoolConfigConfigEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigConfigEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigConfigEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigConfigEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kms_key_arn: str):
        """
        :param str kms_key_arn: The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> str:
        """
        The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        return pulumi.get(self, "kms_key_arn")


@pulumi.output_type
class AwsNodePoolConfigInstancePlacement(dict):
    def __init__(__self__, *,
                 tenancy: Optional[str] = None):
        """
        :param str tenancy: The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        if tenancy is not None:
            pulumi.set(__self__, "tenancy", tenancy)

    @property
    @pulumi.getter
    def tenancy(self) -> Optional[str]:
        """
        The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        return pulumi.get(self, "tenancy")


@pulumi.output_type
class AwsNodePoolConfigProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretArn":
            suggest = "secret_arn"
        elif key == "secretVersion":
            suggest = "secret_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_arn: str,
                 secret_version: str):
        """
        :param str secret_arn: The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        :param str secret_version: The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        pulumi.set(__self__, "secret_arn", secret_arn)
        pulumi.set(__self__, "secret_version", secret_version)

    @property
    @pulumi.getter(name="secretArn")
    def secret_arn(self) -> str:
        """
        The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_arn")

    @property
    @pulumi.getter(name="secretVersion")
    def secret_version(self) -> str:
        """
        The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_version")


@pulumi.output_type
class AwsNodePoolConfigRootVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"
        elif key == "sizeGib":
            suggest = "size_gib"
        elif key == "volumeType":
            suggest = "volume_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigRootVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigRootVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigRootVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 iops: Optional[int] = None,
                 kms_key_arn: Optional[str] = None,
                 size_gib: Optional[int] = None,
                 throughput: Optional[int] = None,
                 volume_type: Optional[str] = None):
        """
        :param int iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param str kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param int size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param int throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3.
        :param str volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter
    def iops(self) -> Optional[int]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[str]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[int]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @property
    @pulumi.getter
    def throughput(self) -> Optional[int]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3.
        """
        return pulumi.get(self, "throughput")

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[str]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")


@pulumi.output_type
class AwsNodePoolConfigSpotConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "instanceTypes":
            suggest = "instance_types"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigSpotConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigSpotConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigSpotConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 instance_types: Sequence[str]):
        """
        :param Sequence[str] instance_types: List of AWS EC2 instance types for creating a spot node pool's nodes. The specified instance types must have the same number of CPUs and memory. You can use the Amazon EC2 Instance Selector tool (https://github.com/aws/amazon-ec2-instance-selector) to choose instance types with matching CPU and memory
        """
        pulumi.set(__self__, "instance_types", instance_types)

    @property
    @pulumi.getter(name="instanceTypes")
    def instance_types(self) -> Sequence[str]:
        """
        List of AWS EC2 instance types for creating a spot node pool's nodes. The specified instance types must have the same number of CPUs and memory. You can use the Amazon EC2 Instance Selector tool (https://github.com/aws/amazon-ec2-instance-selector) to choose instance types with matching CPU and memory
        """
        return pulumi.get(self, "instance_types")


@pulumi.output_type
class AwsNodePoolConfigSshConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ec2KeyPair":
            suggest = "ec2_key_pair"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigSshConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigSshConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigSshConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ec2_key_pair: str):
        """
        :param str ec2_key_pair: The name of the EC2 key pair used to login into cluster machines.
        """
        pulumi.set(__self__, "ec2_key_pair", ec2_key_pair)

    @property
    @pulumi.getter(name="ec2KeyPair")
    def ec2_key_pair(self) -> str:
        """
        The name of the EC2 key pair used to login into cluster machines.
        """
        return pulumi.get(self, "ec2_key_pair")


@pulumi.output_type
class AwsNodePoolConfigTaint(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        """
        :param str effect: The taint effect. Possible values: EFFECT_UNSPECIFIED, NO_SCHEDULE, PREFER_NO_SCHEDULE, NO_EXECUTE
        :param str key: Key for the taint.
        :param str value: Value for the taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        """
        The taint effect. Possible values: EFFECT_UNSPECIFIED, NO_SCHEDULE, PREFER_NO_SCHEDULE, NO_EXECUTE
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        Key for the taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value for the taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class AwsNodePoolManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[bool] = None):
        """
        :param bool auto_repair: Optional. Whether or not the nodes will be automatically repaired.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[bool]:
        """
        Optional. Whether or not the nodes will be automatically repaired.
        """
        return pulumi.get(self, "auto_repair")


@pulumi.output_type
class AwsNodePoolMaxPodsConstraint(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxPodsPerNode":
            suggest = "max_pods_per_node"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolMaxPodsConstraint. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolMaxPodsConstraint.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolMaxPodsConstraint.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_pods_per_node: int):
        """
        :param int max_pods_per_node: The maximum number of pods to schedule on a single node.
               
               - - -
        """
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> int:
        """
        The maximum number of pods to schedule on a single node.

        - - -
        """
        return pulumi.get(self, "max_pods_per_node")


@pulumi.output_type
class AzureClusterAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminUsers":
            suggest = "admin_users"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_users: Sequence['outputs.AzureClusterAuthorizationAdminUser']):
        """
        :param Sequence['AzureClusterAuthorizationAdminUserArgs'] admin_users: Users that can perform operations as a cluster admin. A new ClusterRoleBinding will be created to grant the cluster-admin ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        pulumi.set(__self__, "admin_users", admin_users)

    @property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> Sequence['outputs.AzureClusterAuthorizationAdminUser']:
        """
        Users that can perform operations as a cluster admin. A new ClusterRoleBinding will be created to grant the cluster-admin ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")


@pulumi.output_type
class AzureClusterAuthorizationAdminUser(dict):
    def __init__(__self__, *,
                 username: str):
        """
        :param str username: The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def username(self) -> str:
        """
        The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class AzureClusterAzureServicesAuthentication(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "applicationId":
            suggest = "application_id"
        elif key == "tenantId":
            suggest = "tenant_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterAzureServicesAuthentication. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterAzureServicesAuthentication.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterAzureServicesAuthentication.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 application_id: str,
                 tenant_id: str):
        """
        :param str application_id: The Azure Active Directory Application ID for Authentication configuration.
        :param str tenant_id: The Azure Active Directory Tenant ID for Authentication configuration.
        """
        pulumi.set(__self__, "application_id", application_id)
        pulumi.set(__self__, "tenant_id", tenant_id)

    @property
    @pulumi.getter(name="applicationId")
    def application_id(self) -> str:
        """
        The Azure Active Directory Application ID for Authentication configuration.
        """
        return pulumi.get(self, "application_id")

    @property
    @pulumi.getter(name="tenantId")
    def tenant_id(self) -> str:
        """
        The Azure Active Directory Tenant ID for Authentication configuration.
        """
        return pulumi.get(self, "tenant_id")


@pulumi.output_type
class AzureClusterControlPlane(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sshConfig":
            suggest = "ssh_config"
        elif key == "subnetId":
            suggest = "subnet_id"
        elif key == "databaseEncryption":
            suggest = "database_encryption"
        elif key == "mainVolume":
            suggest = "main_volume"
        elif key == "proxyConfig":
            suggest = "proxy_config"
        elif key == "replicaPlacements":
            suggest = "replica_placements"
        elif key == "rootVolume":
            suggest = "root_volume"
        elif key == "vmSize":
            suggest = "vm_size"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlane. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlane.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlane.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ssh_config: 'outputs.AzureClusterControlPlaneSshConfig',
                 subnet_id: str,
                 version: str,
                 database_encryption: Optional['outputs.AzureClusterControlPlaneDatabaseEncryption'] = None,
                 main_volume: Optional['outputs.AzureClusterControlPlaneMainVolume'] = None,
                 proxy_config: Optional['outputs.AzureClusterControlPlaneProxyConfig'] = None,
                 replica_placements: Optional[Sequence['outputs.AzureClusterControlPlaneReplicaPlacement']] = None,
                 root_volume: Optional['outputs.AzureClusterControlPlaneRootVolume'] = None,
                 tags: Optional[Mapping[str, str]] = None,
                 vm_size: Optional[str] = None):
        """
        :param 'AzureClusterControlPlaneSshConfigArgs' ssh_config: SSH configuration for how to access the underlying control plane machines.
        :param str subnet_id: The ARM ID of the subnet where the control plane VMs are deployed. Example: `/subscriptions//resourceGroups//providers/Microsoft.Network/virtualNetworks//subnets/default`.
        :param str version: The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling GetAzureServerConfig.
        :param 'AzureClusterControlPlaneDatabaseEncryptionArgs' database_encryption: Optional. Configuration related to application-layer secrets encryption.
        :param 'AzureClusterControlPlaneMainVolumeArgs' main_volume: Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. When unspecified, it defaults to a 8-GiB Azure Disk.
        :param 'AzureClusterControlPlaneProxyConfigArgs' proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param Sequence['AzureClusterControlPlaneReplicaPlacementArgs'] replica_placements: Configuration for where to place the control plane replicas. Up to three replica placement instances can be specified. If replica_placements is set, the replica placement instances will be applied to the three control plane replicas as evenly as possible.
        :param 'AzureClusterControlPlaneRootVolumeArgs' root_volume: Optional. Configuration related to the root volume provisioned for each control plane replica. When unspecified, it defaults to 32-GiB Azure Disk.
        :param Mapping[str, str] tags: Optional. A set of tags to apply to all underlying control plane Azure resources.
        :param str vm_size: Optional. The Azure VM size name. Example: `Standard_DS2_v2`. For available VM sizes, see https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        pulumi.set(__self__, "ssh_config", ssh_config)
        pulumi.set(__self__, "subnet_id", subnet_id)
        pulumi.set(__self__, "version", version)
        if database_encryption is not None:
            pulumi.set(__self__, "database_encryption", database_encryption)
        if main_volume is not None:
            pulumi.set(__self__, "main_volume", main_volume)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if replica_placements is not None:
            pulumi.set(__self__, "replica_placements", replica_placements)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if vm_size is not None:
            pulumi.set(__self__, "vm_size", vm_size)

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> 'outputs.AzureClusterControlPlaneSshConfig':
        """
        SSH configuration for how to access the underlying control plane machines.
        """
        return pulumi.get(self, "ssh_config")

    @property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> str:
        """
        The ARM ID of the subnet where the control plane VMs are deployed. Example: `/subscriptions//resourceGroups//providers/Microsoft.Network/virtualNetworks//subnets/default`.
        """
        return pulumi.get(self, "subnet_id")

    @property
    @pulumi.getter
    def version(self) -> str:
        """
        The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling GetAzureServerConfig.
        """
        return pulumi.get(self, "version")

    @property
    @pulumi.getter(name="databaseEncryption")
    def database_encryption(self) -> Optional['outputs.AzureClusterControlPlaneDatabaseEncryption']:
        """
        Optional. Configuration related to application-layer secrets encryption.
        """
        return pulumi.get(self, "database_encryption")

    @property
    @pulumi.getter(name="mainVolume")
    def main_volume(self) -> Optional['outputs.AzureClusterControlPlaneMainVolume']:
        """
        Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. When unspecified, it defaults to a 8-GiB Azure Disk.
        """
        return pulumi.get(self, "main_volume")

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional['outputs.AzureClusterControlPlaneProxyConfig']:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @property
    @pulumi.getter(name="replicaPlacements")
    def replica_placements(self) -> Optional[Sequence['outputs.AzureClusterControlPlaneReplicaPlacement']]:
        """
        Configuration for where to place the control plane replicas. Up to three replica placement instances can be specified. If replica_placements is set, the replica placement instances will be applied to the three control plane replicas as evenly as possible.
        """
        return pulumi.get(self, "replica_placements")

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional['outputs.AzureClusterControlPlaneRootVolume']:
        """
        Optional. Configuration related to the root volume provisioned for each control plane replica. When unspecified, it defaults to 32-GiB Azure Disk.
        """
        return pulumi.get(self, "root_volume")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, str]]:
        """
        Optional. A set of tags to apply to all underlying control plane Azure resources.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter(name="vmSize")
    def vm_size(self) -> Optional[str]:
        """
        Optional. The Azure VM size name. Example: `Standard_DS2_v2`. For available VM sizes, see https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        return pulumi.get(self, "vm_size")


@pulumi.output_type
class AzureClusterControlPlaneDatabaseEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "keyId":
            suggest = "key_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneDatabaseEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneDatabaseEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneDatabaseEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 key_id: str):
        """
        :param str key_id: The ARM ID of the Azure Key Vault key to encrypt / decrypt data. For example: `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>` Encryption will always take the latest version of the key and hence specific version is not supported.
        """
        pulumi.set(__self__, "key_id", key_id)

    @property
    @pulumi.getter(name="keyId")
    def key_id(self) -> str:
        """
        The ARM ID of the Azure Key Vault key to encrypt / decrypt data. For example: `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>` Encryption will always take the latest version of the key and hence specific version is not supported.
        """
        return pulumi.get(self, "key_id")


@pulumi.output_type
class AzureClusterControlPlaneMainVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sizeGib":
            suggest = "size_gib"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneMainVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneMainVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneMainVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 size_gib: Optional[int] = None):
        """
        :param int size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[int]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")


@pulumi.output_type
class AzureClusterControlPlaneProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "resourceGroupId":
            suggest = "resource_group_id"
        elif key == "secretId":
            suggest = "secret_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 resource_group_id: str,
                 secret_id: str):
        """
        :param str resource_group_id: The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        :param str secret_id: The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        pulumi.set(__self__, "resource_group_id", resource_group_id)
        pulumi.set(__self__, "secret_id", secret_id)

    @property
    @pulumi.getter(name="resourceGroupId")
    def resource_group_id(self) -> str:
        """
        The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        """
        return pulumi.get(self, "resource_group_id")

    @property
    @pulumi.getter(name="secretId")
    def secret_id(self) -> str:
        """
        The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        return pulumi.get(self, "secret_id")


@pulumi.output_type
class AzureClusterControlPlaneReplicaPlacement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "azureAvailabilityZone":
            suggest = "azure_availability_zone"
        elif key == "subnetId":
            suggest = "subnet_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneReplicaPlacement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneReplicaPlacement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneReplicaPlacement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 azure_availability_zone: str,
                 subnet_id: str):
        """
        :param str azure_availability_zone: For a given replica, the Azure availability zone where to provision the control plane VM and the ETCD disk.
        :param str subnet_id: For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
        """
        pulumi.set(__self__, "azure_availability_zone", azure_availability_zone)
        pulumi.set(__self__, "subnet_id", subnet_id)

    @property
    @pulumi.getter(name="azureAvailabilityZone")
    def azure_availability_zone(self) -> str:
        """
        For a given replica, the Azure availability zone where to provision the control plane VM and the ETCD disk.
        """
        return pulumi.get(self, "azure_availability_zone")

    @property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> str:
        """
        For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
        """
        return pulumi.get(self, "subnet_id")


@pulumi.output_type
class AzureClusterControlPlaneRootVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sizeGib":
            suggest = "size_gib"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneRootVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneRootVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneRootVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 size_gib: Optional[int] = None):
        """
        :param int size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[int]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")


@pulumi.output_type
class AzureClusterControlPlaneSshConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "authorizedKey":
            suggest = "authorized_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneSshConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneSshConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneSshConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 authorized_key: str):
        """
        :param str authorized_key: The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        pulumi.set(__self__, "authorized_key", authorized_key)

    @property
    @pulumi.getter(name="authorizedKey")
    def authorized_key(self) -> str:
        """
        The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        return pulumi.get(self, "authorized_key")


@pulumi.output_type
class AzureClusterFleet(dict):
    def __init__(__self__, *,
                 membership: Optional[str] = None,
                 project: Optional[str] = None):
        """
        :param str membership: The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        :param str project: The number of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @property
    @pulumi.getter
    def membership(self) -> Optional[str]:
        """
        The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")

    @property
    @pulumi.getter
    def project(self) -> Optional[str]:
        """
        The number of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")


@pulumi.output_type
class AzureClusterLoggingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "componentConfig":
            suggest = "component_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterLoggingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterLoggingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterLoggingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component_config: Optional['outputs.AzureClusterLoggingConfigComponentConfig'] = None):
        """
        :param 'AzureClusterLoggingConfigComponentConfigArgs' component_config: Configuration of the logging components.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional['outputs.AzureClusterLoggingConfigComponentConfig']:
        """
        Configuration of the logging components.
        """
        return pulumi.get(self, "component_config")


@pulumi.output_type
class AzureClusterLoggingConfigComponentConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableComponents":
            suggest = "enable_components"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterLoggingConfigComponentConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_components: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] enable_components: Components of the logging configuration to be enabled.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[Sequence[str]]:
        """
        Components of the logging configuration to be enabled.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class AzureClusterNetworking(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "podAddressCidrBlocks":
            suggest = "pod_address_cidr_blocks"
        elif key == "serviceAddressCidrBlocks":
            suggest = "service_address_cidr_blocks"
        elif key == "virtualNetworkId":
            suggest = "virtual_network_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterNetworking. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterNetworking.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterNetworking.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pod_address_cidr_blocks: Sequence[str],
                 service_address_cidr_blocks: Sequence[str],
                 virtual_network_id: str):
        """
        :param Sequence[str] pod_address_cidr_blocks: The IP address range of the pods in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All pods in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param Sequence[str] service_address_cidr_blocks: The IP address range for services in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All services in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creating a cluster.
        :param str virtual_network_id: The Azure Resource Manager (ARM) ID of the VNet associated with your cluster. All components in the cluster (i.e. control plane and node pools) run on a single VNet. Example: `/subscriptions/*/resourceGroups/*/providers/Microsoft.Network/virtualNetworks/*` This field cannot be changed after creation.
               
               - - -
        """
        pulumi.set(__self__, "pod_address_cidr_blocks", pod_address_cidr_blocks)
        pulumi.set(__self__, "service_address_cidr_blocks", service_address_cidr_blocks)
        pulumi.set(__self__, "virtual_network_id", virtual_network_id)

    @property
    @pulumi.getter(name="podAddressCidrBlocks")
    def pod_address_cidr_blocks(self) -> Sequence[str]:
        """
        The IP address range of the pods in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All pods in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "pod_address_cidr_blocks")

    @property
    @pulumi.getter(name="serviceAddressCidrBlocks")
    def service_address_cidr_blocks(self) -> Sequence[str]:
        """
        The IP address range for services in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All services in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creating a cluster.
        """
        return pulumi.get(self, "service_address_cidr_blocks")

    @property
    @pulumi.getter(name="virtualNetworkId")
    def virtual_network_id(self) -> str:
        """
        The Azure Resource Manager (ARM) ID of the VNet associated with your cluster. All components in the cluster (i.e. control plane and node pools) run on a single VNet. Example: `/subscriptions/*/resourceGroups/*/providers/Microsoft.Network/virtualNetworks/*` This field cannot be changed after creation.

        - - -
        """
        return pulumi.get(self, "virtual_network_id")


@pulumi.output_type
class AzureClusterWorkloadIdentityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "identityProvider":
            suggest = "identity_provider"
        elif key == "issuerUri":
            suggest = "issuer_uri"
        elif key == "workloadPool":
            suggest = "workload_pool"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterWorkloadIdentityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterWorkloadIdentityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterWorkloadIdentityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 identity_provider: Optional[str] = None,
                 issuer_uri: Optional[str] = None,
                 workload_pool: Optional[str] = None):
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[str]:
        return pulumi.get(self, "identity_provider")

    @property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[str]:
        return pulumi.get(self, "issuer_uri")

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[str]:
        return pulumi.get(self, "workload_pool")


@pulumi.output_type
class AzureNodePoolAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxNodeCount":
            suggest = "max_node_count"
        elif key == "minNodeCount":
            suggest = "min_node_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_node_count: int,
                 min_node_count: int):
        """
        :param int max_node_count: Maximum number of nodes in the node pool. Must be >= min_node_count.
        :param int min_node_count: Minimum number of nodes in the node pool. Must be >= 1 and <= max_node_count.
        """
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> int:
        """
        Maximum number of nodes in the node pool. Must be >= min_node_count.
        """
        return pulumi.get(self, "max_node_count")

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> int:
        """
        Minimum number of nodes in the node pool. Must be >= 1 and <= max_node_count.
        """
        return pulumi.get(self, "min_node_count")


@pulumi.output_type
class AzureNodePoolConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sshConfig":
            suggest = "ssh_config"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "proxyConfig":
            suggest = "proxy_config"
        elif key == "rootVolume":
            suggest = "root_volume"
        elif key == "vmSize":
            suggest = "vm_size"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ssh_config: 'outputs.AzureNodePoolConfigSshConfig',
                 image_type: Optional[str] = None,
                 proxy_config: Optional['outputs.AzureNodePoolConfigProxyConfig'] = None,
                 root_volume: Optional['outputs.AzureNodePoolConfigRootVolume'] = None,
                 tags: Optional[Mapping[str, str]] = None,
                 vm_size: Optional[str] = None):
        """
        :param 'AzureNodePoolConfigSshConfigArgs' ssh_config: SSH configuration for how to access the node pool machines.
        :param str image_type: (Beta only) The OS image type to use on node pool instances.
        :param 'AzureNodePoolConfigProxyConfigArgs' proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param 'AzureNodePoolConfigRootVolumeArgs' root_volume: Optional. Configuration related to the root volume provisioned for each node pool machine. When unspecified, it defaults to a 32-GiB Azure Disk.
        :param Mapping[str, str] tags: Optional. A set of tags to apply to all underlying Azure resources for this node pool. This currently only includes Virtual Machine Scale Sets. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        :param str vm_size: Optional. The Azure VM size name. Example: `Standard_DS2_v2`. See (/anthos/clusters/docs/azure/reference/supported-vms) for options. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        pulumi.set(__self__, "ssh_config", ssh_config)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if vm_size is not None:
            pulumi.set(__self__, "vm_size", vm_size)

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> 'outputs.AzureNodePoolConfigSshConfig':
        """
        SSH configuration for how to access the node pool machines.
        """
        return pulumi.get(self, "ssh_config")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[str]:
        """
        (Beta only) The OS image type to use on node pool instances.
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional['outputs.AzureNodePoolConfigProxyConfig']:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional['outputs.AzureNodePoolConfigRootVolume']:
        """
        Optional. Configuration related to the root volume provisioned for each node pool machine. When unspecified, it defaults to a 32-GiB Azure Disk.
        """
        return pulumi.get(self, "root_volume")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, str]]:
        """
        Optional. A set of tags to apply to all underlying Azure resources for this node pool. This currently only includes Virtual Machine Scale Sets. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter(name="vmSize")
    def vm_size(self) -> Optional[str]:
        """
        Optional. The Azure VM size name. Example: `Standard_DS2_v2`. See (/anthos/clusters/docs/azure/reference/supported-vms) for options. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        return pulumi.get(self, "vm_size")


@pulumi.output_type
class AzureNodePoolConfigProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "resourceGroupId":
            suggest = "resource_group_id"
        elif key == "secretId":
            suggest = "secret_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolConfigProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolConfigProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolConfigProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 resource_group_id: str,
                 secret_id: str):
        """
        :param str resource_group_id: The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        :param str secret_id: The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        pulumi.set(__self__, "resource_group_id", resource_group_id)
        pulumi.set(__self__, "secret_id", secret_id)

    @property
    @pulumi.getter(name="resourceGroupId")
    def resource_group_id(self) -> str:
        """
        The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        """
        return pulumi.get(self, "resource_group_id")

    @property
    @pulumi.getter(name="secretId")
    def secret_id(self) -> str:
        """
        The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        return pulumi.get(self, "secret_id")


@pulumi.output_type
class AzureNodePoolConfigRootVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sizeGib":
            suggest = "size_gib"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolConfigRootVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolConfigRootVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolConfigRootVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 size_gib: Optional[int] = None):
        """
        :param int size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[int]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")


@pulumi.output_type
class AzureNodePoolConfigSshConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "authorizedKey":
            suggest = "authorized_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolConfigSshConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolConfigSshConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolConfigSshConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 authorized_key: str):
        """
        :param str authorized_key: The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        pulumi.set(__self__, "authorized_key", authorized_key)

    @property
    @pulumi.getter(name="authorizedKey")
    def authorized_key(self) -> str:
        """
        The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        return pulumi.get(self, "authorized_key")


@pulumi.output_type
class AzureNodePoolManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[bool] = None):
        """
        :param bool auto_repair: Optional. Whether or not the nodes will be automatically repaired.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[bool]:
        """
        Optional. Whether or not the nodes will be automatically repaired.
        """
        return pulumi.get(self, "auto_repair")


@pulumi.output_type
class AzureNodePoolMaxPodsConstraint(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxPodsPerNode":
            suggest = "max_pods_per_node"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolMaxPodsConstraint. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolMaxPodsConstraint.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolMaxPodsConstraint.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_pods_per_node: int):
        """
        :param int max_pods_per_node: The maximum number of pods to schedule on a single node.
               
               - - -
        """
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> int:
        """
        The maximum number of pods to schedule on a single node.

        - - -
        """
        return pulumi.get(self, "max_pods_per_node")


@pulumi.output_type
class ClusterAddonsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cloudrunConfig":
            suggest = "cloudrun_config"
        elif key == "configConnectorConfig":
            suggest = "config_connector_config"
        elif key == "dnsCacheConfig":
            suggest = "dns_cache_config"
        elif key == "gcePersistentDiskCsiDriverConfig":
            suggest = "gce_persistent_disk_csi_driver_config"
        elif key == "gcpFilestoreCsiDriverConfig":
            suggest = "gcp_filestore_csi_driver_config"
        elif key == "gcsFuseCsiDriverConfig":
            suggest = "gcs_fuse_csi_driver_config"
        elif key == "gkeBackupAgentConfig":
            suggest = "gke_backup_agent_config"
        elif key == "horizontalPodAutoscaling":
            suggest = "horizontal_pod_autoscaling"
        elif key == "httpLoadBalancing":
            suggest = "http_load_balancing"
        elif key == "istioConfig":
            suggest = "istio_config"
        elif key == "kalmConfig":
            suggest = "kalm_config"
        elif key == "networkPolicyConfig":
            suggest = "network_policy_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAddonsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAddonsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAddonsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cloudrun_config: Optional['outputs.ClusterAddonsConfigCloudrunConfig'] = None,
                 config_connector_config: Optional['outputs.ClusterAddonsConfigConfigConnectorConfig'] = None,
                 dns_cache_config: Optional['outputs.ClusterAddonsConfigDnsCacheConfig'] = None,
                 gce_persistent_disk_csi_driver_config: Optional['outputs.ClusterAddonsConfigGcePersistentDiskCsiDriverConfig'] = None,
                 gcp_filestore_csi_driver_config: Optional['outputs.ClusterAddonsConfigGcpFilestoreCsiDriverConfig'] = None,
                 gcs_fuse_csi_driver_config: Optional['outputs.ClusterAddonsConfigGcsFuseCsiDriverConfig'] = None,
                 gke_backup_agent_config: Optional['outputs.ClusterAddonsConfigGkeBackupAgentConfig'] = None,
                 horizontal_pod_autoscaling: Optional['outputs.ClusterAddonsConfigHorizontalPodAutoscaling'] = None,
                 http_load_balancing: Optional['outputs.ClusterAddonsConfigHttpLoadBalancing'] = None,
                 istio_config: Optional['outputs.ClusterAddonsConfigIstioConfig'] = None,
                 kalm_config: Optional['outputs.ClusterAddonsConfigKalmConfig'] = None,
                 network_policy_config: Optional['outputs.ClusterAddonsConfigNetworkPolicyConfig'] = None):
        """
        :param 'ClusterAddonsConfigCloudrunConfigArgs' cloudrun_config: . Structure is documented below.
        :param 'ClusterAddonsConfigConfigConnectorConfigArgs' config_connector_config: .
               The status of the ConfigConnector addon. It is disabled by default; Set `enabled = true` to enable.
               
               
               This example `addons_config` disables two addons:
               
               ```python
               import pulumi
               ```
               <a name="nested_binary_authorization"></a>The `binary_authorization` block supports:
        :param 'ClusterAddonsConfigDnsCacheConfigArgs' dns_cache_config: .
               The status of the NodeLocal DNSCache addon. It is disabled by default.
               Set `enabled = true` to enable.
               
               **Enabling/Disabling NodeLocal DNSCache in an existing cluster is a disruptive operation.
               All cluster nodes running GKE 1.15 and higher are recreated.**
        :param 'ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs' gce_persistent_disk_csi_driver_config: .
               Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set `enabled = true` to enable.
               
               **Note:** The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        :param 'ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs' gcp_filestore_csi_driver_config: The status of the Filestore CSI driver addon,
               which allows the usage of filestore instance as volumes.
               It is disabled by default; set `enabled = true` to enable.
        :param 'ClusterAddonsConfigGcsFuseCsiDriverConfigArgs' gcs_fuse_csi_driver_config: The status of the GCSFuse CSI driver addon,
               which allows the usage of a gcs bucket as volumes.
               It is disabled by default; set `enabled = true` to enable.
        :param 'ClusterAddonsConfigGkeBackupAgentConfigArgs' gke_backup_agent_config: .
               The status of the Backup for GKE agent addon. It is disabled by default; Set `enabled = true` to enable.
        :param 'ClusterAddonsConfigHorizontalPodAutoscalingArgs' horizontal_pod_autoscaling: The status of the Horizontal Pod Autoscaling
               addon, which increases or decreases the number of replica pods a replication controller
               has based on the resource usage of the existing pods.
               It is enabled by default;
               set `disabled = true` to disable.
        :param 'ClusterAddonsConfigHttpLoadBalancingArgs' http_load_balancing: The status of the HTTP (L7) load balancing
               controller addon, which makes it easy to set up HTTP load balancers for services in a
               cluster. It is enabled by default; set `disabled = true` to disable.
        :param 'ClusterAddonsConfigIstioConfigArgs' istio_config: .
               Structure is documented below.
        :param 'ClusterAddonsConfigKalmConfigArgs' kalm_config: .
               Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set `enabled = true` to enable.
        :param 'ClusterAddonsConfigNetworkPolicyConfigArgs' network_policy_config: Whether we should enable the network policy addon
               for the master.  This must be enabled in order to enable network policy for the nodes.
               To enable this, you must also define a `network_policy` block,
               otherwise nothing will happen.
               It can only be disabled if the nodes already do not have network policies enabled.
               Defaults to disabled; set `disabled = false` to enable.
        """
        if cloudrun_config is not None:
            pulumi.set(__self__, "cloudrun_config", cloudrun_config)
        if config_connector_config is not None:
            pulumi.set(__self__, "config_connector_config", config_connector_config)
        if dns_cache_config is not None:
            pulumi.set(__self__, "dns_cache_config", dns_cache_config)
        if gce_persistent_disk_csi_driver_config is not None:
            pulumi.set(__self__, "gce_persistent_disk_csi_driver_config", gce_persistent_disk_csi_driver_config)
        if gcp_filestore_csi_driver_config is not None:
            pulumi.set(__self__, "gcp_filestore_csi_driver_config", gcp_filestore_csi_driver_config)
        if gcs_fuse_csi_driver_config is not None:
            pulumi.set(__self__, "gcs_fuse_csi_driver_config", gcs_fuse_csi_driver_config)
        if gke_backup_agent_config is not None:
            pulumi.set(__self__, "gke_backup_agent_config", gke_backup_agent_config)
        if horizontal_pod_autoscaling is not None:
            pulumi.set(__self__, "horizontal_pod_autoscaling", horizontal_pod_autoscaling)
        if http_load_balancing is not None:
            pulumi.set(__self__, "http_load_balancing", http_load_balancing)
        if istio_config is not None:
            pulumi.set(__self__, "istio_config", istio_config)
        if kalm_config is not None:
            pulumi.set(__self__, "kalm_config", kalm_config)
        if network_policy_config is not None:
            pulumi.set(__self__, "network_policy_config", network_policy_config)

    @property
    @pulumi.getter(name="cloudrunConfig")
    def cloudrun_config(self) -> Optional['outputs.ClusterAddonsConfigCloudrunConfig']:
        """
        . Structure is documented below.
        """
        return pulumi.get(self, "cloudrun_config")

    @property
    @pulumi.getter(name="configConnectorConfig")
    def config_connector_config(self) -> Optional['outputs.ClusterAddonsConfigConfigConnectorConfig']:
        """
        .
        The status of the ConfigConnector addon. It is disabled by default; Set `enabled = true` to enable.


        This example `addons_config` disables two addons:

        ```python
        import pulumi
        ```
        <a name="nested_binary_authorization"></a>The `binary_authorization` block supports:
        """
        return pulumi.get(self, "config_connector_config")

    @property
    @pulumi.getter(name="dnsCacheConfig")
    def dns_cache_config(self) -> Optional['outputs.ClusterAddonsConfigDnsCacheConfig']:
        """
        .
        The status of the NodeLocal DNSCache addon. It is disabled by default.
        Set `enabled = true` to enable.

        **Enabling/Disabling NodeLocal DNSCache in an existing cluster is a disruptive operation.
        All cluster nodes running GKE 1.15 and higher are recreated.**
        """
        return pulumi.get(self, "dns_cache_config")

    @property
    @pulumi.getter(name="gcePersistentDiskCsiDriverConfig")
    def gce_persistent_disk_csi_driver_config(self) -> Optional['outputs.ClusterAddonsConfigGcePersistentDiskCsiDriverConfig']:
        """
        .
        Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set `enabled = true` to enable.

        **Note:** The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        """
        return pulumi.get(self, "gce_persistent_disk_csi_driver_config")

    @property
    @pulumi.getter(name="gcpFilestoreCsiDriverConfig")
    def gcp_filestore_csi_driver_config(self) -> Optional['outputs.ClusterAddonsConfigGcpFilestoreCsiDriverConfig']:
        """
        The status of the Filestore CSI driver addon,
        which allows the usage of filestore instance as volumes.
        It is disabled by default; set `enabled = true` to enable.
        """
        return pulumi.get(self, "gcp_filestore_csi_driver_config")

    @property
    @pulumi.getter(name="gcsFuseCsiDriverConfig")
    def gcs_fuse_csi_driver_config(self) -> Optional['outputs.ClusterAddonsConfigGcsFuseCsiDriverConfig']:
        """
        The status of the GCSFuse CSI driver addon,
        which allows the usage of a gcs bucket as volumes.
        It is disabled by default; set `enabled = true` to enable.
        """
        return pulumi.get(self, "gcs_fuse_csi_driver_config")

    @property
    @pulumi.getter(name="gkeBackupAgentConfig")
    def gke_backup_agent_config(self) -> Optional['outputs.ClusterAddonsConfigGkeBackupAgentConfig']:
        """
        .
        The status of the Backup for GKE agent addon. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "gke_backup_agent_config")

    @property
    @pulumi.getter(name="horizontalPodAutoscaling")
    def horizontal_pod_autoscaling(self) -> Optional['outputs.ClusterAddonsConfigHorizontalPodAutoscaling']:
        """
        The status of the Horizontal Pod Autoscaling
        addon, which increases or decreases the number of replica pods a replication controller
        has based on the resource usage of the existing pods.
        It is enabled by default;
        set `disabled = true` to disable.
        """
        return pulumi.get(self, "horizontal_pod_autoscaling")

    @property
    @pulumi.getter(name="httpLoadBalancing")
    def http_load_balancing(self) -> Optional['outputs.ClusterAddonsConfigHttpLoadBalancing']:
        """
        The status of the HTTP (L7) load balancing
        controller addon, which makes it easy to set up HTTP load balancers for services in a
        cluster. It is enabled by default; set `disabled = true` to disable.
        """
        return pulumi.get(self, "http_load_balancing")

    @property
    @pulumi.getter(name="istioConfig")
    def istio_config(self) -> Optional['outputs.ClusterAddonsConfigIstioConfig']:
        """
        .
        Structure is documented below.
        """
        return pulumi.get(self, "istio_config")

    @property
    @pulumi.getter(name="kalmConfig")
    def kalm_config(self) -> Optional['outputs.ClusterAddonsConfigKalmConfig']:
        """
        .
        Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "kalm_config")

    @property
    @pulumi.getter(name="networkPolicyConfig")
    def network_policy_config(self) -> Optional['outputs.ClusterAddonsConfigNetworkPolicyConfig']:
        """
        Whether we should enable the network policy addon
        for the master.  This must be enabled in order to enable network policy for the nodes.
        To enable this, you must also define a `network_policy` block,
        otherwise nothing will happen.
        It can only be disabled if the nodes already do not have network policies enabled.
        Defaults to disabled; set `disabled = false` to enable.
        """
        return pulumi.get(self, "network_policy_config")


@pulumi.output_type
class ClusterAddonsConfigCloudrunConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "loadBalancerType":
            suggest = "load_balancer_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAddonsConfigCloudrunConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAddonsConfigCloudrunConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAddonsConfigCloudrunConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disabled: bool,
                 load_balancer_type: Optional[str] = None):
        """
        :param bool disabled: The status of the CloudRun addon. It is disabled by default. Set `disabled=false` to enable.
        :param str load_balancer_type: The load balancer type of CloudRun ingress service. It is external load balancer by default.
               Set `load_balancer_type=LOAD_BALANCER_TYPE_INTERNAL` to configure it as internal load balancer.
        """
        pulumi.set(__self__, "disabled", disabled)
        if load_balancer_type is not None:
            pulumi.set(__self__, "load_balancer_type", load_balancer_type)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        The status of the CloudRun addon. It is disabled by default. Set `disabled=false` to enable.
        """
        return pulumi.get(self, "disabled")

    @property
    @pulumi.getter(name="loadBalancerType")
    def load_balancer_type(self) -> Optional[str]:
        """
        The load balancer type of CloudRun ingress service. It is external load balancer by default.
        Set `load_balancer_type=LOAD_BALANCER_TYPE_INTERNAL` to configure it as internal load balancer.
        """
        return pulumi.get(self, "load_balancer_type")


@pulumi.output_type
class ClusterAddonsConfigConfigConnectorConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigDnsCacheConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigGcePersistentDiskCsiDriverConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigGcpFilestoreCsiDriverConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigGcsFuseCsiDriverConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigGkeBackupAgentConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigHorizontalPodAutoscaling(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterAddonsConfigHttpLoadBalancing(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterAddonsConfigIstioConfig(dict):
    def __init__(__self__, *,
                 disabled: bool,
                 auth: Optional[str] = None):
        """
        :param bool disabled: The status of the Istio addon, which makes it easy to set up Istio for services in a
               cluster. It is disabled by default. Set `disabled = false` to enable.
        :param str auth: The authentication type between services in Istio. Available options include `AUTH_MUTUAL_TLS`.
        """
        pulumi.set(__self__, "disabled", disabled)
        if auth is not None:
            pulumi.set(__self__, "auth", auth)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        The status of the Istio addon, which makes it easy to set up Istio for services in a
        cluster. It is disabled by default. Set `disabled = false` to enable.
        """
        return pulumi.get(self, "disabled")

    @property
    @pulumi.getter
    def auth(self) -> Optional[str]:
        """
        The authentication type between services in Istio. Available options include `AUTH_MUTUAL_TLS`.
        """
        return pulumi.get(self, "auth")


@pulumi.output_type
class ClusterAddonsConfigKalmConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigNetworkPolicyConfig(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterAuthenticatorGroupsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "securityGroup":
            suggest = "security_group"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAuthenticatorGroupsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAuthenticatorGroupsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAuthenticatorGroupsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 security_group: str):
        """
        :param str security_group: The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format `gke-security-groups@yourdomain.com`.
        """
        pulumi.set(__self__, "security_group", security_group)

    @property
    @pulumi.getter(name="securityGroup")
    def security_group(self) -> str:
        """
        The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format `gke-security-groups@yourdomain.com`.
        """
        return pulumi.get(self, "security_group")


@pulumi.output_type
class ClusterBinaryAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "evaluationMode":
            suggest = "evaluation_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterBinaryAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterBinaryAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterBinaryAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: Optional[bool] = None,
                 evaluation_mode: Optional[str] = None):
        """
        :param bool enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        :param str evaluation_mode: Mode of operation for Binary Authorization policy evaluation. Valid values are `DISABLED`
               and `PROJECT_SINGLETON_POLICY_ENFORCE`. `PROJECT_SINGLETON_POLICY_ENFORCE` is functionally equivalent to the
               deprecated `enable_binary_authorization` parameter being set to `true`.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[bool]:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        warnings.warn("""Deprecated in favor of evaluation_mode.""", DeprecationWarning)
        pulumi.log.warn("""enabled is deprecated: Deprecated in favor of evaluation_mode.""")

        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[str]:
        """
        Mode of operation for Binary Authorization policy evaluation. Valid values are `DISABLED`
        and `PROJECT_SINGLETON_POLICY_ENFORCE`. `PROJECT_SINGLETON_POLICY_ENFORCE` is functionally equivalent to the
        deprecated `enable_binary_authorization` parameter being set to `true`.
        """
        return pulumi.get(self, "evaluation_mode")


@pulumi.output_type
class ClusterClusterAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoProvisioningDefaults":
            suggest = "auto_provisioning_defaults"
        elif key == "autoscalingProfile":
            suggest = "autoscaling_profile"
        elif key == "resourceLimits":
            suggest = "resource_limits"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_provisioning_defaults: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaults'] = None,
                 autoscaling_profile: Optional[str] = None,
                 enabled: Optional[bool] = None,
                 resource_limits: Optional[Sequence['outputs.ClusterClusterAutoscalingResourceLimit']] = None):
        """
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsArgs' auto_provisioning_defaults: Contains defaults for a node pool created by NAP. A subset of fields also apply to
               GKE Autopilot clusters.
               Structure is documented below.
        :param str autoscaling_profile: ) Configuration
               options for the [Autoscaling profile](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler#autoscaling_profiles)
               feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability
               when deciding to remove nodes from a cluster. Can be `BALANCED` or `OPTIMIZE_UTILIZATION`. Defaults to `BALANCED`.
        :param bool enabled: Whether node auto-provisioning is enabled. Must be supplied for GKE Standard clusters, `true` is implied
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
        :param Sequence['ClusterClusterAutoscalingResourceLimitArgs'] resource_limits: Global constraints for machine resources in the
               cluster. Configuring the `cpu` and `memory` types is required if node
               auto-provisioning is enabled. These limits will apply to node pool autoscaling
               in addition to node auto-provisioning. Structure is documented below.
        """
        if auto_provisioning_defaults is not None:
            pulumi.set(__self__, "auto_provisioning_defaults", auto_provisioning_defaults)
        if autoscaling_profile is not None:
            pulumi.set(__self__, "autoscaling_profile", autoscaling_profile)
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if resource_limits is not None:
            pulumi.set(__self__, "resource_limits", resource_limits)

    @property
    @pulumi.getter(name="autoProvisioningDefaults")
    def auto_provisioning_defaults(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaults']:
        """
        Contains defaults for a node pool created by NAP. A subset of fields also apply to
        GKE Autopilot clusters.
        Structure is documented below.
        """
        return pulumi.get(self, "auto_provisioning_defaults")

    @property
    @pulumi.getter(name="autoscalingProfile")
    def autoscaling_profile(self) -> Optional[str]:
        """
        ) Configuration
        options for the [Autoscaling profile](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler#autoscaling_profiles)
        feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability
        when deciding to remove nodes from a cluster. Can be `BALANCED` or `OPTIMIZE_UTILIZATION`. Defaults to `BALANCED`.
        """
        return pulumi.get(self, "autoscaling_profile")

    @property
    @pulumi.getter
    def enabled(self) -> Optional[bool]:
        """
        Whether node auto-provisioning is enabled. Must be supplied for GKE Standard clusters, `true` is implied
        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="resourceLimits")
    def resource_limits(self) -> Optional[Sequence['outputs.ClusterClusterAutoscalingResourceLimit']]:
        """
        Global constraints for machine resources in the
        cluster. Configuring the `cpu` and `memory` types is required if node
        auto-provisioning is enabled. These limits will apply to node pool autoscaling
        in addition to node auto-provisioning. Structure is documented below.
        """
        return pulumi.get(self, "resource_limits")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaults(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskKmsKey":
            suggest = "boot_disk_kms_key"
        elif key == "diskSize":
            suggest = "disk_size"
        elif key == "diskType":
            suggest = "disk_type"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "minCpuPlatform":
            suggest = "min_cpu_platform"
        elif key == "oauthScopes":
            suggest = "oauth_scopes"
        elif key == "serviceAccount":
            suggest = "service_account"
        elif key == "shieldedInstanceConfig":
            suggest = "shielded_instance_config"
        elif key == "upgradeSettings":
            suggest = "upgrade_settings"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaults. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaults.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaults.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 boot_disk_kms_key: Optional[str] = None,
                 disk_size: Optional[int] = None,
                 disk_type: Optional[str] = None,
                 image_type: Optional[str] = None,
                 management: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsManagement'] = None,
                 min_cpu_platform: Optional[str] = None,
                 oauth_scopes: Optional[Sequence[str]] = None,
                 service_account: Optional[str] = None,
                 shielded_instance_config: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig'] = None,
                 upgrade_settings: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings'] = None):
        """
        :param str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
        :param int disk_size: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. Defaults to `100`
        :param str disk_type: Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd' or 'pd-balanced'). Defaults to `pd-standard`
        :param str image_type: The default image type used by NAP once a new node pool is being created. Please note that according to the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning#default-image-type) the value must be one of the [COS_CONTAINERD, COS, UBUNTU_CONTAINERD, UBUNTU]. __NOTE__ : COS AND UBUNTU are deprecated as of `GKE 1.24`
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs' management: NodeManagement configuration for this NodePool. Structure is documented below.
        :param str min_cpu_platform: Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the
               specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such
               as "Intel Haswell" or "Intel Sandy Bridge".
        :param Sequence[str] oauth_scopes: Scopes that are used by NAP and GKE Autopilot when creating node pools. Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               > `monitoring.write` is always enabled regardless of user input.  `monitoring` and `logging.write` may also be enabled depending on the values for `monitoring_service` and `logging_service`.
        :param str service_account: The Google Cloud Platform Service Account to be used by the node VMs created by GKE Autopilot or NAP.
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs' shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs' upgrade_settings: Specifies the upgrade settings for NAP created node pools. Structure is documented below.
        """
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if disk_size is not None:
            pulumi.set(__self__, "disk_size", disk_size)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if management is not None:
            pulumi.set(__self__, "management", management)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if upgrade_settings is not None:
            pulumi.set(__self__, "upgrade_settings", upgrade_settings)

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[str]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="diskSize")
    def disk_size(self) -> Optional[int]:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. Defaults to `100`
        """
        return pulumi.get(self, "disk_size")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[str]:
        """
        Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd' or 'pd-balanced'). Defaults to `pd-standard`
        """
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[str]:
        """
        The default image type used by NAP once a new node pool is being created. Please note that according to the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning#default-image-type) the value must be one of the [COS_CONTAINERD, COS, UBUNTU_CONTAINERD, UBUNTU]. __NOTE__ : COS AND UBUNTU are deprecated as of `GKE 1.24`
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter
    def management(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsManagement']:
        """
        NodeManagement configuration for this NodePool. Structure is documented below.
        """
        return pulumi.get(self, "management")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[str]:
        """
        Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the
        specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such
        as "Intel Haswell" or "Intel Sandy Bridge".
        """
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[Sequence[str]]:
        """
        Scopes that are used by NAP and GKE Autopilot when creating node pools. Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        > `monitoring.write` is always enabled regardless of user input.  `monitoring` and `logging.write` may also be enabled depending on the values for `monitoring_service` and `logging_service`.
        """
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[str]:
        """
        The Google Cloud Platform Service Account to be used by the node VMs created by GKE Autopilot or NAP.
        """
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig']:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings']:
        """
        Specifies the upgrade settings for NAP created node pools. Structure is documented below.
        """
        return pulumi.get(self, "upgrade_settings")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"
        elif key == "autoUpgrade":
            suggest = "auto_upgrade"
        elif key == "upgradeOptions":
            suggest = "upgrade_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[bool] = None,
                 auto_upgrade: Optional[bool] = None,
                 upgrade_options: Optional[Sequence['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption']] = None):
        """
        :param bool auto_repair: Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
               
               This block also contains several computed attributes, documented below.
        :param bool auto_upgrade: Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)
        if upgrade_options is not None:
            pulumi.set(__self__, "upgrade_options", upgrade_options)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[bool]:
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.

        This block also contains several computed attributes, documented below.
        """
        return pulumi.get(self, "auto_repair")

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[bool]:
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        return pulumi.get(self, "auto_upgrade")

    @property
    @pulumi.getter(name="upgradeOptions")
    def upgrade_options(self) -> Optional[Sequence['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption']]:
        return pulumi.get(self, "upgrade_options")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoUpgradeStartTime":
            suggest = "auto_upgrade_start_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_upgrade_start_time: Optional[str] = None,
                 description: Optional[str] = None):
        """
        :param str description: Description of the cluster.
        """
        if auto_upgrade_start_time is not None:
            pulumi.set(__self__, "auto_upgrade_start_time", auto_upgrade_start_time)
        if description is not None:
            pulumi.set(__self__, "description", description)

    @property
    @pulumi.getter(name="autoUpgradeStartTime")
    def auto_upgrade_start_time(self) -> Optional[str]:
        return pulumi.get(self, "auto_upgrade_start_time")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        """
        Description of the cluster.
        """
        return pulumi.get(self, "description")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableIntegrityMonitoring":
            suggest = "enable_integrity_monitoring"
        elif key == "enableSecureBoot":
            suggest = "enable_secure_boot"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[bool] = None,
                 enable_secure_boot: Optional[bool] = None):
        """
        :param bool enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param bool enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[bool]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[bool]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "blueGreenSettings":
            suggest = "blue_green_settings"
        elif key == "maxSurge":
            suggest = "max_surge"
        elif key == "maxUnavailable":
            suggest = "max_unavailable"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 blue_green_settings: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings'] = None,
                 max_surge: Optional[int] = None,
                 max_unavailable: Optional[int] = None,
                 strategy: Optional[str] = None):
        """
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs' blue_green_settings: Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param int max_surge: The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param int max_unavailable: The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param str strategy: Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings']:
        """
        Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "blue_green_settings")

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[int]:
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_surge")

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[int]:
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_unavailable")

    @property
    @pulumi.getter
    def strategy(self) -> Optional[str]:
        """
        Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodePoolSoakDuration":
            suggest = "node_pool_soak_duration"
        elif key == "standardRolloutPolicy":
            suggest = "standard_rollout_policy"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_pool_soak_duration: Optional[str] = None,
                 standard_rollout_policy: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy'] = None):
        """
        :param str node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs' standard_rollout_policy: Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        if standard_rollout_policy is not None:
            pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[str]:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy']:
        """
        Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "standard_rollout_policy")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "batchNodeCount":
            suggest = "batch_node_count"
        elif key == "batchPercentage":
            suggest = "batch_percentage"
        elif key == "batchSoakDuration":
            suggest = "batch_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 batch_node_count: Optional[int] = None,
                 batch_percentage: Optional[float] = None,
                 batch_soak_duration: Optional[str] = None):
        """
        :param int batch_node_count: Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        :param float batch_percentage: Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        :param str batch_soak_duration: Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[int]:
        """
        Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_node_count")

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[float]:
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_percentage")

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[str]:
        """
        Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class ClusterClusterAutoscalingResourceLimit(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "resourceType":
            suggest = "resource_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingResourceLimit. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingResourceLimit.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingResourceLimit.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 resource_type: str,
                 maximum: Optional[int] = None,
                 minimum: Optional[int] = None):
        """
        :param str resource_type: The type of the resource. For example, `cpu` and
               `memory`.  See the [guide to using Node Auto-Provisioning](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)
               for a list of types.
        :param int maximum: Maximum amount of the resource in the cluster.
        :param int minimum: Minimum amount of the resource in the cluster.
        """
        pulumi.set(__self__, "resource_type", resource_type)
        if maximum is not None:
            pulumi.set(__self__, "maximum", maximum)
        if minimum is not None:
            pulumi.set(__self__, "minimum", minimum)

    @property
    @pulumi.getter(name="resourceType")
    def resource_type(self) -> str:
        """
        The type of the resource. For example, `cpu` and
        `memory`.  See the [guide to using Node Auto-Provisioning](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)
        for a list of types.
        """
        return pulumi.get(self, "resource_type")

    @property
    @pulumi.getter
    def maximum(self) -> Optional[int]:
        """
        Maximum amount of the resource in the cluster.
        """
        return pulumi.get(self, "maximum")

    @property
    @pulumi.getter
    def minimum(self) -> Optional[int]:
        """
        Minimum amount of the resource in the cluster.
        """
        return pulumi.get(self, "minimum")


@pulumi.output_type
class ClusterClusterTelemetry(dict):
    def __init__(__self__, *,
                 type: str):
        """
        :param str type: Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
               `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
        `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class ClusterConfidentialNodes(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterCostManagementConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether to enable the [cost allocation](https://cloud.google.com/kubernetes-engine/docs/how-to/cost-allocations) feature.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether to enable the [cost allocation](https://cloud.google.com/kubernetes-engine/docs/how-to/cost-allocations) feature.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterDatabaseEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "keyName":
            suggest = "key_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterDatabaseEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterDatabaseEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterDatabaseEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 state: str,
                 key_name: Optional[str] = None):
        """
        :param str state: `ENCRYPTED` or `DECRYPTED`
        :param str key_name: the key to use to encrypt/decrypt secrets.  See the [DatabaseEncryption definition](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.DatabaseEncryption) for more information.
               
               <a name="nested_enable_k8s_beta_apis"></a>The `enable_k8s_beta_apis` block supports:
        """
        pulumi.set(__self__, "state", state)
        if key_name is not None:
            pulumi.set(__self__, "key_name", key_name)

    @property
    @pulumi.getter
    def state(self) -> str:
        """
        `ENCRYPTED` or `DECRYPTED`
        """
        return pulumi.get(self, "state")

    @property
    @pulumi.getter(name="keyName")
    def key_name(self) -> Optional[str]:
        """
        the key to use to encrypt/decrypt secrets.  See the [DatabaseEncryption definition](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.DatabaseEncryption) for more information.

        <a name="nested_enable_k8s_beta_apis"></a>The `enable_k8s_beta_apis` block supports:
        """
        return pulumi.get(self, "key_name")


@pulumi.output_type
class ClusterDefaultSnatStatus(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterDnsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "clusterDns":
            suggest = "cluster_dns"
        elif key == "clusterDnsDomain":
            suggest = "cluster_dns_domain"
        elif key == "clusterDnsScope":
            suggest = "cluster_dns_scope"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterDnsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterDnsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterDnsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cluster_dns: Optional[str] = None,
                 cluster_dns_domain: Optional[str] = None,
                 cluster_dns_scope: Optional[str] = None):
        """
        :param str cluster_dns: Which in-cluster DNS provider should be used. `PROVIDER_UNSPECIFIED` (default) or `PLATFORM_DEFAULT` or `CLOUD_DNS`.
        :param str cluster_dns_domain: The suffix used for all cluster service records.
        :param str cluster_dns_scope: The scope of access to cluster DNS records. `DNS_SCOPE_UNSPECIFIED` (default) or `CLUSTER_SCOPE` or `VPC_SCOPE`.
        """
        if cluster_dns is not None:
            pulumi.set(__self__, "cluster_dns", cluster_dns)
        if cluster_dns_domain is not None:
            pulumi.set(__self__, "cluster_dns_domain", cluster_dns_domain)
        if cluster_dns_scope is not None:
            pulumi.set(__self__, "cluster_dns_scope", cluster_dns_scope)

    @property
    @pulumi.getter(name="clusterDns")
    def cluster_dns(self) -> Optional[str]:
        """
        Which in-cluster DNS provider should be used. `PROVIDER_UNSPECIFIED` (default) or `PLATFORM_DEFAULT` or `CLOUD_DNS`.
        """
        return pulumi.get(self, "cluster_dns")

    @property
    @pulumi.getter(name="clusterDnsDomain")
    def cluster_dns_domain(self) -> Optional[str]:
        """
        The suffix used for all cluster service records.
        """
        return pulumi.get(self, "cluster_dns_domain")

    @property
    @pulumi.getter(name="clusterDnsScope")
    def cluster_dns_scope(self) -> Optional[str]:
        """
        The scope of access to cluster DNS records. `DNS_SCOPE_UNSPECIFIED` (default) or `CLUSTER_SCOPE` or `VPC_SCOPE`.
        """
        return pulumi.get(self, "cluster_dns_scope")


@pulumi.output_type
class ClusterEnableK8sBetaApis(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enabledApis":
            suggest = "enabled_apis"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterEnableK8sBetaApis. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterEnableK8sBetaApis.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterEnableK8sBetaApis.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled_apis: Sequence[str]):
        """
        :param Sequence[str] enabled_apis: Enabled Kubernetes Beta APIs. To list a Beta API resource, use the representation {group}/{version}/{resource}. The version must be a Beta version. Note that you cannot disable beta APIs that are already enabled on a cluster without recreating it. See the [Configure beta APIs](https://cloud.google.com/kubernetes-engine/docs/how-to/use-beta-apis#configure-beta-apis) for more information.
        """
        pulumi.set(__self__, "enabled_apis", enabled_apis)

    @property
    @pulumi.getter(name="enabledApis")
    def enabled_apis(self) -> Sequence[str]:
        """
        Enabled Kubernetes Beta APIs. To list a Beta API resource, use the representation {group}/{version}/{resource}. The version must be a Beta version. Note that you cannot disable beta APIs that are already enabled on a cluster without recreating it. See the [Configure beta APIs](https://cloud.google.com/kubernetes-engine/docs/how-to/use-beta-apis#configure-beta-apis) for more information.
        """
        return pulumi.get(self, "enabled_apis")


@pulumi.output_type
class ClusterGatewayApiConfig(dict):
    def __init__(__self__, *,
                 channel: str):
        """
        :param str channel: Which Gateway Api channel should be used. `CHANNEL_DISABLED`, `CHANNEL_EXPERIMENTAL` or `CHANNEL_STANDARD`.
        """
        pulumi.set(__self__, "channel", channel)

    @property
    @pulumi.getter
    def channel(self) -> str:
        """
        Which Gateway Api channel should be used. `CHANNEL_DISABLED`, `CHANNEL_EXPERIMENTAL` or `CHANNEL_STANDARD`.
        """
        return pulumi.get(self, "channel")


@pulumi.output_type
class ClusterIdentityServiceConfig(dict):
    def __init__(__self__, *,
                 enabled: Optional[bool] = None):
        """
        :param bool enabled: Whether to enable the Identity Service component. It is disabled by default. Set `enabled=true` to enable.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[bool]:
        """
        Whether to enable the Identity Service component. It is disabled by default. Set `enabled=true` to enable.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterIpAllocationPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "additionalPodRangesConfig":
            suggest = "additional_pod_ranges_config"
        elif key == "clusterIpv4CidrBlock":
            suggest = "cluster_ipv4_cidr_block"
        elif key == "clusterSecondaryRangeName":
            suggest = "cluster_secondary_range_name"
        elif key == "podCidrOverprovisionConfig":
            suggest = "pod_cidr_overprovision_config"
        elif key == "servicesIpv4CidrBlock":
            suggest = "services_ipv4_cidr_block"
        elif key == "servicesSecondaryRangeName":
            suggest = "services_secondary_range_name"
        elif key == "stackType":
            suggest = "stack_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterIpAllocationPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterIpAllocationPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterIpAllocationPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 additional_pod_ranges_config: Optional['outputs.ClusterIpAllocationPolicyAdditionalPodRangesConfig'] = None,
                 cluster_ipv4_cidr_block: Optional[str] = None,
                 cluster_secondary_range_name: Optional[str] = None,
                 pod_cidr_overprovision_config: Optional['outputs.ClusterIpAllocationPolicyPodCidrOverprovisionConfig'] = None,
                 services_ipv4_cidr_block: Optional[str] = None,
                 services_secondary_range_name: Optional[str] = None,
                 stack_type: Optional[str] = None):
        """
        :param 'ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs' additional_pod_ranges_config: The configuration for additional pod secondary ranges at
               the cluster level. Used for Autopilot clusters and Standard clusters with which control of the
               secondary Pod IP address assignment to node pools isn't needed. Structure is documented below.
        :param str cluster_ipv4_cidr_block: The IP address range for the cluster pod IPs.
               Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
               to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
               from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
               pick a specific range to use.
        :param str cluster_secondary_range_name: The name of the existing secondary
               range in the cluster's subnetwork to use for pod IP addresses. Alternatively,
               `cluster_ipv4_cidr_block` can be used to automatically create a GKE-managed one.
        :param str services_ipv4_cidr_block: The IP address range of the services IPs in this cluster.
               Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
               to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
               from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
               pick a specific range to use.
        :param str services_secondary_range_name: The name of the existing
               secondary range in the cluster's subnetwork to use for service `ClusterIP`s.
               Alternatively, `services_ipv4_cidr_block` can be used to automatically create a
               GKE-managed one.
        :param str stack_type: The IP Stack Type of the cluster.
               Default value is `IPV4`.
               Possible values are `IPV4` and `IPV4_IPV6`.
        """
        if additional_pod_ranges_config is not None:
            pulumi.set(__self__, "additional_pod_ranges_config", additional_pod_ranges_config)
        if cluster_ipv4_cidr_block is not None:
            pulumi.set(__self__, "cluster_ipv4_cidr_block", cluster_ipv4_cidr_block)
        if cluster_secondary_range_name is not None:
            pulumi.set(__self__, "cluster_secondary_range_name", cluster_secondary_range_name)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if services_ipv4_cidr_block is not None:
            pulumi.set(__self__, "services_ipv4_cidr_block", services_ipv4_cidr_block)
        if services_secondary_range_name is not None:
            pulumi.set(__self__, "services_secondary_range_name", services_secondary_range_name)
        if stack_type is not None:
            pulumi.set(__self__, "stack_type", stack_type)

    @property
    @pulumi.getter(name="additionalPodRangesConfig")
    def additional_pod_ranges_config(self) -> Optional['outputs.ClusterIpAllocationPolicyAdditionalPodRangesConfig']:
        """
        The configuration for additional pod secondary ranges at
        the cluster level. Used for Autopilot clusters and Standard clusters with which control of the
        secondary Pod IP address assignment to node pools isn't needed. Structure is documented below.
        """
        return pulumi.get(self, "additional_pod_ranges_config")

    @property
    @pulumi.getter(name="clusterIpv4CidrBlock")
    def cluster_ipv4_cidr_block(self) -> Optional[str]:
        """
        The IP address range for the cluster pod IPs.
        Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
        to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
        from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
        pick a specific range to use.
        """
        return pulumi.get(self, "cluster_ipv4_cidr_block")

    @property
    @pulumi.getter(name="clusterSecondaryRangeName")
    def cluster_secondary_range_name(self) -> Optional[str]:
        """
        The name of the existing secondary
        range in the cluster's subnetwork to use for pod IP addresses. Alternatively,
        `cluster_ipv4_cidr_block` can be used to automatically create a GKE-managed one.
        """
        return pulumi.get(self, "cluster_secondary_range_name")

    @property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional['outputs.ClusterIpAllocationPolicyPodCidrOverprovisionConfig']:
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @property
    @pulumi.getter(name="servicesIpv4CidrBlock")
    def services_ipv4_cidr_block(self) -> Optional[str]:
        """
        The IP address range of the services IPs in this cluster.
        Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
        to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
        from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
        pick a specific range to use.
        """
        return pulumi.get(self, "services_ipv4_cidr_block")

    @property
    @pulumi.getter(name="servicesSecondaryRangeName")
    def services_secondary_range_name(self) -> Optional[str]:
        """
        The name of the existing
        secondary range in the cluster's subnetwork to use for service `ClusterIP`s.
        Alternatively, `services_ipv4_cidr_block` can be used to automatically create a
        GKE-managed one.
        """
        return pulumi.get(self, "services_secondary_range_name")

    @property
    @pulumi.getter(name="stackType")
    def stack_type(self) -> Optional[str]:
        """
        The IP Stack Type of the cluster.
        Default value is `IPV4`.
        Possible values are `IPV4` and `IPV4_IPV6`.
        """
        return pulumi.get(self, "stack_type")


@pulumi.output_type
class ClusterIpAllocationPolicyAdditionalPodRangesConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "podRangeNames":
            suggest = "pod_range_names"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterIpAllocationPolicyAdditionalPodRangesConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterIpAllocationPolicyAdditionalPodRangesConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterIpAllocationPolicyAdditionalPodRangesConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pod_range_names: Sequence[str]):
        """
        :param Sequence[str] pod_range_names: The names of the Pod ranges to add to the cluster.
        """
        pulumi.set(__self__, "pod_range_names", pod_range_names)

    @property
    @pulumi.getter(name="podRangeNames")
    def pod_range_names(self) -> Sequence[str]:
        """
        The names of the Pod ranges to add to the cluster.
        """
        return pulumi.get(self, "pod_range_names")


@pulumi.output_type
class ClusterIpAllocationPolicyPodCidrOverprovisionConfig(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterLoggingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableComponents":
            suggest = "enable_components"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterLoggingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterLoggingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterLoggingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_components: Sequence[str]):
        """
        :param Sequence[str] enable_components: The GKE components exposing logs. Supported values include:
               `SYSTEM_COMPONENTS`, `APISERVER`, `CONTROLLER_MANAGER`, `SCHEDULER`, and `WORKLOADS`.
        """
        pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Sequence[str]:
        """
        The GKE components exposing logs. Supported values include:
        `SYSTEM_COMPONENTS`, `APISERVER`, `CONTROLLER_MANAGER`, `SCHEDULER`, and `WORKLOADS`.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class ClusterMaintenancePolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dailyMaintenanceWindow":
            suggest = "daily_maintenance_window"
        elif key == "maintenanceExclusions":
            suggest = "maintenance_exclusions"
        elif key == "recurringWindow":
            suggest = "recurring_window"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 daily_maintenance_window: Optional['outputs.ClusterMaintenancePolicyDailyMaintenanceWindow'] = None,
                 maintenance_exclusions: Optional[Sequence['outputs.ClusterMaintenancePolicyMaintenanceExclusion']] = None,
                 recurring_window: Optional['outputs.ClusterMaintenancePolicyRecurringWindow'] = None):
        """
        :param 'ClusterMaintenancePolicyDailyMaintenanceWindowArgs' daily_maintenance_window: Time window specified for daily maintenance operations.
               Specify `start_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM,
               where HH : \\[00-23\\] and MM : \\[00-59\\] GMT. For example:
               
               Examples:
               ```python
               import pulumi
               ```
        :param Sequence['ClusterMaintenancePolicyMaintenanceExclusionArgs'] maintenance_exclusions: Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows. A cluster can have up to 20 maintenance exclusions at a time [Maintenance Window and Exclusions](https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions)
        :param 'ClusterMaintenancePolicyRecurringWindowArgs' recurring_window: Time window for recurring maintenance operations.
               
               Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
               the initial date that the window starts, and the end time is used for calculating duration.  Specify `recurrence` in
               [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
               Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.
               
               Examples:
               ```python
               import pulumi
               ```
               
               ```python
               import pulumi
               ```
        """
        if daily_maintenance_window is not None:
            pulumi.set(__self__, "daily_maintenance_window", daily_maintenance_window)
        if maintenance_exclusions is not None:
            pulumi.set(__self__, "maintenance_exclusions", maintenance_exclusions)
        if recurring_window is not None:
            pulumi.set(__self__, "recurring_window", recurring_window)

    @property
    @pulumi.getter(name="dailyMaintenanceWindow")
    def daily_maintenance_window(self) -> Optional['outputs.ClusterMaintenancePolicyDailyMaintenanceWindow']:
        """
        Time window specified for daily maintenance operations.
        Specify `start_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM,
        where HH : \\[00-23\\] and MM : \\[00-59\\] GMT. For example:

        Examples:
        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "daily_maintenance_window")

    @property
    @pulumi.getter(name="maintenanceExclusions")
    def maintenance_exclusions(self) -> Optional[Sequence['outputs.ClusterMaintenancePolicyMaintenanceExclusion']]:
        """
        Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows. A cluster can have up to 20 maintenance exclusions at a time [Maintenance Window and Exclusions](https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions)
        """
        return pulumi.get(self, "maintenance_exclusions")

    @property
    @pulumi.getter(name="recurringWindow")
    def recurring_window(self) -> Optional['outputs.ClusterMaintenancePolicyRecurringWindow']:
        """
        Time window for recurring maintenance operations.

        Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
        the initial date that the window starts, and the end time is used for calculating duration.  Specify `recurrence` in
        [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
        Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.

        Examples:
        ```python
        import pulumi
        ```

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "recurring_window")


@pulumi.output_type
class ClusterMaintenancePolicyDailyMaintenanceWindow(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "startTime":
            suggest = "start_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicyDailyMaintenanceWindow. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicyDailyMaintenanceWindow.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicyDailyMaintenanceWindow.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 start_time: str,
                 duration: Optional[str] = None):
        pulumi.set(__self__, "start_time", start_time)
        if duration is not None:
            pulumi.set(__self__, "duration", duration)

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> str:
        return pulumi.get(self, "start_time")

    @property
    @pulumi.getter
    def duration(self) -> Optional[str]:
        return pulumi.get(self, "duration")


@pulumi.output_type
class ClusterMaintenancePolicyMaintenanceExclusion(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "endTime":
            suggest = "end_time"
        elif key == "exclusionName":
            suggest = "exclusion_name"
        elif key == "startTime":
            suggest = "start_time"
        elif key == "exclusionOptions":
            suggest = "exclusion_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicyMaintenanceExclusion. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicyMaintenanceExclusion.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicyMaintenanceExclusion.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 end_time: str,
                 exclusion_name: str,
                 start_time: str,
                 exclusion_options: Optional['outputs.ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions'] = None):
        """
        :param 'ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs' exclusion_options: MaintenanceExclusionOptions provides maintenance exclusion related options.
        """
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "exclusion_name", exclusion_name)
        pulumi.set(__self__, "start_time", start_time)
        if exclusion_options is not None:
            pulumi.set(__self__, "exclusion_options", exclusion_options)

    @property
    @pulumi.getter(name="endTime")
    def end_time(self) -> str:
        return pulumi.get(self, "end_time")

    @property
    @pulumi.getter(name="exclusionName")
    def exclusion_name(self) -> str:
        return pulumi.get(self, "exclusion_name")

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> str:
        return pulumi.get(self, "start_time")

    @property
    @pulumi.getter(name="exclusionOptions")
    def exclusion_options(self) -> Optional['outputs.ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions']:
        """
        MaintenanceExclusionOptions provides maintenance exclusion related options.
        """
        return pulumi.get(self, "exclusion_options")


@pulumi.output_type
class ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions(dict):
    def __init__(__self__, *,
                 scope: str):
        """
        :param str scope: The scope of automatic upgrades to restrict in the exclusion window. One of: **NO_UPGRADES | NO_MINOR_UPGRADES | NO_MINOR_OR_NODE_UPGRADES**
               
               Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
               the initial date that the window starts, and the end time is used for calculating duration.Specify `recurrence` in
               [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
               Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.
               
               Examples:
               
               ```python
               import pulumi
               ```
        """
        pulumi.set(__self__, "scope", scope)

    @property
    @pulumi.getter
    def scope(self) -> str:
        """
        The scope of automatic upgrades to restrict in the exclusion window. One of: **NO_UPGRADES | NO_MINOR_UPGRADES | NO_MINOR_OR_NODE_UPGRADES**

        Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
        the initial date that the window starts, and the end time is used for calculating duration.Specify `recurrence` in
        [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
        Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.

        Examples:

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "scope")


@pulumi.output_type
class ClusterMaintenancePolicyRecurringWindow(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "endTime":
            suggest = "end_time"
        elif key == "startTime":
            suggest = "start_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicyRecurringWindow. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicyRecurringWindow.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicyRecurringWindow.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 end_time: str,
                 recurrence: str,
                 start_time: str):
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "recurrence", recurrence)
        pulumi.set(__self__, "start_time", start_time)

    @property
    @pulumi.getter(name="endTime")
    def end_time(self) -> str:
        return pulumi.get(self, "end_time")

    @property
    @pulumi.getter
    def recurrence(self) -> str:
        return pulumi.get(self, "recurrence")

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> str:
        return pulumi.get(self, "start_time")


@pulumi.output_type
class ClusterMasterAuth(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "clientCertificateConfig":
            suggest = "client_certificate_config"
        elif key == "clientCertificate":
            suggest = "client_certificate"
        elif key == "clientKey":
            suggest = "client_key"
        elif key == "clusterCaCertificate":
            suggest = "cluster_ca_certificate"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterAuth. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterAuth.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterAuth.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 client_certificate_config: 'outputs.ClusterMasterAuthClientCertificateConfig',
                 client_certificate: Optional[str] = None,
                 client_key: Optional[str] = None,
                 cluster_ca_certificate: Optional[str] = None):
        """
        :param 'ClusterMasterAuthClientCertificateConfigArgs' client_certificate_config: Whether client certificate authorization is enabled for this cluster.  For example:
               
               ```python
               import pulumi
               ```
               
               This block also contains several computed attributes, documented below.
        """
        pulumi.set(__self__, "client_certificate_config", client_certificate_config)
        if client_certificate is not None:
            pulumi.set(__self__, "client_certificate", client_certificate)
        if client_key is not None:
            pulumi.set(__self__, "client_key", client_key)
        if cluster_ca_certificate is not None:
            pulumi.set(__self__, "cluster_ca_certificate", cluster_ca_certificate)

    @property
    @pulumi.getter(name="clientCertificateConfig")
    def client_certificate_config(self) -> 'outputs.ClusterMasterAuthClientCertificateConfig':
        """
        Whether client certificate authorization is enabled for this cluster.  For example:

        ```python
        import pulumi
        ```

        This block also contains several computed attributes, documented below.
        """
        return pulumi.get(self, "client_certificate_config")

    @property
    @pulumi.getter(name="clientCertificate")
    def client_certificate(self) -> Optional[str]:
        return pulumi.get(self, "client_certificate")

    @property
    @pulumi.getter(name="clientKey")
    def client_key(self) -> Optional[str]:
        return pulumi.get(self, "client_key")

    @property
    @pulumi.getter(name="clusterCaCertificate")
    def cluster_ca_certificate(self) -> Optional[str]:
        return pulumi.get(self, "cluster_ca_certificate")


@pulumi.output_type
class ClusterMasterAuthClientCertificateConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "issueClientCertificate":
            suggest = "issue_client_certificate"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterAuthClientCertificateConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterAuthClientCertificateConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterAuthClientCertificateConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 issue_client_certificate: bool):
        pulumi.set(__self__, "issue_client_certificate", issue_client_certificate)

    @property
    @pulumi.getter(name="issueClientCertificate")
    def issue_client_certificate(self) -> bool:
        return pulumi.get(self, "issue_client_certificate")


@pulumi.output_type
class ClusterMasterAuthorizedNetworksConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cidrBlocks":
            suggest = "cidr_blocks"
        elif key == "gcpPublicCidrsAccessEnabled":
            suggest = "gcp_public_cidrs_access_enabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterAuthorizedNetworksConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterAuthorizedNetworksConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterAuthorizedNetworksConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cidr_blocks: Optional[Sequence['outputs.ClusterMasterAuthorizedNetworksConfigCidrBlock']] = None,
                 gcp_public_cidrs_access_enabled: Optional[bool] = None):
        """
        :param Sequence['ClusterMasterAuthorizedNetworksConfigCidrBlockArgs'] cidr_blocks: External networks that can access the
               Kubernetes cluster master through HTTPS.
        :param bool gcp_public_cidrs_access_enabled: Whether Kubernetes master is
               accessible via Google Compute Engine Public IPs.
        """
        if cidr_blocks is not None:
            pulumi.set(__self__, "cidr_blocks", cidr_blocks)
        if gcp_public_cidrs_access_enabled is not None:
            pulumi.set(__self__, "gcp_public_cidrs_access_enabled", gcp_public_cidrs_access_enabled)

    @property
    @pulumi.getter(name="cidrBlocks")
    def cidr_blocks(self) -> Optional[Sequence['outputs.ClusterMasterAuthorizedNetworksConfigCidrBlock']]:
        """
        External networks that can access the
        Kubernetes cluster master through HTTPS.
        """
        return pulumi.get(self, "cidr_blocks")

    @property
    @pulumi.getter(name="gcpPublicCidrsAccessEnabled")
    def gcp_public_cidrs_access_enabled(self) -> Optional[bool]:
        """
        Whether Kubernetes master is
        accessible via Google Compute Engine Public IPs.
        """
        return pulumi.get(self, "gcp_public_cidrs_access_enabled")


@pulumi.output_type
class ClusterMasterAuthorizedNetworksConfigCidrBlock(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cidrBlock":
            suggest = "cidr_block"
        elif key == "displayName":
            suggest = "display_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterAuthorizedNetworksConfigCidrBlock. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterAuthorizedNetworksConfigCidrBlock.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterAuthorizedNetworksConfigCidrBlock.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cidr_block: str,
                 display_name: Optional[str] = None):
        """
        :param str cidr_block: External network that can access Kubernetes master through HTTPS.
               Must be specified in CIDR notation.
        :param str display_name: Field for users to identify CIDR blocks.
        """
        pulumi.set(__self__, "cidr_block", cidr_block)
        if display_name is not None:
            pulumi.set(__self__, "display_name", display_name)

    @property
    @pulumi.getter(name="cidrBlock")
    def cidr_block(self) -> str:
        """
        External network that can access Kubernetes master through HTTPS.
        Must be specified in CIDR notation.
        """
        return pulumi.get(self, "cidr_block")

    @property
    @pulumi.getter(name="displayName")
    def display_name(self) -> Optional[str]:
        """
        Field for users to identify CIDR blocks.
        """
        return pulumi.get(self, "display_name")


@pulumi.output_type
class ClusterMeshCertificates(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableCertificates":
            suggest = "enable_certificates"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMeshCertificates. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMeshCertificates.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMeshCertificates.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_certificates: bool):
        """
        :param bool enable_certificates: Controls the issuance of workload mTLS certificates. It is enabled by default. Workload Identity is required, see workload_config.
        """
        pulumi.set(__self__, "enable_certificates", enable_certificates)

    @property
    @pulumi.getter(name="enableCertificates")
    def enable_certificates(self) -> bool:
        """
        Controls the issuance of workload mTLS certificates. It is enabled by default. Workload Identity is required, see workload_config.
        """
        return pulumi.get(self, "enable_certificates")


@pulumi.output_type
class ClusterMonitoringConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "advancedDatapathObservabilityConfigs":
            suggest = "advanced_datapath_observability_configs"
        elif key == "enableComponents":
            suggest = "enable_components"
        elif key == "managedPrometheus":
            suggest = "managed_prometheus"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMonitoringConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMonitoringConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMonitoringConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 advanced_datapath_observability_configs: Optional[Sequence['outputs.ClusterMonitoringConfigAdvancedDatapathObservabilityConfig']] = None,
                 enable_components: Optional[Sequence[str]] = None,
                 managed_prometheus: Optional['outputs.ClusterMonitoringConfigManagedPrometheus'] = None):
        """
        :param Sequence['ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs'] advanced_datapath_observability_configs: Configuration for Advanced Datapath Monitoring. Structure is documented below.
        :param Sequence[str] enable_components: The GKE components exposing metrics. Supported values include: `SYSTEM_COMPONENTS`, `APISERVER`, `SCHEDULER`, `CONTROLLER_MANAGER`, `STORAGE`, `HPA`, `POD`, `DAEMONSET`, `DEPLOYMENT` and `STATEFULSET`. In beta provider, `WORKLOADS` is supported on top of those 10 values. (`WORKLOADS` is deprecated and removed in GKE 1.24.)
        :param 'ClusterMonitoringConfigManagedPrometheusArgs' managed_prometheus: Configuration for Managed Service for Prometheus. Structure is documented below.
        """
        if advanced_datapath_observability_configs is not None:
            pulumi.set(__self__, "advanced_datapath_observability_configs", advanced_datapath_observability_configs)
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)
        if managed_prometheus is not None:
            pulumi.set(__self__, "managed_prometheus", managed_prometheus)

    @property
    @pulumi.getter(name="advancedDatapathObservabilityConfigs")
    def advanced_datapath_observability_configs(self) -> Optional[Sequence['outputs.ClusterMonitoringConfigAdvancedDatapathObservabilityConfig']]:
        """
        Configuration for Advanced Datapath Monitoring. Structure is documented below.
        """
        return pulumi.get(self, "advanced_datapath_observability_configs")

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[Sequence[str]]:
        """
        The GKE components exposing metrics. Supported values include: `SYSTEM_COMPONENTS`, `APISERVER`, `SCHEDULER`, `CONTROLLER_MANAGER`, `STORAGE`, `HPA`, `POD`, `DAEMONSET`, `DEPLOYMENT` and `STATEFULSET`. In beta provider, `WORKLOADS` is supported on top of those 10 values. (`WORKLOADS` is deprecated and removed in GKE 1.24.)
        """
        return pulumi.get(self, "enable_components")

    @property
    @pulumi.getter(name="managedPrometheus")
    def managed_prometheus(self) -> Optional['outputs.ClusterMonitoringConfigManagedPrometheus']:
        """
        Configuration for Managed Service for Prometheus. Structure is documented below.
        """
        return pulumi.get(self, "managed_prometheus")


@pulumi.output_type
class ClusterMonitoringConfigAdvancedDatapathObservabilityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableMetrics":
            suggest = "enable_metrics"
        elif key == "relayMode":
            suggest = "relay_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMonitoringConfigAdvancedDatapathObservabilityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMonitoringConfigAdvancedDatapathObservabilityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMonitoringConfigAdvancedDatapathObservabilityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_metrics: bool,
                 relay_mode: Optional[str] = None):
        """
        :param bool enable_metrics: Whether or not to enable advanced datapath metrics.
        :param str relay_mode: Mode used to make Relay available.
        """
        pulumi.set(__self__, "enable_metrics", enable_metrics)
        if relay_mode is not None:
            pulumi.set(__self__, "relay_mode", relay_mode)

    @property
    @pulumi.getter(name="enableMetrics")
    def enable_metrics(self) -> bool:
        """
        Whether or not to enable advanced datapath metrics.
        """
        return pulumi.get(self, "enable_metrics")

    @property
    @pulumi.getter(name="relayMode")
    def relay_mode(self) -> Optional[str]:
        """
        Mode used to make Relay available.
        """
        return pulumi.get(self, "relay_mode")


@pulumi.output_type
class ClusterMonitoringConfigManagedPrometheus(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the managed collection is enabled.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the managed collection is enabled.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNetworkPolicy(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 provider: Optional[str] = None):
        """
        :param bool enabled: Whether network policy is enabled on the cluster.
        :param str provider: The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.
        """
        pulumi.set(__self__, "enabled", enabled)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether network policy is enabled on the cluster.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter
    def provider(self) -> Optional[str]:
        """
        The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.
        """
        return pulumi.get(self, "provider")


@pulumi.output_type
class ClusterNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "advancedMachineFeatures":
            suggest = "advanced_machine_features"
        elif key == "bootDiskKmsKey":
            suggest = "boot_disk_kms_key"
        elif key == "confidentialNodes":
            suggest = "confidential_nodes"
        elif key == "diskSizeGb":
            suggest = "disk_size_gb"
        elif key == "diskType":
            suggest = "disk_type"
        elif key == "ephemeralStorageConfig":
            suggest = "ephemeral_storage_config"
        elif key == "ephemeralStorageLocalSsdConfig":
            suggest = "ephemeral_storage_local_ssd_config"
        elif key == "fastSocket":
            suggest = "fast_socket"
        elif key == "gcfsConfig":
            suggest = "gcfs_config"
        elif key == "guestAccelerators":
            suggest = "guest_accelerators"
        elif key == "hostMaintenancePolicy":
            suggest = "host_maintenance_policy"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "kubeletConfig":
            suggest = "kubelet_config"
        elif key == "linuxNodeConfig":
            suggest = "linux_node_config"
        elif key == "localNvmeSsdBlockConfig":
            suggest = "local_nvme_ssd_block_config"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "loggingVariant":
            suggest = "logging_variant"
        elif key == "machineType":
            suggest = "machine_type"
        elif key == "minCpuPlatform":
            suggest = "min_cpu_platform"
        elif key == "nodeGroup":
            suggest = "node_group"
        elif key == "oauthScopes":
            suggest = "oauth_scopes"
        elif key == "reservationAffinity":
            suggest = "reservation_affinity"
        elif key == "resourceLabels":
            suggest = "resource_labels"
        elif key == "sandboxConfig":
            suggest = "sandbox_config"
        elif key == "serviceAccount":
            suggest = "service_account"
        elif key == "shieldedInstanceConfig":
            suggest = "shielded_instance_config"
        elif key == "soleTenantConfig":
            suggest = "sole_tenant_config"
        elif key == "workloadMetadataConfig":
            suggest = "workload_metadata_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 advanced_machine_features: Optional['outputs.ClusterNodeConfigAdvancedMachineFeatures'] = None,
                 boot_disk_kms_key: Optional[str] = None,
                 confidential_nodes: Optional['outputs.ClusterNodeConfigConfidentialNodes'] = None,
                 disk_size_gb: Optional[int] = None,
                 disk_type: Optional[str] = None,
                 ephemeral_storage_config: Optional['outputs.ClusterNodeConfigEphemeralStorageConfig'] = None,
                 ephemeral_storage_local_ssd_config: Optional['outputs.ClusterNodeConfigEphemeralStorageLocalSsdConfig'] = None,
                 fast_socket: Optional['outputs.ClusterNodeConfigFastSocket'] = None,
                 gcfs_config: Optional['outputs.ClusterNodeConfigGcfsConfig'] = None,
                 guest_accelerators: Optional[Sequence['outputs.ClusterNodeConfigGuestAccelerator']] = None,
                 gvnic: Optional['outputs.ClusterNodeConfigGvnic'] = None,
                 host_maintenance_policy: Optional['outputs.ClusterNodeConfigHostMaintenancePolicy'] = None,
                 image_type: Optional[str] = None,
                 kubelet_config: Optional['outputs.ClusterNodeConfigKubeletConfig'] = None,
                 labels: Optional[Mapping[str, str]] = None,
                 linux_node_config: Optional['outputs.ClusterNodeConfigLinuxNodeConfig'] = None,
                 local_nvme_ssd_block_config: Optional['outputs.ClusterNodeConfigLocalNvmeSsdBlockConfig'] = None,
                 local_ssd_count: Optional[int] = None,
                 logging_variant: Optional[str] = None,
                 machine_type: Optional[str] = None,
                 metadata: Optional[Mapping[str, str]] = None,
                 min_cpu_platform: Optional[str] = None,
                 node_group: Optional[str] = None,
                 oauth_scopes: Optional[Sequence[str]] = None,
                 preemptible: Optional[bool] = None,
                 reservation_affinity: Optional['outputs.ClusterNodeConfigReservationAffinity'] = None,
                 resource_labels: Optional[Mapping[str, str]] = None,
                 sandbox_config: Optional['outputs.ClusterNodeConfigSandboxConfig'] = None,
                 service_account: Optional[str] = None,
                 shielded_instance_config: Optional['outputs.ClusterNodeConfigShieldedInstanceConfig'] = None,
                 sole_tenant_config: Optional['outputs.ClusterNodeConfigSoleTenantConfig'] = None,
                 spot: Optional[bool] = None,
                 tags: Optional[Sequence[str]] = None,
                 taints: Optional[Sequence['outputs.ClusterNodeConfigTaint']] = None,
                 workload_metadata_config: Optional['outputs.ClusterNodeConfigWorkloadMetadataConfig'] = None):
        """
        :param 'ClusterNodeConfigAdvancedMachineFeaturesArgs' advanced_machine_features: Specifies options for controlling
               advanced machine features. Structure is documented below.
        :param str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        :param 'ClusterNodeConfigConfidentialNodesArgs' confidential_nodes: Configuration for [Confidential Nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/confidential-gke-nodes) feature. Structure is documented below documented below.
        :param int disk_size_gb: Size of the disk attached to each node, specified
               in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        :param str disk_type: Type of the disk attached to each node
               (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        :param 'ClusterNodeConfigEphemeralStorageConfigArgs' ephemeral_storage_config: ) Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param 'ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs' ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param 'ClusterNodeConfigFastSocketArgs' fast_socket: Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
               Node Pool must enable gvnic.
               GKE version 1.25.2-gke.1700 or later.
               Structure is documented below.
        :param 'ClusterNodeConfigGcfsConfigArgs' gcfs_config: Parameters for the Google Container Filesystem (GCFS).
               If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
               For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
               A `machine_type` that has more than 16 GiB of memory is also recommended.
               GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
               Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param Sequence['ClusterNodeConfigGuestAcceleratorArgs'] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
               Structure documented below.
        :param 'ClusterNodeConfigGvnicArgs' gvnic: Google Virtual NIC (gVNIC) is a virtual network interface.
               Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
               gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
               GKE node version 1.15.11-gke.15 or later
               Structure is documented below.
               
               
               ```python
               import pulumi
               ```
        :param str image_type: The image type to use for this node. Note that changing the image type
               will delete and recreate all nodes in the node pool.
        :param 'ClusterNodeConfigKubeletConfigArgs' kubelet_config: Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param Mapping[str, str] labels: The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
               reserved by Kubernetes Core components and cannot be specified.
        :param 'ClusterNodeConfigLinuxNodeConfigArgs' linux_node_config: Linux node configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Note that validations happen all server side. All attributes are optional.
               Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param 'ClusterNodeConfigLocalNvmeSsdBlockConfigArgs' local_nvme_ssd_block_config: Parameters for the local NVMe SSDs. Structure is documented below.
        :param int local_ssd_count: The amount of local SSD disks that will be
               attached to each cluster node. Defaults to 0.
        :param str logging_variant: Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        :param str machine_type: The name of a Google Compute Engine machine type.
               Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
               [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        :param Mapping[str, str] metadata: The metadata key/value pairs assigned to instances in
               the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
               `true` by the API; if `metadata` is set but that default value is not
               included, the provider will attempt to unset the value. To avoid this, set the
               value in your config.
        :param str min_cpu_platform: Minimum CPU platform to be used by this instance.
               The instance may be scheduled on the specified or newer CPU platform. Applicable
               values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
               [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
               for more information.
        :param str node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        :param Sequence[str] oauth_scopes: The set of Google API scopes to be made available
               on all of the node VMs under the "default" service account.
               Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        :param bool preemptible: A boolean that represents whether or not the underlying node VMs
               are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
               for more information. Defaults to false.
        :param 'ClusterNodeConfigReservationAffinityArgs' reservation_affinity: The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        :param Mapping[str, str] resource_labels: The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
               for how these labels are applied to clusters, node pools and nodes.
        :param str service_account: The service account to be used by the Node VMs.
               If not specified, the "default" service account is used.
        :param 'ClusterNodeConfigShieldedInstanceConfigArgs' shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param 'ClusterNodeConfigSoleTenantConfigArgs' sole_tenant_config: Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
               
               ```python
               import pulumi
               ```
        :param bool spot: A boolean that represents whether the underlying node VMs are spot.
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
               for more information. Defaults to false.
        :param Sequence[str] tags: The list of instance tags applied to all nodes. Tags are used to identify
               valid sources or targets for network firewalls.
        :param Sequence['ClusterNodeConfigTaintArgs'] taints: A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
               to apply to nodes. GKE's API can only set this field on cluster creation.
               However, GKE will add taints to your nodes if you enable certain features such
               as GPUs. If this field is set, any diffs on this field will cause the provider to
               recreate the underlying resource. Taint values can be updated safely in
               Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
               this field to manage taints. If you do, `lifecycle.ignore_changes` is
               recommended. Structure is documented below.
        :param 'ClusterNodeConfigWorkloadMetadataConfigArgs' workload_metadata_config: Metadata configuration to expose to workloads on the node pool.
               Structure is documented below.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional['outputs.ClusterNodeConfigAdvancedMachineFeatures']:
        """
        Specifies options for controlling
        advanced machine features. Structure is documented below.
        """
        return pulumi.get(self, "advanced_machine_features")

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[str]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional['outputs.ClusterNodeConfigConfidentialNodes']:
        """
        Configuration for [Confidential Nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/confidential-gke-nodes) feature. Structure is documented below documented below.
        """
        return pulumi.get(self, "confidential_nodes")

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[int]:
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[str]:
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        """
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional['outputs.ClusterNodeConfigEphemeralStorageConfig']:
        """
        ) Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional['outputs.ClusterNodeConfigEphemeralStorageLocalSsdConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional['outputs.ClusterNodeConfigFastSocket']:
        """
        Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
        Node Pool must enable gvnic.
        GKE version 1.25.2-gke.1700 or later.
        Structure is documented below.
        """
        return pulumi.get(self, "fast_socket")

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional['outputs.ClusterNodeConfigGcfsConfig']:
        """
        Parameters for the Google Container Filesystem (GCFS).
        If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
        For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
        A `machine_type` that has more than 16 GiB of memory is also recommended.
        GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
        Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "gcfs_config")

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[Sequence['outputs.ClusterNodeConfigGuestAccelerator']]:
        """
        List of the type and count of accelerator cards attached to the instance.
        Structure documented below.
        """
        return pulumi.get(self, "guest_accelerators")

    @property
    @pulumi.getter
    def gvnic(self) -> Optional['outputs.ClusterNodeConfigGvnic']:
        """
        Google Virtual NIC (gVNIC) is a virtual network interface.
        Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
        gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
        GKE node version 1.15.11-gke.15 or later
        Structure is documented below.


        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "gvnic")

    @property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional['outputs.ClusterNodeConfigHostMaintenancePolicy']:
        return pulumi.get(self, "host_maintenance_policy")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[str]:
        """
        The image type to use for this node. Note that changing the image type
        will delete and recreate all nodes in the node pool.
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional['outputs.ClusterNodeConfigKubeletConfig']:
        """
        Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "kubelet_config")

    @property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, str]]:
        """
        The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
        reserved by Kubernetes Core components and cannot be specified.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional['outputs.ClusterNodeConfigLinuxNodeConfig']:
        """
        Linux node configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Note that validations happen all server side. All attributes are optional.
        Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "linux_node_config")

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional['outputs.ClusterNodeConfigLocalNvmeSsdBlockConfig']:
        """
        Parameters for the local NVMe SSDs. Structure is documented below.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        """
        The amount of local SSD disks that will be
        attached to each cluster node. Defaults to 0.
        """
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[str]:
        """
        Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[str]:
        """
        The name of a Google Compute Engine machine type.
        Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
        [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        """
        return pulumi.get(self, "machine_type")

    @property
    @pulumi.getter
    def metadata(self) -> Optional[Mapping[str, str]]:
        """
        The metadata key/value pairs assigned to instances in
        the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
        `true` by the API; if `metadata` is set but that default value is not
        included, the provider will attempt to unset the value. To avoid this, set the
        value in your config.
        """
        return pulumi.get(self, "metadata")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[str]:
        """
        Minimum CPU platform to be used by this instance.
        The instance may be scheduled on the specified or newer CPU platform. Applicable
        values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
        [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
        for more information.
        """
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[str]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        """
        return pulumi.get(self, "node_group")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[Sequence[str]]:
        """
        The set of Google API scopes to be made available
        on all of the node VMs under the "default" service account.
        Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        """
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter
    def preemptible(self) -> Optional[bool]:
        """
        A boolean that represents whether or not the underlying node VMs
        are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "preemptible")

    @property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional['outputs.ClusterNodeConfigReservationAffinity']:
        """
        The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        """
        return pulumi.get(self, "reservation_affinity")

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[Mapping[str, str]]:
        """
        The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
        for how these labels are applied to clusters, node pools and nodes.
        """
        return pulumi.get(self, "resource_labels")

    @property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional['outputs.ClusterNodeConfigSandboxConfig']:
        return pulumi.get(self, "sandbox_config")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[str]:
        """
        The service account to be used by the Node VMs.
        If not specified, the "default" service account is used.
        """
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional['outputs.ClusterNodeConfigShieldedInstanceConfig']:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional['outputs.ClusterNodeConfigSoleTenantConfig']:
        """
        Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "sole_tenant_config")

    @property
    @pulumi.getter
    def spot(self) -> Optional[bool]:
        """
        A boolean that represents whether the underlying node VMs are spot.
        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "spot")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Sequence[str]]:
        """
        The list of instance tags applied to all nodes. Tags are used to identify
        valid sources or targets for network firewalls.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def taints(self) -> Optional[Sequence['outputs.ClusterNodeConfigTaint']]:
        """
        A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
        to apply to nodes. GKE's API can only set this field on cluster creation.
        However, GKE will add taints to your nodes if you enable certain features such
        as GPUs. If this field is set, any diffs on this field will cause the provider to
        recreate the underlying resource. Taint values can be updated safely in
        Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
        this field to manage taints. If you do, `lifecycle.ignore_changes` is
        recommended. Structure is documented below.
        """
        return pulumi.get(self, "taints")

    @property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional['outputs.ClusterNodeConfigWorkloadMetadataConfig']:
        """
        Metadata configuration to expose to workloads on the node pool.
        Structure is documented below.
        """
        return pulumi.get(self, "workload_metadata_config")


@pulumi.output_type
class ClusterNodeConfigAdvancedMachineFeatures(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "threadsPerCore":
            suggest = "threads_per_core"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigAdvancedMachineFeatures. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 threads_per_core: int):
        """
        :param int threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> int:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")


@pulumi.output_type
class ClusterNodeConfigConfidentialNodes(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodeConfigEphemeralStorageConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigEphemeralStorageConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodeConfigEphemeralStorageLocalSsdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigEphemeralStorageLocalSsdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodeConfigFastSocket(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodeConfigGcfsConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodeConfigGuestAccelerator(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverInstallationConfig":
            suggest = "gpu_driver_installation_config"
        elif key == "gpuPartitionSize":
            suggest = "gpu_partition_size"
        elif key == "gpuSharingConfig":
            suggest = "gpu_sharing_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigGuestAccelerator. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigGuestAccelerator.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigGuestAccelerator.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 count: int,
                 type: str,
                 gpu_driver_installation_config: Optional['outputs.ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig'] = None,
                 gpu_partition_size: Optional[str] = None,
                 gpu_sharing_config: Optional['outputs.ClusterNodeConfigGuestAcceleratorGpuSharingConfig'] = None):
        """
        :param int count: The number of the guest accelerator cards exposed to this instance.
        :param str type: The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        :param 'ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs' gpu_driver_installation_config: Configuration for auto installation of GPU driver. Structure is documented below.
        :param str gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        :param 'ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs' gpu_sharing_config: Configuration for GPU sharing. Structure is documented below.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @property
    @pulumi.getter
    def count(self) -> int:
        """
        The number of the guest accelerator cards exposed to this instance.
        """
        return pulumi.get(self, "count")

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        """
        return pulumi.get(self, "type")

    @property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional['outputs.ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig']:
        """
        Configuration for auto installation of GPU driver. Structure is documented below.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[str]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        """
        return pulumi.get(self, "gpu_partition_size")

    @property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional['outputs.ClusterNodeConfigGuestAcceleratorGpuSharingConfig']:
        """
        Configuration for GPU sharing. Structure is documented below.
        """
        return pulumi.get(self, "gpu_sharing_config")


@pulumi.output_type
class ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverVersion":
            suggest = "gpu_driver_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_driver_version: str):
        """
        :param str gpu_driver_version: Mode for how the GPU driver is installed.
               Accepted values are:
               * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to not install any GPU driver.
               * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
               * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
               * `"LATEST"`: "Latest" GPU driver in COS.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> str:
        """
        Mode for how the GPU driver is installed.
        Accepted values are:
        * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to not install any GPU driver.
        * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
        * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
        * `"LATEST"`: "Latest" GPU driver in COS.
        """
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class ClusterNodeConfigGuestAcceleratorGpuSharingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuSharingStrategy":
            suggest = "gpu_sharing_strategy"
        elif key == "maxSharedClientsPerGpu":
            suggest = "max_shared_clients_per_gpu"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigGuestAcceleratorGpuSharingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_sharing_strategy: str,
                 max_shared_clients_per_gpu: int):
        """
        :param str gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node.
               Accepted values are:
               * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        :param int max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> str:
        """
        The type of GPU sharing strategy to enable on the GPU node.
        Accepted values are:
        * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> int:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class ClusterNodeConfigGvnic(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodeConfigHostMaintenancePolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maintenanceInterval":
            suggest = "maintenance_interval"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigHostMaintenancePolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 maintenance_interval: str):
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> str:
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class ClusterNodeConfigKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cpuManagerPolicy":
            suggest = "cpu_manager_policy"
        elif key == "cpuCfsQuota":
            suggest = "cpu_cfs_quota"
        elif key == "cpuCfsQuotaPeriod":
            suggest = "cpu_cfs_quota_period"
        elif key == "podPidsLimit":
            suggest = "pod_pids_limit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cpu_manager_policy: str,
                 cpu_cfs_quota: Optional[bool] = None,
                 cpu_cfs_quota_period: Optional[str] = None,
                 pod_pids_limit: Optional[int] = None):
        """
        :param str cpu_manager_policy: The CPU management policy on the node. See
               [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
               One of `"none"` or `"static"`. Defaults to `none` when `kubelet_config` is unset.
        :param bool cpu_cfs_quota: If true, enables CPU CFS quota enforcement for
               containers that specify CPU limits.
        :param str cpu_cfs_quota_period: The CPU CFS quota period value. Specified
               as a sequence of decimal numbers, each with optional fraction and a unit suffix,
               such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
               "h". The value must be a positive duration.
               
               > Note: At the time of writing (2020/08/18) the GKE API rejects the `none`
               value and accepts an invalid `default` value instead. While this remains true,
               not specifying the `kubelet_config` block should be the equivalent of specifying
               `none`.
        :param int pod_pids_limit: Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> str:
        """
        The CPU management policy on the node. See
        [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
        One of `"none"` or `"static"`. Defaults to `none` when `kubelet_config` is unset.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[bool]:
        """
        If true, enables CPU CFS quota enforcement for
        containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[str]:
        """
        The CPU CFS quota period value. Specified
        as a sequence of decimal numbers, each with optional fraction and a unit suffix,
        such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
        "h". The value must be a positive duration.

        > Note: At the time of writing (2020/08/18) the GKE API rejects the `none`
        value and accepts an invalid `default` value instead. While this remains true,
        not specifying the `kubelet_config` block should be the equivalent of specifying
        `none`.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[int]:
        """
        Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        return pulumi.get(self, "pod_pids_limit")


@pulumi.output_type
class ClusterNodeConfigLinuxNodeConfig(dict):
    def __init__(__self__, *,
                 sysctls: Mapping[str, str]):
        """
        :param Mapping[str, str] sysctls: The Linux kernel parameters to be applied to the nodes
               and all pods running on the nodes. Specified as a map from the key, such as
               `net.core.wmem_max`, to a string value.
        """
        pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter
    def sysctls(self) -> Mapping[str, str]:
        """
        The Linux kernel parameters to be applied to the nodes
        and all pods running on the nodes. Specified as a map from the key, such as
        `net.core.wmem_max`, to a string value.
        """
        return pulumi.get(self, "sysctls")


@pulumi.output_type
class ClusterNodeConfigLocalNvmeSsdBlockConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigLocalNvmeSsdBlockConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
               > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
        > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodeConfigReservationAffinity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "consumeReservationType":
            suggest = "consume_reservation_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigReservationAffinity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigReservationAffinity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigReservationAffinity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 consume_reservation_type: str,
                 key: Optional[str] = None,
                 values: Optional[Sequence[str]] = None):
        """
        :param str consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param str key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param Sequence[str] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> str:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def values(self) -> Optional[Sequence[str]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ClusterNodeConfigSandboxConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sandboxType":
            suggest = "sandbox_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigSandboxConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigSandboxConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigSandboxConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 sandbox_type: str):
        """
        :param str sandbox_type: Which sandbox to use for pods in the node pool.
               Accepted values are:
               
               * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> str:
        """
        Which sandbox to use for pods in the node pool.
        Accepted values are:

        * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class ClusterNodeConfigShieldedInstanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableIntegrityMonitoring":
            suggest = "enable_integrity_monitoring"
        elif key == "enableSecureBoot":
            suggest = "enable_secure_boot"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigShieldedInstanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[bool] = None,
                 enable_secure_boot: Optional[bool] = None):
        """
        :param bool enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param bool enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[bool]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[bool]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class ClusterNodeConfigSoleTenantConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodeAffinities":
            suggest = "node_affinities"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigSoleTenantConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigSoleTenantConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigSoleTenantConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.ClusterNodeConfigSoleTenantConfigNodeAffinity']):
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.ClusterNodeConfigSoleTenantConfigNodeAffinity']:
        return pulumi.get(self, "node_affinities")


@pulumi.output_type
class ClusterNodeConfigSoleTenantConfigNodeAffinity(dict):
    def __init__(__self__, *,
                 key: str,
                 operator: str,
                 values: Sequence[str]):
        """
        :param str key: The default or custom node affinity label key name.
        :param str operator: Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        :param Sequence[str] values: List of node affinity label values as strings.
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        The default or custom node affinity label key name.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def operator(self) -> str:
        """
        Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        """
        return pulumi.get(self, "operator")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        """
        List of node affinity label values as strings.
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ClusterNodeConfigTaint(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        """
        :param str effect: Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        :param str key: Key for taint.
        :param str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        """
        Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class ClusterNodeConfigWorkloadMetadataConfig(dict):
    def __init__(__self__, *,
                 mode: str):
        """
        :param str mode: How to expose the node metadata to the workload running on the node.
               Accepted values are:
               * UNSPECIFIED: Not Set
               * GCE_METADATA: Expose all Compute Engine metadata to pods.
               * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> str:
        """
        How to expose the node metadata to the workload running on the node.
        Accepted values are:
        * UNSPECIFIED: Not Set
        * GCE_METADATA: Expose all Compute Engine metadata to pods.
        * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class ClusterNodePool(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "initialNodeCount":
            suggest = "initial_node_count"
        elif key == "instanceGroupUrls":
            suggest = "instance_group_urls"
        elif key == "managedInstanceGroupUrls":
            suggest = "managed_instance_group_urls"
        elif key == "maxPodsPerNode":
            suggest = "max_pods_per_node"
        elif key == "namePrefix":
            suggest = "name_prefix"
        elif key == "networkConfig":
            suggest = "network_config"
        elif key == "nodeConfig":
            suggest = "node_config"
        elif key == "nodeCount":
            suggest = "node_count"
        elif key == "nodeLocations":
            suggest = "node_locations"
        elif key == "placementPolicy":
            suggest = "placement_policy"
        elif key == "upgradeSettings":
            suggest = "upgrade_settings"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePool. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePool.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePool.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 autoscaling: Optional['outputs.ClusterNodePoolAutoscaling'] = None,
                 initial_node_count: Optional[int] = None,
                 instance_group_urls: Optional[Sequence[str]] = None,
                 managed_instance_group_urls: Optional[Sequence[str]] = None,
                 management: Optional['outputs.ClusterNodePoolManagement'] = None,
                 max_pods_per_node: Optional[int] = None,
                 name: Optional[str] = None,
                 name_prefix: Optional[str] = None,
                 network_config: Optional['outputs.ClusterNodePoolNetworkConfig'] = None,
                 node_config: Optional['outputs.ClusterNodePoolNodeConfig'] = None,
                 node_count: Optional[int] = None,
                 node_locations: Optional[Sequence[str]] = None,
                 placement_policy: Optional['outputs.ClusterNodePoolPlacementPolicy'] = None,
                 upgrade_settings: Optional['outputs.ClusterNodePoolUpgradeSettings'] = None,
                 version: Optional[str] = None):
        """
        :param int initial_node_count: The number of nodes to create in this
               cluster's default node pool. In regional or multi-zonal clusters, this is the
               number of nodes per zone. Must be set if `node_pool` is not set. If you're using
               `container.NodePool` objects with no default node pool, you'll need to
               set this to a value of at least `1`, alongside setting
               `remove_default_node_pool` to `true`.
        :param 'ClusterNodePoolManagementArgs' management: NodeManagement configuration for this NodePool. Structure is documented below.
        :param str name: The name of the cluster, unique within the project and
               location.
               
               - - -
        :param 'ClusterNodePoolNetworkConfigArgs' network_config: Configuration for
               [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
        :param 'ClusterNodePoolNodeConfigArgs' node_config: Parameters used in creating the default node pool.
               Generally, this field should not be used at the same time as a
               `container.NodePool` or a `node_pool` block; this configuration
               manages the default node pool, which isn't recommended to be used.
               Structure is documented below.
        :param Sequence[str] node_locations: The list of zones in which the cluster's nodes
               are located. Nodes must be in the region of their regional cluster or in the
               same region as their cluster's zone for zonal clusters. If this is specified for
               a zonal cluster, omit the cluster's zone.
               
               > A "multi-zonal" cluster is a zonal cluster with at least one additional zone
               defined; in a multi-zonal cluster, the cluster master is only present in a
               single zone while nodes are present in each of the primary zone and the node
               locations. In contrast, in a regional cluster, cluster master nodes are present
               in multiple zones in the region. For that reason, regional clusters should be
               preferred.
        :param 'ClusterNodePoolUpgradeSettingsArgs' upgrade_settings: Specifies the upgrade settings for NAP created node pools. Structure is documented below.
        """
        if autoscaling is not None:
            pulumi.set(__self__, "autoscaling", autoscaling)
        if initial_node_count is not None:
            pulumi.set(__self__, "initial_node_count", initial_node_count)
        if instance_group_urls is not None:
            pulumi.set(__self__, "instance_group_urls", instance_group_urls)
        if managed_instance_group_urls is not None:
            pulumi.set(__self__, "managed_instance_group_urls", managed_instance_group_urls)
        if management is not None:
            pulumi.set(__self__, "management", management)
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if name_prefix is not None:
            pulumi.set(__self__, "name_prefix", name_prefix)
        if network_config is not None:
            pulumi.set(__self__, "network_config", network_config)
        if node_config is not None:
            pulumi.set(__self__, "node_config", node_config)
        if node_count is not None:
            pulumi.set(__self__, "node_count", node_count)
        if node_locations is not None:
            pulumi.set(__self__, "node_locations", node_locations)
        if placement_policy is not None:
            pulumi.set(__self__, "placement_policy", placement_policy)
        if upgrade_settings is not None:
            pulumi.set(__self__, "upgrade_settings", upgrade_settings)
        if version is not None:
            pulumi.set(__self__, "version", version)

    @property
    @pulumi.getter
    def autoscaling(self) -> Optional['outputs.ClusterNodePoolAutoscaling']:
        return pulumi.get(self, "autoscaling")

    @property
    @pulumi.getter(name="initialNodeCount")
    def initial_node_count(self) -> Optional[int]:
        """
        The number of nodes to create in this
        cluster's default node pool. In regional or multi-zonal clusters, this is the
        number of nodes per zone. Must be set if `node_pool` is not set. If you're using
        `container.NodePool` objects with no default node pool, you'll need to
        set this to a value of at least `1`, alongside setting
        `remove_default_node_pool` to `true`.
        """
        return pulumi.get(self, "initial_node_count")

    @property
    @pulumi.getter(name="instanceGroupUrls")
    def instance_group_urls(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "instance_group_urls")

    @property
    @pulumi.getter(name="managedInstanceGroupUrls")
    def managed_instance_group_urls(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "managed_instance_group_urls")

    @property
    @pulumi.getter
    def management(self) -> Optional['outputs.ClusterNodePoolManagement']:
        """
        NodeManagement configuration for this NodePool. Structure is documented below.
        """
        return pulumi.get(self, "management")

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[int]:
        return pulumi.get(self, "max_pods_per_node")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of the cluster, unique within the project and
        location.

        - - -
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="namePrefix")
    def name_prefix(self) -> Optional[str]:
        return pulumi.get(self, "name_prefix")

    @property
    @pulumi.getter(name="networkConfig")
    def network_config(self) -> Optional['outputs.ClusterNodePoolNetworkConfig']:
        """
        Configuration for
        [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
        """
        return pulumi.get(self, "network_config")

    @property
    @pulumi.getter(name="nodeConfig")
    def node_config(self) -> Optional['outputs.ClusterNodePoolNodeConfig']:
        """
        Parameters used in creating the default node pool.
        Generally, this field should not be used at the same time as a
        `container.NodePool` or a `node_pool` block; this configuration
        manages the default node pool, which isn't recommended to be used.
        Structure is documented below.
        """
        return pulumi.get(self, "node_config")

    @property
    @pulumi.getter(name="nodeCount")
    def node_count(self) -> Optional[int]:
        return pulumi.get(self, "node_count")

    @property
    @pulumi.getter(name="nodeLocations")
    def node_locations(self) -> Optional[Sequence[str]]:
        """
        The list of zones in which the cluster's nodes
        are located. Nodes must be in the region of their regional cluster or in the
        same region as their cluster's zone for zonal clusters. If this is specified for
        a zonal cluster, omit the cluster's zone.

        > A "multi-zonal" cluster is a zonal cluster with at least one additional zone
        defined; in a multi-zonal cluster, the cluster master is only present in a
        single zone while nodes are present in each of the primary zone and the node
        locations. In contrast, in a regional cluster, cluster master nodes are present
        in multiple zones in the region. For that reason, regional clusters should be
        preferred.
        """
        return pulumi.get(self, "node_locations")

    @property
    @pulumi.getter(name="placementPolicy")
    def placement_policy(self) -> Optional['outputs.ClusterNodePoolPlacementPolicy']:
        return pulumi.get(self, "placement_policy")

    @property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Optional['outputs.ClusterNodePoolUpgradeSettings']:
        """
        Specifies the upgrade settings for NAP created node pools. Structure is documented below.
        """
        return pulumi.get(self, "upgrade_settings")

    @property
    @pulumi.getter
    def version(self) -> Optional[str]:
        return pulumi.get(self, "version")


@pulumi.output_type
class ClusterNodePoolAutoConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "networkTags":
            suggest = "network_tags"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolAutoConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolAutoConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolAutoConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 network_tags: Optional['outputs.ClusterNodePoolAutoConfigNetworkTags'] = None):
        """
        :param 'ClusterNodePoolAutoConfigNetworkTagsArgs' network_tags: The network tag config for the cluster's automatically provisioned node pools.
        """
        if network_tags is not None:
            pulumi.set(__self__, "network_tags", network_tags)

    @property
    @pulumi.getter(name="networkTags")
    def network_tags(self) -> Optional['outputs.ClusterNodePoolAutoConfigNetworkTags']:
        """
        The network tag config for the cluster's automatically provisioned node pools.
        """
        return pulumi.get(self, "network_tags")


@pulumi.output_type
class ClusterNodePoolAutoConfigNetworkTags(dict):
    def __init__(__self__, *,
                 tags: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] tags: List of network tags applied to auto-provisioned node pools.
               
               ```python
               import pulumi
               ```
        """
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @property
    @pulumi.getter
    def tags(self) -> Optional[Sequence[str]]:
        """
        List of network tags applied to auto-provisioned node pools.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "tags")


@pulumi.output_type
class ClusterNodePoolAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "locationPolicy":
            suggest = "location_policy"
        elif key == "maxNodeCount":
            suggest = "max_node_count"
        elif key == "minNodeCount":
            suggest = "min_node_count"
        elif key == "totalMaxNodeCount":
            suggest = "total_max_node_count"
        elif key == "totalMinNodeCount":
            suggest = "total_min_node_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 location_policy: Optional[str] = None,
                 max_node_count: Optional[int] = None,
                 min_node_count: Optional[int] = None,
                 total_max_node_count: Optional[int] = None,
                 total_min_node_count: Optional[int] = None):
        if location_policy is not None:
            pulumi.set(__self__, "location_policy", location_policy)
        if max_node_count is not None:
            pulumi.set(__self__, "max_node_count", max_node_count)
        if min_node_count is not None:
            pulumi.set(__self__, "min_node_count", min_node_count)
        if total_max_node_count is not None:
            pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        if total_min_node_count is not None:
            pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> Optional[str]:
        return pulumi.get(self, "location_policy")

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> Optional[int]:
        return pulumi.get(self, "max_node_count")

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> Optional[int]:
        return pulumi.get(self, "min_node_count")

    @property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> Optional[int]:
        return pulumi.get(self, "total_max_node_count")

    @property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> Optional[int]:
        return pulumi.get(self, "total_min_node_count")


@pulumi.output_type
class ClusterNodePoolDefaults(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodeConfigDefaults":
            suggest = "node_config_defaults"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaults. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaults.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaults.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_config_defaults: Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaults'] = None):
        """
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsArgs' node_config_defaults: Subset of NodeConfig message that has defaults.
        """
        if node_config_defaults is not None:
            pulumi.set(__self__, "node_config_defaults", node_config_defaults)

    @property
    @pulumi.getter(name="nodeConfigDefaults")
    def node_config_defaults(self) -> Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaults']:
        """
        Subset of NodeConfig message that has defaults.
        """
        return pulumi.get(self, "node_config_defaults")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaults(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gcfsConfig":
            suggest = "gcfs_config"
        elif key == "loggingVariant":
            suggest = "logging_variant"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaultsNodeConfigDefaults. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaults.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaults.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gcfs_config: Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfig'] = None,
                 logging_variant: Optional[str] = None):
        """
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs' gcfs_config: ) The default Google Container Filesystem (GCFS) configuration at the cluster level. e.g. enable [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming) across all the node pools within the cluster. Structure is documented below.
        :param str logging_variant: The type of logging agent that is deployed by default for newly created node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfig']:
        """
        ) The default Google Container Filesystem (GCFS) configuration at the cluster level. e.g. enable [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming) across all the node pools within the cluster. Structure is documented below.
        """
        return pulumi.get(self, "gcfs_config")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[str]:
        """
        The type of logging agent that is deployed by default for newly created node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"
        elif key == "autoUpgrade":
            suggest = "auto_upgrade"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[bool] = None,
                 auto_upgrade: Optional[bool] = None):
        """
        :param bool auto_repair: Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
               
               This block also contains several computed attributes, documented below.
        :param bool auto_upgrade: Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[bool]:
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.

        This block also contains several computed attributes, documented below.
        """
        return pulumi.get(self, "auto_repair")

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[bool]:
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        return pulumi.get(self, "auto_upgrade")


@pulumi.output_type
class ClusterNodePoolNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "additionalNodeNetworkConfigs":
            suggest = "additional_node_network_configs"
        elif key == "additionalPodNetworkConfigs":
            suggest = "additional_pod_network_configs"
        elif key == "createPodRange":
            suggest = "create_pod_range"
        elif key == "enablePrivateNodes":
            suggest = "enable_private_nodes"
        elif key == "podCidrOverprovisionConfig":
            suggest = "pod_cidr_overprovision_config"
        elif key == "podIpv4CidrBlock":
            suggest = "pod_ipv4_cidr_block"
        elif key == "podRange":
            suggest = "pod_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 additional_node_network_configs: Optional[Sequence['outputs.ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfig']] = None,
                 additional_pod_network_configs: Optional[Sequence['outputs.ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig']] = None,
                 create_pod_range: Optional[bool] = None,
                 enable_private_nodes: Optional[bool] = None,
                 pod_cidr_overprovision_config: Optional['outputs.ClusterNodePoolNetworkConfigPodCidrOverprovisionConfig'] = None,
                 pod_ipv4_cidr_block: Optional[str] = None,
                 pod_range: Optional[str] = None):
        """
        :param bool create_pod_range: Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        :param bool enable_private_nodes: Enables the private cluster feature,
               creating a private endpoint on the cluster. In a private cluster, nodes only
               have RFC 1918 private addresses and communicate with the master's private
               endpoint via private networking.
        :param str pod_ipv4_cidr_block: The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        :param str pod_range: The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        if additional_node_network_configs is not None:
            pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        if additional_pod_network_configs is not None:
            pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        if create_pod_range is not None:
            pulumi.set(__self__, "create_pod_range", create_pod_range)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if pod_ipv4_cidr_block is not None:
            pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        if pod_range is not None:
            pulumi.set(__self__, "pod_range", pod_range)

    @property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Optional[Sequence['outputs.ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfig']]:
        return pulumi.get(self, "additional_node_network_configs")

    @property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Optional[Sequence['outputs.ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig']]:
        return pulumi.get(self, "additional_pod_network_configs")

    @property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> Optional[bool]:
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        """
        return pulumi.get(self, "create_pod_range")

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[bool]:
        """
        Enables the private cluster feature,
        creating a private endpoint on the cluster. In a private cluster, nodes only
        have RFC 1918 private addresses and communicate with the master's private
        endpoint via private networking.
        """
        return pulumi.get(self, "enable_private_nodes")

    @property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional['outputs.ClusterNodePoolNetworkConfigPodCidrOverprovisionConfig']:
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> Optional[str]:
        """
        The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> Optional[str]:
        """
        The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        return pulumi.get(self, "pod_range")


@pulumi.output_type
class ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfig(dict):
    def __init__(__self__, *,
                 network: Optional[str] = None,
                 subnetwork: Optional[str] = None):
        """
        :param str network: The name or self_link of the Google Compute Engine
               network to which the cluster is connected. For Shared VPC, set this to the self link of the
               shared network.
        :param str subnetwork: The name or self_link of the Google Compute Engine
               subnetwork in which the cluster's instances are launched.
        """
        if network is not None:
            pulumi.set(__self__, "network", network)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter
    def network(self) -> Optional[str]:
        """
        The name or self_link of the Google Compute Engine
        network to which the cluster is connected. For Shared VPC, set this to the self link of the
        shared network.
        """
        return pulumi.get(self, "network")

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[str]:
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxPodsPerNode":
            suggest = "max_pods_per_node"
        elif key == "secondaryPodRange":
            suggest = "secondary_pod_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_pods_per_node: Optional[int] = None,
                 secondary_pod_range: Optional[str] = None,
                 subnetwork: Optional[str] = None):
        """
        :param str subnetwork: The name or self_link of the Google Compute Engine
               subnetwork in which the cluster's instances are launched.
        """
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if secondary_pod_range is not None:
            pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[int]:
        return pulumi.get(self, "max_pods_per_node")

    @property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> Optional[str]:
        return pulumi.get(self, "secondary_pod_range")

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[str]:
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class ClusterNodePoolNetworkConfigPodCidrOverprovisionConfig(dict):
    def __init__(__self__, *,
                 disabled: bool):
        """
        :param bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterNodePoolNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "advancedMachineFeatures":
            suggest = "advanced_machine_features"
        elif key == "bootDiskKmsKey":
            suggest = "boot_disk_kms_key"
        elif key == "confidentialNodes":
            suggest = "confidential_nodes"
        elif key == "diskSizeGb":
            suggest = "disk_size_gb"
        elif key == "diskType":
            suggest = "disk_type"
        elif key == "ephemeralStorageConfig":
            suggest = "ephemeral_storage_config"
        elif key == "ephemeralStorageLocalSsdConfig":
            suggest = "ephemeral_storage_local_ssd_config"
        elif key == "fastSocket":
            suggest = "fast_socket"
        elif key == "gcfsConfig":
            suggest = "gcfs_config"
        elif key == "guestAccelerators":
            suggest = "guest_accelerators"
        elif key == "hostMaintenancePolicy":
            suggest = "host_maintenance_policy"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "kubeletConfig":
            suggest = "kubelet_config"
        elif key == "linuxNodeConfig":
            suggest = "linux_node_config"
        elif key == "localNvmeSsdBlockConfig":
            suggest = "local_nvme_ssd_block_config"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "loggingVariant":
            suggest = "logging_variant"
        elif key == "machineType":
            suggest = "machine_type"
        elif key == "minCpuPlatform":
            suggest = "min_cpu_platform"
        elif key == "nodeGroup":
            suggest = "node_group"
        elif key == "oauthScopes":
            suggest = "oauth_scopes"
        elif key == "reservationAffinity":
            suggest = "reservation_affinity"
        elif key == "resourceLabels":
            suggest = "resource_labels"
        elif key == "sandboxConfig":
            suggest = "sandbox_config"
        elif key == "serviceAccount":
            suggest = "service_account"
        elif key == "shieldedInstanceConfig":
            suggest = "shielded_instance_config"
        elif key == "soleTenantConfig":
            suggest = "sole_tenant_config"
        elif key == "workloadMetadataConfig":
            suggest = "workload_metadata_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 advanced_machine_features: Optional['outputs.ClusterNodePoolNodeConfigAdvancedMachineFeatures'] = None,
                 boot_disk_kms_key: Optional[str] = None,
                 confidential_nodes: Optional['outputs.ClusterNodePoolNodeConfigConfidentialNodes'] = None,
                 disk_size_gb: Optional[int] = None,
                 disk_type: Optional[str] = None,
                 ephemeral_storage_config: Optional['outputs.ClusterNodePoolNodeConfigEphemeralStorageConfig'] = None,
                 ephemeral_storage_local_ssd_config: Optional['outputs.ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig'] = None,
                 fast_socket: Optional['outputs.ClusterNodePoolNodeConfigFastSocket'] = None,
                 gcfs_config: Optional['outputs.ClusterNodePoolNodeConfigGcfsConfig'] = None,
                 guest_accelerators: Optional[Sequence['outputs.ClusterNodePoolNodeConfigGuestAccelerator']] = None,
                 gvnic: Optional['outputs.ClusterNodePoolNodeConfigGvnic'] = None,
                 host_maintenance_policy: Optional['outputs.ClusterNodePoolNodeConfigHostMaintenancePolicy'] = None,
                 image_type: Optional[str] = None,
                 kubelet_config: Optional['outputs.ClusterNodePoolNodeConfigKubeletConfig'] = None,
                 labels: Optional[Mapping[str, str]] = None,
                 linux_node_config: Optional['outputs.ClusterNodePoolNodeConfigLinuxNodeConfig'] = None,
                 local_nvme_ssd_block_config: Optional['outputs.ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig'] = None,
                 local_ssd_count: Optional[int] = None,
                 logging_variant: Optional[str] = None,
                 machine_type: Optional[str] = None,
                 metadata: Optional[Mapping[str, str]] = None,
                 min_cpu_platform: Optional[str] = None,
                 node_group: Optional[str] = None,
                 oauth_scopes: Optional[Sequence[str]] = None,
                 preemptible: Optional[bool] = None,
                 reservation_affinity: Optional['outputs.ClusterNodePoolNodeConfigReservationAffinity'] = None,
                 resource_labels: Optional[Mapping[str, str]] = None,
                 sandbox_config: Optional['outputs.ClusterNodePoolNodeConfigSandboxConfig'] = None,
                 service_account: Optional[str] = None,
                 shielded_instance_config: Optional['outputs.ClusterNodePoolNodeConfigShieldedInstanceConfig'] = None,
                 sole_tenant_config: Optional['outputs.ClusterNodePoolNodeConfigSoleTenantConfig'] = None,
                 spot: Optional[bool] = None,
                 tags: Optional[Sequence[str]] = None,
                 taints: Optional[Sequence['outputs.ClusterNodePoolNodeConfigTaint']] = None,
                 workload_metadata_config: Optional['outputs.ClusterNodePoolNodeConfigWorkloadMetadataConfig'] = None):
        """
        :param 'ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs' advanced_machine_features: Specifies options for controlling
               advanced machine features. Structure is documented below.
        :param str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        :param 'ClusterNodePoolNodeConfigConfidentialNodesArgs' confidential_nodes: Configuration for [Confidential Nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/confidential-gke-nodes) feature. Structure is documented below documented below.
        :param int disk_size_gb: Size of the disk attached to each node, specified
               in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        :param str disk_type: Type of the disk attached to each node
               (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        :param 'ClusterNodePoolNodeConfigEphemeralStorageConfigArgs' ephemeral_storage_config: ) Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param 'ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs' ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param 'ClusterNodePoolNodeConfigFastSocketArgs' fast_socket: Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
               Node Pool must enable gvnic.
               GKE version 1.25.2-gke.1700 or later.
               Structure is documented below.
        :param 'ClusterNodePoolNodeConfigGcfsConfigArgs' gcfs_config: Parameters for the Google Container Filesystem (GCFS).
               If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
               For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
               A `machine_type` that has more than 16 GiB of memory is also recommended.
               GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
               Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param Sequence['ClusterNodePoolNodeConfigGuestAcceleratorArgs'] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
               Structure documented below.
        :param 'ClusterNodePoolNodeConfigGvnicArgs' gvnic: Google Virtual NIC (gVNIC) is a virtual network interface.
               Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
               gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
               GKE node version 1.15.11-gke.15 or later
               Structure is documented below.
               
               
               ```python
               import pulumi
               ```
        :param str image_type: The image type to use for this node. Note that changing the image type
               will delete and recreate all nodes in the node pool.
        :param 'ClusterNodePoolNodeConfigKubeletConfigArgs' kubelet_config: Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param Mapping[str, str] labels: The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
               reserved by Kubernetes Core components and cannot be specified.
        :param 'ClusterNodePoolNodeConfigLinuxNodeConfigArgs' linux_node_config: Linux node configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Note that validations happen all server side. All attributes are optional.
               Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param 'ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs' local_nvme_ssd_block_config: Parameters for the local NVMe SSDs. Structure is documented below.
        :param int local_ssd_count: The amount of local SSD disks that will be
               attached to each cluster node. Defaults to 0.
        :param str logging_variant: Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        :param str machine_type: The name of a Google Compute Engine machine type.
               Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
               [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        :param Mapping[str, str] metadata: The metadata key/value pairs assigned to instances in
               the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
               `true` by the API; if `metadata` is set but that default value is not
               included, the provider will attempt to unset the value. To avoid this, set the
               value in your config.
        :param str min_cpu_platform: Minimum CPU platform to be used by this instance.
               The instance may be scheduled on the specified or newer CPU platform. Applicable
               values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
               [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
               for more information.
        :param str node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        :param Sequence[str] oauth_scopes: The set of Google API scopes to be made available
               on all of the node VMs under the "default" service account.
               Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        :param bool preemptible: A boolean that represents whether or not the underlying node VMs
               are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
               for more information. Defaults to false.
        :param 'ClusterNodePoolNodeConfigReservationAffinityArgs' reservation_affinity: The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        :param Mapping[str, str] resource_labels: The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
               for how these labels are applied to clusters, node pools and nodes.
        :param str service_account: The service account to be used by the Node VMs.
               If not specified, the "default" service account is used.
        :param 'ClusterNodePoolNodeConfigShieldedInstanceConfigArgs' shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigSoleTenantConfigArgs' sole_tenant_config: Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
               
               ```python
               import pulumi
               ```
        :param bool spot: A boolean that represents whether the underlying node VMs are spot.
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
               for more information. Defaults to false.
        :param Sequence[str] tags: The list of instance tags applied to all nodes. Tags are used to identify
               valid sources or targets for network firewalls.
        :param Sequence['ClusterNodePoolNodeConfigTaintArgs'] taints: A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
               to apply to nodes. GKE's API can only set this field on cluster creation.
               However, GKE will add taints to your nodes if you enable certain features such
               as GPUs. If this field is set, any diffs on this field will cause the provider to
               recreate the underlying resource. Taint values can be updated safely in
               Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
               this field to manage taints. If you do, `lifecycle.ignore_changes` is
               recommended. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs' workload_metadata_config: Metadata configuration to expose to workloads on the node pool.
               Structure is documented below.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional['outputs.ClusterNodePoolNodeConfigAdvancedMachineFeatures']:
        """
        Specifies options for controlling
        advanced machine features. Structure is documented below.
        """
        return pulumi.get(self, "advanced_machine_features")

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[str]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional['outputs.ClusterNodePoolNodeConfigConfidentialNodes']:
        """
        Configuration for [Confidential Nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/confidential-gke-nodes) feature. Structure is documented below documented below.
        """
        return pulumi.get(self, "confidential_nodes")

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[int]:
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[str]:
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        """
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigEphemeralStorageConfig']:
        """
        ) Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional['outputs.ClusterNodePoolNodeConfigFastSocket']:
        """
        Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
        Node Pool must enable gvnic.
        GKE version 1.25.2-gke.1700 or later.
        Structure is documented below.
        """
        return pulumi.get(self, "fast_socket")

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigGcfsConfig']:
        """
        Parameters for the Google Container Filesystem (GCFS).
        If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
        For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
        A `machine_type` that has more than 16 GiB of memory is also recommended.
        GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
        Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "gcfs_config")

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[Sequence['outputs.ClusterNodePoolNodeConfigGuestAccelerator']]:
        """
        List of the type and count of accelerator cards attached to the instance.
        Structure documented below.
        """
        return pulumi.get(self, "guest_accelerators")

    @property
    @pulumi.getter
    def gvnic(self) -> Optional['outputs.ClusterNodePoolNodeConfigGvnic']:
        """
        Google Virtual NIC (gVNIC) is a virtual network interface.
        Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
        gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
        GKE node version 1.15.11-gke.15 or later
        Structure is documented below.


        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "gvnic")

    @property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional['outputs.ClusterNodePoolNodeConfigHostMaintenancePolicy']:
        return pulumi.get(self, "host_maintenance_policy")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[str]:
        """
        The image type to use for this node. Note that changing the image type
        will delete and recreate all nodes in the node pool.
        """
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigKubeletConfig']:
        """
        Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "kubelet_config")

    @property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, str]]:
        """
        The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
        reserved by Kubernetes Core components and cannot be specified.
        """
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigLinuxNodeConfig']:
        """
        Linux node configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Note that validations happen all server side. All attributes are optional.
        Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "linux_node_config")

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig']:
        """
        Parameters for the local NVMe SSDs. Structure is documented below.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        """
        The amount of local SSD disks that will be
        attached to each cluster node. Defaults to 0.
        """
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[str]:
        """
        Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[str]:
        """
        The name of a Google Compute Engine machine type.
        Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
        [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        """
        return pulumi.get(self, "machine_type")

    @property
    @pulumi.getter
    def metadata(self) -> Optional[Mapping[str, str]]:
        """
        The metadata key/value pairs assigned to instances in
        the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
        `true` by the API; if `metadata` is set but that default value is not
        included, the provider will attempt to unset the value. To avoid this, set the
        value in your config.
        """
        return pulumi.get(self, "metadata")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[str]:
        """
        Minimum CPU platform to be used by this instance.
        The instance may be scheduled on the specified or newer CPU platform. Applicable
        values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
        [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
        for more information.
        """
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[str]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        """
        return pulumi.get(self, "node_group")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[Sequence[str]]:
        """
        The set of Google API scopes to be made available
        on all of the node VMs under the "default" service account.
        Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        """
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter
    def preemptible(self) -> Optional[bool]:
        """
        A boolean that represents whether or not the underlying node VMs
        are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "preemptible")

    @property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional['outputs.ClusterNodePoolNodeConfigReservationAffinity']:
        """
        The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        """
        return pulumi.get(self, "reservation_affinity")

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[Mapping[str, str]]:
        """
        The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
        for how these labels are applied to clusters, node pools and nodes.
        """
        return pulumi.get(self, "resource_labels")

    @property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigSandboxConfig']:
        return pulumi.get(self, "sandbox_config")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[str]:
        """
        The service account to be used by the Node VMs.
        If not specified, the "default" service account is used.
        """
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigShieldedInstanceConfig']:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigSoleTenantConfig']:
        """
        Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "sole_tenant_config")

    @property
    @pulumi.getter
    def spot(self) -> Optional[bool]:
        """
        A boolean that represents whether the underlying node VMs are spot.
        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "spot")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Sequence[str]]:
        """
        The list of instance tags applied to all nodes. Tags are used to identify
        valid sources or targets for network firewalls.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def taints(self) -> Optional[Sequence['outputs.ClusterNodePoolNodeConfigTaint']]:
        """
        A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
        to apply to nodes. GKE's API can only set this field on cluster creation.
        However, GKE will add taints to your nodes if you enable certain features such
        as GPUs. If this field is set, any diffs on this field will cause the provider to
        recreate the underlying resource. Taint values can be updated safely in
        Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
        this field to manage taints. If you do, `lifecycle.ignore_changes` is
        recommended. Structure is documented below.
        """
        return pulumi.get(self, "taints")

    @property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigWorkloadMetadataConfig']:
        """
        Metadata configuration to expose to workloads on the node pool.
        Structure is documented below.
        """
        return pulumi.get(self, "workload_metadata_config")


@pulumi.output_type
class ClusterNodePoolNodeConfigAdvancedMachineFeatures(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "threadsPerCore":
            suggest = "threads_per_core"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigAdvancedMachineFeatures. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 threads_per_core: int):
        """
        :param int threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> int:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")


@pulumi.output_type
class ClusterNodePoolNodeConfigConfidentialNodes(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigEphemeralStorageConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigEphemeralStorageConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodePoolNodeConfigFastSocket(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigGcfsConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigGuestAccelerator(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverInstallationConfig":
            suggest = "gpu_driver_installation_config"
        elif key == "gpuPartitionSize":
            suggest = "gpu_partition_size"
        elif key == "gpuSharingConfig":
            suggest = "gpu_sharing_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigGuestAccelerator. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigGuestAccelerator.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigGuestAccelerator.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 count: int,
                 type: str,
                 gpu_driver_installation_config: Optional['outputs.ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig'] = None,
                 gpu_partition_size: Optional[str] = None,
                 gpu_sharing_config: Optional['outputs.ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig'] = None):
        """
        :param int count: The number of the guest accelerator cards exposed to this instance.
        :param str type: The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        :param 'ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs' gpu_driver_installation_config: Configuration for auto installation of GPU driver. Structure is documented below.
        :param str gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        :param 'ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs' gpu_sharing_config: Configuration for GPU sharing. Structure is documented below.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @property
    @pulumi.getter
    def count(self) -> int:
        """
        The number of the guest accelerator cards exposed to this instance.
        """
        return pulumi.get(self, "count")

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        """
        return pulumi.get(self, "type")

    @property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig']:
        """
        Configuration for auto installation of GPU driver. Structure is documented below.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[str]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        """
        return pulumi.get(self, "gpu_partition_size")

    @property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig']:
        """
        Configuration for GPU sharing. Structure is documented below.
        """
        return pulumi.get(self, "gpu_sharing_config")


@pulumi.output_type
class ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverVersion":
            suggest = "gpu_driver_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_driver_version: str):
        """
        :param str gpu_driver_version: Mode for how the GPU driver is installed.
               Accepted values are:
               * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to not install any GPU driver.
               * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
               * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
               * `"LATEST"`: "Latest" GPU driver in COS.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> str:
        """
        Mode for how the GPU driver is installed.
        Accepted values are:
        * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to not install any GPU driver.
        * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
        * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
        * `"LATEST"`: "Latest" GPU driver in COS.
        """
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuSharingStrategy":
            suggest = "gpu_sharing_strategy"
        elif key == "maxSharedClientsPerGpu":
            suggest = "max_shared_clients_per_gpu"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_sharing_strategy: str,
                 max_shared_clients_per_gpu: int):
        """
        :param str gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node.
               Accepted values are:
               * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        :param int max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> str:
        """
        The type of GPU sharing strategy to enable on the GPU node.
        Accepted values are:
        * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> int:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class ClusterNodePoolNodeConfigGvnic(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigHostMaintenancePolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maintenanceInterval":
            suggest = "maintenance_interval"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigHostMaintenancePolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 maintenance_interval: str):
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> str:
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class ClusterNodePoolNodeConfigKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cpuManagerPolicy":
            suggest = "cpu_manager_policy"
        elif key == "cpuCfsQuota":
            suggest = "cpu_cfs_quota"
        elif key == "cpuCfsQuotaPeriod":
            suggest = "cpu_cfs_quota_period"
        elif key == "podPidsLimit":
            suggest = "pod_pids_limit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cpu_manager_policy: str,
                 cpu_cfs_quota: Optional[bool] = None,
                 cpu_cfs_quota_period: Optional[str] = None,
                 pod_pids_limit: Optional[int] = None):
        """
        :param str cpu_manager_policy: The CPU management policy on the node. See
               [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
               One of `"none"` or `"static"`. Defaults to `none` when `kubelet_config` is unset.
        :param bool cpu_cfs_quota: If true, enables CPU CFS quota enforcement for
               containers that specify CPU limits.
        :param str cpu_cfs_quota_period: The CPU CFS quota period value. Specified
               as a sequence of decimal numbers, each with optional fraction and a unit suffix,
               such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
               "h". The value must be a positive duration.
               
               > Note: At the time of writing (2020/08/18) the GKE API rejects the `none`
               value and accepts an invalid `default` value instead. While this remains true,
               not specifying the `kubelet_config` block should be the equivalent of specifying
               `none`.
        :param int pod_pids_limit: Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> str:
        """
        The CPU management policy on the node. See
        [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
        One of `"none"` or `"static"`. Defaults to `none` when `kubelet_config` is unset.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[bool]:
        """
        If true, enables CPU CFS quota enforcement for
        containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[str]:
        """
        The CPU CFS quota period value. Specified
        as a sequence of decimal numbers, each with optional fraction and a unit suffix,
        such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
        "h". The value must be a positive duration.

        > Note: At the time of writing (2020/08/18) the GKE API rejects the `none`
        value and accepts an invalid `default` value instead. While this remains true,
        not specifying the `kubelet_config` block should be the equivalent of specifying
        `none`.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[int]:
        """
        Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        return pulumi.get(self, "pod_pids_limit")


@pulumi.output_type
class ClusterNodePoolNodeConfigLinuxNodeConfig(dict):
    def __init__(__self__, *,
                 sysctls: Mapping[str, str]):
        """
        :param Mapping[str, str] sysctls: The Linux kernel parameters to be applied to the nodes
               and all pods running on the nodes. Specified as a map from the key, such as
               `net.core.wmem_max`, to a string value.
        """
        pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter
    def sysctls(self) -> Mapping[str, str]:
        """
        The Linux kernel parameters to be applied to the nodes
        and all pods running on the nodes. Specified as a map from the key, such as
        `net.core.wmem_max`, to a string value.
        """
        return pulumi.get(self, "sysctls")


@pulumi.output_type
class ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        """
        :param int local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
               > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
        > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodePoolNodeConfigReservationAffinity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "consumeReservationType":
            suggest = "consume_reservation_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigReservationAffinity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigReservationAffinity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigReservationAffinity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 consume_reservation_type: str,
                 key: Optional[str] = None,
                 values: Optional[Sequence[str]] = None):
        """
        :param str consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param str key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param Sequence[str] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> str:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def values(self) -> Optional[Sequence[str]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ClusterNodePoolNodeConfigSandboxConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sandboxType":
            suggest = "sandbox_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigSandboxConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigSandboxConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigSandboxConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 sandbox_type: str):
        """
        :param str sandbox_type: Which sandbox to use for pods in the node pool.
               Accepted values are:
               
               * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> str:
        """
        Which sandbox to use for pods in the node pool.
        Accepted values are:

        * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class ClusterNodePoolNodeConfigShieldedInstanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableIntegrityMonitoring":
            suggest = "enable_integrity_monitoring"
        elif key == "enableSecureBoot":
            suggest = "enable_secure_boot"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigShieldedInstanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[bool] = None,
                 enable_secure_boot: Optional[bool] = None):
        """
        :param bool enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param bool enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[bool]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[bool]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class ClusterNodePoolNodeConfigSoleTenantConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodeAffinities":
            suggest = "node_affinities"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigSoleTenantConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigSoleTenantConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigSoleTenantConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinity']):
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinity']:
        return pulumi.get(self, "node_affinities")


@pulumi.output_type
class ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinity(dict):
    def __init__(__self__, *,
                 key: str,
                 operator: str,
                 values: Sequence[str]):
        """
        :param str key: The default or custom node affinity label key name.
        :param str operator: Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        :param Sequence[str] values: List of node affinity label values as strings.
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        The default or custom node affinity label key name.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def operator(self) -> str:
        """
        Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        """
        return pulumi.get(self, "operator")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        """
        List of node affinity label values as strings.
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ClusterNodePoolNodeConfigTaint(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        """
        :param str effect: Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        :param str key: Key for taint.
        :param str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        """
        Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        """
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class ClusterNodePoolNodeConfigWorkloadMetadataConfig(dict):
    def __init__(__self__, *,
                 mode: str):
        """
        :param str mode: How to expose the node metadata to the workload running on the node.
               Accepted values are:
               * UNSPECIFIED: Not Set
               * GCE_METADATA: Expose all Compute Engine metadata to pods.
               * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> str:
        """
        How to expose the node metadata to the workload running on the node.
        Accepted values are:
        * UNSPECIFIED: Not Set
        * GCE_METADATA: Expose all Compute Engine metadata to pods.
        * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class ClusterNodePoolPlacementPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "policyName":
            suggest = "policy_name"
        elif key == "tpuTopology":
            suggest = "tpu_topology"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolPlacementPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolPlacementPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolPlacementPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 type: str,
                 policy_name: Optional[str] = None,
                 tpu_topology: Optional[str] = None):
        """
        :param str type: Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
               `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        pulumi.set(__self__, "type", type)
        if policy_name is not None:
            pulumi.set(__self__, "policy_name", policy_name)
        if tpu_topology is not None:
            pulumi.set(__self__, "tpu_topology", tpu_topology)

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
        `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        return pulumi.get(self, "type")

    @property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> Optional[str]:
        return pulumi.get(self, "policy_name")

    @property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> Optional[str]:
        return pulumi.get(self, "tpu_topology")


@pulumi.output_type
class ClusterNodePoolUpgradeSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "blueGreenSettings":
            suggest = "blue_green_settings"
        elif key == "maxSurge":
            suggest = "max_surge"
        elif key == "maxUnavailable":
            suggest = "max_unavailable"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolUpgradeSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolUpgradeSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolUpgradeSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 blue_green_settings: Optional['outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettings'] = None,
                 max_surge: Optional[int] = None,
                 max_unavailable: Optional[int] = None,
                 strategy: Optional[str] = None):
        """
        :param 'ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs' blue_green_settings: Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param int max_surge: The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param int max_unavailable: The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param str strategy: Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional['outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettings']:
        """
        Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "blue_green_settings")

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[int]:
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_surge")

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[int]:
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_unavailable")

    @property
    @pulumi.getter
    def strategy(self) -> Optional[str]:
        """
        Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class ClusterNodePoolUpgradeSettingsBlueGreenSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "standardRolloutPolicy":
            suggest = "standard_rollout_policy"
        elif key == "nodePoolSoakDuration":
            suggest = "node_pool_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolUpgradeSettingsBlueGreenSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 standard_rollout_policy: 'outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
                 node_pool_soak_duration: Optional[str] = None):
        """
        :param 'ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs' standard_rollout_policy: Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param str node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)

    @property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> 'outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy':
        """
        Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "standard_rollout_policy")

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[str]:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "node_pool_soak_duration")


@pulumi.output_type
class ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "batchNodeCount":
            suggest = "batch_node_count"
        elif key == "batchPercentage":
            suggest = "batch_percentage"
        elif key == "batchSoakDuration":
            suggest = "batch_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 batch_node_count: Optional[int] = None,
                 batch_percentage: Optional[float] = None,
                 batch_soak_duration: Optional[str] = None):
        """
        :param int batch_node_count: Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        :param float batch_percentage: Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        :param str batch_soak_duration: Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[int]:
        """
        Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_node_count")

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[float]:
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_percentage")

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[str]:
        """
        Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class ClusterNotificationConfig(dict):
    def __init__(__self__, *,
                 pubsub: 'outputs.ClusterNotificationConfigPubsub'):
        """
        :param 'ClusterNotificationConfigPubsubArgs' pubsub: The pubsub config for the cluster's upgrade notifications.
        """
        pulumi.set(__self__, "pubsub", pubsub)

    @property
    @pulumi.getter
    def pubsub(self) -> 'outputs.ClusterNotificationConfigPubsub':
        """
        The pubsub config for the cluster's upgrade notifications.
        """
        return pulumi.get(self, "pubsub")


@pulumi.output_type
class ClusterNotificationConfigPubsub(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 filter: Optional['outputs.ClusterNotificationConfigPubsubFilter'] = None,
                 topic: Optional[str] = None):
        """
        :param bool enabled: Whether or not the notification config is enabled
        :param 'ClusterNotificationConfigPubsubFilterArgs' filter: Choose what type of notifications you want to receive. If no filters are applied, you'll receive all notification types. Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param str topic: The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: `projects/{project}/topics/{topic}`.
        """
        pulumi.set(__self__, "enabled", enabled)
        if filter is not None:
            pulumi.set(__self__, "filter", filter)
        if topic is not None:
            pulumi.set(__self__, "topic", topic)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether or not the notification config is enabled
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter
    def filter(self) -> Optional['outputs.ClusterNotificationConfigPubsubFilter']:
        """
        Choose what type of notifications you want to receive. If no filters are applied, you'll receive all notification types. Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "filter")

    @property
    @pulumi.getter
    def topic(self) -> Optional[str]:
        """
        The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: `projects/{project}/topics/{topic}`.
        """
        return pulumi.get(self, "topic")


@pulumi.output_type
class ClusterNotificationConfigPubsubFilter(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "eventTypes":
            suggest = "event_types"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNotificationConfigPubsubFilter. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNotificationConfigPubsubFilter.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNotificationConfigPubsubFilter.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 event_types: Sequence[str]):
        """
        :param Sequence[str] event_types: Can be used to filter what notifications are sent. Accepted values are `UPGRADE_AVAILABLE_EVENT`, `UPGRADE_EVENT` and `SECURITY_BULLETIN_EVENT`. See [Filtering notifications](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-notifications#filtering) for more details.
        """
        pulumi.set(__self__, "event_types", event_types)

    @property
    @pulumi.getter(name="eventTypes")
    def event_types(self) -> Sequence[str]:
        """
        Can be used to filter what notifications are sent. Accepted values are `UPGRADE_AVAILABLE_EVENT`, `UPGRADE_EVENT` and `SECURITY_BULLETIN_EVENT`. See [Filtering notifications](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-notifications#filtering) for more details.
        """
        return pulumi.get(self, "event_types")


@pulumi.output_type
class ClusterPodSecurityPolicyConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable the PodSecurityPolicy controller for this cluster.
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable the PodSecurityPolicy controller for this cluster.
        If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterPrivateClusterConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enablePrivateEndpoint":
            suggest = "enable_private_endpoint"
        elif key == "enablePrivateNodes":
            suggest = "enable_private_nodes"
        elif key == "masterGlobalAccessConfig":
            suggest = "master_global_access_config"
        elif key == "masterIpv4CidrBlock":
            suggest = "master_ipv4_cidr_block"
        elif key == "peeringName":
            suggest = "peering_name"
        elif key == "privateEndpoint":
            suggest = "private_endpoint"
        elif key == "privateEndpointSubnetwork":
            suggest = "private_endpoint_subnetwork"
        elif key == "publicEndpoint":
            suggest = "public_endpoint"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterPrivateClusterConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterPrivateClusterConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterPrivateClusterConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_private_endpoint: Optional[bool] = None,
                 enable_private_nodes: Optional[bool] = None,
                 master_global_access_config: Optional['outputs.ClusterPrivateClusterConfigMasterGlobalAccessConfig'] = None,
                 master_ipv4_cidr_block: Optional[str] = None,
                 peering_name: Optional[str] = None,
                 private_endpoint: Optional[str] = None,
                 private_endpoint_subnetwork: Optional[str] = None,
                 public_endpoint: Optional[str] = None):
        """
        :param bool enable_private_endpoint: When `true`, the cluster's private
               endpoint is used as the cluster endpoint and access through the public endpoint
               is disabled. When `false`, either endpoint can be used. This field only applies
               to private clusters, when `enable_private_nodes` is `true`.
        :param bool enable_private_nodes: Enables the private cluster feature,
               creating a private endpoint on the cluster. In a private cluster, nodes only
               have RFC 1918 private addresses and communicate with the master's private
               endpoint via private networking.
        :param 'ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs' master_global_access_config: Controls cluster master global
               access settings. If unset, the provider will no longer manage this field and will
               not modify the previously-set value. Structure is documented below.
        :param str master_ipv4_cidr_block: The IP range in CIDR notation to use for
               the hosted master network. This range will be used for assigning private IP
               addresses to the cluster master(s) and the ILB VIP. This range must not overlap
               with any other ranges in use within the cluster's network, and it must be a /28
               subnet. See [Private Cluster Limitations](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#req_res_lim)
               for more details. This field only applies to private clusters, when
               `enable_private_nodes` is `true`.
        :param str peering_name: The name of the peering between this cluster and the Google owned VPC.
        :param str private_endpoint: The internal IP address of this cluster's master endpoint.
        :param str private_endpoint_subnetwork: Subnetwork in cluster's network where master's endpoint will be provisioned.
        :param str public_endpoint: The external IP address of this cluster's master endpoint.
               
               !> The Google provider is unable to validate certain configurations of
               `private_cluster_config` when `enable_private_nodes` is `false`. It's
               recommended that you omit the block entirely if the field is not set to `true`.
        """
        if enable_private_endpoint is not None:
            pulumi.set(__self__, "enable_private_endpoint", enable_private_endpoint)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if master_global_access_config is not None:
            pulumi.set(__self__, "master_global_access_config", master_global_access_config)
        if master_ipv4_cidr_block is not None:
            pulumi.set(__self__, "master_ipv4_cidr_block", master_ipv4_cidr_block)
        if peering_name is not None:
            pulumi.set(__self__, "peering_name", peering_name)
        if private_endpoint is not None:
            pulumi.set(__self__, "private_endpoint", private_endpoint)
        if private_endpoint_subnetwork is not None:
            pulumi.set(__self__, "private_endpoint_subnetwork", private_endpoint_subnetwork)
        if public_endpoint is not None:
            pulumi.set(__self__, "public_endpoint", public_endpoint)

    @property
    @pulumi.getter(name="enablePrivateEndpoint")
    def enable_private_endpoint(self) -> Optional[bool]:
        """
        When `true`, the cluster's private
        endpoint is used as the cluster endpoint and access through the public endpoint
        is disabled. When `false`, either endpoint can be used. This field only applies
        to private clusters, when `enable_private_nodes` is `true`.
        """
        return pulumi.get(self, "enable_private_endpoint")

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[bool]:
        """
        Enables the private cluster feature,
        creating a private endpoint on the cluster. In a private cluster, nodes only
        have RFC 1918 private addresses and communicate with the master's private
        endpoint via private networking.
        """
        return pulumi.get(self, "enable_private_nodes")

    @property
    @pulumi.getter(name="masterGlobalAccessConfig")
    def master_global_access_config(self) -> Optional['outputs.ClusterPrivateClusterConfigMasterGlobalAccessConfig']:
        """
        Controls cluster master global
        access settings. If unset, the provider will no longer manage this field and will
        not modify the previously-set value. Structure is documented below.
        """
        return pulumi.get(self, "master_global_access_config")

    @property
    @pulumi.getter(name="masterIpv4CidrBlock")
    def master_ipv4_cidr_block(self) -> Optional[str]:
        """
        The IP range in CIDR notation to use for
        the hosted master network. This range will be used for assigning private IP
        addresses to the cluster master(s) and the ILB VIP. This range must not overlap
        with any other ranges in use within the cluster's network, and it must be a /28
        subnet. See [Private Cluster Limitations](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#req_res_lim)
        for more details. This field only applies to private clusters, when
        `enable_private_nodes` is `true`.
        """
        return pulumi.get(self, "master_ipv4_cidr_block")

    @property
    @pulumi.getter(name="peeringName")
    def peering_name(self) -> Optional[str]:
        """
        The name of the peering between this cluster and the Google owned VPC.
        """
        return pulumi.get(self, "peering_name")

    @property
    @pulumi.getter(name="privateEndpoint")
    def private_endpoint(self) -> Optional[str]:
        """
        The internal IP address of this cluster's master endpoint.
        """
        return pulumi.get(self, "private_endpoint")

    @property
    @pulumi.getter(name="privateEndpointSubnetwork")
    def private_endpoint_subnetwork(self) -> Optional[str]:
        """
        Subnetwork in cluster's network where master's endpoint will be provisioned.
        """
        return pulumi.get(self, "private_endpoint_subnetwork")

    @property
    @pulumi.getter(name="publicEndpoint")
    def public_endpoint(self) -> Optional[str]:
        """
        The external IP address of this cluster's master endpoint.

        !> The Google provider is unable to validate certain configurations of
        `private_cluster_config` when `enable_private_nodes` is `false`. It's
        recommended that you omit the block entirely if the field is not set to `true`.
        """
        return pulumi.get(self, "public_endpoint")


@pulumi.output_type
class ClusterPrivateClusterConfigMasterGlobalAccessConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Whether the cluster master is accessible globally or
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Whether the cluster master is accessible globally or
        not.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterProtectConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "workloadConfig":
            suggest = "workload_config"
        elif key == "workloadVulnerabilityMode":
            suggest = "workload_vulnerability_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterProtectConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterProtectConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterProtectConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 workload_config: Optional['outputs.ClusterProtectConfigWorkloadConfig'] = None,
                 workload_vulnerability_mode: Optional[str] = None):
        """
        :param 'ClusterProtectConfigWorkloadConfigArgs' workload_config: ) WorkloadConfig defines which actions are enabled for a cluster's workload configurations. Structure is documented below
        :param str workload_vulnerability_mode: ) Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        if workload_config is not None:
            pulumi.set(__self__, "workload_config", workload_config)
        if workload_vulnerability_mode is not None:
            pulumi.set(__self__, "workload_vulnerability_mode", workload_vulnerability_mode)

    @property
    @pulumi.getter(name="workloadConfig")
    def workload_config(self) -> Optional['outputs.ClusterProtectConfigWorkloadConfig']:
        """
        ) WorkloadConfig defines which actions are enabled for a cluster's workload configurations. Structure is documented below
        """
        return pulumi.get(self, "workload_config")

    @property
    @pulumi.getter(name="workloadVulnerabilityMode")
    def workload_vulnerability_mode(self) -> Optional[str]:
        """
        ) Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "workload_vulnerability_mode")


@pulumi.output_type
class ClusterProtectConfigWorkloadConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "auditMode":
            suggest = "audit_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterProtectConfigWorkloadConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterProtectConfigWorkloadConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterProtectConfigWorkloadConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 audit_mode: str):
        """
        :param str audit_mode: ) Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        pulumi.set(__self__, "audit_mode", audit_mode)

    @property
    @pulumi.getter(name="auditMode")
    def audit_mode(self) -> str:
        """
        ) Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "audit_mode")


@pulumi.output_type
class ClusterReleaseChannel(dict):
    def __init__(__self__, *,
                 channel: str):
        """
        :param str channel: The selected release channel.
               Accepted values are:
               * UNSPECIFIED: Not set.
               * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
               * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
               * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
        """
        pulumi.set(__self__, "channel", channel)

    @property
    @pulumi.getter
    def channel(self) -> str:
        """
        The selected release channel.
        Accepted values are:
        * UNSPECIFIED: Not set.
        * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
        * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
        * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
        """
        return pulumi.get(self, "channel")


@pulumi.output_type
class ClusterResourceUsageExportConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bigqueryDestination":
            suggest = "bigquery_destination"
        elif key == "enableNetworkEgressMetering":
            suggest = "enable_network_egress_metering"
        elif key == "enableResourceConsumptionMetering":
            suggest = "enable_resource_consumption_metering"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterResourceUsageExportConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterResourceUsageExportConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterResourceUsageExportConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 bigquery_destination: 'outputs.ClusterResourceUsageExportConfigBigqueryDestination',
                 enable_network_egress_metering: Optional[bool] = None,
                 enable_resource_consumption_metering: Optional[bool] = None):
        """
        :param 'ClusterResourceUsageExportConfigBigqueryDestinationArgs' bigquery_destination: Parameters for using BigQuery as the destination of resource usage export.
               
               * `bigquery_destination.dataset_id` (Required) - The ID of a BigQuery Dataset. For Example:
               
               ```python
               import pulumi
               ```
        :param bool enable_network_egress_metering: Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created
               in the cluster to meter network egress traffic.
        :param bool enable_resource_consumption_metering: Whether to enable resource
               consumption metering on this cluster. When enabled, a table will be created in
               the resource export BigQuery dataset to store resource consumption data. The
               resulting table can be joined with the resource usage table or with BigQuery
               billing export. Defaults to `true`.
        """
        pulumi.set(__self__, "bigquery_destination", bigquery_destination)
        if enable_network_egress_metering is not None:
            pulumi.set(__self__, "enable_network_egress_metering", enable_network_egress_metering)
        if enable_resource_consumption_metering is not None:
            pulumi.set(__self__, "enable_resource_consumption_metering", enable_resource_consumption_metering)

    @property
    @pulumi.getter(name="bigqueryDestination")
    def bigquery_destination(self) -> 'outputs.ClusterResourceUsageExportConfigBigqueryDestination':
        """
        Parameters for using BigQuery as the destination of resource usage export.

        * `bigquery_destination.dataset_id` (Required) - The ID of a BigQuery Dataset. For Example:

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "bigquery_destination")

    @property
    @pulumi.getter(name="enableNetworkEgressMetering")
    def enable_network_egress_metering(self) -> Optional[bool]:
        """
        Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created
        in the cluster to meter network egress traffic.
        """
        return pulumi.get(self, "enable_network_egress_metering")

    @property
    @pulumi.getter(name="enableResourceConsumptionMetering")
    def enable_resource_consumption_metering(self) -> Optional[bool]:
        """
        Whether to enable resource
        consumption metering on this cluster. When enabled, a table will be created in
        the resource export BigQuery dataset to store resource consumption data. The
        resulting table can be joined with the resource usage table or with BigQuery
        billing export. Defaults to `true`.
        """
        return pulumi.get(self, "enable_resource_consumption_metering")


@pulumi.output_type
class ClusterResourceUsageExportConfigBigqueryDestination(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "datasetId":
            suggest = "dataset_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterResourceUsageExportConfigBigqueryDestination. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterResourceUsageExportConfigBigqueryDestination.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterResourceUsageExportConfigBigqueryDestination.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dataset_id: str):
        pulumi.set(__self__, "dataset_id", dataset_id)

    @property
    @pulumi.getter(name="datasetId")
    def dataset_id(self) -> str:
        return pulumi.get(self, "dataset_id")


@pulumi.output_type
class ClusterSecurityPostureConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "vulnerabilityMode":
            suggest = "vulnerability_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterSecurityPostureConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterSecurityPostureConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterSecurityPostureConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 mode: Optional[str] = None,
                 vulnerability_mode: Optional[str] = None):
        """
        :param str mode: Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include `DISABLED` and `BASIC`.
        :param str vulnerability_mode: Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include `VULNERABILITY_DISABLED` and `VULNERABILITY_BASIC`.
        """
        if mode is not None:
            pulumi.set(__self__, "mode", mode)
        if vulnerability_mode is not None:
            pulumi.set(__self__, "vulnerability_mode", vulnerability_mode)

    @property
    @pulumi.getter
    def mode(self) -> Optional[str]:
        """
        Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include `DISABLED` and `BASIC`.
        """
        return pulumi.get(self, "mode")

    @property
    @pulumi.getter(name="vulnerabilityMode")
    def vulnerability_mode(self) -> Optional[str]:
        """
        Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include `VULNERABILITY_DISABLED` and `VULNERABILITY_BASIC`.
        """
        return pulumi.get(self, "vulnerability_mode")


@pulumi.output_type
class ClusterServiceExternalIpsConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Controls whether external ips specified by a service will be allowed. It is enabled by default.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Controls whether external ips specified by a service will be allowed. It is enabled by default.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterTpuConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ipv4CidrBlock":
            suggest = "ipv4_cidr_block"
        elif key == "useServiceNetworking":
            suggest = "use_service_networking"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterTpuConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterTpuConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterTpuConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: bool,
                 ipv4_cidr_block: Optional[str] = None,
                 use_service_networking: Optional[bool] = None):
        """
        :param bool enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)
        if ipv4_cidr_block is not None:
            pulumi.set(__self__, "ipv4_cidr_block", ipv4_cidr_block)
        if use_service_networking is not None:
            pulumi.set(__self__, "use_service_networking", use_service_networking)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="ipv4CidrBlock")
    def ipv4_cidr_block(self) -> Optional[str]:
        return pulumi.get(self, "ipv4_cidr_block")

    @property
    @pulumi.getter(name="useServiceNetworking")
    def use_service_networking(self) -> Optional[bool]:
        return pulumi.get(self, "use_service_networking")


@pulumi.output_type
class ClusterVerticalPodAutoscaling(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enables vertical pod autoscaling
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enables vertical pod autoscaling
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterWorkloadIdentityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "workloadPool":
            suggest = "workload_pool"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterWorkloadIdentityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterWorkloadIdentityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterWorkloadIdentityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 workload_pool: Optional[str] = None):
        """
        :param str workload_pool: The workload pool to attach all Kubernetes service accounts to.
               
               ```python
               import pulumi
               ```
        """
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[str]:
        """
        The workload pool to attach all Kubernetes service accounts to.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "workload_pool")


@pulumi.output_type
class NodePoolAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "locationPolicy":
            suggest = "location_policy"
        elif key == "maxNodeCount":
            suggest = "max_node_count"
        elif key == "minNodeCount":
            suggest = "min_node_count"
        elif key == "totalMaxNodeCount":
            suggest = "total_max_node_count"
        elif key == "totalMinNodeCount":
            suggest = "total_min_node_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 location_policy: Optional[str] = None,
                 max_node_count: Optional[int] = None,
                 min_node_count: Optional[int] = None,
                 total_max_node_count: Optional[int] = None,
                 total_min_node_count: Optional[int] = None):
        """
        :param str location_policy: Location policy specifies the algorithm used when
               scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
               * "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones.
               * "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations,
               and reduce preemption risk for Spot VMs.
        :param int max_node_count: Maximum number of nodes per zone in the NodePool.
               Must be >= min_node_count. Cannot be used with total limits.
        :param int min_node_count: Minimum number of nodes per zone in the NodePool.
               Must be >=0 and <= `max_node_count`. Cannot be used with total limits.
        :param int total_max_node_count: Total maximum number of nodes in the NodePool.
               Must be >= total_min_node_count. Cannot be used with per zone limits.
               Total size limits are supported only in 1.24.1+ clusters.
        :param int total_min_node_count: Total minimum number of nodes in the NodePool.
               Must be >=0 and <= `total_max_node_count`. Cannot be used with per zone limits.
               Total size limits are supported only in 1.24.1+ clusters.
        """
        if location_policy is not None:
            pulumi.set(__self__, "location_policy", location_policy)
        if max_node_count is not None:
            pulumi.set(__self__, "max_node_count", max_node_count)
        if min_node_count is not None:
            pulumi.set(__self__, "min_node_count", min_node_count)
        if total_max_node_count is not None:
            pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        if total_min_node_count is not None:
            pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> Optional[str]:
        """
        Location policy specifies the algorithm used when
        scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
        * "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones.
        * "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations,
        and reduce preemption risk for Spot VMs.
        """
        return pulumi.get(self, "location_policy")

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> Optional[int]:
        """
        Maximum number of nodes per zone in the NodePool.
        Must be >= min_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "max_node_count")

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> Optional[int]:
        """
        Minimum number of nodes per zone in the NodePool.
        Must be >=0 and <= `max_node_count`. Cannot be used with total limits.
        """
        return pulumi.get(self, "min_node_count")

    @property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> Optional[int]:
        """
        Total maximum number of nodes in the NodePool.
        Must be >= total_min_node_count. Cannot be used with per zone limits.
        Total size limits are supported only in 1.24.1+ clusters.
        """
        return pulumi.get(self, "total_max_node_count")

    @property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> Optional[int]:
        """
        Total minimum number of nodes in the NodePool.
        Must be >=0 and <= `total_max_node_count`. Cannot be used with per zone limits.
        Total size limits are supported only in 1.24.1+ clusters.
        """
        return pulumi.get(self, "total_min_node_count")


@pulumi.output_type
class NodePoolManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"
        elif key == "autoUpgrade":
            suggest = "auto_upgrade"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[bool] = None,
                 auto_upgrade: Optional[bool] = None):
        """
        :param bool auto_repair: Whether the nodes will be automatically repaired.
        :param bool auto_upgrade: Whether the nodes will be automatically upgraded.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[bool]:
        """
        Whether the nodes will be automatically repaired.
        """
        return pulumi.get(self, "auto_repair")

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[bool]:
        """
        Whether the nodes will be automatically upgraded.
        """
        return pulumi.get(self, "auto_upgrade")


@pulumi.output_type
class NodePoolNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "additionalNodeNetworkConfigs":
            suggest = "additional_node_network_configs"
        elif key == "additionalPodNetworkConfigs":
            suggest = "additional_pod_network_configs"
        elif key == "createPodRange":
            suggest = "create_pod_range"
        elif key == "enablePrivateNodes":
            suggest = "enable_private_nodes"
        elif key == "podCidrOverprovisionConfig":
            suggest = "pod_cidr_overprovision_config"
        elif key == "podIpv4CidrBlock":
            suggest = "pod_ipv4_cidr_block"
        elif key == "podRange":
            suggest = "pod_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 additional_node_network_configs: Optional[Sequence['outputs.NodePoolNetworkConfigAdditionalNodeNetworkConfig']] = None,
                 additional_pod_network_configs: Optional[Sequence['outputs.NodePoolNetworkConfigAdditionalPodNetworkConfig']] = None,
                 create_pod_range: Optional[bool] = None,
                 enable_private_nodes: Optional[bool] = None,
                 pod_cidr_overprovision_config: Optional['outputs.NodePoolNetworkConfigPodCidrOverprovisionConfig'] = None,
                 pod_ipv4_cidr_block: Optional[str] = None,
                 pod_range: Optional[str] = None):
        """
        :param Sequence['NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs'] additional_node_network_configs: We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface.
               Structure is documented below
        :param Sequence['NodePoolNetworkConfigAdditionalPodNetworkConfigArgs'] additional_pod_network_configs: We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node.
               Structure is documented below
        :param bool create_pod_range: Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        :param bool enable_private_nodes: Whether nodes have internal IP addresses only.
        :param str pod_ipv4_cidr_block: The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        :param str pod_range: The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        if additional_node_network_configs is not None:
            pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        if additional_pod_network_configs is not None:
            pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        if create_pod_range is not None:
            pulumi.set(__self__, "create_pod_range", create_pod_range)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if pod_ipv4_cidr_block is not None:
            pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        if pod_range is not None:
            pulumi.set(__self__, "pod_range", pod_range)

    @property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Optional[Sequence['outputs.NodePoolNetworkConfigAdditionalNodeNetworkConfig']]:
        """
        We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface.
        Structure is documented below
        """
        return pulumi.get(self, "additional_node_network_configs")

    @property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Optional[Sequence['outputs.NodePoolNetworkConfigAdditionalPodNetworkConfig']]:
        """
        We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node.
        Structure is documented below
        """
        return pulumi.get(self, "additional_pod_network_configs")

    @property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> Optional[bool]:
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        """
        return pulumi.get(self, "create_pod_range")

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[bool]:
        """
        Whether nodes have internal IP addresses only.
        """
        return pulumi.get(self, "enable_private_nodes")

    @property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional['outputs.NodePoolNetworkConfigPodCidrOverprovisionConfig']:
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> Optional[str]:
        """
        The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> Optional[str]:
        """
        The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        return pulumi.get(self, "pod_range")


@pulumi.output_type
class NodePoolNetworkConfigAdditionalNodeNetworkConfig(dict):
    def __init__(__self__, *,
                 network: Optional[str] = None,
                 subnetwork: Optional[str] = None):
        """
        :param str network: Name of the VPC where the additional interface belongs.
        :param str subnetwork: Name of the subnetwork where the additional interface belongs.
        """
        if network is not None:
            pulumi.set(__self__, "network", network)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter
    def network(self) -> Optional[str]:
        """
        Name of the VPC where the additional interface belongs.
        """
        return pulumi.get(self, "network")

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[str]:
        """
        Name of the subnetwork where the additional interface belongs.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class NodePoolNetworkConfigAdditionalPodNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxPodsPerNode":
            suggest = "max_pods_per_node"
        elif key == "secondaryPodRange":
            suggest = "secondary_pod_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNetworkConfigAdditionalPodNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNetworkConfigAdditionalPodNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNetworkConfigAdditionalPodNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_pods_per_node: Optional[int] = None,
                 secondary_pod_range: Optional[str] = None,
                 subnetwork: Optional[str] = None):
        """
        :param int max_pods_per_node: The maximum number of pods per node which use this pod network.
        :param str secondary_pod_range: The name of the secondary range on the subnet which provides IP address for this pod range.
        :param str subnetwork: Name of the subnetwork where the additional pod network belongs.
        """
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if secondary_pod_range is not None:
            pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[int]:
        """
        The maximum number of pods per node which use this pod network.
        """
        return pulumi.get(self, "max_pods_per_node")

    @property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> Optional[str]:
        """
        The name of the secondary range on the subnet which provides IP address for this pod range.
        """
        return pulumi.get(self, "secondary_pod_range")

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[str]:
        """
        Name of the subnetwork where the additional pod network belongs.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class NodePoolNetworkConfigPodCidrOverprovisionConfig(dict):
    def __init__(__self__, *,
                 disabled: bool):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class NodePoolNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "advancedMachineFeatures":
            suggest = "advanced_machine_features"
        elif key == "bootDiskKmsKey":
            suggest = "boot_disk_kms_key"
        elif key == "confidentialNodes":
            suggest = "confidential_nodes"
        elif key == "diskSizeGb":
            suggest = "disk_size_gb"
        elif key == "diskType":
            suggest = "disk_type"
        elif key == "ephemeralStorageConfig":
            suggest = "ephemeral_storage_config"
        elif key == "ephemeralStorageLocalSsdConfig":
            suggest = "ephemeral_storage_local_ssd_config"
        elif key == "fastSocket":
            suggest = "fast_socket"
        elif key == "gcfsConfig":
            suggest = "gcfs_config"
        elif key == "guestAccelerators":
            suggest = "guest_accelerators"
        elif key == "hostMaintenancePolicy":
            suggest = "host_maintenance_policy"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "kubeletConfig":
            suggest = "kubelet_config"
        elif key == "linuxNodeConfig":
            suggest = "linux_node_config"
        elif key == "localNvmeSsdBlockConfig":
            suggest = "local_nvme_ssd_block_config"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "loggingVariant":
            suggest = "logging_variant"
        elif key == "machineType":
            suggest = "machine_type"
        elif key == "minCpuPlatform":
            suggest = "min_cpu_platform"
        elif key == "nodeGroup":
            suggest = "node_group"
        elif key == "oauthScopes":
            suggest = "oauth_scopes"
        elif key == "reservationAffinity":
            suggest = "reservation_affinity"
        elif key == "resourceLabels":
            suggest = "resource_labels"
        elif key == "sandboxConfig":
            suggest = "sandbox_config"
        elif key == "serviceAccount":
            suggest = "service_account"
        elif key == "shieldedInstanceConfig":
            suggest = "shielded_instance_config"
        elif key == "soleTenantConfig":
            suggest = "sole_tenant_config"
        elif key == "workloadMetadataConfig":
            suggest = "workload_metadata_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 advanced_machine_features: Optional['outputs.NodePoolNodeConfigAdvancedMachineFeatures'] = None,
                 boot_disk_kms_key: Optional[str] = None,
                 confidential_nodes: Optional['outputs.NodePoolNodeConfigConfidentialNodes'] = None,
                 disk_size_gb: Optional[int] = None,
                 disk_type: Optional[str] = None,
                 ephemeral_storage_config: Optional['outputs.NodePoolNodeConfigEphemeralStorageConfig'] = None,
                 ephemeral_storage_local_ssd_config: Optional['outputs.NodePoolNodeConfigEphemeralStorageLocalSsdConfig'] = None,
                 fast_socket: Optional['outputs.NodePoolNodeConfigFastSocket'] = None,
                 gcfs_config: Optional['outputs.NodePoolNodeConfigGcfsConfig'] = None,
                 guest_accelerators: Optional[Sequence['outputs.NodePoolNodeConfigGuestAccelerator']] = None,
                 gvnic: Optional['outputs.NodePoolNodeConfigGvnic'] = None,
                 host_maintenance_policy: Optional['outputs.NodePoolNodeConfigHostMaintenancePolicy'] = None,
                 image_type: Optional[str] = None,
                 kubelet_config: Optional['outputs.NodePoolNodeConfigKubeletConfig'] = None,
                 labels: Optional[Mapping[str, str]] = None,
                 linux_node_config: Optional['outputs.NodePoolNodeConfigLinuxNodeConfig'] = None,
                 local_nvme_ssd_block_config: Optional['outputs.NodePoolNodeConfigLocalNvmeSsdBlockConfig'] = None,
                 local_ssd_count: Optional[int] = None,
                 logging_variant: Optional[str] = None,
                 machine_type: Optional[str] = None,
                 metadata: Optional[Mapping[str, str]] = None,
                 min_cpu_platform: Optional[str] = None,
                 node_group: Optional[str] = None,
                 oauth_scopes: Optional[Sequence[str]] = None,
                 preemptible: Optional[bool] = None,
                 reservation_affinity: Optional['outputs.NodePoolNodeConfigReservationAffinity'] = None,
                 resource_labels: Optional[Mapping[str, str]] = None,
                 sandbox_config: Optional['outputs.NodePoolNodeConfigSandboxConfig'] = None,
                 service_account: Optional[str] = None,
                 shielded_instance_config: Optional['outputs.NodePoolNodeConfigShieldedInstanceConfig'] = None,
                 sole_tenant_config: Optional['outputs.NodePoolNodeConfigSoleTenantConfig'] = None,
                 spot: Optional[bool] = None,
                 tags: Optional[Sequence[str]] = None,
                 taints: Optional[Sequence['outputs.NodePoolNodeConfigTaint']] = None,
                 workload_metadata_config: Optional['outputs.NodePoolNodeConfigWorkloadMetadataConfig'] = None):
        """
        :param 'NodePoolNodeConfigConfidentialNodesArgs' confidential_nodes: Configuration for Confidential Nodes feature. Structure is documented below.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional['outputs.NodePoolNodeConfigAdvancedMachineFeatures']:
        return pulumi.get(self, "advanced_machine_features")

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[str]:
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional['outputs.NodePoolNodeConfigConfidentialNodes']:
        """
        Configuration for Confidential Nodes feature. Structure is documented below.
        """
        return pulumi.get(self, "confidential_nodes")

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[int]:
        return pulumi.get(self, "disk_size_gb")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[str]:
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional['outputs.NodePoolNodeConfigEphemeralStorageConfig']:
        return pulumi.get(self, "ephemeral_storage_config")

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional['outputs.NodePoolNodeConfigEphemeralStorageLocalSsdConfig']:
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional['outputs.NodePoolNodeConfigFastSocket']:
        return pulumi.get(self, "fast_socket")

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional['outputs.NodePoolNodeConfigGcfsConfig']:
        return pulumi.get(self, "gcfs_config")

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[Sequence['outputs.NodePoolNodeConfigGuestAccelerator']]:
        return pulumi.get(self, "guest_accelerators")

    @property
    @pulumi.getter
    def gvnic(self) -> Optional['outputs.NodePoolNodeConfigGvnic']:
        return pulumi.get(self, "gvnic")

    @property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional['outputs.NodePoolNodeConfigHostMaintenancePolicy']:
        return pulumi.get(self, "host_maintenance_policy")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[str]:
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional['outputs.NodePoolNodeConfigKubeletConfig']:
        return pulumi.get(self, "kubelet_config")

    @property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional['outputs.NodePoolNodeConfigLinuxNodeConfig']:
        return pulumi.get(self, "linux_node_config")

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional['outputs.NodePoolNodeConfigLocalNvmeSsdBlockConfig']:
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[str]:
        return pulumi.get(self, "logging_variant")

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[str]:
        return pulumi.get(self, "machine_type")

    @property
    @pulumi.getter
    def metadata(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "metadata")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[str]:
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[str]:
        return pulumi.get(self, "node_group")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter
    def preemptible(self) -> Optional[bool]:
        return pulumi.get(self, "preemptible")

    @property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional['outputs.NodePoolNodeConfigReservationAffinity']:
        return pulumi.get(self, "reservation_affinity")

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "resource_labels")

    @property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional['outputs.NodePoolNodeConfigSandboxConfig']:
        return pulumi.get(self, "sandbox_config")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[str]:
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional['outputs.NodePoolNodeConfigShieldedInstanceConfig']:
        return pulumi.get(self, "shielded_instance_config")

    @property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional['outputs.NodePoolNodeConfigSoleTenantConfig']:
        return pulumi.get(self, "sole_tenant_config")

    @property
    @pulumi.getter
    def spot(self) -> Optional[bool]:
        return pulumi.get(self, "spot")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def taints(self) -> Optional[Sequence['outputs.NodePoolNodeConfigTaint']]:
        return pulumi.get(self, "taints")

    @property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional['outputs.NodePoolNodeConfigWorkloadMetadataConfig']:
        return pulumi.get(self, "workload_metadata_config")


@pulumi.output_type
class NodePoolNodeConfigAdvancedMachineFeatures(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "threadsPerCore":
            suggest = "threads_per_core"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigAdvancedMachineFeatures. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 threads_per_core: int):
        pulumi.set(__self__, "threads_per_core", threads_per_core)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> int:
        return pulumi.get(self, "threads_per_core")


@pulumi.output_type
class NodePoolNodeConfigConfidentialNodes(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolNodeConfigEphemeralStorageConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigEphemeralStorageConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class NodePoolNodeConfigEphemeralStorageLocalSsdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigEphemeralStorageLocalSsdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class NodePoolNodeConfigFastSocket(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolNodeConfigGcfsConfig(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolNodeConfigGuestAccelerator(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverInstallationConfig":
            suggest = "gpu_driver_installation_config"
        elif key == "gpuPartitionSize":
            suggest = "gpu_partition_size"
        elif key == "gpuSharingConfig":
            suggest = "gpu_sharing_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigGuestAccelerator. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigGuestAccelerator.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigGuestAccelerator.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 count: int,
                 type: str,
                 gpu_driver_installation_config: Optional['outputs.NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig'] = None,
                 gpu_partition_size: Optional[str] = None,
                 gpu_sharing_config: Optional['outputs.NodePoolNodeConfigGuestAcceleratorGpuSharingConfig'] = None):
        """
        :param str type: The type of the policy. Supports a single value: COMPACT.
               Specifying COMPACT placement policy type places node pool's nodes in a closer
               physical proximity in order to reduce network latency between nodes.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @property
    @pulumi.getter
    def count(self) -> int:
        return pulumi.get(self, "count")

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        The type of the policy. Supports a single value: COMPACT.
        Specifying COMPACT placement policy type places node pool's nodes in a closer
        physical proximity in order to reduce network latency between nodes.
        """
        return pulumi.get(self, "type")

    @property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional['outputs.NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig']:
        return pulumi.get(self, "gpu_driver_installation_config")

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[str]:
        return pulumi.get(self, "gpu_partition_size")

    @property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional['outputs.NodePoolNodeConfigGuestAcceleratorGpuSharingConfig']:
        return pulumi.get(self, "gpu_sharing_config")


@pulumi.output_type
class NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverVersion":
            suggest = "gpu_driver_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_driver_version: str):
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> str:
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class NodePoolNodeConfigGuestAcceleratorGpuSharingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuSharingStrategy":
            suggest = "gpu_sharing_strategy"
        elif key == "maxSharedClientsPerGpu":
            suggest = "max_shared_clients_per_gpu"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigGuestAcceleratorGpuSharingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_sharing_strategy: str,
                 max_shared_clients_per_gpu: int):
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> str:
        return pulumi.get(self, "gpu_sharing_strategy")

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> int:
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class NodePoolNodeConfigGvnic(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolNodeConfigHostMaintenancePolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maintenanceInterval":
            suggest = "maintenance_interval"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigHostMaintenancePolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 maintenance_interval: str):
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> str:
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class NodePoolNodeConfigKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cpuManagerPolicy":
            suggest = "cpu_manager_policy"
        elif key == "cpuCfsQuota":
            suggest = "cpu_cfs_quota"
        elif key == "cpuCfsQuotaPeriod":
            suggest = "cpu_cfs_quota_period"
        elif key == "podPidsLimit":
            suggest = "pod_pids_limit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cpu_manager_policy: str,
                 cpu_cfs_quota: Optional[bool] = None,
                 cpu_cfs_quota_period: Optional[str] = None,
                 pod_pids_limit: Optional[int] = None):
        pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> str:
        return pulumi.get(self, "cpu_manager_policy")

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[bool]:
        return pulumi.get(self, "cpu_cfs_quota")

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[str]:
        return pulumi.get(self, "cpu_cfs_quota_period")

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[int]:
        return pulumi.get(self, "pod_pids_limit")


@pulumi.output_type
class NodePoolNodeConfigLinuxNodeConfig(dict):
    def __init__(__self__, *,
                 sysctls: Mapping[str, str]):
        pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter
    def sysctls(self) -> Mapping[str, str]:
        return pulumi.get(self, "sysctls")


@pulumi.output_type
class NodePoolNodeConfigLocalNvmeSsdBlockConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigLocalNvmeSsdBlockConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: int):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class NodePoolNodeConfigReservationAffinity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "consumeReservationType":
            suggest = "consume_reservation_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigReservationAffinity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigReservationAffinity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigReservationAffinity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 consume_reservation_type: str,
                 key: Optional[str] = None,
                 values: Optional[Sequence[str]] = None):
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> str:
        return pulumi.get(self, "consume_reservation_type")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def values(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "values")


@pulumi.output_type
class NodePoolNodeConfigSandboxConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sandboxType":
            suggest = "sandbox_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigSandboxConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigSandboxConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigSandboxConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 sandbox_type: str):
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> str:
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class NodePoolNodeConfigShieldedInstanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableIntegrityMonitoring":
            suggest = "enable_integrity_monitoring"
        elif key == "enableSecureBoot":
            suggest = "enable_secure_boot"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigShieldedInstanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[bool] = None,
                 enable_secure_boot: Optional[bool] = None):
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[bool]:
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[bool]:
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class NodePoolNodeConfigSoleTenantConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodeAffinities":
            suggest = "node_affinities"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigSoleTenantConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigSoleTenantConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigSoleTenantConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.NodePoolNodeConfigSoleTenantConfigNodeAffinity']):
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.NodePoolNodeConfigSoleTenantConfigNodeAffinity']:
        return pulumi.get(self, "node_affinities")


@pulumi.output_type
class NodePoolNodeConfigSoleTenantConfigNodeAffinity(dict):
    def __init__(__self__, *,
                 key: str,
                 operator: str,
                 values: Sequence[str]):
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def operator(self) -> str:
        return pulumi.get(self, "operator")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        return pulumi.get(self, "values")


@pulumi.output_type
class NodePoolNodeConfigTaint(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        return pulumi.get(self, "value")


@pulumi.output_type
class NodePoolNodeConfigWorkloadMetadataConfig(dict):
    def __init__(__self__, *,
                 mode: str):
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> str:
        return pulumi.get(self, "mode")


@pulumi.output_type
class NodePoolPlacementPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "policyName":
            suggest = "policy_name"
        elif key == "tpuTopology":
            suggest = "tpu_topology"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolPlacementPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolPlacementPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolPlacementPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 type: str,
                 policy_name: Optional[str] = None,
                 tpu_topology: Optional[str] = None):
        """
        :param str type: The type of the policy. Supports a single value: COMPACT.
               Specifying COMPACT placement policy type places node pool's nodes in a closer
               physical proximity in order to reduce network latency between nodes.
        :param str policy_name: If set, refers to the name of a custom resource policy supplied by the user.
               The resource policy must be in the same project and region as the node pool.
               If not found, InvalidArgument error is returned.
        :param str tpu_topology: The [TPU placement topology](https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies) for pod slice node pool.
        """
        pulumi.set(__self__, "type", type)
        if policy_name is not None:
            pulumi.set(__self__, "policy_name", policy_name)
        if tpu_topology is not None:
            pulumi.set(__self__, "tpu_topology", tpu_topology)

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        The type of the policy. Supports a single value: COMPACT.
        Specifying COMPACT placement policy type places node pool's nodes in a closer
        physical proximity in order to reduce network latency between nodes.
        """
        return pulumi.get(self, "type")

    @property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> Optional[str]:
        """
        If set, refers to the name of a custom resource policy supplied by the user.
        The resource policy must be in the same project and region as the node pool.
        If not found, InvalidArgument error is returned.
        """
        return pulumi.get(self, "policy_name")

    @property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> Optional[str]:
        """
        The [TPU placement topology](https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies) for pod slice node pool.
        """
        return pulumi.get(self, "tpu_topology")


@pulumi.output_type
class NodePoolUpgradeSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "blueGreenSettings":
            suggest = "blue_green_settings"
        elif key == "maxSurge":
            suggest = "max_surge"
        elif key == "maxUnavailable":
            suggest = "max_unavailable"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolUpgradeSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolUpgradeSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolUpgradeSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 blue_green_settings: Optional['outputs.NodePoolUpgradeSettingsBlueGreenSettings'] = None,
                 max_surge: Optional[int] = None,
                 max_unavailable: Optional[int] = None,
                 strategy: Optional[str] = None):
        """
        :param 'NodePoolUpgradeSettingsBlueGreenSettingsArgs' blue_green_settings: The settings to adjust [blue green upgrades](https://cloud.google.com/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy).
               Structure is documented below
        :param int max_surge: The number of additional nodes that can be added to the node pool during
               an upgrade. Increasing `max_surge` raises the number of nodes that can be upgraded simultaneously.
               Can be set to 0 or greater.
        :param int max_unavailable: The number of nodes that can be simultaneously unavailable during
               an upgrade. Increasing `max_unavailable` raises the number of nodes that can be upgraded in
               parallel. Can be set to 0 or greater.
               
               `max_surge` and `max_unavailable` must not be negative and at least one of them must be greater than zero.
        :param str strategy: The upgrade stragey to be used for upgrading the nodes.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional['outputs.NodePoolUpgradeSettingsBlueGreenSettings']:
        """
        The settings to adjust [blue green upgrades](https://cloud.google.com/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy).
        Structure is documented below
        """
        return pulumi.get(self, "blue_green_settings")

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[int]:
        """
        The number of additional nodes that can be added to the node pool during
        an upgrade. Increasing `max_surge` raises the number of nodes that can be upgraded simultaneously.
        Can be set to 0 or greater.
        """
        return pulumi.get(self, "max_surge")

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[int]:
        """
        The number of nodes that can be simultaneously unavailable during
        an upgrade. Increasing `max_unavailable` raises the number of nodes that can be upgraded in
        parallel. Can be set to 0 or greater.

        `max_surge` and `max_unavailable` must not be negative and at least one of them must be greater than zero.
        """
        return pulumi.get(self, "max_unavailable")

    @property
    @pulumi.getter
    def strategy(self) -> Optional[str]:
        """
        The upgrade stragey to be used for upgrading the nodes.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class NodePoolUpgradeSettingsBlueGreenSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "standardRolloutPolicy":
            suggest = "standard_rollout_policy"
        elif key == "nodePoolSoakDuration":
            suggest = "node_pool_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolUpgradeSettingsBlueGreenSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 standard_rollout_policy: 'outputs.NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
                 node_pool_soak_duration: Optional[str] = None):
        """
        :param 'NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs' standard_rollout_policy: Specifies the standard policy settings for blue-green upgrades.
        :param str node_pool_soak_duration: Time needed after draining the entire blue pool.
               After this period, the blue pool will be cleaned up.
        """
        pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)

    @property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> 'outputs.NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy':
        """
        Specifies the standard policy settings for blue-green upgrades.
        """
        return pulumi.get(self, "standard_rollout_policy")

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[str]:
        """
        Time needed after draining the entire blue pool.
        After this period, the blue pool will be cleaned up.
        """
        return pulumi.get(self, "node_pool_soak_duration")


@pulumi.output_type
class NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "batchNodeCount":
            suggest = "batch_node_count"
        elif key == "batchPercentage":
            suggest = "batch_percentage"
        elif key == "batchSoakDuration":
            suggest = "batch_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 batch_node_count: Optional[int] = None,
                 batch_percentage: Optional[float] = None,
                 batch_soak_duration: Optional[str] = None):
        """
        :param int batch_node_count: Number of blue nodes to drain in a batch.
        :param float batch_percentage: Percentage of the blue pool nodes to drain in a batch.
        :param str batch_soak_duration: Soak time after each batch gets drained.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[int]:
        """
        Number of blue nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_node_count")

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[float]:
        """
        Percentage of the blue pool nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_percentage")

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[str]:
        """
        Soak time after each batch gets drained.
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class GetClusterAddonsConfigResult(dict):
    def __init__(__self__, *,
                 cloudrun_configs: Sequence['outputs.GetClusterAddonsConfigCloudrunConfigResult'],
                 config_connector_configs: Sequence['outputs.GetClusterAddonsConfigConfigConnectorConfigResult'],
                 dns_cache_configs: Sequence['outputs.GetClusterAddonsConfigDnsCacheConfigResult'],
                 gce_persistent_disk_csi_driver_configs: Sequence['outputs.GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigResult'],
                 gcp_filestore_csi_driver_configs: Sequence['outputs.GetClusterAddonsConfigGcpFilestoreCsiDriverConfigResult'],
                 gcs_fuse_csi_driver_configs: Sequence['outputs.GetClusterAddonsConfigGcsFuseCsiDriverConfigResult'],
                 gke_backup_agent_configs: Sequence['outputs.GetClusterAddonsConfigGkeBackupAgentConfigResult'],
                 horizontal_pod_autoscalings: Sequence['outputs.GetClusterAddonsConfigHorizontalPodAutoscalingResult'],
                 http_load_balancings: Sequence['outputs.GetClusterAddonsConfigHttpLoadBalancingResult'],
                 istio_configs: Sequence['outputs.GetClusterAddonsConfigIstioConfigResult'],
                 kalm_configs: Sequence['outputs.GetClusterAddonsConfigKalmConfigResult'],
                 network_policy_configs: Sequence['outputs.GetClusterAddonsConfigNetworkPolicyConfigResult']):
        pulumi.set(__self__, "cloudrun_configs", cloudrun_configs)
        pulumi.set(__self__, "config_connector_configs", config_connector_configs)
        pulumi.set(__self__, "dns_cache_configs", dns_cache_configs)
        pulumi.set(__self__, "gce_persistent_disk_csi_driver_configs", gce_persistent_disk_csi_driver_configs)
        pulumi.set(__self__, "gcp_filestore_csi_driver_configs", gcp_filestore_csi_driver_configs)
        pulumi.set(__self__, "gcs_fuse_csi_driver_configs", gcs_fuse_csi_driver_configs)
        pulumi.set(__self__, "gke_backup_agent_configs", gke_backup_agent_configs)
        pulumi.set(__self__, "horizontal_pod_autoscalings", horizontal_pod_autoscalings)
        pulumi.set(__self__, "http_load_balancings", http_load_balancings)
        pulumi.set(__self__, "istio_configs", istio_configs)
        pulumi.set(__self__, "kalm_configs", kalm_configs)
        pulumi.set(__self__, "network_policy_configs", network_policy_configs)

    @property
    @pulumi.getter(name="cloudrunConfigs")
    def cloudrun_configs(self) -> Sequence['outputs.GetClusterAddonsConfigCloudrunConfigResult']:
        return pulumi.get(self, "cloudrun_configs")

    @property
    @pulumi.getter(name="configConnectorConfigs")
    def config_connector_configs(self) -> Sequence['outputs.GetClusterAddonsConfigConfigConnectorConfigResult']:
        return pulumi.get(self, "config_connector_configs")

    @property
    @pulumi.getter(name="dnsCacheConfigs")
    def dns_cache_configs(self) -> Sequence['outputs.GetClusterAddonsConfigDnsCacheConfigResult']:
        return pulumi.get(self, "dns_cache_configs")

    @property
    @pulumi.getter(name="gcePersistentDiskCsiDriverConfigs")
    def gce_persistent_disk_csi_driver_configs(self) -> Sequence['outputs.GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigResult']:
        return pulumi.get(self, "gce_persistent_disk_csi_driver_configs")

    @property
    @pulumi.getter(name="gcpFilestoreCsiDriverConfigs")
    def gcp_filestore_csi_driver_configs(self) -> Sequence['outputs.GetClusterAddonsConfigGcpFilestoreCsiDriverConfigResult']:
        return pulumi.get(self, "gcp_filestore_csi_driver_configs")

    @property
    @pulumi.getter(name="gcsFuseCsiDriverConfigs")
    def gcs_fuse_csi_driver_configs(self) -> Sequence['outputs.GetClusterAddonsConfigGcsFuseCsiDriverConfigResult']:
        return pulumi.get(self, "gcs_fuse_csi_driver_configs")

    @property
    @pulumi.getter(name="gkeBackupAgentConfigs")
    def gke_backup_agent_configs(self) -> Sequence['outputs.GetClusterAddonsConfigGkeBackupAgentConfigResult']:
        return pulumi.get(self, "gke_backup_agent_configs")

    @property
    @pulumi.getter(name="horizontalPodAutoscalings")
    def horizontal_pod_autoscalings(self) -> Sequence['outputs.GetClusterAddonsConfigHorizontalPodAutoscalingResult']:
        return pulumi.get(self, "horizontal_pod_autoscalings")

    @property
    @pulumi.getter(name="httpLoadBalancings")
    def http_load_balancings(self) -> Sequence['outputs.GetClusterAddonsConfigHttpLoadBalancingResult']:
        return pulumi.get(self, "http_load_balancings")

    @property
    @pulumi.getter(name="istioConfigs")
    def istio_configs(self) -> Sequence['outputs.GetClusterAddonsConfigIstioConfigResult']:
        return pulumi.get(self, "istio_configs")

    @property
    @pulumi.getter(name="kalmConfigs")
    def kalm_configs(self) -> Sequence['outputs.GetClusterAddonsConfigKalmConfigResult']:
        return pulumi.get(self, "kalm_configs")

    @property
    @pulumi.getter(name="networkPolicyConfigs")
    def network_policy_configs(self) -> Sequence['outputs.GetClusterAddonsConfigNetworkPolicyConfigResult']:
        return pulumi.get(self, "network_policy_configs")


@pulumi.output_type
class GetClusterAddonsConfigCloudrunConfigResult(dict):
    def __init__(__self__, *,
                 disabled: bool,
                 load_balancer_type: str):
        pulumi.set(__self__, "disabled", disabled)
        pulumi.set(__self__, "load_balancer_type", load_balancer_type)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")

    @property
    @pulumi.getter(name="loadBalancerType")
    def load_balancer_type(self) -> str:
        return pulumi.get(self, "load_balancer_type")


@pulumi.output_type
class GetClusterAddonsConfigConfigConnectorConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigDnsCacheConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigGcpFilestoreCsiDriverConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigGcsFuseCsiDriverConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigGkeBackupAgentConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigHorizontalPodAutoscalingResult(dict):
    def __init__(__self__, *,
                 disabled: bool):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterAddonsConfigHttpLoadBalancingResult(dict):
    def __init__(__self__, *,
                 disabled: bool):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterAddonsConfigIstioConfigResult(dict):
    def __init__(__self__, *,
                 auth: str,
                 disabled: bool):
        pulumi.set(__self__, "auth", auth)
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def auth(self) -> str:
        return pulumi.get(self, "auth")

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterAddonsConfigKalmConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigNetworkPolicyConfigResult(dict):
    def __init__(__self__, *,
                 disabled: bool):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterAuthenticatorGroupsConfigResult(dict):
    def __init__(__self__, *,
                 security_group: str):
        pulumi.set(__self__, "security_group", security_group)

    @property
    @pulumi.getter(name="securityGroup")
    def security_group(self) -> str:
        return pulumi.get(self, "security_group")


@pulumi.output_type
class GetClusterBinaryAuthorizationResult(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 evaluation_mode: str):
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> str:
        return pulumi.get(self, "evaluation_mode")


@pulumi.output_type
class GetClusterClusterAutoscalingResult(dict):
    def __init__(__self__, *,
                 auto_provisioning_defaults: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultResult'],
                 autoscaling_profile: str,
                 enabled: bool,
                 resource_limits: Sequence['outputs.GetClusterClusterAutoscalingResourceLimitResult']):
        pulumi.set(__self__, "auto_provisioning_defaults", auto_provisioning_defaults)
        pulumi.set(__self__, "autoscaling_profile", autoscaling_profile)
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "resource_limits", resource_limits)

    @property
    @pulumi.getter(name="autoProvisioningDefaults")
    def auto_provisioning_defaults(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultResult']:
        return pulumi.get(self, "auto_provisioning_defaults")

    @property
    @pulumi.getter(name="autoscalingProfile")
    def autoscaling_profile(self) -> str:
        return pulumi.get(self, "autoscaling_profile")

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="resourceLimits")
    def resource_limits(self) -> Sequence['outputs.GetClusterClusterAutoscalingResourceLimitResult']:
        return pulumi.get(self, "resource_limits")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultResult(dict):
    def __init__(__self__, *,
                 boot_disk_kms_key: str,
                 disk_size: int,
                 disk_type: str,
                 image_type: str,
                 managements: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultManagementResult'],
                 min_cpu_platform: str,
                 oauth_scopes: Sequence[str],
                 service_account: str,
                 shielded_instance_configs: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigResult'],
                 upgrade_settings: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingResult']):
        pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        pulumi.set(__self__, "disk_size", disk_size)
        pulumi.set(__self__, "disk_type", disk_type)
        pulumi.set(__self__, "image_type", image_type)
        pulumi.set(__self__, "managements", managements)
        pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        pulumi.set(__self__, "service_account", service_account)
        pulumi.set(__self__, "shielded_instance_configs", shielded_instance_configs)
        pulumi.set(__self__, "upgrade_settings", upgrade_settings)

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> str:
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="diskSize")
    def disk_size(self) -> int:
        return pulumi.get(self, "disk_size")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> str:
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> str:
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter
    def managements(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultManagementResult']:
        return pulumi.get(self, "managements")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> str:
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Sequence[str]:
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> str:
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfigs")
    def shielded_instance_configs(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigResult']:
        return pulumi.get(self, "shielded_instance_configs")

    @property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingResult']:
        return pulumi.get(self, "upgrade_settings")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultManagementResult(dict):
    def __init__(__self__, *,
                 auto_repair: bool,
                 auto_upgrade: bool,
                 upgrade_options: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionResult']):
        pulumi.set(__self__, "auto_repair", auto_repair)
        pulumi.set(__self__, "auto_upgrade", auto_upgrade)
        pulumi.set(__self__, "upgrade_options", upgrade_options)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> bool:
        return pulumi.get(self, "auto_repair")

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> bool:
        return pulumi.get(self, "auto_upgrade")

    @property
    @pulumi.getter(name="upgradeOptions")
    def upgrade_options(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionResult']:
        return pulumi.get(self, "upgrade_options")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionResult(dict):
    def __init__(__self__, *,
                 auto_upgrade_start_time: str,
                 description: str):
        pulumi.set(__self__, "auto_upgrade_start_time", auto_upgrade_start_time)
        pulumi.set(__self__, "description", description)

    @property
    @pulumi.getter(name="autoUpgradeStartTime")
    def auto_upgrade_start_time(self) -> str:
        return pulumi.get(self, "auto_upgrade_start_time")

    @property
    @pulumi.getter
    def description(self) -> str:
        return pulumi.get(self, "description")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigResult(dict):
    def __init__(__self__, *,
                 enable_integrity_monitoring: bool,
                 enable_secure_boot: bool):
        pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> bool:
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> bool:
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingResult(dict):
    def __init__(__self__, *,
                 blue_green_settings: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingResult'],
                 max_surge: int,
                 max_unavailable: int,
                 strategy: str):
        pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        pulumi.set(__self__, "max_surge", max_surge)
        pulumi.set(__self__, "max_unavailable", max_unavailable)
        pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingResult']:
        return pulumi.get(self, "blue_green_settings")

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> int:
        return pulumi.get(self, "max_surge")

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> int:
        return pulumi.get(self, "max_unavailable")

    @property
    @pulumi.getter
    def strategy(self) -> str:
        return pulumi.get(self, "strategy")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingResult(dict):
    def __init__(__self__, *,
                 node_pool_soak_duration: str,
                 standard_rollout_policies: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult']):
        pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        pulumi.set(__self__, "standard_rollout_policies", standard_rollout_policies)

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> str:
        return pulumi.get(self, "node_pool_soak_duration")

    @property
    @pulumi.getter(name="standardRolloutPolicies")
    def standard_rollout_policies(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult']:
        return pulumi.get(self, "standard_rollout_policies")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult(dict):
    def __init__(__self__, *,
                 batch_node_count: int,
                 batch_percentage: float,
                 batch_soak_duration: str):
        pulumi.set(__self__, "batch_node_count", batch_node_count)
        pulumi.set(__self__, "batch_percentage", batch_percentage)
        pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> int:
        return pulumi.get(self, "batch_node_count")

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> float:
        return pulumi.get(self, "batch_percentage")

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> str:
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class GetClusterClusterAutoscalingResourceLimitResult(dict):
    def __init__(__self__, *,
                 maximum: int,
                 minimum: int,
                 resource_type: str):
        pulumi.set(__self__, "maximum", maximum)
        pulumi.set(__self__, "minimum", minimum)
        pulumi.set(__self__, "resource_type", resource_type)

    @property
    @pulumi.getter
    def maximum(self) -> int:
        return pulumi.get(self, "maximum")

    @property
    @pulumi.getter
    def minimum(self) -> int:
        return pulumi.get(self, "minimum")

    @property
    @pulumi.getter(name="resourceType")
    def resource_type(self) -> str:
        return pulumi.get(self, "resource_type")


@pulumi.output_type
class GetClusterClusterTelemetryResult(dict):
    def __init__(__self__, *,
                 type: str):
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def type(self) -> str:
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterConfidentialNodeResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterCostManagementConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterDatabaseEncryptionResult(dict):
    def __init__(__self__, *,
                 key_name: str,
                 state: str):
        pulumi.set(__self__, "key_name", key_name)
        pulumi.set(__self__, "state", state)

    @property
    @pulumi.getter(name="keyName")
    def key_name(self) -> str:
        return pulumi.get(self, "key_name")

    @property
    @pulumi.getter
    def state(self) -> str:
        return pulumi.get(self, "state")


@pulumi.output_type
class GetClusterDefaultSnatStatusResult(dict):
    def __init__(__self__, *,
                 disabled: bool):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterDnsConfigResult(dict):
    def __init__(__self__, *,
                 cluster_dns: str,
                 cluster_dns_domain: str,
                 cluster_dns_scope: str):
        pulumi.set(__self__, "cluster_dns", cluster_dns)
        pulumi.set(__self__, "cluster_dns_domain", cluster_dns_domain)
        pulumi.set(__self__, "cluster_dns_scope", cluster_dns_scope)

    @property
    @pulumi.getter(name="clusterDns")
    def cluster_dns(self) -> str:
        return pulumi.get(self, "cluster_dns")

    @property
    @pulumi.getter(name="clusterDnsDomain")
    def cluster_dns_domain(self) -> str:
        return pulumi.get(self, "cluster_dns_domain")

    @property
    @pulumi.getter(name="clusterDnsScope")
    def cluster_dns_scope(self) -> str:
        return pulumi.get(self, "cluster_dns_scope")


@pulumi.output_type
class GetClusterEnableK8sBetaApiResult(dict):
    def __init__(__self__, *,
                 enabled_apis: Sequence[str]):
        pulumi.set(__self__, "enabled_apis", enabled_apis)

    @property
    @pulumi.getter(name="enabledApis")
    def enabled_apis(self) -> Sequence[str]:
        return pulumi.get(self, "enabled_apis")


@pulumi.output_type
class GetClusterGatewayApiConfigResult(dict):
    def __init__(__self__, *,
                 channel: str):
        pulumi.set(__self__, "channel", channel)

    @property
    @pulumi.getter
    def channel(self) -> str:
        return pulumi.get(self, "channel")


@pulumi.output_type
class GetClusterIdentityServiceConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterIpAllocationPolicyResult(dict):
    def __init__(__self__, *,
                 additional_pod_ranges_configs: Sequence['outputs.GetClusterIpAllocationPolicyAdditionalPodRangesConfigResult'],
                 cluster_ipv4_cidr_block: str,
                 cluster_secondary_range_name: str,
                 pod_cidr_overprovision_configs: Sequence['outputs.GetClusterIpAllocationPolicyPodCidrOverprovisionConfigResult'],
                 services_ipv4_cidr_block: str,
                 services_secondary_range_name: str,
                 stack_type: str):
        pulumi.set(__self__, "additional_pod_ranges_configs", additional_pod_ranges_configs)
        pulumi.set(__self__, "cluster_ipv4_cidr_block", cluster_ipv4_cidr_block)
        pulumi.set(__self__, "cluster_secondary_range_name", cluster_secondary_range_name)
        pulumi.set(__self__, "pod_cidr_overprovision_configs", pod_cidr_overprovision_configs)
        pulumi.set(__self__, "services_ipv4_cidr_block", services_ipv4_cidr_block)
        pulumi.set(__self__, "services_secondary_range_name", services_secondary_range_name)
        pulumi.set(__self__, "stack_type", stack_type)

    @property
    @pulumi.getter(name="additionalPodRangesConfigs")
    def additional_pod_ranges_configs(self) -> Sequence['outputs.GetClusterIpAllocationPolicyAdditionalPodRangesConfigResult']:
        return pulumi.get(self, "additional_pod_ranges_configs")

    @property
    @pulumi.getter(name="clusterIpv4CidrBlock")
    def cluster_ipv4_cidr_block(self) -> str:
        return pulumi.get(self, "cluster_ipv4_cidr_block")

    @property
    @pulumi.getter(name="clusterSecondaryRangeName")
    def cluster_secondary_range_name(self) -> str:
        return pulumi.get(self, "cluster_secondary_range_name")

    @property
    @pulumi.getter(name="podCidrOverprovisionConfigs")
    def pod_cidr_overprovision_configs(self) -> Sequence['outputs.GetClusterIpAllocationPolicyPodCidrOverprovisionConfigResult']:
        return pulumi.get(self, "pod_cidr_overprovision_configs")

    @property
    @pulumi.getter(name="servicesIpv4CidrBlock")
    def services_ipv4_cidr_block(self) -> str:
        return pulumi.get(self, "services_ipv4_cidr_block")

    @property
    @pulumi.getter(name="servicesSecondaryRangeName")
    def services_secondary_range_name(self) -> str:
        return pulumi.get(self, "services_secondary_range_name")

    @property
    @pulumi.getter(name="stackType")
    def stack_type(self) -> str:
        return pulumi.get(self, "stack_type")


@pulumi.output_type
class GetClusterIpAllocationPolicyAdditionalPodRangesConfigResult(dict):
    def __init__(__self__, *,
                 pod_range_names: Sequence[str]):
        pulumi.set(__self__, "pod_range_names", pod_range_names)

    @property
    @pulumi.getter(name="podRangeNames")
    def pod_range_names(self) -> Sequence[str]:
        return pulumi.get(self, "pod_range_names")


@pulumi.output_type
class GetClusterIpAllocationPolicyPodCidrOverprovisionConfigResult(dict):
    def __init__(__self__, *,
                 disabled: bool):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterLoggingConfigResult(dict):
    def __init__(__self__, *,
                 enable_components: Sequence[str]):
        pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Sequence[str]:
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class GetClusterMaintenancePolicyResult(dict):
    def __init__(__self__, *,
                 daily_maintenance_windows: Sequence['outputs.GetClusterMaintenancePolicyDailyMaintenanceWindowResult'],
                 maintenance_exclusions: Sequence['outputs.GetClusterMaintenancePolicyMaintenanceExclusionResult'],
                 recurring_windows: Sequence['outputs.GetClusterMaintenancePolicyRecurringWindowResult']):
        pulumi.set(__self__, "daily_maintenance_windows", daily_maintenance_windows)
        pulumi.set(__self__, "maintenance_exclusions", maintenance_exclusions)
        pulumi.set(__self__, "recurring_windows", recurring_windows)

    @property
    @pulumi.getter(name="dailyMaintenanceWindows")
    def daily_maintenance_windows(self) -> Sequence['outputs.GetClusterMaintenancePolicyDailyMaintenanceWindowResult']:
        return pulumi.get(self, "daily_maintenance_windows")

    @property
    @pulumi.getter(name="maintenanceExclusions")
    def maintenance_exclusions(self) -> Sequence['outputs.GetClusterMaintenancePolicyMaintenanceExclusionResult']:
        return pulumi.get(self, "maintenance_exclusions")

    @property
    @pulumi.getter(name="recurringWindows")
    def recurring_windows(self) -> Sequence['outputs.GetClusterMaintenancePolicyRecurringWindowResult']:
        return pulumi.get(self, "recurring_windows")


@pulumi.output_type
class GetClusterMaintenancePolicyDailyMaintenanceWindowResult(dict):
    def __init__(__self__, *,
                 duration: str,
                 start_time: str):
        pulumi.set(__self__, "duration", duration)
        pulumi.set(__self__, "start_time", start_time)

    @property
    @pulumi.getter
    def duration(self) -> str:
        return pulumi.get(self, "duration")

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> str:
        return pulumi.get(self, "start_time")


@pulumi.output_type
class GetClusterMaintenancePolicyMaintenanceExclusionResult(dict):
    def __init__(__self__, *,
                 end_time: str,
                 exclusion_name: str,
                 exclusion_options: Sequence['outputs.GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionResult'],
                 start_time: str):
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "exclusion_name", exclusion_name)
        pulumi.set(__self__, "exclusion_options", exclusion_options)
        pulumi.set(__self__, "start_time", start_time)

    @property
    @pulumi.getter(name="endTime")
    def end_time(self) -> str:
        return pulumi.get(self, "end_time")

    @property
    @pulumi.getter(name="exclusionName")
    def exclusion_name(self) -> str:
        return pulumi.get(self, "exclusion_name")

    @property
    @pulumi.getter(name="exclusionOptions")
    def exclusion_options(self) -> Sequence['outputs.GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionResult']:
        return pulumi.get(self, "exclusion_options")

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> str:
        return pulumi.get(self, "start_time")


@pulumi.output_type
class GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionResult(dict):
    def __init__(__self__, *,
                 scope: str):
        pulumi.set(__self__, "scope", scope)

    @property
    @pulumi.getter
    def scope(self) -> str:
        return pulumi.get(self, "scope")


@pulumi.output_type
class GetClusterMaintenancePolicyRecurringWindowResult(dict):
    def __init__(__self__, *,
                 end_time: str,
                 recurrence: str,
                 start_time: str):
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "recurrence", recurrence)
        pulumi.set(__self__, "start_time", start_time)

    @property
    @pulumi.getter(name="endTime")
    def end_time(self) -> str:
        return pulumi.get(self, "end_time")

    @property
    @pulumi.getter
    def recurrence(self) -> str:
        return pulumi.get(self, "recurrence")

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> str:
        return pulumi.get(self, "start_time")


@pulumi.output_type
class GetClusterMasterAuthResult(dict):
    def __init__(__self__, *,
                 client_certificate: str,
                 client_certificate_configs: Sequence['outputs.GetClusterMasterAuthClientCertificateConfigResult'],
                 client_key: str,
                 cluster_ca_certificate: str):
        pulumi.set(__self__, "client_certificate", client_certificate)
        pulumi.set(__self__, "client_certificate_configs", client_certificate_configs)
        pulumi.set(__self__, "client_key", client_key)
        pulumi.set(__self__, "cluster_ca_certificate", cluster_ca_certificate)

    @property
    @pulumi.getter(name="clientCertificate")
    def client_certificate(self) -> str:
        return pulumi.get(self, "client_certificate")

    @property
    @pulumi.getter(name="clientCertificateConfigs")
    def client_certificate_configs(self) -> Sequence['outputs.GetClusterMasterAuthClientCertificateConfigResult']:
        return pulumi.get(self, "client_certificate_configs")

    @property
    @pulumi.getter(name="clientKey")
    def client_key(self) -> str:
        return pulumi.get(self, "client_key")

    @property
    @pulumi.getter(name="clusterCaCertificate")
    def cluster_ca_certificate(self) -> str:
        return pulumi.get(self, "cluster_ca_certificate")


@pulumi.output_type
class GetClusterMasterAuthClientCertificateConfigResult(dict):
    def __init__(__self__, *,
                 issue_client_certificate: bool):
        pulumi.set(__self__, "issue_client_certificate", issue_client_certificate)

    @property
    @pulumi.getter(name="issueClientCertificate")
    def issue_client_certificate(self) -> bool:
        return pulumi.get(self, "issue_client_certificate")


@pulumi.output_type
class GetClusterMasterAuthorizedNetworksConfigResult(dict):
    def __init__(__self__, *,
                 cidr_blocks: Sequence['outputs.GetClusterMasterAuthorizedNetworksConfigCidrBlockResult'],
                 gcp_public_cidrs_access_enabled: bool):
        pulumi.set(__self__, "cidr_blocks", cidr_blocks)
        pulumi.set(__self__, "gcp_public_cidrs_access_enabled", gcp_public_cidrs_access_enabled)

    @property
    @pulumi.getter(name="cidrBlocks")
    def cidr_blocks(self) -> Sequence['outputs.GetClusterMasterAuthorizedNetworksConfigCidrBlockResult']:
        return pulumi.get(self, "cidr_blocks")

    @property
    @pulumi.getter(name="gcpPublicCidrsAccessEnabled")
    def gcp_public_cidrs_access_enabled(self) -> bool:
        return pulumi.get(self, "gcp_public_cidrs_access_enabled")


@pulumi.output_type
class GetClusterMasterAuthorizedNetworksConfigCidrBlockResult(dict):
    def __init__(__self__, *,
                 cidr_block: str,
                 display_name: str):
        pulumi.set(__self__, "cidr_block", cidr_block)
        pulumi.set(__self__, "display_name", display_name)

    @property
    @pulumi.getter(name="cidrBlock")
    def cidr_block(self) -> str:
        return pulumi.get(self, "cidr_block")

    @property
    @pulumi.getter(name="displayName")
    def display_name(self) -> str:
        return pulumi.get(self, "display_name")


@pulumi.output_type
class GetClusterMeshCertificateResult(dict):
    def __init__(__self__, *,
                 enable_certificates: bool):
        pulumi.set(__self__, "enable_certificates", enable_certificates)

    @property
    @pulumi.getter(name="enableCertificates")
    def enable_certificates(self) -> bool:
        return pulumi.get(self, "enable_certificates")


@pulumi.output_type
class GetClusterMonitoringConfigResult(dict):
    def __init__(__self__, *,
                 advanced_datapath_observability_configs: Sequence['outputs.GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigResult'],
                 enable_components: Sequence[str],
                 managed_prometheuses: Sequence['outputs.GetClusterMonitoringConfigManagedPrometheusResult']):
        pulumi.set(__self__, "advanced_datapath_observability_configs", advanced_datapath_observability_configs)
        pulumi.set(__self__, "enable_components", enable_components)
        pulumi.set(__self__, "managed_prometheuses", managed_prometheuses)

    @property
    @pulumi.getter(name="advancedDatapathObservabilityConfigs")
    def advanced_datapath_observability_configs(self) -> Sequence['outputs.GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigResult']:
        return pulumi.get(self, "advanced_datapath_observability_configs")

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Sequence[str]:
        return pulumi.get(self, "enable_components")

    @property
    @pulumi.getter(name="managedPrometheuses")
    def managed_prometheuses(self) -> Sequence['outputs.GetClusterMonitoringConfigManagedPrometheusResult']:
        return pulumi.get(self, "managed_prometheuses")


@pulumi.output_type
class GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigResult(dict):
    def __init__(__self__, *,
                 enable_metrics: bool,
                 relay_mode: str):
        pulumi.set(__self__, "enable_metrics", enable_metrics)
        pulumi.set(__self__, "relay_mode", relay_mode)

    @property
    @pulumi.getter(name="enableMetrics")
    def enable_metrics(self) -> bool:
        return pulumi.get(self, "enable_metrics")

    @property
    @pulumi.getter(name="relayMode")
    def relay_mode(self) -> str:
        return pulumi.get(self, "relay_mode")


@pulumi.output_type
class GetClusterMonitoringConfigManagedPrometheusResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNetworkPolicyResult(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 provider: str):
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "provider", provider)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter
    def provider(self) -> str:
        return pulumi.get(self, "provider")


@pulumi.output_type
class GetClusterNodeConfigResult(dict):
    def __init__(__self__, *,
                 advanced_machine_features: Sequence['outputs.GetClusterNodeConfigAdvancedMachineFeatureResult'],
                 boot_disk_kms_key: str,
                 confidential_nodes: Sequence['outputs.GetClusterNodeConfigConfidentialNodeResult'],
                 disk_size_gb: int,
                 disk_type: str,
                 ephemeral_storage_configs: Sequence['outputs.GetClusterNodeConfigEphemeralStorageConfigResult'],
                 ephemeral_storage_local_ssd_configs: Sequence['outputs.GetClusterNodeConfigEphemeralStorageLocalSsdConfigResult'],
                 fast_sockets: Sequence['outputs.GetClusterNodeConfigFastSocketResult'],
                 gcfs_configs: Sequence['outputs.GetClusterNodeConfigGcfsConfigResult'],
                 guest_accelerators: Sequence['outputs.GetClusterNodeConfigGuestAcceleratorResult'],
                 gvnics: Sequence['outputs.GetClusterNodeConfigGvnicResult'],
                 host_maintenance_policies: Sequence['outputs.GetClusterNodeConfigHostMaintenancePolicyResult'],
                 image_type: str,
                 kubelet_configs: Sequence['outputs.GetClusterNodeConfigKubeletConfigResult'],
                 labels: Mapping[str, str],
                 linux_node_configs: Sequence['outputs.GetClusterNodeConfigLinuxNodeConfigResult'],
                 local_nvme_ssd_block_configs: Sequence['outputs.GetClusterNodeConfigLocalNvmeSsdBlockConfigResult'],
                 local_ssd_count: int,
                 logging_variant: str,
                 machine_type: str,
                 metadata: Mapping[str, str],
                 min_cpu_platform: str,
                 node_group: str,
                 oauth_scopes: Sequence[str],
                 preemptible: bool,
                 reservation_affinities: Sequence['outputs.GetClusterNodeConfigReservationAffinityResult'],
                 resource_labels: Mapping[str, str],
                 sandbox_configs: Sequence['outputs.GetClusterNodeConfigSandboxConfigResult'],
                 service_account: str,
                 shielded_instance_configs: Sequence['outputs.GetClusterNodeConfigShieldedInstanceConfigResult'],
                 sole_tenant_configs: Sequence['outputs.GetClusterNodeConfigSoleTenantConfigResult'],
                 spot: bool,
                 tags: Sequence[str],
                 taints: Sequence['outputs.GetClusterNodeConfigTaintResult'],
                 workload_metadata_configs: Sequence['outputs.GetClusterNodeConfigWorkloadMetadataConfigResult']):
        pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        pulumi.set(__self__, "disk_type", disk_type)
        pulumi.set(__self__, "ephemeral_storage_configs", ephemeral_storage_configs)
        pulumi.set(__self__, "ephemeral_storage_local_ssd_configs", ephemeral_storage_local_ssd_configs)
        pulumi.set(__self__, "fast_sockets", fast_sockets)
        pulumi.set(__self__, "gcfs_configs", gcfs_configs)
        pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        pulumi.set(__self__, "gvnics", gvnics)
        pulumi.set(__self__, "host_maintenance_policies", host_maintenance_policies)
        pulumi.set(__self__, "image_type", image_type)
        pulumi.set(__self__, "kubelet_configs", kubelet_configs)
        pulumi.set(__self__, "labels", labels)
        pulumi.set(__self__, "linux_node_configs", linux_node_configs)
        pulumi.set(__self__, "local_nvme_ssd_block_configs", local_nvme_ssd_block_configs)
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        pulumi.set(__self__, "logging_variant", logging_variant)
        pulumi.set(__self__, "machine_type", machine_type)
        pulumi.set(__self__, "metadata", metadata)
        pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        pulumi.set(__self__, "node_group", node_group)
        pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        pulumi.set(__self__, "preemptible", preemptible)
        pulumi.set(__self__, "reservation_affinities", reservation_affinities)
        pulumi.set(__self__, "resource_labels", resource_labels)
        pulumi.set(__self__, "sandbox_configs", sandbox_configs)
        pulumi.set(__self__, "service_account", service_account)
        pulumi.set(__self__, "shielded_instance_configs", shielded_instance_configs)
        pulumi.set(__self__, "sole_tenant_configs", sole_tenant_configs)
        pulumi.set(__self__, "spot", spot)
        pulumi.set(__self__, "tags", tags)
        pulumi.set(__self__, "taints", taints)
        pulumi.set(__self__, "workload_metadata_configs", workload_metadata_configs)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Sequence['outputs.GetClusterNodeConfigAdvancedMachineFeatureResult']:
        return pulumi.get(self, "advanced_machine_features")

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> str:
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Sequence['outputs.GetClusterNodeConfigConfidentialNodeResult']:
        return pulumi.get(self, "confidential_nodes")

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> int:
        return pulumi.get(self, "disk_size_gb")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> str:
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="ephemeralStorageConfigs")
    def ephemeral_storage_configs(self) -> Sequence['outputs.GetClusterNodeConfigEphemeralStorageConfigResult']:
        return pulumi.get(self, "ephemeral_storage_configs")

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfigs")
    def ephemeral_storage_local_ssd_configs(self) -> Sequence['outputs.GetClusterNodeConfigEphemeralStorageLocalSsdConfigResult']:
        return pulumi.get(self, "ephemeral_storage_local_ssd_configs")

    @property
    @pulumi.getter(name="fastSockets")
    def fast_sockets(self) -> Sequence['outputs.GetClusterNodeConfigFastSocketResult']:
        return pulumi.get(self, "fast_sockets")

    @property
    @pulumi.getter(name="gcfsConfigs")
    def gcfs_configs(self) -> Sequence['outputs.GetClusterNodeConfigGcfsConfigResult']:
        return pulumi.get(self, "gcfs_configs")

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Sequence['outputs.GetClusterNodeConfigGuestAcceleratorResult']:
        return pulumi.get(self, "guest_accelerators")

    @property
    @pulumi.getter
    def gvnics(self) -> Sequence['outputs.GetClusterNodeConfigGvnicResult']:
        return pulumi.get(self, "gvnics")

    @property
    @pulumi.getter(name="hostMaintenancePolicies")
    def host_maintenance_policies(self) -> Sequence['outputs.GetClusterNodeConfigHostMaintenancePolicyResult']:
        return pulumi.get(self, "host_maintenance_policies")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> str:
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="kubeletConfigs")
    def kubelet_configs(self) -> Sequence['outputs.GetClusterNodeConfigKubeletConfigResult']:
        return pulumi.get(self, "kubelet_configs")

    @property
    @pulumi.getter
    def labels(self) -> Mapping[str, str]:
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="linuxNodeConfigs")
    def linux_node_configs(self) -> Sequence['outputs.GetClusterNodeConfigLinuxNodeConfigResult']:
        return pulumi.get(self, "linux_node_configs")

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfigs")
    def local_nvme_ssd_block_configs(self) -> Sequence['outputs.GetClusterNodeConfigLocalNvmeSsdBlockConfigResult']:
        return pulumi.get(self, "local_nvme_ssd_block_configs")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> str:
        return pulumi.get(self, "logging_variant")

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> str:
        return pulumi.get(self, "machine_type")

    @property
    @pulumi.getter
    def metadata(self) -> Mapping[str, str]:
        return pulumi.get(self, "metadata")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> str:
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> str:
        return pulumi.get(self, "node_group")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Sequence[str]:
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter
    def preemptible(self) -> bool:
        return pulumi.get(self, "preemptible")

    @property
    @pulumi.getter(name="reservationAffinities")
    def reservation_affinities(self) -> Sequence['outputs.GetClusterNodeConfigReservationAffinityResult']:
        return pulumi.get(self, "reservation_affinities")

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Mapping[str, str]:
        return pulumi.get(self, "resource_labels")

    @property
    @pulumi.getter(name="sandboxConfigs")
    def sandbox_configs(self) -> Sequence['outputs.GetClusterNodeConfigSandboxConfigResult']:
        return pulumi.get(self, "sandbox_configs")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> str:
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfigs")
    def shielded_instance_configs(self) -> Sequence['outputs.GetClusterNodeConfigShieldedInstanceConfigResult']:
        return pulumi.get(self, "shielded_instance_configs")

    @property
    @pulumi.getter(name="soleTenantConfigs")
    def sole_tenant_configs(self) -> Sequence['outputs.GetClusterNodeConfigSoleTenantConfigResult']:
        return pulumi.get(self, "sole_tenant_configs")

    @property
    @pulumi.getter
    def spot(self) -> bool:
        return pulumi.get(self, "spot")

    @property
    @pulumi.getter
    def tags(self) -> Sequence[str]:
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def taints(self) -> Sequence['outputs.GetClusterNodeConfigTaintResult']:
        return pulumi.get(self, "taints")

    @property
    @pulumi.getter(name="workloadMetadataConfigs")
    def workload_metadata_configs(self) -> Sequence['outputs.GetClusterNodeConfigWorkloadMetadataConfigResult']:
        return pulumi.get(self, "workload_metadata_configs")


@pulumi.output_type
class GetClusterNodeConfigAdvancedMachineFeatureResult(dict):
    def __init__(__self__, *,
                 threads_per_core: int):
        pulumi.set(__self__, "threads_per_core", threads_per_core)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> int:
        return pulumi.get(self, "threads_per_core")


@pulumi.output_type
class GetClusterNodeConfigConfidentialNodeResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigEphemeralStorageConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodeConfigEphemeralStorageLocalSsdConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodeConfigFastSocketResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigGcfsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigGuestAcceleratorResult(dict):
    def __init__(__self__, *,
                 count: int,
                 gpu_driver_installation_configs: Sequence['outputs.GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult'],
                 gpu_partition_size: str,
                 gpu_sharing_configs: Sequence['outputs.GetClusterNodeConfigGuestAcceleratorGpuSharingConfigResult'],
                 type: str):
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "gpu_driver_installation_configs", gpu_driver_installation_configs)
        pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        pulumi.set(__self__, "gpu_sharing_configs", gpu_sharing_configs)
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def count(self) -> int:
        return pulumi.get(self, "count")

    @property
    @pulumi.getter(name="gpuDriverInstallationConfigs")
    def gpu_driver_installation_configs(self) -> Sequence['outputs.GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult']:
        return pulumi.get(self, "gpu_driver_installation_configs")

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> str:
        return pulumi.get(self, "gpu_partition_size")

    @property
    @pulumi.getter(name="gpuSharingConfigs")
    def gpu_sharing_configs(self) -> Sequence['outputs.GetClusterNodeConfigGuestAcceleratorGpuSharingConfigResult']:
        return pulumi.get(self, "gpu_sharing_configs")

    @property
    @pulumi.getter
    def type(self) -> str:
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult(dict):
    def __init__(__self__, *,
                 gpu_driver_version: str):
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> str:
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class GetClusterNodeConfigGuestAcceleratorGpuSharingConfigResult(dict):
    def __init__(__self__, *,
                 gpu_sharing_strategy: str,
                 max_shared_clients_per_gpu: int):
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> str:
        return pulumi.get(self, "gpu_sharing_strategy")

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> int:
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class GetClusterNodeConfigGvnicResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigHostMaintenancePolicyResult(dict):
    def __init__(__self__, *,
                 maintenance_interval: str):
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> str:
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class GetClusterNodeConfigKubeletConfigResult(dict):
    def __init__(__self__, *,
                 cpu_cfs_quota: bool,
                 cpu_cfs_quota_period: str,
                 cpu_manager_policy: str,
                 pod_pids_limit: int):
        pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> bool:
        return pulumi.get(self, "cpu_cfs_quota")

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> str:
        return pulumi.get(self, "cpu_cfs_quota_period")

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> str:
        return pulumi.get(self, "cpu_manager_policy")

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> int:
        return pulumi.get(self, "pod_pids_limit")


@pulumi.output_type
class GetClusterNodeConfigLinuxNodeConfigResult(dict):
    def __init__(__self__, *,
                 sysctls: Mapping[str, str]):
        pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter
    def sysctls(self) -> Mapping[str, str]:
        return pulumi.get(self, "sysctls")


@pulumi.output_type
class GetClusterNodeConfigLocalNvmeSsdBlockConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodeConfigReservationAffinityResult(dict):
    def __init__(__self__, *,
                 consume_reservation_type: str,
                 key: str,
                 values: Sequence[str]):
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> str:
        return pulumi.get(self, "consume_reservation_type")

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        return pulumi.get(self, "values")


@pulumi.output_type
class GetClusterNodeConfigSandboxConfigResult(dict):
    def __init__(__self__, *,
                 sandbox_type: str):
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> str:
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class GetClusterNodeConfigShieldedInstanceConfigResult(dict):
    def __init__(__self__, *,
                 enable_integrity_monitoring: bool,
                 enable_secure_boot: bool):
        pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> bool:
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> bool:
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class GetClusterNodeConfigSoleTenantConfigResult(dict):
    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.GetClusterNodeConfigSoleTenantConfigNodeAffinityResult']):
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.GetClusterNodeConfigSoleTenantConfigNodeAffinityResult']:
        return pulumi.get(self, "node_affinities")


@pulumi.output_type
class GetClusterNodeConfigSoleTenantConfigNodeAffinityResult(dict):
    def __init__(__self__, *,
                 key: str,
                 operator: str,
                 values: Sequence[str]):
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def operator(self) -> str:
        return pulumi.get(self, "operator")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        return pulumi.get(self, "values")


@pulumi.output_type
class GetClusterNodeConfigTaintResult(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetClusterNodeConfigWorkloadMetadataConfigResult(dict):
    def __init__(__self__, *,
                 mode: str):
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> str:
        return pulumi.get(self, "mode")


@pulumi.output_type
class GetClusterNodePoolResult(dict):
    def __init__(__self__, *,
                 autoscalings: Sequence['outputs.GetClusterNodePoolAutoscalingResult'],
                 initial_node_count: int,
                 instance_group_urls: Sequence[str],
                 managed_instance_group_urls: Sequence[str],
                 managements: Sequence['outputs.GetClusterNodePoolManagementResult'],
                 max_pods_per_node: int,
                 name: str,
                 name_prefix: str,
                 network_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigResult'],
                 node_configs: Sequence['outputs.GetClusterNodePoolNodeConfigResult'],
                 node_count: int,
                 node_locations: Sequence[str],
                 placement_policies: Sequence['outputs.GetClusterNodePoolPlacementPolicyResult'],
                 upgrade_settings: Sequence['outputs.GetClusterNodePoolUpgradeSettingResult'],
                 version: str):
        """
        :param str name: The name of the cluster.
        """
        pulumi.set(__self__, "autoscalings", autoscalings)
        pulumi.set(__self__, "initial_node_count", initial_node_count)
        pulumi.set(__self__, "instance_group_urls", instance_group_urls)
        pulumi.set(__self__, "managed_instance_group_urls", managed_instance_group_urls)
        pulumi.set(__self__, "managements", managements)
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "name_prefix", name_prefix)
        pulumi.set(__self__, "network_configs", network_configs)
        pulumi.set(__self__, "node_configs", node_configs)
        pulumi.set(__self__, "node_count", node_count)
        pulumi.set(__self__, "node_locations", node_locations)
        pulumi.set(__self__, "placement_policies", placement_policies)
        pulumi.set(__self__, "upgrade_settings", upgrade_settings)
        pulumi.set(__self__, "version", version)

    @property
    @pulumi.getter
    def autoscalings(self) -> Sequence['outputs.GetClusterNodePoolAutoscalingResult']:
        return pulumi.get(self, "autoscalings")

    @property
    @pulumi.getter(name="initialNodeCount")
    def initial_node_count(self) -> int:
        return pulumi.get(self, "initial_node_count")

    @property
    @pulumi.getter(name="instanceGroupUrls")
    def instance_group_urls(self) -> Sequence[str]:
        return pulumi.get(self, "instance_group_urls")

    @property
    @pulumi.getter(name="managedInstanceGroupUrls")
    def managed_instance_group_urls(self) -> Sequence[str]:
        return pulumi.get(self, "managed_instance_group_urls")

    @property
    @pulumi.getter
    def managements(self) -> Sequence['outputs.GetClusterNodePoolManagementResult']:
        return pulumi.get(self, "managements")

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> int:
        return pulumi.get(self, "max_pods_per_node")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The name of the cluster.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="namePrefix")
    def name_prefix(self) -> str:
        return pulumi.get(self, "name_prefix")

    @property
    @pulumi.getter(name="networkConfigs")
    def network_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigResult']:
        return pulumi.get(self, "network_configs")

    @property
    @pulumi.getter(name="nodeConfigs")
    def node_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigResult']:
        return pulumi.get(self, "node_configs")

    @property
    @pulumi.getter(name="nodeCount")
    def node_count(self) -> int:
        return pulumi.get(self, "node_count")

    @property
    @pulumi.getter(name="nodeLocations")
    def node_locations(self) -> Sequence[str]:
        return pulumi.get(self, "node_locations")

    @property
    @pulumi.getter(name="placementPolicies")
    def placement_policies(self) -> Sequence['outputs.GetClusterNodePoolPlacementPolicyResult']:
        return pulumi.get(self, "placement_policies")

    @property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Sequence['outputs.GetClusterNodePoolUpgradeSettingResult']:
        return pulumi.get(self, "upgrade_settings")

    @property
    @pulumi.getter
    def version(self) -> str:
        return pulumi.get(self, "version")


@pulumi.output_type
class GetClusterNodePoolAutoConfigResult(dict):
    def __init__(__self__, *,
                 network_tags: Sequence['outputs.GetClusterNodePoolAutoConfigNetworkTagResult']):
        pulumi.set(__self__, "network_tags", network_tags)

    @property
    @pulumi.getter(name="networkTags")
    def network_tags(self) -> Sequence['outputs.GetClusterNodePoolAutoConfigNetworkTagResult']:
        return pulumi.get(self, "network_tags")


@pulumi.output_type
class GetClusterNodePoolAutoConfigNetworkTagResult(dict):
    def __init__(__self__, *,
                 tags: Sequence[str]):
        pulumi.set(__self__, "tags", tags)

    @property
    @pulumi.getter
    def tags(self) -> Sequence[str]:
        return pulumi.get(self, "tags")


@pulumi.output_type
class GetClusterNodePoolAutoscalingResult(dict):
    def __init__(__self__, *,
                 location_policy: str,
                 max_node_count: int,
                 min_node_count: int,
                 total_max_node_count: int,
                 total_min_node_count: int):
        pulumi.set(__self__, "location_policy", location_policy)
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)
        pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> str:
        return pulumi.get(self, "location_policy")

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> int:
        return pulumi.get(self, "max_node_count")

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> int:
        return pulumi.get(self, "min_node_count")

    @property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> int:
        return pulumi.get(self, "total_max_node_count")

    @property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> int:
        return pulumi.get(self, "total_min_node_count")


@pulumi.output_type
class GetClusterNodePoolDefaultResult(dict):
    def __init__(__self__, *,
                 node_config_defaults: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultResult']):
        pulumi.set(__self__, "node_config_defaults", node_config_defaults)

    @property
    @pulumi.getter(name="nodeConfigDefaults")
    def node_config_defaults(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultResult']:
        return pulumi.get(self, "node_config_defaults")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultResult(dict):
    def __init__(__self__, *,
                 gcfs_configs: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigResult'],
                 logging_variant: str):
        pulumi.set(__self__, "gcfs_configs", gcfs_configs)
        pulumi.set(__self__, "logging_variant", logging_variant)

    @property
    @pulumi.getter(name="gcfsConfigs")
    def gcfs_configs(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigResult']:
        return pulumi.get(self, "gcfs_configs")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> str:
        return pulumi.get(self, "logging_variant")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolManagementResult(dict):
    def __init__(__self__, *,
                 auto_repair: bool,
                 auto_upgrade: bool):
        pulumi.set(__self__, "auto_repair", auto_repair)
        pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> bool:
        return pulumi.get(self, "auto_repair")

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> bool:
        return pulumi.get(self, "auto_upgrade")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigResult(dict):
    def __init__(__self__, *,
                 additional_node_network_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigResult'],
                 additional_pod_network_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigResult'],
                 create_pod_range: bool,
                 enable_private_nodes: bool,
                 pod_cidr_overprovision_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigResult'],
                 pod_ipv4_cidr_block: str,
                 pod_range: str):
        pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        pulumi.set(__self__, "create_pod_range", create_pod_range)
        pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        pulumi.set(__self__, "pod_cidr_overprovision_configs", pod_cidr_overprovision_configs)
        pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        pulumi.set(__self__, "pod_range", pod_range)

    @property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigResult']:
        return pulumi.get(self, "additional_node_network_configs")

    @property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigResult']:
        return pulumi.get(self, "additional_pod_network_configs")

    @property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> bool:
        return pulumi.get(self, "create_pod_range")

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> bool:
        return pulumi.get(self, "enable_private_nodes")

    @property
    @pulumi.getter(name="podCidrOverprovisionConfigs")
    def pod_cidr_overprovision_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigResult']:
        return pulumi.get(self, "pod_cidr_overprovision_configs")

    @property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> str:
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> str:
        return pulumi.get(self, "pod_range")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigResult(dict):
    def __init__(__self__, *,
                 network: str,
                 subnetwork: str):
        pulumi.set(__self__, "network", network)
        pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter
    def network(self) -> str:
        return pulumi.get(self, "network")

    @property
    @pulumi.getter
    def subnetwork(self) -> str:
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigResult(dict):
    def __init__(__self__, *,
                 max_pods_per_node: int,
                 secondary_pod_range: str,
                 subnetwork: str):
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> int:
        return pulumi.get(self, "max_pods_per_node")

    @property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> str:
        return pulumi.get(self, "secondary_pod_range")

    @property
    @pulumi.getter
    def subnetwork(self) -> str:
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigResult(dict):
    def __init__(__self__, *,
                 disabled: bool):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigResult(dict):
    def __init__(__self__, *,
                 advanced_machine_features: Sequence['outputs.GetClusterNodePoolNodeConfigAdvancedMachineFeatureResult'],
                 boot_disk_kms_key: str,
                 confidential_nodes: Sequence['outputs.GetClusterNodePoolNodeConfigConfidentialNodeResult'],
                 disk_size_gb: int,
                 disk_type: str,
                 ephemeral_storage_configs: Sequence['outputs.GetClusterNodePoolNodeConfigEphemeralStorageConfigResult'],
                 ephemeral_storage_local_ssd_configs: Sequence['outputs.GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigResult'],
                 fast_sockets: Sequence['outputs.GetClusterNodePoolNodeConfigFastSocketResult'],
                 gcfs_configs: Sequence['outputs.GetClusterNodePoolNodeConfigGcfsConfigResult'],
                 guest_accelerators: Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorResult'],
                 gvnics: Sequence['outputs.GetClusterNodePoolNodeConfigGvnicResult'],
                 host_maintenance_policies: Sequence['outputs.GetClusterNodePoolNodeConfigHostMaintenancePolicyResult'],
                 image_type: str,
                 kubelet_configs: Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigResult'],
                 labels: Mapping[str, str],
                 linux_node_configs: Sequence['outputs.GetClusterNodePoolNodeConfigLinuxNodeConfigResult'],
                 local_nvme_ssd_block_configs: Sequence['outputs.GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigResult'],
                 local_ssd_count: int,
                 logging_variant: str,
                 machine_type: str,
                 metadata: Mapping[str, str],
                 min_cpu_platform: str,
                 node_group: str,
                 oauth_scopes: Sequence[str],
                 preemptible: bool,
                 reservation_affinities: Sequence['outputs.GetClusterNodePoolNodeConfigReservationAffinityResult'],
                 resource_labels: Mapping[str, str],
                 sandbox_configs: Sequence['outputs.GetClusterNodePoolNodeConfigSandboxConfigResult'],
                 service_account: str,
                 shielded_instance_configs: Sequence['outputs.GetClusterNodePoolNodeConfigShieldedInstanceConfigResult'],
                 sole_tenant_configs: Sequence['outputs.GetClusterNodePoolNodeConfigSoleTenantConfigResult'],
                 spot: bool,
                 tags: Sequence[str],
                 taints: Sequence['outputs.GetClusterNodePoolNodeConfigTaintResult'],
                 workload_metadata_configs: Sequence['outputs.GetClusterNodePoolNodeConfigWorkloadMetadataConfigResult']):
        pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        pulumi.set(__self__, "disk_type", disk_type)
        pulumi.set(__self__, "ephemeral_storage_configs", ephemeral_storage_configs)
        pulumi.set(__self__, "ephemeral_storage_local_ssd_configs", ephemeral_storage_local_ssd_configs)
        pulumi.set(__self__, "fast_sockets", fast_sockets)
        pulumi.set(__self__, "gcfs_configs", gcfs_configs)
        pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        pulumi.set(__self__, "gvnics", gvnics)
        pulumi.set(__self__, "host_maintenance_policies", host_maintenance_policies)
        pulumi.set(__self__, "image_type", image_type)
        pulumi.set(__self__, "kubelet_configs", kubelet_configs)
        pulumi.set(__self__, "labels", labels)
        pulumi.set(__self__, "linux_node_configs", linux_node_configs)
        pulumi.set(__self__, "local_nvme_ssd_block_configs", local_nvme_ssd_block_configs)
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        pulumi.set(__self__, "logging_variant", logging_variant)
        pulumi.set(__self__, "machine_type", machine_type)
        pulumi.set(__self__, "metadata", metadata)
        pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        pulumi.set(__self__, "node_group", node_group)
        pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        pulumi.set(__self__, "preemptible", preemptible)
        pulumi.set(__self__, "reservation_affinities", reservation_affinities)
        pulumi.set(__self__, "resource_labels", resource_labels)
        pulumi.set(__self__, "sandbox_configs", sandbox_configs)
        pulumi.set(__self__, "service_account", service_account)
        pulumi.set(__self__, "shielded_instance_configs", shielded_instance_configs)
        pulumi.set(__self__, "sole_tenant_configs", sole_tenant_configs)
        pulumi.set(__self__, "spot", spot)
        pulumi.set(__self__, "tags", tags)
        pulumi.set(__self__, "taints", taints)
        pulumi.set(__self__, "workload_metadata_configs", workload_metadata_configs)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigAdvancedMachineFeatureResult']:
        return pulumi.get(self, "advanced_machine_features")

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> str:
        return pulumi.get(self, "boot_disk_kms_key")

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigConfidentialNodeResult']:
        return pulumi.get(self, "confidential_nodes")

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> int:
        return pulumi.get(self, "disk_size_gb")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> str:
        return pulumi.get(self, "disk_type")

    @property
    @pulumi.getter(name="ephemeralStorageConfigs")
    def ephemeral_storage_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigEphemeralStorageConfigResult']:
        return pulumi.get(self, "ephemeral_storage_configs")

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfigs")
    def ephemeral_storage_local_ssd_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigResult']:
        return pulumi.get(self, "ephemeral_storage_local_ssd_configs")

    @property
    @pulumi.getter(name="fastSockets")
    def fast_sockets(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigFastSocketResult']:
        return pulumi.get(self, "fast_sockets")

    @property
    @pulumi.getter(name="gcfsConfigs")
    def gcfs_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGcfsConfigResult']:
        return pulumi.get(self, "gcfs_configs")

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorResult']:
        return pulumi.get(self, "guest_accelerators")

    @property
    @pulumi.getter
    def gvnics(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGvnicResult']:
        return pulumi.get(self, "gvnics")

    @property
    @pulumi.getter(name="hostMaintenancePolicies")
    def host_maintenance_policies(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigHostMaintenancePolicyResult']:
        return pulumi.get(self, "host_maintenance_policies")

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> str:
        return pulumi.get(self, "image_type")

    @property
    @pulumi.getter(name="kubeletConfigs")
    def kubelet_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigResult']:
        return pulumi.get(self, "kubelet_configs")

    @property
    @pulumi.getter
    def labels(self) -> Mapping[str, str]:
        return pulumi.get(self, "labels")

    @property
    @pulumi.getter(name="linuxNodeConfigs")
    def linux_node_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigLinuxNodeConfigResult']:
        return pulumi.get(self, "linux_node_configs")

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfigs")
    def local_nvme_ssd_block_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigResult']:
        return pulumi.get(self, "local_nvme_ssd_block_configs")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> str:
        return pulumi.get(self, "logging_variant")

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> str:
        return pulumi.get(self, "machine_type")

    @property
    @pulumi.getter
    def metadata(self) -> Mapping[str, str]:
        return pulumi.get(self, "metadata")

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> str:
        return pulumi.get(self, "min_cpu_platform")

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> str:
        return pulumi.get(self, "node_group")

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Sequence[str]:
        return pulumi.get(self, "oauth_scopes")

    @property
    @pulumi.getter
    def preemptible(self) -> bool:
        return pulumi.get(self, "preemptible")

    @property
    @pulumi.getter(name="reservationAffinities")
    def reservation_affinities(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigReservationAffinityResult']:
        return pulumi.get(self, "reservation_affinities")

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Mapping[str, str]:
        return pulumi.get(self, "resource_labels")

    @property
    @pulumi.getter(name="sandboxConfigs")
    def sandbox_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigSandboxConfigResult']:
        return pulumi.get(self, "sandbox_configs")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> str:
        return pulumi.get(self, "service_account")

    @property
    @pulumi.getter(name="shieldedInstanceConfigs")
    def shielded_instance_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigShieldedInstanceConfigResult']:
        return pulumi.get(self, "shielded_instance_configs")

    @property
    @pulumi.getter(name="soleTenantConfigs")
    def sole_tenant_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigSoleTenantConfigResult']:
        return pulumi.get(self, "sole_tenant_configs")

    @property
    @pulumi.getter
    def spot(self) -> bool:
        return pulumi.get(self, "spot")

    @property
    @pulumi.getter
    def tags(self) -> Sequence[str]:
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def taints(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigTaintResult']:
        return pulumi.get(self, "taints")

    @property
    @pulumi.getter(name="workloadMetadataConfigs")
    def workload_metadata_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigWorkloadMetadataConfigResult']:
        return pulumi.get(self, "workload_metadata_configs")


@pulumi.output_type
class GetClusterNodePoolNodeConfigAdvancedMachineFeatureResult(dict):
    def __init__(__self__, *,
                 threads_per_core: int):
        pulumi.set(__self__, "threads_per_core", threads_per_core)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> int:
        return pulumi.get(self, "threads_per_core")


@pulumi.output_type
class GetClusterNodePoolNodeConfigConfidentialNodeResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigEphemeralStorageConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodePoolNodeConfigFastSocketResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGcfsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGuestAcceleratorResult(dict):
    def __init__(__self__, *,
                 count: int,
                 gpu_driver_installation_configs: Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult'],
                 gpu_partition_size: str,
                 gpu_sharing_configs: Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigResult'],
                 type: str):
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "gpu_driver_installation_configs", gpu_driver_installation_configs)
        pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        pulumi.set(__self__, "gpu_sharing_configs", gpu_sharing_configs)
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def count(self) -> int:
        return pulumi.get(self, "count")

    @property
    @pulumi.getter(name="gpuDriverInstallationConfigs")
    def gpu_driver_installation_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult']:
        return pulumi.get(self, "gpu_driver_installation_configs")

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> str:
        return pulumi.get(self, "gpu_partition_size")

    @property
    @pulumi.getter(name="gpuSharingConfigs")
    def gpu_sharing_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigResult']:
        return pulumi.get(self, "gpu_sharing_configs")

    @property
    @pulumi.getter
    def type(self) -> str:
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult(dict):
    def __init__(__self__, *,
                 gpu_driver_version: str):
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> str:
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigResult(dict):
    def __init__(__self__, *,
                 gpu_sharing_strategy: str,
                 max_shared_clients_per_gpu: int):
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> str:
        return pulumi.get(self, "gpu_sharing_strategy")

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> int:
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGvnicResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigHostMaintenancePolicyResult(dict):
    def __init__(__self__, *,
                 maintenance_interval: str):
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> str:
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class GetClusterNodePoolNodeConfigKubeletConfigResult(dict):
    def __init__(__self__, *,
                 cpu_cfs_quota: bool,
                 cpu_cfs_quota_period: str,
                 cpu_manager_policy: str,
                 pod_pids_limit: int):
        pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> bool:
        return pulumi.get(self, "cpu_cfs_quota")

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> str:
        return pulumi.get(self, "cpu_cfs_quota_period")

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> str:
        return pulumi.get(self, "cpu_manager_policy")

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> int:
        return pulumi.get(self, "pod_pids_limit")


@pulumi.output_type
class GetClusterNodePoolNodeConfigLinuxNodeConfigResult(dict):
    def __init__(__self__, *,
                 sysctls: Mapping[str, str]):
        pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter
    def sysctls(self) -> Mapping[str, str]:
        return pulumi.get(self, "sysctls")


@pulumi.output_type
class GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodePoolNodeConfigReservationAffinityResult(dict):
    def __init__(__self__, *,
                 consume_reservation_type: str,
                 key: str,
                 values: Sequence[str]):
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> str:
        return pulumi.get(self, "consume_reservation_type")

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        return pulumi.get(self, "values")


@pulumi.output_type
class GetClusterNodePoolNodeConfigSandboxConfigResult(dict):
    def __init__(__self__, *,
                 sandbox_type: str):
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> str:
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class GetClusterNodePoolNodeConfigShieldedInstanceConfigResult(dict):
    def __init__(__self__, *,
                 enable_integrity_monitoring: bool,
                 enable_secure_boot: bool):
        pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> bool:
        return pulumi.get(self, "enable_integrity_monitoring")

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> bool:
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class GetClusterNodePoolNodeConfigSoleTenantConfigResult(dict):
    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityResult']):
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityResult']:
        return pulumi.get(self, "node_affinities")


@pulumi.output_type
class GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityResult(dict):
    def __init__(__self__, *,
                 key: str,
                 operator: str,
                 values: Sequence[str]):
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def operator(self) -> str:
        return pulumi.get(self, "operator")

    @property
    @pulumi.getter
    def values(self) -> Sequence[str]:
        return pulumi.get(self, "values")


@pulumi.output_type
class GetClusterNodePoolNodeConfigTaintResult(dict):
    def __init__(__self__, *,
                 effect: str,
                 key: str,
                 value: str):
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> str:
        return pulumi.get(self, "effect")

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetClusterNodePoolNodeConfigWorkloadMetadataConfigResult(dict):
    def __init__(__self__, *,
                 mode: str):
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> str:
        return pulumi.get(self, "mode")


@pulumi.output_type
class GetClusterNodePoolPlacementPolicyResult(dict):
    def __init__(__self__, *,
                 policy_name: str,
                 tpu_topology: str,
                 type: str):
        pulumi.set(__self__, "policy_name", policy_name)
        pulumi.set(__self__, "tpu_topology", tpu_topology)
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> str:
        return pulumi.get(self, "policy_name")

    @property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> str:
        return pulumi.get(self, "tpu_topology")

    @property
    @pulumi.getter
    def type(self) -> str:
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterNodePoolUpgradeSettingResult(dict):
    def __init__(__self__, *,
                 blue_green_settings: Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingResult'],
                 max_surge: int,
                 max_unavailable: int,
                 strategy: str):
        pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        pulumi.set(__self__, "max_surge", max_surge)
        pulumi.set(__self__, "max_unavailable", max_unavailable)
        pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingResult']:
        return pulumi.get(self, "blue_green_settings")

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> int:
        return pulumi.get(self, "max_surge")

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> int:
        return pulumi.get(self, "max_unavailable")

    @property
    @pulumi.getter
    def strategy(self) -> str:
        return pulumi.get(self, "strategy")


@pulumi.output_type
class GetClusterNodePoolUpgradeSettingBlueGreenSettingResult(dict):
    def __init__(__self__, *,
                 node_pool_soak_duration: str,
                 standard_rollout_policies: Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult']):
        pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        pulumi.set(__self__, "standard_rollout_policies", standard_rollout_policies)

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> str:
        return pulumi.get(self, "node_pool_soak_duration")

    @property
    @pulumi.getter(name="standardRolloutPolicies")
    def standard_rollout_policies(self) -> Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult']:
        return pulumi.get(self, "standard_rollout_policies")


@pulumi.output_type
class GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult(dict):
    def __init__(__self__, *,
                 batch_node_count: int,
                 batch_percentage: float,
                 batch_soak_duration: str):
        pulumi.set(__self__, "batch_node_count", batch_node_count)
        pulumi.set(__self__, "batch_percentage", batch_percentage)
        pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> int:
        return pulumi.get(self, "batch_node_count")

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> float:
        return pulumi.get(self, "batch_percentage")

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> str:
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class GetClusterNotificationConfigResult(dict):
    def __init__(__self__, *,
                 pubsubs: Sequence['outputs.GetClusterNotificationConfigPubsubResult']):
        pulumi.set(__self__, "pubsubs", pubsubs)

    @property
    @pulumi.getter
    def pubsubs(self) -> Sequence['outputs.GetClusterNotificationConfigPubsubResult']:
        return pulumi.get(self, "pubsubs")


@pulumi.output_type
class GetClusterNotificationConfigPubsubResult(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 filters: Sequence['outputs.GetClusterNotificationConfigPubsubFilterResult'],
                 topic: str):
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "filters", filters)
        pulumi.set(__self__, "topic", topic)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter
    def filters(self) -> Sequence['outputs.GetClusterNotificationConfigPubsubFilterResult']:
        return pulumi.get(self, "filters")

    @property
    @pulumi.getter
    def topic(self) -> str:
        return pulumi.get(self, "topic")


@pulumi.output_type
class GetClusterNotificationConfigPubsubFilterResult(dict):
    def __init__(__self__, *,
                 event_types: Sequence[str]):
        pulumi.set(__self__, "event_types", event_types)

    @property
    @pulumi.getter(name="eventTypes")
    def event_types(self) -> Sequence[str]:
        return pulumi.get(self, "event_types")


@pulumi.output_type
class GetClusterPodSecurityPolicyConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterPrivateClusterConfigResult(dict):
    def __init__(__self__, *,
                 enable_private_endpoint: bool,
                 enable_private_nodes: bool,
                 master_global_access_configs: Sequence['outputs.GetClusterPrivateClusterConfigMasterGlobalAccessConfigResult'],
                 master_ipv4_cidr_block: str,
                 peering_name: str,
                 private_endpoint: str,
                 private_endpoint_subnetwork: str,
                 public_endpoint: str):
        pulumi.set(__self__, "enable_private_endpoint", enable_private_endpoint)
        pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        pulumi.set(__self__, "master_global_access_configs", master_global_access_configs)
        pulumi.set(__self__, "master_ipv4_cidr_block", master_ipv4_cidr_block)
        pulumi.set(__self__, "peering_name", peering_name)
        pulumi.set(__self__, "private_endpoint", private_endpoint)
        pulumi.set(__self__, "private_endpoint_subnetwork", private_endpoint_subnetwork)
        pulumi.set(__self__, "public_endpoint", public_endpoint)

    @property
    @pulumi.getter(name="enablePrivateEndpoint")
    def enable_private_endpoint(self) -> bool:
        return pulumi.get(self, "enable_private_endpoint")

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> bool:
        return pulumi.get(self, "enable_private_nodes")

    @property
    @pulumi.getter(name="masterGlobalAccessConfigs")
    def master_global_access_configs(self) -> Sequence['outputs.GetClusterPrivateClusterConfigMasterGlobalAccessConfigResult']:
        return pulumi.get(self, "master_global_access_configs")

    @property
    @pulumi.getter(name="masterIpv4CidrBlock")
    def master_ipv4_cidr_block(self) -> str:
        return pulumi.get(self, "master_ipv4_cidr_block")

    @property
    @pulumi.getter(name="peeringName")
    def peering_name(self) -> str:
        return pulumi.get(self, "peering_name")

    @property
    @pulumi.getter(name="privateEndpoint")
    def private_endpoint(self) -> str:
        return pulumi.get(self, "private_endpoint")

    @property
    @pulumi.getter(name="privateEndpointSubnetwork")
    def private_endpoint_subnetwork(self) -> str:
        return pulumi.get(self, "private_endpoint_subnetwork")

    @property
    @pulumi.getter(name="publicEndpoint")
    def public_endpoint(self) -> str:
        return pulumi.get(self, "public_endpoint")


@pulumi.output_type
class GetClusterPrivateClusterConfigMasterGlobalAccessConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterProtectConfigResult(dict):
    def __init__(__self__, *,
                 workload_configs: Sequence['outputs.GetClusterProtectConfigWorkloadConfigResult'],
                 workload_vulnerability_mode: str):
        pulumi.set(__self__, "workload_configs", workload_configs)
        pulumi.set(__self__, "workload_vulnerability_mode", workload_vulnerability_mode)

    @property
    @pulumi.getter(name="workloadConfigs")
    def workload_configs(self) -> Sequence['outputs.GetClusterProtectConfigWorkloadConfigResult']:
        return pulumi.get(self, "workload_configs")

    @property
    @pulumi.getter(name="workloadVulnerabilityMode")
    def workload_vulnerability_mode(self) -> str:
        return pulumi.get(self, "workload_vulnerability_mode")


@pulumi.output_type
class GetClusterProtectConfigWorkloadConfigResult(dict):
    def __init__(__self__, *,
                 audit_mode: str):
        pulumi.set(__self__, "audit_mode", audit_mode)

    @property
    @pulumi.getter(name="auditMode")
    def audit_mode(self) -> str:
        return pulumi.get(self, "audit_mode")


@pulumi.output_type
class GetClusterReleaseChannelResult(dict):
    def __init__(__self__, *,
                 channel: str):
        pulumi.set(__self__, "channel", channel)

    @property
    @pulumi.getter
    def channel(self) -> str:
        return pulumi.get(self, "channel")


@pulumi.output_type
class GetClusterResourceUsageExportConfigResult(dict):
    def __init__(__self__, *,
                 bigquery_destinations: Sequence['outputs.GetClusterResourceUsageExportConfigBigqueryDestinationResult'],
                 enable_network_egress_metering: bool,
                 enable_resource_consumption_metering: bool):
        pulumi.set(__self__, "bigquery_destinations", bigquery_destinations)
        pulumi.set(__self__, "enable_network_egress_metering", enable_network_egress_metering)
        pulumi.set(__self__, "enable_resource_consumption_metering", enable_resource_consumption_metering)

    @property
    @pulumi.getter(name="bigqueryDestinations")
    def bigquery_destinations(self) -> Sequence['outputs.GetClusterResourceUsageExportConfigBigqueryDestinationResult']:
        return pulumi.get(self, "bigquery_destinations")

    @property
    @pulumi.getter(name="enableNetworkEgressMetering")
    def enable_network_egress_metering(self) -> bool:
        return pulumi.get(self, "enable_network_egress_metering")

    @property
    @pulumi.getter(name="enableResourceConsumptionMetering")
    def enable_resource_consumption_metering(self) -> bool:
        return pulumi.get(self, "enable_resource_consumption_metering")


@pulumi.output_type
class GetClusterResourceUsageExportConfigBigqueryDestinationResult(dict):
    def __init__(__self__, *,
                 dataset_id: str):
        pulumi.set(__self__, "dataset_id", dataset_id)

    @property
    @pulumi.getter(name="datasetId")
    def dataset_id(self) -> str:
        return pulumi.get(self, "dataset_id")


@pulumi.output_type
class GetClusterSecurityPostureConfigResult(dict):
    def __init__(__self__, *,
                 mode: str,
                 vulnerability_mode: str):
        pulumi.set(__self__, "mode", mode)
        pulumi.set(__self__, "vulnerability_mode", vulnerability_mode)

    @property
    @pulumi.getter
    def mode(self) -> str:
        return pulumi.get(self, "mode")

    @property
    @pulumi.getter(name="vulnerabilityMode")
    def vulnerability_mode(self) -> str:
        return pulumi.get(self, "vulnerability_mode")


@pulumi.output_type
class GetClusterServiceExternalIpsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterTpuConfigResult(dict):
    def __init__(__self__, *,
                 enabled: bool,
                 ipv4_cidr_block: str,
                 use_service_networking: bool):
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "ipv4_cidr_block", ipv4_cidr_block)
        pulumi.set(__self__, "use_service_networking", use_service_networking)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="ipv4CidrBlock")
    def ipv4_cidr_block(self) -> str:
        return pulumi.get(self, "ipv4_cidr_block")

    @property
    @pulumi.getter(name="useServiceNetworking")
    def use_service_networking(self) -> bool:
        return pulumi.get(self, "use_service_networking")


@pulumi.output_type
class GetClusterVerticalPodAutoscalingResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterWorkloadIdentityConfigResult(dict):
    def __init__(__self__, *,
                 workload_pool: str):
        pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> str:
        return pulumi.get(self, "workload_pool")


