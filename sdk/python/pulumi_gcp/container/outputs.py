# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities
from . import outputs

__all__ = [
    'AttachedClusterAuthorization',
    'AttachedClusterBinaryAuthorization',
    'AttachedClusterError',
    'AttachedClusterFleet',
    'AttachedClusterLoggingConfig',
    'AttachedClusterLoggingConfigComponentConfig',
    'AttachedClusterMonitoringConfig',
    'AttachedClusterMonitoringConfigManagedPrometheusConfig',
    'AttachedClusterOidcConfig',
    'AttachedClusterProxyConfig',
    'AttachedClusterProxyConfigKubernetesSecret',
    'AttachedClusterSecurityPostureConfig',
    'AttachedClusterWorkloadIdentityConfig',
    'AwsClusterAuthorization',
    'AwsClusterAuthorizationAdminGroup',
    'AwsClusterAuthorizationAdminUser',
    'AwsClusterBinaryAuthorization',
    'AwsClusterControlPlane',
    'AwsClusterControlPlaneAwsServicesAuthentication',
    'AwsClusterControlPlaneConfigEncryption',
    'AwsClusterControlPlaneDatabaseEncryption',
    'AwsClusterControlPlaneInstancePlacement',
    'AwsClusterControlPlaneMainVolume',
    'AwsClusterControlPlaneProxyConfig',
    'AwsClusterControlPlaneRootVolume',
    'AwsClusterControlPlaneSshConfig',
    'AwsClusterFleet',
    'AwsClusterLoggingConfig',
    'AwsClusterLoggingConfigComponentConfig',
    'AwsClusterNetworking',
    'AwsClusterWorkloadIdentityConfig',
    'AwsNodePoolAutoscaling',
    'AwsNodePoolConfig',
    'AwsNodePoolConfigAutoscalingMetricsCollection',
    'AwsNodePoolConfigConfigEncryption',
    'AwsNodePoolConfigInstancePlacement',
    'AwsNodePoolConfigProxyConfig',
    'AwsNodePoolConfigRootVolume',
    'AwsNodePoolConfigSpotConfig',
    'AwsNodePoolConfigSshConfig',
    'AwsNodePoolConfigTaint',
    'AwsNodePoolKubeletConfig',
    'AwsNodePoolManagement',
    'AwsNodePoolMaxPodsConstraint',
    'AwsNodePoolUpdateSettings',
    'AwsNodePoolUpdateSettingsSurgeSettings',
    'AzureClusterAuthorization',
    'AzureClusterAuthorizationAdminGroup',
    'AzureClusterAuthorizationAdminUser',
    'AzureClusterAzureServicesAuthentication',
    'AzureClusterControlPlane',
    'AzureClusterControlPlaneDatabaseEncryption',
    'AzureClusterControlPlaneMainVolume',
    'AzureClusterControlPlaneProxyConfig',
    'AzureClusterControlPlaneReplicaPlacement',
    'AzureClusterControlPlaneRootVolume',
    'AzureClusterControlPlaneSshConfig',
    'AzureClusterFleet',
    'AzureClusterLoggingConfig',
    'AzureClusterLoggingConfigComponentConfig',
    'AzureClusterNetworking',
    'AzureClusterWorkloadIdentityConfig',
    'AzureNodePoolAutoscaling',
    'AzureNodePoolConfig',
    'AzureNodePoolConfigProxyConfig',
    'AzureNodePoolConfigRootVolume',
    'AzureNodePoolConfigSshConfig',
    'AzureNodePoolManagement',
    'AzureNodePoolMaxPodsConstraint',
    'ClusterAddonsConfig',
    'ClusterAddonsConfigCloudrunConfig',
    'ClusterAddonsConfigConfigConnectorConfig',
    'ClusterAddonsConfigDnsCacheConfig',
    'ClusterAddonsConfigGcePersistentDiskCsiDriverConfig',
    'ClusterAddonsConfigGcpFilestoreCsiDriverConfig',
    'ClusterAddonsConfigGcsFuseCsiDriverConfig',
    'ClusterAddonsConfigGkeBackupAgentConfig',
    'ClusterAddonsConfigHorizontalPodAutoscaling',
    'ClusterAddonsConfigHttpLoadBalancing',
    'ClusterAddonsConfigIstioConfig',
    'ClusterAddonsConfigKalmConfig',
    'ClusterAddonsConfigLustreCsiDriverConfig',
    'ClusterAddonsConfigNetworkPolicyConfig',
    'ClusterAddonsConfigParallelstoreCsiDriverConfig',
    'ClusterAddonsConfigRayOperatorConfig',
    'ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfig',
    'ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfig',
    'ClusterAddonsConfigStatefulHaConfig',
    'ClusterAnonymousAuthenticationConfig',
    'ClusterAuthenticatorGroupsConfig',
    'ClusterBinaryAuthorization',
    'ClusterClusterAutoscaling',
    'ClusterClusterAutoscalingAutoProvisioningDefaults',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsManagement',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
    'ClusterClusterAutoscalingResourceLimit',
    'ClusterClusterTelemetry',
    'ClusterConfidentialNodes',
    'ClusterControlPlaneEndpointsConfig',
    'ClusterControlPlaneEndpointsConfigDnsEndpointConfig',
    'ClusterControlPlaneEndpointsConfigIpEndpointsConfig',
    'ClusterCostManagementConfig',
    'ClusterDatabaseEncryption',
    'ClusterDefaultSnatStatus',
    'ClusterDnsConfig',
    'ClusterEnableK8sBetaApis',
    'ClusterEnterpriseConfig',
    'ClusterFleet',
    'ClusterGatewayApiConfig',
    'ClusterGkeAutoUpgradeConfig',
    'ClusterIdentityServiceConfig',
    'ClusterIpAllocationPolicy',
    'ClusterIpAllocationPolicyAdditionalIpRangesConfig',
    'ClusterIpAllocationPolicyAdditionalPodRangesConfig',
    'ClusterIpAllocationPolicyAutoIpamConfig',
    'ClusterIpAllocationPolicyNetworkTierConfig',
    'ClusterIpAllocationPolicyPodCidrOverprovisionConfig',
    'ClusterLoggingConfig',
    'ClusterMaintenancePolicy',
    'ClusterMaintenancePolicyDailyMaintenanceWindow',
    'ClusterMaintenancePolicyMaintenanceExclusion',
    'ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions',
    'ClusterMaintenancePolicyRecurringWindow',
    'ClusterMasterAuth',
    'ClusterMasterAuthClientCertificateConfig',
    'ClusterMasterAuthorizedNetworksConfig',
    'ClusterMasterAuthorizedNetworksConfigCidrBlock',
    'ClusterMeshCertificates',
    'ClusterMonitoringConfig',
    'ClusterMonitoringConfigAdvancedDatapathObservabilityConfig',
    'ClusterMonitoringConfigManagedPrometheus',
    'ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfig',
    'ClusterNetworkPerformanceConfig',
    'ClusterNetworkPolicy',
    'ClusterNodeConfig',
    'ClusterNodeConfigAdvancedMachineFeatures',
    'ClusterNodeConfigBootDisk',
    'ClusterNodeConfigConfidentialNodes',
    'ClusterNodeConfigContainerdConfig',
    'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig',
    'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig',
    'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig',
    'ClusterNodeConfigContainerdConfigWritableCgroups',
    'ClusterNodeConfigEffectiveTaint',
    'ClusterNodeConfigEphemeralStorageConfig',
    'ClusterNodeConfigEphemeralStorageLocalSsdConfig',
    'ClusterNodeConfigFastSocket',
    'ClusterNodeConfigGcfsConfig',
    'ClusterNodeConfigGuestAccelerator',
    'ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig',
    'ClusterNodeConfigGuestAcceleratorGpuSharingConfig',
    'ClusterNodeConfigGvnic',
    'ClusterNodeConfigHostMaintenancePolicy',
    'ClusterNodeConfigKubeletConfig',
    'ClusterNodeConfigKubeletConfigEvictionMinimumReclaim',
    'ClusterNodeConfigKubeletConfigEvictionSoft',
    'ClusterNodeConfigKubeletConfigEvictionSoftGracePeriod',
    'ClusterNodeConfigKubeletConfigMemoryManager',
    'ClusterNodeConfigKubeletConfigTopologyManager',
    'ClusterNodeConfigLinuxNodeConfig',
    'ClusterNodeConfigLinuxNodeConfigHugepagesConfig',
    'ClusterNodeConfigLinuxNodeConfigNodeKernelModuleLoading',
    'ClusterNodeConfigLocalNvmeSsdBlockConfig',
    'ClusterNodeConfigReservationAffinity',
    'ClusterNodeConfigSandboxConfig',
    'ClusterNodeConfigSecondaryBootDisk',
    'ClusterNodeConfigShieldedInstanceConfig',
    'ClusterNodeConfigSoleTenantConfig',
    'ClusterNodeConfigSoleTenantConfigNodeAffinity',
    'ClusterNodeConfigTaint',
    'ClusterNodeConfigWindowsNodeConfig',
    'ClusterNodeConfigWorkloadMetadataConfig',
    'ClusterNodePool',
    'ClusterNodePoolAutoConfig',
    'ClusterNodePoolAutoConfigLinuxNodeConfig',
    'ClusterNodePoolAutoConfigLinuxNodeConfigNodeKernelModuleLoading',
    'ClusterNodePoolAutoConfigNetworkTags',
    'ClusterNodePoolAutoConfigNodeKubeletConfig',
    'ClusterNodePoolAutoscaling',
    'ClusterNodePoolDefaults',
    'ClusterNodePoolDefaultsNodeConfigDefaults',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigWritableCgroups',
    'ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfig',
    'ClusterNodePoolManagement',
    'ClusterNodePoolNetworkConfig',
    'ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfig',
    'ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig',
    'ClusterNodePoolNetworkConfigNetworkPerformanceConfig',
    'ClusterNodePoolNetworkConfigPodCidrOverprovisionConfig',
    'ClusterNodePoolNodeConfig',
    'ClusterNodePoolNodeConfigAdvancedMachineFeatures',
    'ClusterNodePoolNodeConfigBootDisk',
    'ClusterNodePoolNodeConfigConfidentialNodes',
    'ClusterNodePoolNodeConfigContainerdConfig',
    'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig',
    'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig',
    'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig',
    'ClusterNodePoolNodeConfigContainerdConfigWritableCgroups',
    'ClusterNodePoolNodeConfigEffectiveTaint',
    'ClusterNodePoolNodeConfigEphemeralStorageConfig',
    'ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig',
    'ClusterNodePoolNodeConfigFastSocket',
    'ClusterNodePoolNodeConfigGcfsConfig',
    'ClusterNodePoolNodeConfigGuestAccelerator',
    'ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig',
    'ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig',
    'ClusterNodePoolNodeConfigGvnic',
    'ClusterNodePoolNodeConfigHostMaintenancePolicy',
    'ClusterNodePoolNodeConfigKubeletConfig',
    'ClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaim',
    'ClusterNodePoolNodeConfigKubeletConfigEvictionSoft',
    'ClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod',
    'ClusterNodePoolNodeConfigKubeletConfigMemoryManager',
    'ClusterNodePoolNodeConfigKubeletConfigTopologyManager',
    'ClusterNodePoolNodeConfigLinuxNodeConfig',
    'ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig',
    'ClusterNodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoading',
    'ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig',
    'ClusterNodePoolNodeConfigReservationAffinity',
    'ClusterNodePoolNodeConfigSandboxConfig',
    'ClusterNodePoolNodeConfigSecondaryBootDisk',
    'ClusterNodePoolNodeConfigShieldedInstanceConfig',
    'ClusterNodePoolNodeConfigSoleTenantConfig',
    'ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinity',
    'ClusterNodePoolNodeConfigTaint',
    'ClusterNodePoolNodeConfigWindowsNodeConfig',
    'ClusterNodePoolNodeConfigWorkloadMetadataConfig',
    'ClusterNodePoolPlacementPolicy',
    'ClusterNodePoolQueuedProvisioning',
    'ClusterNodePoolUpgradeSettings',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettings',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
    'ClusterNotificationConfig',
    'ClusterNotificationConfigPubsub',
    'ClusterNotificationConfigPubsubFilter',
    'ClusterPodAutoscaling',
    'ClusterPodSecurityPolicyConfig',
    'ClusterPrivateClusterConfig',
    'ClusterPrivateClusterConfigMasterGlobalAccessConfig',
    'ClusterProtectConfig',
    'ClusterProtectConfigWorkloadConfig',
    'ClusterRbacBindingConfig',
    'ClusterReleaseChannel',
    'ClusterResourceUsageExportConfig',
    'ClusterResourceUsageExportConfigBigqueryDestination',
    'ClusterSecretManagerConfig',
    'ClusterSecretManagerConfigRotationConfig',
    'ClusterSecretSyncConfig',
    'ClusterSecretSyncConfigRotationConfig',
    'ClusterSecurityPostureConfig',
    'ClusterServiceExternalIpsConfig',
    'ClusterTpuConfig',
    'ClusterUserManagedKeysConfig',
    'ClusterVerticalPodAutoscaling',
    'ClusterWorkloadAltsConfig',
    'ClusterWorkloadIdentityConfig',
    'NodePoolAutoscaling',
    'NodePoolManagement',
    'NodePoolNetworkConfig',
    'NodePoolNetworkConfigAdditionalNodeNetworkConfig',
    'NodePoolNetworkConfigAdditionalPodNetworkConfig',
    'NodePoolNetworkConfigNetworkPerformanceConfig',
    'NodePoolNetworkConfigPodCidrOverprovisionConfig',
    'NodePoolNodeConfig',
    'NodePoolNodeConfigAdvancedMachineFeatures',
    'NodePoolNodeConfigBootDisk',
    'NodePoolNodeConfigConfidentialNodes',
    'NodePoolNodeConfigContainerdConfig',
    'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig',
    'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig',
    'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig',
    'NodePoolNodeConfigContainerdConfigWritableCgroups',
    'NodePoolNodeConfigEffectiveTaint',
    'NodePoolNodeConfigEphemeralStorageConfig',
    'NodePoolNodeConfigEphemeralStorageLocalSsdConfig',
    'NodePoolNodeConfigFastSocket',
    'NodePoolNodeConfigGcfsConfig',
    'NodePoolNodeConfigGuestAccelerator',
    'NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig',
    'NodePoolNodeConfigGuestAcceleratorGpuSharingConfig',
    'NodePoolNodeConfigGvnic',
    'NodePoolNodeConfigHostMaintenancePolicy',
    'NodePoolNodeConfigKubeletConfig',
    'NodePoolNodeConfigKubeletConfigEvictionMinimumReclaim',
    'NodePoolNodeConfigKubeletConfigEvictionSoft',
    'NodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod',
    'NodePoolNodeConfigKubeletConfigMemoryManager',
    'NodePoolNodeConfigKubeletConfigTopologyManager',
    'NodePoolNodeConfigLinuxNodeConfig',
    'NodePoolNodeConfigLinuxNodeConfigHugepagesConfig',
    'NodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoading',
    'NodePoolNodeConfigLocalNvmeSsdBlockConfig',
    'NodePoolNodeConfigReservationAffinity',
    'NodePoolNodeConfigSandboxConfig',
    'NodePoolNodeConfigSecondaryBootDisk',
    'NodePoolNodeConfigShieldedInstanceConfig',
    'NodePoolNodeConfigSoleTenantConfig',
    'NodePoolNodeConfigSoleTenantConfigNodeAffinity',
    'NodePoolNodeConfigTaint',
    'NodePoolNodeConfigWindowsNodeConfig',
    'NodePoolNodeConfigWorkloadMetadataConfig',
    'NodePoolPlacementPolicy',
    'NodePoolQueuedProvisioning',
    'NodePoolUpgradeSettings',
    'NodePoolUpgradeSettingsBlueGreenSettings',
    'NodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy',
    'NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy',
    'GetClusterAddonsConfigResult',
    'GetClusterAddonsConfigCloudrunConfigResult',
    'GetClusterAddonsConfigConfigConnectorConfigResult',
    'GetClusterAddonsConfigDnsCacheConfigResult',
    'GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigResult',
    'GetClusterAddonsConfigGcpFilestoreCsiDriverConfigResult',
    'GetClusterAddonsConfigGcsFuseCsiDriverConfigResult',
    'GetClusterAddonsConfigGkeBackupAgentConfigResult',
    'GetClusterAddonsConfigHorizontalPodAutoscalingResult',
    'GetClusterAddonsConfigHttpLoadBalancingResult',
    'GetClusterAddonsConfigIstioConfigResult',
    'GetClusterAddonsConfigKalmConfigResult',
    'GetClusterAddonsConfigLustreCsiDriverConfigResult',
    'GetClusterAddonsConfigNetworkPolicyConfigResult',
    'GetClusterAddonsConfigParallelstoreCsiDriverConfigResult',
    'GetClusterAddonsConfigRayOperatorConfigResult',
    'GetClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigResult',
    'GetClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigResult',
    'GetClusterAddonsConfigStatefulHaConfigResult',
    'GetClusterAnonymousAuthenticationConfigResult',
    'GetClusterAuthenticatorGroupsConfigResult',
    'GetClusterBinaryAuthorizationResult',
    'GetClusterClusterAutoscalingResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultManagementResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingResult',
    'GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult',
    'GetClusterClusterAutoscalingResourceLimitResult',
    'GetClusterClusterTelemetryResult',
    'GetClusterConfidentialNodeResult',
    'GetClusterControlPlaneEndpointsConfigResult',
    'GetClusterControlPlaneEndpointsConfigDnsEndpointConfigResult',
    'GetClusterControlPlaneEndpointsConfigIpEndpointsConfigResult',
    'GetClusterCostManagementConfigResult',
    'GetClusterDatabaseEncryptionResult',
    'GetClusterDefaultSnatStatusResult',
    'GetClusterDnsConfigResult',
    'GetClusterEnableK8sBetaApiResult',
    'GetClusterEnterpriseConfigResult',
    'GetClusterFleetResult',
    'GetClusterGatewayApiConfigResult',
    'GetClusterGkeAutoUpgradeConfigResult',
    'GetClusterIdentityServiceConfigResult',
    'GetClusterIpAllocationPolicyResult',
    'GetClusterIpAllocationPolicyAdditionalIpRangesConfigResult',
    'GetClusterIpAllocationPolicyAdditionalPodRangesConfigResult',
    'GetClusterIpAllocationPolicyAutoIpamConfigResult',
    'GetClusterIpAllocationPolicyNetworkTierConfigResult',
    'GetClusterIpAllocationPolicyPodCidrOverprovisionConfigResult',
    'GetClusterLoggingConfigResult',
    'GetClusterMaintenancePolicyResult',
    'GetClusterMaintenancePolicyDailyMaintenanceWindowResult',
    'GetClusterMaintenancePolicyMaintenanceExclusionResult',
    'GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionResult',
    'GetClusterMaintenancePolicyRecurringWindowResult',
    'GetClusterMasterAuthResult',
    'GetClusterMasterAuthClientCertificateConfigResult',
    'GetClusterMasterAuthorizedNetworksConfigResult',
    'GetClusterMasterAuthorizedNetworksConfigCidrBlockResult',
    'GetClusterMeshCertificateResult',
    'GetClusterMonitoringConfigResult',
    'GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigResult',
    'GetClusterMonitoringConfigManagedPrometheusResult',
    'GetClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigResult',
    'GetClusterNetworkPerformanceConfigResult',
    'GetClusterNetworkPolicyResult',
    'GetClusterNodeConfigResult',
    'GetClusterNodeConfigAdvancedMachineFeatureResult',
    'GetClusterNodeConfigBootDiskResult',
    'GetClusterNodeConfigConfidentialNodeResult',
    'GetClusterNodeConfigContainerdConfigResult',
    'GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigResult',
    'GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult',
    'GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult',
    'GetClusterNodeConfigContainerdConfigWritableCgroupResult',
    'GetClusterNodeConfigEffectiveTaintResult',
    'GetClusterNodeConfigEphemeralStorageConfigResult',
    'GetClusterNodeConfigEphemeralStorageLocalSsdConfigResult',
    'GetClusterNodeConfigFastSocketResult',
    'GetClusterNodeConfigGcfsConfigResult',
    'GetClusterNodeConfigGuestAcceleratorResult',
    'GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult',
    'GetClusterNodeConfigGuestAcceleratorGpuSharingConfigResult',
    'GetClusterNodeConfigGvnicResult',
    'GetClusterNodeConfigHostMaintenancePolicyResult',
    'GetClusterNodeConfigKubeletConfigResult',
    'GetClusterNodeConfigKubeletConfigEvictionMinimumReclaimResult',
    'GetClusterNodeConfigKubeletConfigEvictionSoftResult',
    'GetClusterNodeConfigKubeletConfigEvictionSoftGracePeriodResult',
    'GetClusterNodeConfigKubeletConfigMemoryManagerResult',
    'GetClusterNodeConfigKubeletConfigTopologyManagerResult',
    'GetClusterNodeConfigLinuxNodeConfigResult',
    'GetClusterNodeConfigLinuxNodeConfigHugepagesConfigResult',
    'GetClusterNodeConfigLinuxNodeConfigNodeKernelModuleLoadingResult',
    'GetClusterNodeConfigLocalNvmeSsdBlockConfigResult',
    'GetClusterNodeConfigReservationAffinityResult',
    'GetClusterNodeConfigSandboxConfigResult',
    'GetClusterNodeConfigSecondaryBootDiskResult',
    'GetClusterNodeConfigShieldedInstanceConfigResult',
    'GetClusterNodeConfigSoleTenantConfigResult',
    'GetClusterNodeConfigSoleTenantConfigNodeAffinityResult',
    'GetClusterNodeConfigTaintResult',
    'GetClusterNodeConfigWindowsNodeConfigResult',
    'GetClusterNodeConfigWorkloadMetadataConfigResult',
    'GetClusterNodePoolResult',
    'GetClusterNodePoolAutoConfigResult',
    'GetClusterNodePoolAutoConfigLinuxNodeConfigResult',
    'GetClusterNodePoolAutoConfigLinuxNodeConfigNodeKernelModuleLoadingResult',
    'GetClusterNodePoolAutoConfigNetworkTagResult',
    'GetClusterNodePoolAutoConfigNodeKubeletConfigResult',
    'GetClusterNodePoolAutoscalingResult',
    'GetClusterNodePoolDefaultResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigWritableCgroupResult',
    'GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigResult',
    'GetClusterNodePoolManagementResult',
    'GetClusterNodePoolNetworkConfigResult',
    'GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigResult',
    'GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigResult',
    'GetClusterNodePoolNetworkConfigNetworkPerformanceConfigResult',
    'GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigResult',
    'GetClusterNodePoolNodeConfigResult',
    'GetClusterNodePoolNodeConfigAdvancedMachineFeatureResult',
    'GetClusterNodePoolNodeConfigBootDiskResult',
    'GetClusterNodePoolNodeConfigConfidentialNodeResult',
    'GetClusterNodePoolNodeConfigContainerdConfigResult',
    'GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigResult',
    'GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult',
    'GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult',
    'GetClusterNodePoolNodeConfigContainerdConfigWritableCgroupResult',
    'GetClusterNodePoolNodeConfigEffectiveTaintResult',
    'GetClusterNodePoolNodeConfigEphemeralStorageConfigResult',
    'GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigResult',
    'GetClusterNodePoolNodeConfigFastSocketResult',
    'GetClusterNodePoolNodeConfigGcfsConfigResult',
    'GetClusterNodePoolNodeConfigGuestAcceleratorResult',
    'GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult',
    'GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigResult',
    'GetClusterNodePoolNodeConfigGvnicResult',
    'GetClusterNodePoolNodeConfigHostMaintenancePolicyResult',
    'GetClusterNodePoolNodeConfigKubeletConfigResult',
    'GetClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaimResult',
    'GetClusterNodePoolNodeConfigKubeletConfigEvictionSoftResult',
    'GetClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriodResult',
    'GetClusterNodePoolNodeConfigKubeletConfigMemoryManagerResult',
    'GetClusterNodePoolNodeConfigKubeletConfigTopologyManagerResult',
    'GetClusterNodePoolNodeConfigLinuxNodeConfigResult',
    'GetClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigResult',
    'GetClusterNodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoadingResult',
    'GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigResult',
    'GetClusterNodePoolNodeConfigReservationAffinityResult',
    'GetClusterNodePoolNodeConfigSandboxConfigResult',
    'GetClusterNodePoolNodeConfigSecondaryBootDiskResult',
    'GetClusterNodePoolNodeConfigShieldedInstanceConfigResult',
    'GetClusterNodePoolNodeConfigSoleTenantConfigResult',
    'GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityResult',
    'GetClusterNodePoolNodeConfigTaintResult',
    'GetClusterNodePoolNodeConfigWindowsNodeConfigResult',
    'GetClusterNodePoolNodeConfigWorkloadMetadataConfigResult',
    'GetClusterNodePoolPlacementPolicyResult',
    'GetClusterNodePoolQueuedProvisioningResult',
    'GetClusterNodePoolUpgradeSettingResult',
    'GetClusterNodePoolUpgradeSettingBlueGreenSettingResult',
    'GetClusterNodePoolUpgradeSettingBlueGreenSettingAutoscaledRolloutPolicyResult',
    'GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult',
    'GetClusterNotificationConfigResult',
    'GetClusterNotificationConfigPubsubResult',
    'GetClusterNotificationConfigPubsubFilterResult',
    'GetClusterPodAutoscalingResult',
    'GetClusterPodSecurityPolicyConfigResult',
    'GetClusterPrivateClusterConfigResult',
    'GetClusterPrivateClusterConfigMasterGlobalAccessConfigResult',
    'GetClusterProtectConfigResult',
    'GetClusterProtectConfigWorkloadConfigResult',
    'GetClusterRbacBindingConfigResult',
    'GetClusterReleaseChannelResult',
    'GetClusterResourceUsageExportConfigResult',
    'GetClusterResourceUsageExportConfigBigqueryDestinationResult',
    'GetClusterSecretManagerConfigResult',
    'GetClusterSecretManagerConfigRotationConfigResult',
    'GetClusterSecretSyncConfigResult',
    'GetClusterSecretSyncConfigRotationConfigResult',
    'GetClusterSecurityPostureConfigResult',
    'GetClusterServiceExternalIpsConfigResult',
    'GetClusterTpuConfigResult',
    'GetClusterUserManagedKeysConfigResult',
    'GetClusterVerticalPodAutoscalingResult',
    'GetClusterWorkloadAltsConfigResult',
    'GetClusterWorkloadIdentityConfigResult',
]

@pulumi.output_type
class AttachedClusterAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminGroups":
            suggest = "admin_groups"
        elif key == "adminUsers":
            suggest = "admin_users"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_groups: Optional[Sequence[_builtins.str]] = None,
                 admin_users: Optional[Sequence[_builtins.str]] = None):
        """
        :param Sequence[_builtins.str] admin_groups: Groups that can perform operations as a cluster admin. A managed
               ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
               to the groups. Up to ten admin groups can be provided.
               For more info on RBAC, see
               https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        :param Sequence[_builtins.str] admin_users: Users that can perform operations as a cluster admin. A managed
               ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
               to the users. Up to ten admin users can be provided.
               For more info on RBAC, see
               https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        if admin_groups is not None:
            pulumi.set(__self__, "admin_groups", admin_groups)
        if admin_users is not None:
            pulumi.set(__self__, "admin_users", admin_users)

    @_builtins.property
    @pulumi.getter(name="adminGroups")
    def admin_groups(self) -> Optional[Sequence[_builtins.str]]:
        """
        Groups that can perform operations as a cluster admin. A managed
        ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
        to the groups. Up to ten admin groups can be provided.
        For more info on RBAC, see
        https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_groups")

    @_builtins.property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> Optional[Sequence[_builtins.str]]:
        """
        Users that can perform operations as a cluster admin. A managed
        ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
        to the users. Up to ten admin users can be provided.
        For more info on RBAC, see
        https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")


@pulumi.output_type
class AttachedClusterBinaryAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "evaluationMode":
            suggest = "evaluation_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterBinaryAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterBinaryAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterBinaryAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 evaluation_mode: Optional[_builtins.str] = None):
        """
        :param _builtins.str evaluation_mode: Configure Binary Authorization evaluation mode.
               Possible values are: `DISABLED`, `PROJECT_SINGLETON_POLICY_ENFORCE`.
        """
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @_builtins.property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[_builtins.str]:
        """
        Configure Binary Authorization evaluation mode.
        Possible values are: `DISABLED`, `PROJECT_SINGLETON_POLICY_ENFORCE`.
        """
        return pulumi.get(self, "evaluation_mode")


@pulumi.output_type
class AttachedClusterError(dict):
    def __init__(__self__, *,
                 message: Optional[_builtins.str] = None):
        """
        :param _builtins.str message: Human-friendly description of the error.
        """
        if message is not None:
            pulumi.set(__self__, "message", message)

    @_builtins.property
    @pulumi.getter
    def message(self) -> Optional[_builtins.str]:
        """
        Human-friendly description of the error.
        """
        return pulumi.get(self, "message")


@pulumi.output_type
class AttachedClusterFleet(dict):
    def __init__(__self__, *,
                 project: _builtins.str,
                 membership: Optional[_builtins.str] = None):
        """
        :param _builtins.str project: The number of the Fleet host project where this cluster will be registered.
        :param _builtins.str membership: (Output)
               The name of the managed Hub Membership resource associated to this
               cluster. Membership names are formatted as
               projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        pulumi.set(__self__, "project", project)
        if membership is not None:
            pulumi.set(__self__, "membership", membership)

    @_builtins.property
    @pulumi.getter
    def project(self) -> _builtins.str:
        """
        The number of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")

    @_builtins.property
    @pulumi.getter
    def membership(self) -> Optional[_builtins.str]:
        """
        (Output)
        The name of the managed Hub Membership resource associated to this
        cluster. Membership names are formatted as
        projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")


@pulumi.output_type
class AttachedClusterLoggingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "componentConfig":
            suggest = "component_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterLoggingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterLoggingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterLoggingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component_config: Optional['outputs.AttachedClusterLoggingConfigComponentConfig'] = None):
        """
        :param 'AttachedClusterLoggingConfigComponentConfigArgs' component_config: The configuration of the logging components
               Structure is documented below.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @_builtins.property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional['outputs.AttachedClusterLoggingConfigComponentConfig']:
        """
        The configuration of the logging components
        Structure is documented below.
        """
        return pulumi.get(self, "component_config")


@pulumi.output_type
class AttachedClusterLoggingConfigComponentConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableComponents":
            suggest = "enable_components"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterLoggingConfigComponentConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_components: Optional[Sequence[_builtins.str]] = None):
        """
        :param Sequence[_builtins.str] enable_components: The components to be enabled.
               Each value may be one of: `SYSTEM_COMPONENTS`, `WORKLOADS`.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @_builtins.property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[Sequence[_builtins.str]]:
        """
        The components to be enabled.
        Each value may be one of: `SYSTEM_COMPONENTS`, `WORKLOADS`.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class AttachedClusterMonitoringConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "managedPrometheusConfig":
            suggest = "managed_prometheus_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterMonitoringConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterMonitoringConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterMonitoringConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 managed_prometheus_config: Optional['outputs.AttachedClusterMonitoringConfigManagedPrometheusConfig'] = None):
        """
        :param 'AttachedClusterMonitoringConfigManagedPrometheusConfigArgs' managed_prometheus_config: Enable Google Cloud Managed Service for Prometheus in the cluster.
               Structure is documented below.
        """
        if managed_prometheus_config is not None:
            pulumi.set(__self__, "managed_prometheus_config", managed_prometheus_config)

    @_builtins.property
    @pulumi.getter(name="managedPrometheusConfig")
    def managed_prometheus_config(self) -> Optional['outputs.AttachedClusterMonitoringConfigManagedPrometheusConfig']:
        """
        Enable Google Cloud Managed Service for Prometheus in the cluster.
        Structure is documented below.
        """
        return pulumi.get(self, "managed_prometheus_config")


@pulumi.output_type
class AttachedClusterMonitoringConfigManagedPrometheusConfig(dict):
    def __init__(__self__, *,
                 enabled: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool enabled: Enable Managed Collection.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> Optional[_builtins.bool]:
        """
        Enable Managed Collection.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class AttachedClusterOidcConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "issuerUrl":
            suggest = "issuer_url"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterOidcConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterOidcConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterOidcConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 issuer_url: _builtins.str,
                 jwks: Optional[_builtins.str] = None):
        """
        :param _builtins.str issuer_url: A JSON Web Token (JWT) issuer URI. `issuer` must start with `https://`
        :param _builtins.str jwks: OIDC verification keys in JWKS format (RFC 7517).
        """
        pulumi.set(__self__, "issuer_url", issuer_url)
        if jwks is not None:
            pulumi.set(__self__, "jwks", jwks)

    @_builtins.property
    @pulumi.getter(name="issuerUrl")
    def issuer_url(self) -> _builtins.str:
        """
        A JSON Web Token (JWT) issuer URI. `issuer` must start with `https://`
        """
        return pulumi.get(self, "issuer_url")

    @_builtins.property
    @pulumi.getter
    def jwks(self) -> Optional[_builtins.str]:
        """
        OIDC verification keys in JWKS format (RFC 7517).
        """
        return pulumi.get(self, "jwks")


@pulumi.output_type
class AttachedClusterProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kubernetesSecret":
            suggest = "kubernetes_secret"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kubernetes_secret: Optional['outputs.AttachedClusterProxyConfigKubernetesSecret'] = None):
        """
        :param 'AttachedClusterProxyConfigKubernetesSecretArgs' kubernetes_secret: The Kubernetes Secret resource that contains the HTTP(S) proxy configuration.
               Structure is documented below.
        """
        if kubernetes_secret is not None:
            pulumi.set(__self__, "kubernetes_secret", kubernetes_secret)

    @_builtins.property
    @pulumi.getter(name="kubernetesSecret")
    def kubernetes_secret(self) -> Optional['outputs.AttachedClusterProxyConfigKubernetesSecret']:
        """
        The Kubernetes Secret resource that contains the HTTP(S) proxy configuration.
        Structure is documented below.
        """
        return pulumi.get(self, "kubernetes_secret")


@pulumi.output_type
class AttachedClusterProxyConfigKubernetesSecret(dict):
    def __init__(__self__, *,
                 name: _builtins.str,
                 namespace: _builtins.str):
        """
        :param _builtins.str name: Name of the kubernetes secret containing the proxy config.
        :param _builtins.str namespace: Namespace of the kubernetes secret containing the proxy config.
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "namespace", namespace)

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Name of the kubernetes secret containing the proxy config.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def namespace(self) -> _builtins.str:
        """
        Namespace of the kubernetes secret containing the proxy config.
        """
        return pulumi.get(self, "namespace")


@pulumi.output_type
class AttachedClusterSecurityPostureConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "vulnerabilityMode":
            suggest = "vulnerability_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterSecurityPostureConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterSecurityPostureConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterSecurityPostureConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 vulnerability_mode: _builtins.str):
        """
        :param _builtins.str vulnerability_mode: Sets the mode of the Kubernetes security posture API's workload vulnerability scanning.
               Possible values are: `VULNERABILITY_DISABLED`, `VULNERABILITY_ENTERPRISE`.
        """
        pulumi.set(__self__, "vulnerability_mode", vulnerability_mode)

    @_builtins.property
    @pulumi.getter(name="vulnerabilityMode")
    def vulnerability_mode(self) -> _builtins.str:
        """
        Sets the mode of the Kubernetes security posture API's workload vulnerability scanning.
        Possible values are: `VULNERABILITY_DISABLED`, `VULNERABILITY_ENTERPRISE`.
        """
        return pulumi.get(self, "vulnerability_mode")


@pulumi.output_type
class AttachedClusterWorkloadIdentityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "identityProvider":
            suggest = "identity_provider"
        elif key == "issuerUri":
            suggest = "issuer_uri"
        elif key == "workloadPool":
            suggest = "workload_pool"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AttachedClusterWorkloadIdentityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AttachedClusterWorkloadIdentityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AttachedClusterWorkloadIdentityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 identity_provider: Optional[_builtins.str] = None,
                 issuer_uri: Optional[_builtins.str] = None,
                 workload_pool: Optional[_builtins.str] = None):
        """
        :param _builtins.str identity_provider: The ID of the OIDC Identity Provider (IdP) associated to
               the Workload Identity Pool.
        :param _builtins.str issuer_uri: The OIDC issuer URL for this cluster.
        :param _builtins.str workload_pool: The Workload Identity Pool associated to the cluster.
        """
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @_builtins.property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[_builtins.str]:
        """
        The ID of the OIDC Identity Provider (IdP) associated to
        the Workload Identity Pool.
        """
        return pulumi.get(self, "identity_provider")

    @_builtins.property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[_builtins.str]:
        """
        The OIDC issuer URL for this cluster.
        """
        return pulumi.get(self, "issuer_uri")

    @_builtins.property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[_builtins.str]:
        """
        The Workload Identity Pool associated to the cluster.
        """
        return pulumi.get(self, "workload_pool")


@pulumi.output_type
class AwsClusterAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminUsers":
            suggest = "admin_users"
        elif key == "adminGroups":
            suggest = "admin_groups"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_users: Sequence['outputs.AwsClusterAuthorizationAdminUser'],
                 admin_groups: Optional[Sequence['outputs.AwsClusterAuthorizationAdminGroup']] = None):
        """
        :param Sequence['AwsClusterAuthorizationAdminUserArgs'] admin_users: Users to perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        :param Sequence['AwsClusterAuthorizationAdminGroupArgs'] admin_groups: Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        pulumi.set(__self__, "admin_users", admin_users)
        if admin_groups is not None:
            pulumi.set(__self__, "admin_groups", admin_groups)

    @_builtins.property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> Sequence['outputs.AwsClusterAuthorizationAdminUser']:
        """
        Users to perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")

    @_builtins.property
    @pulumi.getter(name="adminGroups")
    def admin_groups(self) -> Optional[Sequence['outputs.AwsClusterAuthorizationAdminGroup']]:
        """
        Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_groups")


@pulumi.output_type
class AwsClusterAuthorizationAdminGroup(dict):
    def __init__(__self__, *,
                 group: _builtins.str):
        """
        :param _builtins.str group: The name of the group, e.g. `my-group@domain.com`.
        """
        pulumi.set(__self__, "group", group)

    @_builtins.property
    @pulumi.getter
    def group(self) -> _builtins.str:
        """
        The name of the group, e.g. `my-group@domain.com`.
        """
        return pulumi.get(self, "group")


@pulumi.output_type
class AwsClusterAuthorizationAdminUser(dict):
    def __init__(__self__, *,
                 username: _builtins.str):
        """
        :param _builtins.str username: The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        pulumi.set(__self__, "username", username)

    @_builtins.property
    @pulumi.getter
    def username(self) -> _builtins.str:
        """
        The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class AwsClusterBinaryAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "evaluationMode":
            suggest = "evaluation_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterBinaryAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterBinaryAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterBinaryAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 evaluation_mode: Optional[_builtins.str] = None):
        """
        :param _builtins.str evaluation_mode: Mode of operation for Binary Authorization policy evaluation. Possible values: DISABLED, PROJECT_SINGLETON_POLICY_ENFORCE
        """
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @_builtins.property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[_builtins.str]:
        """
        Mode of operation for Binary Authorization policy evaluation. Possible values: DISABLED, PROJECT_SINGLETON_POLICY_ENFORCE
        """
        return pulumi.get(self, "evaluation_mode")


@pulumi.output_type
class AwsClusterControlPlane(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "awsServicesAuthentication":
            suggest = "aws_services_authentication"
        elif key == "configEncryption":
            suggest = "config_encryption"
        elif key == "databaseEncryption":
            suggest = "database_encryption"
        elif key == "iamInstanceProfile":
            suggest = "iam_instance_profile"
        elif key == "subnetIds":
            suggest = "subnet_ids"
        elif key == "instancePlacement":
            suggest = "instance_placement"
        elif key == "instanceType":
            suggest = "instance_type"
        elif key == "mainVolume":
            suggest = "main_volume"
        elif key == "proxyConfig":
            suggest = "proxy_config"
        elif key == "rootVolume":
            suggest = "root_volume"
        elif key == "securityGroupIds":
            suggest = "security_group_ids"
        elif key == "sshConfig":
            suggest = "ssh_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlane. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlane.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlane.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 aws_services_authentication: 'outputs.AwsClusterControlPlaneAwsServicesAuthentication',
                 config_encryption: 'outputs.AwsClusterControlPlaneConfigEncryption',
                 database_encryption: 'outputs.AwsClusterControlPlaneDatabaseEncryption',
                 iam_instance_profile: _builtins.str,
                 subnet_ids: Sequence[_builtins.str],
                 version: _builtins.str,
                 instance_placement: Optional['outputs.AwsClusterControlPlaneInstancePlacement'] = None,
                 instance_type: Optional[_builtins.str] = None,
                 main_volume: Optional['outputs.AwsClusterControlPlaneMainVolume'] = None,
                 proxy_config: Optional['outputs.AwsClusterControlPlaneProxyConfig'] = None,
                 root_volume: Optional['outputs.AwsClusterControlPlaneRootVolume'] = None,
                 security_group_ids: Optional[Sequence[_builtins.str]] = None,
                 ssh_config: Optional['outputs.AwsClusterControlPlaneSshConfig'] = None,
                 tags: Optional[Mapping[str, _builtins.str]] = None):
        """
        :param 'AwsClusterControlPlaneAwsServicesAuthenticationArgs' aws_services_authentication: Authentication configuration for management of AWS resources.
        :param 'AwsClusterControlPlaneConfigEncryptionArgs' config_encryption: The ARN of the AWS KMS key used to encrypt cluster configuration.
        :param 'AwsClusterControlPlaneDatabaseEncryptionArgs' database_encryption: The ARN of the AWS KMS key used to encrypt cluster secrets.
        :param _builtins.str iam_instance_profile: The name of the AWS IAM instance pofile to assign to each control plane replica.
        :param Sequence[_builtins.str] subnet_ids: The list of subnets where control plane replicas will run. A replica will be provisioned on each subnet and up to three values can be provided. Each subnet must be in a different AWS Availability Zone (AZ).
        :param _builtins.str version: The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling .
        :param 'AwsClusterControlPlaneInstancePlacementArgs' instance_placement: Details of placement information for an instance.
        :param _builtins.str instance_type: Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        :param 'AwsClusterControlPlaneMainVolumeArgs' main_volume: Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 8 GiB with the GP2 volume type.
        :param 'AwsClusterControlPlaneProxyConfigArgs' proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param 'AwsClusterControlPlaneRootVolumeArgs' root_volume: Optional. Configuration related to the root volume provisioned for each control plane replica. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        :param Sequence[_builtins.str] security_group_ids: Optional. The IDs of additional security groups to add to control plane replicas. The Anthos Multi-Cloud API will automatically create and manage security groups with the minimum rules needed for a functioning cluster.
        :param 'AwsClusterControlPlaneSshConfigArgs' ssh_config: Optional. SSH configuration for how to access the underlying control plane machines.
        :param Mapping[str, _builtins.str] tags: Optional. A set of AWS resource tags to propagate to all underlying managed AWS resources. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        pulumi.set(__self__, "aws_services_authentication", aws_services_authentication)
        pulumi.set(__self__, "config_encryption", config_encryption)
        pulumi.set(__self__, "database_encryption", database_encryption)
        pulumi.set(__self__, "iam_instance_profile", iam_instance_profile)
        pulumi.set(__self__, "subnet_ids", subnet_ids)
        pulumi.set(__self__, "version", version)
        if instance_placement is not None:
            pulumi.set(__self__, "instance_placement", instance_placement)
        if instance_type is not None:
            pulumi.set(__self__, "instance_type", instance_type)
        if main_volume is not None:
            pulumi.set(__self__, "main_volume", main_volume)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if security_group_ids is not None:
            pulumi.set(__self__, "security_group_ids", security_group_ids)
        if ssh_config is not None:
            pulumi.set(__self__, "ssh_config", ssh_config)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @_builtins.property
    @pulumi.getter(name="awsServicesAuthentication")
    def aws_services_authentication(self) -> 'outputs.AwsClusterControlPlaneAwsServicesAuthentication':
        """
        Authentication configuration for management of AWS resources.
        """
        return pulumi.get(self, "aws_services_authentication")

    @_builtins.property
    @pulumi.getter(name="configEncryption")
    def config_encryption(self) -> 'outputs.AwsClusterControlPlaneConfigEncryption':
        """
        The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        return pulumi.get(self, "config_encryption")

    @_builtins.property
    @pulumi.getter(name="databaseEncryption")
    def database_encryption(self) -> 'outputs.AwsClusterControlPlaneDatabaseEncryption':
        """
        The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        return pulumi.get(self, "database_encryption")

    @_builtins.property
    @pulumi.getter(name="iamInstanceProfile")
    def iam_instance_profile(self) -> _builtins.str:
        """
        The name of the AWS IAM instance pofile to assign to each control plane replica.
        """
        return pulumi.get(self, "iam_instance_profile")

    @_builtins.property
    @pulumi.getter(name="subnetIds")
    def subnet_ids(self) -> Sequence[_builtins.str]:
        """
        The list of subnets where control plane replicas will run. A replica will be provisioned on each subnet and up to three values can be provided. Each subnet must be in a different AWS Availability Zone (AZ).
        """
        return pulumi.get(self, "subnet_ids")

    @_builtins.property
    @pulumi.getter
    def version(self) -> _builtins.str:
        """
        The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling .
        """
        return pulumi.get(self, "version")

    @_builtins.property
    @pulumi.getter(name="instancePlacement")
    def instance_placement(self) -> Optional['outputs.AwsClusterControlPlaneInstancePlacement']:
        """
        Details of placement information for an instance.
        """
        return pulumi.get(self, "instance_placement")

    @_builtins.property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> Optional[_builtins.str]:
        """
        Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        """
        return pulumi.get(self, "instance_type")

    @_builtins.property
    @pulumi.getter(name="mainVolume")
    def main_volume(self) -> Optional['outputs.AwsClusterControlPlaneMainVolume']:
        """
        Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 8 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "main_volume")

    @_builtins.property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional['outputs.AwsClusterControlPlaneProxyConfig']:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @_builtins.property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional['outputs.AwsClusterControlPlaneRootVolume']:
        """
        Optional. Configuration related to the root volume provisioned for each control plane replica. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "root_volume")

    @_builtins.property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> Optional[Sequence[_builtins.str]]:
        """
        Optional. The IDs of additional security groups to add to control plane replicas. The Anthos Multi-Cloud API will automatically create and manage security groups with the minimum rules needed for a functioning cluster.
        """
        return pulumi.get(self, "security_group_ids")

    @_builtins.property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> Optional['outputs.AwsClusterControlPlaneSshConfig']:
        """
        Optional. SSH configuration for how to access the underlying control plane machines.
        """
        return pulumi.get(self, "ssh_config")

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        Optional. A set of AWS resource tags to propagate to all underlying managed AWS resources. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")


@pulumi.output_type
class AwsClusterControlPlaneAwsServicesAuthentication(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "roleArn":
            suggest = "role_arn"
        elif key == "roleSessionName":
            suggest = "role_session_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneAwsServicesAuthentication. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneAwsServicesAuthentication.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneAwsServicesAuthentication.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 role_arn: _builtins.str,
                 role_session_name: Optional[_builtins.str] = None):
        """
        :param _builtins.str role_arn: The Amazon Resource Name (ARN) of the role that the Anthos Multi-Cloud API will assume when managing AWS resources on your account.
        :param _builtins.str role_session_name: Optional. An identifier for the assumed role session. When unspecified, it defaults to `multicloud-service-agent`.
        """
        pulumi.set(__self__, "role_arn", role_arn)
        if role_session_name is not None:
            pulumi.set(__self__, "role_session_name", role_session_name)

    @_builtins.property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> _builtins.str:
        """
        The Amazon Resource Name (ARN) of the role that the Anthos Multi-Cloud API will assume when managing AWS resources on your account.
        """
        return pulumi.get(self, "role_arn")

    @_builtins.property
    @pulumi.getter(name="roleSessionName")
    def role_session_name(self) -> Optional[_builtins.str]:
        """
        Optional. An identifier for the assumed role session. When unspecified, it defaults to `multicloud-service-agent`.
        """
        return pulumi.get(self, "role_session_name")


@pulumi.output_type
class AwsClusterControlPlaneConfigEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneConfigEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneConfigEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneConfigEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kms_key_arn: _builtins.str):
        """
        :param _builtins.str kms_key_arn: The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @_builtins.property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> _builtins.str:
        """
        The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        return pulumi.get(self, "kms_key_arn")


@pulumi.output_type
class AwsClusterControlPlaneDatabaseEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneDatabaseEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneDatabaseEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneDatabaseEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kms_key_arn: _builtins.str):
        """
        :param _builtins.str kms_key_arn: The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @_builtins.property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> _builtins.str:
        """
        The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        return pulumi.get(self, "kms_key_arn")


@pulumi.output_type
class AwsClusterControlPlaneInstancePlacement(dict):
    def __init__(__self__, *,
                 tenancy: Optional[_builtins.str] = None):
        """
        :param _builtins.str tenancy: The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        if tenancy is not None:
            pulumi.set(__self__, "tenancy", tenancy)

    @_builtins.property
    @pulumi.getter
    def tenancy(self) -> Optional[_builtins.str]:
        """
        The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        return pulumi.get(self, "tenancy")


@pulumi.output_type
class AwsClusterControlPlaneMainVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"
        elif key == "sizeGib":
            suggest = "size_gib"
        elif key == "volumeType":
            suggest = "volume_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneMainVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneMainVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneMainVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 iops: Optional[_builtins.int] = None,
                 kms_key_arn: Optional[_builtins.str] = None,
                 size_gib: Optional[_builtins.int] = None,
                 throughput: Optional[_builtins.int] = None,
                 volume_type: Optional[_builtins.str] = None):
        """
        :param _builtins.int iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param _builtins.str kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param _builtins.int size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param _builtins.int throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        :param _builtins.str volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @_builtins.property
    @pulumi.getter
    def iops(self) -> Optional[_builtins.int]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @_builtins.property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[_builtins.str]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @_builtins.property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[_builtins.int]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @_builtins.property
    @pulumi.getter
    def throughput(self) -> Optional[_builtins.int]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        """
        return pulumi.get(self, "throughput")

    @_builtins.property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[_builtins.str]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")


@pulumi.output_type
class AwsClusterControlPlaneProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretArn":
            suggest = "secret_arn"
        elif key == "secretVersion":
            suggest = "secret_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_arn: _builtins.str,
                 secret_version: _builtins.str):
        """
        :param _builtins.str secret_arn: The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        :param _builtins.str secret_version: The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        pulumi.set(__self__, "secret_arn", secret_arn)
        pulumi.set(__self__, "secret_version", secret_version)

    @_builtins.property
    @pulumi.getter(name="secretArn")
    def secret_arn(self) -> _builtins.str:
        """
        The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_arn")

    @_builtins.property
    @pulumi.getter(name="secretVersion")
    def secret_version(self) -> _builtins.str:
        """
        The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_version")


@pulumi.output_type
class AwsClusterControlPlaneRootVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"
        elif key == "sizeGib":
            suggest = "size_gib"
        elif key == "volumeType":
            suggest = "volume_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneRootVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneRootVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneRootVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 iops: Optional[_builtins.int] = None,
                 kms_key_arn: Optional[_builtins.str] = None,
                 size_gib: Optional[_builtins.int] = None,
                 throughput: Optional[_builtins.int] = None,
                 volume_type: Optional[_builtins.str] = None):
        """
        :param _builtins.int iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param _builtins.str kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param _builtins.int size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param _builtins.int throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        :param _builtins.str volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @_builtins.property
    @pulumi.getter
    def iops(self) -> Optional[_builtins.int]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @_builtins.property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[_builtins.str]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @_builtins.property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[_builtins.int]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @_builtins.property
    @pulumi.getter
    def throughput(self) -> Optional[_builtins.int]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        """
        return pulumi.get(self, "throughput")

    @_builtins.property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[_builtins.str]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")


@pulumi.output_type
class AwsClusterControlPlaneSshConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ec2KeyPair":
            suggest = "ec2_key_pair"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterControlPlaneSshConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterControlPlaneSshConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterControlPlaneSshConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ec2_key_pair: _builtins.str):
        """
        :param _builtins.str ec2_key_pair: The name of the EC2 key pair used to login into cluster machines.
        """
        pulumi.set(__self__, "ec2_key_pair", ec2_key_pair)

    @_builtins.property
    @pulumi.getter(name="ec2KeyPair")
    def ec2_key_pair(self) -> _builtins.str:
        """
        The name of the EC2 key pair used to login into cluster machines.
        """
        return pulumi.get(self, "ec2_key_pair")


@pulumi.output_type
class AwsClusterFleet(dict):
    def __init__(__self__, *,
                 membership: Optional[_builtins.str] = None,
                 project: Optional[_builtins.str] = None):
        """
        :param _builtins.str membership: The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        :param _builtins.str project: The number of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @_builtins.property
    @pulumi.getter
    def membership(self) -> Optional[_builtins.str]:
        """
        The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")

    @_builtins.property
    @pulumi.getter
    def project(self) -> Optional[_builtins.str]:
        """
        The number of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")


@pulumi.output_type
class AwsClusterLoggingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "componentConfig":
            suggest = "component_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterLoggingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterLoggingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterLoggingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component_config: Optional['outputs.AwsClusterLoggingConfigComponentConfig'] = None):
        """
        :param 'AwsClusterLoggingConfigComponentConfigArgs' component_config: Configuration of the logging components.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @_builtins.property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional['outputs.AwsClusterLoggingConfigComponentConfig']:
        """
        Configuration of the logging components.
        """
        return pulumi.get(self, "component_config")


@pulumi.output_type
class AwsClusterLoggingConfigComponentConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableComponents":
            suggest = "enable_components"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterLoggingConfigComponentConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_components: Optional[Sequence[_builtins.str]] = None):
        """
        :param Sequence[_builtins.str] enable_components: Components of the logging configuration to be enabled.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @_builtins.property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[Sequence[_builtins.str]]:
        """
        Components of the logging configuration to be enabled.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class AwsClusterNetworking(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "podAddressCidrBlocks":
            suggest = "pod_address_cidr_blocks"
        elif key == "serviceAddressCidrBlocks":
            suggest = "service_address_cidr_blocks"
        elif key == "vpcId":
            suggest = "vpc_id"
        elif key == "perNodePoolSgRulesDisabled":
            suggest = "per_node_pool_sg_rules_disabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterNetworking. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterNetworking.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterNetworking.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pod_address_cidr_blocks: Sequence[_builtins.str],
                 service_address_cidr_blocks: Sequence[_builtins.str],
                 vpc_id: _builtins.str,
                 per_node_pool_sg_rules_disabled: Optional[_builtins.bool] = None):
        """
        :param Sequence[_builtins.str] pod_address_cidr_blocks: All pods in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param Sequence[_builtins.str] service_address_cidr_blocks: All services in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param _builtins.str vpc_id: The VPC associated with the cluster. All component clusters (i.e. control plane and node pools) run on a single VPC. This field cannot be changed after creation.
               
               - - -
        :param _builtins.bool per_node_pool_sg_rules_disabled: Disable the per node pool subnet security group rules on the control plane security group. When set to true, you must also provide one or more security groups that ensure node pools are able to send requests to the control plane on TCP/443 and TCP/8132. Failure to do so may result in unavailable node pools.
        """
        pulumi.set(__self__, "pod_address_cidr_blocks", pod_address_cidr_blocks)
        pulumi.set(__self__, "service_address_cidr_blocks", service_address_cidr_blocks)
        pulumi.set(__self__, "vpc_id", vpc_id)
        if per_node_pool_sg_rules_disabled is not None:
            pulumi.set(__self__, "per_node_pool_sg_rules_disabled", per_node_pool_sg_rules_disabled)

    @_builtins.property
    @pulumi.getter(name="podAddressCidrBlocks")
    def pod_address_cidr_blocks(self) -> Sequence[_builtins.str]:
        """
        All pods in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "pod_address_cidr_blocks")

    @_builtins.property
    @pulumi.getter(name="serviceAddressCidrBlocks")
    def service_address_cidr_blocks(self) -> Sequence[_builtins.str]:
        """
        All services in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "service_address_cidr_blocks")

    @_builtins.property
    @pulumi.getter(name="vpcId")
    def vpc_id(self) -> _builtins.str:
        """
        The VPC associated with the cluster. All component clusters (i.e. control plane and node pools) run on a single VPC. This field cannot be changed after creation.

        - - -
        """
        return pulumi.get(self, "vpc_id")

    @_builtins.property
    @pulumi.getter(name="perNodePoolSgRulesDisabled")
    def per_node_pool_sg_rules_disabled(self) -> Optional[_builtins.bool]:
        """
        Disable the per node pool subnet security group rules on the control plane security group. When set to true, you must also provide one or more security groups that ensure node pools are able to send requests to the control plane on TCP/443 and TCP/8132. Failure to do so may result in unavailable node pools.
        """
        return pulumi.get(self, "per_node_pool_sg_rules_disabled")


@pulumi.output_type
class AwsClusterWorkloadIdentityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "identityProvider":
            suggest = "identity_provider"
        elif key == "issuerUri":
            suggest = "issuer_uri"
        elif key == "workloadPool":
            suggest = "workload_pool"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsClusterWorkloadIdentityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsClusterWorkloadIdentityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsClusterWorkloadIdentityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 identity_provider: Optional[_builtins.str] = None,
                 issuer_uri: Optional[_builtins.str] = None,
                 workload_pool: Optional[_builtins.str] = None):
        """
        :param _builtins.str identity_provider: The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        :param _builtins.str issuer_uri: The OIDC issuer URL for this cluster.
        :param _builtins.str workload_pool: The Workload Identity Pool associated to the cluster.
        """
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @_builtins.property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[_builtins.str]:
        """
        The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        """
        return pulumi.get(self, "identity_provider")

    @_builtins.property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[_builtins.str]:
        """
        The OIDC issuer URL for this cluster.
        """
        return pulumi.get(self, "issuer_uri")

    @_builtins.property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[_builtins.str]:
        """
        The Workload Identity Pool associated to the cluster.
        """
        return pulumi.get(self, "workload_pool")


@pulumi.output_type
class AwsNodePoolAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxNodeCount":
            suggest = "max_node_count"
        elif key == "minNodeCount":
            suggest = "min_node_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_node_count: _builtins.int,
                 min_node_count: _builtins.int):
        """
        :param _builtins.int max_node_count: Maximum number of nodes in the NodePool. Must be >= min_node_count.
        :param _builtins.int min_node_count: Minimum number of nodes in the NodePool. Must be >= 1 and <= max_node_count.
        """
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)

    @_builtins.property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> _builtins.int:
        """
        Maximum number of nodes in the NodePool. Must be >= min_node_count.
        """
        return pulumi.get(self, "max_node_count")

    @_builtins.property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> _builtins.int:
        """
        Minimum number of nodes in the NodePool. Must be >= 1 and <= max_node_count.
        """
        return pulumi.get(self, "min_node_count")


@pulumi.output_type
class AwsNodePoolConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "configEncryption":
            suggest = "config_encryption"
        elif key == "iamInstanceProfile":
            suggest = "iam_instance_profile"
        elif key == "autoscalingMetricsCollection":
            suggest = "autoscaling_metrics_collection"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "instancePlacement":
            suggest = "instance_placement"
        elif key == "instanceType":
            suggest = "instance_type"
        elif key == "proxyConfig":
            suggest = "proxy_config"
        elif key == "rootVolume":
            suggest = "root_volume"
        elif key == "securityGroupIds":
            suggest = "security_group_ids"
        elif key == "spotConfig":
            suggest = "spot_config"
        elif key == "sshConfig":
            suggest = "ssh_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 config_encryption: 'outputs.AwsNodePoolConfigConfigEncryption',
                 iam_instance_profile: _builtins.str,
                 autoscaling_metrics_collection: Optional['outputs.AwsNodePoolConfigAutoscalingMetricsCollection'] = None,
                 image_type: Optional[_builtins.str] = None,
                 instance_placement: Optional['outputs.AwsNodePoolConfigInstancePlacement'] = None,
                 instance_type: Optional[_builtins.str] = None,
                 labels: Optional[Mapping[str, _builtins.str]] = None,
                 proxy_config: Optional['outputs.AwsNodePoolConfigProxyConfig'] = None,
                 root_volume: Optional['outputs.AwsNodePoolConfigRootVolume'] = None,
                 security_group_ids: Optional[Sequence[_builtins.str]] = None,
                 spot_config: Optional['outputs.AwsNodePoolConfigSpotConfig'] = None,
                 ssh_config: Optional['outputs.AwsNodePoolConfigSshConfig'] = None,
                 tags: Optional[Mapping[str, _builtins.str]] = None,
                 taints: Optional[Sequence['outputs.AwsNodePoolConfigTaint']] = None):
        """
        :param 'AwsNodePoolConfigConfigEncryptionArgs' config_encryption: The ARN of the AWS KMS key used to encrypt node pool configuration.
        :param _builtins.str iam_instance_profile: The name of the AWS IAM role assigned to nodes in the pool.
        :param 'AwsNodePoolConfigAutoscalingMetricsCollectionArgs' autoscaling_metrics_collection: Optional. Configuration related to CloudWatch metrics collection on the Auto Scaling group of the node pool. When unspecified, metrics collection is disabled.
        :param _builtins.str image_type: The OS image type to use on node pool instances.
        :param 'AwsNodePoolConfigInstancePlacementArgs' instance_placement: Details of placement information for an instance.
        :param _builtins.str instance_type: Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        :param Mapping[str, _builtins.str] labels: Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        :param 'AwsNodePoolConfigProxyConfigArgs' proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param 'AwsNodePoolConfigRootVolumeArgs' root_volume: Optional. Template for the root volume provisioned for node pool nodes. Volumes will be provisioned in the availability zone assigned to the node pool subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        :param Sequence[_builtins.str] security_group_ids: Optional. The IDs of additional security groups to add to nodes in this pool. The manager will automatically create security groups with minimum rules needed for a functioning cluster.
        :param 'AwsNodePoolConfigSpotConfigArgs' spot_config: Optional. When specified, the node pool will provision Spot instances from the set of spot_config.instance_types. This field is mutually exclusive with `instance_type`
        :param 'AwsNodePoolConfigSshConfigArgs' ssh_config: Optional. The SSH configuration.
        :param Mapping[str, _builtins.str] tags: Optional. Key/value metadata to assign to each underlying AWS resource. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        :param Sequence['AwsNodePoolConfigTaintArgs'] taints: Optional. The initial taints assigned to nodes of this node pool.
        """
        pulumi.set(__self__, "config_encryption", config_encryption)
        pulumi.set(__self__, "iam_instance_profile", iam_instance_profile)
        if autoscaling_metrics_collection is not None:
            pulumi.set(__self__, "autoscaling_metrics_collection", autoscaling_metrics_collection)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if instance_placement is not None:
            pulumi.set(__self__, "instance_placement", instance_placement)
        if instance_type is not None:
            pulumi.set(__self__, "instance_type", instance_type)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if security_group_ids is not None:
            pulumi.set(__self__, "security_group_ids", security_group_ids)
        if spot_config is not None:
            pulumi.set(__self__, "spot_config", spot_config)
        if ssh_config is not None:
            pulumi.set(__self__, "ssh_config", ssh_config)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)

    @_builtins.property
    @pulumi.getter(name="configEncryption")
    def config_encryption(self) -> 'outputs.AwsNodePoolConfigConfigEncryption':
        """
        The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        return pulumi.get(self, "config_encryption")

    @_builtins.property
    @pulumi.getter(name="iamInstanceProfile")
    def iam_instance_profile(self) -> _builtins.str:
        """
        The name of the AWS IAM role assigned to nodes in the pool.
        """
        return pulumi.get(self, "iam_instance_profile")

    @_builtins.property
    @pulumi.getter(name="autoscalingMetricsCollection")
    def autoscaling_metrics_collection(self) -> Optional['outputs.AwsNodePoolConfigAutoscalingMetricsCollection']:
        """
        Optional. Configuration related to CloudWatch metrics collection on the Auto Scaling group of the node pool. When unspecified, metrics collection is disabled.
        """
        return pulumi.get(self, "autoscaling_metrics_collection")

    @_builtins.property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[_builtins.str]:
        """
        The OS image type to use on node pool instances.
        """
        return pulumi.get(self, "image_type")

    @_builtins.property
    @pulumi.getter(name="instancePlacement")
    def instance_placement(self) -> Optional['outputs.AwsNodePoolConfigInstancePlacement']:
        """
        Details of placement information for an instance.
        """
        return pulumi.get(self, "instance_placement")

    @_builtins.property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> Optional[_builtins.str]:
        """
        Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        """
        return pulumi.get(self, "instance_type")

    @_builtins.property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        """
        return pulumi.get(self, "labels")

    @_builtins.property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional['outputs.AwsNodePoolConfigProxyConfig']:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @_builtins.property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional['outputs.AwsNodePoolConfigRootVolume']:
        """
        Optional. Template for the root volume provisioned for node pool nodes. Volumes will be provisioned in the availability zone assigned to the node pool subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "root_volume")

    @_builtins.property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> Optional[Sequence[_builtins.str]]:
        """
        Optional. The IDs of additional security groups to add to nodes in this pool. The manager will automatically create security groups with minimum rules needed for a functioning cluster.
        """
        return pulumi.get(self, "security_group_ids")

    @_builtins.property
    @pulumi.getter(name="spotConfig")
    def spot_config(self) -> Optional['outputs.AwsNodePoolConfigSpotConfig']:
        """
        Optional. When specified, the node pool will provision Spot instances from the set of spot_config.instance_types. This field is mutually exclusive with `instance_type`
        """
        return pulumi.get(self, "spot_config")

    @_builtins.property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> Optional['outputs.AwsNodePoolConfigSshConfig']:
        """
        Optional. The SSH configuration.
        """
        return pulumi.get(self, "ssh_config")

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        Optional. Key/value metadata to assign to each underlying AWS resource. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")

    @_builtins.property
    @pulumi.getter
    def taints(self) -> Optional[Sequence['outputs.AwsNodePoolConfigTaint']]:
        """
        Optional. The initial taints assigned to nodes of this node pool.
        """
        return pulumi.get(self, "taints")


@pulumi.output_type
class AwsNodePoolConfigAutoscalingMetricsCollection(dict):
    def __init__(__self__, *,
                 granularity: _builtins.str,
                 metrics: Optional[Sequence[_builtins.str]] = None):
        """
        :param _builtins.str granularity: The frequency at which EC2 Auto Scaling sends aggregated data to AWS CloudWatch. The only valid value is "1Minute".
        :param Sequence[_builtins.str] metrics: The metrics to enable. For a list of valid metrics, see https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html. If you specify granularity and don't specify any metrics, all metrics are enabled.
        """
        pulumi.set(__self__, "granularity", granularity)
        if metrics is not None:
            pulumi.set(__self__, "metrics", metrics)

    @_builtins.property
    @pulumi.getter
    def granularity(self) -> _builtins.str:
        """
        The frequency at which EC2 Auto Scaling sends aggregated data to AWS CloudWatch. The only valid value is "1Minute".
        """
        return pulumi.get(self, "granularity")

    @_builtins.property
    @pulumi.getter
    def metrics(self) -> Optional[Sequence[_builtins.str]]:
        """
        The metrics to enable. For a list of valid metrics, see https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html. If you specify granularity and don't specify any metrics, all metrics are enabled.
        """
        return pulumi.get(self, "metrics")


@pulumi.output_type
class AwsNodePoolConfigConfigEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigConfigEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigConfigEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigConfigEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kms_key_arn: _builtins.str):
        """
        :param _builtins.str kms_key_arn: The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @_builtins.property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> _builtins.str:
        """
        The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        return pulumi.get(self, "kms_key_arn")


@pulumi.output_type
class AwsNodePoolConfigInstancePlacement(dict):
    def __init__(__self__, *,
                 tenancy: Optional[_builtins.str] = None):
        """
        :param _builtins.str tenancy: The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        if tenancy is not None:
            pulumi.set(__self__, "tenancy", tenancy)

    @_builtins.property
    @pulumi.getter
    def tenancy(self) -> Optional[_builtins.str]:
        """
        The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        return pulumi.get(self, "tenancy")


@pulumi.output_type
class AwsNodePoolConfigProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretArn":
            suggest = "secret_arn"
        elif key == "secretVersion":
            suggest = "secret_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_arn: _builtins.str,
                 secret_version: _builtins.str):
        """
        :param _builtins.str secret_arn: The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        :param _builtins.str secret_version: The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        pulumi.set(__self__, "secret_arn", secret_arn)
        pulumi.set(__self__, "secret_version", secret_version)

    @_builtins.property
    @pulumi.getter(name="secretArn")
    def secret_arn(self) -> _builtins.str:
        """
        The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_arn")

    @_builtins.property
    @pulumi.getter(name="secretVersion")
    def secret_version(self) -> _builtins.str:
        """
        The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_version")


@pulumi.output_type
class AwsNodePoolConfigRootVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyArn":
            suggest = "kms_key_arn"
        elif key == "sizeGib":
            suggest = "size_gib"
        elif key == "volumeType":
            suggest = "volume_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigRootVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigRootVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigRootVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 iops: Optional[_builtins.int] = None,
                 kms_key_arn: Optional[_builtins.str] = None,
                 size_gib: Optional[_builtins.int] = None,
                 throughput: Optional[_builtins.int] = None,
                 volume_type: Optional[_builtins.str] = None):
        """
        :param _builtins.int iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param _builtins.str kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param _builtins.int size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param _builtins.int throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        :param _builtins.str volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @_builtins.property
    @pulumi.getter
    def iops(self) -> Optional[_builtins.int]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @_builtins.property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[_builtins.str]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @_builtins.property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[_builtins.int]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @_builtins.property
    @pulumi.getter
    def throughput(self) -> Optional[_builtins.int]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        """
        return pulumi.get(self, "throughput")

    @_builtins.property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[_builtins.str]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")


@pulumi.output_type
class AwsNodePoolConfigSpotConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "instanceTypes":
            suggest = "instance_types"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigSpotConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigSpotConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigSpotConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 instance_types: Sequence[_builtins.str]):
        """
        :param Sequence[_builtins.str] instance_types: List of AWS EC2 instance types for creating a spot node pool's nodes. The specified instance types must have the same number of CPUs and memory. You can use the Amazon EC2 Instance Selector tool (https://github.com/aws/amazon-ec2-instance-selector) to choose instance types with matching CPU and memory
        """
        pulumi.set(__self__, "instance_types", instance_types)

    @_builtins.property
    @pulumi.getter(name="instanceTypes")
    def instance_types(self) -> Sequence[_builtins.str]:
        """
        List of AWS EC2 instance types for creating a spot node pool's nodes. The specified instance types must have the same number of CPUs and memory. You can use the Amazon EC2 Instance Selector tool (https://github.com/aws/amazon-ec2-instance-selector) to choose instance types with matching CPU and memory
        """
        return pulumi.get(self, "instance_types")


@pulumi.output_type
class AwsNodePoolConfigSshConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ec2KeyPair":
            suggest = "ec2_key_pair"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolConfigSshConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolConfigSshConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolConfigSshConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ec2_key_pair: _builtins.str):
        """
        :param _builtins.str ec2_key_pair: The name of the EC2 key pair used to login into cluster machines.
        """
        pulumi.set(__self__, "ec2_key_pair", ec2_key_pair)

    @_builtins.property
    @pulumi.getter(name="ec2KeyPair")
    def ec2_key_pair(self) -> _builtins.str:
        """
        The name of the EC2 key pair used to login into cluster machines.
        """
        return pulumi.get(self, "ec2_key_pair")


@pulumi.output_type
class AwsNodePoolConfigTaint(dict):
    def __init__(__self__, *,
                 effect: _builtins.str,
                 key: _builtins.str,
                 value: _builtins.str):
        """
        :param _builtins.str effect: The taint effect. Possible values: EFFECT_UNSPECIFIED, NO_SCHEDULE, PREFER_NO_SCHEDULE, NO_EXECUTE
        :param _builtins.str key: Key for the taint.
        :param _builtins.str value: Value for the taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def effect(self) -> _builtins.str:
        """
        The taint effect. Possible values: EFFECT_UNSPECIFIED, NO_SCHEDULE, PREFER_NO_SCHEDULE, NO_EXECUTE
        """
        return pulumi.get(self, "effect")

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        Key for the taint.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def value(self) -> _builtins.str:
        """
        Value for the taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class AwsNodePoolKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cpuCfsQuota":
            suggest = "cpu_cfs_quota"
        elif key == "cpuCfsQuotaPeriod":
            suggest = "cpu_cfs_quota_period"
        elif key == "cpuManagerPolicy":
            suggest = "cpu_manager_policy"
        elif key == "podPidsLimit":
            suggest = "pod_pids_limit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cpu_cfs_quota: Optional[_builtins.bool] = None,
                 cpu_cfs_quota_period: Optional[_builtins.str] = None,
                 cpu_manager_policy: Optional[_builtins.str] = None,
                 pod_pids_limit: Optional[_builtins.int] = None):
        """
        :param _builtins.bool cpu_cfs_quota: Whether or not to enable CPU CFS quota. Defaults to true.
        :param _builtins.str cpu_cfs_quota_period: Optional. The CPU CFS quota period to use for the node. Defaults to "100ms".
        :param _builtins.str cpu_manager_policy: The CpuManagerPolicy to use for the node. Defaults to "none".
        :param _builtins.int pod_pids_limit: Optional. The maximum number of PIDs in each pod running on the node. The limit scales automatically based on underlying machine size if left unset.
        """
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if cpu_manager_policy is not None:
            pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @_builtins.property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[_builtins.bool]:
        """
        Whether or not to enable CPU CFS quota. Defaults to true.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @_builtins.property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[_builtins.str]:
        """
        Optional. The CPU CFS quota period to use for the node. Defaults to "100ms".
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @_builtins.property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> Optional[_builtins.str]:
        """
        The CpuManagerPolicy to use for the node. Defaults to "none".
        """
        return pulumi.get(self, "cpu_manager_policy")

    @_builtins.property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[_builtins.int]:
        """
        Optional. The maximum number of PIDs in each pod running on the node. The limit scales automatically based on underlying machine size if left unset.
        """
        return pulumi.get(self, "pod_pids_limit")


@pulumi.output_type
class AwsNodePoolManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool auto_repair: Optional. Whether or not the nodes will be automatically repaired.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)

    @_builtins.property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[_builtins.bool]:
        """
        Optional. Whether or not the nodes will be automatically repaired.
        """
        return pulumi.get(self, "auto_repair")


@pulumi.output_type
class AwsNodePoolMaxPodsConstraint(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxPodsPerNode":
            suggest = "max_pods_per_node"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolMaxPodsConstraint. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolMaxPodsConstraint.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolMaxPodsConstraint.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_pods_per_node: _builtins.int):
        """
        :param _builtins.int max_pods_per_node: The maximum number of pods to schedule on a single node.
               
               - - -
        """
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)

    @_builtins.property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> _builtins.int:
        """
        The maximum number of pods to schedule on a single node.

        - - -
        """
        return pulumi.get(self, "max_pods_per_node")


@pulumi.output_type
class AwsNodePoolUpdateSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "surgeSettings":
            suggest = "surge_settings"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolUpdateSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolUpdateSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolUpdateSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 surge_settings: Optional['outputs.AwsNodePoolUpdateSettingsSurgeSettings'] = None):
        """
        :param 'AwsNodePoolUpdateSettingsSurgeSettingsArgs' surge_settings: Optional. Settings for surge update.
        """
        if surge_settings is not None:
            pulumi.set(__self__, "surge_settings", surge_settings)

    @_builtins.property
    @pulumi.getter(name="surgeSettings")
    def surge_settings(self) -> Optional['outputs.AwsNodePoolUpdateSettingsSurgeSettings']:
        """
        Optional. Settings for surge update.
        """
        return pulumi.get(self, "surge_settings")


@pulumi.output_type
class AwsNodePoolUpdateSettingsSurgeSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxSurge":
            suggest = "max_surge"
        elif key == "maxUnavailable":
            suggest = "max_unavailable"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AwsNodePoolUpdateSettingsSurgeSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AwsNodePoolUpdateSettingsSurgeSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AwsNodePoolUpdateSettingsSurgeSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_surge: Optional[_builtins.int] = None,
                 max_unavailable: Optional[_builtins.int] = None):
        """
        :param _builtins.int max_surge: Optional. The maximum number of nodes that can be created beyond the current size of the node pool during the update process.
        :param _builtins.int max_unavailable: Optional. The maximum number of nodes that can be simultaneously unavailable during the update process. A node is considered unavailable if its status is not Ready.
        """
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)

    @_builtins.property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[_builtins.int]:
        """
        Optional. The maximum number of nodes that can be created beyond the current size of the node pool during the update process.
        """
        return pulumi.get(self, "max_surge")

    @_builtins.property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[_builtins.int]:
        """
        Optional. The maximum number of nodes that can be simultaneously unavailable during the update process. A node is considered unavailable if its status is not Ready.
        """
        return pulumi.get(self, "max_unavailable")


@pulumi.output_type
class AzureClusterAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminUsers":
            suggest = "admin_users"
        elif key == "adminGroups":
            suggest = "admin_groups"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_users: Sequence['outputs.AzureClusterAuthorizationAdminUser'],
                 admin_groups: Optional[Sequence['outputs.AzureClusterAuthorizationAdminGroup']] = None):
        """
        :param Sequence['AzureClusterAuthorizationAdminUserArgs'] admin_users: Users that can perform operations as a cluster admin. A new ClusterRoleBinding will be created to grant the cluster-admin ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        :param Sequence['AzureClusterAuthorizationAdminGroupArgs'] admin_groups: Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        pulumi.set(__self__, "admin_users", admin_users)
        if admin_groups is not None:
            pulumi.set(__self__, "admin_groups", admin_groups)

    @_builtins.property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> Sequence['outputs.AzureClusterAuthorizationAdminUser']:
        """
        Users that can perform operations as a cluster admin. A new ClusterRoleBinding will be created to grant the cluster-admin ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")

    @_builtins.property
    @pulumi.getter(name="adminGroups")
    def admin_groups(self) -> Optional[Sequence['outputs.AzureClusterAuthorizationAdminGroup']]:
        """
        Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_groups")


@pulumi.output_type
class AzureClusterAuthorizationAdminGroup(dict):
    def __init__(__self__, *,
                 group: _builtins.str):
        """
        :param _builtins.str group: The name of the group, e.g. `my-group@domain.com`.
        """
        pulumi.set(__self__, "group", group)

    @_builtins.property
    @pulumi.getter
    def group(self) -> _builtins.str:
        """
        The name of the group, e.g. `my-group@domain.com`.
        """
        return pulumi.get(self, "group")


@pulumi.output_type
class AzureClusterAuthorizationAdminUser(dict):
    def __init__(__self__, *,
                 username: _builtins.str):
        """
        :param _builtins.str username: The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        pulumi.set(__self__, "username", username)

    @_builtins.property
    @pulumi.getter
    def username(self) -> _builtins.str:
        """
        The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class AzureClusterAzureServicesAuthentication(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "applicationId":
            suggest = "application_id"
        elif key == "tenantId":
            suggest = "tenant_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterAzureServicesAuthentication. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterAzureServicesAuthentication.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterAzureServicesAuthentication.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 application_id: _builtins.str,
                 tenant_id: _builtins.str):
        """
        :param _builtins.str application_id: The Azure Active Directory Application ID for Authentication configuration.
        :param _builtins.str tenant_id: The Azure Active Directory Tenant ID for Authentication configuration.
        """
        pulumi.set(__self__, "application_id", application_id)
        pulumi.set(__self__, "tenant_id", tenant_id)

    @_builtins.property
    @pulumi.getter(name="applicationId")
    def application_id(self) -> _builtins.str:
        """
        The Azure Active Directory Application ID for Authentication configuration.
        """
        return pulumi.get(self, "application_id")

    @_builtins.property
    @pulumi.getter(name="tenantId")
    def tenant_id(self) -> _builtins.str:
        """
        The Azure Active Directory Tenant ID for Authentication configuration.
        """
        return pulumi.get(self, "tenant_id")


@pulumi.output_type
class AzureClusterControlPlane(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sshConfig":
            suggest = "ssh_config"
        elif key == "subnetId":
            suggest = "subnet_id"
        elif key == "databaseEncryption":
            suggest = "database_encryption"
        elif key == "mainVolume":
            suggest = "main_volume"
        elif key == "proxyConfig":
            suggest = "proxy_config"
        elif key == "replicaPlacements":
            suggest = "replica_placements"
        elif key == "rootVolume":
            suggest = "root_volume"
        elif key == "vmSize":
            suggest = "vm_size"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlane. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlane.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlane.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ssh_config: 'outputs.AzureClusterControlPlaneSshConfig',
                 subnet_id: _builtins.str,
                 version: _builtins.str,
                 database_encryption: Optional['outputs.AzureClusterControlPlaneDatabaseEncryption'] = None,
                 main_volume: Optional['outputs.AzureClusterControlPlaneMainVolume'] = None,
                 proxy_config: Optional['outputs.AzureClusterControlPlaneProxyConfig'] = None,
                 replica_placements: Optional[Sequence['outputs.AzureClusterControlPlaneReplicaPlacement']] = None,
                 root_volume: Optional['outputs.AzureClusterControlPlaneRootVolume'] = None,
                 tags: Optional[Mapping[str, _builtins.str]] = None,
                 vm_size: Optional[_builtins.str] = None):
        """
        :param 'AzureClusterControlPlaneSshConfigArgs' ssh_config: SSH configuration for how to access the underlying control plane machines.
        :param _builtins.str subnet_id: The ARM ID of the subnet where the control plane VMs are deployed. Example: `/subscriptions//resourceGroups//providers/Microsoft.Network/virtualNetworks//subnets/default`.
        :param _builtins.str version: The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling GetAzureServerConfig.
        :param 'AzureClusterControlPlaneDatabaseEncryptionArgs' database_encryption: Optional. Configuration related to application-layer secrets encryption.
        :param 'AzureClusterControlPlaneMainVolumeArgs' main_volume: Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. When unspecified, it defaults to a 8-GiB Azure Disk.
        :param 'AzureClusterControlPlaneProxyConfigArgs' proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param Sequence['AzureClusterControlPlaneReplicaPlacementArgs'] replica_placements: Configuration for where to place the control plane replicas. Up to three replica placement instances can be specified. If replica_placements is set, the replica placement instances will be applied to the three control plane replicas as evenly as possible.
        :param 'AzureClusterControlPlaneRootVolumeArgs' root_volume: Optional. Configuration related to the root volume provisioned for each control plane replica. When unspecified, it defaults to 32-GiB Azure Disk.
        :param Mapping[str, _builtins.str] tags: Optional. A set of tags to apply to all underlying control plane Azure resources.
        :param _builtins.str vm_size: Optional. The Azure VM size name. Example: `Standard_DS2_v2`. For available VM sizes, see https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        pulumi.set(__self__, "ssh_config", ssh_config)
        pulumi.set(__self__, "subnet_id", subnet_id)
        pulumi.set(__self__, "version", version)
        if database_encryption is not None:
            pulumi.set(__self__, "database_encryption", database_encryption)
        if main_volume is not None:
            pulumi.set(__self__, "main_volume", main_volume)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if replica_placements is not None:
            pulumi.set(__self__, "replica_placements", replica_placements)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if vm_size is not None:
            pulumi.set(__self__, "vm_size", vm_size)

    @_builtins.property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> 'outputs.AzureClusterControlPlaneSshConfig':
        """
        SSH configuration for how to access the underlying control plane machines.
        """
        return pulumi.get(self, "ssh_config")

    @_builtins.property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> _builtins.str:
        """
        The ARM ID of the subnet where the control plane VMs are deployed. Example: `/subscriptions//resourceGroups//providers/Microsoft.Network/virtualNetworks//subnets/default`.
        """
        return pulumi.get(self, "subnet_id")

    @_builtins.property
    @pulumi.getter
    def version(self) -> _builtins.str:
        """
        The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling GetAzureServerConfig.
        """
        return pulumi.get(self, "version")

    @_builtins.property
    @pulumi.getter(name="databaseEncryption")
    def database_encryption(self) -> Optional['outputs.AzureClusterControlPlaneDatabaseEncryption']:
        """
        Optional. Configuration related to application-layer secrets encryption.
        """
        return pulumi.get(self, "database_encryption")

    @_builtins.property
    @pulumi.getter(name="mainVolume")
    def main_volume(self) -> Optional['outputs.AzureClusterControlPlaneMainVolume']:
        """
        Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. When unspecified, it defaults to a 8-GiB Azure Disk.
        """
        return pulumi.get(self, "main_volume")

    @_builtins.property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional['outputs.AzureClusterControlPlaneProxyConfig']:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @_builtins.property
    @pulumi.getter(name="replicaPlacements")
    def replica_placements(self) -> Optional[Sequence['outputs.AzureClusterControlPlaneReplicaPlacement']]:
        """
        Configuration for where to place the control plane replicas. Up to three replica placement instances can be specified. If replica_placements is set, the replica placement instances will be applied to the three control plane replicas as evenly as possible.
        """
        return pulumi.get(self, "replica_placements")

    @_builtins.property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional['outputs.AzureClusterControlPlaneRootVolume']:
        """
        Optional. Configuration related to the root volume provisioned for each control plane replica. When unspecified, it defaults to 32-GiB Azure Disk.
        """
        return pulumi.get(self, "root_volume")

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        Optional. A set of tags to apply to all underlying control plane Azure resources.
        """
        return pulumi.get(self, "tags")

    @_builtins.property
    @pulumi.getter(name="vmSize")
    def vm_size(self) -> Optional[_builtins.str]:
        """
        Optional. The Azure VM size name. Example: `Standard_DS2_v2`. For available VM sizes, see https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        return pulumi.get(self, "vm_size")


@pulumi.output_type
class AzureClusterControlPlaneDatabaseEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "keyId":
            suggest = "key_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneDatabaseEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneDatabaseEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneDatabaseEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 key_id: _builtins.str):
        """
        :param _builtins.str key_id: The ARM ID of the Azure Key Vault key to encrypt / decrypt data. For example: `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>` Encryption will always take the latest version of the key and hence specific version is not supported.
        """
        pulumi.set(__self__, "key_id", key_id)

    @_builtins.property
    @pulumi.getter(name="keyId")
    def key_id(self) -> _builtins.str:
        """
        The ARM ID of the Azure Key Vault key to encrypt / decrypt data. For example: `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>` Encryption will always take the latest version of the key and hence specific version is not supported.
        """
        return pulumi.get(self, "key_id")


@pulumi.output_type
class AzureClusterControlPlaneMainVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sizeGib":
            suggest = "size_gib"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneMainVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneMainVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneMainVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 size_gib: Optional[_builtins.int] = None):
        """
        :param _builtins.int size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @_builtins.property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[_builtins.int]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")


@pulumi.output_type
class AzureClusterControlPlaneProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "resourceGroupId":
            suggest = "resource_group_id"
        elif key == "secretId":
            suggest = "secret_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 resource_group_id: _builtins.str,
                 secret_id: _builtins.str):
        """
        :param _builtins.str resource_group_id: The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        :param _builtins.str secret_id: The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        pulumi.set(__self__, "resource_group_id", resource_group_id)
        pulumi.set(__self__, "secret_id", secret_id)

    @_builtins.property
    @pulumi.getter(name="resourceGroupId")
    def resource_group_id(self) -> _builtins.str:
        """
        The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        """
        return pulumi.get(self, "resource_group_id")

    @_builtins.property
    @pulumi.getter(name="secretId")
    def secret_id(self) -> _builtins.str:
        """
        The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        return pulumi.get(self, "secret_id")


@pulumi.output_type
class AzureClusterControlPlaneReplicaPlacement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "azureAvailabilityZone":
            suggest = "azure_availability_zone"
        elif key == "subnetId":
            suggest = "subnet_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneReplicaPlacement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneReplicaPlacement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneReplicaPlacement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 azure_availability_zone: _builtins.str,
                 subnet_id: _builtins.str):
        """
        :param _builtins.str azure_availability_zone: For a given replica, the Azure availability zone where to provision the control plane VM and the ETCD disk.
        :param _builtins.str subnet_id: For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
        """
        pulumi.set(__self__, "azure_availability_zone", azure_availability_zone)
        pulumi.set(__self__, "subnet_id", subnet_id)

    @_builtins.property
    @pulumi.getter(name="azureAvailabilityZone")
    def azure_availability_zone(self) -> _builtins.str:
        """
        For a given replica, the Azure availability zone where to provision the control plane VM and the ETCD disk.
        """
        return pulumi.get(self, "azure_availability_zone")

    @_builtins.property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> _builtins.str:
        """
        For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
        """
        return pulumi.get(self, "subnet_id")


@pulumi.output_type
class AzureClusterControlPlaneRootVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sizeGib":
            suggest = "size_gib"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneRootVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneRootVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneRootVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 size_gib: Optional[_builtins.int] = None):
        """
        :param _builtins.int size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @_builtins.property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[_builtins.int]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")


@pulumi.output_type
class AzureClusterControlPlaneSshConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "authorizedKey":
            suggest = "authorized_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterControlPlaneSshConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterControlPlaneSshConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterControlPlaneSshConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 authorized_key: _builtins.str):
        """
        :param _builtins.str authorized_key: The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        pulumi.set(__self__, "authorized_key", authorized_key)

    @_builtins.property
    @pulumi.getter(name="authorizedKey")
    def authorized_key(self) -> _builtins.str:
        """
        The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        return pulumi.get(self, "authorized_key")


@pulumi.output_type
class AzureClusterFleet(dict):
    def __init__(__self__, *,
                 membership: Optional[_builtins.str] = None,
                 project: Optional[_builtins.str] = None):
        """
        :param _builtins.str membership: The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        :param _builtins.str project: The number of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @_builtins.property
    @pulumi.getter
    def membership(self) -> Optional[_builtins.str]:
        """
        The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")

    @_builtins.property
    @pulumi.getter
    def project(self) -> Optional[_builtins.str]:
        """
        The number of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")


@pulumi.output_type
class AzureClusterLoggingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "componentConfig":
            suggest = "component_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterLoggingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterLoggingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterLoggingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component_config: Optional['outputs.AzureClusterLoggingConfigComponentConfig'] = None):
        """
        :param 'AzureClusterLoggingConfigComponentConfigArgs' component_config: Configuration of the logging components.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @_builtins.property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional['outputs.AzureClusterLoggingConfigComponentConfig']:
        """
        Configuration of the logging components.
        """
        return pulumi.get(self, "component_config")


@pulumi.output_type
class AzureClusterLoggingConfigComponentConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableComponents":
            suggest = "enable_components"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterLoggingConfigComponentConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterLoggingConfigComponentConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_components: Optional[Sequence[_builtins.str]] = None):
        """
        :param Sequence[_builtins.str] enable_components: Components of the logging configuration to be enabled.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @_builtins.property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[Sequence[_builtins.str]]:
        """
        Components of the logging configuration to be enabled.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class AzureClusterNetworking(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "podAddressCidrBlocks":
            suggest = "pod_address_cidr_blocks"
        elif key == "serviceAddressCidrBlocks":
            suggest = "service_address_cidr_blocks"
        elif key == "virtualNetworkId":
            suggest = "virtual_network_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterNetworking. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterNetworking.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterNetworking.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pod_address_cidr_blocks: Sequence[_builtins.str],
                 service_address_cidr_blocks: Sequence[_builtins.str],
                 virtual_network_id: _builtins.str):
        """
        :param Sequence[_builtins.str] pod_address_cidr_blocks: The IP address range of the pods in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All pods in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param Sequence[_builtins.str] service_address_cidr_blocks: The IP address range for services in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All services in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creating a cluster.
        :param _builtins.str virtual_network_id: The Azure Resource Manager (ARM) ID of the VNet associated with your cluster. All components in the cluster (i.e. control plane and node pools) run on a single VNet. Example: `/subscriptions/*/resourceGroups/*/providers/Microsoft.Network/virtualNetworks/*` This field cannot be changed after creation.
               
               - - -
        """
        pulumi.set(__self__, "pod_address_cidr_blocks", pod_address_cidr_blocks)
        pulumi.set(__self__, "service_address_cidr_blocks", service_address_cidr_blocks)
        pulumi.set(__self__, "virtual_network_id", virtual_network_id)

    @_builtins.property
    @pulumi.getter(name="podAddressCidrBlocks")
    def pod_address_cidr_blocks(self) -> Sequence[_builtins.str]:
        """
        The IP address range of the pods in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All pods in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "pod_address_cidr_blocks")

    @_builtins.property
    @pulumi.getter(name="serviceAddressCidrBlocks")
    def service_address_cidr_blocks(self) -> Sequence[_builtins.str]:
        """
        The IP address range for services in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All services in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creating a cluster.
        """
        return pulumi.get(self, "service_address_cidr_blocks")

    @_builtins.property
    @pulumi.getter(name="virtualNetworkId")
    def virtual_network_id(self) -> _builtins.str:
        """
        The Azure Resource Manager (ARM) ID of the VNet associated with your cluster. All components in the cluster (i.e. control plane and node pools) run on a single VNet. Example: `/subscriptions/*/resourceGroups/*/providers/Microsoft.Network/virtualNetworks/*` This field cannot be changed after creation.

        - - -
        """
        return pulumi.get(self, "virtual_network_id")


@pulumi.output_type
class AzureClusterWorkloadIdentityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "identityProvider":
            suggest = "identity_provider"
        elif key == "issuerUri":
            suggest = "issuer_uri"
        elif key == "workloadPool":
            suggest = "workload_pool"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureClusterWorkloadIdentityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureClusterWorkloadIdentityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureClusterWorkloadIdentityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 identity_provider: Optional[_builtins.str] = None,
                 issuer_uri: Optional[_builtins.str] = None,
                 workload_pool: Optional[_builtins.str] = None):
        """
        :param _builtins.str identity_provider: The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        :param _builtins.str issuer_uri: The OIDC issuer URL for this cluster.
        :param _builtins.str workload_pool: The Workload Identity Pool associated to the cluster.
        """
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @_builtins.property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[_builtins.str]:
        """
        The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        """
        return pulumi.get(self, "identity_provider")

    @_builtins.property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[_builtins.str]:
        """
        The OIDC issuer URL for this cluster.
        """
        return pulumi.get(self, "issuer_uri")

    @_builtins.property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[_builtins.str]:
        """
        The Workload Identity Pool associated to the cluster.
        """
        return pulumi.get(self, "workload_pool")


@pulumi.output_type
class AzureNodePoolAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxNodeCount":
            suggest = "max_node_count"
        elif key == "minNodeCount":
            suggest = "min_node_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_node_count: _builtins.int,
                 min_node_count: _builtins.int):
        """
        :param _builtins.int max_node_count: Maximum number of nodes in the node pool. Must be >= min_node_count.
        :param _builtins.int min_node_count: Minimum number of nodes in the node pool. Must be >= 1 and <= max_node_count.
        """
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)

    @_builtins.property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> _builtins.int:
        """
        Maximum number of nodes in the node pool. Must be >= min_node_count.
        """
        return pulumi.get(self, "max_node_count")

    @_builtins.property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> _builtins.int:
        """
        Minimum number of nodes in the node pool. Must be >= 1 and <= max_node_count.
        """
        return pulumi.get(self, "min_node_count")


@pulumi.output_type
class AzureNodePoolConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sshConfig":
            suggest = "ssh_config"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "proxyConfig":
            suggest = "proxy_config"
        elif key == "rootVolume":
            suggest = "root_volume"
        elif key == "vmSize":
            suggest = "vm_size"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ssh_config: 'outputs.AzureNodePoolConfigSshConfig',
                 image_type: Optional[_builtins.str] = None,
                 labels: Optional[Mapping[str, _builtins.str]] = None,
                 proxy_config: Optional['outputs.AzureNodePoolConfigProxyConfig'] = None,
                 root_volume: Optional['outputs.AzureNodePoolConfigRootVolume'] = None,
                 tags: Optional[Mapping[str, _builtins.str]] = None,
                 vm_size: Optional[_builtins.str] = None):
        """
        :param 'AzureNodePoolConfigSshConfigArgs' ssh_config: SSH configuration for how to access the node pool machines.
        :param _builtins.str image_type: The OS image type to use on node pool instances.
        :param Mapping[str, _builtins.str] labels: Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        :param 'AzureNodePoolConfigProxyConfigArgs' proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param 'AzureNodePoolConfigRootVolumeArgs' root_volume: Optional. Configuration related to the root volume provisioned for each node pool machine. When unspecified, it defaults to a 32-GiB Azure Disk.
        :param Mapping[str, _builtins.str] tags: Optional. A set of tags to apply to all underlying Azure resources for this node pool. This currently only includes Virtual Machine Scale Sets. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        :param _builtins.str vm_size: Optional. The Azure VM size name. Example: `Standard_DS2_v2`. See (/anthos/clusters/docs/azure/reference/supported-vms) for options. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        pulumi.set(__self__, "ssh_config", ssh_config)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if vm_size is not None:
            pulumi.set(__self__, "vm_size", vm_size)

    @_builtins.property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> 'outputs.AzureNodePoolConfigSshConfig':
        """
        SSH configuration for how to access the node pool machines.
        """
        return pulumi.get(self, "ssh_config")

    @_builtins.property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[_builtins.str]:
        """
        The OS image type to use on node pool instances.
        """
        return pulumi.get(self, "image_type")

    @_builtins.property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        """
        return pulumi.get(self, "labels")

    @_builtins.property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional['outputs.AzureNodePoolConfigProxyConfig']:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @_builtins.property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional['outputs.AzureNodePoolConfigRootVolume']:
        """
        Optional. Configuration related to the root volume provisioned for each node pool machine. When unspecified, it defaults to a 32-GiB Azure Disk.
        """
        return pulumi.get(self, "root_volume")

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        Optional. A set of tags to apply to all underlying Azure resources for this node pool. This currently only includes Virtual Machine Scale Sets. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")

    @_builtins.property
    @pulumi.getter(name="vmSize")
    def vm_size(self) -> Optional[_builtins.str]:
        """
        Optional. The Azure VM size name. Example: `Standard_DS2_v2`. See (/anthos/clusters/docs/azure/reference/supported-vms) for options. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        return pulumi.get(self, "vm_size")


@pulumi.output_type
class AzureNodePoolConfigProxyConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "resourceGroupId":
            suggest = "resource_group_id"
        elif key == "secretId":
            suggest = "secret_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolConfigProxyConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolConfigProxyConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolConfigProxyConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 resource_group_id: _builtins.str,
                 secret_id: _builtins.str):
        """
        :param _builtins.str resource_group_id: The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        :param _builtins.str secret_id: The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        pulumi.set(__self__, "resource_group_id", resource_group_id)
        pulumi.set(__self__, "secret_id", secret_id)

    @_builtins.property
    @pulumi.getter(name="resourceGroupId")
    def resource_group_id(self) -> _builtins.str:
        """
        The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        """
        return pulumi.get(self, "resource_group_id")

    @_builtins.property
    @pulumi.getter(name="secretId")
    def secret_id(self) -> _builtins.str:
        """
        The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        return pulumi.get(self, "secret_id")


@pulumi.output_type
class AzureNodePoolConfigRootVolume(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sizeGib":
            suggest = "size_gib"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolConfigRootVolume. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolConfigRootVolume.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolConfigRootVolume.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 size_gib: Optional[_builtins.int] = None):
        """
        :param _builtins.int size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @_builtins.property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[_builtins.int]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")


@pulumi.output_type
class AzureNodePoolConfigSshConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "authorizedKey":
            suggest = "authorized_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolConfigSshConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolConfigSshConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolConfigSshConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 authorized_key: _builtins.str):
        """
        :param _builtins.str authorized_key: The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        pulumi.set(__self__, "authorized_key", authorized_key)

    @_builtins.property
    @pulumi.getter(name="authorizedKey")
    def authorized_key(self) -> _builtins.str:
        """
        The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        return pulumi.get(self, "authorized_key")


@pulumi.output_type
class AzureNodePoolManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool auto_repair: Optional. Whether or not the nodes will be automatically repaired.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)

    @_builtins.property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[_builtins.bool]:
        """
        Optional. Whether or not the nodes will be automatically repaired.
        """
        return pulumi.get(self, "auto_repair")


@pulumi.output_type
class AzureNodePoolMaxPodsConstraint(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxPodsPerNode":
            suggest = "max_pods_per_node"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AzureNodePoolMaxPodsConstraint. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AzureNodePoolMaxPodsConstraint.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AzureNodePoolMaxPodsConstraint.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_pods_per_node: _builtins.int):
        """
        :param _builtins.int max_pods_per_node: The maximum number of pods to schedule on a single node.
               
               - - -
        """
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)

    @_builtins.property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> _builtins.int:
        """
        The maximum number of pods to schedule on a single node.

        - - -
        """
        return pulumi.get(self, "max_pods_per_node")


@pulumi.output_type
class ClusterAddonsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cloudrunConfig":
            suggest = "cloudrun_config"
        elif key == "configConnectorConfig":
            suggest = "config_connector_config"
        elif key == "dnsCacheConfig":
            suggest = "dns_cache_config"
        elif key == "gcePersistentDiskCsiDriverConfig":
            suggest = "gce_persistent_disk_csi_driver_config"
        elif key == "gcpFilestoreCsiDriverConfig":
            suggest = "gcp_filestore_csi_driver_config"
        elif key == "gcsFuseCsiDriverConfig":
            suggest = "gcs_fuse_csi_driver_config"
        elif key == "gkeBackupAgentConfig":
            suggest = "gke_backup_agent_config"
        elif key == "horizontalPodAutoscaling":
            suggest = "horizontal_pod_autoscaling"
        elif key == "httpLoadBalancing":
            suggest = "http_load_balancing"
        elif key == "istioConfig":
            suggest = "istio_config"
        elif key == "kalmConfig":
            suggest = "kalm_config"
        elif key == "lustreCsiDriverConfig":
            suggest = "lustre_csi_driver_config"
        elif key == "networkPolicyConfig":
            suggest = "network_policy_config"
        elif key == "parallelstoreCsiDriverConfig":
            suggest = "parallelstore_csi_driver_config"
        elif key == "rayOperatorConfigs":
            suggest = "ray_operator_configs"
        elif key == "statefulHaConfig":
            suggest = "stateful_ha_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAddonsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAddonsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAddonsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cloudrun_config: Optional['outputs.ClusterAddonsConfigCloudrunConfig'] = None,
                 config_connector_config: Optional['outputs.ClusterAddonsConfigConfigConnectorConfig'] = None,
                 dns_cache_config: Optional['outputs.ClusterAddonsConfigDnsCacheConfig'] = None,
                 gce_persistent_disk_csi_driver_config: Optional['outputs.ClusterAddonsConfigGcePersistentDiskCsiDriverConfig'] = None,
                 gcp_filestore_csi_driver_config: Optional['outputs.ClusterAddonsConfigGcpFilestoreCsiDriverConfig'] = None,
                 gcs_fuse_csi_driver_config: Optional['outputs.ClusterAddonsConfigGcsFuseCsiDriverConfig'] = None,
                 gke_backup_agent_config: Optional['outputs.ClusterAddonsConfigGkeBackupAgentConfig'] = None,
                 horizontal_pod_autoscaling: Optional['outputs.ClusterAddonsConfigHorizontalPodAutoscaling'] = None,
                 http_load_balancing: Optional['outputs.ClusterAddonsConfigHttpLoadBalancing'] = None,
                 istio_config: Optional['outputs.ClusterAddonsConfigIstioConfig'] = None,
                 kalm_config: Optional['outputs.ClusterAddonsConfigKalmConfig'] = None,
                 lustre_csi_driver_config: Optional['outputs.ClusterAddonsConfigLustreCsiDriverConfig'] = None,
                 network_policy_config: Optional['outputs.ClusterAddonsConfigNetworkPolicyConfig'] = None,
                 parallelstore_csi_driver_config: Optional['outputs.ClusterAddonsConfigParallelstoreCsiDriverConfig'] = None,
                 ray_operator_configs: Optional[Sequence['outputs.ClusterAddonsConfigRayOperatorConfig']] = None,
                 stateful_ha_config: Optional['outputs.ClusterAddonsConfigStatefulHaConfig'] = None):
        """
        :param 'ClusterAddonsConfigCloudrunConfigArgs' cloudrun_config: . Structure is documented below.
        :param 'ClusterAddonsConfigConfigConnectorConfigArgs' config_connector_config: .
               The status of the ConfigConnector addon. It is disabled by default; Set `enabled = true` to enable.
        :param 'ClusterAddonsConfigDnsCacheConfigArgs' dns_cache_config: .
               The status of the NodeLocal DNSCache addon. It is disabled by default.
               Set `enabled = true` to enable.
               
               **Enabling/Disabling NodeLocal DNSCache in an existing cluster is a disruptive operation.
               All cluster nodes running GKE 1.15 and higher are recreated.**
        :param 'ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs' gce_persistent_disk_csi_driver_config: .
               Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set `enabled = true` to enable.
               
               **Note:** The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        :param 'ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs' gcp_filestore_csi_driver_config: The status of the Filestore CSI driver addon,
               which allows the usage of filestore instance as volumes.
               It is disabled by default; set `enabled = true` to enable.
        :param 'ClusterAddonsConfigGcsFuseCsiDriverConfigArgs' gcs_fuse_csi_driver_config: The status of the GCSFuse CSI driver addon,
               which allows the usage of a gcs bucket as volumes.
               It is disabled by default for Standard clusters; set `enabled = true` to enable.
               It is enabled by default for Autopilot clusters with version 1.24 or later; set `enabled = true` to enable it explicitly.
               See [Enable the Cloud Storage FUSE CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver#enable) for more information.
        :param 'ClusterAddonsConfigGkeBackupAgentConfigArgs' gke_backup_agent_config: .
               The status of the Backup for GKE agent addon. It is disabled by default; Set `enabled = true` to enable.
        :param 'ClusterAddonsConfigHorizontalPodAutoscalingArgs' horizontal_pod_autoscaling: The status of the Horizontal Pod Autoscaling
               addon, which increases or decreases the number of replica pods a replication controller
               has based on the resource usage of the existing pods.
               It is enabled by default;
               set `disabled = true` to disable.
        :param 'ClusterAddonsConfigHttpLoadBalancingArgs' http_load_balancing: The status of the HTTP (L7) load balancing
               controller addon, which makes it easy to set up HTTP load balancers for services in a
               cluster. It is enabled by default; set `disabled = true` to disable.
        :param 'ClusterAddonsConfigIstioConfigArgs' istio_config: .
               Structure is documented below.
        :param 'ClusterAddonsConfigKalmConfigArgs' kalm_config: .
               Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set `enabled = true` to enable.
        :param 'ClusterAddonsConfigLustreCsiDriverConfigArgs' lustre_csi_driver_config: The status of the Lustre CSI driver addon,
               which allows the usage of a Lustre instances as volumes.
               It is disabled by default for Standard clusters; set `enabled = true` to enable.
               It is disabled by default for Autopilot clusters; set `enabled = true` to enable.
               Lustre CSI Driver Config has optional subfield
               `enable_legacy_lustre_port` which allows the Lustre CSI driver to initialize LNet (the virtual networklayer for Lustre kernel module) using port 6988.
               This flag is required to workaround a port conflict with the gke-metadata-server on GKE nodes.
               See [Enable Lustre CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/lustre-csi-driver-new-volume) for more information.
               
               This example `addons_config` disables two addons:
        :param 'ClusterAddonsConfigNetworkPolicyConfigArgs' network_policy_config: Whether we should enable the network policy addon
               for the master.  This must be enabled in order to enable network policy for the nodes.
               To enable this, you must also define a `network_policy` block,
               otherwise nothing will happen.
               It can only be disabled if the nodes already do not have network policies enabled.
               Defaults to disabled; set `disabled = false` to enable.
        :param 'ClusterAddonsConfigParallelstoreCsiDriverConfigArgs' parallelstore_csi_driver_config: The status of the Parallelstore CSI driver addon,
               which allows the usage of a Parallelstore instances as volumes.
               It is disabled by default for Standard clusters; set `enabled = true` to enable.
               It is enabled by default for Autopilot clusters with version 1.29 or later; set `enabled = true` to enable it explicitly.
               See [Enable the Parallelstore CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/parallelstore-csi-new-volume#enable) for more information.
        :param Sequence['ClusterAddonsConfigRayOperatorConfigArgs'] ray_operator_configs: . The status of the [Ray Operator
               addon](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/concepts/overview).
               It is disabled by default. Set `enabled = true` to enable. The minimum
               cluster version to enable Ray is 1.30.0-gke.1747000.
               
               Ray Operator config has optional subfields
               `ray_cluster_logging_config.enabled` and
               `ray_cluster_monitoring_config.enabled` which control Ray Cluster logging
               and monitoring respectively. See [Collect and view logs and metrics for Ray
               clusters on
               GKE](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/how-to/collect-view-logs-metrics)
               for more information.
        :param 'ClusterAddonsConfigStatefulHaConfigArgs' stateful_ha_config: .
               The status of the Stateful HA addon, which provides automatic configurable failover for stateful applications.
               It is disabled by default for Standard clusters. Set `enabled = true` to enable.
        """
        if cloudrun_config is not None:
            pulumi.set(__self__, "cloudrun_config", cloudrun_config)
        if config_connector_config is not None:
            pulumi.set(__self__, "config_connector_config", config_connector_config)
        if dns_cache_config is not None:
            pulumi.set(__self__, "dns_cache_config", dns_cache_config)
        if gce_persistent_disk_csi_driver_config is not None:
            pulumi.set(__self__, "gce_persistent_disk_csi_driver_config", gce_persistent_disk_csi_driver_config)
        if gcp_filestore_csi_driver_config is not None:
            pulumi.set(__self__, "gcp_filestore_csi_driver_config", gcp_filestore_csi_driver_config)
        if gcs_fuse_csi_driver_config is not None:
            pulumi.set(__self__, "gcs_fuse_csi_driver_config", gcs_fuse_csi_driver_config)
        if gke_backup_agent_config is not None:
            pulumi.set(__self__, "gke_backup_agent_config", gke_backup_agent_config)
        if horizontal_pod_autoscaling is not None:
            pulumi.set(__self__, "horizontal_pod_autoscaling", horizontal_pod_autoscaling)
        if http_load_balancing is not None:
            pulumi.set(__self__, "http_load_balancing", http_load_balancing)
        if istio_config is not None:
            pulumi.set(__self__, "istio_config", istio_config)
        if kalm_config is not None:
            pulumi.set(__self__, "kalm_config", kalm_config)
        if lustre_csi_driver_config is not None:
            pulumi.set(__self__, "lustre_csi_driver_config", lustre_csi_driver_config)
        if network_policy_config is not None:
            pulumi.set(__self__, "network_policy_config", network_policy_config)
        if parallelstore_csi_driver_config is not None:
            pulumi.set(__self__, "parallelstore_csi_driver_config", parallelstore_csi_driver_config)
        if ray_operator_configs is not None:
            pulumi.set(__self__, "ray_operator_configs", ray_operator_configs)
        if stateful_ha_config is not None:
            pulumi.set(__self__, "stateful_ha_config", stateful_ha_config)

    @_builtins.property
    @pulumi.getter(name="cloudrunConfig")
    def cloudrun_config(self) -> Optional['outputs.ClusterAddonsConfigCloudrunConfig']:
        """
        . Structure is documented below.
        """
        return pulumi.get(self, "cloudrun_config")

    @_builtins.property
    @pulumi.getter(name="configConnectorConfig")
    def config_connector_config(self) -> Optional['outputs.ClusterAddonsConfigConfigConnectorConfig']:
        """
        .
        The status of the ConfigConnector addon. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "config_connector_config")

    @_builtins.property
    @pulumi.getter(name="dnsCacheConfig")
    def dns_cache_config(self) -> Optional['outputs.ClusterAddonsConfigDnsCacheConfig']:
        """
        .
        The status of the NodeLocal DNSCache addon. It is disabled by default.
        Set `enabled = true` to enable.

        **Enabling/Disabling NodeLocal DNSCache in an existing cluster is a disruptive operation.
        All cluster nodes running GKE 1.15 and higher are recreated.**
        """
        return pulumi.get(self, "dns_cache_config")

    @_builtins.property
    @pulumi.getter(name="gcePersistentDiskCsiDriverConfig")
    def gce_persistent_disk_csi_driver_config(self) -> Optional['outputs.ClusterAddonsConfigGcePersistentDiskCsiDriverConfig']:
        """
        .
        Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set `enabled = true` to enable.

        **Note:** The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        """
        return pulumi.get(self, "gce_persistent_disk_csi_driver_config")

    @_builtins.property
    @pulumi.getter(name="gcpFilestoreCsiDriverConfig")
    def gcp_filestore_csi_driver_config(self) -> Optional['outputs.ClusterAddonsConfigGcpFilestoreCsiDriverConfig']:
        """
        The status of the Filestore CSI driver addon,
        which allows the usage of filestore instance as volumes.
        It is disabled by default; set `enabled = true` to enable.
        """
        return pulumi.get(self, "gcp_filestore_csi_driver_config")

    @_builtins.property
    @pulumi.getter(name="gcsFuseCsiDriverConfig")
    def gcs_fuse_csi_driver_config(self) -> Optional['outputs.ClusterAddonsConfigGcsFuseCsiDriverConfig']:
        """
        The status of the GCSFuse CSI driver addon,
        which allows the usage of a gcs bucket as volumes.
        It is disabled by default for Standard clusters; set `enabled = true` to enable.
        It is enabled by default for Autopilot clusters with version 1.24 or later; set `enabled = true` to enable it explicitly.
        See [Enable the Cloud Storage FUSE CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver#enable) for more information.
        """
        return pulumi.get(self, "gcs_fuse_csi_driver_config")

    @_builtins.property
    @pulumi.getter(name="gkeBackupAgentConfig")
    def gke_backup_agent_config(self) -> Optional['outputs.ClusterAddonsConfigGkeBackupAgentConfig']:
        """
        .
        The status of the Backup for GKE agent addon. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "gke_backup_agent_config")

    @_builtins.property
    @pulumi.getter(name="horizontalPodAutoscaling")
    def horizontal_pod_autoscaling(self) -> Optional['outputs.ClusterAddonsConfigHorizontalPodAutoscaling']:
        """
        The status of the Horizontal Pod Autoscaling
        addon, which increases or decreases the number of replica pods a replication controller
        has based on the resource usage of the existing pods.
        It is enabled by default;
        set `disabled = true` to disable.
        """
        return pulumi.get(self, "horizontal_pod_autoscaling")

    @_builtins.property
    @pulumi.getter(name="httpLoadBalancing")
    def http_load_balancing(self) -> Optional['outputs.ClusterAddonsConfigHttpLoadBalancing']:
        """
        The status of the HTTP (L7) load balancing
        controller addon, which makes it easy to set up HTTP load balancers for services in a
        cluster. It is enabled by default; set `disabled = true` to disable.
        """
        return pulumi.get(self, "http_load_balancing")

    @_builtins.property
    @pulumi.getter(name="istioConfig")
    def istio_config(self) -> Optional['outputs.ClusterAddonsConfigIstioConfig']:
        """
        .
        Structure is documented below.
        """
        return pulumi.get(self, "istio_config")

    @_builtins.property
    @pulumi.getter(name="kalmConfig")
    def kalm_config(self) -> Optional['outputs.ClusterAddonsConfigKalmConfig']:
        """
        .
        Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "kalm_config")

    @_builtins.property
    @pulumi.getter(name="lustreCsiDriverConfig")
    def lustre_csi_driver_config(self) -> Optional['outputs.ClusterAddonsConfigLustreCsiDriverConfig']:
        """
        The status of the Lustre CSI driver addon,
        which allows the usage of a Lustre instances as volumes.
        It is disabled by default for Standard clusters; set `enabled = true` to enable.
        It is disabled by default for Autopilot clusters; set `enabled = true` to enable.
        Lustre CSI Driver Config has optional subfield
        `enable_legacy_lustre_port` which allows the Lustre CSI driver to initialize LNet (the virtual networklayer for Lustre kernel module) using port 6988.
        This flag is required to workaround a port conflict with the gke-metadata-server on GKE nodes.
        See [Enable Lustre CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/lustre-csi-driver-new-volume) for more information.

        This example `addons_config` disables two addons:
        """
        return pulumi.get(self, "lustre_csi_driver_config")

    @_builtins.property
    @pulumi.getter(name="networkPolicyConfig")
    def network_policy_config(self) -> Optional['outputs.ClusterAddonsConfigNetworkPolicyConfig']:
        """
        Whether we should enable the network policy addon
        for the master.  This must be enabled in order to enable network policy for the nodes.
        To enable this, you must also define a `network_policy` block,
        otherwise nothing will happen.
        It can only be disabled if the nodes already do not have network policies enabled.
        Defaults to disabled; set `disabled = false` to enable.
        """
        return pulumi.get(self, "network_policy_config")

    @_builtins.property
    @pulumi.getter(name="parallelstoreCsiDriverConfig")
    def parallelstore_csi_driver_config(self) -> Optional['outputs.ClusterAddonsConfigParallelstoreCsiDriverConfig']:
        """
        The status of the Parallelstore CSI driver addon,
        which allows the usage of a Parallelstore instances as volumes.
        It is disabled by default for Standard clusters; set `enabled = true` to enable.
        It is enabled by default for Autopilot clusters with version 1.29 or later; set `enabled = true` to enable it explicitly.
        See [Enable the Parallelstore CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/parallelstore-csi-new-volume#enable) for more information.
        """
        return pulumi.get(self, "parallelstore_csi_driver_config")

    @_builtins.property
    @pulumi.getter(name="rayOperatorConfigs")
    def ray_operator_configs(self) -> Optional[Sequence['outputs.ClusterAddonsConfigRayOperatorConfig']]:
        """
        . The status of the [Ray Operator
        addon](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/concepts/overview).
        It is disabled by default. Set `enabled = true` to enable. The minimum
        cluster version to enable Ray is 1.30.0-gke.1747000.

        Ray Operator config has optional subfields
        `ray_cluster_logging_config.enabled` and
        `ray_cluster_monitoring_config.enabled` which control Ray Cluster logging
        and monitoring respectively. See [Collect and view logs and metrics for Ray
        clusters on
        GKE](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/how-to/collect-view-logs-metrics)
        for more information.
        """
        return pulumi.get(self, "ray_operator_configs")

    @_builtins.property
    @pulumi.getter(name="statefulHaConfig")
    def stateful_ha_config(self) -> Optional['outputs.ClusterAddonsConfigStatefulHaConfig']:
        """
        .
        The status of the Stateful HA addon, which provides automatic configurable failover for stateful applications.
        It is disabled by default for Standard clusters. Set `enabled = true` to enable.
        """
        return pulumi.get(self, "stateful_ha_config")


@pulumi.output_type
class ClusterAddonsConfigCloudrunConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "loadBalancerType":
            suggest = "load_balancer_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAddonsConfigCloudrunConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAddonsConfigCloudrunConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAddonsConfigCloudrunConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disabled: _builtins.bool,
                 load_balancer_type: Optional[_builtins.str] = None):
        """
        :param _builtins.bool disabled: The status of the CloudRun addon. It is disabled by default. Set `disabled=false` to enable.
        :param _builtins.str load_balancer_type: The load balancer type of CloudRun ingress service. It is external load balancer by default.
               Set `load_balancer_type=LOAD_BALANCER_TYPE_INTERNAL` to configure it as internal load balancer.
        """
        pulumi.set(__self__, "disabled", disabled)
        if load_balancer_type is not None:
            pulumi.set(__self__, "load_balancer_type", load_balancer_type)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        """
        The status of the CloudRun addon. It is disabled by default. Set `disabled=false` to enable.
        """
        return pulumi.get(self, "disabled")

    @_builtins.property
    @pulumi.getter(name="loadBalancerType")
    def load_balancer_type(self) -> Optional[_builtins.str]:
        """
        The load balancer type of CloudRun ingress service. It is external load balancer by default.
        Set `load_balancer_type=LOAD_BALANCER_TYPE_INTERNAL` to configure it as internal load balancer.
        """
        return pulumi.get(self, "load_balancer_type")


@pulumi.output_type
class ClusterAddonsConfigConfigConnectorConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigDnsCacheConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigGcePersistentDiskCsiDriverConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigGcpFilestoreCsiDriverConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigGcsFuseCsiDriverConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigGkeBackupAgentConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigHorizontalPodAutoscaling(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        """
        :param _builtins.bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterAddonsConfigHttpLoadBalancing(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        """
        :param _builtins.bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterAddonsConfigIstioConfig(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool,
                 auth: Optional[_builtins.str] = None):
        """
        :param _builtins.bool disabled: The status of the Istio addon, which makes it easy to set up Istio for services in a
               cluster. It is disabled by default. Set `disabled = false` to enable.
        :param _builtins.str auth: The authentication type between services in Istio. Available options include `AUTH_MUTUAL_TLS`.
        """
        pulumi.set(__self__, "disabled", disabled)
        if auth is not None:
            pulumi.set(__self__, "auth", auth)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        """
        The status of the Istio addon, which makes it easy to set up Istio for services in a
        cluster. It is disabled by default. Set `disabled = false` to enable.
        """
        return pulumi.get(self, "disabled")

    @_builtins.property
    @pulumi.getter
    def auth(self) -> Optional[_builtins.str]:
        """
        The authentication type between services in Istio. Available options include `AUTH_MUTUAL_TLS`.
        """
        return pulumi.get(self, "auth")


@pulumi.output_type
class ClusterAddonsConfigKalmConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigLustreCsiDriverConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableLegacyLustrePort":
            suggest = "enable_legacy_lustre_port"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAddonsConfigLustreCsiDriverConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAddonsConfigLustreCsiDriverConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAddonsConfigLustreCsiDriverConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 enable_legacy_lustre_port: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool enabled: Whether the Lustre CSI driver is enabled for this cluster.
        :param _builtins.bool enable_legacy_lustre_port: If set to true, the Lustre CSI driver will initialize LNet (the virtual network layer for Lustre kernel module) using port 6988.
               										This flag is required to workaround a port conflict with the gke-metadata-server on GKE nodes.
        """
        pulumi.set(__self__, "enabled", enabled)
        if enable_legacy_lustre_port is not None:
            pulumi.set(__self__, "enable_legacy_lustre_port", enable_legacy_lustre_port)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether the Lustre CSI driver is enabled for this cluster.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="enableLegacyLustrePort")
    def enable_legacy_lustre_port(self) -> Optional[_builtins.bool]:
        """
        If set to true, the Lustre CSI driver will initialize LNet (the virtual network layer for Lustre kernel module) using port 6988.
        										This flag is required to workaround a port conflict with the gke-metadata-server on GKE nodes.
        """
        return pulumi.get(self, "enable_legacy_lustre_port")


@pulumi.output_type
class ClusterAddonsConfigNetworkPolicyConfig(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        """
        :param _builtins.bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterAddonsConfigParallelstoreCsiDriverConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigRayOperatorConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "rayClusterLoggingConfig":
            suggest = "ray_cluster_logging_config"
        elif key == "rayClusterMonitoringConfig":
            suggest = "ray_cluster_monitoring_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAddonsConfigRayOperatorConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAddonsConfigRayOperatorConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAddonsConfigRayOperatorConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 ray_cluster_logging_config: Optional['outputs.ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfig'] = None,
                 ray_cluster_monitoring_config: Optional['outputs.ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfig'] = None):
        """
        :param 'ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgs' ray_cluster_logging_config: The status of Ray Logging, which scrapes Ray cluster logs to Cloud Logging. Defaults to disabled; set enabled = true to enable.
        :param 'ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgs' ray_cluster_monitoring_config: The status of Ray Cluster monitoring, which shows Ray cluster metrics in Cloud Console. Defaults to disabled; set enabled = true to enable.
        """
        pulumi.set(__self__, "enabled", enabled)
        if ray_cluster_logging_config is not None:
            pulumi.set(__self__, "ray_cluster_logging_config", ray_cluster_logging_config)
        if ray_cluster_monitoring_config is not None:
            pulumi.set(__self__, "ray_cluster_monitoring_config", ray_cluster_monitoring_config)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="rayClusterLoggingConfig")
    def ray_cluster_logging_config(self) -> Optional['outputs.ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfig']:
        """
        The status of Ray Logging, which scrapes Ray cluster logs to Cloud Logging. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "ray_cluster_logging_config")

    @_builtins.property
    @pulumi.getter(name="rayClusterMonitoringConfig")
    def ray_cluster_monitoring_config(self) -> Optional['outputs.ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfig']:
        """
        The status of Ray Cluster monitoring, which shows Ray cluster metrics in Cloud Console. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "ray_cluster_monitoring_config")


@pulumi.output_type
class ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAddonsConfigStatefulHaConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterAnonymousAuthenticationConfig(dict):
    def __init__(__self__, *,
                 mode: _builtins.str):
        """
        :param _builtins.str mode: Sets or removes authentication restrictions. Available options include `LIMITED` and `ENABLED`.
        """
        pulumi.set(__self__, "mode", mode)

    @_builtins.property
    @pulumi.getter
    def mode(self) -> _builtins.str:
        """
        Sets or removes authentication restrictions. Available options include `LIMITED` and `ENABLED`.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class ClusterAuthenticatorGroupsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "securityGroup":
            suggest = "security_group"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAuthenticatorGroupsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAuthenticatorGroupsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAuthenticatorGroupsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 security_group: _builtins.str):
        """
        :param _builtins.str security_group: The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format `gke-security-groups@yourdomain.com`.
        """
        pulumi.set(__self__, "security_group", security_group)

    @_builtins.property
    @pulumi.getter(name="securityGroup")
    def security_group(self) -> _builtins.str:
        """
        The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format `gke-security-groups@yourdomain.com`.
        """
        return pulumi.get(self, "security_group")


@pulumi.output_type
class ClusterBinaryAuthorization(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "evaluationMode":
            suggest = "evaluation_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterBinaryAuthorization. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterBinaryAuthorization.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterBinaryAuthorization.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: Optional[_builtins.bool] = None,
                 evaluation_mode: Optional[_builtins.str] = None):
        """
        :param _builtins.bool enabled: Enable Binary Authorization for this cluster.
        :param _builtins.str evaluation_mode: Mode of operation for Binary Authorization policy evaluation.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @_builtins.property
    @pulumi.getter
    @_utilities.deprecated("""Deprecated in favor of evaluation_mode.""")
    def enabled(self) -> Optional[_builtins.bool]:
        """
        Enable Binary Authorization for this cluster.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[_builtins.str]:
        """
        Mode of operation for Binary Authorization policy evaluation.
        """
        return pulumi.get(self, "evaluation_mode")


@pulumi.output_type
class ClusterClusterAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoProvisioningDefaults":
            suggest = "auto_provisioning_defaults"
        elif key == "autoProvisioningLocations":
            suggest = "auto_provisioning_locations"
        elif key == "autoscalingProfile":
            suggest = "autoscaling_profile"
        elif key == "defaultComputeClassEnabled":
            suggest = "default_compute_class_enabled"
        elif key == "resourceLimits":
            suggest = "resource_limits"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_provisioning_defaults: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaults'] = None,
                 auto_provisioning_locations: Optional[Sequence[_builtins.str]] = None,
                 autoscaling_profile: Optional[_builtins.str] = None,
                 default_compute_class_enabled: Optional[_builtins.bool] = None,
                 enabled: Optional[_builtins.bool] = None,
                 resource_limits: Optional[Sequence['outputs.ClusterClusterAutoscalingResourceLimit']] = None):
        """
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsArgs' auto_provisioning_defaults: Contains defaults for a node pool created by NAP. A subset of fields also apply to
               GKE Autopilot clusters.
               Structure is documented below.
        :param Sequence[_builtins.str] auto_provisioning_locations: The list of Google Compute Engine
               [zones](https://cloud.google.com/compute/docs/zones#available) in which the
               NodePool's nodes can be created by NAP.
        :param _builtins.str autoscaling_profile: Configuration
               options for the [Autoscaling profile](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler#autoscaling_profiles)
               feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability
               when deciding to remove nodes from a cluster. Can be `BALANCED` or `OPTIMIZE_UTILIZATION`. Defaults to `BALANCED`.
        :param _builtins.bool default_compute_class_enabled: Specifies whether default compute class behaviour is enabled. If enabled, cluster autoscaler will use Compute Class with name default for all the workloads, if not overriden.
        :param _builtins.bool enabled: Whether node auto-provisioning is enabled. Must be supplied for GKE Standard clusters, `true` is implied
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
        :param Sequence['ClusterClusterAutoscalingResourceLimitArgs'] resource_limits: Global constraints for machine resources in the
               cluster. Configuring the `cpu` and `memory` types is required if node
               auto-provisioning is enabled. These limits will apply to node pool autoscaling
               in addition to node auto-provisioning. Structure is documented below.
        """
        if auto_provisioning_defaults is not None:
            pulumi.set(__self__, "auto_provisioning_defaults", auto_provisioning_defaults)
        if auto_provisioning_locations is not None:
            pulumi.set(__self__, "auto_provisioning_locations", auto_provisioning_locations)
        if autoscaling_profile is not None:
            pulumi.set(__self__, "autoscaling_profile", autoscaling_profile)
        if default_compute_class_enabled is not None:
            pulumi.set(__self__, "default_compute_class_enabled", default_compute_class_enabled)
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if resource_limits is not None:
            pulumi.set(__self__, "resource_limits", resource_limits)

    @_builtins.property
    @pulumi.getter(name="autoProvisioningDefaults")
    def auto_provisioning_defaults(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaults']:
        """
        Contains defaults for a node pool created by NAP. A subset of fields also apply to
        GKE Autopilot clusters.
        Structure is documented below.
        """
        return pulumi.get(self, "auto_provisioning_defaults")

    @_builtins.property
    @pulumi.getter(name="autoProvisioningLocations")
    def auto_provisioning_locations(self) -> Optional[Sequence[_builtins.str]]:
        """
        The list of Google Compute Engine
        [zones](https://cloud.google.com/compute/docs/zones#available) in which the
        NodePool's nodes can be created by NAP.
        """
        return pulumi.get(self, "auto_provisioning_locations")

    @_builtins.property
    @pulumi.getter(name="autoscalingProfile")
    def autoscaling_profile(self) -> Optional[_builtins.str]:
        """
        Configuration
        options for the [Autoscaling profile](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler#autoscaling_profiles)
        feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability
        when deciding to remove nodes from a cluster. Can be `BALANCED` or `OPTIMIZE_UTILIZATION`. Defaults to `BALANCED`.
        """
        return pulumi.get(self, "autoscaling_profile")

    @_builtins.property
    @pulumi.getter(name="defaultComputeClassEnabled")
    def default_compute_class_enabled(self) -> Optional[_builtins.bool]:
        """
        Specifies whether default compute class behaviour is enabled. If enabled, cluster autoscaler will use Compute Class with name default for all the workloads, if not overriden.
        """
        return pulumi.get(self, "default_compute_class_enabled")

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> Optional[_builtins.bool]:
        """
        Whether node auto-provisioning is enabled. Must be supplied for GKE Standard clusters, `true` is implied
        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="resourceLimits")
    def resource_limits(self) -> Optional[Sequence['outputs.ClusterClusterAutoscalingResourceLimit']]:
        """
        Global constraints for machine resources in the
        cluster. Configuring the `cpu` and `memory` types is required if node
        auto-provisioning is enabled. These limits will apply to node pool autoscaling
        in addition to node auto-provisioning. Structure is documented below.
        """
        return pulumi.get(self, "resource_limits")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaults(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskKmsKey":
            suggest = "boot_disk_kms_key"
        elif key == "diskSize":
            suggest = "disk_size"
        elif key == "diskType":
            suggest = "disk_type"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "minCpuPlatform":
            suggest = "min_cpu_platform"
        elif key == "oauthScopes":
            suggest = "oauth_scopes"
        elif key == "serviceAccount":
            suggest = "service_account"
        elif key == "shieldedInstanceConfig":
            suggest = "shielded_instance_config"
        elif key == "upgradeSettings":
            suggest = "upgrade_settings"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaults. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaults.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaults.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 boot_disk_kms_key: Optional[_builtins.str] = None,
                 disk_size: Optional[_builtins.int] = None,
                 disk_type: Optional[_builtins.str] = None,
                 image_type: Optional[_builtins.str] = None,
                 management: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsManagement'] = None,
                 min_cpu_platform: Optional[_builtins.str] = None,
                 oauth_scopes: Optional[Sequence[_builtins.str]] = None,
                 service_account: Optional[_builtins.str] = None,
                 shielded_instance_config: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig'] = None,
                 upgrade_settings: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings'] = None):
        """
        :param _builtins.str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
        :param _builtins.int disk_size: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. Defaults to `100`
        :param _builtins.str disk_type: Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd', 'pd-balanced', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`.
        :param _builtins.str image_type: The default image type used by NAP once a new node pool is being created. Please note that according to the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning#default-image-type) the value must be one of the [COS_CONTAINERD, COS, UBUNTU_CONTAINERD, UBUNTU]. __NOTE__ : COS AND UBUNTU are deprecated as of `GKE 1.24`
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs' management: NodeManagement configuration for this NodePool. Structure is documented below.
        :param _builtins.str min_cpu_platform: Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the
               specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such
               as "Intel Haswell" or "Intel Sandy Bridge".
        :param Sequence[_builtins.str] oauth_scopes: Scopes that are used by NAP and GKE Autopilot when creating node pools. Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               > `monitoring.write` is always enabled regardless of user input.  `monitoring` and `logging.write` may also be enabled depending on the values for `monitoring_service` and `logging_service`.
        :param _builtins.str service_account: The `email` of the Google Cloud Platform Service Account to be used by the node VMs created by GKE Autopilot or NAP.
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs' shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs' upgrade_settings: Specifies the upgrade settings for NAP created node pools
        """
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if disk_size is not None:
            pulumi.set(__self__, "disk_size", disk_size)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if management is not None:
            pulumi.set(__self__, "management", management)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if upgrade_settings is not None:
            pulumi.set(__self__, "upgrade_settings", upgrade_settings)

    @_builtins.property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[_builtins.str]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @_builtins.property
    @pulumi.getter(name="diskSize")
    def disk_size(self) -> Optional[_builtins.int]:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. Defaults to `100`
        """
        return pulumi.get(self, "disk_size")

    @_builtins.property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[_builtins.str]:
        """
        Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd', 'pd-balanced', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`.
        """
        return pulumi.get(self, "disk_type")

    @_builtins.property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[_builtins.str]:
        """
        The default image type used by NAP once a new node pool is being created. Please note that according to the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning#default-image-type) the value must be one of the [COS_CONTAINERD, COS, UBUNTU_CONTAINERD, UBUNTU]. __NOTE__ : COS AND UBUNTU are deprecated as of `GKE 1.24`
        """
        return pulumi.get(self, "image_type")

    @_builtins.property
    @pulumi.getter
    def management(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsManagement']:
        """
        NodeManagement configuration for this NodePool. Structure is documented below.
        """
        return pulumi.get(self, "management")

    @_builtins.property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[_builtins.str]:
        """
        Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the
        specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such
        as "Intel Haswell" or "Intel Sandy Bridge".
        """
        return pulumi.get(self, "min_cpu_platform")

    @_builtins.property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[Sequence[_builtins.str]]:
        """
        Scopes that are used by NAP and GKE Autopilot when creating node pools. Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        > `monitoring.write` is always enabled regardless of user input.  `monitoring` and `logging.write` may also be enabled depending on the values for `monitoring_service` and `logging_service`.
        """
        return pulumi.get(self, "oauth_scopes")

    @_builtins.property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[_builtins.str]:
        """
        The `email` of the Google Cloud Platform Service Account to be used by the node VMs created by GKE Autopilot or NAP.
        """
        return pulumi.get(self, "service_account")

    @_builtins.property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig']:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @_builtins.property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings']:
        """
        Specifies the upgrade settings for NAP created node pools
        """
        return pulumi.get(self, "upgrade_settings")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"
        elif key == "autoUpgrade":
            suggest = "auto_upgrade"
        elif key == "upgradeOptions":
            suggest = "upgrade_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[_builtins.bool] = None,
                 auto_upgrade: Optional[_builtins.bool] = None,
                 upgrade_options: Optional[Sequence['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption']] = None):
        """
        :param _builtins.bool auto_repair: Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
               
               This block also contains several computed attributes, documented below.
        :param _builtins.bool auto_upgrade: Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        :param Sequence['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs'] upgrade_options: Specifies the [Auto Upgrade knobs](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/NodeManagement#AutoUpgradeOptions) for the node pool.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)
        if upgrade_options is not None:
            pulumi.set(__self__, "upgrade_options", upgrade_options)

    @_builtins.property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[_builtins.bool]:
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.

        This block also contains several computed attributes, documented below.
        """
        return pulumi.get(self, "auto_repair")

    @_builtins.property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[_builtins.bool]:
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        return pulumi.get(self, "auto_upgrade")

    @_builtins.property
    @pulumi.getter(name="upgradeOptions")
    def upgrade_options(self) -> Optional[Sequence['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption']]:
        """
        Specifies the [Auto Upgrade knobs](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/NodeManagement#AutoUpgradeOptions) for the node pool.
        """
        return pulumi.get(self, "upgrade_options")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoUpgradeStartTime":
            suggest = "auto_upgrade_start_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_upgrade_start_time: Optional[_builtins.str] = None,
                 description: Optional[_builtins.str] = None):
        """
        :param _builtins.str auto_upgrade_start_time: This field is set when upgrades are about to commence with the approximate start time for the upgrades, in RFC3339 text format.
        :param _builtins.str description: Description of the cluster.
        """
        if auto_upgrade_start_time is not None:
            pulumi.set(__self__, "auto_upgrade_start_time", auto_upgrade_start_time)
        if description is not None:
            pulumi.set(__self__, "description", description)

    @_builtins.property
    @pulumi.getter(name="autoUpgradeStartTime")
    def auto_upgrade_start_time(self) -> Optional[_builtins.str]:
        """
        This field is set when upgrades are about to commence with the approximate start time for the upgrades, in RFC3339 text format.
        """
        return pulumi.get(self, "auto_upgrade_start_time")

    @_builtins.property
    @pulumi.getter
    def description(self) -> Optional[_builtins.str]:
        """
        Description of the cluster.
        """
        return pulumi.get(self, "description")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableIntegrityMonitoring":
            suggest = "enable_integrity_monitoring"
        elif key == "enableSecureBoot":
            suggest = "enable_secure_boot"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[_builtins.bool] = None,
                 enable_secure_boot: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param _builtins.bool enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @_builtins.property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[_builtins.bool]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @_builtins.property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[_builtins.bool]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "blueGreenSettings":
            suggest = "blue_green_settings"
        elif key == "maxSurge":
            suggest = "max_surge"
        elif key == "maxUnavailable":
            suggest = "max_unavailable"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 blue_green_settings: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings'] = None,
                 max_surge: Optional[_builtins.int] = None,
                 max_unavailable: Optional[_builtins.int] = None,
                 strategy: Optional[_builtins.str] = None):
        """
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs' blue_green_settings: Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param _builtins.int max_surge: The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param _builtins.int max_unavailable: The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param _builtins.str strategy: Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @_builtins.property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings']:
        """
        Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "blue_green_settings")

    @_builtins.property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[_builtins.int]:
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_surge")

    @_builtins.property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[_builtins.int]:
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_unavailable")

    @_builtins.property
    @pulumi.getter
    def strategy(self) -> Optional[_builtins.str]:
        """
        Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodePoolSoakDuration":
            suggest = "node_pool_soak_duration"
        elif key == "standardRolloutPolicy":
            suggest = "standard_rollout_policy"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_pool_soak_duration: Optional[_builtins.str] = None,
                 standard_rollout_policy: Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy'] = None):
        """
        :param _builtins.str node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        :param 'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs' standard_rollout_policy: Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        if standard_rollout_policy is not None:
            pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)

    @_builtins.property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[_builtins.str]:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @_builtins.property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> Optional['outputs.ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy']:
        """
        Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "standard_rollout_policy")


@pulumi.output_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "batchNodeCount":
            suggest = "batch_node_count"
        elif key == "batchPercentage":
            suggest = "batch_percentage"
        elif key == "batchSoakDuration":
            suggest = "batch_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 batch_node_count: Optional[_builtins.int] = None,
                 batch_percentage: Optional[_builtins.float] = None,
                 batch_soak_duration: Optional[_builtins.str] = None):
        """
        :param _builtins.int batch_node_count: Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        :param _builtins.float batch_percentage: Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        :param _builtins.str batch_soak_duration: Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @_builtins.property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[_builtins.int]:
        """
        Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_node_count")

    @_builtins.property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[_builtins.float]:
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_percentage")

    @_builtins.property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[_builtins.str]:
        """
        Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class ClusterClusterAutoscalingResourceLimit(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "resourceType":
            suggest = "resource_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterAutoscalingResourceLimit. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterAutoscalingResourceLimit.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterAutoscalingResourceLimit.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 maximum: _builtins.int,
                 resource_type: _builtins.str,
                 minimum: Optional[_builtins.int] = None):
        """
        :param _builtins.int maximum: Maximum amount of the resource in the cluster.
        :param _builtins.str resource_type: The type of the resource. For example, `cpu` and
               `memory`.  See the [guide to using Node Auto-Provisioning](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)
               for a list of types.
        :param _builtins.int minimum: Minimum amount of the resource in the cluster.
        """
        pulumi.set(__self__, "maximum", maximum)
        pulumi.set(__self__, "resource_type", resource_type)
        if minimum is not None:
            pulumi.set(__self__, "minimum", minimum)

    @_builtins.property
    @pulumi.getter
    def maximum(self) -> _builtins.int:
        """
        Maximum amount of the resource in the cluster.
        """
        return pulumi.get(self, "maximum")

    @_builtins.property
    @pulumi.getter(name="resourceType")
    def resource_type(self) -> _builtins.str:
        """
        The type of the resource. For example, `cpu` and
        `memory`.  See the [guide to using Node Auto-Provisioning](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)
        for a list of types.
        """
        return pulumi.get(self, "resource_type")

    @_builtins.property
    @pulumi.getter
    def minimum(self) -> Optional[_builtins.int]:
        """
        Minimum amount of the resource in the cluster.
        """
        return pulumi.get(self, "minimum")


@pulumi.output_type
class ClusterClusterTelemetry(dict):
    def __init__(__self__, *,
                 type: _builtins.str):
        """
        :param _builtins.str type: Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
               `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
        `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class ClusterConfidentialNodes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "confidentialInstanceType":
            suggest = "confidential_instance_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterConfidentialNodes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterConfidentialNodes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterConfidentialNodes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 confidential_instance_type: Optional[_builtins.str] = None):
        """
        :param _builtins.bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        :param _builtins.str confidential_instance_type: Defines the type of technology used
               by the confidential node.
        """
        pulumi.set(__self__, "enabled", enabled)
        if confidential_instance_type is not None:
            pulumi.set(__self__, "confidential_instance_type", confidential_instance_type)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="confidentialInstanceType")
    def confidential_instance_type(self) -> Optional[_builtins.str]:
        """
        Defines the type of technology used
        by the confidential node.
        """
        return pulumi.get(self, "confidential_instance_type")


@pulumi.output_type
class ClusterControlPlaneEndpointsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dnsEndpointConfig":
            suggest = "dns_endpoint_config"
        elif key == "ipEndpointsConfig":
            suggest = "ip_endpoints_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterControlPlaneEndpointsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterControlPlaneEndpointsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterControlPlaneEndpointsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dns_endpoint_config: Optional['outputs.ClusterControlPlaneEndpointsConfigDnsEndpointConfig'] = None,
                 ip_endpoints_config: Optional['outputs.ClusterControlPlaneEndpointsConfigIpEndpointsConfig'] = None):
        """
        :param 'ClusterControlPlaneEndpointsConfigDnsEndpointConfigArgs' dns_endpoint_config: DNS endpoint configuration.
        :param 'ClusterControlPlaneEndpointsConfigIpEndpointsConfigArgs' ip_endpoints_config: IP endpoint configuration.
        """
        if dns_endpoint_config is not None:
            pulumi.set(__self__, "dns_endpoint_config", dns_endpoint_config)
        if ip_endpoints_config is not None:
            pulumi.set(__self__, "ip_endpoints_config", ip_endpoints_config)

    @_builtins.property
    @pulumi.getter(name="dnsEndpointConfig")
    def dns_endpoint_config(self) -> Optional['outputs.ClusterControlPlaneEndpointsConfigDnsEndpointConfig']:
        """
        DNS endpoint configuration.
        """
        return pulumi.get(self, "dns_endpoint_config")

    @_builtins.property
    @pulumi.getter(name="ipEndpointsConfig")
    def ip_endpoints_config(self) -> Optional['outputs.ClusterControlPlaneEndpointsConfigIpEndpointsConfig']:
        """
        IP endpoint configuration.
        """
        return pulumi.get(self, "ip_endpoints_config")


@pulumi.output_type
class ClusterControlPlaneEndpointsConfigDnsEndpointConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowExternalTraffic":
            suggest = "allow_external_traffic"
        elif key == "enableK8sCertsViaDns":
            suggest = "enable_k8s_certs_via_dns"
        elif key == "enableK8sTokensViaDns":
            suggest = "enable_k8s_tokens_via_dns"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterControlPlaneEndpointsConfigDnsEndpointConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterControlPlaneEndpointsConfigDnsEndpointConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterControlPlaneEndpointsConfigDnsEndpointConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allow_external_traffic: Optional[_builtins.bool] = None,
                 enable_k8s_certs_via_dns: Optional[_builtins.bool] = None,
                 enable_k8s_tokens_via_dns: Optional[_builtins.bool] = None,
                 endpoint: Optional[_builtins.str] = None):
        """
        :param _builtins.bool allow_external_traffic: Controls whether user traffic is allowed over this endpoint. Note that GCP-managed services may still use the endpoint even if this is false.
        :param _builtins.bool enable_k8s_certs_via_dns: Controls whether the k8s certs auth is allowed via Dns.
        :param _builtins.bool enable_k8s_tokens_via_dns: Controls whether the k8s token auth is allowed via Dns.
        :param _builtins.str endpoint: The cluster's DNS endpoint.
        """
        if allow_external_traffic is not None:
            pulumi.set(__self__, "allow_external_traffic", allow_external_traffic)
        if enable_k8s_certs_via_dns is not None:
            pulumi.set(__self__, "enable_k8s_certs_via_dns", enable_k8s_certs_via_dns)
        if enable_k8s_tokens_via_dns is not None:
            pulumi.set(__self__, "enable_k8s_tokens_via_dns", enable_k8s_tokens_via_dns)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)

    @_builtins.property
    @pulumi.getter(name="allowExternalTraffic")
    def allow_external_traffic(self) -> Optional[_builtins.bool]:
        """
        Controls whether user traffic is allowed over this endpoint. Note that GCP-managed services may still use the endpoint even if this is false.
        """
        return pulumi.get(self, "allow_external_traffic")

    @_builtins.property
    @pulumi.getter(name="enableK8sCertsViaDns")
    def enable_k8s_certs_via_dns(self) -> Optional[_builtins.bool]:
        """
        Controls whether the k8s certs auth is allowed via Dns.
        """
        return pulumi.get(self, "enable_k8s_certs_via_dns")

    @_builtins.property
    @pulumi.getter(name="enableK8sTokensViaDns")
    def enable_k8s_tokens_via_dns(self) -> Optional[_builtins.bool]:
        """
        Controls whether the k8s token auth is allowed via Dns.
        """
        return pulumi.get(self, "enable_k8s_tokens_via_dns")

    @_builtins.property
    @pulumi.getter
    def endpoint(self) -> Optional[_builtins.str]:
        """
        The cluster's DNS endpoint.
        """
        return pulumi.get(self, "endpoint")


@pulumi.output_type
class ClusterControlPlaneEndpointsConfigIpEndpointsConfig(dict):
    def __init__(__self__, *,
                 enabled: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool enabled: Controls whether to allow direct IP access. Defaults to `true`.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> Optional[_builtins.bool]:
        """
        Controls whether to allow direct IP access. Defaults to `true`.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterCostManagementConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether to enable the [cost allocation](https://cloud.google.com/kubernetes-engine/docs/how-to/cost-allocations) feature.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether to enable the [cost allocation](https://cloud.google.com/kubernetes-engine/docs/how-to/cost-allocations) feature.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterDatabaseEncryption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "keyName":
            suggest = "key_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterDatabaseEncryption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterDatabaseEncryption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterDatabaseEncryption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 state: _builtins.str,
                 key_name: Optional[_builtins.str] = None):
        """
        :param _builtins.str state: `ENCRYPTED` or `DECRYPTED`
        :param _builtins.str key_name: the key to use to encrypt/decrypt secrets.  See the [DatabaseEncryption definition](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.DatabaseEncryption) for more information.
               
               <a name="nested_enable_k8s_beta_apis"></a>The `enable_k8s_beta_apis` block supports:
        """
        pulumi.set(__self__, "state", state)
        if key_name is not None:
            pulumi.set(__self__, "key_name", key_name)

    @_builtins.property
    @pulumi.getter
    def state(self) -> _builtins.str:
        """
        `ENCRYPTED` or `DECRYPTED`
        """
        return pulumi.get(self, "state")

    @_builtins.property
    @pulumi.getter(name="keyName")
    def key_name(self) -> Optional[_builtins.str]:
        """
        the key to use to encrypt/decrypt secrets.  See the [DatabaseEncryption definition](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.DatabaseEncryption) for more information.

        <a name="nested_enable_k8s_beta_apis"></a>The `enable_k8s_beta_apis` block supports:
        """
        return pulumi.get(self, "key_name")


@pulumi.output_type
class ClusterDefaultSnatStatus(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        """
        :param _builtins.bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterDnsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "additiveVpcScopeDnsDomain":
            suggest = "additive_vpc_scope_dns_domain"
        elif key == "clusterDns":
            suggest = "cluster_dns"
        elif key == "clusterDnsDomain":
            suggest = "cluster_dns_domain"
        elif key == "clusterDnsScope":
            suggest = "cluster_dns_scope"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterDnsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterDnsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterDnsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 additive_vpc_scope_dns_domain: Optional[_builtins.str] = None,
                 cluster_dns: Optional[_builtins.str] = None,
                 cluster_dns_domain: Optional[_builtins.str] = None,
                 cluster_dns_scope: Optional[_builtins.str] = None):
        """
        :param _builtins.str additive_vpc_scope_dns_domain: This will enable Cloud DNS additive VPC scope. Must provide a domain name that is unique within the VPC. For this to work `cluster_dns = "CLOUD_DNS"` and `cluster_dns_scope = "CLUSTER_SCOPE"` must both be set as well.
        :param _builtins.str cluster_dns: Which in-cluster DNS provider should be used. `PROVIDER_UNSPECIFIED` (default) or `PLATFORM_DEFAULT` or `CLOUD_DNS` or `KUBE_DNS`.
        :param _builtins.str cluster_dns_domain: The suffix used for all cluster service records.
        :param _builtins.str cluster_dns_scope: The scope of access to cluster DNS records. `DNS_SCOPE_UNSPECIFIED` or `CLUSTER_SCOPE` or `VPC_SCOPE`. If the `cluster_dns` field is set to `CLOUD_DNS`, `DNS_SCOPE_UNSPECIFIED` and empty/null behave like `CLUSTER_SCOPE`.
        """
        if additive_vpc_scope_dns_domain is not None:
            pulumi.set(__self__, "additive_vpc_scope_dns_domain", additive_vpc_scope_dns_domain)
        if cluster_dns is not None:
            pulumi.set(__self__, "cluster_dns", cluster_dns)
        if cluster_dns_domain is not None:
            pulumi.set(__self__, "cluster_dns_domain", cluster_dns_domain)
        if cluster_dns_scope is not None:
            pulumi.set(__self__, "cluster_dns_scope", cluster_dns_scope)

    @_builtins.property
    @pulumi.getter(name="additiveVpcScopeDnsDomain")
    def additive_vpc_scope_dns_domain(self) -> Optional[_builtins.str]:
        """
        This will enable Cloud DNS additive VPC scope. Must provide a domain name that is unique within the VPC. For this to work `cluster_dns = "CLOUD_DNS"` and `cluster_dns_scope = "CLUSTER_SCOPE"` must both be set as well.
        """
        return pulumi.get(self, "additive_vpc_scope_dns_domain")

    @_builtins.property
    @pulumi.getter(name="clusterDns")
    def cluster_dns(self) -> Optional[_builtins.str]:
        """
        Which in-cluster DNS provider should be used. `PROVIDER_UNSPECIFIED` (default) or `PLATFORM_DEFAULT` or `CLOUD_DNS` or `KUBE_DNS`.
        """
        return pulumi.get(self, "cluster_dns")

    @_builtins.property
    @pulumi.getter(name="clusterDnsDomain")
    def cluster_dns_domain(self) -> Optional[_builtins.str]:
        """
        The suffix used for all cluster service records.
        """
        return pulumi.get(self, "cluster_dns_domain")

    @_builtins.property
    @pulumi.getter(name="clusterDnsScope")
    def cluster_dns_scope(self) -> Optional[_builtins.str]:
        """
        The scope of access to cluster DNS records. `DNS_SCOPE_UNSPECIFIED` or `CLUSTER_SCOPE` or `VPC_SCOPE`. If the `cluster_dns` field is set to `CLOUD_DNS`, `DNS_SCOPE_UNSPECIFIED` and empty/null behave like `CLUSTER_SCOPE`.
        """
        return pulumi.get(self, "cluster_dns_scope")


@pulumi.output_type
class ClusterEnableK8sBetaApis(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enabledApis":
            suggest = "enabled_apis"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterEnableK8sBetaApis. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterEnableK8sBetaApis.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterEnableK8sBetaApis.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled_apis: Sequence[_builtins.str]):
        """
        :param Sequence[_builtins.str] enabled_apis: Enabled Kubernetes Beta APIs.
        """
        pulumi.set(__self__, "enabled_apis", enabled_apis)

    @_builtins.property
    @pulumi.getter(name="enabledApis")
    def enabled_apis(self) -> Sequence[_builtins.str]:
        """
        Enabled Kubernetes Beta APIs.
        """
        return pulumi.get(self, "enabled_apis")


@pulumi.output_type
class ClusterEnterpriseConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "clusterTier":
            suggest = "cluster_tier"
        elif key == "desiredTier":
            suggest = "desired_tier"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterEnterpriseConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterEnterpriseConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterEnterpriseConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cluster_tier: Optional[_builtins.str] = None,
                 desired_tier: Optional[_builtins.str] = None):
        """
        :param _builtins.str cluster_tier: The effective tier of the cluster.
        :param _builtins.str desired_tier: (DEPRECATED) Sets the tier of the cluster. Available options include `STANDARD` and `ENTERPRISE`. Deprecated as GKE Enterprise features are now available without an Enterprise tier. See https://cloud.google.com/blog/products/containers-kubernetes/gke-gets-new-pricing-and-capabilities-on-10th-birthday for the announcement of this change.
        """
        if cluster_tier is not None:
            pulumi.set(__self__, "cluster_tier", cluster_tier)
        if desired_tier is not None:
            pulumi.set(__self__, "desired_tier", desired_tier)

    @_builtins.property
    @pulumi.getter(name="clusterTier")
    @_utilities.deprecated("""GKE Enterprise features are now available without an Enterprise tier. This field is deprecated and will be removed in a future major release""")
    def cluster_tier(self) -> Optional[_builtins.str]:
        """
        The effective tier of the cluster.
        """
        return pulumi.get(self, "cluster_tier")

    @_builtins.property
    @pulumi.getter(name="desiredTier")
    @_utilities.deprecated("""GKE Enterprise features are now available without an Enterprise tier. This field is deprecated and will be removed in a future major release""")
    def desired_tier(self) -> Optional[_builtins.str]:
        """
        (DEPRECATED) Sets the tier of the cluster. Available options include `STANDARD` and `ENTERPRISE`. Deprecated as GKE Enterprise features are now available without an Enterprise tier. See https://cloud.google.com/blog/products/containers-kubernetes/gke-gets-new-pricing-and-capabilities-on-10th-birthday for the announcement of this change.
        """
        return pulumi.get(self, "desired_tier")


@pulumi.output_type
class ClusterFleet(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "membershipId":
            suggest = "membership_id"
        elif key == "membershipLocation":
            suggest = "membership_location"
        elif key == "membershipType":
            suggest = "membership_type"
        elif key == "preRegistered":
            suggest = "pre_registered"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterFleet. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterFleet.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterFleet.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 membership: Optional[_builtins.str] = None,
                 membership_id: Optional[_builtins.str] = None,
                 membership_location: Optional[_builtins.str] = None,
                 membership_type: Optional[_builtins.str] = None,
                 pre_registered: Optional[_builtins.bool] = None,
                 project: Optional[_builtins.str] = None):
        """
        :param _builtins.str membership: The resource name of the fleet Membership resource associated to this cluster with format `//gkehub.googleapis.com/projects/{{project}}/locations/{{location}}/memberships/{{name}}`. See the official doc for [fleet management](https://cloud.google.com/kubernetes-engine/docs/fleets-overview).
        :param _builtins.str membership_id: The short name of the fleet membership, extracted from `fleet.0.membership`. You can use this field to configure `membership_id` under google_gkehub_feature_membership.
        :param _builtins.str membership_location: The location of the fleet membership,  extracted from `fleet.0.membership`. You can use this field to configure `membership_location` under google_gkehub_feature_membership.
        :param _builtins.str membership_type: Sets the membership type of the cluster.  Available option is `LIGHTWEIGHT` to support only lightweight compatible features.  If unspecified, the membership_type will be a regular membership that supports all features.
        :param _builtins.bool pre_registered: Whether the cluster has been registered via the fleet API.
        :param _builtins.str project: The name of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if membership_id is not None:
            pulumi.set(__self__, "membership_id", membership_id)
        if membership_location is not None:
            pulumi.set(__self__, "membership_location", membership_location)
        if membership_type is not None:
            pulumi.set(__self__, "membership_type", membership_type)
        if pre_registered is not None:
            pulumi.set(__self__, "pre_registered", pre_registered)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @_builtins.property
    @pulumi.getter
    def membership(self) -> Optional[_builtins.str]:
        """
        The resource name of the fleet Membership resource associated to this cluster with format `//gkehub.googleapis.com/projects/{{project}}/locations/{{location}}/memberships/{{name}}`. See the official doc for [fleet management](https://cloud.google.com/kubernetes-engine/docs/fleets-overview).
        """
        return pulumi.get(self, "membership")

    @_builtins.property
    @pulumi.getter(name="membershipId")
    def membership_id(self) -> Optional[_builtins.str]:
        """
        The short name of the fleet membership, extracted from `fleet.0.membership`. You can use this field to configure `membership_id` under google_gkehub_feature_membership.
        """
        return pulumi.get(self, "membership_id")

    @_builtins.property
    @pulumi.getter(name="membershipLocation")
    def membership_location(self) -> Optional[_builtins.str]:
        """
        The location of the fleet membership,  extracted from `fleet.0.membership`. You can use this field to configure `membership_location` under google_gkehub_feature_membership.
        """
        return pulumi.get(self, "membership_location")

    @_builtins.property
    @pulumi.getter(name="membershipType")
    def membership_type(self) -> Optional[_builtins.str]:
        """
        Sets the membership type of the cluster.  Available option is `LIGHTWEIGHT` to support only lightweight compatible features.  If unspecified, the membership_type will be a regular membership that supports all features.
        """
        return pulumi.get(self, "membership_type")

    @_builtins.property
    @pulumi.getter(name="preRegistered")
    def pre_registered(self) -> Optional[_builtins.bool]:
        """
        Whether the cluster has been registered via the fleet API.
        """
        return pulumi.get(self, "pre_registered")

    @_builtins.property
    @pulumi.getter
    def project(self) -> Optional[_builtins.str]:
        """
        The name of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")


@pulumi.output_type
class ClusterGatewayApiConfig(dict):
    def __init__(__self__, *,
                 channel: _builtins.str):
        """
        :param _builtins.str channel: Which Gateway Api channel should be used. `CHANNEL_DISABLED`, `CHANNEL_EXPERIMENTAL` or `CHANNEL_STANDARD`.
        """
        pulumi.set(__self__, "channel", channel)

    @_builtins.property
    @pulumi.getter
    def channel(self) -> _builtins.str:
        """
        Which Gateway Api channel should be used. `CHANNEL_DISABLED`, `CHANNEL_EXPERIMENTAL` or `CHANNEL_STANDARD`.
        """
        return pulumi.get(self, "channel")


@pulumi.output_type
class ClusterGkeAutoUpgradeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "patchMode":
            suggest = "patch_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterGkeAutoUpgradeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterGkeAutoUpgradeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterGkeAutoUpgradeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 patch_mode: _builtins.str):
        """
        :param _builtins.str patch_mode: The selected patch mode.
               Accepted values are:
               * ACCELERATED: Upgrades to the latest available patch version in a given minor and release channel.
        """
        pulumi.set(__self__, "patch_mode", patch_mode)

    @_builtins.property
    @pulumi.getter(name="patchMode")
    def patch_mode(self) -> _builtins.str:
        """
        The selected patch mode.
        Accepted values are:
        * ACCELERATED: Upgrades to the latest available patch version in a given minor and release channel.
        """
        return pulumi.get(self, "patch_mode")


@pulumi.output_type
class ClusterIdentityServiceConfig(dict):
    def __init__(__self__, *,
                 enabled: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool enabled: Whether to enable the Identity Service component. It is disabled by default. Set `enabled=true` to enable.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> Optional[_builtins.bool]:
        """
        Whether to enable the Identity Service component. It is disabled by default. Set `enabled=true` to enable.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterIpAllocationPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "additionalIpRangesConfigs":
            suggest = "additional_ip_ranges_configs"
        elif key == "additionalPodRangesConfig":
            suggest = "additional_pod_ranges_config"
        elif key == "autoIpamConfig":
            suggest = "auto_ipam_config"
        elif key == "clusterIpv4CidrBlock":
            suggest = "cluster_ipv4_cidr_block"
        elif key == "clusterSecondaryRangeName":
            suggest = "cluster_secondary_range_name"
        elif key == "networkTierConfig":
            suggest = "network_tier_config"
        elif key == "podCidrOverprovisionConfig":
            suggest = "pod_cidr_overprovision_config"
        elif key == "servicesIpv4CidrBlock":
            suggest = "services_ipv4_cidr_block"
        elif key == "servicesSecondaryRangeName":
            suggest = "services_secondary_range_name"
        elif key == "stackType":
            suggest = "stack_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterIpAllocationPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterIpAllocationPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterIpAllocationPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 additional_ip_ranges_configs: Optional[Sequence['outputs.ClusterIpAllocationPolicyAdditionalIpRangesConfig']] = None,
                 additional_pod_ranges_config: Optional['outputs.ClusterIpAllocationPolicyAdditionalPodRangesConfig'] = None,
                 auto_ipam_config: Optional['outputs.ClusterIpAllocationPolicyAutoIpamConfig'] = None,
                 cluster_ipv4_cidr_block: Optional[_builtins.str] = None,
                 cluster_secondary_range_name: Optional[_builtins.str] = None,
                 network_tier_config: Optional['outputs.ClusterIpAllocationPolicyNetworkTierConfig'] = None,
                 pod_cidr_overprovision_config: Optional['outputs.ClusterIpAllocationPolicyPodCidrOverprovisionConfig'] = None,
                 services_ipv4_cidr_block: Optional[_builtins.str] = None,
                 services_secondary_range_name: Optional[_builtins.str] = None,
                 stack_type: Optional[_builtins.str] = None):
        """
        :param Sequence['ClusterIpAllocationPolicyAdditionalIpRangesConfigArgs'] additional_ip_ranges_configs: The configuration for individual additional subnetworks attached to the cluster.
               Structure is documented below.
        :param 'ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs' additional_pod_ranges_config: The configuration for additional pod secondary ranges at
               the cluster level. Used for Autopilot clusters and Standard clusters with which control of the
               secondary Pod IP address assignment to node pools isn't needed. Structure is documented below.
        :param 'ClusterIpAllocationPolicyAutoIpamConfigArgs' auto_ipam_config: All the information related to Auto IPAM. Structure is documented below
        :param _builtins.str cluster_ipv4_cidr_block: The IP address range for the cluster pod IPs.
               Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
               to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
               from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
               pick a specific range to use.
        :param _builtins.str cluster_secondary_range_name: The name of the existing secondary
               range in the cluster's subnetwork to use for pod IP addresses. Alternatively,
               `cluster_ipv4_cidr_block` can be used to automatically create a GKE-managed one.
        :param 'ClusterIpAllocationPolicyNetworkTierConfigArgs' network_tier_config: Contains network tier information. Structure is documented below
               
               <a name="nested_auto_ipam_config"></a>The auto ipam config supports:
        :param 'ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs' pod_cidr_overprovision_config: Configuration for cluster level pod cidr overprovision. Default is disabled=false.
        :param _builtins.str services_ipv4_cidr_block: The IP address range of the services IPs in this cluster.
               Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
               to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
               from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
               pick a specific range to use.
        :param _builtins.str services_secondary_range_name: The name of the existing
               secondary range in the cluster's subnetwork to use for service `ClusterIP`s.
               Alternatively, `services_ipv4_cidr_block` can be used to automatically create a
               GKE-managed one.
        :param _builtins.str stack_type: The IP Stack Type of the cluster.
               Default value is `IPV4`.
               Possible values are `IPV4` and `IPV4_IPV6`.
        """
        if additional_ip_ranges_configs is not None:
            pulumi.set(__self__, "additional_ip_ranges_configs", additional_ip_ranges_configs)
        if additional_pod_ranges_config is not None:
            pulumi.set(__self__, "additional_pod_ranges_config", additional_pod_ranges_config)
        if auto_ipam_config is not None:
            pulumi.set(__self__, "auto_ipam_config", auto_ipam_config)
        if cluster_ipv4_cidr_block is not None:
            pulumi.set(__self__, "cluster_ipv4_cidr_block", cluster_ipv4_cidr_block)
        if cluster_secondary_range_name is not None:
            pulumi.set(__self__, "cluster_secondary_range_name", cluster_secondary_range_name)
        if network_tier_config is not None:
            pulumi.set(__self__, "network_tier_config", network_tier_config)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if services_ipv4_cidr_block is not None:
            pulumi.set(__self__, "services_ipv4_cidr_block", services_ipv4_cidr_block)
        if services_secondary_range_name is not None:
            pulumi.set(__self__, "services_secondary_range_name", services_secondary_range_name)
        if stack_type is not None:
            pulumi.set(__self__, "stack_type", stack_type)

    @_builtins.property
    @pulumi.getter(name="additionalIpRangesConfigs")
    def additional_ip_ranges_configs(self) -> Optional[Sequence['outputs.ClusterIpAllocationPolicyAdditionalIpRangesConfig']]:
        """
        The configuration for individual additional subnetworks attached to the cluster.
        Structure is documented below.
        """
        return pulumi.get(self, "additional_ip_ranges_configs")

    @_builtins.property
    @pulumi.getter(name="additionalPodRangesConfig")
    def additional_pod_ranges_config(self) -> Optional['outputs.ClusterIpAllocationPolicyAdditionalPodRangesConfig']:
        """
        The configuration for additional pod secondary ranges at
        the cluster level. Used for Autopilot clusters and Standard clusters with which control of the
        secondary Pod IP address assignment to node pools isn't needed. Structure is documented below.
        """
        return pulumi.get(self, "additional_pod_ranges_config")

    @_builtins.property
    @pulumi.getter(name="autoIpamConfig")
    def auto_ipam_config(self) -> Optional['outputs.ClusterIpAllocationPolicyAutoIpamConfig']:
        """
        All the information related to Auto IPAM. Structure is documented below
        """
        return pulumi.get(self, "auto_ipam_config")

    @_builtins.property
    @pulumi.getter(name="clusterIpv4CidrBlock")
    def cluster_ipv4_cidr_block(self) -> Optional[_builtins.str]:
        """
        The IP address range for the cluster pod IPs.
        Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
        to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
        from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
        pick a specific range to use.
        """
        return pulumi.get(self, "cluster_ipv4_cidr_block")

    @_builtins.property
    @pulumi.getter(name="clusterSecondaryRangeName")
    def cluster_secondary_range_name(self) -> Optional[_builtins.str]:
        """
        The name of the existing secondary
        range in the cluster's subnetwork to use for pod IP addresses. Alternatively,
        `cluster_ipv4_cidr_block` can be used to automatically create a GKE-managed one.
        """
        return pulumi.get(self, "cluster_secondary_range_name")

    @_builtins.property
    @pulumi.getter(name="networkTierConfig")
    def network_tier_config(self) -> Optional['outputs.ClusterIpAllocationPolicyNetworkTierConfig']:
        """
        Contains network tier information. Structure is documented below

        <a name="nested_auto_ipam_config"></a>The auto ipam config supports:
        """
        return pulumi.get(self, "network_tier_config")

    @_builtins.property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional['outputs.ClusterIpAllocationPolicyPodCidrOverprovisionConfig']:
        """
        Configuration for cluster level pod cidr overprovision. Default is disabled=false.
        """
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @_builtins.property
    @pulumi.getter(name="servicesIpv4CidrBlock")
    def services_ipv4_cidr_block(self) -> Optional[_builtins.str]:
        """
        The IP address range of the services IPs in this cluster.
        Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
        to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
        from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
        pick a specific range to use.
        """
        return pulumi.get(self, "services_ipv4_cidr_block")

    @_builtins.property
    @pulumi.getter(name="servicesSecondaryRangeName")
    def services_secondary_range_name(self) -> Optional[_builtins.str]:
        """
        The name of the existing
        secondary range in the cluster's subnetwork to use for service `ClusterIP`s.
        Alternatively, `services_ipv4_cidr_block` can be used to automatically create a
        GKE-managed one.
        """
        return pulumi.get(self, "services_secondary_range_name")

    @_builtins.property
    @pulumi.getter(name="stackType")
    def stack_type(self) -> Optional[_builtins.str]:
        """
        The IP Stack Type of the cluster.
        Default value is `IPV4`.
        Possible values are `IPV4` and `IPV4_IPV6`.
        """
        return pulumi.get(self, "stack_type")


@pulumi.output_type
class ClusterIpAllocationPolicyAdditionalIpRangesConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "podIpv4RangeNames":
            suggest = "pod_ipv4_range_names"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterIpAllocationPolicyAdditionalIpRangesConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterIpAllocationPolicyAdditionalIpRangesConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterIpAllocationPolicyAdditionalIpRangesConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 subnetwork: _builtins.str,
                 pod_ipv4_range_names: Optional[Sequence[_builtins.str]] = None):
        """
        :param _builtins.str subnetwork: Name of the subnetwork. This can be the full path of the subnetwork or just the name.
        :param Sequence[_builtins.str] pod_ipv4_range_names: List of secondary ranges names within this subnetwork that can be used for pod IPs.
        """
        pulumi.set(__self__, "subnetwork", subnetwork)
        if pod_ipv4_range_names is not None:
            pulumi.set(__self__, "pod_ipv4_range_names", pod_ipv4_range_names)

    @_builtins.property
    @pulumi.getter
    def subnetwork(self) -> _builtins.str:
        """
        Name of the subnetwork. This can be the full path of the subnetwork or just the name.
        """
        return pulumi.get(self, "subnetwork")

    @_builtins.property
    @pulumi.getter(name="podIpv4RangeNames")
    def pod_ipv4_range_names(self) -> Optional[Sequence[_builtins.str]]:
        """
        List of secondary ranges names within this subnetwork that can be used for pod IPs.
        """
        return pulumi.get(self, "pod_ipv4_range_names")


@pulumi.output_type
class ClusterIpAllocationPolicyAdditionalPodRangesConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "podRangeNames":
            suggest = "pod_range_names"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterIpAllocationPolicyAdditionalPodRangesConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterIpAllocationPolicyAdditionalPodRangesConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterIpAllocationPolicyAdditionalPodRangesConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pod_range_names: Sequence[_builtins.str]):
        """
        :param Sequence[_builtins.str] pod_range_names: The names of the Pod ranges to add to the cluster.
        """
        pulumi.set(__self__, "pod_range_names", pod_range_names)

    @_builtins.property
    @pulumi.getter(name="podRangeNames")
    def pod_range_names(self) -> Sequence[_builtins.str]:
        """
        The names of the Pod ranges to add to the cluster.
        """
        return pulumi.get(self, "pod_range_names")


@pulumi.output_type
class ClusterIpAllocationPolicyAutoIpamConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: The flag that enables Auto IPAM on this cluster.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        The flag that enables Auto IPAM on this cluster.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterIpAllocationPolicyNetworkTierConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "networkTier":
            suggest = "network_tier"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterIpAllocationPolicyNetworkTierConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterIpAllocationPolicyNetworkTierConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterIpAllocationPolicyNetworkTierConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 network_tier: _builtins.str):
        """
        :param _builtins.str network_tier: Network tier configuration.
               Accepted values are:
               * `NETWORK_TIER_DEFAULT`: (Default) Use project-level configuration.
               * `NETWORK_TIER_PREMIUM`: Premium network tier.
               * `NETWORK_TIER_STANDARD`: Standard network tier.
        """
        pulumi.set(__self__, "network_tier", network_tier)

    @_builtins.property
    @pulumi.getter(name="networkTier")
    def network_tier(self) -> _builtins.str:
        """
        Network tier configuration.
        Accepted values are:
        * `NETWORK_TIER_DEFAULT`: (Default) Use project-level configuration.
        * `NETWORK_TIER_PREMIUM`: Premium network tier.
        * `NETWORK_TIER_STANDARD`: Standard network tier.
        """
        return pulumi.get(self, "network_tier")


@pulumi.output_type
class ClusterIpAllocationPolicyPodCidrOverprovisionConfig(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        """
        :param _builtins.bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterLoggingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableComponents":
            suggest = "enable_components"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterLoggingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterLoggingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterLoggingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_components: Sequence[_builtins.str]):
        """
        :param Sequence[_builtins.str] enable_components: The GKE components exposing logs. Supported values include:
               `SYSTEM_COMPONENTS`, `APISERVER`, `CONTROLLER_MANAGER`, `SCHEDULER`, and `WORKLOADS`.
        """
        pulumi.set(__self__, "enable_components", enable_components)

    @_builtins.property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Sequence[_builtins.str]:
        """
        The GKE components exposing logs. Supported values include:
        `SYSTEM_COMPONENTS`, `APISERVER`, `CONTROLLER_MANAGER`, `SCHEDULER`, and `WORKLOADS`.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class ClusterMaintenancePolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dailyMaintenanceWindow":
            suggest = "daily_maintenance_window"
        elif key == "maintenanceExclusions":
            suggest = "maintenance_exclusions"
        elif key == "recurringWindow":
            suggest = "recurring_window"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 daily_maintenance_window: Optional['outputs.ClusterMaintenancePolicyDailyMaintenanceWindow'] = None,
                 maintenance_exclusions: Optional[Sequence['outputs.ClusterMaintenancePolicyMaintenanceExclusion']] = None,
                 recurring_window: Optional['outputs.ClusterMaintenancePolicyRecurringWindow'] = None):
        """
        :param 'ClusterMaintenancePolicyDailyMaintenanceWindowArgs' daily_maintenance_window: Time window specified for daily maintenance operations.
               Specify `start_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM,
               where HH : \\[00-23\\] and MM : \\[00-59\\] GMT. For example:
               
               Examples:
        :param Sequence['ClusterMaintenancePolicyMaintenanceExclusionArgs'] maintenance_exclusions: Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows. A cluster can have up to 20 maintenance exclusions at a time [Maintenance Window and Exclusions](https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions)
        :param 'ClusterMaintenancePolicyRecurringWindowArgs' recurring_window: Time window for recurring maintenance operations.
               
               Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
               the initial date that the window starts, and the end time is used for calculating duration.  Specify `recurrence` in
               [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
               Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.
               
               Examples:
               ```
               maintenance_policy {
               recurring_window {
               start_time = "2019-08-01T02:00:00Z"
               end_time = "2019-08-01T06:00:00Z"
               recurrence = "FREQ=DAILY"
               }
               }
               ```
               
               ```
               maintenance_policy {
               recurring_window {
               start_time = "2019-01-01T09:00:00Z"
               end_time = "2019-01-01T17:00:00Z"
               recurrence = "FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR"
               }
               }
               ```
        """
        if daily_maintenance_window is not None:
            pulumi.set(__self__, "daily_maintenance_window", daily_maintenance_window)
        if maintenance_exclusions is not None:
            pulumi.set(__self__, "maintenance_exclusions", maintenance_exclusions)
        if recurring_window is not None:
            pulumi.set(__self__, "recurring_window", recurring_window)

    @_builtins.property
    @pulumi.getter(name="dailyMaintenanceWindow")
    def daily_maintenance_window(self) -> Optional['outputs.ClusterMaintenancePolicyDailyMaintenanceWindow']:
        """
        Time window specified for daily maintenance operations.
        Specify `start_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM,
        where HH : \\[00-23\\] and MM : \\[00-59\\] GMT. For example:

        Examples:
        """
        return pulumi.get(self, "daily_maintenance_window")

    @_builtins.property
    @pulumi.getter(name="maintenanceExclusions")
    def maintenance_exclusions(self) -> Optional[Sequence['outputs.ClusterMaintenancePolicyMaintenanceExclusion']]:
        """
        Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows. A cluster can have up to 20 maintenance exclusions at a time [Maintenance Window and Exclusions](https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions)
        """
        return pulumi.get(self, "maintenance_exclusions")

    @_builtins.property
    @pulumi.getter(name="recurringWindow")
    def recurring_window(self) -> Optional['outputs.ClusterMaintenancePolicyRecurringWindow']:
        """
        Time window for recurring maintenance operations.

        Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
        the initial date that the window starts, and the end time is used for calculating duration.  Specify `recurrence` in
        [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
        Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.

        Examples:
        ```
        maintenance_policy {
        recurring_window {
        start_time = "2019-08-01T02:00:00Z"
        end_time = "2019-08-01T06:00:00Z"
        recurrence = "FREQ=DAILY"
        }
        }
        ```

        ```
        maintenance_policy {
        recurring_window {
        start_time = "2019-01-01T09:00:00Z"
        end_time = "2019-01-01T17:00:00Z"
        recurrence = "FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR"
        }
        }
        ```
        """
        return pulumi.get(self, "recurring_window")


@pulumi.output_type
class ClusterMaintenancePolicyDailyMaintenanceWindow(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "startTime":
            suggest = "start_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicyDailyMaintenanceWindow. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicyDailyMaintenanceWindow.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicyDailyMaintenanceWindow.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 start_time: _builtins.str,
                 duration: Optional[_builtins.str] = None):
        """
        :param _builtins.str duration: Duration of the time window, automatically chosen to be
               smallest possible in the given scenario.
               Duration will be in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "PTnHnMnS".
        """
        pulumi.set(__self__, "start_time", start_time)
        if duration is not None:
            pulumi.set(__self__, "duration", duration)

    @_builtins.property
    @pulumi.getter(name="startTime")
    def start_time(self) -> _builtins.str:
        return pulumi.get(self, "start_time")

    @_builtins.property
    @pulumi.getter
    def duration(self) -> Optional[_builtins.str]:
        """
        Duration of the time window, automatically chosen to be
        smallest possible in the given scenario.
        Duration will be in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "PTnHnMnS".
        """
        return pulumi.get(self, "duration")


@pulumi.output_type
class ClusterMaintenancePolicyMaintenanceExclusion(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "exclusionName":
            suggest = "exclusion_name"
        elif key == "startTime":
            suggest = "start_time"
        elif key == "endTime":
            suggest = "end_time"
        elif key == "exclusionOptions":
            suggest = "exclusion_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicyMaintenanceExclusion. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicyMaintenanceExclusion.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicyMaintenanceExclusion.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 exclusion_name: _builtins.str,
                 start_time: _builtins.str,
                 end_time: Optional[_builtins.str] = None,
                 exclusion_options: Optional['outputs.ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions'] = None):
        """
        :param 'ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs' exclusion_options: MaintenanceExclusionOptions provides maintenance exclusion related options.
        """
        pulumi.set(__self__, "exclusion_name", exclusion_name)
        pulumi.set(__self__, "start_time", start_time)
        if end_time is not None:
            pulumi.set(__self__, "end_time", end_time)
        if exclusion_options is not None:
            pulumi.set(__self__, "exclusion_options", exclusion_options)

    @_builtins.property
    @pulumi.getter(name="exclusionName")
    def exclusion_name(self) -> _builtins.str:
        return pulumi.get(self, "exclusion_name")

    @_builtins.property
    @pulumi.getter(name="startTime")
    def start_time(self) -> _builtins.str:
        return pulumi.get(self, "start_time")

    @_builtins.property
    @pulumi.getter(name="endTime")
    def end_time(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "end_time")

    @_builtins.property
    @pulumi.getter(name="exclusionOptions")
    def exclusion_options(self) -> Optional['outputs.ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions']:
        """
        MaintenanceExclusionOptions provides maintenance exclusion related options.
        """
        return pulumi.get(self, "exclusion_options")


@pulumi.output_type
class ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "endTimeBehavior":
            suggest = "end_time_behavior"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicyMaintenanceExclusionExclusionOptions.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 scope: _builtins.str,
                 end_time_behavior: Optional[_builtins.str] = None):
        """
        :param _builtins.str scope: The scope of automatic upgrades to restrict in the exclusion window. One of: **NO_UPGRADES | NO_MINOR_UPGRADES | NO_MINOR_OR_NODE_UPGRADES**
        :param _builtins.str end_time_behavior: The exclusion window end time behavior. One of: **UNTIL_END_OF_SUPPORT**. One and and one of `end_time_behavior` and `end_time` should be specified.
               
               Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
               the initial date that the window starts, and the end time is used for calculating duration.Specify `recurrence` in
               [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
               Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.
               
               Examples:
               
               ```
               maintenance_policy {
               recurring_window {
               start_time = "2019-01-01T00:00:00Z"
               end_time = "2019-01-02T00:00:00Z"
               recurrence = "FREQ=DAILY"
               }
               maintenance_exclusion{
               exclusion_name = "batch job"
               start_time = "2019-01-01T00:00:00Z"
               end_time = "2019-01-02T00:00:00Z"
               exclusion_options {
               scope = "NO_UPGRADES"
               }
               }
               maintenance_exclusion{
               exclusion_name = "holiday data load"
               start_time = "2019-05-01T00:00:00Z"
               exclusion_options {
               scope = "NO_MINOR_UPGRADES"
               end_time_behavior = "UNTIL_END_OF_SUPPORT"
               }
               }
               }
               ```
        """
        pulumi.set(__self__, "scope", scope)
        if end_time_behavior is not None:
            pulumi.set(__self__, "end_time_behavior", end_time_behavior)

    @_builtins.property
    @pulumi.getter
    def scope(self) -> _builtins.str:
        """
        The scope of automatic upgrades to restrict in the exclusion window. One of: **NO_UPGRADES | NO_MINOR_UPGRADES | NO_MINOR_OR_NODE_UPGRADES**
        """
        return pulumi.get(self, "scope")

    @_builtins.property
    @pulumi.getter(name="endTimeBehavior")
    def end_time_behavior(self) -> Optional[_builtins.str]:
        """
        The exclusion window end time behavior. One of: **UNTIL_END_OF_SUPPORT**. One and and one of `end_time_behavior` and `end_time` should be specified.

        Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
        the initial date that the window starts, and the end time is used for calculating duration.Specify `recurrence` in
        [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
        Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.

        Examples:

        ```
        maintenance_policy {
        recurring_window {
        start_time = "2019-01-01T00:00:00Z"
        end_time = "2019-01-02T00:00:00Z"
        recurrence = "FREQ=DAILY"
        }
        maintenance_exclusion{
        exclusion_name = "batch job"
        start_time = "2019-01-01T00:00:00Z"
        end_time = "2019-01-02T00:00:00Z"
        exclusion_options {
        scope = "NO_UPGRADES"
        }
        }
        maintenance_exclusion{
        exclusion_name = "holiday data load"
        start_time = "2019-05-01T00:00:00Z"
        exclusion_options {
        scope = "NO_MINOR_UPGRADES"
        end_time_behavior = "UNTIL_END_OF_SUPPORT"
        }
        }
        }
        ```
        """
        return pulumi.get(self, "end_time_behavior")


@pulumi.output_type
class ClusterMaintenancePolicyRecurringWindow(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "endTime":
            suggest = "end_time"
        elif key == "startTime":
            suggest = "start_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMaintenancePolicyRecurringWindow. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMaintenancePolicyRecurringWindow.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMaintenancePolicyRecurringWindow.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 end_time: _builtins.str,
                 recurrence: _builtins.str,
                 start_time: _builtins.str):
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "recurrence", recurrence)
        pulumi.set(__self__, "start_time", start_time)

    @_builtins.property
    @pulumi.getter(name="endTime")
    def end_time(self) -> _builtins.str:
        return pulumi.get(self, "end_time")

    @_builtins.property
    @pulumi.getter
    def recurrence(self) -> _builtins.str:
        return pulumi.get(self, "recurrence")

    @_builtins.property
    @pulumi.getter(name="startTime")
    def start_time(self) -> _builtins.str:
        return pulumi.get(self, "start_time")


@pulumi.output_type
class ClusterMasterAuth(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "clientCertificateConfig":
            suggest = "client_certificate_config"
        elif key == "clientCertificate":
            suggest = "client_certificate"
        elif key == "clientKey":
            suggest = "client_key"
        elif key == "clusterCaCertificate":
            suggest = "cluster_ca_certificate"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterAuth. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterAuth.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterAuth.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 client_certificate_config: 'outputs.ClusterMasterAuthClientCertificateConfig',
                 client_certificate: Optional[_builtins.str] = None,
                 client_key: Optional[_builtins.str] = None,
                 cluster_ca_certificate: Optional[_builtins.str] = None):
        """
        :param 'ClusterMasterAuthClientCertificateConfigArgs' client_certificate_config: Whether client certificate authorization is enabled for this cluster.  For example:
        :param _builtins.str client_certificate: Base64 encoded public certificate
               used by clients to authenticate to the cluster endpoint.
        :param _builtins.str client_key: Base64 encoded private key used by clients
               to authenticate to the cluster endpoint.
        :param _builtins.str cluster_ca_certificate: Base64 encoded public certificate
               that is the root certificate of the cluster.
        """
        pulumi.set(__self__, "client_certificate_config", client_certificate_config)
        if client_certificate is not None:
            pulumi.set(__self__, "client_certificate", client_certificate)
        if client_key is not None:
            pulumi.set(__self__, "client_key", client_key)
        if cluster_ca_certificate is not None:
            pulumi.set(__self__, "cluster_ca_certificate", cluster_ca_certificate)

    @_builtins.property
    @pulumi.getter(name="clientCertificateConfig")
    def client_certificate_config(self) -> 'outputs.ClusterMasterAuthClientCertificateConfig':
        """
        Whether client certificate authorization is enabled for this cluster.  For example:
        """
        return pulumi.get(self, "client_certificate_config")

    @_builtins.property
    @pulumi.getter(name="clientCertificate")
    def client_certificate(self) -> Optional[_builtins.str]:
        """
        Base64 encoded public certificate
        used by clients to authenticate to the cluster endpoint.
        """
        return pulumi.get(self, "client_certificate")

    @_builtins.property
    @pulumi.getter(name="clientKey")
    def client_key(self) -> Optional[_builtins.str]:
        """
        Base64 encoded private key used by clients
        to authenticate to the cluster endpoint.
        """
        return pulumi.get(self, "client_key")

    @_builtins.property
    @pulumi.getter(name="clusterCaCertificate")
    def cluster_ca_certificate(self) -> Optional[_builtins.str]:
        """
        Base64 encoded public certificate
        that is the root certificate of the cluster.
        """
        return pulumi.get(self, "cluster_ca_certificate")


@pulumi.output_type
class ClusterMasterAuthClientCertificateConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "issueClientCertificate":
            suggest = "issue_client_certificate"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterAuthClientCertificateConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterAuthClientCertificateConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterAuthClientCertificateConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 issue_client_certificate: _builtins.bool):
        """
        :param _builtins.bool issue_client_certificate: Whether client certificate authorization is enabled for this cluster.
        """
        pulumi.set(__self__, "issue_client_certificate", issue_client_certificate)

    @_builtins.property
    @pulumi.getter(name="issueClientCertificate")
    def issue_client_certificate(self) -> _builtins.bool:
        """
        Whether client certificate authorization is enabled for this cluster.
        """
        return pulumi.get(self, "issue_client_certificate")


@pulumi.output_type
class ClusterMasterAuthorizedNetworksConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cidrBlocks":
            suggest = "cidr_blocks"
        elif key == "gcpPublicCidrsAccessEnabled":
            suggest = "gcp_public_cidrs_access_enabled"
        elif key == "privateEndpointEnforcementEnabled":
            suggest = "private_endpoint_enforcement_enabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterAuthorizedNetworksConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterAuthorizedNetworksConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterAuthorizedNetworksConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cidr_blocks: Optional[Sequence['outputs.ClusterMasterAuthorizedNetworksConfigCidrBlock']] = None,
                 gcp_public_cidrs_access_enabled: Optional[_builtins.bool] = None,
                 private_endpoint_enforcement_enabled: Optional[_builtins.bool] = None):
        """
        :param Sequence['ClusterMasterAuthorizedNetworksConfigCidrBlockArgs'] cidr_blocks: External networks that can access the
               Kubernetes cluster master through HTTPS.
        :param _builtins.bool gcp_public_cidrs_access_enabled: Whether Kubernetes master is
               accessible via Google Compute Engine Public IPs.
        :param _builtins.bool private_endpoint_enforcement_enabled: Whether authorized networks is enforced on the private endpoint or not.
        """
        if cidr_blocks is not None:
            pulumi.set(__self__, "cidr_blocks", cidr_blocks)
        if gcp_public_cidrs_access_enabled is not None:
            pulumi.set(__self__, "gcp_public_cidrs_access_enabled", gcp_public_cidrs_access_enabled)
        if private_endpoint_enforcement_enabled is not None:
            pulumi.set(__self__, "private_endpoint_enforcement_enabled", private_endpoint_enforcement_enabled)

    @_builtins.property
    @pulumi.getter(name="cidrBlocks")
    def cidr_blocks(self) -> Optional[Sequence['outputs.ClusterMasterAuthorizedNetworksConfigCidrBlock']]:
        """
        External networks that can access the
        Kubernetes cluster master through HTTPS.
        """
        return pulumi.get(self, "cidr_blocks")

    @_builtins.property
    @pulumi.getter(name="gcpPublicCidrsAccessEnabled")
    def gcp_public_cidrs_access_enabled(self) -> Optional[_builtins.bool]:
        """
        Whether Kubernetes master is
        accessible via Google Compute Engine Public IPs.
        """
        return pulumi.get(self, "gcp_public_cidrs_access_enabled")

    @_builtins.property
    @pulumi.getter(name="privateEndpointEnforcementEnabled")
    def private_endpoint_enforcement_enabled(self) -> Optional[_builtins.bool]:
        """
        Whether authorized networks is enforced on the private endpoint or not.
        """
        return pulumi.get(self, "private_endpoint_enforcement_enabled")


@pulumi.output_type
class ClusterMasterAuthorizedNetworksConfigCidrBlock(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cidrBlock":
            suggest = "cidr_block"
        elif key == "displayName":
            suggest = "display_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterAuthorizedNetworksConfigCidrBlock. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterAuthorizedNetworksConfigCidrBlock.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterAuthorizedNetworksConfigCidrBlock.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cidr_block: _builtins.str,
                 display_name: Optional[_builtins.str] = None):
        """
        :param _builtins.str cidr_block: External network that can access Kubernetes master through HTTPS.
               Must be specified in CIDR notation.
        :param _builtins.str display_name: Field for users to identify CIDR blocks.
        """
        pulumi.set(__self__, "cidr_block", cidr_block)
        if display_name is not None:
            pulumi.set(__self__, "display_name", display_name)

    @_builtins.property
    @pulumi.getter(name="cidrBlock")
    def cidr_block(self) -> _builtins.str:
        """
        External network that can access Kubernetes master through HTTPS.
        Must be specified in CIDR notation.
        """
        return pulumi.get(self, "cidr_block")

    @_builtins.property
    @pulumi.getter(name="displayName")
    def display_name(self) -> Optional[_builtins.str]:
        """
        Field for users to identify CIDR blocks.
        """
        return pulumi.get(self, "display_name")


@pulumi.output_type
class ClusterMeshCertificates(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableCertificates":
            suggest = "enable_certificates"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMeshCertificates. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMeshCertificates.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMeshCertificates.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_certificates: _builtins.bool):
        """
        :param _builtins.bool enable_certificates: Controls the issuance of workload mTLS certificates. It is enabled by default. Workload Identity is required, see workload_config.
        """
        pulumi.set(__self__, "enable_certificates", enable_certificates)

    @_builtins.property
    @pulumi.getter(name="enableCertificates")
    def enable_certificates(self) -> _builtins.bool:
        """
        Controls the issuance of workload mTLS certificates. It is enabled by default. Workload Identity is required, see workload_config.
        """
        return pulumi.get(self, "enable_certificates")


@pulumi.output_type
class ClusterMonitoringConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "advancedDatapathObservabilityConfig":
            suggest = "advanced_datapath_observability_config"
        elif key == "enableComponents":
            suggest = "enable_components"
        elif key == "managedPrometheus":
            suggest = "managed_prometheus"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMonitoringConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMonitoringConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMonitoringConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 advanced_datapath_observability_config: Optional['outputs.ClusterMonitoringConfigAdvancedDatapathObservabilityConfig'] = None,
                 enable_components: Optional[Sequence[_builtins.str]] = None,
                 managed_prometheus: Optional['outputs.ClusterMonitoringConfigManagedPrometheus'] = None):
        """
        :param 'ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs' advanced_datapath_observability_config: Configuration for Advanced Datapath Monitoring. Structure is documented below.
        :param Sequence[_builtins.str] enable_components: The GKE components exposing metrics. Supported values include: `SYSTEM_COMPONENTS`, `APISERVER`, `SCHEDULER`, `CONTROLLER_MANAGER`, `STORAGE`, `HPA`, `POD`, `DAEMONSET`, `DEPLOYMENT`, `STATEFULSET`, `KUBELET`, `CADVISOR`, `DCGM` and `JOBSET`. In beta provider, `WORKLOADS` is supported on top of those 12 values. (`WORKLOADS` is deprecated and removed in GKE 1.24.) `KUBELET` and `CADVISOR` are only supported in GKE 1.29.3-gke.1093000 and above. `JOBSET` is only supported in GKE 1.32.1-gke.1357001 and above.
        :param 'ClusterMonitoringConfigManagedPrometheusArgs' managed_prometheus: Configuration for Managed Service for Prometheus. Structure is documented below.
        """
        if advanced_datapath_observability_config is not None:
            pulumi.set(__self__, "advanced_datapath_observability_config", advanced_datapath_observability_config)
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)
        if managed_prometheus is not None:
            pulumi.set(__self__, "managed_prometheus", managed_prometheus)

    @_builtins.property
    @pulumi.getter(name="advancedDatapathObservabilityConfig")
    def advanced_datapath_observability_config(self) -> Optional['outputs.ClusterMonitoringConfigAdvancedDatapathObservabilityConfig']:
        """
        Configuration for Advanced Datapath Monitoring. Structure is documented below.
        """
        return pulumi.get(self, "advanced_datapath_observability_config")

    @_builtins.property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[Sequence[_builtins.str]]:
        """
        The GKE components exposing metrics. Supported values include: `SYSTEM_COMPONENTS`, `APISERVER`, `SCHEDULER`, `CONTROLLER_MANAGER`, `STORAGE`, `HPA`, `POD`, `DAEMONSET`, `DEPLOYMENT`, `STATEFULSET`, `KUBELET`, `CADVISOR`, `DCGM` and `JOBSET`. In beta provider, `WORKLOADS` is supported on top of those 12 values. (`WORKLOADS` is deprecated and removed in GKE 1.24.) `KUBELET` and `CADVISOR` are only supported in GKE 1.29.3-gke.1093000 and above. `JOBSET` is only supported in GKE 1.32.1-gke.1357001 and above.
        """
        return pulumi.get(self, "enable_components")

    @_builtins.property
    @pulumi.getter(name="managedPrometheus")
    def managed_prometheus(self) -> Optional['outputs.ClusterMonitoringConfigManagedPrometheus']:
        """
        Configuration for Managed Service for Prometheus. Structure is documented below.
        """
        return pulumi.get(self, "managed_prometheus")


@pulumi.output_type
class ClusterMonitoringConfigAdvancedDatapathObservabilityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableMetrics":
            suggest = "enable_metrics"
        elif key == "enableRelay":
            suggest = "enable_relay"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMonitoringConfigAdvancedDatapathObservabilityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMonitoringConfigAdvancedDatapathObservabilityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMonitoringConfigAdvancedDatapathObservabilityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_metrics: _builtins.bool,
                 enable_relay: _builtins.bool):
        """
        :param _builtins.bool enable_metrics: Whether or not to enable advanced datapath metrics.
        :param _builtins.bool enable_relay: Whether or not Relay is enabled.
        """
        pulumi.set(__self__, "enable_metrics", enable_metrics)
        pulumi.set(__self__, "enable_relay", enable_relay)

    @_builtins.property
    @pulumi.getter(name="enableMetrics")
    def enable_metrics(self) -> _builtins.bool:
        """
        Whether or not to enable advanced datapath metrics.
        """
        return pulumi.get(self, "enable_metrics")

    @_builtins.property
    @pulumi.getter(name="enableRelay")
    def enable_relay(self) -> _builtins.bool:
        """
        Whether or not Relay is enabled.
        """
        return pulumi.get(self, "enable_relay")


@pulumi.output_type
class ClusterMonitoringConfigManagedPrometheus(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoMonitoringConfig":
            suggest = "auto_monitoring_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMonitoringConfigManagedPrometheus. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMonitoringConfigManagedPrometheus.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMonitoringConfigManagedPrometheus.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 auto_monitoring_config: Optional['outputs.ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfig'] = None):
        """
        :param _builtins.bool enabled: Whether or not the managed collection is enabled.
        :param 'ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigArgs' auto_monitoring_config: Configuration options for GKE Auto-Monitoring.
        """
        pulumi.set(__self__, "enabled", enabled)
        if auto_monitoring_config is not None:
            pulumi.set(__self__, "auto_monitoring_config", auto_monitoring_config)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not the managed collection is enabled.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="autoMonitoringConfig")
    def auto_monitoring_config(self) -> Optional['outputs.ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfig']:
        """
        Configuration options for GKE Auto-Monitoring.
        """
        return pulumi.get(self, "auto_monitoring_config")


@pulumi.output_type
class ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfig(dict):
    def __init__(__self__, *,
                 scope: _builtins.str):
        """
        :param _builtins.str scope: Whether or not to enable GKE Auto-Monitoring. Supported values include: `ALL`, `NONE`.
        """
        pulumi.set(__self__, "scope", scope)

    @_builtins.property
    @pulumi.getter
    def scope(self) -> _builtins.str:
        """
        Whether or not to enable GKE Auto-Monitoring. Supported values include: `ALL`, `NONE`.
        """
        return pulumi.get(self, "scope")


@pulumi.output_type
class ClusterNetworkPerformanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "totalEgressBandwidthTier":
            suggest = "total_egress_bandwidth_tier"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNetworkPerformanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNetworkPerformanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNetworkPerformanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 total_egress_bandwidth_tier: _builtins.str):
        """
        :param _builtins.str total_egress_bandwidth_tier: Specifies the total network bandwidth tier for NodePools in the cluster.
        """
        pulumi.set(__self__, "total_egress_bandwidth_tier", total_egress_bandwidth_tier)

    @_builtins.property
    @pulumi.getter(name="totalEgressBandwidthTier")
    def total_egress_bandwidth_tier(self) -> _builtins.str:
        """
        Specifies the total network bandwidth tier for NodePools in the cluster.
        """
        return pulumi.get(self, "total_egress_bandwidth_tier")


@pulumi.output_type
class ClusterNetworkPolicy(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 provider: Optional[_builtins.str] = None):
        """
        :param _builtins.bool enabled: Whether network policy is enabled on the cluster.
        :param _builtins.str provider: The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.
        """
        pulumi.set(__self__, "enabled", enabled)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether network policy is enabled on the cluster.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter
    def provider(self) -> Optional[_builtins.str]:
        """
        The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.
        """
        return pulumi.get(self, "provider")


@pulumi.output_type
class ClusterNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "advancedMachineFeatures":
            suggest = "advanced_machine_features"
        elif key == "bootDisk":
            suggest = "boot_disk"
        elif key == "bootDiskKmsKey":
            suggest = "boot_disk_kms_key"
        elif key == "confidentialNodes":
            suggest = "confidential_nodes"
        elif key == "containerdConfig":
            suggest = "containerd_config"
        elif key == "diskSizeGb":
            suggest = "disk_size_gb"
        elif key == "diskType":
            suggest = "disk_type"
        elif key == "effectiveTaints":
            suggest = "effective_taints"
        elif key == "enableConfidentialStorage":
            suggest = "enable_confidential_storage"
        elif key == "ephemeralStorageConfig":
            suggest = "ephemeral_storage_config"
        elif key == "ephemeralStorageLocalSsdConfig":
            suggest = "ephemeral_storage_local_ssd_config"
        elif key == "fastSocket":
            suggest = "fast_socket"
        elif key == "flexStart":
            suggest = "flex_start"
        elif key == "gcfsConfig":
            suggest = "gcfs_config"
        elif key == "guestAccelerators":
            suggest = "guest_accelerators"
        elif key == "hostMaintenancePolicy":
            suggest = "host_maintenance_policy"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "kubeletConfig":
            suggest = "kubelet_config"
        elif key == "linuxNodeConfig":
            suggest = "linux_node_config"
        elif key == "localNvmeSsdBlockConfig":
            suggest = "local_nvme_ssd_block_config"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "localSsdEncryptionMode":
            suggest = "local_ssd_encryption_mode"
        elif key == "loggingVariant":
            suggest = "logging_variant"
        elif key == "machineType":
            suggest = "machine_type"
        elif key == "maxRunDuration":
            suggest = "max_run_duration"
        elif key == "minCpuPlatform":
            suggest = "min_cpu_platform"
        elif key == "nodeGroup":
            suggest = "node_group"
        elif key == "oauthScopes":
            suggest = "oauth_scopes"
        elif key == "reservationAffinity":
            suggest = "reservation_affinity"
        elif key == "resourceLabels":
            suggest = "resource_labels"
        elif key == "resourceManagerTags":
            suggest = "resource_manager_tags"
        elif key == "sandboxConfig":
            suggest = "sandbox_config"
        elif key == "secondaryBootDisks":
            suggest = "secondary_boot_disks"
        elif key == "serviceAccount":
            suggest = "service_account"
        elif key == "shieldedInstanceConfig":
            suggest = "shielded_instance_config"
        elif key == "soleTenantConfig":
            suggest = "sole_tenant_config"
        elif key == "storagePools":
            suggest = "storage_pools"
        elif key == "windowsNodeConfig":
            suggest = "windows_node_config"
        elif key == "workloadMetadataConfig":
            suggest = "workload_metadata_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 advanced_machine_features: Optional['outputs.ClusterNodeConfigAdvancedMachineFeatures'] = None,
                 boot_disk: Optional['outputs.ClusterNodeConfigBootDisk'] = None,
                 boot_disk_kms_key: Optional[_builtins.str] = None,
                 confidential_nodes: Optional['outputs.ClusterNodeConfigConfidentialNodes'] = None,
                 containerd_config: Optional['outputs.ClusterNodeConfigContainerdConfig'] = None,
                 disk_size_gb: Optional[_builtins.int] = None,
                 disk_type: Optional[_builtins.str] = None,
                 effective_taints: Optional[Sequence['outputs.ClusterNodeConfigEffectiveTaint']] = None,
                 enable_confidential_storage: Optional[_builtins.bool] = None,
                 ephemeral_storage_config: Optional['outputs.ClusterNodeConfigEphemeralStorageConfig'] = None,
                 ephemeral_storage_local_ssd_config: Optional['outputs.ClusterNodeConfigEphemeralStorageLocalSsdConfig'] = None,
                 fast_socket: Optional['outputs.ClusterNodeConfigFastSocket'] = None,
                 flex_start: Optional[_builtins.bool] = None,
                 gcfs_config: Optional['outputs.ClusterNodeConfigGcfsConfig'] = None,
                 guest_accelerators: Optional[Sequence['outputs.ClusterNodeConfigGuestAccelerator']] = None,
                 gvnic: Optional['outputs.ClusterNodeConfigGvnic'] = None,
                 host_maintenance_policy: Optional['outputs.ClusterNodeConfigHostMaintenancePolicy'] = None,
                 image_type: Optional[_builtins.str] = None,
                 kubelet_config: Optional['outputs.ClusterNodeConfigKubeletConfig'] = None,
                 labels: Optional[Mapping[str, _builtins.str]] = None,
                 linux_node_config: Optional['outputs.ClusterNodeConfigLinuxNodeConfig'] = None,
                 local_nvme_ssd_block_config: Optional['outputs.ClusterNodeConfigLocalNvmeSsdBlockConfig'] = None,
                 local_ssd_count: Optional[_builtins.int] = None,
                 local_ssd_encryption_mode: Optional[_builtins.str] = None,
                 logging_variant: Optional[_builtins.str] = None,
                 machine_type: Optional[_builtins.str] = None,
                 max_run_duration: Optional[_builtins.str] = None,
                 metadata: Optional[Mapping[str, _builtins.str]] = None,
                 min_cpu_platform: Optional[_builtins.str] = None,
                 node_group: Optional[_builtins.str] = None,
                 oauth_scopes: Optional[Sequence[_builtins.str]] = None,
                 preemptible: Optional[_builtins.bool] = None,
                 reservation_affinity: Optional['outputs.ClusterNodeConfigReservationAffinity'] = None,
                 resource_labels: Optional[Mapping[str, _builtins.str]] = None,
                 resource_manager_tags: Optional[Mapping[str, _builtins.str]] = None,
                 sandbox_config: Optional['outputs.ClusterNodeConfigSandboxConfig'] = None,
                 secondary_boot_disks: Optional[Sequence['outputs.ClusterNodeConfigSecondaryBootDisk']] = None,
                 service_account: Optional[_builtins.str] = None,
                 shielded_instance_config: Optional['outputs.ClusterNodeConfigShieldedInstanceConfig'] = None,
                 sole_tenant_config: Optional['outputs.ClusterNodeConfigSoleTenantConfig'] = None,
                 spot: Optional[_builtins.bool] = None,
                 storage_pools: Optional[Sequence[_builtins.str]] = None,
                 tags: Optional[Sequence[_builtins.str]] = None,
                 taints: Optional[Sequence['outputs.ClusterNodeConfigTaint']] = None,
                 windows_node_config: Optional['outputs.ClusterNodeConfigWindowsNodeConfig'] = None,
                 workload_metadata_config: Optional['outputs.ClusterNodeConfigWorkloadMetadataConfig'] = None):
        """
        :param 'ClusterNodeConfigAdvancedMachineFeaturesArgs' advanced_machine_features: Specifies options for controlling
               advanced machine features. Structure is documented below.
        :param 'ClusterNodeConfigBootDiskArgs' boot_disk: Configuration of the node pool boot disk. Structure is documented below
        :param _builtins.str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        :param 'ClusterNodeConfigConfidentialNodesArgs' confidential_nodes: Configuration for Confidential Nodes feature. Structure is documented below.
        :param 'ClusterNodeConfigContainerdConfigArgs' containerd_config: Parameters to customize containerd runtime. Structure is documented below.
        :param _builtins.int disk_size_gb: Size of the disk attached to each node, specified
               in GB. The smallest allowed disk size is 10GB. Defaults to 100GB. This is being migrated to `boot_disk.size_gb`, and must match if specified in both places.
               Prefer configuring `boot_disk`.
        :param _builtins.str disk_type: Type of the disk attached to each node
               (e.g. 'pd-standard', 'pd-balanced', 'pd-ssd', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`. This is being migrated to `boot_disk.disk_type`, and must match if specified in both places. Prefer configuring `boot_disk`.
        :param Sequence['ClusterNodeConfigEffectiveTaintArgs'] effective_taints: List of kubernetes taints applied to each node. Structure is documented above.
        :param _builtins.bool enable_confidential_storage: Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        :param 'ClusterNodeConfigEphemeralStorageConfigArgs' ephemeral_storage_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        :param 'ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs' ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        :param 'ClusterNodeConfigFastSocketArgs' fast_socket: Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
               Node Pool must enable gvnic.
               GKE version 1.25.2-gke.1700 or later.
               Structure is documented below.
        :param _builtins.bool flex_start: Enables Flex Start provisioning model for the node pool.
        :param 'ClusterNodeConfigGcfsConfigArgs' gcfs_config: Parameters for the Google Container Filesystem (GCFS).
               If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
               For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
               A `machine_type` that has more than 16 GiB of memory is also recommended.
               GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
               Structure is documented below.
        :param Sequence['ClusterNodeConfigGuestAcceleratorArgs'] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
               Structure documented below.
        :param 'ClusterNodeConfigGvnicArgs' gvnic: Google Virtual NIC (gVNIC) is a virtual network interface.
               Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
               gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
               GKE node version 1.15.11-gke.15 or later
               Structure is documented below.
        :param 'ClusterNodeConfigHostMaintenancePolicyArgs' host_maintenance_policy: The maintenance policy for the hosts on which the GKE VMs run on.
        :param _builtins.str image_type: The image type to use for this node. Note that changing the image type
               will delete and recreate all nodes in the node pool.
        :param 'ClusterNodeConfigKubeletConfigArgs' kubelet_config: Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Structure is documented below.
               
               ```
               kubelet_config {
               cpu_manager_policy   = "static"
               cpu_cfs_quota        = true
               cpu_cfs_quota_period = "100us"
               pod_pids_limit       = 1024
               }
               ```
        :param Mapping[str, _builtins.str] labels: The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
               reserved by Kubernetes Core components and cannot be specified.
        :param 'ClusterNodeConfigLinuxNodeConfigArgs' linux_node_config: Parameters that can be configured on Linux nodes. Structure is documented below.
        :param 'ClusterNodeConfigLocalNvmeSsdBlockConfigArgs' local_nvme_ssd_block_config: Parameters for the local NVMe SSDs. Structure is documented below.
        :param _builtins.int local_ssd_count: The amount of local SSD disks that will be
               attached to each cluster node. Defaults to 0.
        :param _builtins.str local_ssd_encryption_mode: Possible Local SSD encryption modes:
               Accepted values are:
               * `STANDARD_ENCRYPTION`: The given node will be encrypted using keys managed by Google infrastructure and the keys wll be deleted when the node is deleted.
               * `EPHEMERAL_KEY_ENCRYPTION`: The given node will opt-in for using ephemeral key for encrypting Local SSDs. The Local SSDs will not be able to recover data in case of node crash.
        :param _builtins.str logging_variant: Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        :param _builtins.str machine_type: The name of a Google Compute Engine machine type.
               Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
               [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        :param _builtins.str max_run_duration: The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        :param Mapping[str, _builtins.str] metadata: The metadata key/value pairs assigned to instances in
               the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
               `true` by the API; if `metadata` is set but that default value is not
               included, the provider will attempt to unset the value. To avoid this, set the
               value in your config.
        :param _builtins.str min_cpu_platform: Minimum CPU platform to be used by this instance.
               The instance may be scheduled on the specified or newer CPU platform. Applicable
               values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
               [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
               for more information.
        :param _builtins.str node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        :param Sequence[_builtins.str] oauth_scopes: The set of Google API scopes to be made available
               on all of the node VMs under the "default" service account.
               Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        :param _builtins.bool preemptible: A boolean that represents whether or not the underlying node VMs
               are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
               for more information. Defaults to false.
        :param 'ClusterNodeConfigReservationAffinityArgs' reservation_affinity: The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        :param Mapping[str, _builtins.str] resource_labels: The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
               for how these labels are applied to clusters, node pools and nodes.
        :param Mapping[str, _builtins.str] resource_manager_tags: A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        :param 'ClusterNodeConfigSandboxConfigArgs' sandbox_config: Sandbox configuration for this node.
        :param Sequence['ClusterNodeConfigSecondaryBootDiskArgs'] secondary_boot_disks: Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        :param _builtins.str service_account: The service account to be used by the Node VMs.
               If not specified, the "default" service account is used.
        :param 'ClusterNodeConfigShieldedInstanceConfigArgs' shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param 'ClusterNodeConfigSoleTenantConfigArgs' sole_tenant_config: Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). Structure is documented below.
        :param _builtins.bool spot: A boolean that represents whether the underlying node VMs are spot.
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
               for more information. Defaults to false.
        :param Sequence[_builtins.str] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param Sequence[_builtins.str] tags: The list of instance tags applied to all nodes. Tags are used to identify
               valid sources or targets for network firewalls.
        :param Sequence['ClusterNodeConfigTaintArgs'] taints: A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
               to apply to nodes. GKE's API can only set this field on cluster creation.
               However, GKE will add taints to your nodes if you enable certain features such
               as GPUs. If this field is set, any diffs on this field will cause the provider to
               recreate the underlying resource. Taint values can be updated safely in
               Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
               this field to manage taints. If you do, `lifecycle.ignore_changes` is
               recommended. Structure is documented below.
        :param 'ClusterNodeConfigWindowsNodeConfigArgs' windows_node_config: Windows node configuration, currently supporting OSVersion [attribute](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/NodeConfig#osversion). The value must be one of [OS_VERSION_UNSPECIFIED, OS_VERSION_LTSC2019, OS_VERSION_LTSC2022]. For example:
        :param 'ClusterNodeConfigWorkloadMetadataConfigArgs' workload_metadata_config: Metadata configuration to expose to workloads on the node pool.
               Structure is documented below.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk is not None:
            pulumi.set(__self__, "boot_disk", boot_disk)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if containerd_config is not None:
            pulumi.set(__self__, "containerd_config", containerd_config)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if effective_taints is not None:
            pulumi.set(__self__, "effective_taints", effective_taints)
        if enable_confidential_storage is not None:
            pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if flex_start is not None:
            pulumi.set(__self__, "flex_start", flex_start)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if local_ssd_encryption_mode is not None:
            pulumi.set(__self__, "local_ssd_encryption_mode", local_ssd_encryption_mode)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if max_run_duration is not None:
            pulumi.set(__self__, "max_run_duration", max_run_duration)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if resource_manager_tags is not None:
            pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if secondary_boot_disks is not None:
            pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if storage_pools is not None:
            pulumi.set(__self__, "storage_pools", storage_pools)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if windows_node_config is not None:
            pulumi.set(__self__, "windows_node_config", windows_node_config)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @_builtins.property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional['outputs.ClusterNodeConfigAdvancedMachineFeatures']:
        """
        Specifies options for controlling
        advanced machine features. Structure is documented below.
        """
        return pulumi.get(self, "advanced_machine_features")

    @_builtins.property
    @pulumi.getter(name="bootDisk")
    def boot_disk(self) -> Optional['outputs.ClusterNodeConfigBootDisk']:
        """
        Configuration of the node pool boot disk. Structure is documented below
        """
        return pulumi.get(self, "boot_disk")

    @_builtins.property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[_builtins.str]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @_builtins.property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional['outputs.ClusterNodeConfigConfidentialNodes']:
        """
        Configuration for Confidential Nodes feature. Structure is documented below.
        """
        return pulumi.get(self, "confidential_nodes")

    @_builtins.property
    @pulumi.getter(name="containerdConfig")
    def containerd_config(self) -> Optional['outputs.ClusterNodeConfigContainerdConfig']:
        """
        Parameters to customize containerd runtime. Structure is documented below.
        """
        return pulumi.get(self, "containerd_config")

    @_builtins.property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[_builtins.int]:
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB. This is being migrated to `boot_disk.size_gb`, and must match if specified in both places.
        Prefer configuring `boot_disk`.
        """
        return pulumi.get(self, "disk_size_gb")

    @_builtins.property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[_builtins.str]:
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced', 'pd-ssd', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`. This is being migrated to `boot_disk.disk_type`, and must match if specified in both places. Prefer configuring `boot_disk`.
        """
        return pulumi.get(self, "disk_type")

    @_builtins.property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Optional[Sequence['outputs.ClusterNodeConfigEffectiveTaint']]:
        """
        List of kubernetes taints applied to each node. Structure is documented above.
        """
        return pulumi.get(self, "effective_taints")

    @_builtins.property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> Optional[_builtins.bool]:
        """
        Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @_builtins.property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional['outputs.ClusterNodeConfigEphemeralStorageConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @_builtins.property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional['outputs.ClusterNodeConfigEphemeralStorageLocalSsdConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @_builtins.property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional['outputs.ClusterNodeConfigFastSocket']:
        """
        Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
        Node Pool must enable gvnic.
        GKE version 1.25.2-gke.1700 or later.
        Structure is documented below.
        """
        return pulumi.get(self, "fast_socket")

    @_builtins.property
    @pulumi.getter(name="flexStart")
    def flex_start(self) -> Optional[_builtins.bool]:
        """
        Enables Flex Start provisioning model for the node pool.
        """
        return pulumi.get(self, "flex_start")

    @_builtins.property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional['outputs.ClusterNodeConfigGcfsConfig']:
        """
        Parameters for the Google Container Filesystem (GCFS).
        If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
        For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
        A `machine_type` that has more than 16 GiB of memory is also recommended.
        GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
        Structure is documented below.
        """
        return pulumi.get(self, "gcfs_config")

    @_builtins.property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[Sequence['outputs.ClusterNodeConfigGuestAccelerator']]:
        """
        List of the type and count of accelerator cards attached to the instance.
        Structure documented below.
        """
        return pulumi.get(self, "guest_accelerators")

    @_builtins.property
    @pulumi.getter
    def gvnic(self) -> Optional['outputs.ClusterNodeConfigGvnic']:
        """
        Google Virtual NIC (gVNIC) is a virtual network interface.
        Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
        gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
        GKE node version 1.15.11-gke.15 or later
        Structure is documented below.
        """
        return pulumi.get(self, "gvnic")

    @_builtins.property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional['outputs.ClusterNodeConfigHostMaintenancePolicy']:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policy")

    @_builtins.property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[_builtins.str]:
        """
        The image type to use for this node. Note that changing the image type
        will delete and recreate all nodes in the node pool.
        """
        return pulumi.get(self, "image_type")

    @_builtins.property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional['outputs.ClusterNodeConfigKubeletConfig']:
        """
        Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Structure is documented below.

        ```
        kubelet_config {
        cpu_manager_policy   = "static"
        cpu_cfs_quota        = true
        cpu_cfs_quota_period = "100us"
        pod_pids_limit       = 1024
        }
        ```
        """
        return pulumi.get(self, "kubelet_config")

    @_builtins.property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
        reserved by Kubernetes Core components and cannot be specified.
        """
        return pulumi.get(self, "labels")

    @_builtins.property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional['outputs.ClusterNodeConfigLinuxNodeConfig']:
        """
        Parameters that can be configured on Linux nodes. Structure is documented below.
        """
        return pulumi.get(self, "linux_node_config")

    @_builtins.property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional['outputs.ClusterNodeConfigLocalNvmeSsdBlockConfig']:
        """
        Parameters for the local NVMe SSDs. Structure is documented below.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[_builtins.int]:
        """
        The amount of local SSD disks that will be
        attached to each cluster node. Defaults to 0.
        """
        return pulumi.get(self, "local_ssd_count")

    @_builtins.property
    @pulumi.getter(name="localSsdEncryptionMode")
    def local_ssd_encryption_mode(self) -> Optional[_builtins.str]:
        """
        Possible Local SSD encryption modes:
        Accepted values are:
        * `STANDARD_ENCRYPTION`: The given node will be encrypted using keys managed by Google infrastructure and the keys wll be deleted when the node is deleted.
        * `EPHEMERAL_KEY_ENCRYPTION`: The given node will opt-in for using ephemeral key for encrypting Local SSDs. The Local SSDs will not be able to recover data in case of node crash.
        """
        return pulumi.get(self, "local_ssd_encryption_mode")

    @_builtins.property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[_builtins.str]:
        """
        Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")

    @_builtins.property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[_builtins.str]:
        """
        The name of a Google Compute Engine machine type.
        Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
        [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        """
        return pulumi.get(self, "machine_type")

    @_builtins.property
    @pulumi.getter(name="maxRunDuration")
    def max_run_duration(self) -> Optional[_builtins.str]:
        """
        The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        """
        return pulumi.get(self, "max_run_duration")

    @_builtins.property
    @pulumi.getter
    def metadata(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The metadata key/value pairs assigned to instances in
        the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
        `true` by the API; if `metadata` is set but that default value is not
        included, the provider will attempt to unset the value. To avoid this, set the
        value in your config.
        """
        return pulumi.get(self, "metadata")

    @_builtins.property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[_builtins.str]:
        """
        Minimum CPU platform to be used by this instance.
        The instance may be scheduled on the specified or newer CPU platform. Applicable
        values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
        [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
        for more information.
        """
        return pulumi.get(self, "min_cpu_platform")

    @_builtins.property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[_builtins.str]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        """
        return pulumi.get(self, "node_group")

    @_builtins.property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[Sequence[_builtins.str]]:
        """
        The set of Google API scopes to be made available
        on all of the node VMs under the "default" service account.
        Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        """
        return pulumi.get(self, "oauth_scopes")

    @_builtins.property
    @pulumi.getter
    def preemptible(self) -> Optional[_builtins.bool]:
        """
        A boolean that represents whether or not the underlying node VMs
        are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "preemptible")

    @_builtins.property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional['outputs.ClusterNodeConfigReservationAffinity']:
        """
        The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        """
        return pulumi.get(self, "reservation_affinity")

    @_builtins.property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
        for how these labels are applied to clusters, node pools and nodes.
        """
        return pulumi.get(self, "resource_labels")

    @_builtins.property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        return pulumi.get(self, "resource_manager_tags")

    @_builtins.property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional['outputs.ClusterNodeConfigSandboxConfig']:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_config")

    @_builtins.property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Optional[Sequence['outputs.ClusterNodeConfigSecondaryBootDisk']]:
        """
        Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @_builtins.property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[_builtins.str]:
        """
        The service account to be used by the Node VMs.
        If not specified, the "default" service account is used.
        """
        return pulumi.get(self, "service_account")

    @_builtins.property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional['outputs.ClusterNodeConfigShieldedInstanceConfig']:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @_builtins.property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional['outputs.ClusterNodeConfigSoleTenantConfig']:
        """
        Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). Structure is documented below.
        """
        return pulumi.get(self, "sole_tenant_config")

    @_builtins.property
    @pulumi.getter
    def spot(self) -> Optional[_builtins.bool]:
        """
        A boolean that represents whether the underlying node VMs are spot.
        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "spot")

    @_builtins.property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Optional[Sequence[_builtins.str]]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Optional[Sequence[_builtins.str]]:
        """
        The list of instance tags applied to all nodes. Tags are used to identify
        valid sources or targets for network firewalls.
        """
        return pulumi.get(self, "tags")

    @_builtins.property
    @pulumi.getter
    def taints(self) -> Optional[Sequence['outputs.ClusterNodeConfigTaint']]:
        """
        A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
        to apply to nodes. GKE's API can only set this field on cluster creation.
        However, GKE will add taints to your nodes if you enable certain features such
        as GPUs. If this field is set, any diffs on this field will cause the provider to
        recreate the underlying resource. Taint values can be updated safely in
        Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
        this field to manage taints. If you do, `lifecycle.ignore_changes` is
        recommended. Structure is documented below.
        """
        return pulumi.get(self, "taints")

    @_builtins.property
    @pulumi.getter(name="windowsNodeConfig")
    def windows_node_config(self) -> Optional['outputs.ClusterNodeConfigWindowsNodeConfig']:
        """
        Windows node configuration, currently supporting OSVersion [attribute](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/NodeConfig#osversion). The value must be one of [OS_VERSION_UNSPECIFIED, OS_VERSION_LTSC2019, OS_VERSION_LTSC2022]. For example:
        """
        return pulumi.get(self, "windows_node_config")

    @_builtins.property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional['outputs.ClusterNodeConfigWorkloadMetadataConfig']:
        """
        Metadata configuration to expose to workloads on the node pool.
        Structure is documented below.
        """
        return pulumi.get(self, "workload_metadata_config")


@pulumi.output_type
class ClusterNodeConfigAdvancedMachineFeatures(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "threadsPerCore":
            suggest = "threads_per_core"
        elif key == "enableNestedVirtualization":
            suggest = "enable_nested_virtualization"
        elif key == "performanceMonitoringUnit":
            suggest = "performance_monitoring_unit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigAdvancedMachineFeatures. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 threads_per_core: _builtins.int,
                 enable_nested_virtualization: Optional[_builtins.bool] = None,
                 performance_monitoring_unit: Optional[_builtins.str] = None):
        """
        :param _builtins.int threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        :param _builtins.bool enable_nested_virtualization: Defines whether the instance should have nested virtualization enabled. Defaults to false.
        :param _builtins.str performance_monitoring_unit: Defines the performance monitoring unit [PMU](https://cloud.google.com/compute/docs/pmu-overview) level. Valid values are `ARCHITECTURAL`, `STANDARD`, or `ENHANCED`. Defaults to off.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)
        if enable_nested_virtualization is not None:
            pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)
        if performance_monitoring_unit is not None:
            pulumi.set(__self__, "performance_monitoring_unit", performance_monitoring_unit)

    @_builtins.property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> _builtins.int:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")

    @_builtins.property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> Optional[_builtins.bool]:
        """
        Defines whether the instance should have nested virtualization enabled. Defaults to false.
        """
        return pulumi.get(self, "enable_nested_virtualization")

    @_builtins.property
    @pulumi.getter(name="performanceMonitoringUnit")
    def performance_monitoring_unit(self) -> Optional[_builtins.str]:
        """
        Defines the performance monitoring unit [PMU](https://cloud.google.com/compute/docs/pmu-overview) level. Valid values are `ARCHITECTURAL`, `STANDARD`, or `ENHANCED`. Defaults to off.
        """
        return pulumi.get(self, "performance_monitoring_unit")


@pulumi.output_type
class ClusterNodeConfigBootDisk(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "diskType":
            suggest = "disk_type"
        elif key == "provisionedIops":
            suggest = "provisioned_iops"
        elif key == "provisionedThroughput":
            suggest = "provisioned_throughput"
        elif key == "sizeGb":
            suggest = "size_gb"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigBootDisk. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigBootDisk.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigBootDisk.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disk_type: Optional[_builtins.str] = None,
                 provisioned_iops: Optional[_builtins.int] = None,
                 provisioned_throughput: Optional[_builtins.int] = None,
                 size_gb: Optional[_builtins.int] = None):
        """
        :param _builtins.str disk_type: Type of the disk attached to each node
               (e.g. 'pd-standard', 'pd-balanced', 'pd-ssd', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`. This is being migrated from `node_config.disk_type`, and must match if specified in both places. Prefer using this field.
        :param _builtins.int provisioned_iops: Configure disk IOPs. This is only valid if the `disk_type` is 'hyperdisk-balanced'. See [performance limit documention](https://cloud.google.com/compute/docs/disks/hyperdisk-perf-limits) for more information about valid values.
        :param _builtins.int provisioned_throughput: Configure disk throughput. This is only valid if the `disk_type` is 'hyperdisk-balanced'. See [performance limit documention](https://cloud.google.com/compute/docs/disks/hyperdisk-perf-limits) for more information about valid values.
        :param _builtins.int size_gb: Size of the disk attached to each node, specified
               in GB. The smallest allowed disk size is 10GB. Defaults to 100GB. This is being migrated from `node_config.disk_size_gb`, and must match if specified in both places. Prefer using this field.
        """
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if provisioned_iops is not None:
            pulumi.set(__self__, "provisioned_iops", provisioned_iops)
        if provisioned_throughput is not None:
            pulumi.set(__self__, "provisioned_throughput", provisioned_throughput)
        if size_gb is not None:
            pulumi.set(__self__, "size_gb", size_gb)

    @_builtins.property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[_builtins.str]:
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced', 'pd-ssd', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`. This is being migrated from `node_config.disk_type`, and must match if specified in both places. Prefer using this field.
        """
        return pulumi.get(self, "disk_type")

    @_builtins.property
    @pulumi.getter(name="provisionedIops")
    def provisioned_iops(self) -> Optional[_builtins.int]:
        """
        Configure disk IOPs. This is only valid if the `disk_type` is 'hyperdisk-balanced'. See [performance limit documention](https://cloud.google.com/compute/docs/disks/hyperdisk-perf-limits) for more information about valid values.
        """
        return pulumi.get(self, "provisioned_iops")

    @_builtins.property
    @pulumi.getter(name="provisionedThroughput")
    def provisioned_throughput(self) -> Optional[_builtins.int]:
        """
        Configure disk throughput. This is only valid if the `disk_type` is 'hyperdisk-balanced'. See [performance limit documention](https://cloud.google.com/compute/docs/disks/hyperdisk-perf-limits) for more information about valid values.
        """
        return pulumi.get(self, "provisioned_throughput")

    @_builtins.property
    @pulumi.getter(name="sizeGb")
    def size_gb(self) -> Optional[_builtins.int]:
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB. This is being migrated from `node_config.disk_size_gb`, and must match if specified in both places. Prefer using this field.
        """
        return pulumi.get(self, "size_gb")


@pulumi.output_type
class ClusterNodeConfigConfidentialNodes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "confidentialInstanceType":
            suggest = "confidential_instance_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigConfidentialNodes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigConfidentialNodes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigConfidentialNodes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 confidential_instance_type: Optional[_builtins.str] = None):
        """
        :param _builtins.bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        :param _builtins.str confidential_instance_type: Defines the type of technology used
               by the confidential node.
        """
        pulumi.set(__self__, "enabled", enabled)
        if confidential_instance_type is not None:
            pulumi.set(__self__, "confidential_instance_type", confidential_instance_type)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="confidentialInstanceType")
    def confidential_instance_type(self) -> Optional[_builtins.str]:
        """
        Defines the type of technology used
        by the confidential node.
        """
        return pulumi.get(self, "confidential_instance_type")


@pulumi.output_type
class ClusterNodeConfigContainerdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateRegistryAccessConfig":
            suggest = "private_registry_access_config"
        elif key == "writableCgroups":
            suggest = "writable_cgroups"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigContainerdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigContainerdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigContainerdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 private_registry_access_config: Optional['outputs.ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig'] = None,
                 writable_cgroups: Optional['outputs.ClusterNodeConfigContainerdConfigWritableCgroups'] = None):
        """
        :param 'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs' private_registry_access_config: Configuration for private container registries. There are two fields in this config:
        :param 'ClusterNodeConfigContainerdConfigWritableCgroupsArgs' writable_cgroups: Configuration for writable cgroups. This allows containers to have a writable `/sys/fs/cgroup` directory, which is required for some workloads to create their own sub-cgroups. The `writable_cgroups` block supports:
        """
        if private_registry_access_config is not None:
            pulumi.set(__self__, "private_registry_access_config", private_registry_access_config)
        if writable_cgroups is not None:
            pulumi.set(__self__, "writable_cgroups", writable_cgroups)

    @_builtins.property
    @pulumi.getter(name="privateRegistryAccessConfig")
    def private_registry_access_config(self) -> Optional['outputs.ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig']:
        """
        Configuration for private container registries. There are two fields in this config:
        """
        return pulumi.get(self, "private_registry_access_config")

    @_builtins.property
    @pulumi.getter(name="writableCgroups")
    def writable_cgroups(self) -> Optional['outputs.ClusterNodeConfigContainerdConfigWritableCgroups']:
        """
        Configuration for writable cgroups. This allows containers to have a writable `/sys/fs/cgroup` directory, which is required for some workloads to create their own sub-cgroups. The `writable_cgroups` block supports:
        """
        return pulumi.get(self, "writable_cgroups")


@pulumi.output_type
class ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "certificateAuthorityDomainConfigs":
            suggest = "certificate_authority_domain_configs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 certificate_authority_domain_configs: Optional[Sequence['outputs.ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']] = None):
        """
        :param _builtins.bool enabled: Enables private registry config. If set to false, all other fields in this object must not be set.
        :param Sequence['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
        pulumi.set(__self__, "enabled", enabled)
        if certificate_authority_domain_configs is not None:
            pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enables private registry config. If set to false, all other fields in this object must not be set.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Optional[Sequence['outputs.ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']]:
        """
        List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
        return pulumi.get(self, "certificate_authority_domain_configs")


@pulumi.output_type
class ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gcpSecretManagerCertificateConfig":
            suggest = "gcp_secret_manager_certificate_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 fqdns: Sequence[_builtins.str],
                 gcp_secret_manager_certificate_config: 'outputs.ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig'):
        """
        :param Sequence[_builtins.str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param 'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs' gcp_secret_manager_certificate_config: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_config", gcp_secret_manager_certificate_config)

    @_builtins.property
    @pulumi.getter
    def fqdns(self) -> Sequence[_builtins.str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @_builtins.property
    @pulumi.getter(name="gcpSecretManagerCertificateConfig")
    def gcp_secret_manager_certificate_config(self) -> 'outputs.ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig':
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_config")


@pulumi.output_type
class ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretUri":
            suggest = "secret_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_uri: _builtins.str):
        """
        :param _builtins.str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @_builtins.property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> _builtins.str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class ClusterNodeConfigContainerdConfigWritableCgroups(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether writable cgroups are enabled.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether writable cgroups are enabled.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodeConfigEffectiveTaint(dict):
    def __init__(__self__, *,
                 effect: Optional[_builtins.str] = None,
                 key: Optional[_builtins.str] = None,
                 value: Optional[_builtins.str] = None):
        """
        :param _builtins.str effect: Effect for taint.
        :param _builtins.str key: Key for taint.
        :param _builtins.str value: Value for taint.
        """
        if effect is not None:
            pulumi.set(__self__, "effect", effect)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def effect(self) -> Optional[_builtins.str]:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @_builtins.property
    @pulumi.getter
    def key(self) -> Optional[_builtins.str]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def value(self) -> Optional[_builtins.str]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class ClusterNodeConfigEphemeralStorageConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigEphemeralStorageConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: _builtins.int):
        """
        :param _builtins.int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodeConfigEphemeralStorageLocalSsdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "dataCacheCount":
            suggest = "data_cache_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigEphemeralStorageLocalSsdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: _builtins.int,
                 data_cache_count: Optional[_builtins.int] = None):
        """
        :param _builtins.int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        :param _builtins.int data_cache_count: Number of raw-block local NVMe SSD disks to be attached to the node utilized for GKE Data Cache. If zero, then GKE Data Cache will not be enabled in the nodes.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if data_cache_count is not None:
            pulumi.set(__self__, "data_cache_count", data_cache_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")

    @_builtins.property
    @pulumi.getter(name="dataCacheCount")
    def data_cache_count(self) -> Optional[_builtins.int]:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node utilized for GKE Data Cache. If zero, then GKE Data Cache will not be enabled in the nodes.
        """
        return pulumi.get(self, "data_cache_count")


@pulumi.output_type
class ClusterNodeConfigFastSocket(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not the NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not the NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodeConfigGcfsConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodeConfigGuestAccelerator(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverInstallationConfig":
            suggest = "gpu_driver_installation_config"
        elif key == "gpuPartitionSize":
            suggest = "gpu_partition_size"
        elif key == "gpuSharingConfig":
            suggest = "gpu_sharing_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigGuestAccelerator. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigGuestAccelerator.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigGuestAccelerator.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 count: _builtins.int,
                 type: _builtins.str,
                 gpu_driver_installation_config: Optional['outputs.ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig'] = None,
                 gpu_partition_size: Optional[_builtins.str] = None,
                 gpu_sharing_config: Optional['outputs.ClusterNodeConfigGuestAcceleratorGpuSharingConfig'] = None):
        """
        :param _builtins.int count: The number of the guest accelerator cards exposed to this instance.
        :param _builtins.str type: The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        :param 'ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs' gpu_driver_installation_config: Configuration for auto installation of GPU driver. Structure is documented below.
        :param _builtins.str gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        :param 'ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs' gpu_sharing_config: Configuration for GPU sharing. Structure is documented below.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @_builtins.property
    @pulumi.getter
    def count(self) -> _builtins.int:
        """
        The number of the guest accelerator cards exposed to this instance.
        """
        return pulumi.get(self, "count")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        """
        return pulumi.get(self, "type")

    @_builtins.property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional['outputs.ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig']:
        """
        Configuration for auto installation of GPU driver. Structure is documented below.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @_builtins.property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[_builtins.str]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        """
        return pulumi.get(self, "gpu_partition_size")

    @_builtins.property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional['outputs.ClusterNodeConfigGuestAcceleratorGpuSharingConfig']:
        """
        Configuration for GPU sharing. Structure is documented below.
        """
        return pulumi.get(self, "gpu_sharing_config")


@pulumi.output_type
class ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverVersion":
            suggest = "gpu_driver_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_driver_version: _builtins.str):
        """
        :param _builtins.str gpu_driver_version: Mode for how the GPU driver is installed.
               Accepted values are:
               * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to install the "Default" GPU driver. Before GKE `1.30.1-gke.1156000`, the default value is to not install any GPU driver.
               * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
               * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
               * `"LATEST"`: "Latest" GPU driver in COS.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @_builtins.property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> _builtins.str:
        """
        Mode for how the GPU driver is installed.
        Accepted values are:
        * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to install the "Default" GPU driver. Before GKE `1.30.1-gke.1156000`, the default value is to not install any GPU driver.
        * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
        * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
        * `"LATEST"`: "Latest" GPU driver in COS.
        """
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class ClusterNodeConfigGuestAcceleratorGpuSharingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuSharingStrategy":
            suggest = "gpu_sharing_strategy"
        elif key == "maxSharedClientsPerGpu":
            suggest = "max_shared_clients_per_gpu"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigGuestAcceleratorGpuSharingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_sharing_strategy: _builtins.str,
                 max_shared_clients_per_gpu: _builtins.int):
        """
        :param _builtins.str gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node.
               Accepted values are:
               * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
               * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        :param _builtins.int max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @_builtins.property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> _builtins.str:
        """
        The type of GPU sharing strategy to enable on the GPU node.
        Accepted values are:
        * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @_builtins.property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> _builtins.int:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class ClusterNodeConfigGvnic(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodeConfigHostMaintenancePolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maintenanceInterval":
            suggest = "maintenance_interval"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigHostMaintenancePolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 maintenance_interval: _builtins.str):
        """
        :param _builtins.str maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @_builtins.property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> _builtins.str:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class ClusterNodeConfigKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowedUnsafeSysctls":
            suggest = "allowed_unsafe_sysctls"
        elif key == "containerLogMaxFiles":
            suggest = "container_log_max_files"
        elif key == "containerLogMaxSize":
            suggest = "container_log_max_size"
        elif key == "cpuCfsQuota":
            suggest = "cpu_cfs_quota"
        elif key == "cpuCfsQuotaPeriod":
            suggest = "cpu_cfs_quota_period"
        elif key == "cpuManagerPolicy":
            suggest = "cpu_manager_policy"
        elif key == "evictionMaxPodGracePeriodSeconds":
            suggest = "eviction_max_pod_grace_period_seconds"
        elif key == "evictionMinimumReclaim":
            suggest = "eviction_minimum_reclaim"
        elif key == "evictionSoft":
            suggest = "eviction_soft"
        elif key == "evictionSoftGracePeriod":
            suggest = "eviction_soft_grace_period"
        elif key == "imageGcHighThresholdPercent":
            suggest = "image_gc_high_threshold_percent"
        elif key == "imageGcLowThresholdPercent":
            suggest = "image_gc_low_threshold_percent"
        elif key == "imageMaximumGcAge":
            suggest = "image_maximum_gc_age"
        elif key == "imageMinimumGcAge":
            suggest = "image_minimum_gc_age"
        elif key == "insecureKubeletReadonlyPortEnabled":
            suggest = "insecure_kubelet_readonly_port_enabled"
        elif key == "maxParallelImagePulls":
            suggest = "max_parallel_image_pulls"
        elif key == "memoryManager":
            suggest = "memory_manager"
        elif key == "podPidsLimit":
            suggest = "pod_pids_limit"
        elif key == "singleProcessOomKill":
            suggest = "single_process_oom_kill"
        elif key == "topologyManager":
            suggest = "topology_manager"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allowed_unsafe_sysctls: Optional[Sequence[_builtins.str]] = None,
                 container_log_max_files: Optional[_builtins.int] = None,
                 container_log_max_size: Optional[_builtins.str] = None,
                 cpu_cfs_quota: Optional[_builtins.bool] = None,
                 cpu_cfs_quota_period: Optional[_builtins.str] = None,
                 cpu_manager_policy: Optional[_builtins.str] = None,
                 eviction_max_pod_grace_period_seconds: Optional[_builtins.int] = None,
                 eviction_minimum_reclaim: Optional['outputs.ClusterNodeConfigKubeletConfigEvictionMinimumReclaim'] = None,
                 eviction_soft: Optional['outputs.ClusterNodeConfigKubeletConfigEvictionSoft'] = None,
                 eviction_soft_grace_period: Optional['outputs.ClusterNodeConfigKubeletConfigEvictionSoftGracePeriod'] = None,
                 image_gc_high_threshold_percent: Optional[_builtins.int] = None,
                 image_gc_low_threshold_percent: Optional[_builtins.int] = None,
                 image_maximum_gc_age: Optional[_builtins.str] = None,
                 image_minimum_gc_age: Optional[_builtins.str] = None,
                 insecure_kubelet_readonly_port_enabled: Optional[_builtins.str] = None,
                 max_parallel_image_pulls: Optional[_builtins.int] = None,
                 memory_manager: Optional['outputs.ClusterNodeConfigKubeletConfigMemoryManager'] = None,
                 pod_pids_limit: Optional[_builtins.int] = None,
                 single_process_oom_kill: Optional[_builtins.bool] = None,
                 topology_manager: Optional['outputs.ClusterNodeConfigKubeletConfigTopologyManager'] = None):
        """
        :param Sequence[_builtins.str] allowed_unsafe_sysctls: Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods. The allowed sysctl groups are `kernel.shm*`, `kernel.msg*`, `kernel.sem`, `fs.mqueue.*`, and `net.*`.
        :param _builtins.int container_log_max_files: Defines the maximum number of container log files that can be present for a container. The integer must be between 2 and 10, inclusive.
        :param _builtins.str container_log_max_size: Defines the maximum size of the
               container log file before it is rotated. Specified as a positive number and a
               unit suffix, such as `"100Ki"`, `"10Mi"`. Valid units are "Ki", "Mi", "Gi".
               The value must be between `"10Mi"` and `"500Mi"`, inclusive. And the total container log size
               (`container_log_max_size` * `container_log_max_files`) cannot exceed 1% of the total storage of the node.
        :param _builtins.bool cpu_cfs_quota: If true, enables CPU CFS quota enforcement for
               containers that specify CPU limits.
        :param _builtins.str cpu_cfs_quota_period: The CPU CFS quota period value. Specified
               as a sequence of decimal numbers, each with optional fraction and a unit suffix,
               such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
               "h". The value must be a positive duration.
        :param _builtins.str cpu_manager_policy: The CPU management policy on the node. See
               [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
               One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
               Prior to the 6.4.0 this field was marked as required. The workaround for the required field
               is setting the empty string `""`, which will function identically to not setting this field.
        :param _builtins.int eviction_max_pod_grace_period_seconds: Defines the maximum allowed grace period (in seconds) to use when terminating pods in response to a soft eviction threshold being met. The integer must be positive and not exceed 300.
        :param 'ClusterNodeConfigKubeletConfigEvictionMinimumReclaimArgs' eviction_minimum_reclaim: Defines a map of signal names to percentage that defines minimum reclaims. It describes the minimum amount of a given resource the kubelet will reclaim when performing a pod eviction. Structure is documented below.
        :param 'ClusterNodeConfigKubeletConfigEvictionSoftArgs' eviction_soft: Defines a map of signal names to quantities or percentage that defines soft eviction thresholds. Structure is documented below.
        :param 'ClusterNodeConfigKubeletConfigEvictionSoftGracePeriodArgs' eviction_soft_grace_period: Defines a map of signal names to durations that defines grace periods for soft eviction thresholds. Each soft eviction threshold must have a corresponding grace period. Structure is documented below.
        :param _builtins.int image_gc_high_threshold_percent: Defines the percent of disk usage after which image garbage collection is always run. The integer must be between 10 and 85, inclusive.
        :param _builtins.int image_gc_low_threshold_percent: Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to. The integer must be between 10 and 85, inclusive.
        :param _builtins.str image_maximum_gc_age: Defines the maximum age an image can be unused before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`, and `"2h45m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h". The value must be a positive duration.
        :param _builtins.str image_minimum_gc_age: Defines the minimum age for an unused image before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`. The value cannot be greater than "2m".
        :param _builtins.str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param _builtins.int max_parallel_image_pulls: Set the maximum number of image pulls in parallel. The integer must be between 2 and 5, inclusive.
        :param 'ClusterNodeConfigKubeletConfigMemoryManagerArgs' memory_manager: Configuration for the [memory manager](https://kubernetes.io/docs/tasks/administer-cluster/memory-manager/) on the node.
               The memory manager optimizes memory and hugepages allocation for pods, especially
               those in the Guaranteed QoS class, by influencing NUMA affinity. Structure is documented below.
        :param _builtins.int pod_pids_limit: Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        :param _builtins.bool single_process_oom_kill: Defines whether to enable single process OOM killer. If true, the processes in the container will be OOM killed individually instead of as a group.
        :param 'ClusterNodeConfigKubeletConfigTopologyManagerArgs' topology_manager: These settings control the kubelet's [Topology Manager policy](https://kubernetes.io/docs/tasks/administer-cluster/topology-manager/#topology-manager-policies), which coordinates the set of components responsible for performance optimizations related to CPU isolation, memory, and device locality. Structure is documented below.
        """
        if allowed_unsafe_sysctls is not None:
            pulumi.set(__self__, "allowed_unsafe_sysctls", allowed_unsafe_sysctls)
        if container_log_max_files is not None:
            pulumi.set(__self__, "container_log_max_files", container_log_max_files)
        if container_log_max_size is not None:
            pulumi.set(__self__, "container_log_max_size", container_log_max_size)
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if cpu_manager_policy is not None:
            pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if eviction_max_pod_grace_period_seconds is not None:
            pulumi.set(__self__, "eviction_max_pod_grace_period_seconds", eviction_max_pod_grace_period_seconds)
        if eviction_minimum_reclaim is not None:
            pulumi.set(__self__, "eviction_minimum_reclaim", eviction_minimum_reclaim)
        if eviction_soft is not None:
            pulumi.set(__self__, "eviction_soft", eviction_soft)
        if eviction_soft_grace_period is not None:
            pulumi.set(__self__, "eviction_soft_grace_period", eviction_soft_grace_period)
        if image_gc_high_threshold_percent is not None:
            pulumi.set(__self__, "image_gc_high_threshold_percent", image_gc_high_threshold_percent)
        if image_gc_low_threshold_percent is not None:
            pulumi.set(__self__, "image_gc_low_threshold_percent", image_gc_low_threshold_percent)
        if image_maximum_gc_age is not None:
            pulumi.set(__self__, "image_maximum_gc_age", image_maximum_gc_age)
        if image_minimum_gc_age is not None:
            pulumi.set(__self__, "image_minimum_gc_age", image_minimum_gc_age)
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        if max_parallel_image_pulls is not None:
            pulumi.set(__self__, "max_parallel_image_pulls", max_parallel_image_pulls)
        if memory_manager is not None:
            pulumi.set(__self__, "memory_manager", memory_manager)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)
        if single_process_oom_kill is not None:
            pulumi.set(__self__, "single_process_oom_kill", single_process_oom_kill)
        if topology_manager is not None:
            pulumi.set(__self__, "topology_manager", topology_manager)

    @_builtins.property
    @pulumi.getter(name="allowedUnsafeSysctls")
    def allowed_unsafe_sysctls(self) -> Optional[Sequence[_builtins.str]]:
        """
        Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods. The allowed sysctl groups are `kernel.shm*`, `kernel.msg*`, `kernel.sem`, `fs.mqueue.*`, and `net.*`.
        """
        return pulumi.get(self, "allowed_unsafe_sysctls")

    @_builtins.property
    @pulumi.getter(name="containerLogMaxFiles")
    def container_log_max_files(self) -> Optional[_builtins.int]:
        """
        Defines the maximum number of container log files that can be present for a container. The integer must be between 2 and 10, inclusive.
        """
        return pulumi.get(self, "container_log_max_files")

    @_builtins.property
    @pulumi.getter(name="containerLogMaxSize")
    def container_log_max_size(self) -> Optional[_builtins.str]:
        """
        Defines the maximum size of the
        container log file before it is rotated. Specified as a positive number and a
        unit suffix, such as `"100Ki"`, `"10Mi"`. Valid units are "Ki", "Mi", "Gi".
        The value must be between `"10Mi"` and `"500Mi"`, inclusive. And the total container log size
        (`container_log_max_size` * `container_log_max_files`) cannot exceed 1% of the total storage of the node.
        """
        return pulumi.get(self, "container_log_max_size")

    @_builtins.property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[_builtins.bool]:
        """
        If true, enables CPU CFS quota enforcement for
        containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @_builtins.property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[_builtins.str]:
        """
        The CPU CFS quota period value. Specified
        as a sequence of decimal numbers, each with optional fraction and a unit suffix,
        such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
        "h". The value must be a positive duration.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @_builtins.property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> Optional[_builtins.str]:
        """
        The CPU management policy on the node. See
        [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
        One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
        Prior to the 6.4.0 this field was marked as required. The workaround for the required field
        is setting the empty string `""`, which will function identically to not setting this field.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @_builtins.property
    @pulumi.getter(name="evictionMaxPodGracePeriodSeconds")
    def eviction_max_pod_grace_period_seconds(self) -> Optional[_builtins.int]:
        """
        Defines the maximum allowed grace period (in seconds) to use when terminating pods in response to a soft eviction threshold being met. The integer must be positive and not exceed 300.
        """
        return pulumi.get(self, "eviction_max_pod_grace_period_seconds")

    @_builtins.property
    @pulumi.getter(name="evictionMinimumReclaim")
    def eviction_minimum_reclaim(self) -> Optional['outputs.ClusterNodeConfigKubeletConfigEvictionMinimumReclaim']:
        """
        Defines a map of signal names to percentage that defines minimum reclaims. It describes the minimum amount of a given resource the kubelet will reclaim when performing a pod eviction. Structure is documented below.
        """
        return pulumi.get(self, "eviction_minimum_reclaim")

    @_builtins.property
    @pulumi.getter(name="evictionSoft")
    def eviction_soft(self) -> Optional['outputs.ClusterNodeConfigKubeletConfigEvictionSoft']:
        """
        Defines a map of signal names to quantities or percentage that defines soft eviction thresholds. Structure is documented below.
        """
        return pulumi.get(self, "eviction_soft")

    @_builtins.property
    @pulumi.getter(name="evictionSoftGracePeriod")
    def eviction_soft_grace_period(self) -> Optional['outputs.ClusterNodeConfigKubeletConfigEvictionSoftGracePeriod']:
        """
        Defines a map of signal names to durations that defines grace periods for soft eviction thresholds. Each soft eviction threshold must have a corresponding grace period. Structure is documented below.
        """
        return pulumi.get(self, "eviction_soft_grace_period")

    @_builtins.property
    @pulumi.getter(name="imageGcHighThresholdPercent")
    def image_gc_high_threshold_percent(self) -> Optional[_builtins.int]:
        """
        Defines the percent of disk usage after which image garbage collection is always run. The integer must be between 10 and 85, inclusive.
        """
        return pulumi.get(self, "image_gc_high_threshold_percent")

    @_builtins.property
    @pulumi.getter(name="imageGcLowThresholdPercent")
    def image_gc_low_threshold_percent(self) -> Optional[_builtins.int]:
        """
        Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to. The integer must be between 10 and 85, inclusive.
        """
        return pulumi.get(self, "image_gc_low_threshold_percent")

    @_builtins.property
    @pulumi.getter(name="imageMaximumGcAge")
    def image_maximum_gc_age(self) -> Optional[_builtins.str]:
        """
        Defines the maximum age an image can be unused before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`, and `"2h45m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h". The value must be a positive duration.
        """
        return pulumi.get(self, "image_maximum_gc_age")

    @_builtins.property
    @pulumi.getter(name="imageMinimumGcAge")
    def image_minimum_gc_age(self) -> Optional[_builtins.str]:
        """
        Defines the minimum age for an unused image before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`. The value cannot be greater than "2m".
        """
        return pulumi.get(self, "image_minimum_gc_age")

    @_builtins.property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[_builtins.str]:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @_builtins.property
    @pulumi.getter(name="maxParallelImagePulls")
    def max_parallel_image_pulls(self) -> Optional[_builtins.int]:
        """
        Set the maximum number of image pulls in parallel. The integer must be between 2 and 5, inclusive.
        """
        return pulumi.get(self, "max_parallel_image_pulls")

    @_builtins.property
    @pulumi.getter(name="memoryManager")
    def memory_manager(self) -> Optional['outputs.ClusterNodeConfigKubeletConfigMemoryManager']:
        """
        Configuration for the [memory manager](https://kubernetes.io/docs/tasks/administer-cluster/memory-manager/) on the node.
        The memory manager optimizes memory and hugepages allocation for pods, especially
        those in the Guaranteed QoS class, by influencing NUMA affinity. Structure is documented below.
        """
        return pulumi.get(self, "memory_manager")

    @_builtins.property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[_builtins.int]:
        """
        Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        return pulumi.get(self, "pod_pids_limit")

    @_builtins.property
    @pulumi.getter(name="singleProcessOomKill")
    def single_process_oom_kill(self) -> Optional[_builtins.bool]:
        """
        Defines whether to enable single process OOM killer. If true, the processes in the container will be OOM killed individually instead of as a group.
        """
        return pulumi.get(self, "single_process_oom_kill")

    @_builtins.property
    @pulumi.getter(name="topologyManager")
    def topology_manager(self) -> Optional['outputs.ClusterNodeConfigKubeletConfigTopologyManager']:
        """
        These settings control the kubelet's [Topology Manager policy](https://kubernetes.io/docs/tasks/administer-cluster/topology-manager/#topology-manager-policies), which coordinates the set of components responsible for performance optimizations related to CPU isolation, memory, and device locality. Structure is documented below.
        """
        return pulumi.get(self, "topology_manager")


@pulumi.output_type
class ClusterNodeConfigKubeletConfigEvictionMinimumReclaim(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "imagefsAvailable":
            suggest = "imagefs_available"
        elif key == "imagefsInodesFree":
            suggest = "imagefs_inodes_free"
        elif key == "memoryAvailable":
            suggest = "memory_available"
        elif key == "nodefsAvailable":
            suggest = "nodefs_available"
        elif key == "nodefsInodesFree":
            suggest = "nodefs_inodes_free"
        elif key == "pidAvailable":
            suggest = "pid_available"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigKubeletConfigEvictionMinimumReclaim. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigKubeletConfigEvictionMinimumReclaim.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigKubeletConfigEvictionMinimumReclaim.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 imagefs_available: Optional[_builtins.str] = None,
                 imagefs_inodes_free: Optional[_builtins.str] = None,
                 memory_available: Optional[_builtins.str] = None,
                 nodefs_available: Optional[_builtins.str] = None,
                 nodefs_inodes_free: Optional[_builtins.str] = None,
                 pid_available: Optional[_builtins.str] = None):
        """
        :param _builtins.str imagefs_available: Defines percentage of minimum reclaim for imagefs.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        :param _builtins.str imagefs_inodes_free: Defines percentage of minimum reclaim for imagefs.inodesFree. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        :param _builtins.str memory_available: Defines percentage of minimum reclaim for memory.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        :param _builtins.str nodefs_available: Defines percentage of minimum reclaim for nodefs.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        :param _builtins.str nodefs_inodes_free: Defines percentage of minimum reclaim for nodefs.inodesFree. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        :param _builtins.str pid_available: Defines percentage of minimum reclaim for pid.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        if imagefs_available is not None:
            pulumi.set(__self__, "imagefs_available", imagefs_available)
        if imagefs_inodes_free is not None:
            pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        if memory_available is not None:
            pulumi.set(__self__, "memory_available", memory_available)
        if nodefs_available is not None:
            pulumi.set(__self__, "nodefs_available", nodefs_available)
        if nodefs_inodes_free is not None:
            pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        if pid_available is not None:
            pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for imagefs.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for imagefs.inodesFree. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for memory.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for nodefs.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for nodefs.inodesFree. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for pid.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class ClusterNodeConfigKubeletConfigEvictionSoft(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "imagefsAvailable":
            suggest = "imagefs_available"
        elif key == "imagefsInodesFree":
            suggest = "imagefs_inodes_free"
        elif key == "memoryAvailable":
            suggest = "memory_available"
        elif key == "nodefsAvailable":
            suggest = "nodefs_available"
        elif key == "nodefsInodesFree":
            suggest = "nodefs_inodes_free"
        elif key == "pidAvailable":
            suggest = "pid_available"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigKubeletConfigEvictionSoft. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigKubeletConfigEvictionSoft.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigKubeletConfigEvictionSoft.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 imagefs_available: Optional[_builtins.str] = None,
                 imagefs_inodes_free: Optional[_builtins.str] = None,
                 memory_available: Optional[_builtins.str] = None,
                 nodefs_available: Optional[_builtins.str] = None,
                 nodefs_inodes_free: Optional[_builtins.str] = None,
                 pid_available: Optional[_builtins.str] = None):
        """
        :param _builtins.str imagefs_available: Defines percentage of soft eviction threshold for imagefs.available. The value must be a percentage between `15%` and `50%`, such as `"20%"`.
        :param _builtins.str imagefs_inodes_free: Defines percentage of soft eviction threshold for imagefs.inodesFree. The value must be a percentage between `5%` and `50%`, such as `"20%"`.
        :param _builtins.str memory_available: Defines quantity of soft eviction threshold for memory.available. The value must be a quantity, such as `"100Mi"`. The value must be greater than or equal to the GKE default hard eviction threshold of `"100Mi"` and less than 50% of machine memory.
        :param _builtins.str nodefs_available: Defines percentage of soft eviction threshold for nodefs.available. The value must be a percentage between `10%` and `50%`, such as `"20%"`.
        :param _builtins.str nodefs_inodes_free: Defines percentage of soft eviction threshold for nodefs.inodesFree. The value must be a percentage between `5%` and `50%`, such as `"20%"`.
        :param _builtins.str pid_available: Defines percentage of soft eviction threshold for pid.available. The value must be a percentage between `10%` and `50%`, such as `"20%"`.
        """
        if imagefs_available is not None:
            pulumi.set(__self__, "imagefs_available", imagefs_available)
        if imagefs_inodes_free is not None:
            pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        if memory_available is not None:
            pulumi.set(__self__, "memory_available", memory_available)
        if nodefs_available is not None:
            pulumi.set(__self__, "nodefs_available", nodefs_available)
        if nodefs_inodes_free is not None:
            pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        if pid_available is not None:
            pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for imagefs.available. The value must be a percentage between `15%` and `50%`, such as `"20%"`.
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for imagefs.inodesFree. The value must be a percentage between `5%` and `50%`, such as `"20%"`.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> Optional[_builtins.str]:
        """
        Defines quantity of soft eviction threshold for memory.available. The value must be a quantity, such as `"100Mi"`. The value must be greater than or equal to the GKE default hard eviction threshold of `"100Mi"` and less than 50% of machine memory.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for nodefs.available. The value must be a percentage between `10%` and `50%`, such as `"20%"`.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for nodefs.inodesFree. The value must be a percentage between `5%` and `50%`, such as `"20%"`.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for pid.available. The value must be a percentage between `10%` and `50%`, such as `"20%"`.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class ClusterNodeConfigKubeletConfigEvictionSoftGracePeriod(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "imagefsAvailable":
            suggest = "imagefs_available"
        elif key == "imagefsInodesFree":
            suggest = "imagefs_inodes_free"
        elif key == "memoryAvailable":
            suggest = "memory_available"
        elif key == "nodefsAvailable":
            suggest = "nodefs_available"
        elif key == "nodefsInodesFree":
            suggest = "nodefs_inodes_free"
        elif key == "pidAvailable":
            suggest = "pid_available"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigKubeletConfigEvictionSoftGracePeriod. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigKubeletConfigEvictionSoftGracePeriod.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigKubeletConfigEvictionSoftGracePeriod.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 imagefs_available: Optional[_builtins.str] = None,
                 imagefs_inodes_free: Optional[_builtins.str] = None,
                 memory_available: Optional[_builtins.str] = None,
                 nodefs_available: Optional[_builtins.str] = None,
                 nodefs_inodes_free: Optional[_builtins.str] = None,
                 pid_available: Optional[_builtins.str] = None):
        """
        :param _builtins.str imagefs_available: Defines grace period for the imagefs.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        :param _builtins.str imagefs_inodes_free: Defines grace period for the imagefs.inodesFree soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        :param _builtins.str memory_available: Defines grace period for the memory.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`, such as `"30s"`, `"1m30s"`, `"2.5m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h".
        :param _builtins.str nodefs_available: Defines grace period for the nodefs.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        :param _builtins.str nodefs_inodes_free: Defines grace period for the nodefs.inodesFree soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        :param _builtins.str pid_available: Defines grace period for the pid.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        """
        if imagefs_available is not None:
            pulumi.set(__self__, "imagefs_available", imagefs_available)
        if imagefs_inodes_free is not None:
            pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        if memory_available is not None:
            pulumi.set(__self__, "memory_available", memory_available)
        if nodefs_available is not None:
            pulumi.set(__self__, "nodefs_available", nodefs_available)
        if nodefs_inodes_free is not None:
            pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        if pid_available is not None:
            pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the imagefs.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the imagefs.inodesFree soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the memory.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`, such as `"30s"`, `"1m30s"`, `"2.5m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h".
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the nodefs.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the nodefs.inodesFree soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the pid.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class ClusterNodeConfigKubeletConfigMemoryManager(dict):
    def __init__(__self__, *,
                 policy: Optional[_builtins.str] = None):
        """
        :param _builtins.str policy: The [Memory
               Manager](https://kubernetes.io/docs/tasks/administer-cluster/memory-manager/)
               policy can be set to None (default) or Static. This policy dictates how memory alignment is handled on the node.  If unset (or set to the empty string `""`), the API will treat the field as if set to "None".
        """
        if policy is not None:
            pulumi.set(__self__, "policy", policy)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> Optional[_builtins.str]:
        """
        The [Memory
        Manager](https://kubernetes.io/docs/tasks/administer-cluster/memory-manager/)
        policy can be set to None (default) or Static. This policy dictates how memory alignment is handled on the node.  If unset (or set to the empty string `""`), the API will treat the field as if set to "None".
        """
        return pulumi.get(self, "policy")


@pulumi.output_type
class ClusterNodeConfigKubeletConfigTopologyManager(dict):
    def __init__(__self__, *,
                 policy: Optional[_builtins.str] = None,
                 scope: Optional[_builtins.str] = None):
        """
        :param _builtins.str policy: The Topology Manager policy controls resource alignment on the node and can be set to one of the following: none (default), best-effort, restricted, or single-numa-node.  If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
        :param _builtins.str scope: The Topology Manager scope, defining the granularity at which
               policy decisions are applied. Valid values are "container" (resources are aligned
               per container within a pod which is set by default) or "pod" (resources are aligned for the entire pod).  If unset (or set to the empty string `""`), the API will treat the field as if set to "container".
        """
        if policy is not None:
            pulumi.set(__self__, "policy", policy)
        if scope is not None:
            pulumi.set(__self__, "scope", scope)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> Optional[_builtins.str]:
        """
        The Topology Manager policy controls resource alignment on the node and can be set to one of the following: none (default), best-effort, restricted, or single-numa-node.  If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
        """
        return pulumi.get(self, "policy")

    @_builtins.property
    @pulumi.getter
    def scope(self) -> Optional[_builtins.str]:
        """
        The Topology Manager scope, defining the granularity at which
        policy decisions are applied. Valid values are "container" (resources are aligned
        per container within a pod which is set by default) or "pod" (resources are aligned for the entire pod).  If unset (or set to the empty string `""`), the API will treat the field as if set to "container".
        """
        return pulumi.get(self, "scope")


@pulumi.output_type
class ClusterNodeConfigLinuxNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cgroupMode":
            suggest = "cgroup_mode"
        elif key == "hugepagesConfig":
            suggest = "hugepages_config"
        elif key == "nodeKernelModuleLoading":
            suggest = "node_kernel_module_loading"
        elif key == "transparentHugepageDefrag":
            suggest = "transparent_hugepage_defrag"
        elif key == "transparentHugepageEnabled":
            suggest = "transparent_hugepage_enabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigLinuxNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigLinuxNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigLinuxNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cgroup_mode: Optional[_builtins.str] = None,
                 hugepages_config: Optional['outputs.ClusterNodeConfigLinuxNodeConfigHugepagesConfig'] = None,
                 node_kernel_module_loading: Optional['outputs.ClusterNodeConfigLinuxNodeConfigNodeKernelModuleLoading'] = None,
                 sysctls: Optional[Mapping[str, _builtins.str]] = None,
                 transparent_hugepage_defrag: Optional[_builtins.str] = None,
                 transparent_hugepage_enabled: Optional[_builtins.str] = None):
        """
        :param _builtins.str cgroup_mode: Possible cgroup modes that can be used.
               Accepted values are:
               * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
               * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
               * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        :param 'ClusterNodeConfigLinuxNodeConfigHugepagesConfigArgs' hugepages_config: Amounts for 2M and 1G hugepages. Structure is documented below.
        :param 'ClusterNodeConfigLinuxNodeConfigNodeKernelModuleLoadingArgs' node_kernel_module_loading: The settings for kernel module loading.
        :param Mapping[str, _builtins.str] sysctls: The Linux kernel parameters to be applied to the nodes
               and all pods running on the nodes. Specified as a map from the key, such as
               `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Note that validations happen all server side. All attributes are optional.
        :param _builtins.str transparent_hugepage_defrag: The Linux kernel transparent hugepage defrag setting.
        :param _builtins.str transparent_hugepage_enabled: The Linux kernel transparent hugepage setting.
        """
        if cgroup_mode is not None:
            pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        if hugepages_config is not None:
            pulumi.set(__self__, "hugepages_config", hugepages_config)
        if node_kernel_module_loading is not None:
            pulumi.set(__self__, "node_kernel_module_loading", node_kernel_module_loading)
        if sysctls is not None:
            pulumi.set(__self__, "sysctls", sysctls)
        if transparent_hugepage_defrag is not None:
            pulumi.set(__self__, "transparent_hugepage_defrag", transparent_hugepage_defrag)
        if transparent_hugepage_enabled is not None:
            pulumi.set(__self__, "transparent_hugepage_enabled", transparent_hugepage_enabled)

    @_builtins.property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> Optional[_builtins.str]:
        """
        Possible cgroup modes that can be used.
        Accepted values are:
        * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
        * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
        * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        """
        return pulumi.get(self, "cgroup_mode")

    @_builtins.property
    @pulumi.getter(name="hugepagesConfig")
    def hugepages_config(self) -> Optional['outputs.ClusterNodeConfigLinuxNodeConfigHugepagesConfig']:
        """
        Amounts for 2M and 1G hugepages. Structure is documented below.
        """
        return pulumi.get(self, "hugepages_config")

    @_builtins.property
    @pulumi.getter(name="nodeKernelModuleLoading")
    def node_kernel_module_loading(self) -> Optional['outputs.ClusterNodeConfigLinuxNodeConfigNodeKernelModuleLoading']:
        """
        The settings for kernel module loading.
        """
        return pulumi.get(self, "node_kernel_module_loading")

    @_builtins.property
    @pulumi.getter
    def sysctls(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The Linux kernel parameters to be applied to the nodes
        and all pods running on the nodes. Specified as a map from the key, such as
        `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Note that validations happen all server side. All attributes are optional.
        """
        return pulumi.get(self, "sysctls")

    @_builtins.property
    @pulumi.getter(name="transparentHugepageDefrag")
    def transparent_hugepage_defrag(self) -> Optional[_builtins.str]:
        """
        The Linux kernel transparent hugepage defrag setting.
        """
        return pulumi.get(self, "transparent_hugepage_defrag")

    @_builtins.property
    @pulumi.getter(name="transparentHugepageEnabled")
    def transparent_hugepage_enabled(self) -> Optional[_builtins.str]:
        """
        The Linux kernel transparent hugepage setting.
        """
        return pulumi.get(self, "transparent_hugepage_enabled")


@pulumi.output_type
class ClusterNodeConfigLinuxNodeConfigHugepagesConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "hugepageSize1g":
            suggest = "hugepage_size1g"
        elif key == "hugepageSize2m":
            suggest = "hugepage_size2m"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigLinuxNodeConfigHugepagesConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigLinuxNodeConfigHugepagesConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigLinuxNodeConfigHugepagesConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 hugepage_size1g: Optional[_builtins.int] = None,
                 hugepage_size2m: Optional[_builtins.int] = None):
        """
        :param _builtins.int hugepage_size1g: Amount of 1G hugepages.
        :param _builtins.int hugepage_size2m: Amount of 2M hugepages.
        """
        if hugepage_size1g is not None:
            pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        if hugepage_size2m is not None:
            pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @_builtins.property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> Optional[_builtins.int]:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @_builtins.property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> Optional[_builtins.int]:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")


@pulumi.output_type
class ClusterNodeConfigLinuxNodeConfigNodeKernelModuleLoading(dict):
    def __init__(__self__, *,
                 policy: Optional[_builtins.str] = None):
        """
        :param _builtins.str policy: The policy for kernel module loading.
        """
        if policy is not None:
            pulumi.set(__self__, "policy", policy)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> Optional[_builtins.str]:
        """
        The policy for kernel module loading.
        """
        return pulumi.get(self, "policy")


@pulumi.output_type
class ClusterNodeConfigLocalNvmeSsdBlockConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigLocalNvmeSsdBlockConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: _builtins.int):
        """
        :param _builtins.int local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
               > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
        > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodeConfigReservationAffinity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "consumeReservationType":
            suggest = "consume_reservation_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigReservationAffinity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigReservationAffinity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigReservationAffinity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 consume_reservation_type: _builtins.str,
                 key: Optional[_builtins.str] = None,
                 values: Optional[Sequence[_builtins.str]] = None):
        """
        :param _builtins.str consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param _builtins.str key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param Sequence[_builtins.str] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @_builtins.property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> _builtins.str:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @_builtins.property
    @pulumi.getter
    def key(self) -> Optional[_builtins.str]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def values(self) -> Optional[Sequence[_builtins.str]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ClusterNodeConfigSandboxConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sandboxType":
            suggest = "sandbox_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigSandboxConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigSandboxConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigSandboxConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 sandbox_type: _builtins.str):
        """
        :param _builtins.str sandbox_type: Which sandbox to use for pods in the node pool.
               Accepted values are:
               
               * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @_builtins.property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> _builtins.str:
        """
        Which sandbox to use for pods in the node pool.
        Accepted values are:

        * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class ClusterNodeConfigSecondaryBootDisk(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "diskImage":
            suggest = "disk_image"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigSecondaryBootDisk. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigSecondaryBootDisk.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigSecondaryBootDisk.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disk_image: _builtins.str,
                 mode: Optional[_builtins.str] = None):
        """
        :param _builtins.str disk_image: Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        :param _builtins.str mode: Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        if mode is not None:
            pulumi.set(__self__, "mode", mode)

    @_builtins.property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> _builtins.str:
        """
        Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        """
        return pulumi.get(self, "disk_image")

    @_builtins.property
    @pulumi.getter
    def mode(self) -> Optional[_builtins.str]:
        """
        Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class ClusterNodeConfigShieldedInstanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableIntegrityMonitoring":
            suggest = "enable_integrity_monitoring"
        elif key == "enableSecureBoot":
            suggest = "enable_secure_boot"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigShieldedInstanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[_builtins.bool] = None,
                 enable_secure_boot: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param _builtins.bool enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @_builtins.property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[_builtins.bool]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @_builtins.property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[_builtins.bool]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class ClusterNodeConfigSoleTenantConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodeAffinities":
            suggest = "node_affinities"
        elif key == "minNodeCpus":
            suggest = "min_node_cpus"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodeConfigSoleTenantConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodeConfigSoleTenantConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodeConfigSoleTenantConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.ClusterNodeConfigSoleTenantConfigNodeAffinity'],
                 min_node_cpus: Optional[_builtins.int] = None):
        """
        :param Sequence['ClusterNodeConfigSoleTenantConfigNodeAffinityArgs'] node_affinities: The node affinity settings for the sole tenant node pool. Structure is documented below.
        :param _builtins.int min_node_cpus: Specifies the minimum number of vCPUs that each sole tenant node must have to use CPU overcommit. If not specified, the CPU overcommit feeature is disabled. The value should be greater than or equal to half of the machine type's CPU count.
        """
        pulumi.set(__self__, "node_affinities", node_affinities)
        if min_node_cpus is not None:
            pulumi.set(__self__, "min_node_cpus", min_node_cpus)

    @_builtins.property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.ClusterNodeConfigSoleTenantConfigNodeAffinity']:
        """
        The node affinity settings for the sole tenant node pool. Structure is documented below.
        """
        return pulumi.get(self, "node_affinities")

    @_builtins.property
    @pulumi.getter(name="minNodeCpus")
    def min_node_cpus(self) -> Optional[_builtins.int]:
        """
        Specifies the minimum number of vCPUs that each sole tenant node must have to use CPU overcommit. If not specified, the CPU overcommit feeature is disabled. The value should be greater than or equal to half of the machine type's CPU count.
        """
        return pulumi.get(self, "min_node_cpus")


@pulumi.output_type
class ClusterNodeConfigSoleTenantConfigNodeAffinity(dict):
    def __init__(__self__, *,
                 key: _builtins.str,
                 operator: _builtins.str,
                 values: Sequence[_builtins.str]):
        """
        :param _builtins.str key: The default or custom node affinity label key name.
        :param _builtins.str operator: Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        :param Sequence[_builtins.str] values: List of node affinity label values as strings.
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        The default or custom node affinity label key name.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def operator(self) -> _builtins.str:
        """
        Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        """
        return pulumi.get(self, "operator")

    @_builtins.property
    @pulumi.getter
    def values(self) -> Sequence[_builtins.str]:
        """
        List of node affinity label values as strings.
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ClusterNodeConfigTaint(dict):
    def __init__(__self__, *,
                 effect: _builtins.str,
                 key: _builtins.str,
                 value: _builtins.str):
        """
        :param _builtins.str effect: Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        :param _builtins.str key: Key for taint.
        :param _builtins.str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def effect(self) -> _builtins.str:
        """
        Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        """
        return pulumi.get(self, "effect")

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def value(self) -> _builtins.str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class ClusterNodeConfigWindowsNodeConfig(dict):
    def __init__(__self__, *,
                 osversion: Optional[_builtins.str] = None):
        """
        :param _builtins.str osversion: The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        if osversion is not None:
            pulumi.set(__self__, "osversion", osversion)

    @_builtins.property
    @pulumi.getter
    def osversion(self) -> Optional[_builtins.str]:
        """
        The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        return pulumi.get(self, "osversion")


@pulumi.output_type
class ClusterNodeConfigWorkloadMetadataConfig(dict):
    def __init__(__self__, *,
                 mode: _builtins.str):
        """
        :param _builtins.str mode: How to expose the node metadata to the workload running on the node.
               Accepted values are:
               * UNSPECIFIED: Not Set
               * GCE_METADATA: Expose all Compute Engine metadata to pods.
               * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        pulumi.set(__self__, "mode", mode)

    @_builtins.property
    @pulumi.getter
    def mode(self) -> _builtins.str:
        """
        How to expose the node metadata to the workload running on the node.
        Accepted values are:
        * UNSPECIFIED: Not Set
        * GCE_METADATA: Expose all Compute Engine metadata to pods.
        * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class ClusterNodePool(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "initialNodeCount":
            suggest = "initial_node_count"
        elif key == "instanceGroupUrls":
            suggest = "instance_group_urls"
        elif key == "managedInstanceGroupUrls":
            suggest = "managed_instance_group_urls"
        elif key == "maxPodsPerNode":
            suggest = "max_pods_per_node"
        elif key == "namePrefix":
            suggest = "name_prefix"
        elif key == "networkConfig":
            suggest = "network_config"
        elif key == "nodeConfig":
            suggest = "node_config"
        elif key == "nodeCount":
            suggest = "node_count"
        elif key == "nodeLocations":
            suggest = "node_locations"
        elif key == "placementPolicy":
            suggest = "placement_policy"
        elif key == "queuedProvisioning":
            suggest = "queued_provisioning"
        elif key == "upgradeSettings":
            suggest = "upgrade_settings"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePool. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePool.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePool.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 autoscaling: Optional['outputs.ClusterNodePoolAutoscaling'] = None,
                 initial_node_count: Optional[_builtins.int] = None,
                 instance_group_urls: Optional[Sequence[_builtins.str]] = None,
                 managed_instance_group_urls: Optional[Sequence[_builtins.str]] = None,
                 management: Optional['outputs.ClusterNodePoolManagement'] = None,
                 max_pods_per_node: Optional[_builtins.int] = None,
                 name: Optional[_builtins.str] = None,
                 name_prefix: Optional[_builtins.str] = None,
                 network_config: Optional['outputs.ClusterNodePoolNetworkConfig'] = None,
                 node_config: Optional['outputs.ClusterNodePoolNodeConfig'] = None,
                 node_count: Optional[_builtins.int] = None,
                 node_locations: Optional[Sequence[_builtins.str]] = None,
                 placement_policy: Optional['outputs.ClusterNodePoolPlacementPolicy'] = None,
                 queued_provisioning: Optional['outputs.ClusterNodePoolQueuedProvisioning'] = None,
                 upgrade_settings: Optional['outputs.ClusterNodePoolUpgradeSettings'] = None,
                 version: Optional[_builtins.str] = None):
        """
        :param 'ClusterNodePoolAutoscalingArgs' autoscaling: Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
        :param _builtins.int initial_node_count: The number of nodes to create in this
               cluster's default node pool. In regional or multi-zonal clusters, this is the
               number of nodes per zone. Must be set if `node_pool` is not set. If you're using
               `container.NodePool` objects with no default node pool, you'll need to
               set this to a value of at least `1`, alongside setting
               `remove_default_node_pool` to `true`.
        :param Sequence[_builtins.str] instance_group_urls: The resource URLs of the managed instance groups associated with this node pool.
        :param Sequence[_builtins.str] managed_instance_group_urls: List of instance group URLs which have been assigned to this node pool.
        :param 'ClusterNodePoolManagementArgs' management: Node management configuration, wherein auto-repair and auto-upgrade is configured.
        :param _builtins.int max_pods_per_node: The maximum number of pods per node in this node pool. Note that this does not work on node pools which are "route-based" - that is, node pools belonging to clusters that do not have IP Aliasing enabled.
        :param _builtins.str name: The name of the cluster, unique within the project and
               location.
               
               - - -
        :param _builtins.str name_prefix: Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.
        :param 'ClusterNodePoolNetworkConfigArgs' network_config: Configuration for
               [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
        :param 'ClusterNodePoolNodeConfigArgs' node_config: Parameters used in creating the default node pool.
               Generally, this field should not be used at the same time as a
               `container.NodePool` or a `node_pool` block; this configuration
               manages the default node pool, which isn't recommended to be used.
               Structure is documented below.
        :param _builtins.int node_count: The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.
        :param Sequence[_builtins.str] node_locations: The list of zones in which the cluster's nodes
               are located. Nodes must be in the region of their regional cluster or in the
               same region as their cluster's zone for zonal clusters. If this is specified for
               a zonal cluster, omit the cluster's zone.
               
               > A "multi-zonal" cluster is a zonal cluster with at least one additional zone
               defined; in a multi-zonal cluster, the cluster master is only present in a
               single zone while nodes are present in each of the primary zone and the node
               locations. In contrast, in a regional cluster, cluster master nodes are present
               in multiple zones in the region. For that reason, regional clusters should be
               preferred.
        :param 'ClusterNodePoolPlacementPolicyArgs' placement_policy: Specifies the node placement policy
        :param 'ClusterNodePoolQueuedProvisioningArgs' queued_provisioning: Specifies the configuration of queued provisioning
        :param 'ClusterNodePoolUpgradeSettingsArgs' upgrade_settings: Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of max_surge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.
        """
        if autoscaling is not None:
            pulumi.set(__self__, "autoscaling", autoscaling)
        if initial_node_count is not None:
            pulumi.set(__self__, "initial_node_count", initial_node_count)
        if instance_group_urls is not None:
            pulumi.set(__self__, "instance_group_urls", instance_group_urls)
        if managed_instance_group_urls is not None:
            pulumi.set(__self__, "managed_instance_group_urls", managed_instance_group_urls)
        if management is not None:
            pulumi.set(__self__, "management", management)
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if name_prefix is not None:
            pulumi.set(__self__, "name_prefix", name_prefix)
        if network_config is not None:
            pulumi.set(__self__, "network_config", network_config)
        if node_config is not None:
            pulumi.set(__self__, "node_config", node_config)
        if node_count is not None:
            pulumi.set(__self__, "node_count", node_count)
        if node_locations is not None:
            pulumi.set(__self__, "node_locations", node_locations)
        if placement_policy is not None:
            pulumi.set(__self__, "placement_policy", placement_policy)
        if queued_provisioning is not None:
            pulumi.set(__self__, "queued_provisioning", queued_provisioning)
        if upgrade_settings is not None:
            pulumi.set(__self__, "upgrade_settings", upgrade_settings)
        if version is not None:
            pulumi.set(__self__, "version", version)

    @_builtins.property
    @pulumi.getter
    def autoscaling(self) -> Optional['outputs.ClusterNodePoolAutoscaling']:
        """
        Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
        """
        return pulumi.get(self, "autoscaling")

    @_builtins.property
    @pulumi.getter(name="initialNodeCount")
    def initial_node_count(self) -> Optional[_builtins.int]:
        """
        The number of nodes to create in this
        cluster's default node pool. In regional or multi-zonal clusters, this is the
        number of nodes per zone. Must be set if `node_pool` is not set. If you're using
        `container.NodePool` objects with no default node pool, you'll need to
        set this to a value of at least `1`, alongside setting
        `remove_default_node_pool` to `true`.
        """
        return pulumi.get(self, "initial_node_count")

    @_builtins.property
    @pulumi.getter(name="instanceGroupUrls")
    def instance_group_urls(self) -> Optional[Sequence[_builtins.str]]:
        """
        The resource URLs of the managed instance groups associated with this node pool.
        """
        return pulumi.get(self, "instance_group_urls")

    @_builtins.property
    @pulumi.getter(name="managedInstanceGroupUrls")
    def managed_instance_group_urls(self) -> Optional[Sequence[_builtins.str]]:
        """
        List of instance group URLs which have been assigned to this node pool.
        """
        return pulumi.get(self, "managed_instance_group_urls")

    @_builtins.property
    @pulumi.getter
    def management(self) -> Optional['outputs.ClusterNodePoolManagement']:
        """
        Node management configuration, wherein auto-repair and auto-upgrade is configured.
        """
        return pulumi.get(self, "management")

    @_builtins.property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[_builtins.int]:
        """
        The maximum number of pods per node in this node pool. Note that this does not work on node pools which are "route-based" - that is, node pools belonging to clusters that do not have IP Aliasing enabled.
        """
        return pulumi.get(self, "max_pods_per_node")

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[_builtins.str]:
        """
        The name of the cluster, unique within the project and
        location.

        - - -
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter(name="namePrefix")
    def name_prefix(self) -> Optional[_builtins.str]:
        """
        Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.
        """
        return pulumi.get(self, "name_prefix")

    @_builtins.property
    @pulumi.getter(name="networkConfig")
    def network_config(self) -> Optional['outputs.ClusterNodePoolNetworkConfig']:
        """
        Configuration for
        [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
        """
        return pulumi.get(self, "network_config")

    @_builtins.property
    @pulumi.getter(name="nodeConfig")
    def node_config(self) -> Optional['outputs.ClusterNodePoolNodeConfig']:
        """
        Parameters used in creating the default node pool.
        Generally, this field should not be used at the same time as a
        `container.NodePool` or a `node_pool` block; this configuration
        manages the default node pool, which isn't recommended to be used.
        Structure is documented below.
        """
        return pulumi.get(self, "node_config")

    @_builtins.property
    @pulumi.getter(name="nodeCount")
    def node_count(self) -> Optional[_builtins.int]:
        """
        The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.
        """
        return pulumi.get(self, "node_count")

    @_builtins.property
    @pulumi.getter(name="nodeLocations")
    def node_locations(self) -> Optional[Sequence[_builtins.str]]:
        """
        The list of zones in which the cluster's nodes
        are located. Nodes must be in the region of their regional cluster or in the
        same region as their cluster's zone for zonal clusters. If this is specified for
        a zonal cluster, omit the cluster's zone.

        > A "multi-zonal" cluster is a zonal cluster with at least one additional zone
        defined; in a multi-zonal cluster, the cluster master is only present in a
        single zone while nodes are present in each of the primary zone and the node
        locations. In contrast, in a regional cluster, cluster master nodes are present
        in multiple zones in the region. For that reason, regional clusters should be
        preferred.
        """
        return pulumi.get(self, "node_locations")

    @_builtins.property
    @pulumi.getter(name="placementPolicy")
    def placement_policy(self) -> Optional['outputs.ClusterNodePoolPlacementPolicy']:
        """
        Specifies the node placement policy
        """
        return pulumi.get(self, "placement_policy")

    @_builtins.property
    @pulumi.getter(name="queuedProvisioning")
    def queued_provisioning(self) -> Optional['outputs.ClusterNodePoolQueuedProvisioning']:
        """
        Specifies the configuration of queued provisioning
        """
        return pulumi.get(self, "queued_provisioning")

    @_builtins.property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Optional['outputs.ClusterNodePoolUpgradeSettings']:
        """
        Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of max_surge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.
        """
        return pulumi.get(self, "upgrade_settings")

    @_builtins.property
    @pulumi.getter
    def version(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "version")


@pulumi.output_type
class ClusterNodePoolAutoConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "linuxNodeConfig":
            suggest = "linux_node_config"
        elif key == "networkTags":
            suggest = "network_tags"
        elif key == "nodeKubeletConfig":
            suggest = "node_kubelet_config"
        elif key == "resourceManagerTags":
            suggest = "resource_manager_tags"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolAutoConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolAutoConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolAutoConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 linux_node_config: Optional['outputs.ClusterNodePoolAutoConfigLinuxNodeConfig'] = None,
                 network_tags: Optional['outputs.ClusterNodePoolAutoConfigNetworkTags'] = None,
                 node_kubelet_config: Optional['outputs.ClusterNodePoolAutoConfigNodeKubeletConfig'] = None,
                 resource_manager_tags: Optional[Mapping[str, _builtins.str]] = None):
        """
        :param 'ClusterNodePoolAutoConfigLinuxNodeConfigArgs' linux_node_config: Linux system configuration for the cluster's automatically provisioned node pools. Only `cgroup_mode` field is supported in `node_pool_auto_config`. Structure is documented below.
        :param 'ClusterNodePoolAutoConfigNetworkTagsArgs' network_tags: The network tag config for the cluster's automatically provisioned node pools. Structure is documented below.
        :param 'ClusterNodePoolAutoConfigNodeKubeletConfigArgs' node_kubelet_config: Kubelet configuration for Autopilot clusters. Currently, only `insecure_kubelet_readonly_port_enabled` is supported here.
               Structure is documented below.
        :param Mapping[str, _builtins.str] resource_manager_tags: A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if network_tags is not None:
            pulumi.set(__self__, "network_tags", network_tags)
        if node_kubelet_config is not None:
            pulumi.set(__self__, "node_kubelet_config", node_kubelet_config)
        if resource_manager_tags is not None:
            pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)

    @_builtins.property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional['outputs.ClusterNodePoolAutoConfigLinuxNodeConfig']:
        """
        Linux system configuration for the cluster's automatically provisioned node pools. Only `cgroup_mode` field is supported in `node_pool_auto_config`. Structure is documented below.
        """
        return pulumi.get(self, "linux_node_config")

    @_builtins.property
    @pulumi.getter(name="networkTags")
    def network_tags(self) -> Optional['outputs.ClusterNodePoolAutoConfigNetworkTags']:
        """
        The network tag config for the cluster's automatically provisioned node pools. Structure is documented below.
        """
        return pulumi.get(self, "network_tags")

    @_builtins.property
    @pulumi.getter(name="nodeKubeletConfig")
    def node_kubelet_config(self) -> Optional['outputs.ClusterNodePoolAutoConfigNodeKubeletConfig']:
        """
        Kubelet configuration for Autopilot clusters. Currently, only `insecure_kubelet_readonly_port_enabled` is supported here.
        Structure is documented below.
        """
        return pulumi.get(self, "node_kubelet_config")

    @_builtins.property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        return pulumi.get(self, "resource_manager_tags")


@pulumi.output_type
class ClusterNodePoolAutoConfigLinuxNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cgroupMode":
            suggest = "cgroup_mode"
        elif key == "nodeKernelModuleLoading":
            suggest = "node_kernel_module_loading"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolAutoConfigLinuxNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolAutoConfigLinuxNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolAutoConfigLinuxNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cgroup_mode: Optional[_builtins.str] = None,
                 node_kernel_module_loading: Optional['outputs.ClusterNodePoolAutoConfigLinuxNodeConfigNodeKernelModuleLoading'] = None):
        """
        :param _builtins.str cgroup_mode: Possible cgroup modes that can be used.
               Accepted values are:
               * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
               * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
               * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        :param 'ClusterNodePoolAutoConfigLinuxNodeConfigNodeKernelModuleLoadingArgs' node_kernel_module_loading: The settings for kernel module loading.
        """
        if cgroup_mode is not None:
            pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        if node_kernel_module_loading is not None:
            pulumi.set(__self__, "node_kernel_module_loading", node_kernel_module_loading)

    @_builtins.property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> Optional[_builtins.str]:
        """
        Possible cgroup modes that can be used.
        Accepted values are:
        * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
        * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
        * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        """
        return pulumi.get(self, "cgroup_mode")

    @_builtins.property
    @pulumi.getter(name="nodeKernelModuleLoading")
    def node_kernel_module_loading(self) -> Optional['outputs.ClusterNodePoolAutoConfigLinuxNodeConfigNodeKernelModuleLoading']:
        """
        The settings for kernel module loading.
        """
        return pulumi.get(self, "node_kernel_module_loading")


@pulumi.output_type
class ClusterNodePoolAutoConfigLinuxNodeConfigNodeKernelModuleLoading(dict):
    def __init__(__self__, *,
                 policy: Optional[_builtins.str] = None):
        """
        :param _builtins.str policy: The policy for kernel module loading.
        """
        if policy is not None:
            pulumi.set(__self__, "policy", policy)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> Optional[_builtins.str]:
        """
        The policy for kernel module loading.
        """
        return pulumi.get(self, "policy")


@pulumi.output_type
class ClusterNodePoolAutoConfigNetworkTags(dict):
    def __init__(__self__, *,
                 tags: Optional[Sequence[_builtins.str]] = None):
        """
        :param Sequence[_builtins.str] tags: List of network tags applied to auto-provisioned node pools.
        """
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Optional[Sequence[_builtins.str]]:
        """
        List of network tags applied to auto-provisioned node pools.
        """
        return pulumi.get(self, "tags")


@pulumi.output_type
class ClusterNodePoolAutoConfigNodeKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "insecureKubeletReadonlyPortEnabled":
            suggest = "insecure_kubelet_readonly_port_enabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolAutoConfigNodeKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolAutoConfigNodeKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolAutoConfigNodeKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 insecure_kubelet_readonly_port_enabled: Optional[_builtins.str] = None):
        """
        :param _builtins.str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)

    @_builtins.property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[_builtins.str]:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")


@pulumi.output_type
class ClusterNodePoolAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "locationPolicy":
            suggest = "location_policy"
        elif key == "maxNodeCount":
            suggest = "max_node_count"
        elif key == "minNodeCount":
            suggest = "min_node_count"
        elif key == "totalMaxNodeCount":
            suggest = "total_max_node_count"
        elif key == "totalMinNodeCount":
            suggest = "total_min_node_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 location_policy: Optional[_builtins.str] = None,
                 max_node_count: Optional[_builtins.int] = None,
                 min_node_count: Optional[_builtins.int] = None,
                 total_max_node_count: Optional[_builtins.int] = None,
                 total_min_node_count: Optional[_builtins.int] = None):
        """
        :param _builtins.str location_policy: Location policy specifies the algorithm used when scaling-up the node pool. "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones. "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations, and reduces preemption risk for Spot VMs.
        :param _builtins.int max_node_count: Maximum number of nodes per zone in the node pool. Must be >= min_node_count. Cannot be used with total limits.
        :param _builtins.int min_node_count: Minimum number of nodes per zone in the node pool. Must be >=0 and <= max_node_count. Cannot be used with total limits.
        :param _builtins.int total_max_node_count: Maximum number of all nodes in the node pool. Must be >= total_min_node_count. Cannot be used with per zone limits.
        :param _builtins.int total_min_node_count: Minimum number of all nodes in the node pool. Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
        """
        if location_policy is not None:
            pulumi.set(__self__, "location_policy", location_policy)
        if max_node_count is not None:
            pulumi.set(__self__, "max_node_count", max_node_count)
        if min_node_count is not None:
            pulumi.set(__self__, "min_node_count", min_node_count)
        if total_max_node_count is not None:
            pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        if total_min_node_count is not None:
            pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @_builtins.property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> Optional[_builtins.str]:
        """
        Location policy specifies the algorithm used when scaling-up the node pool. "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones. "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations, and reduces preemption risk for Spot VMs.
        """
        return pulumi.get(self, "location_policy")

    @_builtins.property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> Optional[_builtins.int]:
        """
        Maximum number of nodes per zone in the node pool. Must be >= min_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "max_node_count")

    @_builtins.property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> Optional[_builtins.int]:
        """
        Minimum number of nodes per zone in the node pool. Must be >=0 and <= max_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "min_node_count")

    @_builtins.property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> Optional[_builtins.int]:
        """
        Maximum number of all nodes in the node pool. Must be >= total_min_node_count. Cannot be used with per zone limits.
        """
        return pulumi.get(self, "total_max_node_count")

    @_builtins.property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> Optional[_builtins.int]:
        """
        Minimum number of all nodes in the node pool. Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
        """
        return pulumi.get(self, "total_min_node_count")


@pulumi.output_type
class ClusterNodePoolDefaults(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodeConfigDefaults":
            suggest = "node_config_defaults"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaults. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaults.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaults.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_config_defaults: Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaults'] = None):
        """
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsArgs' node_config_defaults: Subset of NodeConfig message that has defaults.
        """
        if node_config_defaults is not None:
            pulumi.set(__self__, "node_config_defaults", node_config_defaults)

    @_builtins.property
    @pulumi.getter(name="nodeConfigDefaults")
    def node_config_defaults(self) -> Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaults']:
        """
        Subset of NodeConfig message that has defaults.
        """
        return pulumi.get(self, "node_config_defaults")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaults(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "containerdConfig":
            suggest = "containerd_config"
        elif key == "gcfsConfig":
            suggest = "gcfs_config"
        elif key == "insecureKubeletReadonlyPortEnabled":
            suggest = "insecure_kubelet_readonly_port_enabled"
        elif key == "loggingVariant":
            suggest = "logging_variant"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaultsNodeConfigDefaults. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaults.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaults.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 containerd_config: Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig'] = None,
                 gcfs_config: Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfig'] = None,
                 insecure_kubelet_readonly_port_enabled: Optional[_builtins.str] = None,
                 logging_variant: Optional[_builtins.str] = None):
        """
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigArgs' containerd_config: Parameters for containerd configuration.
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs' gcfs_config: The default Google Container Filesystem (GCFS) configuration at the cluster level. e.g. enable [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming) across all the node pools within the cluster. Structure is documented below.
        :param _builtins.str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled for newly created node pools in the cluster. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param _builtins.str logging_variant: The type of logging agent that is deployed by default for newly created node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        if containerd_config is not None:
            pulumi.set(__self__, "containerd_config", containerd_config)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)

    @_builtins.property
    @pulumi.getter(name="containerdConfig")
    def containerd_config(self) -> Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig']:
        """
        Parameters for containerd configuration.
        """
        return pulumi.get(self, "containerd_config")

    @_builtins.property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfig']:
        """
        The default Google Container Filesystem (GCFS) configuration at the cluster level. e.g. enable [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming) across all the node pools within the cluster. Structure is documented below.
        """
        return pulumi.get(self, "gcfs_config")

    @_builtins.property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[_builtins.str]:
        """
        Controls whether the kubelet read-only port is enabled for newly created node pools in the cluster. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @_builtins.property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[_builtins.str]:
        """
        The type of logging agent that is deployed by default for newly created node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateRegistryAccessConfig":
            suggest = "private_registry_access_config"
        elif key == "writableCgroups":
            suggest = "writable_cgroups"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 private_registry_access_config: Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig'] = None,
                 writable_cgroups: Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigWritableCgroups'] = None):
        """
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigArgs' private_registry_access_config: Configuration for private container registries. There are two fields in this config:
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigWritableCgroupsArgs' writable_cgroups: Configuration for writable cgroups. This allows containers to have a writable `/sys/fs/cgroup` directory, which is required for some workloads to create their own sub-cgroups. The `writable_cgroups` block supports:
        """
        if private_registry_access_config is not None:
            pulumi.set(__self__, "private_registry_access_config", private_registry_access_config)
        if writable_cgroups is not None:
            pulumi.set(__self__, "writable_cgroups", writable_cgroups)

    @_builtins.property
    @pulumi.getter(name="privateRegistryAccessConfig")
    def private_registry_access_config(self) -> Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig']:
        """
        Configuration for private container registries. There are two fields in this config:
        """
        return pulumi.get(self, "private_registry_access_config")

    @_builtins.property
    @pulumi.getter(name="writableCgroups")
    def writable_cgroups(self) -> Optional['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigWritableCgroups']:
        """
        Configuration for writable cgroups. This allows containers to have a writable `/sys/fs/cgroup` directory, which is required for some workloads to create their own sub-cgroups. The `writable_cgroups` block supports:
        """
        return pulumi.get(self, "writable_cgroups")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "certificateAuthorityDomainConfigs":
            suggest = "certificate_authority_domain_configs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 certificate_authority_domain_configs: Optional[Sequence['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']] = None):
        """
        :param _builtins.bool enabled: Enables private registry config. If set to false, all other fields in this object must not be set.
        :param Sequence['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
        pulumi.set(__self__, "enabled", enabled)
        if certificate_authority_domain_configs is not None:
            pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enables private registry config. If set to false, all other fields in this object must not be set.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Optional[Sequence['outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']]:
        """
        List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
        return pulumi.get(self, "certificate_authority_domain_configs")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gcpSecretManagerCertificateConfig":
            suggest = "gcp_secret_manager_certificate_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 fqdns: Sequence[_builtins.str],
                 gcp_secret_manager_certificate_config: 'outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig'):
        """
        :param Sequence[_builtins.str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param 'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs' gcp_secret_manager_certificate_config: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_config", gcp_secret_manager_certificate_config)

    @_builtins.property
    @pulumi.getter
    def fqdns(self) -> Sequence[_builtins.str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @_builtins.property
    @pulumi.getter(name="gcpSecretManagerCertificateConfig")
    def gcp_secret_manager_certificate_config(self) -> 'outputs.ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig':
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_config")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretUri":
            suggest = "secret_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_uri: _builtins.str):
        """
        :param _builtins.str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @_builtins.property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> _builtins.str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigWritableCgroups(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether writable cgroups are enabled.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether writable cgroups are enabled.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"
        elif key == "autoUpgrade":
            suggest = "auto_upgrade"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[_builtins.bool] = None,
                 auto_upgrade: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool auto_repair: Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
               
               This block also contains several computed attributes, documented below.
        :param _builtins.bool auto_upgrade: Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @_builtins.property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[_builtins.bool]:
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.

        This block also contains several computed attributes, documented below.
        """
        return pulumi.get(self, "auto_repair")

    @_builtins.property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[_builtins.bool]:
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        return pulumi.get(self, "auto_upgrade")


@pulumi.output_type
class ClusterNodePoolNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "additionalNodeNetworkConfigs":
            suggest = "additional_node_network_configs"
        elif key == "additionalPodNetworkConfigs":
            suggest = "additional_pod_network_configs"
        elif key == "createPodRange":
            suggest = "create_pod_range"
        elif key == "enablePrivateNodes":
            suggest = "enable_private_nodes"
        elif key == "networkPerformanceConfig":
            suggest = "network_performance_config"
        elif key == "podCidrOverprovisionConfig":
            suggest = "pod_cidr_overprovision_config"
        elif key == "podIpv4CidrBlock":
            suggest = "pod_ipv4_cidr_block"
        elif key == "podRange":
            suggest = "pod_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 additional_node_network_configs: Optional[Sequence['outputs.ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfig']] = None,
                 additional_pod_network_configs: Optional[Sequence['outputs.ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig']] = None,
                 create_pod_range: Optional[_builtins.bool] = None,
                 enable_private_nodes: Optional[_builtins.bool] = None,
                 network_performance_config: Optional['outputs.ClusterNodePoolNetworkConfigNetworkPerformanceConfig'] = None,
                 pod_cidr_overprovision_config: Optional['outputs.ClusterNodePoolNetworkConfigPodCidrOverprovisionConfig'] = None,
                 pod_ipv4_cidr_block: Optional[_builtins.str] = None,
                 pod_range: Optional[_builtins.str] = None,
                 subnetwork: Optional[_builtins.str] = None):
        """
        :param Sequence['ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs'] additional_node_network_configs: We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface
        :param Sequence['ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs'] additional_pod_network_configs: We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node
        :param _builtins.bool create_pod_range: Whether to create a new range for pod IPs in this node pool. Defaults are provided for pod_range and pod_ipv4_cidr_block if they are not specified.
        :param _builtins.bool enable_private_nodes: Whether nodes have internal IP addresses only.
        :param 'ClusterNodePoolNetworkConfigNetworkPerformanceConfigArgs' network_performance_config: Network bandwidth tier configuration.
        :param 'ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs' pod_cidr_overprovision_config: Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited
        :param _builtins.str pod_ipv4_cidr_block: The IP address range for pod IPs in this node pool. Only applicable if create_pod_range is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        :param _builtins.str pod_range: The ID of the secondary range for pod IPs. If create_pod_range is true, this ID is used for the new range. If create_pod_range is false, uses an existing secondary range with this ID.
        :param _builtins.str subnetwork: The name or self_link of the Google Compute Engine
               subnetwork in which the cluster's instances are launched.
        """
        if additional_node_network_configs is not None:
            pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        if additional_pod_network_configs is not None:
            pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        if create_pod_range is not None:
            pulumi.set(__self__, "create_pod_range", create_pod_range)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if network_performance_config is not None:
            pulumi.set(__self__, "network_performance_config", network_performance_config)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if pod_ipv4_cidr_block is not None:
            pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        if pod_range is not None:
            pulumi.set(__self__, "pod_range", pod_range)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @_builtins.property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Optional[Sequence['outputs.ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfig']]:
        """
        We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface
        """
        return pulumi.get(self, "additional_node_network_configs")

    @_builtins.property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Optional[Sequence['outputs.ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig']]:
        """
        We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node
        """
        return pulumi.get(self, "additional_pod_network_configs")

    @_builtins.property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> Optional[_builtins.bool]:
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for pod_range and pod_ipv4_cidr_block if they are not specified.
        """
        return pulumi.get(self, "create_pod_range")

    @_builtins.property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[_builtins.bool]:
        """
        Whether nodes have internal IP addresses only.
        """
        return pulumi.get(self, "enable_private_nodes")

    @_builtins.property
    @pulumi.getter(name="networkPerformanceConfig")
    def network_performance_config(self) -> Optional['outputs.ClusterNodePoolNetworkConfigNetworkPerformanceConfig']:
        """
        Network bandwidth tier configuration.
        """
        return pulumi.get(self, "network_performance_config")

    @_builtins.property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional['outputs.ClusterNodePoolNetworkConfigPodCidrOverprovisionConfig']:
        """
        Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited
        """
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @_builtins.property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> Optional[_builtins.str]:
        """
        The IP address range for pod IPs in this node pool. Only applicable if create_pod_range is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @_builtins.property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> Optional[_builtins.str]:
        """
        The ID of the secondary range for pod IPs. If create_pod_range is true, this ID is used for the new range. If create_pod_range is false, uses an existing secondary range with this ID.
        """
        return pulumi.get(self, "pod_range")

    @_builtins.property
    @pulumi.getter
    def subnetwork(self) -> Optional[_builtins.str]:
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfig(dict):
    def __init__(__self__, *,
                 network: Optional[_builtins.str] = None,
                 subnetwork: Optional[_builtins.str] = None):
        """
        :param _builtins.str network: The name or self_link of the Google Compute Engine
               network to which the cluster is connected. For Shared VPC, set this to the self link of the
               shared network.
        :param _builtins.str subnetwork: The name or self_link of the Google Compute Engine
               subnetwork in which the cluster's instances are launched.
        """
        if network is not None:
            pulumi.set(__self__, "network", network)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @_builtins.property
    @pulumi.getter
    def network(self) -> Optional[_builtins.str]:
        """
        The name or self_link of the Google Compute Engine
        network to which the cluster is connected. For Shared VPC, set this to the self link of the
        shared network.
        """
        return pulumi.get(self, "network")

    @_builtins.property
    @pulumi.getter
    def subnetwork(self) -> Optional[_builtins.str]:
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxPodsPerNode":
            suggest = "max_pods_per_node"
        elif key == "secondaryPodRange":
            suggest = "secondary_pod_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNetworkConfigAdditionalPodNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_pods_per_node: Optional[_builtins.int] = None,
                 secondary_pod_range: Optional[_builtins.str] = None,
                 subnetwork: Optional[_builtins.str] = None):
        """
        :param _builtins.int max_pods_per_node: The maximum number of pods per node which use this pod network.
        :param _builtins.str secondary_pod_range: The name of the secondary range on the subnet which provides IP address for this pod range.
        :param _builtins.str subnetwork: The name or self_link of the Google Compute Engine
               subnetwork in which the cluster's instances are launched.
        """
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if secondary_pod_range is not None:
            pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @_builtins.property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[_builtins.int]:
        """
        The maximum number of pods per node which use this pod network.
        """
        return pulumi.get(self, "max_pods_per_node")

    @_builtins.property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> Optional[_builtins.str]:
        """
        The name of the secondary range on the subnet which provides IP address for this pod range.
        """
        return pulumi.get(self, "secondary_pod_range")

    @_builtins.property
    @pulumi.getter
    def subnetwork(self) -> Optional[_builtins.str]:
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class ClusterNodePoolNetworkConfigNetworkPerformanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "totalEgressBandwidthTier":
            suggest = "total_egress_bandwidth_tier"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNetworkConfigNetworkPerformanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNetworkConfigNetworkPerformanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNetworkConfigNetworkPerformanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 total_egress_bandwidth_tier: _builtins.str):
        """
        :param _builtins.str total_egress_bandwidth_tier: Specifies the total network bandwidth tier for NodePools in the cluster.
        """
        pulumi.set(__self__, "total_egress_bandwidth_tier", total_egress_bandwidth_tier)

    @_builtins.property
    @pulumi.getter(name="totalEgressBandwidthTier")
    def total_egress_bandwidth_tier(self) -> _builtins.str:
        """
        Specifies the total network bandwidth tier for NodePools in the cluster.
        """
        return pulumi.get(self, "total_egress_bandwidth_tier")


@pulumi.output_type
class ClusterNodePoolNetworkConfigPodCidrOverprovisionConfig(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        """
        :param _builtins.bool disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class ClusterNodePoolNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "advancedMachineFeatures":
            suggest = "advanced_machine_features"
        elif key == "bootDisk":
            suggest = "boot_disk"
        elif key == "bootDiskKmsKey":
            suggest = "boot_disk_kms_key"
        elif key == "confidentialNodes":
            suggest = "confidential_nodes"
        elif key == "containerdConfig":
            suggest = "containerd_config"
        elif key == "diskSizeGb":
            suggest = "disk_size_gb"
        elif key == "diskType":
            suggest = "disk_type"
        elif key == "effectiveTaints":
            suggest = "effective_taints"
        elif key == "enableConfidentialStorage":
            suggest = "enable_confidential_storage"
        elif key == "ephemeralStorageConfig":
            suggest = "ephemeral_storage_config"
        elif key == "ephemeralStorageLocalSsdConfig":
            suggest = "ephemeral_storage_local_ssd_config"
        elif key == "fastSocket":
            suggest = "fast_socket"
        elif key == "flexStart":
            suggest = "flex_start"
        elif key == "gcfsConfig":
            suggest = "gcfs_config"
        elif key == "guestAccelerators":
            suggest = "guest_accelerators"
        elif key == "hostMaintenancePolicy":
            suggest = "host_maintenance_policy"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "kubeletConfig":
            suggest = "kubelet_config"
        elif key == "linuxNodeConfig":
            suggest = "linux_node_config"
        elif key == "localNvmeSsdBlockConfig":
            suggest = "local_nvme_ssd_block_config"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "localSsdEncryptionMode":
            suggest = "local_ssd_encryption_mode"
        elif key == "loggingVariant":
            suggest = "logging_variant"
        elif key == "machineType":
            suggest = "machine_type"
        elif key == "maxRunDuration":
            suggest = "max_run_duration"
        elif key == "minCpuPlatform":
            suggest = "min_cpu_platform"
        elif key == "nodeGroup":
            suggest = "node_group"
        elif key == "oauthScopes":
            suggest = "oauth_scopes"
        elif key == "reservationAffinity":
            suggest = "reservation_affinity"
        elif key == "resourceLabels":
            suggest = "resource_labels"
        elif key == "resourceManagerTags":
            suggest = "resource_manager_tags"
        elif key == "sandboxConfig":
            suggest = "sandbox_config"
        elif key == "secondaryBootDisks":
            suggest = "secondary_boot_disks"
        elif key == "serviceAccount":
            suggest = "service_account"
        elif key == "shieldedInstanceConfig":
            suggest = "shielded_instance_config"
        elif key == "soleTenantConfig":
            suggest = "sole_tenant_config"
        elif key == "storagePools":
            suggest = "storage_pools"
        elif key == "windowsNodeConfig":
            suggest = "windows_node_config"
        elif key == "workloadMetadataConfig":
            suggest = "workload_metadata_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 advanced_machine_features: Optional['outputs.ClusterNodePoolNodeConfigAdvancedMachineFeatures'] = None,
                 boot_disk: Optional['outputs.ClusterNodePoolNodeConfigBootDisk'] = None,
                 boot_disk_kms_key: Optional[_builtins.str] = None,
                 confidential_nodes: Optional['outputs.ClusterNodePoolNodeConfigConfidentialNodes'] = None,
                 containerd_config: Optional['outputs.ClusterNodePoolNodeConfigContainerdConfig'] = None,
                 disk_size_gb: Optional[_builtins.int] = None,
                 disk_type: Optional[_builtins.str] = None,
                 effective_taints: Optional[Sequence['outputs.ClusterNodePoolNodeConfigEffectiveTaint']] = None,
                 enable_confidential_storage: Optional[_builtins.bool] = None,
                 ephemeral_storage_config: Optional['outputs.ClusterNodePoolNodeConfigEphemeralStorageConfig'] = None,
                 ephemeral_storage_local_ssd_config: Optional['outputs.ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig'] = None,
                 fast_socket: Optional['outputs.ClusterNodePoolNodeConfigFastSocket'] = None,
                 flex_start: Optional[_builtins.bool] = None,
                 gcfs_config: Optional['outputs.ClusterNodePoolNodeConfigGcfsConfig'] = None,
                 guest_accelerators: Optional[Sequence['outputs.ClusterNodePoolNodeConfigGuestAccelerator']] = None,
                 gvnic: Optional['outputs.ClusterNodePoolNodeConfigGvnic'] = None,
                 host_maintenance_policy: Optional['outputs.ClusterNodePoolNodeConfigHostMaintenancePolicy'] = None,
                 image_type: Optional[_builtins.str] = None,
                 kubelet_config: Optional['outputs.ClusterNodePoolNodeConfigKubeletConfig'] = None,
                 labels: Optional[Mapping[str, _builtins.str]] = None,
                 linux_node_config: Optional['outputs.ClusterNodePoolNodeConfigLinuxNodeConfig'] = None,
                 local_nvme_ssd_block_config: Optional['outputs.ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig'] = None,
                 local_ssd_count: Optional[_builtins.int] = None,
                 local_ssd_encryption_mode: Optional[_builtins.str] = None,
                 logging_variant: Optional[_builtins.str] = None,
                 machine_type: Optional[_builtins.str] = None,
                 max_run_duration: Optional[_builtins.str] = None,
                 metadata: Optional[Mapping[str, _builtins.str]] = None,
                 min_cpu_platform: Optional[_builtins.str] = None,
                 node_group: Optional[_builtins.str] = None,
                 oauth_scopes: Optional[Sequence[_builtins.str]] = None,
                 preemptible: Optional[_builtins.bool] = None,
                 reservation_affinity: Optional['outputs.ClusterNodePoolNodeConfigReservationAffinity'] = None,
                 resource_labels: Optional[Mapping[str, _builtins.str]] = None,
                 resource_manager_tags: Optional[Mapping[str, _builtins.str]] = None,
                 sandbox_config: Optional['outputs.ClusterNodePoolNodeConfigSandboxConfig'] = None,
                 secondary_boot_disks: Optional[Sequence['outputs.ClusterNodePoolNodeConfigSecondaryBootDisk']] = None,
                 service_account: Optional[_builtins.str] = None,
                 shielded_instance_config: Optional['outputs.ClusterNodePoolNodeConfigShieldedInstanceConfig'] = None,
                 sole_tenant_config: Optional['outputs.ClusterNodePoolNodeConfigSoleTenantConfig'] = None,
                 spot: Optional[_builtins.bool] = None,
                 storage_pools: Optional[Sequence[_builtins.str]] = None,
                 tags: Optional[Sequence[_builtins.str]] = None,
                 taints: Optional[Sequence['outputs.ClusterNodePoolNodeConfigTaint']] = None,
                 windows_node_config: Optional['outputs.ClusterNodePoolNodeConfigWindowsNodeConfig'] = None,
                 workload_metadata_config: Optional['outputs.ClusterNodePoolNodeConfigWorkloadMetadataConfig'] = None):
        """
        :param 'ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs' advanced_machine_features: Specifies options for controlling
               advanced machine features. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigBootDiskArgs' boot_disk: Configuration of the node pool boot disk. Structure is documented below
        :param _builtins.str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        :param 'ClusterNodePoolNodeConfigConfidentialNodesArgs' confidential_nodes: Configuration for Confidential Nodes feature. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigContainerdConfigArgs' containerd_config: Parameters to customize containerd runtime. Structure is documented below.
        :param _builtins.int disk_size_gb: Size of the disk attached to each node, specified
               in GB. The smallest allowed disk size is 10GB. Defaults to 100GB. This is being migrated to `boot_disk.size_gb`, and must match if specified in both places.
               Prefer configuring `boot_disk`.
        :param _builtins.str disk_type: Type of the disk attached to each node
               (e.g. 'pd-standard', 'pd-balanced', 'pd-ssd', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`. This is being migrated to `boot_disk.disk_type`, and must match if specified in both places. Prefer configuring `boot_disk`.
        :param Sequence['ClusterNodePoolNodeConfigEffectiveTaintArgs'] effective_taints: List of kubernetes taints applied to each node. Structure is documented above.
        :param _builtins.bool enable_confidential_storage: Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        :param 'ClusterNodePoolNodeConfigEphemeralStorageConfigArgs' ephemeral_storage_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs' ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigFastSocketArgs' fast_socket: Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
               Node Pool must enable gvnic.
               GKE version 1.25.2-gke.1700 or later.
               Structure is documented below.
        :param _builtins.bool flex_start: Enables Flex Start provisioning model for the node pool.
        :param 'ClusterNodePoolNodeConfigGcfsConfigArgs' gcfs_config: Parameters for the Google Container Filesystem (GCFS).
               If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
               For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
               A `machine_type` that has more than 16 GiB of memory is also recommended.
               GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
               Structure is documented below.
        :param Sequence['ClusterNodePoolNodeConfigGuestAcceleratorArgs'] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
               Structure documented below.
        :param 'ClusterNodePoolNodeConfigGvnicArgs' gvnic: Google Virtual NIC (gVNIC) is a virtual network interface.
               Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
               gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
               GKE node version 1.15.11-gke.15 or later
               Structure is documented below.
        :param 'ClusterNodePoolNodeConfigHostMaintenancePolicyArgs' host_maintenance_policy: The maintenance policy for the hosts on which the GKE VMs run on.
        :param _builtins.str image_type: The image type to use for this node. Note that changing the image type
               will delete and recreate all nodes in the node pool.
        :param 'ClusterNodePoolNodeConfigKubeletConfigArgs' kubelet_config: Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Structure is documented below.
               
               ```
               kubelet_config {
               cpu_manager_policy   = "static"
               cpu_cfs_quota        = true
               cpu_cfs_quota_period = "100us"
               pod_pids_limit       = 1024
               }
               ```
        :param Mapping[str, _builtins.str] labels: The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
               reserved by Kubernetes Core components and cannot be specified.
        :param 'ClusterNodePoolNodeConfigLinuxNodeConfigArgs' linux_node_config: Parameters that can be configured on Linux nodes. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs' local_nvme_ssd_block_config: Parameters for the local NVMe SSDs. Structure is documented below.
        :param _builtins.int local_ssd_count: The amount of local SSD disks that will be
               attached to each cluster node. Defaults to 0.
        :param _builtins.str local_ssd_encryption_mode: Possible Local SSD encryption modes:
               Accepted values are:
               * `STANDARD_ENCRYPTION`: The given node will be encrypted using keys managed by Google infrastructure and the keys wll be deleted when the node is deleted.
               * `EPHEMERAL_KEY_ENCRYPTION`: The given node will opt-in for using ephemeral key for encrypting Local SSDs. The Local SSDs will not be able to recover data in case of node crash.
        :param _builtins.str logging_variant: Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        :param _builtins.str machine_type: The name of a Google Compute Engine machine type.
               Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
               [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        :param _builtins.str max_run_duration: The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        :param Mapping[str, _builtins.str] metadata: The metadata key/value pairs assigned to instances in
               the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
               `true` by the API; if `metadata` is set but that default value is not
               included, the provider will attempt to unset the value. To avoid this, set the
               value in your config.
        :param _builtins.str min_cpu_platform: Minimum CPU platform to be used by this instance.
               The instance may be scheduled on the specified or newer CPU platform. Applicable
               values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
               [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
               for more information.
        :param _builtins.str node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        :param Sequence[_builtins.str] oauth_scopes: The set of Google API scopes to be made available
               on all of the node VMs under the "default" service account.
               Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        :param _builtins.bool preemptible: A boolean that represents whether or not the underlying node VMs
               are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
               for more information. Defaults to false.
        :param 'ClusterNodePoolNodeConfigReservationAffinityArgs' reservation_affinity: The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        :param Mapping[str, _builtins.str] resource_labels: The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
               for how these labels are applied to clusters, node pools and nodes.
        :param Mapping[str, _builtins.str] resource_manager_tags: A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        :param 'ClusterNodePoolNodeConfigSandboxConfigArgs' sandbox_config: Sandbox configuration for this node.
        :param Sequence['ClusterNodePoolNodeConfigSecondaryBootDiskArgs'] secondary_boot_disks: Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        :param _builtins.str service_account: The service account to be used by the Node VMs.
               If not specified, the "default" service account is used.
        :param 'ClusterNodePoolNodeConfigShieldedInstanceConfigArgs' shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigSoleTenantConfigArgs' sole_tenant_config: Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). Structure is documented below.
        :param _builtins.bool spot: A boolean that represents whether the underlying node VMs are spot.
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
               for more information. Defaults to false.
        :param Sequence[_builtins.str] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param Sequence[_builtins.str] tags: The list of instance tags applied to all nodes. Tags are used to identify
               valid sources or targets for network firewalls.
        :param Sequence['ClusterNodePoolNodeConfigTaintArgs'] taints: A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
               to apply to nodes. GKE's API can only set this field on cluster creation.
               However, GKE will add taints to your nodes if you enable certain features such
               as GPUs. If this field is set, any diffs on this field will cause the provider to
               recreate the underlying resource. Taint values can be updated safely in
               Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
               this field to manage taints. If you do, `lifecycle.ignore_changes` is
               recommended. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigWindowsNodeConfigArgs' windows_node_config: Windows node configuration, currently supporting OSVersion [attribute](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/NodeConfig#osversion). The value must be one of [OS_VERSION_UNSPECIFIED, OS_VERSION_LTSC2019, OS_VERSION_LTSC2022]. For example:
        :param 'ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs' workload_metadata_config: Metadata configuration to expose to workloads on the node pool.
               Structure is documented below.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk is not None:
            pulumi.set(__self__, "boot_disk", boot_disk)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if containerd_config is not None:
            pulumi.set(__self__, "containerd_config", containerd_config)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if effective_taints is not None:
            pulumi.set(__self__, "effective_taints", effective_taints)
        if enable_confidential_storage is not None:
            pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if flex_start is not None:
            pulumi.set(__self__, "flex_start", flex_start)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if local_ssd_encryption_mode is not None:
            pulumi.set(__self__, "local_ssd_encryption_mode", local_ssd_encryption_mode)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if max_run_duration is not None:
            pulumi.set(__self__, "max_run_duration", max_run_duration)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if resource_manager_tags is not None:
            pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if secondary_boot_disks is not None:
            pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if storage_pools is not None:
            pulumi.set(__self__, "storage_pools", storage_pools)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if windows_node_config is not None:
            pulumi.set(__self__, "windows_node_config", windows_node_config)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @_builtins.property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional['outputs.ClusterNodePoolNodeConfigAdvancedMachineFeatures']:
        """
        Specifies options for controlling
        advanced machine features. Structure is documented below.
        """
        return pulumi.get(self, "advanced_machine_features")

    @_builtins.property
    @pulumi.getter(name="bootDisk")
    def boot_disk(self) -> Optional['outputs.ClusterNodePoolNodeConfigBootDisk']:
        """
        Configuration of the node pool boot disk. Structure is documented below
        """
        return pulumi.get(self, "boot_disk")

    @_builtins.property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[_builtins.str]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @_builtins.property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional['outputs.ClusterNodePoolNodeConfigConfidentialNodes']:
        """
        Configuration for Confidential Nodes feature. Structure is documented below.
        """
        return pulumi.get(self, "confidential_nodes")

    @_builtins.property
    @pulumi.getter(name="containerdConfig")
    def containerd_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigContainerdConfig']:
        """
        Parameters to customize containerd runtime. Structure is documented below.
        """
        return pulumi.get(self, "containerd_config")

    @_builtins.property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[_builtins.int]:
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB. This is being migrated to `boot_disk.size_gb`, and must match if specified in both places.
        Prefer configuring `boot_disk`.
        """
        return pulumi.get(self, "disk_size_gb")

    @_builtins.property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[_builtins.str]:
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced', 'pd-ssd', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`. This is being migrated to `boot_disk.disk_type`, and must match if specified in both places. Prefer configuring `boot_disk`.
        """
        return pulumi.get(self, "disk_type")

    @_builtins.property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Optional[Sequence['outputs.ClusterNodePoolNodeConfigEffectiveTaint']]:
        """
        List of kubernetes taints applied to each node. Structure is documented above.
        """
        return pulumi.get(self, "effective_taints")

    @_builtins.property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> Optional[_builtins.bool]:
        """
        Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @_builtins.property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigEphemeralStorageConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @_builtins.property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @_builtins.property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional['outputs.ClusterNodePoolNodeConfigFastSocket']:
        """
        Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
        Node Pool must enable gvnic.
        GKE version 1.25.2-gke.1700 or later.
        Structure is documented below.
        """
        return pulumi.get(self, "fast_socket")

    @_builtins.property
    @pulumi.getter(name="flexStart")
    def flex_start(self) -> Optional[_builtins.bool]:
        """
        Enables Flex Start provisioning model for the node pool.
        """
        return pulumi.get(self, "flex_start")

    @_builtins.property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigGcfsConfig']:
        """
        Parameters for the Google Container Filesystem (GCFS).
        If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
        For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
        A `machine_type` that has more than 16 GiB of memory is also recommended.
        GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
        Structure is documented below.
        """
        return pulumi.get(self, "gcfs_config")

    @_builtins.property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[Sequence['outputs.ClusterNodePoolNodeConfigGuestAccelerator']]:
        """
        List of the type and count of accelerator cards attached to the instance.
        Structure documented below.
        """
        return pulumi.get(self, "guest_accelerators")

    @_builtins.property
    @pulumi.getter
    def gvnic(self) -> Optional['outputs.ClusterNodePoolNodeConfigGvnic']:
        """
        Google Virtual NIC (gVNIC) is a virtual network interface.
        Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
        gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
        GKE node version 1.15.11-gke.15 or later
        Structure is documented below.
        """
        return pulumi.get(self, "gvnic")

    @_builtins.property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional['outputs.ClusterNodePoolNodeConfigHostMaintenancePolicy']:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policy")

    @_builtins.property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[_builtins.str]:
        """
        The image type to use for this node. Note that changing the image type
        will delete and recreate all nodes in the node pool.
        """
        return pulumi.get(self, "image_type")

    @_builtins.property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigKubeletConfig']:
        """
        Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Structure is documented below.

        ```
        kubelet_config {
        cpu_manager_policy   = "static"
        cpu_cfs_quota        = true
        cpu_cfs_quota_period = "100us"
        pod_pids_limit       = 1024
        }
        ```
        """
        return pulumi.get(self, "kubelet_config")

    @_builtins.property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
        reserved by Kubernetes Core components and cannot be specified.
        """
        return pulumi.get(self, "labels")

    @_builtins.property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigLinuxNodeConfig']:
        """
        Parameters that can be configured on Linux nodes. Structure is documented below.
        """
        return pulumi.get(self, "linux_node_config")

    @_builtins.property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig']:
        """
        Parameters for the local NVMe SSDs. Structure is documented below.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[_builtins.int]:
        """
        The amount of local SSD disks that will be
        attached to each cluster node. Defaults to 0.
        """
        return pulumi.get(self, "local_ssd_count")

    @_builtins.property
    @pulumi.getter(name="localSsdEncryptionMode")
    def local_ssd_encryption_mode(self) -> Optional[_builtins.str]:
        """
        Possible Local SSD encryption modes:
        Accepted values are:
        * `STANDARD_ENCRYPTION`: The given node will be encrypted using keys managed by Google infrastructure and the keys wll be deleted when the node is deleted.
        * `EPHEMERAL_KEY_ENCRYPTION`: The given node will opt-in for using ephemeral key for encrypting Local SSDs. The Local SSDs will not be able to recover data in case of node crash.
        """
        return pulumi.get(self, "local_ssd_encryption_mode")

    @_builtins.property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[_builtins.str]:
        """
        Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")

    @_builtins.property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[_builtins.str]:
        """
        The name of a Google Compute Engine machine type.
        Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
        [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        """
        return pulumi.get(self, "machine_type")

    @_builtins.property
    @pulumi.getter(name="maxRunDuration")
    def max_run_duration(self) -> Optional[_builtins.str]:
        """
        The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        """
        return pulumi.get(self, "max_run_duration")

    @_builtins.property
    @pulumi.getter
    def metadata(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The metadata key/value pairs assigned to instances in
        the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
        `true` by the API; if `metadata` is set but that default value is not
        included, the provider will attempt to unset the value. To avoid this, set the
        value in your config.
        """
        return pulumi.get(self, "metadata")

    @_builtins.property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[_builtins.str]:
        """
        Minimum CPU platform to be used by this instance.
        The instance may be scheduled on the specified or newer CPU platform. Applicable
        values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
        [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
        for more information.
        """
        return pulumi.get(self, "min_cpu_platform")

    @_builtins.property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[_builtins.str]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        """
        return pulumi.get(self, "node_group")

    @_builtins.property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[Sequence[_builtins.str]]:
        """
        The set of Google API scopes to be made available
        on all of the node VMs under the "default" service account.
        Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        """
        return pulumi.get(self, "oauth_scopes")

    @_builtins.property
    @pulumi.getter
    def preemptible(self) -> Optional[_builtins.bool]:
        """
        A boolean that represents whether or not the underlying node VMs
        are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "preemptible")

    @_builtins.property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional['outputs.ClusterNodePoolNodeConfigReservationAffinity']:
        """
        The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        """
        return pulumi.get(self, "reservation_affinity")

    @_builtins.property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
        for how these labels are applied to clusters, node pools and nodes.
        """
        return pulumi.get(self, "resource_labels")

    @_builtins.property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        return pulumi.get(self, "resource_manager_tags")

    @_builtins.property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigSandboxConfig']:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_config")

    @_builtins.property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Optional[Sequence['outputs.ClusterNodePoolNodeConfigSecondaryBootDisk']]:
        """
        Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @_builtins.property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[_builtins.str]:
        """
        The service account to be used by the Node VMs.
        If not specified, the "default" service account is used.
        """
        return pulumi.get(self, "service_account")

    @_builtins.property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigShieldedInstanceConfig']:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @_builtins.property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigSoleTenantConfig']:
        """
        Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). Structure is documented below.
        """
        return pulumi.get(self, "sole_tenant_config")

    @_builtins.property
    @pulumi.getter
    def spot(self) -> Optional[_builtins.bool]:
        """
        A boolean that represents whether the underlying node VMs are spot.
        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "spot")

    @_builtins.property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Optional[Sequence[_builtins.str]]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Optional[Sequence[_builtins.str]]:
        """
        The list of instance tags applied to all nodes. Tags are used to identify
        valid sources or targets for network firewalls.
        """
        return pulumi.get(self, "tags")

    @_builtins.property
    @pulumi.getter
    def taints(self) -> Optional[Sequence['outputs.ClusterNodePoolNodeConfigTaint']]:
        """
        A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
        to apply to nodes. GKE's API can only set this field on cluster creation.
        However, GKE will add taints to your nodes if you enable certain features such
        as GPUs. If this field is set, any diffs on this field will cause the provider to
        recreate the underlying resource. Taint values can be updated safely in
        Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
        this field to manage taints. If you do, `lifecycle.ignore_changes` is
        recommended. Structure is documented below.
        """
        return pulumi.get(self, "taints")

    @_builtins.property
    @pulumi.getter(name="windowsNodeConfig")
    def windows_node_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigWindowsNodeConfig']:
        """
        Windows node configuration, currently supporting OSVersion [attribute](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/NodeConfig#osversion). The value must be one of [OS_VERSION_UNSPECIFIED, OS_VERSION_LTSC2019, OS_VERSION_LTSC2022]. For example:
        """
        return pulumi.get(self, "windows_node_config")

    @_builtins.property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigWorkloadMetadataConfig']:
        """
        Metadata configuration to expose to workloads on the node pool.
        Structure is documented below.
        """
        return pulumi.get(self, "workload_metadata_config")


@pulumi.output_type
class ClusterNodePoolNodeConfigAdvancedMachineFeatures(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "threadsPerCore":
            suggest = "threads_per_core"
        elif key == "enableNestedVirtualization":
            suggest = "enable_nested_virtualization"
        elif key == "performanceMonitoringUnit":
            suggest = "performance_monitoring_unit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigAdvancedMachineFeatures. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 threads_per_core: _builtins.int,
                 enable_nested_virtualization: Optional[_builtins.bool] = None,
                 performance_monitoring_unit: Optional[_builtins.str] = None):
        """
        :param _builtins.int threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        :param _builtins.bool enable_nested_virtualization: Defines whether the instance should have nested virtualization enabled. Defaults to false.
        :param _builtins.str performance_monitoring_unit: Defines the performance monitoring unit [PMU](https://cloud.google.com/compute/docs/pmu-overview) level. Valid values are `ARCHITECTURAL`, `STANDARD`, or `ENHANCED`. Defaults to off.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)
        if enable_nested_virtualization is not None:
            pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)
        if performance_monitoring_unit is not None:
            pulumi.set(__self__, "performance_monitoring_unit", performance_monitoring_unit)

    @_builtins.property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> _builtins.int:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")

    @_builtins.property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> Optional[_builtins.bool]:
        """
        Defines whether the instance should have nested virtualization enabled. Defaults to false.
        """
        return pulumi.get(self, "enable_nested_virtualization")

    @_builtins.property
    @pulumi.getter(name="performanceMonitoringUnit")
    def performance_monitoring_unit(self) -> Optional[_builtins.str]:
        """
        Defines the performance monitoring unit [PMU](https://cloud.google.com/compute/docs/pmu-overview) level. Valid values are `ARCHITECTURAL`, `STANDARD`, or `ENHANCED`. Defaults to off.
        """
        return pulumi.get(self, "performance_monitoring_unit")


@pulumi.output_type
class ClusterNodePoolNodeConfigBootDisk(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "diskType":
            suggest = "disk_type"
        elif key == "provisionedIops":
            suggest = "provisioned_iops"
        elif key == "provisionedThroughput":
            suggest = "provisioned_throughput"
        elif key == "sizeGb":
            suggest = "size_gb"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigBootDisk. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigBootDisk.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigBootDisk.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disk_type: Optional[_builtins.str] = None,
                 provisioned_iops: Optional[_builtins.int] = None,
                 provisioned_throughput: Optional[_builtins.int] = None,
                 size_gb: Optional[_builtins.int] = None):
        """
        :param _builtins.str disk_type: Type of the disk attached to each node
               (e.g. 'pd-standard', 'pd-balanced', 'pd-ssd', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`. This is being migrated from `node_config.disk_type`, and must match if specified in both places. Prefer using this field.
        :param _builtins.int provisioned_iops: Configure disk IOPs. This is only valid if the `disk_type` is 'hyperdisk-balanced'. See [performance limit documention](https://cloud.google.com/compute/docs/disks/hyperdisk-perf-limits) for more information about valid values.
        :param _builtins.int provisioned_throughput: Configure disk throughput. This is only valid if the `disk_type` is 'hyperdisk-balanced'. See [performance limit documention](https://cloud.google.com/compute/docs/disks/hyperdisk-perf-limits) for more information about valid values.
        :param _builtins.int size_gb: Size of the disk attached to each node, specified
               in GB. The smallest allowed disk size is 10GB. Defaults to 100GB. This is being migrated from `node_config.disk_size_gb`, and must match if specified in both places. Prefer using this field.
        """
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if provisioned_iops is not None:
            pulumi.set(__self__, "provisioned_iops", provisioned_iops)
        if provisioned_throughput is not None:
            pulumi.set(__self__, "provisioned_throughput", provisioned_throughput)
        if size_gb is not None:
            pulumi.set(__self__, "size_gb", size_gb)

    @_builtins.property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[_builtins.str]:
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced', 'pd-ssd', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`. This is being migrated from `node_config.disk_type`, and must match if specified in both places. Prefer using this field.
        """
        return pulumi.get(self, "disk_type")

    @_builtins.property
    @pulumi.getter(name="provisionedIops")
    def provisioned_iops(self) -> Optional[_builtins.int]:
        """
        Configure disk IOPs. This is only valid if the `disk_type` is 'hyperdisk-balanced'. See [performance limit documention](https://cloud.google.com/compute/docs/disks/hyperdisk-perf-limits) for more information about valid values.
        """
        return pulumi.get(self, "provisioned_iops")

    @_builtins.property
    @pulumi.getter(name="provisionedThroughput")
    def provisioned_throughput(self) -> Optional[_builtins.int]:
        """
        Configure disk throughput. This is only valid if the `disk_type` is 'hyperdisk-balanced'. See [performance limit documention](https://cloud.google.com/compute/docs/disks/hyperdisk-perf-limits) for more information about valid values.
        """
        return pulumi.get(self, "provisioned_throughput")

    @_builtins.property
    @pulumi.getter(name="sizeGb")
    def size_gb(self) -> Optional[_builtins.int]:
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB. This is being migrated from `node_config.disk_size_gb`, and must match if specified in both places. Prefer using this field.
        """
        return pulumi.get(self, "size_gb")


@pulumi.output_type
class ClusterNodePoolNodeConfigConfidentialNodes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "confidentialInstanceType":
            suggest = "confidential_instance_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigConfidentialNodes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigConfidentialNodes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigConfidentialNodes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 confidential_instance_type: Optional[_builtins.str] = None):
        """
        :param _builtins.bool enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        :param _builtins.str confidential_instance_type: Defines the type of technology used
               by the confidential node.
        """
        pulumi.set(__self__, "enabled", enabled)
        if confidential_instance_type is not None:
            pulumi.set(__self__, "confidential_instance_type", confidential_instance_type)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="confidentialInstanceType")
    def confidential_instance_type(self) -> Optional[_builtins.str]:
        """
        Defines the type of technology used
        by the confidential node.
        """
        return pulumi.get(self, "confidential_instance_type")


@pulumi.output_type
class ClusterNodePoolNodeConfigContainerdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateRegistryAccessConfig":
            suggest = "private_registry_access_config"
        elif key == "writableCgroups":
            suggest = "writable_cgroups"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigContainerdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigContainerdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigContainerdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 private_registry_access_config: Optional['outputs.ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig'] = None,
                 writable_cgroups: Optional['outputs.ClusterNodePoolNodeConfigContainerdConfigWritableCgroups'] = None):
        """
        :param 'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs' private_registry_access_config: Configuration for private container registries. There are two fields in this config:
        :param 'ClusterNodePoolNodeConfigContainerdConfigWritableCgroupsArgs' writable_cgroups: Configuration for writable cgroups. This allows containers to have a writable `/sys/fs/cgroup` directory, which is required for some workloads to create their own sub-cgroups. The `writable_cgroups` block supports:
        """
        if private_registry_access_config is not None:
            pulumi.set(__self__, "private_registry_access_config", private_registry_access_config)
        if writable_cgroups is not None:
            pulumi.set(__self__, "writable_cgroups", writable_cgroups)

    @_builtins.property
    @pulumi.getter(name="privateRegistryAccessConfig")
    def private_registry_access_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig']:
        """
        Configuration for private container registries. There are two fields in this config:
        """
        return pulumi.get(self, "private_registry_access_config")

    @_builtins.property
    @pulumi.getter(name="writableCgroups")
    def writable_cgroups(self) -> Optional['outputs.ClusterNodePoolNodeConfigContainerdConfigWritableCgroups']:
        """
        Configuration for writable cgroups. This allows containers to have a writable `/sys/fs/cgroup` directory, which is required for some workloads to create their own sub-cgroups. The `writable_cgroups` block supports:
        """
        return pulumi.get(self, "writable_cgroups")


@pulumi.output_type
class ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "certificateAuthorityDomainConfigs":
            suggest = "certificate_authority_domain_configs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 certificate_authority_domain_configs: Optional[Sequence['outputs.ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']] = None):
        """
        :param _builtins.bool enabled: Enables private registry config. If set to false, all other fields in this object must not be set.
        :param Sequence['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
        pulumi.set(__self__, "enabled", enabled)
        if certificate_authority_domain_configs is not None:
            pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enables private registry config. If set to false, all other fields in this object must not be set.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Optional[Sequence['outputs.ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']]:
        """
        List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
        return pulumi.get(self, "certificate_authority_domain_configs")


@pulumi.output_type
class ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gcpSecretManagerCertificateConfig":
            suggest = "gcp_secret_manager_certificate_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 fqdns: Sequence[_builtins.str],
                 gcp_secret_manager_certificate_config: 'outputs.ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig'):
        """
        :param Sequence[_builtins.str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param 'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs' gcp_secret_manager_certificate_config: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_config", gcp_secret_manager_certificate_config)

    @_builtins.property
    @pulumi.getter
    def fqdns(self) -> Sequence[_builtins.str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @_builtins.property
    @pulumi.getter(name="gcpSecretManagerCertificateConfig")
    def gcp_secret_manager_certificate_config(self) -> 'outputs.ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig':
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_config")


@pulumi.output_type
class ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretUri":
            suggest = "secret_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_uri: _builtins.str):
        """
        :param _builtins.str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @_builtins.property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> _builtins.str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class ClusterNodePoolNodeConfigContainerdConfigWritableCgroups(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether writable cgroups are enabled.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether writable cgroups are enabled.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigEffectiveTaint(dict):
    def __init__(__self__, *,
                 effect: Optional[_builtins.str] = None,
                 key: Optional[_builtins.str] = None,
                 value: Optional[_builtins.str] = None):
        """
        :param _builtins.str effect: Effect for taint.
        :param _builtins.str key: Key for taint.
        :param _builtins.str value: Value for taint.
        """
        if effect is not None:
            pulumi.set(__self__, "effect", effect)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def effect(self) -> Optional[_builtins.str]:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @_builtins.property
    @pulumi.getter
    def key(self) -> Optional[_builtins.str]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def value(self) -> Optional[_builtins.str]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class ClusterNodePoolNodeConfigEphemeralStorageConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigEphemeralStorageConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: _builtins.int):
        """
        :param _builtins.int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "dataCacheCount":
            suggest = "data_cache_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: _builtins.int,
                 data_cache_count: Optional[_builtins.int] = None):
        """
        :param _builtins.int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        :param _builtins.int data_cache_count: Number of raw-block local NVMe SSD disks to be attached to the node utilized for GKE Data Cache. If zero, then GKE Data Cache will not be enabled in the nodes.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if data_cache_count is not None:
            pulumi.set(__self__, "data_cache_count", data_cache_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")

    @_builtins.property
    @pulumi.getter(name="dataCacheCount")
    def data_cache_count(self) -> Optional[_builtins.int]:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node utilized for GKE Data Cache. If zero, then GKE Data Cache will not be enabled in the nodes.
        """
        return pulumi.get(self, "data_cache_count")


@pulumi.output_type
class ClusterNodePoolNodeConfigFastSocket(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not the NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not the NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigGcfsConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigGuestAccelerator(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverInstallationConfig":
            suggest = "gpu_driver_installation_config"
        elif key == "gpuPartitionSize":
            suggest = "gpu_partition_size"
        elif key == "gpuSharingConfig":
            suggest = "gpu_sharing_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigGuestAccelerator. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigGuestAccelerator.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigGuestAccelerator.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 count: _builtins.int,
                 type: _builtins.str,
                 gpu_driver_installation_config: Optional['outputs.ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig'] = None,
                 gpu_partition_size: Optional[_builtins.str] = None,
                 gpu_sharing_config: Optional['outputs.ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig'] = None):
        """
        :param _builtins.int count: The number of the guest accelerator cards exposed to this instance.
        :param _builtins.str type: The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        :param 'ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs' gpu_driver_installation_config: Configuration for auto installation of GPU driver. Structure is documented below.
        :param _builtins.str gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        :param 'ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs' gpu_sharing_config: Configuration for GPU sharing. Structure is documented below.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @_builtins.property
    @pulumi.getter
    def count(self) -> _builtins.int:
        """
        The number of the guest accelerator cards exposed to this instance.
        """
        return pulumi.get(self, "count")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        """
        return pulumi.get(self, "type")

    @_builtins.property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig']:
        """
        Configuration for auto installation of GPU driver. Structure is documented below.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @_builtins.property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[_builtins.str]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        """
        return pulumi.get(self, "gpu_partition_size")

    @_builtins.property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig']:
        """
        Configuration for GPU sharing. Structure is documented below.
        """
        return pulumi.get(self, "gpu_sharing_config")


@pulumi.output_type
class ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverVersion":
            suggest = "gpu_driver_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_driver_version: _builtins.str):
        """
        :param _builtins.str gpu_driver_version: Mode for how the GPU driver is installed.
               Accepted values are:
               * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to install the "Default" GPU driver. Before GKE `1.30.1-gke.1156000`, the default value is to not install any GPU driver.
               * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
               * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
               * `"LATEST"`: "Latest" GPU driver in COS.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @_builtins.property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> _builtins.str:
        """
        Mode for how the GPU driver is installed.
        Accepted values are:
        * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to install the "Default" GPU driver. Before GKE `1.30.1-gke.1156000`, the default value is to not install any GPU driver.
        * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
        * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
        * `"LATEST"`: "Latest" GPU driver in COS.
        """
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuSharingStrategy":
            suggest = "gpu_sharing_strategy"
        elif key == "maxSharedClientsPerGpu":
            suggest = "max_shared_clients_per_gpu"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_sharing_strategy: _builtins.str,
                 max_shared_clients_per_gpu: _builtins.int):
        """
        :param _builtins.str gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node.
               Accepted values are:
               * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
               * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        :param _builtins.int max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @_builtins.property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> _builtins.str:
        """
        The type of GPU sharing strategy to enable on the GPU node.
        Accepted values are:
        * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @_builtins.property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> _builtins.int:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class ClusterNodePoolNodeConfigGvnic(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigHostMaintenancePolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maintenanceInterval":
            suggest = "maintenance_interval"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigHostMaintenancePolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 maintenance_interval: _builtins.str):
        """
        :param _builtins.str maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @_builtins.property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> _builtins.str:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class ClusterNodePoolNodeConfigKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowedUnsafeSysctls":
            suggest = "allowed_unsafe_sysctls"
        elif key == "containerLogMaxFiles":
            suggest = "container_log_max_files"
        elif key == "containerLogMaxSize":
            suggest = "container_log_max_size"
        elif key == "cpuCfsQuota":
            suggest = "cpu_cfs_quota"
        elif key == "cpuCfsQuotaPeriod":
            suggest = "cpu_cfs_quota_period"
        elif key == "cpuManagerPolicy":
            suggest = "cpu_manager_policy"
        elif key == "evictionMaxPodGracePeriodSeconds":
            suggest = "eviction_max_pod_grace_period_seconds"
        elif key == "evictionMinimumReclaim":
            suggest = "eviction_minimum_reclaim"
        elif key == "evictionSoft":
            suggest = "eviction_soft"
        elif key == "evictionSoftGracePeriod":
            suggest = "eviction_soft_grace_period"
        elif key == "imageGcHighThresholdPercent":
            suggest = "image_gc_high_threshold_percent"
        elif key == "imageGcLowThresholdPercent":
            suggest = "image_gc_low_threshold_percent"
        elif key == "imageMaximumGcAge":
            suggest = "image_maximum_gc_age"
        elif key == "imageMinimumGcAge":
            suggest = "image_minimum_gc_age"
        elif key == "insecureKubeletReadonlyPortEnabled":
            suggest = "insecure_kubelet_readonly_port_enabled"
        elif key == "maxParallelImagePulls":
            suggest = "max_parallel_image_pulls"
        elif key == "memoryManager":
            suggest = "memory_manager"
        elif key == "podPidsLimit":
            suggest = "pod_pids_limit"
        elif key == "singleProcessOomKill":
            suggest = "single_process_oom_kill"
        elif key == "topologyManager":
            suggest = "topology_manager"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allowed_unsafe_sysctls: Optional[Sequence[_builtins.str]] = None,
                 container_log_max_files: Optional[_builtins.int] = None,
                 container_log_max_size: Optional[_builtins.str] = None,
                 cpu_cfs_quota: Optional[_builtins.bool] = None,
                 cpu_cfs_quota_period: Optional[_builtins.str] = None,
                 cpu_manager_policy: Optional[_builtins.str] = None,
                 eviction_max_pod_grace_period_seconds: Optional[_builtins.int] = None,
                 eviction_minimum_reclaim: Optional['outputs.ClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaim'] = None,
                 eviction_soft: Optional['outputs.ClusterNodePoolNodeConfigKubeletConfigEvictionSoft'] = None,
                 eviction_soft_grace_period: Optional['outputs.ClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod'] = None,
                 image_gc_high_threshold_percent: Optional[_builtins.int] = None,
                 image_gc_low_threshold_percent: Optional[_builtins.int] = None,
                 image_maximum_gc_age: Optional[_builtins.str] = None,
                 image_minimum_gc_age: Optional[_builtins.str] = None,
                 insecure_kubelet_readonly_port_enabled: Optional[_builtins.str] = None,
                 max_parallel_image_pulls: Optional[_builtins.int] = None,
                 memory_manager: Optional['outputs.ClusterNodePoolNodeConfigKubeletConfigMemoryManager'] = None,
                 pod_pids_limit: Optional[_builtins.int] = None,
                 single_process_oom_kill: Optional[_builtins.bool] = None,
                 topology_manager: Optional['outputs.ClusterNodePoolNodeConfigKubeletConfigTopologyManager'] = None):
        """
        :param Sequence[_builtins.str] allowed_unsafe_sysctls: Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods. The allowed sysctl groups are `kernel.shm*`, `kernel.msg*`, `kernel.sem`, `fs.mqueue.*`, and `net.*`.
        :param _builtins.int container_log_max_files: Defines the maximum number of container log files that can be present for a container. The integer must be between 2 and 10, inclusive.
        :param _builtins.str container_log_max_size: Defines the maximum size of the
               container log file before it is rotated. Specified as a positive number and a
               unit suffix, such as `"100Ki"`, `"10Mi"`. Valid units are "Ki", "Mi", "Gi".
               The value must be between `"10Mi"` and `"500Mi"`, inclusive. And the total container log size
               (`container_log_max_size` * `container_log_max_files`) cannot exceed 1% of the total storage of the node.
        :param _builtins.bool cpu_cfs_quota: If true, enables CPU CFS quota enforcement for
               containers that specify CPU limits.
        :param _builtins.str cpu_cfs_quota_period: The CPU CFS quota period value. Specified
               as a sequence of decimal numbers, each with optional fraction and a unit suffix,
               such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
               "h". The value must be a positive duration.
        :param _builtins.str cpu_manager_policy: The CPU management policy on the node. See
               [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
               One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
               Prior to the 6.4.0 this field was marked as required. The workaround for the required field
               is setting the empty string `""`, which will function identically to not setting this field.
        :param _builtins.int eviction_max_pod_grace_period_seconds: Defines the maximum allowed grace period (in seconds) to use when terminating pods in response to a soft eviction threshold being met. The integer must be positive and not exceed 300.
        :param 'ClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaimArgs' eviction_minimum_reclaim: Defines a map of signal names to percentage that defines minimum reclaims. It describes the minimum amount of a given resource the kubelet will reclaim when performing a pod eviction. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigKubeletConfigEvictionSoftArgs' eviction_soft: Defines a map of signal names to quantities or percentage that defines soft eviction thresholds. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriodArgs' eviction_soft_grace_period: Defines a map of signal names to durations that defines grace periods for soft eviction thresholds. Each soft eviction threshold must have a corresponding grace period. Structure is documented below.
        :param _builtins.int image_gc_high_threshold_percent: Defines the percent of disk usage after which image garbage collection is always run. The integer must be between 10 and 85, inclusive.
        :param _builtins.int image_gc_low_threshold_percent: Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to. The integer must be between 10 and 85, inclusive.
        :param _builtins.str image_maximum_gc_age: Defines the maximum age an image can be unused before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`, and `"2h45m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h". The value must be a positive duration.
        :param _builtins.str image_minimum_gc_age: Defines the minimum age for an unused image before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`. The value cannot be greater than "2m".
        :param _builtins.str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param _builtins.int max_parallel_image_pulls: Set the maximum number of image pulls in parallel. The integer must be between 2 and 5, inclusive.
        :param 'ClusterNodePoolNodeConfigKubeletConfigMemoryManagerArgs' memory_manager: Configuration for the [memory manager](https://kubernetes.io/docs/tasks/administer-cluster/memory-manager/) on the node.
               The memory manager optimizes memory and hugepages allocation for pods, especially
               those in the Guaranteed QoS class, by influencing NUMA affinity. Structure is documented below.
        :param _builtins.int pod_pids_limit: Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        :param _builtins.bool single_process_oom_kill: Defines whether to enable single process OOM killer. If true, the processes in the container will be OOM killed individually instead of as a group.
        :param 'ClusterNodePoolNodeConfigKubeletConfigTopologyManagerArgs' topology_manager: These settings control the kubelet's [Topology Manager policy](https://kubernetes.io/docs/tasks/administer-cluster/topology-manager/#topology-manager-policies), which coordinates the set of components responsible for performance optimizations related to CPU isolation, memory, and device locality. Structure is documented below.
        """
        if allowed_unsafe_sysctls is not None:
            pulumi.set(__self__, "allowed_unsafe_sysctls", allowed_unsafe_sysctls)
        if container_log_max_files is not None:
            pulumi.set(__self__, "container_log_max_files", container_log_max_files)
        if container_log_max_size is not None:
            pulumi.set(__self__, "container_log_max_size", container_log_max_size)
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if cpu_manager_policy is not None:
            pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if eviction_max_pod_grace_period_seconds is not None:
            pulumi.set(__self__, "eviction_max_pod_grace_period_seconds", eviction_max_pod_grace_period_seconds)
        if eviction_minimum_reclaim is not None:
            pulumi.set(__self__, "eviction_minimum_reclaim", eviction_minimum_reclaim)
        if eviction_soft is not None:
            pulumi.set(__self__, "eviction_soft", eviction_soft)
        if eviction_soft_grace_period is not None:
            pulumi.set(__self__, "eviction_soft_grace_period", eviction_soft_grace_period)
        if image_gc_high_threshold_percent is not None:
            pulumi.set(__self__, "image_gc_high_threshold_percent", image_gc_high_threshold_percent)
        if image_gc_low_threshold_percent is not None:
            pulumi.set(__self__, "image_gc_low_threshold_percent", image_gc_low_threshold_percent)
        if image_maximum_gc_age is not None:
            pulumi.set(__self__, "image_maximum_gc_age", image_maximum_gc_age)
        if image_minimum_gc_age is not None:
            pulumi.set(__self__, "image_minimum_gc_age", image_minimum_gc_age)
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        if max_parallel_image_pulls is not None:
            pulumi.set(__self__, "max_parallel_image_pulls", max_parallel_image_pulls)
        if memory_manager is not None:
            pulumi.set(__self__, "memory_manager", memory_manager)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)
        if single_process_oom_kill is not None:
            pulumi.set(__self__, "single_process_oom_kill", single_process_oom_kill)
        if topology_manager is not None:
            pulumi.set(__self__, "topology_manager", topology_manager)

    @_builtins.property
    @pulumi.getter(name="allowedUnsafeSysctls")
    def allowed_unsafe_sysctls(self) -> Optional[Sequence[_builtins.str]]:
        """
        Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods. The allowed sysctl groups are `kernel.shm*`, `kernel.msg*`, `kernel.sem`, `fs.mqueue.*`, and `net.*`.
        """
        return pulumi.get(self, "allowed_unsafe_sysctls")

    @_builtins.property
    @pulumi.getter(name="containerLogMaxFiles")
    def container_log_max_files(self) -> Optional[_builtins.int]:
        """
        Defines the maximum number of container log files that can be present for a container. The integer must be between 2 and 10, inclusive.
        """
        return pulumi.get(self, "container_log_max_files")

    @_builtins.property
    @pulumi.getter(name="containerLogMaxSize")
    def container_log_max_size(self) -> Optional[_builtins.str]:
        """
        Defines the maximum size of the
        container log file before it is rotated. Specified as a positive number and a
        unit suffix, such as `"100Ki"`, `"10Mi"`. Valid units are "Ki", "Mi", "Gi".
        The value must be between `"10Mi"` and `"500Mi"`, inclusive. And the total container log size
        (`container_log_max_size` * `container_log_max_files`) cannot exceed 1% of the total storage of the node.
        """
        return pulumi.get(self, "container_log_max_size")

    @_builtins.property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[_builtins.bool]:
        """
        If true, enables CPU CFS quota enforcement for
        containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @_builtins.property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[_builtins.str]:
        """
        The CPU CFS quota period value. Specified
        as a sequence of decimal numbers, each with optional fraction and a unit suffix,
        such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
        "h". The value must be a positive duration.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @_builtins.property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> Optional[_builtins.str]:
        """
        The CPU management policy on the node. See
        [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
        One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
        Prior to the 6.4.0 this field was marked as required. The workaround for the required field
        is setting the empty string `""`, which will function identically to not setting this field.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @_builtins.property
    @pulumi.getter(name="evictionMaxPodGracePeriodSeconds")
    def eviction_max_pod_grace_period_seconds(self) -> Optional[_builtins.int]:
        """
        Defines the maximum allowed grace period (in seconds) to use when terminating pods in response to a soft eviction threshold being met. The integer must be positive and not exceed 300.
        """
        return pulumi.get(self, "eviction_max_pod_grace_period_seconds")

    @_builtins.property
    @pulumi.getter(name="evictionMinimumReclaim")
    def eviction_minimum_reclaim(self) -> Optional['outputs.ClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaim']:
        """
        Defines a map of signal names to percentage that defines minimum reclaims. It describes the minimum amount of a given resource the kubelet will reclaim when performing a pod eviction. Structure is documented below.
        """
        return pulumi.get(self, "eviction_minimum_reclaim")

    @_builtins.property
    @pulumi.getter(name="evictionSoft")
    def eviction_soft(self) -> Optional['outputs.ClusterNodePoolNodeConfigKubeletConfigEvictionSoft']:
        """
        Defines a map of signal names to quantities or percentage that defines soft eviction thresholds. Structure is documented below.
        """
        return pulumi.get(self, "eviction_soft")

    @_builtins.property
    @pulumi.getter(name="evictionSoftGracePeriod")
    def eviction_soft_grace_period(self) -> Optional['outputs.ClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod']:
        """
        Defines a map of signal names to durations that defines grace periods for soft eviction thresholds. Each soft eviction threshold must have a corresponding grace period. Structure is documented below.
        """
        return pulumi.get(self, "eviction_soft_grace_period")

    @_builtins.property
    @pulumi.getter(name="imageGcHighThresholdPercent")
    def image_gc_high_threshold_percent(self) -> Optional[_builtins.int]:
        """
        Defines the percent of disk usage after which image garbage collection is always run. The integer must be between 10 and 85, inclusive.
        """
        return pulumi.get(self, "image_gc_high_threshold_percent")

    @_builtins.property
    @pulumi.getter(name="imageGcLowThresholdPercent")
    def image_gc_low_threshold_percent(self) -> Optional[_builtins.int]:
        """
        Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to. The integer must be between 10 and 85, inclusive.
        """
        return pulumi.get(self, "image_gc_low_threshold_percent")

    @_builtins.property
    @pulumi.getter(name="imageMaximumGcAge")
    def image_maximum_gc_age(self) -> Optional[_builtins.str]:
        """
        Defines the maximum age an image can be unused before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`, and `"2h45m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h". The value must be a positive duration.
        """
        return pulumi.get(self, "image_maximum_gc_age")

    @_builtins.property
    @pulumi.getter(name="imageMinimumGcAge")
    def image_minimum_gc_age(self) -> Optional[_builtins.str]:
        """
        Defines the minimum age for an unused image before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`. The value cannot be greater than "2m".
        """
        return pulumi.get(self, "image_minimum_gc_age")

    @_builtins.property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[_builtins.str]:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @_builtins.property
    @pulumi.getter(name="maxParallelImagePulls")
    def max_parallel_image_pulls(self) -> Optional[_builtins.int]:
        """
        Set the maximum number of image pulls in parallel. The integer must be between 2 and 5, inclusive.
        """
        return pulumi.get(self, "max_parallel_image_pulls")

    @_builtins.property
    @pulumi.getter(name="memoryManager")
    def memory_manager(self) -> Optional['outputs.ClusterNodePoolNodeConfigKubeletConfigMemoryManager']:
        """
        Configuration for the [memory manager](https://kubernetes.io/docs/tasks/administer-cluster/memory-manager/) on the node.
        The memory manager optimizes memory and hugepages allocation for pods, especially
        those in the Guaranteed QoS class, by influencing NUMA affinity. Structure is documented below.
        """
        return pulumi.get(self, "memory_manager")

    @_builtins.property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[_builtins.int]:
        """
        Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        return pulumi.get(self, "pod_pids_limit")

    @_builtins.property
    @pulumi.getter(name="singleProcessOomKill")
    def single_process_oom_kill(self) -> Optional[_builtins.bool]:
        """
        Defines whether to enable single process OOM killer. If true, the processes in the container will be OOM killed individually instead of as a group.
        """
        return pulumi.get(self, "single_process_oom_kill")

    @_builtins.property
    @pulumi.getter(name="topologyManager")
    def topology_manager(self) -> Optional['outputs.ClusterNodePoolNodeConfigKubeletConfigTopologyManager']:
        """
        These settings control the kubelet's [Topology Manager policy](https://kubernetes.io/docs/tasks/administer-cluster/topology-manager/#topology-manager-policies), which coordinates the set of components responsible for performance optimizations related to CPU isolation, memory, and device locality. Structure is documented below.
        """
        return pulumi.get(self, "topology_manager")


@pulumi.output_type
class ClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaim(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "imagefsAvailable":
            suggest = "imagefs_available"
        elif key == "imagefsInodesFree":
            suggest = "imagefs_inodes_free"
        elif key == "memoryAvailable":
            suggest = "memory_available"
        elif key == "nodefsAvailable":
            suggest = "nodefs_available"
        elif key == "nodefsInodesFree":
            suggest = "nodefs_inodes_free"
        elif key == "pidAvailable":
            suggest = "pid_available"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaim. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaim.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaim.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 imagefs_available: Optional[_builtins.str] = None,
                 imagefs_inodes_free: Optional[_builtins.str] = None,
                 memory_available: Optional[_builtins.str] = None,
                 nodefs_available: Optional[_builtins.str] = None,
                 nodefs_inodes_free: Optional[_builtins.str] = None,
                 pid_available: Optional[_builtins.str] = None):
        """
        :param _builtins.str imagefs_available: Defines percentage of minimum reclaim for imagefs.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        :param _builtins.str imagefs_inodes_free: Defines percentage of minimum reclaim for imagefs.inodesFree. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        :param _builtins.str memory_available: Defines percentage of minimum reclaim for memory.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        :param _builtins.str nodefs_available: Defines percentage of minimum reclaim for nodefs.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        :param _builtins.str nodefs_inodes_free: Defines percentage of minimum reclaim for nodefs.inodesFree. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        :param _builtins.str pid_available: Defines percentage of minimum reclaim for pid.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        if imagefs_available is not None:
            pulumi.set(__self__, "imagefs_available", imagefs_available)
        if imagefs_inodes_free is not None:
            pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        if memory_available is not None:
            pulumi.set(__self__, "memory_available", memory_available)
        if nodefs_available is not None:
            pulumi.set(__self__, "nodefs_available", nodefs_available)
        if nodefs_inodes_free is not None:
            pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        if pid_available is not None:
            pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for imagefs.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for imagefs.inodesFree. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for memory.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for nodefs.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for nodefs.inodesFree. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for pid.available. The value must be a percentage no more than `"10%"`, such as `"5%"`.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class ClusterNodePoolNodeConfigKubeletConfigEvictionSoft(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "imagefsAvailable":
            suggest = "imagefs_available"
        elif key == "imagefsInodesFree":
            suggest = "imagefs_inodes_free"
        elif key == "memoryAvailable":
            suggest = "memory_available"
        elif key == "nodefsAvailable":
            suggest = "nodefs_available"
        elif key == "nodefsInodesFree":
            suggest = "nodefs_inodes_free"
        elif key == "pidAvailable":
            suggest = "pid_available"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigKubeletConfigEvictionSoft. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigKubeletConfigEvictionSoft.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigKubeletConfigEvictionSoft.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 imagefs_available: Optional[_builtins.str] = None,
                 imagefs_inodes_free: Optional[_builtins.str] = None,
                 memory_available: Optional[_builtins.str] = None,
                 nodefs_available: Optional[_builtins.str] = None,
                 nodefs_inodes_free: Optional[_builtins.str] = None,
                 pid_available: Optional[_builtins.str] = None):
        """
        :param _builtins.str imagefs_available: Defines percentage of soft eviction threshold for imagefs.available. The value must be a percentage between `15%` and `50%`, such as `"20%"`.
        :param _builtins.str imagefs_inodes_free: Defines percentage of soft eviction threshold for imagefs.inodesFree. The value must be a percentage between `5%` and `50%`, such as `"20%"`.
        :param _builtins.str memory_available: Defines quantity of soft eviction threshold for memory.available. The value must be a quantity, such as `"100Mi"`. The value must be greater than or equal to the GKE default hard eviction threshold of `"100Mi"` and less than 50% of machine memory.
        :param _builtins.str nodefs_available: Defines percentage of soft eviction threshold for nodefs.available. The value must be a percentage between `10%` and `50%`, such as `"20%"`.
        :param _builtins.str nodefs_inodes_free: Defines percentage of soft eviction threshold for nodefs.inodesFree. The value must be a percentage between `5%` and `50%`, such as `"20%"`.
        :param _builtins.str pid_available: Defines percentage of soft eviction threshold for pid.available. The value must be a percentage between `10%` and `50%`, such as `"20%"`.
        """
        if imagefs_available is not None:
            pulumi.set(__self__, "imagefs_available", imagefs_available)
        if imagefs_inodes_free is not None:
            pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        if memory_available is not None:
            pulumi.set(__self__, "memory_available", memory_available)
        if nodefs_available is not None:
            pulumi.set(__self__, "nodefs_available", nodefs_available)
        if nodefs_inodes_free is not None:
            pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        if pid_available is not None:
            pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for imagefs.available. The value must be a percentage between `15%` and `50%`, such as `"20%"`.
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for imagefs.inodesFree. The value must be a percentage between `5%` and `50%`, such as `"20%"`.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> Optional[_builtins.str]:
        """
        Defines quantity of soft eviction threshold for memory.available. The value must be a quantity, such as `"100Mi"`. The value must be greater than or equal to the GKE default hard eviction threshold of `"100Mi"` and less than 50% of machine memory.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for nodefs.available. The value must be a percentage between `10%` and `50%`, such as `"20%"`.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for nodefs.inodesFree. The value must be a percentage between `5%` and `50%`, such as `"20%"`.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for pid.available. The value must be a percentage between `10%` and `50%`, such as `"20%"`.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class ClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "imagefsAvailable":
            suggest = "imagefs_available"
        elif key == "imagefsInodesFree":
            suggest = "imagefs_inodes_free"
        elif key == "memoryAvailable":
            suggest = "memory_available"
        elif key == "nodefsAvailable":
            suggest = "nodefs_available"
        elif key == "nodefsInodesFree":
            suggest = "nodefs_inodes_free"
        elif key == "pidAvailable":
            suggest = "pid_available"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 imagefs_available: Optional[_builtins.str] = None,
                 imagefs_inodes_free: Optional[_builtins.str] = None,
                 memory_available: Optional[_builtins.str] = None,
                 nodefs_available: Optional[_builtins.str] = None,
                 nodefs_inodes_free: Optional[_builtins.str] = None,
                 pid_available: Optional[_builtins.str] = None):
        """
        :param _builtins.str imagefs_available: Defines grace period for the imagefs.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        :param _builtins.str imagefs_inodes_free: Defines grace period for the imagefs.inodesFree soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        :param _builtins.str memory_available: Defines grace period for the memory.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`, such as `"30s"`, `"1m30s"`, `"2.5m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h".
        :param _builtins.str nodefs_available: Defines grace period for the nodefs.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        :param _builtins.str nodefs_inodes_free: Defines grace period for the nodefs.inodesFree soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        :param _builtins.str pid_available: Defines grace period for the pid.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        """
        if imagefs_available is not None:
            pulumi.set(__self__, "imagefs_available", imagefs_available)
        if imagefs_inodes_free is not None:
            pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        if memory_available is not None:
            pulumi.set(__self__, "memory_available", memory_available)
        if nodefs_available is not None:
            pulumi.set(__self__, "nodefs_available", nodefs_available)
        if nodefs_inodes_free is not None:
            pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        if pid_available is not None:
            pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the imagefs.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the imagefs.inodesFree soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the memory.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`, such as `"30s"`, `"1m30s"`, `"2.5m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h".
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the nodefs.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the nodefs.inodesFree soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the pid.available soft eviction threshold. The value must be a positive duration string no more than `"5m"`.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class ClusterNodePoolNodeConfigKubeletConfigMemoryManager(dict):
    def __init__(__self__, *,
                 policy: Optional[_builtins.str] = None):
        """
        :param _builtins.str policy: The [Memory
               Manager](https://kubernetes.io/docs/tasks/administer-cluster/memory-manager/)
               policy can be set to None (default) or Static. This policy dictates how memory alignment is handled on the node.  If unset (or set to the empty string `""`), the API will treat the field as if set to "None".
        """
        if policy is not None:
            pulumi.set(__self__, "policy", policy)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> Optional[_builtins.str]:
        """
        The [Memory
        Manager](https://kubernetes.io/docs/tasks/administer-cluster/memory-manager/)
        policy can be set to None (default) or Static. This policy dictates how memory alignment is handled on the node.  If unset (or set to the empty string `""`), the API will treat the field as if set to "None".
        """
        return pulumi.get(self, "policy")


@pulumi.output_type
class ClusterNodePoolNodeConfigKubeletConfigTopologyManager(dict):
    def __init__(__self__, *,
                 policy: Optional[_builtins.str] = None,
                 scope: Optional[_builtins.str] = None):
        """
        :param _builtins.str policy: The Topology Manager policy controls resource alignment on the node and can be set to one of the following: none (default), best-effort, restricted, or single-numa-node.  If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
        :param _builtins.str scope: The Topology Manager scope, defining the granularity at which
               policy decisions are applied. Valid values are "container" (resources are aligned
               per container within a pod which is set by default) or "pod" (resources are aligned for the entire pod).  If unset (or set to the empty string `""`), the API will treat the field as if set to "container".
        """
        if policy is not None:
            pulumi.set(__self__, "policy", policy)
        if scope is not None:
            pulumi.set(__self__, "scope", scope)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> Optional[_builtins.str]:
        """
        The Topology Manager policy controls resource alignment on the node and can be set to one of the following: none (default), best-effort, restricted, or single-numa-node.  If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
        """
        return pulumi.get(self, "policy")

    @_builtins.property
    @pulumi.getter
    def scope(self) -> Optional[_builtins.str]:
        """
        The Topology Manager scope, defining the granularity at which
        policy decisions are applied. Valid values are "container" (resources are aligned
        per container within a pod which is set by default) or "pod" (resources are aligned for the entire pod).  If unset (or set to the empty string `""`), the API will treat the field as if set to "container".
        """
        return pulumi.get(self, "scope")


@pulumi.output_type
class ClusterNodePoolNodeConfigLinuxNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cgroupMode":
            suggest = "cgroup_mode"
        elif key == "hugepagesConfig":
            suggest = "hugepages_config"
        elif key == "nodeKernelModuleLoading":
            suggest = "node_kernel_module_loading"
        elif key == "transparentHugepageDefrag":
            suggest = "transparent_hugepage_defrag"
        elif key == "transparentHugepageEnabled":
            suggest = "transparent_hugepage_enabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigLinuxNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigLinuxNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigLinuxNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cgroup_mode: Optional[_builtins.str] = None,
                 hugepages_config: Optional['outputs.ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig'] = None,
                 node_kernel_module_loading: Optional['outputs.ClusterNodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoading'] = None,
                 sysctls: Optional[Mapping[str, _builtins.str]] = None,
                 transparent_hugepage_defrag: Optional[_builtins.str] = None,
                 transparent_hugepage_enabled: Optional[_builtins.str] = None):
        """
        :param _builtins.str cgroup_mode: Possible cgroup modes that can be used.
               Accepted values are:
               * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
               * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
               * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        :param 'ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs' hugepages_config: Amounts for 2M and 1G hugepages. Structure is documented below.
        :param 'ClusterNodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoadingArgs' node_kernel_module_loading: The settings for kernel module loading.
        :param Mapping[str, _builtins.str] sysctls: The Linux kernel parameters to be applied to the nodes
               and all pods running on the nodes. Specified as a map from the key, such as
               `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Note that validations happen all server side. All attributes are optional.
        :param _builtins.str transparent_hugepage_defrag: The Linux kernel transparent hugepage defrag setting.
        :param _builtins.str transparent_hugepage_enabled: The Linux kernel transparent hugepage setting.
        """
        if cgroup_mode is not None:
            pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        if hugepages_config is not None:
            pulumi.set(__self__, "hugepages_config", hugepages_config)
        if node_kernel_module_loading is not None:
            pulumi.set(__self__, "node_kernel_module_loading", node_kernel_module_loading)
        if sysctls is not None:
            pulumi.set(__self__, "sysctls", sysctls)
        if transparent_hugepage_defrag is not None:
            pulumi.set(__self__, "transparent_hugepage_defrag", transparent_hugepage_defrag)
        if transparent_hugepage_enabled is not None:
            pulumi.set(__self__, "transparent_hugepage_enabled", transparent_hugepage_enabled)

    @_builtins.property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> Optional[_builtins.str]:
        """
        Possible cgroup modes that can be used.
        Accepted values are:
        * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
        * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
        * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        """
        return pulumi.get(self, "cgroup_mode")

    @_builtins.property
    @pulumi.getter(name="hugepagesConfig")
    def hugepages_config(self) -> Optional['outputs.ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig']:
        """
        Amounts for 2M and 1G hugepages. Structure is documented below.
        """
        return pulumi.get(self, "hugepages_config")

    @_builtins.property
    @pulumi.getter(name="nodeKernelModuleLoading")
    def node_kernel_module_loading(self) -> Optional['outputs.ClusterNodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoading']:
        """
        The settings for kernel module loading.
        """
        return pulumi.get(self, "node_kernel_module_loading")

    @_builtins.property
    @pulumi.getter
    def sysctls(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The Linux kernel parameters to be applied to the nodes
        and all pods running on the nodes. Specified as a map from the key, such as
        `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Note that validations happen all server side. All attributes are optional.
        """
        return pulumi.get(self, "sysctls")

    @_builtins.property
    @pulumi.getter(name="transparentHugepageDefrag")
    def transparent_hugepage_defrag(self) -> Optional[_builtins.str]:
        """
        The Linux kernel transparent hugepage defrag setting.
        """
        return pulumi.get(self, "transparent_hugepage_defrag")

    @_builtins.property
    @pulumi.getter(name="transparentHugepageEnabled")
    def transparent_hugepage_enabled(self) -> Optional[_builtins.str]:
        """
        The Linux kernel transparent hugepage setting.
        """
        return pulumi.get(self, "transparent_hugepage_enabled")


@pulumi.output_type
class ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "hugepageSize1g":
            suggest = "hugepage_size1g"
        elif key == "hugepageSize2m":
            suggest = "hugepage_size2m"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 hugepage_size1g: Optional[_builtins.int] = None,
                 hugepage_size2m: Optional[_builtins.int] = None):
        """
        :param _builtins.int hugepage_size1g: Amount of 1G hugepages.
        :param _builtins.int hugepage_size2m: Amount of 2M hugepages.
        """
        if hugepage_size1g is not None:
            pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        if hugepage_size2m is not None:
            pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @_builtins.property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> Optional[_builtins.int]:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @_builtins.property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> Optional[_builtins.int]:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")


@pulumi.output_type
class ClusterNodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoading(dict):
    def __init__(__self__, *,
                 policy: Optional[_builtins.str] = None):
        """
        :param _builtins.str policy: The policy for kernel module loading.
        """
        if policy is not None:
            pulumi.set(__self__, "policy", policy)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> Optional[_builtins.str]:
        """
        The policy for kernel module loading.
        """
        return pulumi.get(self, "policy")


@pulumi.output_type
class ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: _builtins.int):
        """
        :param _builtins.int local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
               > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
        > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class ClusterNodePoolNodeConfigReservationAffinity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "consumeReservationType":
            suggest = "consume_reservation_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigReservationAffinity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigReservationAffinity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigReservationAffinity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 consume_reservation_type: _builtins.str,
                 key: Optional[_builtins.str] = None,
                 values: Optional[Sequence[_builtins.str]] = None):
        """
        :param _builtins.str consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param _builtins.str key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param Sequence[_builtins.str] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @_builtins.property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> _builtins.str:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @_builtins.property
    @pulumi.getter
    def key(self) -> Optional[_builtins.str]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def values(self) -> Optional[Sequence[_builtins.str]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ClusterNodePoolNodeConfigSandboxConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sandboxType":
            suggest = "sandbox_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigSandboxConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigSandboxConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigSandboxConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 sandbox_type: _builtins.str):
        """
        :param _builtins.str sandbox_type: Which sandbox to use for pods in the node pool.
               Accepted values are:
               
               * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @_builtins.property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> _builtins.str:
        """
        Which sandbox to use for pods in the node pool.
        Accepted values are:

        * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class ClusterNodePoolNodeConfigSecondaryBootDisk(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "diskImage":
            suggest = "disk_image"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigSecondaryBootDisk. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigSecondaryBootDisk.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigSecondaryBootDisk.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disk_image: _builtins.str,
                 mode: Optional[_builtins.str] = None):
        """
        :param _builtins.str disk_image: Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        :param _builtins.str mode: Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        if mode is not None:
            pulumi.set(__self__, "mode", mode)

    @_builtins.property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> _builtins.str:
        """
        Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        """
        return pulumi.get(self, "disk_image")

    @_builtins.property
    @pulumi.getter
    def mode(self) -> Optional[_builtins.str]:
        """
        Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class ClusterNodePoolNodeConfigShieldedInstanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableIntegrityMonitoring":
            suggest = "enable_integrity_monitoring"
        elif key == "enableSecureBoot":
            suggest = "enable_secure_boot"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigShieldedInstanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[_builtins.bool] = None,
                 enable_secure_boot: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param _builtins.bool enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @_builtins.property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[_builtins.bool]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @_builtins.property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[_builtins.bool]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class ClusterNodePoolNodeConfigSoleTenantConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodeAffinities":
            suggest = "node_affinities"
        elif key == "minNodeCpus":
            suggest = "min_node_cpus"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolNodeConfigSoleTenantConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolNodeConfigSoleTenantConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolNodeConfigSoleTenantConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinity'],
                 min_node_cpus: Optional[_builtins.int] = None):
        """
        :param Sequence['ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs'] node_affinities: The node affinity settings for the sole tenant node pool. Structure is documented below.
        :param _builtins.int min_node_cpus: Specifies the minimum number of vCPUs that each sole tenant node must have to use CPU overcommit. If not specified, the CPU overcommit feeature is disabled. The value should be greater than or equal to half of the machine type's CPU count.
        """
        pulumi.set(__self__, "node_affinities", node_affinities)
        if min_node_cpus is not None:
            pulumi.set(__self__, "min_node_cpus", min_node_cpus)

    @_builtins.property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinity']:
        """
        The node affinity settings for the sole tenant node pool. Structure is documented below.
        """
        return pulumi.get(self, "node_affinities")

    @_builtins.property
    @pulumi.getter(name="minNodeCpus")
    def min_node_cpus(self) -> Optional[_builtins.int]:
        """
        Specifies the minimum number of vCPUs that each sole tenant node must have to use CPU overcommit. If not specified, the CPU overcommit feeature is disabled. The value should be greater than or equal to half of the machine type's CPU count.
        """
        return pulumi.get(self, "min_node_cpus")


@pulumi.output_type
class ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinity(dict):
    def __init__(__self__, *,
                 key: _builtins.str,
                 operator: _builtins.str,
                 values: Sequence[_builtins.str]):
        """
        :param _builtins.str key: The default or custom node affinity label key name.
        :param _builtins.str operator: Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        :param Sequence[_builtins.str] values: List of node affinity label values as strings.
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        The default or custom node affinity label key name.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def operator(self) -> _builtins.str:
        """
        Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        """
        return pulumi.get(self, "operator")

    @_builtins.property
    @pulumi.getter
    def values(self) -> Sequence[_builtins.str]:
        """
        List of node affinity label values as strings.
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ClusterNodePoolNodeConfigTaint(dict):
    def __init__(__self__, *,
                 effect: _builtins.str,
                 key: _builtins.str,
                 value: _builtins.str):
        """
        :param _builtins.str effect: Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        :param _builtins.str key: Key for taint.
        :param _builtins.str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def effect(self) -> _builtins.str:
        """
        Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        """
        return pulumi.get(self, "effect")

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def value(self) -> _builtins.str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class ClusterNodePoolNodeConfigWindowsNodeConfig(dict):
    def __init__(__self__, *,
                 osversion: Optional[_builtins.str] = None):
        """
        :param _builtins.str osversion: The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        if osversion is not None:
            pulumi.set(__self__, "osversion", osversion)

    @_builtins.property
    @pulumi.getter
    def osversion(self) -> Optional[_builtins.str]:
        """
        The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        return pulumi.get(self, "osversion")


@pulumi.output_type
class ClusterNodePoolNodeConfigWorkloadMetadataConfig(dict):
    def __init__(__self__, *,
                 mode: _builtins.str):
        """
        :param _builtins.str mode: How to expose the node metadata to the workload running on the node.
               Accepted values are:
               * UNSPECIFIED: Not Set
               * GCE_METADATA: Expose all Compute Engine metadata to pods.
               * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        pulumi.set(__self__, "mode", mode)

    @_builtins.property
    @pulumi.getter
    def mode(self) -> _builtins.str:
        """
        How to expose the node metadata to the workload running on the node.
        Accepted values are:
        * UNSPECIFIED: Not Set
        * GCE_METADATA: Expose all Compute Engine metadata to pods.
        * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class ClusterNodePoolPlacementPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "policyName":
            suggest = "policy_name"
        elif key == "tpuTopology":
            suggest = "tpu_topology"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolPlacementPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolPlacementPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolPlacementPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 type: _builtins.str,
                 policy_name: Optional[_builtins.str] = None,
                 tpu_topology: Optional[_builtins.str] = None):
        """
        :param _builtins.str type: Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
               `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        :param _builtins.str policy_name: If set, refers to the name of a custom resource policy supplied by the user. The resource policy must be in the same project and region as the node pool. If not found, InvalidArgument error is returned.
        :param _builtins.str tpu_topology: The TPU topology like "2x4" or "2x2x2". https://cloud.google.com/kubernetes-engine/docs/concepts/plan-tpus#topology
        """
        pulumi.set(__self__, "type", type)
        if policy_name is not None:
            pulumi.set(__self__, "policy_name", policy_name)
        if tpu_topology is not None:
            pulumi.set(__self__, "tpu_topology", tpu_topology)

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
        `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        return pulumi.get(self, "type")

    @_builtins.property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> Optional[_builtins.str]:
        """
        If set, refers to the name of a custom resource policy supplied by the user. The resource policy must be in the same project and region as the node pool. If not found, InvalidArgument error is returned.
        """
        return pulumi.get(self, "policy_name")

    @_builtins.property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> Optional[_builtins.str]:
        """
        The TPU topology like "2x4" or "2x2x2". https://cloud.google.com/kubernetes-engine/docs/concepts/plan-tpus#topology
        """
        return pulumi.get(self, "tpu_topology")


@pulumi.output_type
class ClusterNodePoolQueuedProvisioning(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether nodes in this node pool are obtainable solely through the ProvisioningRequest API
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether nodes in this node pool are obtainable solely through the ProvisioningRequest API
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterNodePoolUpgradeSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "blueGreenSettings":
            suggest = "blue_green_settings"
        elif key == "maxSurge":
            suggest = "max_surge"
        elif key == "maxUnavailable":
            suggest = "max_unavailable"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolUpgradeSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolUpgradeSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolUpgradeSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 blue_green_settings: Optional['outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettings'] = None,
                 max_surge: Optional[_builtins.int] = None,
                 max_unavailable: Optional[_builtins.int] = None,
                 strategy: Optional[_builtins.str] = None):
        """
        :param 'ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs' blue_green_settings: Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param _builtins.int max_surge: The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param _builtins.int max_unavailable: The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param _builtins.str strategy: Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @_builtins.property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional['outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettings']:
        """
        Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "blue_green_settings")

    @_builtins.property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[_builtins.int]:
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_surge")

    @_builtins.property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[_builtins.int]:
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_unavailable")

    @_builtins.property
    @pulumi.getter
    def strategy(self) -> Optional[_builtins.str]:
        """
        Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class ClusterNodePoolUpgradeSettingsBlueGreenSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoscaledRolloutPolicy":
            suggest = "autoscaled_rollout_policy"
        elif key == "nodePoolSoakDuration":
            suggest = "node_pool_soak_duration"
        elif key == "standardRolloutPolicy":
            suggest = "standard_rollout_policy"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolUpgradeSettingsBlueGreenSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 autoscaled_rollout_policy: Optional['outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy'] = None,
                 node_pool_soak_duration: Optional[_builtins.str] = None,
                 standard_rollout_policy: Optional['outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy'] = None):
        """
        :param 'ClusterNodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicyArgs' autoscaled_rollout_policy: Autoscaled rollout policy for blue-green upgrade.
        :param _builtins.str node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        :param 'ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs' standard_rollout_policy: Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        if autoscaled_rollout_policy is not None:
            pulumi.set(__self__, "autoscaled_rollout_policy", autoscaled_rollout_policy)
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        if standard_rollout_policy is not None:
            pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)

    @_builtins.property
    @pulumi.getter(name="autoscaledRolloutPolicy")
    def autoscaled_rollout_policy(self) -> Optional['outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy']:
        """
        Autoscaled rollout policy for blue-green upgrade.
        """
        return pulumi.get(self, "autoscaled_rollout_policy")

    @_builtins.property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[_builtins.str]:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @_builtins.property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> Optional['outputs.ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy']:
        """
        Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "standard_rollout_policy")


@pulumi.output_type
class ClusterNodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "waitForDrainDuration":
            suggest = "wait_for_drain_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 wait_for_drain_duration: Optional[_builtins.str] = None):
        """
        :param _builtins.str wait_for_drain_duration: Time in seconds to wait after cordoning the blue pool before draining the nodes.
        """
        if wait_for_drain_duration is not None:
            pulumi.set(__self__, "wait_for_drain_duration", wait_for_drain_duration)

    @_builtins.property
    @pulumi.getter(name="waitForDrainDuration")
    def wait_for_drain_duration(self) -> Optional[_builtins.str]:
        """
        Time in seconds to wait after cordoning the blue pool before draining the nodes.
        """
        return pulumi.get(self, "wait_for_drain_duration")


@pulumi.output_type
class ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "batchNodeCount":
            suggest = "batch_node_count"
        elif key == "batchPercentage":
            suggest = "batch_percentage"
        elif key == "batchSoakDuration":
            suggest = "batch_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 batch_node_count: Optional[_builtins.int] = None,
                 batch_percentage: Optional[_builtins.float] = None,
                 batch_soak_duration: Optional[_builtins.str] = None):
        """
        :param _builtins.int batch_node_count: Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        :param _builtins.float batch_percentage: Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        :param _builtins.str batch_soak_duration: Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @_builtins.property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[_builtins.int]:
        """
        Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_node_count")

    @_builtins.property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[_builtins.float]:
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_percentage")

    @_builtins.property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[_builtins.str]:
        """
        Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class ClusterNotificationConfig(dict):
    def __init__(__self__, *,
                 pubsub: 'outputs.ClusterNotificationConfigPubsub'):
        """
        :param 'ClusterNotificationConfigPubsubArgs' pubsub: The pubsub config for the cluster's upgrade notifications.
        """
        pulumi.set(__self__, "pubsub", pubsub)

    @_builtins.property
    @pulumi.getter
    def pubsub(self) -> 'outputs.ClusterNotificationConfigPubsub':
        """
        The pubsub config for the cluster's upgrade notifications.
        """
        return pulumi.get(self, "pubsub")


@pulumi.output_type
class ClusterNotificationConfigPubsub(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 filter: Optional['outputs.ClusterNotificationConfigPubsubFilter'] = None,
                 topic: Optional[_builtins.str] = None):
        """
        :param _builtins.bool enabled: Whether or not the notification config is enabled
        :param 'ClusterNotificationConfigPubsubFilterArgs' filter: Choose what type of notifications you want to receive. If no filters are applied, you'll receive all notification types. Structure is documented below.
        :param _builtins.str topic: The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: `projects/{project}/topics/{topic}`.
        """
        pulumi.set(__self__, "enabled", enabled)
        if filter is not None:
            pulumi.set(__self__, "filter", filter)
        if topic is not None:
            pulumi.set(__self__, "topic", topic)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not the notification config is enabled
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter
    def filter(self) -> Optional['outputs.ClusterNotificationConfigPubsubFilter']:
        """
        Choose what type of notifications you want to receive. If no filters are applied, you'll receive all notification types. Structure is documented below.
        """
        return pulumi.get(self, "filter")

    @_builtins.property
    @pulumi.getter
    def topic(self) -> Optional[_builtins.str]:
        """
        The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: `projects/{project}/topics/{topic}`.
        """
        return pulumi.get(self, "topic")


@pulumi.output_type
class ClusterNotificationConfigPubsubFilter(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "eventTypes":
            suggest = "event_types"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterNotificationConfigPubsubFilter. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterNotificationConfigPubsubFilter.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterNotificationConfigPubsubFilter.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 event_types: Sequence[_builtins.str]):
        """
        :param Sequence[_builtins.str] event_types: Can be used to filter what notifications are sent. Accepted values are `UPGRADE_AVAILABLE_EVENT`, `UPGRADE_EVENT`, `SECURITY_BULLETIN_EVENT` and `UPGRADE_INFO_EVENT`. See [Filtering notifications](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-notifications#filtering) for more details.
        """
        pulumi.set(__self__, "event_types", event_types)

    @_builtins.property
    @pulumi.getter(name="eventTypes")
    def event_types(self) -> Sequence[_builtins.str]:
        """
        Can be used to filter what notifications are sent. Accepted values are `UPGRADE_AVAILABLE_EVENT`, `UPGRADE_EVENT`, `SECURITY_BULLETIN_EVENT` and `UPGRADE_INFO_EVENT`. See [Filtering notifications](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-notifications#filtering) for more details.
        """
        return pulumi.get(self, "event_types")


@pulumi.output_type
class ClusterPodAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "hpaProfile":
            suggest = "hpa_profile"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterPodAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterPodAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterPodAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 hpa_profile: _builtins.str):
        """
        :param _builtins.str hpa_profile: Enable the Horizontal Pod Autoscaling profile for this cluster.
               Acceptable values are:
               * `"NONE"`: Customers explicitly opt-out of HPA profiles.
               * `"PERFORMANCE"`: PERFORMANCE is used when customers opt-in to the performance HPA profile. In this profile we support a higher number of HPAs per cluster and faster metrics collection for workload autoscaling.
               See [HPAProfile](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#hpaprofile) for more details.
        """
        pulumi.set(__self__, "hpa_profile", hpa_profile)

    @_builtins.property
    @pulumi.getter(name="hpaProfile")
    def hpa_profile(self) -> _builtins.str:
        """
        Enable the Horizontal Pod Autoscaling profile for this cluster.
        Acceptable values are:
        * `"NONE"`: Customers explicitly opt-out of HPA profiles.
        * `"PERFORMANCE"`: PERFORMANCE is used when customers opt-in to the performance HPA profile. In this profile we support a higher number of HPAs per cluster and faster metrics collection for workload autoscaling.
        See [HPAProfile](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#hpaprofile) for more details.
        """
        return pulumi.get(self, "hpa_profile")


@pulumi.output_type
class ClusterPodSecurityPolicyConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Enable the PodSecurityPolicy controller for this cluster.
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable the PodSecurityPolicy controller for this cluster.
        If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterPrivateClusterConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enablePrivateEndpoint":
            suggest = "enable_private_endpoint"
        elif key == "enablePrivateNodes":
            suggest = "enable_private_nodes"
        elif key == "masterGlobalAccessConfig":
            suggest = "master_global_access_config"
        elif key == "masterIpv4CidrBlock":
            suggest = "master_ipv4_cidr_block"
        elif key == "peeringName":
            suggest = "peering_name"
        elif key == "privateEndpoint":
            suggest = "private_endpoint"
        elif key == "privateEndpointSubnetwork":
            suggest = "private_endpoint_subnetwork"
        elif key == "publicEndpoint":
            suggest = "public_endpoint"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterPrivateClusterConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterPrivateClusterConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterPrivateClusterConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_private_endpoint: Optional[_builtins.bool] = None,
                 enable_private_nodes: Optional[_builtins.bool] = None,
                 master_global_access_config: Optional['outputs.ClusterPrivateClusterConfigMasterGlobalAccessConfig'] = None,
                 master_ipv4_cidr_block: Optional[_builtins.str] = None,
                 peering_name: Optional[_builtins.str] = None,
                 private_endpoint: Optional[_builtins.str] = None,
                 private_endpoint_subnetwork: Optional[_builtins.str] = None,
                 public_endpoint: Optional[_builtins.str] = None):
        """
        :param _builtins.bool enable_private_endpoint: When `true`, the cluster's private
               endpoint is used as the cluster endpoint and access through the public endpoint
               is disabled. When `false`, either endpoint can be used. This field only applies
               to private clusters, when `enable_private_nodes` is `true`.
        :param _builtins.bool enable_private_nodes: Enables the private cluster feature,
               creating a private endpoint on the cluster. In a private cluster, nodes only
               have RFC 1918 private addresses and communicate with the master's private
               endpoint via private networking.
        :param 'ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs' master_global_access_config: Controls cluster master global
               access settings. If unset, the provider will no longer manage this field and will
               not modify the previously-set value. Structure is documented below.
        :param _builtins.str master_ipv4_cidr_block: The IP range in CIDR notation to use for
               the hosted master network. This range will be used for assigning private IP
               addresses to the cluster master(s) and the ILB VIP. This range must not overlap
               with any other ranges in use within the cluster's network, and it must be a /28
               subnet. See [Private Cluster Limitations](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#req_res_lim)
               for more details. This field only applies to private clusters, when
               `enable_private_nodes` is `true`.
        :param _builtins.str peering_name: The name of the peering between this cluster and the Google owned VPC.
        :param _builtins.str private_endpoint: The internal IP address of this cluster's master endpoint.
        :param _builtins.str private_endpoint_subnetwork: Subnetwork in cluster's network where master's endpoint will be provisioned.
        :param _builtins.str public_endpoint: The external IP address of this cluster's master endpoint.
               
               !> The Google provider is unable to validate certain configurations of
               `private_cluster_config` when `enable_private_nodes` is `false`. It's
               recommended that you omit the block entirely if the field is not set to `true`.
        """
        if enable_private_endpoint is not None:
            pulumi.set(__self__, "enable_private_endpoint", enable_private_endpoint)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if master_global_access_config is not None:
            pulumi.set(__self__, "master_global_access_config", master_global_access_config)
        if master_ipv4_cidr_block is not None:
            pulumi.set(__self__, "master_ipv4_cidr_block", master_ipv4_cidr_block)
        if peering_name is not None:
            pulumi.set(__self__, "peering_name", peering_name)
        if private_endpoint is not None:
            pulumi.set(__self__, "private_endpoint", private_endpoint)
        if private_endpoint_subnetwork is not None:
            pulumi.set(__self__, "private_endpoint_subnetwork", private_endpoint_subnetwork)
        if public_endpoint is not None:
            pulumi.set(__self__, "public_endpoint", public_endpoint)

    @_builtins.property
    @pulumi.getter(name="enablePrivateEndpoint")
    def enable_private_endpoint(self) -> Optional[_builtins.bool]:
        """
        When `true`, the cluster's private
        endpoint is used as the cluster endpoint and access through the public endpoint
        is disabled. When `false`, either endpoint can be used. This field only applies
        to private clusters, when `enable_private_nodes` is `true`.
        """
        return pulumi.get(self, "enable_private_endpoint")

    @_builtins.property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[_builtins.bool]:
        """
        Enables the private cluster feature,
        creating a private endpoint on the cluster. In a private cluster, nodes only
        have RFC 1918 private addresses and communicate with the master's private
        endpoint via private networking.
        """
        return pulumi.get(self, "enable_private_nodes")

    @_builtins.property
    @pulumi.getter(name="masterGlobalAccessConfig")
    def master_global_access_config(self) -> Optional['outputs.ClusterPrivateClusterConfigMasterGlobalAccessConfig']:
        """
        Controls cluster master global
        access settings. If unset, the provider will no longer manage this field and will
        not modify the previously-set value. Structure is documented below.
        """
        return pulumi.get(self, "master_global_access_config")

    @_builtins.property
    @pulumi.getter(name="masterIpv4CidrBlock")
    def master_ipv4_cidr_block(self) -> Optional[_builtins.str]:
        """
        The IP range in CIDR notation to use for
        the hosted master network. This range will be used for assigning private IP
        addresses to the cluster master(s) and the ILB VIP. This range must not overlap
        with any other ranges in use within the cluster's network, and it must be a /28
        subnet. See [Private Cluster Limitations](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#req_res_lim)
        for more details. This field only applies to private clusters, when
        `enable_private_nodes` is `true`.
        """
        return pulumi.get(self, "master_ipv4_cidr_block")

    @_builtins.property
    @pulumi.getter(name="peeringName")
    def peering_name(self) -> Optional[_builtins.str]:
        """
        The name of the peering between this cluster and the Google owned VPC.
        """
        return pulumi.get(self, "peering_name")

    @_builtins.property
    @pulumi.getter(name="privateEndpoint")
    def private_endpoint(self) -> Optional[_builtins.str]:
        """
        The internal IP address of this cluster's master endpoint.
        """
        return pulumi.get(self, "private_endpoint")

    @_builtins.property
    @pulumi.getter(name="privateEndpointSubnetwork")
    def private_endpoint_subnetwork(self) -> Optional[_builtins.str]:
        """
        Subnetwork in cluster's network where master's endpoint will be provisioned.
        """
        return pulumi.get(self, "private_endpoint_subnetwork")

    @_builtins.property
    @pulumi.getter(name="publicEndpoint")
    def public_endpoint(self) -> Optional[_builtins.str]:
        """
        The external IP address of this cluster's master endpoint.

        !> The Google provider is unable to validate certain configurations of
        `private_cluster_config` when `enable_private_nodes` is `false`. It's
        recommended that you omit the block entirely if the field is not set to `true`.
        """
        return pulumi.get(self, "public_endpoint")


@pulumi.output_type
class ClusterPrivateClusterConfigMasterGlobalAccessConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether the cluster master is accessible globally or
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether the cluster master is accessible globally or
        not.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterProtectConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "workloadConfig":
            suggest = "workload_config"
        elif key == "workloadVulnerabilityMode":
            suggest = "workload_vulnerability_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterProtectConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterProtectConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterProtectConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 workload_config: Optional['outputs.ClusterProtectConfigWorkloadConfig'] = None,
                 workload_vulnerability_mode: Optional[_builtins.str] = None):
        """
        :param 'ClusterProtectConfigWorkloadConfigArgs' workload_config: WorkloadConfig defines which actions are enabled for a cluster's workload configurations. Structure is documented below
        :param _builtins.str workload_vulnerability_mode: Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        if workload_config is not None:
            pulumi.set(__self__, "workload_config", workload_config)
        if workload_vulnerability_mode is not None:
            pulumi.set(__self__, "workload_vulnerability_mode", workload_vulnerability_mode)

    @_builtins.property
    @pulumi.getter(name="workloadConfig")
    def workload_config(self) -> Optional['outputs.ClusterProtectConfigWorkloadConfig']:
        """
        WorkloadConfig defines which actions are enabled for a cluster's workload configurations. Structure is documented below
        """
        return pulumi.get(self, "workload_config")

    @_builtins.property
    @pulumi.getter(name="workloadVulnerabilityMode")
    def workload_vulnerability_mode(self) -> Optional[_builtins.str]:
        """
        Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "workload_vulnerability_mode")


@pulumi.output_type
class ClusterProtectConfigWorkloadConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "auditMode":
            suggest = "audit_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterProtectConfigWorkloadConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterProtectConfigWorkloadConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterProtectConfigWorkloadConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 audit_mode: _builtins.str):
        """
        :param _builtins.str audit_mode: Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        pulumi.set(__self__, "audit_mode", audit_mode)

    @_builtins.property
    @pulumi.getter(name="auditMode")
    def audit_mode(self) -> _builtins.str:
        """
        Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "audit_mode")


@pulumi.output_type
class ClusterRbacBindingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableInsecureBindingSystemAuthenticated":
            suggest = "enable_insecure_binding_system_authenticated"
        elif key == "enableInsecureBindingSystemUnauthenticated":
            suggest = "enable_insecure_binding_system_unauthenticated"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterRbacBindingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterRbacBindingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterRbacBindingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_insecure_binding_system_authenticated: Optional[_builtins.bool] = None,
                 enable_insecure_binding_system_unauthenticated: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool enable_insecure_binding_system_authenticated: Setting this to true will allow any ClusterRoleBinding and RoleBinding with subjects system:authenticated.
        :param _builtins.bool enable_insecure_binding_system_unauthenticated: Setting this to true will allow any ClusterRoleBinding and RoleBinding with subjects system:anonymous or system:unauthenticated.
        """
        if enable_insecure_binding_system_authenticated is not None:
            pulumi.set(__self__, "enable_insecure_binding_system_authenticated", enable_insecure_binding_system_authenticated)
        if enable_insecure_binding_system_unauthenticated is not None:
            pulumi.set(__self__, "enable_insecure_binding_system_unauthenticated", enable_insecure_binding_system_unauthenticated)

    @_builtins.property
    @pulumi.getter(name="enableInsecureBindingSystemAuthenticated")
    def enable_insecure_binding_system_authenticated(self) -> Optional[_builtins.bool]:
        """
        Setting this to true will allow any ClusterRoleBinding and RoleBinding with subjects system:authenticated.
        """
        return pulumi.get(self, "enable_insecure_binding_system_authenticated")

    @_builtins.property
    @pulumi.getter(name="enableInsecureBindingSystemUnauthenticated")
    def enable_insecure_binding_system_unauthenticated(self) -> Optional[_builtins.bool]:
        """
        Setting this to true will allow any ClusterRoleBinding and RoleBinding with subjects system:anonymous or system:unauthenticated.
        """
        return pulumi.get(self, "enable_insecure_binding_system_unauthenticated")


@pulumi.output_type
class ClusterReleaseChannel(dict):
    def __init__(__self__, *,
                 channel: _builtins.str):
        """
        :param _builtins.str channel: The selected release channel.
               Accepted values are:
               * UNSPECIFIED: Not set.
               * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
               * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
               * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
               * EXTENDED: GKE provides extended support for Kubernetes minor versions through the Extended channel. With this channel, you can stay on a minor version for up to 24 months.
        """
        pulumi.set(__self__, "channel", channel)

    @_builtins.property
    @pulumi.getter
    def channel(self) -> _builtins.str:
        """
        The selected release channel.
        Accepted values are:
        * UNSPECIFIED: Not set.
        * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
        * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
        * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
        * EXTENDED: GKE provides extended support for Kubernetes minor versions through the Extended channel. With this channel, you can stay on a minor version for up to 24 months.
        """
        return pulumi.get(self, "channel")


@pulumi.output_type
class ClusterResourceUsageExportConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bigqueryDestination":
            suggest = "bigquery_destination"
        elif key == "enableNetworkEgressMetering":
            suggest = "enable_network_egress_metering"
        elif key == "enableResourceConsumptionMetering":
            suggest = "enable_resource_consumption_metering"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterResourceUsageExportConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterResourceUsageExportConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterResourceUsageExportConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 bigquery_destination: 'outputs.ClusterResourceUsageExportConfigBigqueryDestination',
                 enable_network_egress_metering: Optional[_builtins.bool] = None,
                 enable_resource_consumption_metering: Optional[_builtins.bool] = None):
        """
        :param 'ClusterResourceUsageExportConfigBigqueryDestinationArgs' bigquery_destination: Parameters for using BigQuery as the destination of resource usage export.
               
               * `bigquery_destination.dataset_id` (Required) - The ID of a BigQuery Dataset. For Example:
        :param _builtins.bool enable_network_egress_metering: Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created
               in the cluster to meter network egress traffic.
        :param _builtins.bool enable_resource_consumption_metering: Whether to enable resource
               consumption metering on this cluster. When enabled, a table will be created in
               the resource export BigQuery dataset to store resource consumption data. The
               resulting table can be joined with the resource usage table or with BigQuery
               billing export. Defaults to `true`.
        """
        pulumi.set(__self__, "bigquery_destination", bigquery_destination)
        if enable_network_egress_metering is not None:
            pulumi.set(__self__, "enable_network_egress_metering", enable_network_egress_metering)
        if enable_resource_consumption_metering is not None:
            pulumi.set(__self__, "enable_resource_consumption_metering", enable_resource_consumption_metering)

    @_builtins.property
    @pulumi.getter(name="bigqueryDestination")
    def bigquery_destination(self) -> 'outputs.ClusterResourceUsageExportConfigBigqueryDestination':
        """
        Parameters for using BigQuery as the destination of resource usage export.

        * `bigquery_destination.dataset_id` (Required) - The ID of a BigQuery Dataset. For Example:
        """
        return pulumi.get(self, "bigquery_destination")

    @_builtins.property
    @pulumi.getter(name="enableNetworkEgressMetering")
    def enable_network_egress_metering(self) -> Optional[_builtins.bool]:
        """
        Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created
        in the cluster to meter network egress traffic.
        """
        return pulumi.get(self, "enable_network_egress_metering")

    @_builtins.property
    @pulumi.getter(name="enableResourceConsumptionMetering")
    def enable_resource_consumption_metering(self) -> Optional[_builtins.bool]:
        """
        Whether to enable resource
        consumption metering on this cluster. When enabled, a table will be created in
        the resource export BigQuery dataset to store resource consumption data. The
        resulting table can be joined with the resource usage table or with BigQuery
        billing export. Defaults to `true`.
        """
        return pulumi.get(self, "enable_resource_consumption_metering")


@pulumi.output_type
class ClusterResourceUsageExportConfigBigqueryDestination(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "datasetId":
            suggest = "dataset_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterResourceUsageExportConfigBigqueryDestination. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterResourceUsageExportConfigBigqueryDestination.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterResourceUsageExportConfigBigqueryDestination.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dataset_id: _builtins.str):
        """
        :param _builtins.str dataset_id: The ID of a BigQuery Dataset.
        """
        pulumi.set(__self__, "dataset_id", dataset_id)

    @_builtins.property
    @pulumi.getter(name="datasetId")
    def dataset_id(self) -> _builtins.str:
        """
        The ID of a BigQuery Dataset.
        """
        return pulumi.get(self, "dataset_id")


@pulumi.output_type
class ClusterSecretManagerConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "rotationConfig":
            suggest = "rotation_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterSecretManagerConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterSecretManagerConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterSecretManagerConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 rotation_config: Optional['outputs.ClusterSecretManagerConfigRotationConfig'] = None):
        """
        :param _builtins.bool enabled: Enable the Secret Manager add-on for this cluster.
        :param 'ClusterSecretManagerConfigRotationConfigArgs' rotation_config: config for secret manager auto rotation. Structure is docuemented below
        """
        pulumi.set(__self__, "enabled", enabled)
        if rotation_config is not None:
            pulumi.set(__self__, "rotation_config", rotation_config)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable the Secret Manager add-on for this cluster.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="rotationConfig")
    def rotation_config(self) -> Optional['outputs.ClusterSecretManagerConfigRotationConfig']:
        """
        config for secret manager auto rotation. Structure is docuemented below
        """
        return pulumi.get(self, "rotation_config")


@pulumi.output_type
class ClusterSecretManagerConfigRotationConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "rotationInterval":
            suggest = "rotation_interval"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterSecretManagerConfigRotationConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterSecretManagerConfigRotationConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterSecretManagerConfigRotationConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 rotation_interval: Optional[_builtins.str] = None):
        """
        :param _builtins.bool enabled: Enable the roation in Sync as K8s secret feature for this cluster.
        :param _builtins.str rotation_interval: The interval between two consecutive rotations. Default rotation interval is 2 minutes.
        """
        pulumi.set(__self__, "enabled", enabled)
        if rotation_interval is not None:
            pulumi.set(__self__, "rotation_interval", rotation_interval)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable the roation in Sync as K8s secret feature for this cluster.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="rotationInterval")
    def rotation_interval(self) -> Optional[_builtins.str]:
        """
        The interval between two consecutive rotations. Default rotation interval is 2 minutes.
        """
        return pulumi.get(self, "rotation_interval")


@pulumi.output_type
class ClusterSecretSyncConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "rotationConfig":
            suggest = "rotation_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterSecretSyncConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterSecretSyncConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterSecretSyncConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 rotation_config: Optional['outputs.ClusterSecretSyncConfigRotationConfig'] = None):
        """
        :param _builtins.bool enabled: Enable the Sync as K8s secret feature for this cluster.
        :param 'ClusterSecretSyncConfigRotationConfigArgs' rotation_config: config for secret sync auto rotation. Structure is docuemented below
        """
        pulumi.set(__self__, "enabled", enabled)
        if rotation_config is not None:
            pulumi.set(__self__, "rotation_config", rotation_config)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable the Sync as K8s secret feature for this cluster.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="rotationConfig")
    def rotation_config(self) -> Optional['outputs.ClusterSecretSyncConfigRotationConfig']:
        """
        config for secret sync auto rotation. Structure is docuemented below
        """
        return pulumi.get(self, "rotation_config")


@pulumi.output_type
class ClusterSecretSyncConfigRotationConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "rotationInterval":
            suggest = "rotation_interval"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterSecretSyncConfigRotationConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterSecretSyncConfigRotationConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterSecretSyncConfigRotationConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 rotation_interval: Optional[_builtins.str] = None):
        """
        :param _builtins.bool enabled: Enable the roation in Sync as K8s secret feature for this cluster.
        :param _builtins.str rotation_interval: The interval between two consecutive rotations. Default rotation interval is 2 minutes.
        """
        pulumi.set(__self__, "enabled", enabled)
        if rotation_interval is not None:
            pulumi.set(__self__, "rotation_interval", rotation_interval)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable the roation in Sync as K8s secret feature for this cluster.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="rotationInterval")
    def rotation_interval(self) -> Optional[_builtins.str]:
        """
        The interval between two consecutive rotations. Default rotation interval is 2 minutes.
        """
        return pulumi.get(self, "rotation_interval")


@pulumi.output_type
class ClusterSecurityPostureConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "vulnerabilityMode":
            suggest = "vulnerability_mode"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterSecurityPostureConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterSecurityPostureConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterSecurityPostureConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 mode: Optional[_builtins.str] = None,
                 vulnerability_mode: Optional[_builtins.str] = None):
        """
        :param _builtins.str mode: Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include `DISABLED`, `BASIC`, and `ENTERPRISE`.
        :param _builtins.str vulnerability_mode: Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include `VULNERABILITY_DISABLED`, `VULNERABILITY_BASIC` and `VULNERABILITY_ENTERPRISE`.
        """
        if mode is not None:
            pulumi.set(__self__, "mode", mode)
        if vulnerability_mode is not None:
            pulumi.set(__self__, "vulnerability_mode", vulnerability_mode)

    @_builtins.property
    @pulumi.getter
    def mode(self) -> Optional[_builtins.str]:
        """
        Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include `DISABLED`, `BASIC`, and `ENTERPRISE`.
        """
        return pulumi.get(self, "mode")

    @_builtins.property
    @pulumi.getter(name="vulnerabilityMode")
    def vulnerability_mode(self) -> Optional[_builtins.str]:
        """
        Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include `VULNERABILITY_DISABLED`, `VULNERABILITY_BASIC` and `VULNERABILITY_ENTERPRISE`.
        """
        return pulumi.get(self, "vulnerability_mode")


@pulumi.output_type
class ClusterServiceExternalIpsConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Controls whether external ips specified by a service will be allowed. It is enabled by default.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Controls whether external ips specified by a service will be allowed. It is enabled by default.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterTpuConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ipv4CidrBlock":
            suggest = "ipv4_cidr_block"
        elif key == "useServiceNetworking":
            suggest = "use_service_networking"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterTpuConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterTpuConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterTpuConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 ipv4_cidr_block: Optional[_builtins.str] = None,
                 use_service_networking: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool enabled: Whether Cloud TPU integration is enabled or not
        :param _builtins.str ipv4_cidr_block: IPv4 CIDR block reserved for Cloud TPU in the VPC.
        :param _builtins.bool use_service_networking: Whether to use service networking for Cloud TPU or not
        """
        pulumi.set(__self__, "enabled", enabled)
        if ipv4_cidr_block is not None:
            pulumi.set(__self__, "ipv4_cidr_block", ipv4_cidr_block)
        if use_service_networking is not None:
            pulumi.set(__self__, "use_service_networking", use_service_networking)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether Cloud TPU integration is enabled or not
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="ipv4CidrBlock")
    def ipv4_cidr_block(self) -> Optional[_builtins.str]:
        """
        IPv4 CIDR block reserved for Cloud TPU in the VPC.
        """
        return pulumi.get(self, "ipv4_cidr_block")

    @_builtins.property
    @pulumi.getter(name="useServiceNetworking")
    def use_service_networking(self) -> Optional[_builtins.bool]:
        """
        Whether to use service networking for Cloud TPU or not
        """
        return pulumi.get(self, "use_service_networking")


@pulumi.output_type
class ClusterUserManagedKeysConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "aggregationCa":
            suggest = "aggregation_ca"
        elif key == "clusterCa":
            suggest = "cluster_ca"
        elif key == "controlPlaneDiskEncryptionKey":
            suggest = "control_plane_disk_encryption_key"
        elif key == "etcdApiCa":
            suggest = "etcd_api_ca"
        elif key == "etcdPeerCa":
            suggest = "etcd_peer_ca"
        elif key == "gkeopsEtcdBackupEncryptionKey":
            suggest = "gkeops_etcd_backup_encryption_key"
        elif key == "serviceAccountSigningKeys":
            suggest = "service_account_signing_keys"
        elif key == "serviceAccountVerificationKeys":
            suggest = "service_account_verification_keys"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterUserManagedKeysConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterUserManagedKeysConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterUserManagedKeysConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 aggregation_ca: Optional[_builtins.str] = None,
                 cluster_ca: Optional[_builtins.str] = None,
                 control_plane_disk_encryption_key: Optional[_builtins.str] = None,
                 etcd_api_ca: Optional[_builtins.str] = None,
                 etcd_peer_ca: Optional[_builtins.str] = None,
                 gkeops_etcd_backup_encryption_key: Optional[_builtins.str] = None,
                 service_account_signing_keys: Optional[Sequence[_builtins.str]] = None,
                 service_account_verification_keys: Optional[Sequence[_builtins.str]] = None):
        """
        :param _builtins.str aggregation_ca: The Certificate Authority Service caPool to use for the aggreation CA in this cluster.
        :param _builtins.str cluster_ca: The Certificate Authority Service caPool to use for the cluster CA in this cluster.
        :param _builtins.str control_plane_disk_encryption_key: The Cloud KMS cryptoKey to use for Confidential Hyperdisk on the control plane nodes.
        :param _builtins.str etcd_api_ca: The Certificate Authority Service caPool to use for the etcd API CA in this cluster.
        :param _builtins.str etcd_peer_ca: The Certificate Authority Service caPool to use for the etcd peer CA in this cluster.
        :param _builtins.str gkeops_etcd_backup_encryption_key: Resource path of the Cloud KMS cryptoKey to use for encryption of internal etcd backups.
        :param Sequence[_builtins.str] service_account_signing_keys: The Cloud KMS cryptoKeyVersions to use for signing service account JWTs issued by this cluster.
        :param Sequence[_builtins.str] service_account_verification_keys: The Cloud KMS cryptoKeyVersions to use for verifying service account JWTs issued by this cluster.
        """
        if aggregation_ca is not None:
            pulumi.set(__self__, "aggregation_ca", aggregation_ca)
        if cluster_ca is not None:
            pulumi.set(__self__, "cluster_ca", cluster_ca)
        if control_plane_disk_encryption_key is not None:
            pulumi.set(__self__, "control_plane_disk_encryption_key", control_plane_disk_encryption_key)
        if etcd_api_ca is not None:
            pulumi.set(__self__, "etcd_api_ca", etcd_api_ca)
        if etcd_peer_ca is not None:
            pulumi.set(__self__, "etcd_peer_ca", etcd_peer_ca)
        if gkeops_etcd_backup_encryption_key is not None:
            pulumi.set(__self__, "gkeops_etcd_backup_encryption_key", gkeops_etcd_backup_encryption_key)
        if service_account_signing_keys is not None:
            pulumi.set(__self__, "service_account_signing_keys", service_account_signing_keys)
        if service_account_verification_keys is not None:
            pulumi.set(__self__, "service_account_verification_keys", service_account_verification_keys)

    @_builtins.property
    @pulumi.getter(name="aggregationCa")
    def aggregation_ca(self) -> Optional[_builtins.str]:
        """
        The Certificate Authority Service caPool to use for the aggreation CA in this cluster.
        """
        return pulumi.get(self, "aggregation_ca")

    @_builtins.property
    @pulumi.getter(name="clusterCa")
    def cluster_ca(self) -> Optional[_builtins.str]:
        """
        The Certificate Authority Service caPool to use for the cluster CA in this cluster.
        """
        return pulumi.get(self, "cluster_ca")

    @_builtins.property
    @pulumi.getter(name="controlPlaneDiskEncryptionKey")
    def control_plane_disk_encryption_key(self) -> Optional[_builtins.str]:
        """
        The Cloud KMS cryptoKey to use for Confidential Hyperdisk on the control plane nodes.
        """
        return pulumi.get(self, "control_plane_disk_encryption_key")

    @_builtins.property
    @pulumi.getter(name="etcdApiCa")
    def etcd_api_ca(self) -> Optional[_builtins.str]:
        """
        The Certificate Authority Service caPool to use for the etcd API CA in this cluster.
        """
        return pulumi.get(self, "etcd_api_ca")

    @_builtins.property
    @pulumi.getter(name="etcdPeerCa")
    def etcd_peer_ca(self) -> Optional[_builtins.str]:
        """
        The Certificate Authority Service caPool to use for the etcd peer CA in this cluster.
        """
        return pulumi.get(self, "etcd_peer_ca")

    @_builtins.property
    @pulumi.getter(name="gkeopsEtcdBackupEncryptionKey")
    def gkeops_etcd_backup_encryption_key(self) -> Optional[_builtins.str]:
        """
        Resource path of the Cloud KMS cryptoKey to use for encryption of internal etcd backups.
        """
        return pulumi.get(self, "gkeops_etcd_backup_encryption_key")

    @_builtins.property
    @pulumi.getter(name="serviceAccountSigningKeys")
    def service_account_signing_keys(self) -> Optional[Sequence[_builtins.str]]:
        """
        The Cloud KMS cryptoKeyVersions to use for signing service account JWTs issued by this cluster.
        """
        return pulumi.get(self, "service_account_signing_keys")

    @_builtins.property
    @pulumi.getter(name="serviceAccountVerificationKeys")
    def service_account_verification_keys(self) -> Optional[Sequence[_builtins.str]]:
        """
        The Cloud KMS cryptoKeyVersions to use for verifying service account JWTs issued by this cluster.
        """
        return pulumi.get(self, "service_account_verification_keys")


@pulumi.output_type
class ClusterVerticalPodAutoscaling(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Enables vertical pod autoscaling
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enables vertical pod autoscaling
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class ClusterWorkloadAltsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableAlts":
            suggest = "enable_alts"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterWorkloadAltsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterWorkloadAltsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterWorkloadAltsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_alts: _builtins.bool):
        """
        :param _builtins.bool enable_alts: Whether the alts handshaker should be enabled or not for direct-path. Requires Workload Identity (workloadPool) must be non-empty).
        """
        pulumi.set(__self__, "enable_alts", enable_alts)

    @_builtins.property
    @pulumi.getter(name="enableAlts")
    def enable_alts(self) -> _builtins.bool:
        """
        Whether the alts handshaker should be enabled or not for direct-path. Requires Workload Identity (workloadPool) must be non-empty).
        """
        return pulumi.get(self, "enable_alts")


@pulumi.output_type
class ClusterWorkloadIdentityConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "workloadPool":
            suggest = "workload_pool"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterWorkloadIdentityConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterWorkloadIdentityConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterWorkloadIdentityConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 workload_pool: Optional[_builtins.str] = None):
        """
        :param _builtins.str workload_pool: The workload pool to attach all Kubernetes service accounts to.
        """
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @_builtins.property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[_builtins.str]:
        """
        The workload pool to attach all Kubernetes service accounts to.
        """
        return pulumi.get(self, "workload_pool")


@pulumi.output_type
class NodePoolAutoscaling(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "locationPolicy":
            suggest = "location_policy"
        elif key == "maxNodeCount":
            suggest = "max_node_count"
        elif key == "minNodeCount":
            suggest = "min_node_count"
        elif key == "totalMaxNodeCount":
            suggest = "total_max_node_count"
        elif key == "totalMinNodeCount":
            suggest = "total_min_node_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolAutoscaling. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolAutoscaling.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolAutoscaling.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 location_policy: Optional[_builtins.str] = None,
                 max_node_count: Optional[_builtins.int] = None,
                 min_node_count: Optional[_builtins.int] = None,
                 total_max_node_count: Optional[_builtins.int] = None,
                 total_min_node_count: Optional[_builtins.int] = None):
        """
        :param _builtins.str location_policy: Location policy specifies the algorithm used when
               scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
               * "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones.
               * "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations,
               and reduce preemption risk for Spot VMs.
        :param _builtins.int max_node_count: Maximum number of nodes per zone in the NodePool.
               Must be >= min_node_count. Cannot be used with total limits.
        :param _builtins.int min_node_count: Minimum number of nodes per zone in the NodePool.
               Must be >=0 and <= `max_node_count`. Cannot be used with total limits.
        :param _builtins.int total_max_node_count: Total maximum number of nodes in the NodePool.
               Must be >= total_min_node_count. Cannot be used with per zone limits.
               Total size limits are supported only in 1.24.1+ clusters.
        :param _builtins.int total_min_node_count: Total minimum number of nodes in the NodePool.
               Must be >=0 and <= `total_max_node_count`. Cannot be used with per zone limits.
               Total size limits are supported only in 1.24.1+ clusters.
        """
        if location_policy is not None:
            pulumi.set(__self__, "location_policy", location_policy)
        if max_node_count is not None:
            pulumi.set(__self__, "max_node_count", max_node_count)
        if min_node_count is not None:
            pulumi.set(__self__, "min_node_count", min_node_count)
        if total_max_node_count is not None:
            pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        if total_min_node_count is not None:
            pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @_builtins.property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> Optional[_builtins.str]:
        """
        Location policy specifies the algorithm used when
        scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
        * "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones.
        * "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations,
        and reduce preemption risk for Spot VMs.
        """
        return pulumi.get(self, "location_policy")

    @_builtins.property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> Optional[_builtins.int]:
        """
        Maximum number of nodes per zone in the NodePool.
        Must be >= min_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "max_node_count")

    @_builtins.property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> Optional[_builtins.int]:
        """
        Minimum number of nodes per zone in the NodePool.
        Must be >=0 and <= `max_node_count`. Cannot be used with total limits.
        """
        return pulumi.get(self, "min_node_count")

    @_builtins.property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> Optional[_builtins.int]:
        """
        Total maximum number of nodes in the NodePool.
        Must be >= total_min_node_count. Cannot be used with per zone limits.
        Total size limits are supported only in 1.24.1+ clusters.
        """
        return pulumi.get(self, "total_max_node_count")

    @_builtins.property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> Optional[_builtins.int]:
        """
        Total minimum number of nodes in the NodePool.
        Must be >=0 and <= `total_max_node_count`. Cannot be used with per zone limits.
        Total size limits are supported only in 1.24.1+ clusters.
        """
        return pulumi.get(self, "total_min_node_count")


@pulumi.output_type
class NodePoolManagement(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoRepair":
            suggest = "auto_repair"
        elif key == "autoUpgrade":
            suggest = "auto_upgrade"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolManagement. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolManagement.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolManagement.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_repair: Optional[_builtins.bool] = None,
                 auto_upgrade: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool auto_repair: Whether the nodes will be automatically repaired. Enabled by default.
        :param _builtins.bool auto_upgrade: Whether the nodes will be automatically upgraded. Enabled by default.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @_builtins.property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[_builtins.bool]:
        """
        Whether the nodes will be automatically repaired. Enabled by default.
        """
        return pulumi.get(self, "auto_repair")

    @_builtins.property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[_builtins.bool]:
        """
        Whether the nodes will be automatically upgraded. Enabled by default.
        """
        return pulumi.get(self, "auto_upgrade")


@pulumi.output_type
class NodePoolNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "additionalNodeNetworkConfigs":
            suggest = "additional_node_network_configs"
        elif key == "additionalPodNetworkConfigs":
            suggest = "additional_pod_network_configs"
        elif key == "createPodRange":
            suggest = "create_pod_range"
        elif key == "enablePrivateNodes":
            suggest = "enable_private_nodes"
        elif key == "networkPerformanceConfig":
            suggest = "network_performance_config"
        elif key == "podCidrOverprovisionConfig":
            suggest = "pod_cidr_overprovision_config"
        elif key == "podIpv4CidrBlock":
            suggest = "pod_ipv4_cidr_block"
        elif key == "podRange":
            suggest = "pod_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 additional_node_network_configs: Optional[Sequence['outputs.NodePoolNetworkConfigAdditionalNodeNetworkConfig']] = None,
                 additional_pod_network_configs: Optional[Sequence['outputs.NodePoolNetworkConfigAdditionalPodNetworkConfig']] = None,
                 create_pod_range: Optional[_builtins.bool] = None,
                 enable_private_nodes: Optional[_builtins.bool] = None,
                 network_performance_config: Optional['outputs.NodePoolNetworkConfigNetworkPerformanceConfig'] = None,
                 pod_cidr_overprovision_config: Optional['outputs.NodePoolNetworkConfigPodCidrOverprovisionConfig'] = None,
                 pod_ipv4_cidr_block: Optional[_builtins.str] = None,
                 pod_range: Optional[_builtins.str] = None,
                 subnetwork: Optional[_builtins.str] = None):
        """
        :param Sequence['NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs'] additional_node_network_configs: We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface.
               Structure is documented below
        :param Sequence['NodePoolNetworkConfigAdditionalPodNetworkConfigArgs'] additional_pod_network_configs: We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node.
               Structure is documented below
        :param _builtins.bool create_pod_range: Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        :param _builtins.bool enable_private_nodes: Whether nodes have internal IP addresses only.
        :param 'NodePoolNetworkConfigNetworkPerformanceConfigArgs' network_performance_config: Network bandwidth tier configuration. Structure is documented below.
        :param 'NodePoolNetworkConfigPodCidrOverprovisionConfigArgs' pod_cidr_overprovision_config: Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited. Structure is documented below.
        :param _builtins.str pod_ipv4_cidr_block: The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        :param _builtins.str pod_range: The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        :param _builtins.str subnetwork: The subnetwork path for the node pool. Format: `projects/{project}/regions/{region}/subnetworks/{subnetwork}`. If the cluster is associated with multiple subnetworks, the subnetwork for the node pool is picked based on the IP utilization during node pool creation and is immutable
        """
        if additional_node_network_configs is not None:
            pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        if additional_pod_network_configs is not None:
            pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        if create_pod_range is not None:
            pulumi.set(__self__, "create_pod_range", create_pod_range)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if network_performance_config is not None:
            pulumi.set(__self__, "network_performance_config", network_performance_config)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if pod_ipv4_cidr_block is not None:
            pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        if pod_range is not None:
            pulumi.set(__self__, "pod_range", pod_range)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @_builtins.property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Optional[Sequence['outputs.NodePoolNetworkConfigAdditionalNodeNetworkConfig']]:
        """
        We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface.
        Structure is documented below
        """
        return pulumi.get(self, "additional_node_network_configs")

    @_builtins.property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Optional[Sequence['outputs.NodePoolNetworkConfigAdditionalPodNetworkConfig']]:
        """
        We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node.
        Structure is documented below
        """
        return pulumi.get(self, "additional_pod_network_configs")

    @_builtins.property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> Optional[_builtins.bool]:
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        """
        return pulumi.get(self, "create_pod_range")

    @_builtins.property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[_builtins.bool]:
        """
        Whether nodes have internal IP addresses only.
        """
        return pulumi.get(self, "enable_private_nodes")

    @_builtins.property
    @pulumi.getter(name="networkPerformanceConfig")
    def network_performance_config(self) -> Optional['outputs.NodePoolNetworkConfigNetworkPerformanceConfig']:
        """
        Network bandwidth tier configuration. Structure is documented below.
        """
        return pulumi.get(self, "network_performance_config")

    @_builtins.property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional['outputs.NodePoolNetworkConfigPodCidrOverprovisionConfig']:
        """
        Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited. Structure is documented below.
        """
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @_builtins.property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> Optional[_builtins.str]:
        """
        The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @_builtins.property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> Optional[_builtins.str]:
        """
        The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        return pulumi.get(self, "pod_range")

    @_builtins.property
    @pulumi.getter
    def subnetwork(self) -> Optional[_builtins.str]:
        """
        The subnetwork path for the node pool. Format: `projects/{project}/regions/{region}/subnetworks/{subnetwork}`. If the cluster is associated with multiple subnetworks, the subnetwork for the node pool is picked based on the IP utilization during node pool creation and is immutable
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class NodePoolNetworkConfigAdditionalNodeNetworkConfig(dict):
    def __init__(__self__, *,
                 network: Optional[_builtins.str] = None,
                 subnetwork: Optional[_builtins.str] = None):
        """
        :param _builtins.str network: Name of the VPC where the additional interface belongs.
        :param _builtins.str subnetwork: Name of the subnetwork where the additional interface belongs.
        """
        if network is not None:
            pulumi.set(__self__, "network", network)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @_builtins.property
    @pulumi.getter
    def network(self) -> Optional[_builtins.str]:
        """
        Name of the VPC where the additional interface belongs.
        """
        return pulumi.get(self, "network")

    @_builtins.property
    @pulumi.getter
    def subnetwork(self) -> Optional[_builtins.str]:
        """
        Name of the subnetwork where the additional interface belongs.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class NodePoolNetworkConfigAdditionalPodNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxPodsPerNode":
            suggest = "max_pods_per_node"
        elif key == "secondaryPodRange":
            suggest = "secondary_pod_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNetworkConfigAdditionalPodNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNetworkConfigAdditionalPodNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNetworkConfigAdditionalPodNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_pods_per_node: Optional[_builtins.int] = None,
                 secondary_pod_range: Optional[_builtins.str] = None,
                 subnetwork: Optional[_builtins.str] = None):
        """
        :param _builtins.int max_pods_per_node: The maximum number of pods per node which use this pod network.
        :param _builtins.str secondary_pod_range: The name of the secondary range on the subnet which provides IP address for this pod range.
        :param _builtins.str subnetwork: Name of the subnetwork where the additional pod network belongs.
        """
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if secondary_pod_range is not None:
            pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @_builtins.property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[_builtins.int]:
        """
        The maximum number of pods per node which use this pod network.
        """
        return pulumi.get(self, "max_pods_per_node")

    @_builtins.property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> Optional[_builtins.str]:
        """
        The name of the secondary range on the subnet which provides IP address for this pod range.
        """
        return pulumi.get(self, "secondary_pod_range")

    @_builtins.property
    @pulumi.getter
    def subnetwork(self) -> Optional[_builtins.str]:
        """
        Name of the subnetwork where the additional pod network belongs.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class NodePoolNetworkConfigNetworkPerformanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "totalEgressBandwidthTier":
            suggest = "total_egress_bandwidth_tier"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNetworkConfigNetworkPerformanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNetworkConfigNetworkPerformanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNetworkConfigNetworkPerformanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 total_egress_bandwidth_tier: _builtins.str):
        """
        :param _builtins.str total_egress_bandwidth_tier: Specifies the total network bandwidth tier for the NodePool. [Valid values](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/projects.locations.clusters.nodePools#NodePool.Tier) include: "TIER_1" and "TIER_UNSPECIFIED".
        """
        pulumi.set(__self__, "total_egress_bandwidth_tier", total_egress_bandwidth_tier)

    @_builtins.property
    @pulumi.getter(name="totalEgressBandwidthTier")
    def total_egress_bandwidth_tier(self) -> _builtins.str:
        """
        Specifies the total network bandwidth tier for the NodePool. [Valid values](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/projects.locations.clusters.nodePools#NodePool.Tier) include: "TIER_1" and "TIER_UNSPECIFIED".
        """
        return pulumi.get(self, "total_egress_bandwidth_tier")


@pulumi.output_type
class NodePoolNetworkConfigPodCidrOverprovisionConfig(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        """
        :param _builtins.bool disabled: Whether pod cidr overprovision is disabled.
        """
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        """
        Whether pod cidr overprovision is disabled.
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class NodePoolNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "advancedMachineFeatures":
            suggest = "advanced_machine_features"
        elif key == "bootDisk":
            suggest = "boot_disk"
        elif key == "bootDiskKmsKey":
            suggest = "boot_disk_kms_key"
        elif key == "confidentialNodes":
            suggest = "confidential_nodes"
        elif key == "containerdConfig":
            suggest = "containerd_config"
        elif key == "diskSizeGb":
            suggest = "disk_size_gb"
        elif key == "diskType":
            suggest = "disk_type"
        elif key == "effectiveTaints":
            suggest = "effective_taints"
        elif key == "enableConfidentialStorage":
            suggest = "enable_confidential_storage"
        elif key == "ephemeralStorageConfig":
            suggest = "ephemeral_storage_config"
        elif key == "ephemeralStorageLocalSsdConfig":
            suggest = "ephemeral_storage_local_ssd_config"
        elif key == "fastSocket":
            suggest = "fast_socket"
        elif key == "flexStart":
            suggest = "flex_start"
        elif key == "gcfsConfig":
            suggest = "gcfs_config"
        elif key == "guestAccelerators":
            suggest = "guest_accelerators"
        elif key == "hostMaintenancePolicy":
            suggest = "host_maintenance_policy"
        elif key == "imageType":
            suggest = "image_type"
        elif key == "kubeletConfig":
            suggest = "kubelet_config"
        elif key == "linuxNodeConfig":
            suggest = "linux_node_config"
        elif key == "localNvmeSsdBlockConfig":
            suggest = "local_nvme_ssd_block_config"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "localSsdEncryptionMode":
            suggest = "local_ssd_encryption_mode"
        elif key == "loggingVariant":
            suggest = "logging_variant"
        elif key == "machineType":
            suggest = "machine_type"
        elif key == "maxRunDuration":
            suggest = "max_run_duration"
        elif key == "minCpuPlatform":
            suggest = "min_cpu_platform"
        elif key == "nodeGroup":
            suggest = "node_group"
        elif key == "oauthScopes":
            suggest = "oauth_scopes"
        elif key == "reservationAffinity":
            suggest = "reservation_affinity"
        elif key == "resourceLabels":
            suggest = "resource_labels"
        elif key == "resourceManagerTags":
            suggest = "resource_manager_tags"
        elif key == "sandboxConfig":
            suggest = "sandbox_config"
        elif key == "secondaryBootDisks":
            suggest = "secondary_boot_disks"
        elif key == "serviceAccount":
            suggest = "service_account"
        elif key == "shieldedInstanceConfig":
            suggest = "shielded_instance_config"
        elif key == "soleTenantConfig":
            suggest = "sole_tenant_config"
        elif key == "storagePools":
            suggest = "storage_pools"
        elif key == "windowsNodeConfig":
            suggest = "windows_node_config"
        elif key == "workloadMetadataConfig":
            suggest = "workload_metadata_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 advanced_machine_features: Optional['outputs.NodePoolNodeConfigAdvancedMachineFeatures'] = None,
                 boot_disk: Optional['outputs.NodePoolNodeConfigBootDisk'] = None,
                 boot_disk_kms_key: Optional[_builtins.str] = None,
                 confidential_nodes: Optional['outputs.NodePoolNodeConfigConfidentialNodes'] = None,
                 containerd_config: Optional['outputs.NodePoolNodeConfigContainerdConfig'] = None,
                 disk_size_gb: Optional[_builtins.int] = None,
                 disk_type: Optional[_builtins.str] = None,
                 effective_taints: Optional[Sequence['outputs.NodePoolNodeConfigEffectiveTaint']] = None,
                 enable_confidential_storage: Optional[_builtins.bool] = None,
                 ephemeral_storage_config: Optional['outputs.NodePoolNodeConfigEphemeralStorageConfig'] = None,
                 ephemeral_storage_local_ssd_config: Optional['outputs.NodePoolNodeConfigEphemeralStorageLocalSsdConfig'] = None,
                 fast_socket: Optional['outputs.NodePoolNodeConfigFastSocket'] = None,
                 flex_start: Optional[_builtins.bool] = None,
                 gcfs_config: Optional['outputs.NodePoolNodeConfigGcfsConfig'] = None,
                 guest_accelerators: Optional[Sequence['outputs.NodePoolNodeConfigGuestAccelerator']] = None,
                 gvnic: Optional['outputs.NodePoolNodeConfigGvnic'] = None,
                 host_maintenance_policy: Optional['outputs.NodePoolNodeConfigHostMaintenancePolicy'] = None,
                 image_type: Optional[_builtins.str] = None,
                 kubelet_config: Optional['outputs.NodePoolNodeConfigKubeletConfig'] = None,
                 labels: Optional[Mapping[str, _builtins.str]] = None,
                 linux_node_config: Optional['outputs.NodePoolNodeConfigLinuxNodeConfig'] = None,
                 local_nvme_ssd_block_config: Optional['outputs.NodePoolNodeConfigLocalNvmeSsdBlockConfig'] = None,
                 local_ssd_count: Optional[_builtins.int] = None,
                 local_ssd_encryption_mode: Optional[_builtins.str] = None,
                 logging_variant: Optional[_builtins.str] = None,
                 machine_type: Optional[_builtins.str] = None,
                 max_run_duration: Optional[_builtins.str] = None,
                 metadata: Optional[Mapping[str, _builtins.str]] = None,
                 min_cpu_platform: Optional[_builtins.str] = None,
                 node_group: Optional[_builtins.str] = None,
                 oauth_scopes: Optional[Sequence[_builtins.str]] = None,
                 preemptible: Optional[_builtins.bool] = None,
                 reservation_affinity: Optional['outputs.NodePoolNodeConfigReservationAffinity'] = None,
                 resource_labels: Optional[Mapping[str, _builtins.str]] = None,
                 resource_manager_tags: Optional[Mapping[str, _builtins.str]] = None,
                 sandbox_config: Optional['outputs.NodePoolNodeConfigSandboxConfig'] = None,
                 secondary_boot_disks: Optional[Sequence['outputs.NodePoolNodeConfigSecondaryBootDisk']] = None,
                 service_account: Optional[_builtins.str] = None,
                 shielded_instance_config: Optional['outputs.NodePoolNodeConfigShieldedInstanceConfig'] = None,
                 sole_tenant_config: Optional['outputs.NodePoolNodeConfigSoleTenantConfig'] = None,
                 spot: Optional[_builtins.bool] = None,
                 storage_pools: Optional[Sequence[_builtins.str]] = None,
                 tags: Optional[Sequence[_builtins.str]] = None,
                 taints: Optional[Sequence['outputs.NodePoolNodeConfigTaint']] = None,
                 windows_node_config: Optional['outputs.NodePoolNodeConfigWindowsNodeConfig'] = None,
                 workload_metadata_config: Optional['outputs.NodePoolNodeConfigWorkloadMetadataConfig'] = None):
        """
        :param 'NodePoolNodeConfigAdvancedMachineFeaturesArgs' advanced_machine_features: Specifies options for controlling advanced machine features.
        :param 'NodePoolNodeConfigBootDiskArgs' boot_disk: Boot disk configuration for node pools nodes.
        :param _builtins.str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        :param 'NodePoolNodeConfigConfidentialNodesArgs' confidential_nodes: Configuration for the confidential nodes feature, which makes nodes run on confidential VMs.
        :param 'NodePoolNodeConfigContainerdConfigArgs' containerd_config: Parameters for containerd configuration.
        :param _builtins.int disk_size_gb: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        :param _builtins.str disk_type: Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        :param Sequence['NodePoolNodeConfigEffectiveTaintArgs'] effective_taints: List of kubernetes taints applied to each node.
        :param _builtins.bool enable_confidential_storage: If enabled boot disks are configured with confidential mode.
        :param 'NodePoolNodeConfigEphemeralStorageConfigArgs' ephemeral_storage_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param 'NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs' ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param 'NodePoolNodeConfigFastSocketArgs' fast_socket: Enable or disable NCCL Fast Socket in the node pool.
        :param _builtins.bool flex_start: Enables Flex Start provisioning model for the node pool
        :param 'NodePoolNodeConfigGcfsConfigArgs' gcfs_config: GCFS configuration for this node.
        :param Sequence['NodePoolNodeConfigGuestAcceleratorArgs'] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
        :param 'NodePoolNodeConfigGvnicArgs' gvnic: Enable or disable gvnic in the node pool.
        :param 'NodePoolNodeConfigHostMaintenancePolicyArgs' host_maintenance_policy: The maintenance policy for the hosts on which the GKE VMs run on.
        :param _builtins.str image_type: The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        :param 'NodePoolNodeConfigKubeletConfigArgs' kubelet_config: Node kubelet configs.
        :param Mapping[str, _builtins.str] labels: The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        :param 'NodePoolNodeConfigLinuxNodeConfigArgs' linux_node_config: Parameters that can be configured on Linux nodes.
        :param 'NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs' local_nvme_ssd_block_config: Parameters for raw-block local NVMe SSDs.
        :param _builtins.int local_ssd_count: The number of local SSD disks to be attached to the node.
        :param _builtins.str local_ssd_encryption_mode: LocalSsdEncryptionMode specified the method used for encrypting the local SSDs attached to the node.
        :param _builtins.str logging_variant: Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        :param _builtins.str machine_type: The name of a Google Compute Engine machine type.
        :param _builtins.str max_run_duration: The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        :param Mapping[str, _builtins.str] metadata: The metadata key/value pairs assigned to instances in the cluster.
        :param _builtins.str min_cpu_platform: Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        :param _builtins.str node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        :param Sequence[_builtins.str] oauth_scopes: The set of Google API scopes to be made available on all of the node VMs.
        :param _builtins.bool preemptible: Whether the nodes are created as preemptible VM instances.
        :param 'NodePoolNodeConfigReservationAffinityArgs' reservation_affinity: The reservation affinity configuration for the node pool.
        :param Mapping[str, _builtins.str] resource_labels: The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        :param Mapping[str, _builtins.str] resource_manager_tags: A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        :param 'NodePoolNodeConfigSandboxConfigArgs' sandbox_config: Sandbox configuration for this node.
        :param Sequence['NodePoolNodeConfigSecondaryBootDiskArgs'] secondary_boot_disks: Secondary boot disks for preloading data or container images.
        :param _builtins.str service_account: The Google Cloud Platform Service Account to be used by the node VMs.
        :param 'NodePoolNodeConfigShieldedInstanceConfigArgs' shielded_instance_config: Shielded Instance options.
        :param 'NodePoolNodeConfigSoleTenantConfigArgs' sole_tenant_config: Node affinity options for sole tenant node pools.
        :param _builtins.bool spot: Whether the nodes are created as spot VM instances.
        :param Sequence[_builtins.str] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param Sequence[_builtins.str] tags: The list of instance tags applied to all nodes.
        :param Sequence['NodePoolNodeConfigTaintArgs'] taints: List of Kubernetes taints to be applied to each node.
        :param 'NodePoolNodeConfigWindowsNodeConfigArgs' windows_node_config: Parameters that can be configured on Windows nodes.
        :param 'NodePoolNodeConfigWorkloadMetadataConfigArgs' workload_metadata_config: The workload metadata configuration for this node.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk is not None:
            pulumi.set(__self__, "boot_disk", boot_disk)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if containerd_config is not None:
            pulumi.set(__self__, "containerd_config", containerd_config)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if effective_taints is not None:
            pulumi.set(__self__, "effective_taints", effective_taints)
        if enable_confidential_storage is not None:
            pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if flex_start is not None:
            pulumi.set(__self__, "flex_start", flex_start)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if local_ssd_encryption_mode is not None:
            pulumi.set(__self__, "local_ssd_encryption_mode", local_ssd_encryption_mode)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if max_run_duration is not None:
            pulumi.set(__self__, "max_run_duration", max_run_duration)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if resource_manager_tags is not None:
            pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if secondary_boot_disks is not None:
            pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if storage_pools is not None:
            pulumi.set(__self__, "storage_pools", storage_pools)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if windows_node_config is not None:
            pulumi.set(__self__, "windows_node_config", windows_node_config)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @_builtins.property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional['outputs.NodePoolNodeConfigAdvancedMachineFeatures']:
        """
        Specifies options for controlling advanced machine features.
        """
        return pulumi.get(self, "advanced_machine_features")

    @_builtins.property
    @pulumi.getter(name="bootDisk")
    def boot_disk(self) -> Optional['outputs.NodePoolNodeConfigBootDisk']:
        """
        Boot disk configuration for node pools nodes.
        """
        return pulumi.get(self, "boot_disk")

    @_builtins.property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[_builtins.str]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @_builtins.property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional['outputs.NodePoolNodeConfigConfidentialNodes']:
        """
        Configuration for the confidential nodes feature, which makes nodes run on confidential VMs.
        """
        return pulumi.get(self, "confidential_nodes")

    @_builtins.property
    @pulumi.getter(name="containerdConfig")
    def containerd_config(self) -> Optional['outputs.NodePoolNodeConfigContainerdConfig']:
        """
        Parameters for containerd configuration.
        """
        return pulumi.get(self, "containerd_config")

    @_builtins.property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[_builtins.int]:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @_builtins.property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[_builtins.str]:
        """
        Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        """
        return pulumi.get(self, "disk_type")

    @_builtins.property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Optional[Sequence['outputs.NodePoolNodeConfigEffectiveTaint']]:
        """
        List of kubernetes taints applied to each node.
        """
        return pulumi.get(self, "effective_taints")

    @_builtins.property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> Optional[_builtins.bool]:
        """
        If enabled boot disks are configured with confidential mode.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @_builtins.property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional['outputs.NodePoolNodeConfigEphemeralStorageConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @_builtins.property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional['outputs.NodePoolNodeConfigEphemeralStorageLocalSsdConfig']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @_builtins.property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional['outputs.NodePoolNodeConfigFastSocket']:
        """
        Enable or disable NCCL Fast Socket in the node pool.
        """
        return pulumi.get(self, "fast_socket")

    @_builtins.property
    @pulumi.getter(name="flexStart")
    def flex_start(self) -> Optional[_builtins.bool]:
        """
        Enables Flex Start provisioning model for the node pool
        """
        return pulumi.get(self, "flex_start")

    @_builtins.property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional['outputs.NodePoolNodeConfigGcfsConfig']:
        """
        GCFS configuration for this node.
        """
        return pulumi.get(self, "gcfs_config")

    @_builtins.property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[Sequence['outputs.NodePoolNodeConfigGuestAccelerator']]:
        """
        List of the type and count of accelerator cards attached to the instance.
        """
        return pulumi.get(self, "guest_accelerators")

    @_builtins.property
    @pulumi.getter
    def gvnic(self) -> Optional['outputs.NodePoolNodeConfigGvnic']:
        """
        Enable or disable gvnic in the node pool.
        """
        return pulumi.get(self, "gvnic")

    @_builtins.property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional['outputs.NodePoolNodeConfigHostMaintenancePolicy']:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policy")

    @_builtins.property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[_builtins.str]:
        """
        The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        """
        return pulumi.get(self, "image_type")

    @_builtins.property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional['outputs.NodePoolNodeConfigKubeletConfig']:
        """
        Node kubelet configs.
        """
        return pulumi.get(self, "kubelet_config")

    @_builtins.property
    @pulumi.getter
    def labels(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        """
        return pulumi.get(self, "labels")

    @_builtins.property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional['outputs.NodePoolNodeConfigLinuxNodeConfig']:
        """
        Parameters that can be configured on Linux nodes.
        """
        return pulumi.get(self, "linux_node_config")

    @_builtins.property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional['outputs.NodePoolNodeConfigLocalNvmeSsdBlockConfig']:
        """
        Parameters for raw-block local NVMe SSDs.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[_builtins.int]:
        """
        The number of local SSD disks to be attached to the node.
        """
        return pulumi.get(self, "local_ssd_count")

    @_builtins.property
    @pulumi.getter(name="localSsdEncryptionMode")
    def local_ssd_encryption_mode(self) -> Optional[_builtins.str]:
        """
        LocalSsdEncryptionMode specified the method used for encrypting the local SSDs attached to the node.
        """
        return pulumi.get(self, "local_ssd_encryption_mode")

    @_builtins.property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[_builtins.str]:
        """
        Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        """
        return pulumi.get(self, "logging_variant")

    @_builtins.property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[_builtins.str]:
        """
        The name of a Google Compute Engine machine type.
        """
        return pulumi.get(self, "machine_type")

    @_builtins.property
    @pulumi.getter(name="maxRunDuration")
    def max_run_duration(self) -> Optional[_builtins.str]:
        """
        The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        """
        return pulumi.get(self, "max_run_duration")

    @_builtins.property
    @pulumi.getter
    def metadata(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The metadata key/value pairs assigned to instances in the cluster.
        """
        return pulumi.get(self, "metadata")

    @_builtins.property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[_builtins.str]:
        """
        Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        """
        return pulumi.get(self, "min_cpu_platform")

    @_builtins.property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[_builtins.str]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        """
        return pulumi.get(self, "node_group")

    @_builtins.property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[Sequence[_builtins.str]]:
        """
        The set of Google API scopes to be made available on all of the node VMs.
        """
        return pulumi.get(self, "oauth_scopes")

    @_builtins.property
    @pulumi.getter
    def preemptible(self) -> Optional[_builtins.bool]:
        """
        Whether the nodes are created as preemptible VM instances.
        """
        return pulumi.get(self, "preemptible")

    @_builtins.property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional['outputs.NodePoolNodeConfigReservationAffinity']:
        """
        The reservation affinity configuration for the node pool.
        """
        return pulumi.get(self, "reservation_affinity")

    @_builtins.property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        """
        return pulumi.get(self, "resource_labels")

    @_builtins.property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        """
        return pulumi.get(self, "resource_manager_tags")

    @_builtins.property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional['outputs.NodePoolNodeConfigSandboxConfig']:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_config")

    @_builtins.property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Optional[Sequence['outputs.NodePoolNodeConfigSecondaryBootDisk']]:
        """
        Secondary boot disks for preloading data or container images.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @_builtins.property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[_builtins.str]:
        """
        The Google Cloud Platform Service Account to be used by the node VMs.
        """
        return pulumi.get(self, "service_account")

    @_builtins.property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional['outputs.NodePoolNodeConfigShieldedInstanceConfig']:
        """
        Shielded Instance options.
        """
        return pulumi.get(self, "shielded_instance_config")

    @_builtins.property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional['outputs.NodePoolNodeConfigSoleTenantConfig']:
        """
        Node affinity options for sole tenant node pools.
        """
        return pulumi.get(self, "sole_tenant_config")

    @_builtins.property
    @pulumi.getter
    def spot(self) -> Optional[_builtins.bool]:
        """
        Whether the nodes are created as spot VM instances.
        """
        return pulumi.get(self, "spot")

    @_builtins.property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Optional[Sequence[_builtins.str]]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Optional[Sequence[_builtins.str]]:
        """
        The list of instance tags applied to all nodes.
        """
        return pulumi.get(self, "tags")

    @_builtins.property
    @pulumi.getter
    def taints(self) -> Optional[Sequence['outputs.NodePoolNodeConfigTaint']]:
        """
        List of Kubernetes taints to be applied to each node.
        """
        return pulumi.get(self, "taints")

    @_builtins.property
    @pulumi.getter(name="windowsNodeConfig")
    def windows_node_config(self) -> Optional['outputs.NodePoolNodeConfigWindowsNodeConfig']:
        """
        Parameters that can be configured on Windows nodes.
        """
        return pulumi.get(self, "windows_node_config")

    @_builtins.property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional['outputs.NodePoolNodeConfigWorkloadMetadataConfig']:
        """
        The workload metadata configuration for this node.
        """
        return pulumi.get(self, "workload_metadata_config")


@pulumi.output_type
class NodePoolNodeConfigAdvancedMachineFeatures(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "threadsPerCore":
            suggest = "threads_per_core"
        elif key == "enableNestedVirtualization":
            suggest = "enable_nested_virtualization"
        elif key == "performanceMonitoringUnit":
            suggest = "performance_monitoring_unit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigAdvancedMachineFeatures. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigAdvancedMachineFeatures.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 threads_per_core: _builtins.int,
                 enable_nested_virtualization: Optional[_builtins.bool] = None,
                 performance_monitoring_unit: Optional[_builtins.str] = None):
        """
        :param _builtins.int threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        :param _builtins.bool enable_nested_virtualization: Whether the node should have nested virtualization enabled.
        :param _builtins.str performance_monitoring_unit: Level of Performance Monitoring Unit (PMU) requested. If unset, no access to the PMU is assumed.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)
        if enable_nested_virtualization is not None:
            pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)
        if performance_monitoring_unit is not None:
            pulumi.set(__self__, "performance_monitoring_unit", performance_monitoring_unit)

    @_builtins.property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> _builtins.int:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")

    @_builtins.property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> Optional[_builtins.bool]:
        """
        Whether the node should have nested virtualization enabled.
        """
        return pulumi.get(self, "enable_nested_virtualization")

    @_builtins.property
    @pulumi.getter(name="performanceMonitoringUnit")
    def performance_monitoring_unit(self) -> Optional[_builtins.str]:
        """
        Level of Performance Monitoring Unit (PMU) requested. If unset, no access to the PMU is assumed.
        """
        return pulumi.get(self, "performance_monitoring_unit")


@pulumi.output_type
class NodePoolNodeConfigBootDisk(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "diskType":
            suggest = "disk_type"
        elif key == "provisionedIops":
            suggest = "provisioned_iops"
        elif key == "provisionedThroughput":
            suggest = "provisioned_throughput"
        elif key == "sizeGb":
            suggest = "size_gb"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigBootDisk. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigBootDisk.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigBootDisk.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disk_type: Optional[_builtins.str] = None,
                 provisioned_iops: Optional[_builtins.int] = None,
                 provisioned_throughput: Optional[_builtins.int] = None,
                 size_gb: Optional[_builtins.int] = None):
        """
        :param _builtins.str disk_type: Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        :param _builtins.int provisioned_iops: Configured IOPs provisioning. Only valid with disk type hyperdisk-balanced.
        :param _builtins.int provisioned_throughput: Configured throughput provisioning. Only valid with disk type hyperdisk-balanced.
        :param _builtins.int size_gb: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if provisioned_iops is not None:
            pulumi.set(__self__, "provisioned_iops", provisioned_iops)
        if provisioned_throughput is not None:
            pulumi.set(__self__, "provisioned_throughput", provisioned_throughput)
        if size_gb is not None:
            pulumi.set(__self__, "size_gb", size_gb)

    @_builtins.property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[_builtins.str]:
        """
        Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        """
        return pulumi.get(self, "disk_type")

    @_builtins.property
    @pulumi.getter(name="provisionedIops")
    def provisioned_iops(self) -> Optional[_builtins.int]:
        """
        Configured IOPs provisioning. Only valid with disk type hyperdisk-balanced.
        """
        return pulumi.get(self, "provisioned_iops")

    @_builtins.property
    @pulumi.getter(name="provisionedThroughput")
    def provisioned_throughput(self) -> Optional[_builtins.int]:
        """
        Configured throughput provisioning. Only valid with disk type hyperdisk-balanced.
        """
        return pulumi.get(self, "provisioned_throughput")

    @_builtins.property
    @pulumi.getter(name="sizeGb")
    def size_gb(self) -> Optional[_builtins.int]:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        return pulumi.get(self, "size_gb")


@pulumi.output_type
class NodePoolNodeConfigConfidentialNodes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "confidentialInstanceType":
            suggest = "confidential_instance_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigConfidentialNodes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigConfidentialNodes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigConfidentialNodes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 confidential_instance_type: Optional[_builtins.str] = None):
        """
        :param _builtins.bool enabled: Whether Confidential Nodes feature is enabled for all nodes in this pool.
        :param _builtins.str confidential_instance_type: Defines the type of technology used by the confidential node.
        """
        pulumi.set(__self__, "enabled", enabled)
        if confidential_instance_type is not None:
            pulumi.set(__self__, "confidential_instance_type", confidential_instance_type)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="confidentialInstanceType")
    def confidential_instance_type(self) -> Optional[_builtins.str]:
        """
        Defines the type of technology used by the confidential node.
        """
        return pulumi.get(self, "confidential_instance_type")


@pulumi.output_type
class NodePoolNodeConfigContainerdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateRegistryAccessConfig":
            suggest = "private_registry_access_config"
        elif key == "writableCgroups":
            suggest = "writable_cgroups"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigContainerdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigContainerdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigContainerdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 private_registry_access_config: Optional['outputs.NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig'] = None,
                 writable_cgroups: Optional['outputs.NodePoolNodeConfigContainerdConfigWritableCgroups'] = None):
        """
        :param 'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs' private_registry_access_config: Parameters for private container registries configuration.
        :param 'NodePoolNodeConfigContainerdConfigWritableCgroupsArgs' writable_cgroups: Parameters for writable cgroups configuration.
        """
        if private_registry_access_config is not None:
            pulumi.set(__self__, "private_registry_access_config", private_registry_access_config)
        if writable_cgroups is not None:
            pulumi.set(__self__, "writable_cgroups", writable_cgroups)

    @_builtins.property
    @pulumi.getter(name="privateRegistryAccessConfig")
    def private_registry_access_config(self) -> Optional['outputs.NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig']:
        """
        Parameters for private container registries configuration.
        """
        return pulumi.get(self, "private_registry_access_config")

    @_builtins.property
    @pulumi.getter(name="writableCgroups")
    def writable_cgroups(self) -> Optional['outputs.NodePoolNodeConfigContainerdConfigWritableCgroups']:
        """
        Parameters for writable cgroups configuration.
        """
        return pulumi.get(self, "writable_cgroups")


@pulumi.output_type
class NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "certificateAuthorityDomainConfigs":
            suggest = "certificate_authority_domain_configs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 certificate_authority_domain_configs: Optional[Sequence['outputs.NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']] = None):
        """
        :param _builtins.bool enabled: Whether or not private registries are configured.
        :param Sequence['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: Parameters for configuring CA certificate and domains.
        """
        pulumi.set(__self__, "enabled", enabled)
        if certificate_authority_domain_configs is not None:
            pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not private registries are configured.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Optional[Sequence['outputs.NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig']]:
        """
        Parameters for configuring CA certificate and domains.
        """
        return pulumi.get(self, "certificate_authority_domain_configs")


@pulumi.output_type
class NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gcpSecretManagerCertificateConfig":
            suggest = "gcp_secret_manager_certificate_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 fqdns: Sequence[_builtins.str],
                 gcp_secret_manager_certificate_config: 'outputs.NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig'):
        """
        :param Sequence[_builtins.str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param 'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs' gcp_secret_manager_certificate_config: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_config", gcp_secret_manager_certificate_config)

    @_builtins.property
    @pulumi.getter
    def fqdns(self) -> Sequence[_builtins.str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @_builtins.property
    @pulumi.getter(name="gcpSecretManagerCertificateConfig")
    def gcp_secret_manager_certificate_config(self) -> 'outputs.NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig':
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_config")


@pulumi.output_type
class NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "secretUri":
            suggest = "secret_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 secret_uri: _builtins.str):
        """
        :param _builtins.str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @_builtins.property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> _builtins.str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class NodePoolNodeConfigContainerdConfigWritableCgroups(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether writable cgroups are enabled.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether writable cgroups are enabled.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolNodeConfigEffectiveTaint(dict):
    def __init__(__self__, *,
                 effect: Optional[_builtins.str] = None,
                 key: Optional[_builtins.str] = None,
                 value: Optional[_builtins.str] = None):
        """
        :param _builtins.str effect: Effect for taint.
        :param _builtins.str key: Key for taint.
        :param _builtins.str value: Value for taint.
        """
        if effect is not None:
            pulumi.set(__self__, "effect", effect)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def effect(self) -> Optional[_builtins.str]:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @_builtins.property
    @pulumi.getter
    def key(self) -> Optional[_builtins.str]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def value(self) -> Optional[_builtins.str]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class NodePoolNodeConfigEphemeralStorageConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigEphemeralStorageConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigEphemeralStorageConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: _builtins.int):
        """
        :param _builtins.int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class NodePoolNodeConfigEphemeralStorageLocalSsdConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "dataCacheCount":
            suggest = "data_cache_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigEphemeralStorageLocalSsdConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigEphemeralStorageLocalSsdConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: _builtins.int,
                 data_cache_count: Optional[_builtins.int] = None):
        """
        :param _builtins.int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        :param _builtins.int data_cache_count: Number of local SSDs to be utilized for GKE Data Cache. Uses NVMe interfaces.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if data_cache_count is not None:
            pulumi.set(__self__, "data_cache_count", data_cache_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")

    @_builtins.property
    @pulumi.getter(name="dataCacheCount")
    def data_cache_count(self) -> Optional[_builtins.int]:
        """
        Number of local SSDs to be utilized for GKE Data Cache. Uses NVMe interfaces.
        """
        return pulumi.get(self, "data_cache_count")


@pulumi.output_type
class NodePoolNodeConfigFastSocket(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolNodeConfigGcfsConfig(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not GCFS is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not GCFS is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolNodeConfigGuestAccelerator(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverInstallationConfig":
            suggest = "gpu_driver_installation_config"
        elif key == "gpuPartitionSize":
            suggest = "gpu_partition_size"
        elif key == "gpuSharingConfig":
            suggest = "gpu_sharing_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigGuestAccelerator. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigGuestAccelerator.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigGuestAccelerator.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 count: _builtins.int,
                 type: _builtins.str,
                 gpu_driver_installation_config: Optional['outputs.NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig'] = None,
                 gpu_partition_size: Optional[_builtins.str] = None,
                 gpu_sharing_config: Optional['outputs.NodePoolNodeConfigGuestAcceleratorGpuSharingConfig'] = None):
        """
        :param _builtins.int count: The number of the accelerator cards exposed to an instance.
        :param _builtins.str type: The accelerator type resource name.
        :param 'NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs' gpu_driver_installation_config: Configuration for auto installation of GPU driver.
        :param _builtins.str gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        :param 'NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs' gpu_sharing_config: Configuration for GPU sharing.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @_builtins.property
    @pulumi.getter
    def count(self) -> _builtins.int:
        """
        The number of the accelerator cards exposed to an instance.
        """
        return pulumi.get(self, "count")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        The accelerator type resource name.
        """
        return pulumi.get(self, "type")

    @_builtins.property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional['outputs.NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig']:
        """
        Configuration for auto installation of GPU driver.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @_builtins.property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[_builtins.str]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        """
        return pulumi.get(self, "gpu_partition_size")

    @_builtins.property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional['outputs.NodePoolNodeConfigGuestAcceleratorGpuSharingConfig']:
        """
        Configuration for GPU sharing.
        """
        return pulumi.get(self, "gpu_sharing_config")


@pulumi.output_type
class NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuDriverVersion":
            suggest = "gpu_driver_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_driver_version: _builtins.str):
        """
        :param _builtins.str gpu_driver_version: Mode for how the GPU driver is installed.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @_builtins.property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> _builtins.str:
        """
        Mode for how the GPU driver is installed.
        """
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class NodePoolNodeConfigGuestAcceleratorGpuSharingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gpuSharingStrategy":
            suggest = "gpu_sharing_strategy"
        elif key == "maxSharedClientsPerGpu":
            suggest = "max_shared_clients_per_gpu"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigGuestAcceleratorGpuSharingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigGuestAcceleratorGpuSharingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gpu_sharing_strategy: _builtins.str,
                 max_shared_clients_per_gpu: _builtins.int):
        """
        :param _builtins.str gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        :param _builtins.int max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @_builtins.property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> _builtins.str:
        """
        The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @_builtins.property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> _builtins.int:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class NodePoolNodeConfigGvnic(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not gvnic is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not gvnic is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolNodeConfigHostMaintenancePolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maintenanceInterval":
            suggest = "maintenance_interval"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigHostMaintenancePolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigHostMaintenancePolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 maintenance_interval: _builtins.str):
        """
        :param _builtins.str maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @_builtins.property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> _builtins.str:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class NodePoolNodeConfigKubeletConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowedUnsafeSysctls":
            suggest = "allowed_unsafe_sysctls"
        elif key == "containerLogMaxFiles":
            suggest = "container_log_max_files"
        elif key == "containerLogMaxSize":
            suggest = "container_log_max_size"
        elif key == "cpuCfsQuota":
            suggest = "cpu_cfs_quota"
        elif key == "cpuCfsQuotaPeriod":
            suggest = "cpu_cfs_quota_period"
        elif key == "cpuManagerPolicy":
            suggest = "cpu_manager_policy"
        elif key == "evictionMaxPodGracePeriodSeconds":
            suggest = "eviction_max_pod_grace_period_seconds"
        elif key == "evictionMinimumReclaim":
            suggest = "eviction_minimum_reclaim"
        elif key == "evictionSoft":
            suggest = "eviction_soft"
        elif key == "evictionSoftGracePeriod":
            suggest = "eviction_soft_grace_period"
        elif key == "imageGcHighThresholdPercent":
            suggest = "image_gc_high_threshold_percent"
        elif key == "imageGcLowThresholdPercent":
            suggest = "image_gc_low_threshold_percent"
        elif key == "imageMaximumGcAge":
            suggest = "image_maximum_gc_age"
        elif key == "imageMinimumGcAge":
            suggest = "image_minimum_gc_age"
        elif key == "insecureKubeletReadonlyPortEnabled":
            suggest = "insecure_kubelet_readonly_port_enabled"
        elif key == "maxParallelImagePulls":
            suggest = "max_parallel_image_pulls"
        elif key == "memoryManager":
            suggest = "memory_manager"
        elif key == "podPidsLimit":
            suggest = "pod_pids_limit"
        elif key == "singleProcessOomKill":
            suggest = "single_process_oom_kill"
        elif key == "topologyManager":
            suggest = "topology_manager"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigKubeletConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigKubeletConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigKubeletConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allowed_unsafe_sysctls: Optional[Sequence[_builtins.str]] = None,
                 container_log_max_files: Optional[_builtins.int] = None,
                 container_log_max_size: Optional[_builtins.str] = None,
                 cpu_cfs_quota: Optional[_builtins.bool] = None,
                 cpu_cfs_quota_period: Optional[_builtins.str] = None,
                 cpu_manager_policy: Optional[_builtins.str] = None,
                 eviction_max_pod_grace_period_seconds: Optional[_builtins.int] = None,
                 eviction_minimum_reclaim: Optional['outputs.NodePoolNodeConfigKubeletConfigEvictionMinimumReclaim'] = None,
                 eviction_soft: Optional['outputs.NodePoolNodeConfigKubeletConfigEvictionSoft'] = None,
                 eviction_soft_grace_period: Optional['outputs.NodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod'] = None,
                 image_gc_high_threshold_percent: Optional[_builtins.int] = None,
                 image_gc_low_threshold_percent: Optional[_builtins.int] = None,
                 image_maximum_gc_age: Optional[_builtins.str] = None,
                 image_minimum_gc_age: Optional[_builtins.str] = None,
                 insecure_kubelet_readonly_port_enabled: Optional[_builtins.str] = None,
                 max_parallel_image_pulls: Optional[_builtins.int] = None,
                 memory_manager: Optional['outputs.NodePoolNodeConfigKubeletConfigMemoryManager'] = None,
                 pod_pids_limit: Optional[_builtins.int] = None,
                 single_process_oom_kill: Optional[_builtins.bool] = None,
                 topology_manager: Optional['outputs.NodePoolNodeConfigKubeletConfigTopologyManager'] = None):
        """
        :param Sequence[_builtins.str] allowed_unsafe_sysctls: Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods.
        :param _builtins.int container_log_max_files: Defines the maximum number of container log files that can be present for a container.
        :param _builtins.str container_log_max_size: Defines the maximum size of the container log file before it is rotated.
        :param _builtins.bool cpu_cfs_quota: Enable CPU CFS quota enforcement for containers that specify CPU limits.
        :param _builtins.str cpu_cfs_quota_period: Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        :param _builtins.str cpu_manager_policy: Control the CPU management policy on the node.
        :param _builtins.int eviction_max_pod_grace_period_seconds: Defines the maximum allowed grace period (in seconds) to use when terminating pods in response to a soft eviction threshold being met.
        :param 'NodePoolNodeConfigKubeletConfigEvictionMinimumReclaimArgs' eviction_minimum_reclaim: Defines a map of signal names to percentage that defines minimum reclaims. It describes the minimum amount of a given resource the kubelet will reclaim when performing a pod eviction.
        :param 'NodePoolNodeConfigKubeletConfigEvictionSoftArgs' eviction_soft: Defines a map of signal names to quantities or percentage that defines soft eviction thresholds.
        :param 'NodePoolNodeConfigKubeletConfigEvictionSoftGracePeriodArgs' eviction_soft_grace_period: Defines a map of signal names to durations that defines grace periods for soft eviction thresholds. Each soft eviction threshold must have a corresponding grace period.
        :param _builtins.int image_gc_high_threshold_percent: Defines the percent of disk usage after which image garbage collection is always run.
        :param _builtins.int image_gc_low_threshold_percent: Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to.
        :param _builtins.str image_maximum_gc_age: Defines the maximum age an image can be unused before it is garbage collected.
        :param _builtins.str image_minimum_gc_age: Defines the minimum age for an unused image before it is garbage collected.
        :param _builtins.str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param _builtins.int max_parallel_image_pulls: Set the maximum number of image pulls in parallel.
        :param 'NodePoolNodeConfigKubeletConfigMemoryManagerArgs' memory_manager: Configuration for the Memory Manager on the node. The memory manager optimizes memory and hugepages allocation for pods, especially those in the Guaranteed QoS class, by influencing NUMA affinity.
        :param _builtins.int pod_pids_limit: Controls the maximum number of processes allowed to run in a pod.
        :param _builtins.bool single_process_oom_kill: Defines whether to enable single process OOM killer.
        :param 'NodePoolNodeConfigKubeletConfigTopologyManagerArgs' topology_manager: Configuration for the Topology Manager on the node. The Topology Manager aligns CPU, memory, and device resources on a node to optimize performance, especially for NUMA-aware workloads, by ensuring resource co-location.
        """
        if allowed_unsafe_sysctls is not None:
            pulumi.set(__self__, "allowed_unsafe_sysctls", allowed_unsafe_sysctls)
        if container_log_max_files is not None:
            pulumi.set(__self__, "container_log_max_files", container_log_max_files)
        if container_log_max_size is not None:
            pulumi.set(__self__, "container_log_max_size", container_log_max_size)
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if cpu_manager_policy is not None:
            pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if eviction_max_pod_grace_period_seconds is not None:
            pulumi.set(__self__, "eviction_max_pod_grace_period_seconds", eviction_max_pod_grace_period_seconds)
        if eviction_minimum_reclaim is not None:
            pulumi.set(__self__, "eviction_minimum_reclaim", eviction_minimum_reclaim)
        if eviction_soft is not None:
            pulumi.set(__self__, "eviction_soft", eviction_soft)
        if eviction_soft_grace_period is not None:
            pulumi.set(__self__, "eviction_soft_grace_period", eviction_soft_grace_period)
        if image_gc_high_threshold_percent is not None:
            pulumi.set(__self__, "image_gc_high_threshold_percent", image_gc_high_threshold_percent)
        if image_gc_low_threshold_percent is not None:
            pulumi.set(__self__, "image_gc_low_threshold_percent", image_gc_low_threshold_percent)
        if image_maximum_gc_age is not None:
            pulumi.set(__self__, "image_maximum_gc_age", image_maximum_gc_age)
        if image_minimum_gc_age is not None:
            pulumi.set(__self__, "image_minimum_gc_age", image_minimum_gc_age)
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        if max_parallel_image_pulls is not None:
            pulumi.set(__self__, "max_parallel_image_pulls", max_parallel_image_pulls)
        if memory_manager is not None:
            pulumi.set(__self__, "memory_manager", memory_manager)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)
        if single_process_oom_kill is not None:
            pulumi.set(__self__, "single_process_oom_kill", single_process_oom_kill)
        if topology_manager is not None:
            pulumi.set(__self__, "topology_manager", topology_manager)

    @_builtins.property
    @pulumi.getter(name="allowedUnsafeSysctls")
    def allowed_unsafe_sysctls(self) -> Optional[Sequence[_builtins.str]]:
        """
        Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods.
        """
        return pulumi.get(self, "allowed_unsafe_sysctls")

    @_builtins.property
    @pulumi.getter(name="containerLogMaxFiles")
    def container_log_max_files(self) -> Optional[_builtins.int]:
        """
        Defines the maximum number of container log files that can be present for a container.
        """
        return pulumi.get(self, "container_log_max_files")

    @_builtins.property
    @pulumi.getter(name="containerLogMaxSize")
    def container_log_max_size(self) -> Optional[_builtins.str]:
        """
        Defines the maximum size of the container log file before it is rotated.
        """
        return pulumi.get(self, "container_log_max_size")

    @_builtins.property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[_builtins.bool]:
        """
        Enable CPU CFS quota enforcement for containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @_builtins.property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[_builtins.str]:
        """
        Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @_builtins.property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> Optional[_builtins.str]:
        """
        Control the CPU management policy on the node.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @_builtins.property
    @pulumi.getter(name="evictionMaxPodGracePeriodSeconds")
    def eviction_max_pod_grace_period_seconds(self) -> Optional[_builtins.int]:
        """
        Defines the maximum allowed grace period (in seconds) to use when terminating pods in response to a soft eviction threshold being met.
        """
        return pulumi.get(self, "eviction_max_pod_grace_period_seconds")

    @_builtins.property
    @pulumi.getter(name="evictionMinimumReclaim")
    def eviction_minimum_reclaim(self) -> Optional['outputs.NodePoolNodeConfigKubeletConfigEvictionMinimumReclaim']:
        """
        Defines a map of signal names to percentage that defines minimum reclaims. It describes the minimum amount of a given resource the kubelet will reclaim when performing a pod eviction.
        """
        return pulumi.get(self, "eviction_minimum_reclaim")

    @_builtins.property
    @pulumi.getter(name="evictionSoft")
    def eviction_soft(self) -> Optional['outputs.NodePoolNodeConfigKubeletConfigEvictionSoft']:
        """
        Defines a map of signal names to quantities or percentage that defines soft eviction thresholds.
        """
        return pulumi.get(self, "eviction_soft")

    @_builtins.property
    @pulumi.getter(name="evictionSoftGracePeriod")
    def eviction_soft_grace_period(self) -> Optional['outputs.NodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod']:
        """
        Defines a map of signal names to durations that defines grace periods for soft eviction thresholds. Each soft eviction threshold must have a corresponding grace period.
        """
        return pulumi.get(self, "eviction_soft_grace_period")

    @_builtins.property
    @pulumi.getter(name="imageGcHighThresholdPercent")
    def image_gc_high_threshold_percent(self) -> Optional[_builtins.int]:
        """
        Defines the percent of disk usage after which image garbage collection is always run.
        """
        return pulumi.get(self, "image_gc_high_threshold_percent")

    @_builtins.property
    @pulumi.getter(name="imageGcLowThresholdPercent")
    def image_gc_low_threshold_percent(self) -> Optional[_builtins.int]:
        """
        Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to.
        """
        return pulumi.get(self, "image_gc_low_threshold_percent")

    @_builtins.property
    @pulumi.getter(name="imageMaximumGcAge")
    def image_maximum_gc_age(self) -> Optional[_builtins.str]:
        """
        Defines the maximum age an image can be unused before it is garbage collected.
        """
        return pulumi.get(self, "image_maximum_gc_age")

    @_builtins.property
    @pulumi.getter(name="imageMinimumGcAge")
    def image_minimum_gc_age(self) -> Optional[_builtins.str]:
        """
        Defines the minimum age for an unused image before it is garbage collected.
        """
        return pulumi.get(self, "image_minimum_gc_age")

    @_builtins.property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[_builtins.str]:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @_builtins.property
    @pulumi.getter(name="maxParallelImagePulls")
    def max_parallel_image_pulls(self) -> Optional[_builtins.int]:
        """
        Set the maximum number of image pulls in parallel.
        """
        return pulumi.get(self, "max_parallel_image_pulls")

    @_builtins.property
    @pulumi.getter(name="memoryManager")
    def memory_manager(self) -> Optional['outputs.NodePoolNodeConfigKubeletConfigMemoryManager']:
        """
        Configuration for the Memory Manager on the node. The memory manager optimizes memory and hugepages allocation for pods, especially those in the Guaranteed QoS class, by influencing NUMA affinity.
        """
        return pulumi.get(self, "memory_manager")

    @_builtins.property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[_builtins.int]:
        """
        Controls the maximum number of processes allowed to run in a pod.
        """
        return pulumi.get(self, "pod_pids_limit")

    @_builtins.property
    @pulumi.getter(name="singleProcessOomKill")
    def single_process_oom_kill(self) -> Optional[_builtins.bool]:
        """
        Defines whether to enable single process OOM killer.
        """
        return pulumi.get(self, "single_process_oom_kill")

    @_builtins.property
    @pulumi.getter(name="topologyManager")
    def topology_manager(self) -> Optional['outputs.NodePoolNodeConfigKubeletConfigTopologyManager']:
        """
        Configuration for the Topology Manager on the node. The Topology Manager aligns CPU, memory, and device resources on a node to optimize performance, especially for NUMA-aware workloads, by ensuring resource co-location.
        """
        return pulumi.get(self, "topology_manager")


@pulumi.output_type
class NodePoolNodeConfigKubeletConfigEvictionMinimumReclaim(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "imagefsAvailable":
            suggest = "imagefs_available"
        elif key == "imagefsInodesFree":
            suggest = "imagefs_inodes_free"
        elif key == "memoryAvailable":
            suggest = "memory_available"
        elif key == "nodefsAvailable":
            suggest = "nodefs_available"
        elif key == "nodefsInodesFree":
            suggest = "nodefs_inodes_free"
        elif key == "pidAvailable":
            suggest = "pid_available"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigKubeletConfigEvictionMinimumReclaim. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigKubeletConfigEvictionMinimumReclaim.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigKubeletConfigEvictionMinimumReclaim.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 imagefs_available: Optional[_builtins.str] = None,
                 imagefs_inodes_free: Optional[_builtins.str] = None,
                 memory_available: Optional[_builtins.str] = None,
                 nodefs_available: Optional[_builtins.str] = None,
                 nodefs_inodes_free: Optional[_builtins.str] = None,
                 pid_available: Optional[_builtins.str] = None):
        """
        :param _builtins.str imagefs_available: Defines percentage of minimum reclaim for imagefs.available.
        :param _builtins.str imagefs_inodes_free: Defines percentage of minimum reclaim for imagefs.inodesFree.
        :param _builtins.str memory_available: Defines percentage of minimum reclaim for memory.available.
        :param _builtins.str nodefs_available: Defines percentage of minimum reclaim for nodefs.available.
        :param _builtins.str nodefs_inodes_free: Defines percentage of minimum reclaim for nodefs.inodesFree.
        :param _builtins.str pid_available: Defines percentage of minimum reclaim for pid.available.
        """
        if imagefs_available is not None:
            pulumi.set(__self__, "imagefs_available", imagefs_available)
        if imagefs_inodes_free is not None:
            pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        if memory_available is not None:
            pulumi.set(__self__, "memory_available", memory_available)
        if nodefs_available is not None:
            pulumi.set(__self__, "nodefs_available", nodefs_available)
        if nodefs_inodes_free is not None:
            pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        if pid_available is not None:
            pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for imagefs.available.
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for imagefs.inodesFree.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for memory.available.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for nodefs.available.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for nodefs.inodesFree.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of minimum reclaim for pid.available.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class NodePoolNodeConfigKubeletConfigEvictionSoft(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "imagefsAvailable":
            suggest = "imagefs_available"
        elif key == "imagefsInodesFree":
            suggest = "imagefs_inodes_free"
        elif key == "memoryAvailable":
            suggest = "memory_available"
        elif key == "nodefsAvailable":
            suggest = "nodefs_available"
        elif key == "nodefsInodesFree":
            suggest = "nodefs_inodes_free"
        elif key == "pidAvailable":
            suggest = "pid_available"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigKubeletConfigEvictionSoft. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigKubeletConfigEvictionSoft.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigKubeletConfigEvictionSoft.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 imagefs_available: Optional[_builtins.str] = None,
                 imagefs_inodes_free: Optional[_builtins.str] = None,
                 memory_available: Optional[_builtins.str] = None,
                 nodefs_available: Optional[_builtins.str] = None,
                 nodefs_inodes_free: Optional[_builtins.str] = None,
                 pid_available: Optional[_builtins.str] = None):
        """
        :param _builtins.str imagefs_available: Defines percentage of soft eviction threshold for imagefs.available.
        :param _builtins.str imagefs_inodes_free: Defines percentage of soft eviction threshold for imagefs.inodesFree.
        :param _builtins.str memory_available: Defines quantity of soft eviction threshold for memory.available.
        :param _builtins.str nodefs_available: Defines percentage of soft eviction threshold for nodefs.available.
        :param _builtins.str nodefs_inodes_free: Defines percentage of soft eviction threshold for nodefs.inodesFree.
        :param _builtins.str pid_available: Defines percentage of soft eviction threshold for pid.available.
        """
        if imagefs_available is not None:
            pulumi.set(__self__, "imagefs_available", imagefs_available)
        if imagefs_inodes_free is not None:
            pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        if memory_available is not None:
            pulumi.set(__self__, "memory_available", memory_available)
        if nodefs_available is not None:
            pulumi.set(__self__, "nodefs_available", nodefs_available)
        if nodefs_inodes_free is not None:
            pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        if pid_available is not None:
            pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for imagefs.available.
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for imagefs.inodesFree.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> Optional[_builtins.str]:
        """
        Defines quantity of soft eviction threshold for memory.available.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for nodefs.available.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for nodefs.inodesFree.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> Optional[_builtins.str]:
        """
        Defines percentage of soft eviction threshold for pid.available.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class NodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "imagefsAvailable":
            suggest = "imagefs_available"
        elif key == "imagefsInodesFree":
            suggest = "imagefs_inodes_free"
        elif key == "memoryAvailable":
            suggest = "memory_available"
        elif key == "nodefsAvailable":
            suggest = "nodefs_available"
        elif key == "nodefsInodesFree":
            suggest = "nodefs_inodes_free"
        elif key == "pidAvailable":
            suggest = "pid_available"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigKubeletConfigEvictionSoftGracePeriod.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 imagefs_available: Optional[_builtins.str] = None,
                 imagefs_inodes_free: Optional[_builtins.str] = None,
                 memory_available: Optional[_builtins.str] = None,
                 nodefs_available: Optional[_builtins.str] = None,
                 nodefs_inodes_free: Optional[_builtins.str] = None,
                 pid_available: Optional[_builtins.str] = None):
        """
        :param _builtins.str imagefs_available: Defines grace period for the imagefs.available soft eviction threshold
        :param _builtins.str imagefs_inodes_free: Defines grace period for the imagefs.inodesFree soft eviction threshold.
        :param _builtins.str memory_available: Defines grace period for the memory.available soft eviction threshold.
        :param _builtins.str nodefs_available: Defines grace period for the nodefs.available soft eviction threshold.
        :param _builtins.str nodefs_inodes_free: Defines grace period for the nodefs.inodesFree soft eviction threshold.
        :param _builtins.str pid_available: Defines grace period for the pid.available soft eviction threshold.
        """
        if imagefs_available is not None:
            pulumi.set(__self__, "imagefs_available", imagefs_available)
        if imagefs_inodes_free is not None:
            pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        if memory_available is not None:
            pulumi.set(__self__, "memory_available", memory_available)
        if nodefs_available is not None:
            pulumi.set(__self__, "nodefs_available", nodefs_available)
        if nodefs_inodes_free is not None:
            pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        if pid_available is not None:
            pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the imagefs.available soft eviction threshold
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the imagefs.inodesFree soft eviction threshold.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the memory.available soft eviction threshold.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the nodefs.available soft eviction threshold.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the nodefs.inodesFree soft eviction threshold.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> Optional[_builtins.str]:
        """
        Defines grace period for the pid.available soft eviction threshold.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class NodePoolNodeConfigKubeletConfigMemoryManager(dict):
    def __init__(__self__, *,
                 policy: Optional[_builtins.str] = None):
        """
        :param _builtins.str policy: The Memory Manager policy to use. This policy guides how memory and hugepages are allocated and managed for pods on the node, influencing NUMA affinity.
        """
        if policy is not None:
            pulumi.set(__self__, "policy", policy)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> Optional[_builtins.str]:
        """
        The Memory Manager policy to use. This policy guides how memory and hugepages are allocated and managed for pods on the node, influencing NUMA affinity.
        """
        return pulumi.get(self, "policy")


@pulumi.output_type
class NodePoolNodeConfigKubeletConfigTopologyManager(dict):
    def __init__(__self__, *,
                 policy: Optional[_builtins.str] = None,
                 scope: Optional[_builtins.str] = None):
        """
        :param _builtins.str policy: The Topology Manager policy to use. This policy dictates how resource alignment is handled on the node.
        :param _builtins.str scope: The Topology Manager scope, defining the granularity at which policy decisions are applied. Valid values are "container" (resources are aligned per container within a pod) or "pod" (resources are aligned for the entire pod).
        """
        if policy is not None:
            pulumi.set(__self__, "policy", policy)
        if scope is not None:
            pulumi.set(__self__, "scope", scope)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> Optional[_builtins.str]:
        """
        The Topology Manager policy to use. This policy dictates how resource alignment is handled on the node.
        """
        return pulumi.get(self, "policy")

    @_builtins.property
    @pulumi.getter
    def scope(self) -> Optional[_builtins.str]:
        """
        The Topology Manager scope, defining the granularity at which policy decisions are applied. Valid values are "container" (resources are aligned per container within a pod) or "pod" (resources are aligned for the entire pod).
        """
        return pulumi.get(self, "scope")


@pulumi.output_type
class NodePoolNodeConfigLinuxNodeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cgroupMode":
            suggest = "cgroup_mode"
        elif key == "hugepagesConfig":
            suggest = "hugepages_config"
        elif key == "nodeKernelModuleLoading":
            suggest = "node_kernel_module_loading"
        elif key == "transparentHugepageDefrag":
            suggest = "transparent_hugepage_defrag"
        elif key == "transparentHugepageEnabled":
            suggest = "transparent_hugepage_enabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigLinuxNodeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigLinuxNodeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigLinuxNodeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cgroup_mode: Optional[_builtins.str] = None,
                 hugepages_config: Optional['outputs.NodePoolNodeConfigLinuxNodeConfigHugepagesConfig'] = None,
                 node_kernel_module_loading: Optional['outputs.NodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoading'] = None,
                 sysctls: Optional[Mapping[str, _builtins.str]] = None,
                 transparent_hugepage_defrag: Optional[_builtins.str] = None,
                 transparent_hugepage_enabled: Optional[_builtins.str] = None):
        """
        :param _builtins.str cgroup_mode: cgroupMode specifies the cgroup mode to be used on the node.
        :param 'NodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs' hugepages_config: Amounts for 2M and 1G hugepages.
        :param 'NodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoadingArgs' node_kernel_module_loading: The settings for kernel module loading.
        :param Mapping[str, _builtins.str] sysctls: The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        :param _builtins.str transparent_hugepage_defrag: The Linux kernel transparent hugepage defrag setting.
        :param _builtins.str transparent_hugepage_enabled: The Linux kernel transparent hugepage setting.
        """
        if cgroup_mode is not None:
            pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        if hugepages_config is not None:
            pulumi.set(__self__, "hugepages_config", hugepages_config)
        if node_kernel_module_loading is not None:
            pulumi.set(__self__, "node_kernel_module_loading", node_kernel_module_loading)
        if sysctls is not None:
            pulumi.set(__self__, "sysctls", sysctls)
        if transparent_hugepage_defrag is not None:
            pulumi.set(__self__, "transparent_hugepage_defrag", transparent_hugepage_defrag)
        if transparent_hugepage_enabled is not None:
            pulumi.set(__self__, "transparent_hugepage_enabled", transparent_hugepage_enabled)

    @_builtins.property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> Optional[_builtins.str]:
        """
        cgroupMode specifies the cgroup mode to be used on the node.
        """
        return pulumi.get(self, "cgroup_mode")

    @_builtins.property
    @pulumi.getter(name="hugepagesConfig")
    def hugepages_config(self) -> Optional['outputs.NodePoolNodeConfigLinuxNodeConfigHugepagesConfig']:
        """
        Amounts for 2M and 1G hugepages.
        """
        return pulumi.get(self, "hugepages_config")

    @_builtins.property
    @pulumi.getter(name="nodeKernelModuleLoading")
    def node_kernel_module_loading(self) -> Optional['outputs.NodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoading']:
        """
        The settings for kernel module loading.
        """
        return pulumi.get(self, "node_kernel_module_loading")

    @_builtins.property
    @pulumi.getter
    def sysctls(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        """
        return pulumi.get(self, "sysctls")

    @_builtins.property
    @pulumi.getter(name="transparentHugepageDefrag")
    def transparent_hugepage_defrag(self) -> Optional[_builtins.str]:
        """
        The Linux kernel transparent hugepage defrag setting.
        """
        return pulumi.get(self, "transparent_hugepage_defrag")

    @_builtins.property
    @pulumi.getter(name="transparentHugepageEnabled")
    def transparent_hugepage_enabled(self) -> Optional[_builtins.str]:
        """
        The Linux kernel transparent hugepage setting.
        """
        return pulumi.get(self, "transparent_hugepage_enabled")


@pulumi.output_type
class NodePoolNodeConfigLinuxNodeConfigHugepagesConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "hugepageSize1g":
            suggest = "hugepage_size1g"
        elif key == "hugepageSize2m":
            suggest = "hugepage_size2m"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigLinuxNodeConfigHugepagesConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigLinuxNodeConfigHugepagesConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigLinuxNodeConfigHugepagesConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 hugepage_size1g: Optional[_builtins.int] = None,
                 hugepage_size2m: Optional[_builtins.int] = None):
        """
        :param _builtins.int hugepage_size1g: Amount of 1G hugepages.
        :param _builtins.int hugepage_size2m: Amount of 2M hugepages.
        """
        if hugepage_size1g is not None:
            pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        if hugepage_size2m is not None:
            pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @_builtins.property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> Optional[_builtins.int]:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @_builtins.property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> Optional[_builtins.int]:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")


@pulumi.output_type
class NodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoading(dict):
    def __init__(__self__, *,
                 policy: Optional[_builtins.str] = None):
        """
        :param _builtins.str policy: The policy for kernel module loading.
        """
        if policy is not None:
            pulumi.set(__self__, "policy", policy)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> Optional[_builtins.str]:
        """
        The policy for kernel module loading.
        """
        return pulumi.get(self, "policy")


@pulumi.output_type
class NodePoolNodeConfigLocalNvmeSsdBlockConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigLocalNvmeSsdBlockConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigLocalNvmeSsdBlockConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_ssd_count: _builtins.int):
        """
        :param _builtins.int local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class NodePoolNodeConfigReservationAffinity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "consumeReservationType":
            suggest = "consume_reservation_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigReservationAffinity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigReservationAffinity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigReservationAffinity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 consume_reservation_type: _builtins.str,
                 key: Optional[_builtins.str] = None,
                 values: Optional[Sequence[_builtins.str]] = None):
        """
        :param _builtins.str consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param _builtins.str key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param Sequence[_builtins.str] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @_builtins.property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> _builtins.str:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @_builtins.property
    @pulumi.getter
    def key(self) -> Optional[_builtins.str]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def values(self) -> Optional[Sequence[_builtins.str]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class NodePoolNodeConfigSandboxConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sandboxType":
            suggest = "sandbox_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigSandboxConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigSandboxConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigSandboxConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 sandbox_type: _builtins.str):
        """
        :param _builtins.str sandbox_type: Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @_builtins.property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> _builtins.str:
        """
        Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class NodePoolNodeConfigSecondaryBootDisk(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "diskImage":
            suggest = "disk_image"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigSecondaryBootDisk. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigSecondaryBootDisk.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigSecondaryBootDisk.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disk_image: _builtins.str,
                 mode: Optional[_builtins.str] = None):
        """
        :param _builtins.str disk_image: Disk image to create the secondary boot disk from
        :param _builtins.str mode: Mode for how the secondary boot disk is used.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        if mode is not None:
            pulumi.set(__self__, "mode", mode)

    @_builtins.property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> _builtins.str:
        """
        Disk image to create the secondary boot disk from
        """
        return pulumi.get(self, "disk_image")

    @_builtins.property
    @pulumi.getter
    def mode(self) -> Optional[_builtins.str]:
        """
        Mode for how the secondary boot disk is used.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class NodePoolNodeConfigShieldedInstanceConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableIntegrityMonitoring":
            suggest = "enable_integrity_monitoring"
        elif key == "enableSecureBoot":
            suggest = "enable_secure_boot"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigShieldedInstanceConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigShieldedInstanceConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[_builtins.bool] = None,
                 enable_secure_boot: Optional[_builtins.bool] = None):
        """
        :param _builtins.bool enable_integrity_monitoring: Defines whether the instance has integrity monitoring enabled.
        :param _builtins.bool enable_secure_boot: Defines whether the instance has Secure Boot enabled.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @_builtins.property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[_builtins.bool]:
        """
        Defines whether the instance has integrity monitoring enabled.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @_builtins.property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[_builtins.bool]:
        """
        Defines whether the instance has Secure Boot enabled.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class NodePoolNodeConfigSoleTenantConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "nodeAffinities":
            suggest = "node_affinities"
        elif key == "minNodeCpus":
            suggest = "min_node_cpus"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolNodeConfigSoleTenantConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolNodeConfigSoleTenantConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolNodeConfigSoleTenantConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 node_affinities: Sequence['outputs.NodePoolNodeConfigSoleTenantConfigNodeAffinity'],
                 min_node_cpus: Optional[_builtins.int] = None):
        """
        :param Sequence['NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs'] node_affinities: .
        :param _builtins.int min_node_cpus: Specifies the minimum number of vCPUs that each sole tenant node must have to use CPU overcommit. If not specified, the CPU overcommit feature is disabled.
        """
        pulumi.set(__self__, "node_affinities", node_affinities)
        if min_node_cpus is not None:
            pulumi.set(__self__, "min_node_cpus", min_node_cpus)

    @_builtins.property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.NodePoolNodeConfigSoleTenantConfigNodeAffinity']:
        """
        .
        """
        return pulumi.get(self, "node_affinities")

    @_builtins.property
    @pulumi.getter(name="minNodeCpus")
    def min_node_cpus(self) -> Optional[_builtins.int]:
        """
        Specifies the minimum number of vCPUs that each sole tenant node must have to use CPU overcommit. If not specified, the CPU overcommit feature is disabled.
        """
        return pulumi.get(self, "min_node_cpus")


@pulumi.output_type
class NodePoolNodeConfigSoleTenantConfigNodeAffinity(dict):
    def __init__(__self__, *,
                 key: _builtins.str,
                 operator: _builtins.str,
                 values: Sequence[_builtins.str]):
        """
        :param _builtins.str key: .
        :param _builtins.str operator: .
        :param Sequence[_builtins.str] values: .
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        .
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def operator(self) -> _builtins.str:
        """
        .
        """
        return pulumi.get(self, "operator")

    @_builtins.property
    @pulumi.getter
    def values(self) -> Sequence[_builtins.str]:
        """
        .
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class NodePoolNodeConfigTaint(dict):
    def __init__(__self__, *,
                 effect: _builtins.str,
                 key: _builtins.str,
                 value: _builtins.str):
        """
        :param _builtins.str effect: Effect for taint.
        :param _builtins.str key: Key for taint.
        :param _builtins.str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def effect(self) -> _builtins.str:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def value(self) -> _builtins.str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class NodePoolNodeConfigWindowsNodeConfig(dict):
    def __init__(__self__, *,
                 osversion: Optional[_builtins.str] = None):
        """
        :param _builtins.str osversion: The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        if osversion is not None:
            pulumi.set(__self__, "osversion", osversion)

    @_builtins.property
    @pulumi.getter
    def osversion(self) -> Optional[_builtins.str]:
        """
        The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        return pulumi.get(self, "osversion")


@pulumi.output_type
class NodePoolNodeConfigWorkloadMetadataConfig(dict):
    def __init__(__self__, *,
                 mode: _builtins.str):
        """
        :param _builtins.str mode: Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        pulumi.set(__self__, "mode", mode)

    @_builtins.property
    @pulumi.getter
    def mode(self) -> _builtins.str:
        """
        Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class NodePoolPlacementPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "policyName":
            suggest = "policy_name"
        elif key == "tpuTopology":
            suggest = "tpu_topology"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolPlacementPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolPlacementPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolPlacementPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 type: _builtins.str,
                 policy_name: Optional[_builtins.str] = None,
                 tpu_topology: Optional[_builtins.str] = None):
        """
        :param _builtins.str type: The type of the policy. Supports a single value: COMPACT.
               Specifying COMPACT placement policy type places node pool's nodes in a closer
               physical proximity in order to reduce network latency between nodes.
        :param _builtins.str policy_name: If set, refers to the name of a custom resource policy supplied by the user.
               The resource policy must be in the same project and region as the node pool.
               If not found, InvalidArgument error is returned.
        :param _builtins.str tpu_topology: The [TPU topology](https://cloud.google.com/kubernetes-engine/docs/concepts/plan-tpus#topology) like `"2x4"` or `"2x2x2"`.
        """
        pulumi.set(__self__, "type", type)
        if policy_name is not None:
            pulumi.set(__self__, "policy_name", policy_name)
        if tpu_topology is not None:
            pulumi.set(__self__, "tpu_topology", tpu_topology)

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        The type of the policy. Supports a single value: COMPACT.
        Specifying COMPACT placement policy type places node pool's nodes in a closer
        physical proximity in order to reduce network latency between nodes.
        """
        return pulumi.get(self, "type")

    @_builtins.property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> Optional[_builtins.str]:
        """
        If set, refers to the name of a custom resource policy supplied by the user.
        The resource policy must be in the same project and region as the node pool.
        If not found, InvalidArgument error is returned.
        """
        return pulumi.get(self, "policy_name")

    @_builtins.property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> Optional[_builtins.str]:
        """
        The [TPU topology](https://cloud.google.com/kubernetes-engine/docs/concepts/plan-tpus#topology) like `"2x4"` or `"2x2x2"`.
        """
        return pulumi.get(self, "tpu_topology")


@pulumi.output_type
class NodePoolQueuedProvisioning(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Makes nodes obtainable through the [ProvisioningRequest API](https://cloud.google.com/kubernetes-engine/docs/how-to/provisioningrequest) exclusively.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Makes nodes obtainable through the [ProvisioningRequest API](https://cloud.google.com/kubernetes-engine/docs/how-to/provisioningrequest) exclusively.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class NodePoolUpgradeSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "blueGreenSettings":
            suggest = "blue_green_settings"
        elif key == "maxSurge":
            suggest = "max_surge"
        elif key == "maxUnavailable":
            suggest = "max_unavailable"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolUpgradeSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolUpgradeSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolUpgradeSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 blue_green_settings: Optional['outputs.NodePoolUpgradeSettingsBlueGreenSettings'] = None,
                 max_surge: Optional[_builtins.int] = None,
                 max_unavailable: Optional[_builtins.int] = None,
                 strategy: Optional[_builtins.str] = None):
        """
        :param 'NodePoolUpgradeSettingsBlueGreenSettingsArgs' blue_green_settings: The settings to adjust [blue green upgrades](https://cloud.google.com/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy).
               Structure is documented below
        :param _builtins.int max_surge: The number of additional nodes that can be added to the node pool during
               an upgrade. Increasing `max_surge` raises the number of nodes that can be upgraded simultaneously.
               Can be set to 0 or greater.
        :param _builtins.int max_unavailable: The number of nodes that can be simultaneously unavailable during
               an upgrade. Increasing `max_unavailable` raises the number of nodes that can be upgraded in
               parallel. Can be set to 0 or greater.
               
               `max_surge` and `max_unavailable` must not be negative and at least one of them must be greater than zero.
        :param _builtins.str strategy: The upgrade strategy to be used for upgrading the nodes.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @_builtins.property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional['outputs.NodePoolUpgradeSettingsBlueGreenSettings']:
        """
        The settings to adjust [blue green upgrades](https://cloud.google.com/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy).
        Structure is documented below
        """
        return pulumi.get(self, "blue_green_settings")

    @_builtins.property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[_builtins.int]:
        """
        The number of additional nodes that can be added to the node pool during
        an upgrade. Increasing `max_surge` raises the number of nodes that can be upgraded simultaneously.
        Can be set to 0 or greater.
        """
        return pulumi.get(self, "max_surge")

    @_builtins.property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[_builtins.int]:
        """
        The number of nodes that can be simultaneously unavailable during
        an upgrade. Increasing `max_unavailable` raises the number of nodes that can be upgraded in
        parallel. Can be set to 0 or greater.

        `max_surge` and `max_unavailable` must not be negative and at least one of them must be greater than zero.
        """
        return pulumi.get(self, "max_unavailable")

    @_builtins.property
    @pulumi.getter
    def strategy(self) -> Optional[_builtins.str]:
        """
        The upgrade strategy to be used for upgrading the nodes.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class NodePoolUpgradeSettingsBlueGreenSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoscaledRolloutPolicy":
            suggest = "autoscaled_rollout_policy"
        elif key == "nodePoolSoakDuration":
            suggest = "node_pool_soak_duration"
        elif key == "standardRolloutPolicy":
            suggest = "standard_rollout_policy"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolUpgradeSettingsBlueGreenSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 autoscaled_rollout_policy: Optional['outputs.NodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy'] = None,
                 node_pool_soak_duration: Optional[_builtins.str] = None,
                 standard_rollout_policy: Optional['outputs.NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy'] = None):
        """
        :param 'NodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicyArgs' autoscaled_rollout_policy: Autoscaled rollout policy for blue-green upgrade.
        :param _builtins.str node_pool_soak_duration: Time needed after draining the entire blue pool.
               After this period, the blue pool will be cleaned up.
        :param 'NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs' standard_rollout_policy: Specifies the standard policy settings for blue-green upgrades.
        """
        if autoscaled_rollout_policy is not None:
            pulumi.set(__self__, "autoscaled_rollout_policy", autoscaled_rollout_policy)
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        if standard_rollout_policy is not None:
            pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)

    @_builtins.property
    @pulumi.getter(name="autoscaledRolloutPolicy")
    def autoscaled_rollout_policy(self) -> Optional['outputs.NodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy']:
        """
        Autoscaled rollout policy for blue-green upgrade.
        """
        return pulumi.get(self, "autoscaled_rollout_policy")

    @_builtins.property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[_builtins.str]:
        """
        Time needed after draining the entire blue pool.
        After this period, the blue pool will be cleaned up.
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @_builtins.property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> Optional['outputs.NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy']:
        """
        Specifies the standard policy settings for blue-green upgrades.
        """
        return pulumi.get(self, "standard_rollout_policy")


@pulumi.output_type
class NodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "waitForDrainDuration":
            suggest = "wait_for_drain_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettingsAutoscaledRolloutPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 wait_for_drain_duration: Optional[_builtins.str] = None):
        """
        :param _builtins.str wait_for_drain_duration: Time in seconds to wait after cordoning the blue pool before draining the nodes.
        """
        if wait_for_drain_duration is not None:
            pulumi.set(__self__, "wait_for_drain_duration", wait_for_drain_duration)

    @_builtins.property
    @pulumi.getter(name="waitForDrainDuration")
    def wait_for_drain_duration(self) -> Optional[_builtins.str]:
        """
        Time in seconds to wait after cordoning the blue pool before draining the nodes.
        """
        return pulumi.get(self, "wait_for_drain_duration")


@pulumi.output_type
class NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "batchNodeCount":
            suggest = "batch_node_count"
        elif key == "batchPercentage":
            suggest = "batch_percentage"
        elif key == "batchSoakDuration":
            suggest = "batch_soak_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 batch_node_count: Optional[_builtins.int] = None,
                 batch_percentage: Optional[_builtins.float] = None,
                 batch_soak_duration: Optional[_builtins.str] = None):
        """
        :param _builtins.int batch_node_count: Number of blue nodes to drain in a batch.
        :param _builtins.float batch_percentage: Percentage of the blue pool nodes to drain in a batch.
        :param _builtins.str batch_soak_duration: Soak time after each batch gets drained.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @_builtins.property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[_builtins.int]:
        """
        Number of blue nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_node_count")

    @_builtins.property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[_builtins.float]:
        """
        Percentage of the blue pool nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_percentage")

    @_builtins.property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[_builtins.str]:
        """
        Soak time after each batch gets drained.
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class GetClusterAddonsConfigResult(dict):
    def __init__(__self__, *,
                 cloudrun_configs: Sequence['outputs.GetClusterAddonsConfigCloudrunConfigResult'],
                 config_connector_configs: Sequence['outputs.GetClusterAddonsConfigConfigConnectorConfigResult'],
                 dns_cache_configs: Sequence['outputs.GetClusterAddonsConfigDnsCacheConfigResult'],
                 gce_persistent_disk_csi_driver_configs: Sequence['outputs.GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigResult'],
                 gcp_filestore_csi_driver_configs: Sequence['outputs.GetClusterAddonsConfigGcpFilestoreCsiDriverConfigResult'],
                 gcs_fuse_csi_driver_configs: Sequence['outputs.GetClusterAddonsConfigGcsFuseCsiDriverConfigResult'],
                 gke_backup_agent_configs: Sequence['outputs.GetClusterAddonsConfigGkeBackupAgentConfigResult'],
                 horizontal_pod_autoscalings: Sequence['outputs.GetClusterAddonsConfigHorizontalPodAutoscalingResult'],
                 http_load_balancings: Sequence['outputs.GetClusterAddonsConfigHttpLoadBalancingResult'],
                 istio_configs: Sequence['outputs.GetClusterAddonsConfigIstioConfigResult'],
                 kalm_configs: Sequence['outputs.GetClusterAddonsConfigKalmConfigResult'],
                 lustre_csi_driver_configs: Sequence['outputs.GetClusterAddonsConfigLustreCsiDriverConfigResult'],
                 network_policy_configs: Sequence['outputs.GetClusterAddonsConfigNetworkPolicyConfigResult'],
                 parallelstore_csi_driver_configs: Sequence['outputs.GetClusterAddonsConfigParallelstoreCsiDriverConfigResult'],
                 ray_operator_configs: Sequence['outputs.GetClusterAddonsConfigRayOperatorConfigResult'],
                 stateful_ha_configs: Sequence['outputs.GetClusterAddonsConfigStatefulHaConfigResult']):
        """
        :param Sequence['GetClusterAddonsConfigCloudrunConfigArgs'] cloudrun_configs: The status of the CloudRun addon. It is disabled by default. Set disabled = false to enable.
        :param Sequence['GetClusterAddonsConfigConfigConnectorConfigArgs'] config_connector_configs: The of the Config Connector addon.
        :param Sequence['GetClusterAddonsConfigDnsCacheConfigArgs'] dns_cache_configs: The status of the NodeLocal DNSCache addon. It is disabled by default. Set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs'] gce_persistent_disk_csi_driver_configs: Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set enabled = true to enable. The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        :param Sequence['GetClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs'] gcp_filestore_csi_driver_configs: The status of the Filestore CSI driver addon, which allows the usage of filestore instance as volumes. Defaults to disabled for Standard clusters; set enabled = true to enable. It is enabled by default for Autopilot clusters; set enabled = true to enable it explicitly.
        :param Sequence['GetClusterAddonsConfigGcsFuseCsiDriverConfigArgs'] gcs_fuse_csi_driver_configs: The status of the GCS Fuse CSI driver addon, which allows the usage of gcs bucket as volumes. Defaults to disabled; set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigGkeBackupAgentConfigArgs'] gke_backup_agent_configs: The status of the Backup for GKE Agent addon. It is disabled by default. Set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigHorizontalPodAutoscalingArgs'] horizontal_pod_autoscalings: The status of the Horizontal Pod Autoscaling addon, which increases or decreases the number of replica pods a replication controller has based on the resource usage of the existing pods. It ensures that a Heapster pod is running in the cluster, which is also used by the Cloud Monitoring service. It is enabled by default; set disabled = true to disable.
        :param Sequence['GetClusterAddonsConfigHttpLoadBalancingArgs'] http_load_balancings: The status of the HTTP (L7) load balancing controller addon, which makes it easy to set up HTTP load balancers for services in a cluster. It is enabled by default; set disabled = true to disable.
        :param Sequence['GetClusterAddonsConfigIstioConfigArgs'] istio_configs: The status of the Istio addon.
        :param Sequence['GetClusterAddonsConfigKalmConfigArgs'] kalm_configs: Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigLustreCsiDriverConfigArgs'] lustre_csi_driver_configs: Configuration for the Lustre CSI driver. Defaults to disabled; set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigNetworkPolicyConfigArgs'] network_policy_configs: Whether we should enable the network policy addon for the master. This must be enabled in order to enable network policy for the nodes. To enable this, you must also define a network_policy block, otherwise nothing will happen. It can only be disabled if the nodes already do not have network policies enabled. Defaults to disabled; set disabled = false to enable.
        :param Sequence['GetClusterAddonsConfigParallelstoreCsiDriverConfigArgs'] parallelstore_csi_driver_configs: The status of the Parallelstore CSI driver addon, which allows the usage of Parallelstore instances as volumes. Defaults to disabled; set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigRayOperatorConfigArgs'] ray_operator_configs: The status of the Ray Operator addon, which enabled management of Ray AI/ML jobs on GKE. Defaults to disabled; set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigStatefulHaConfigArgs'] stateful_ha_configs: The status of the Stateful HA addon, which provides automatic configurable failover for stateful applications. Defaults to disabled; set enabled = true to enable.
        """
        pulumi.set(__self__, "cloudrun_configs", cloudrun_configs)
        pulumi.set(__self__, "config_connector_configs", config_connector_configs)
        pulumi.set(__self__, "dns_cache_configs", dns_cache_configs)
        pulumi.set(__self__, "gce_persistent_disk_csi_driver_configs", gce_persistent_disk_csi_driver_configs)
        pulumi.set(__self__, "gcp_filestore_csi_driver_configs", gcp_filestore_csi_driver_configs)
        pulumi.set(__self__, "gcs_fuse_csi_driver_configs", gcs_fuse_csi_driver_configs)
        pulumi.set(__self__, "gke_backup_agent_configs", gke_backup_agent_configs)
        pulumi.set(__self__, "horizontal_pod_autoscalings", horizontal_pod_autoscalings)
        pulumi.set(__self__, "http_load_balancings", http_load_balancings)
        pulumi.set(__self__, "istio_configs", istio_configs)
        pulumi.set(__self__, "kalm_configs", kalm_configs)
        pulumi.set(__self__, "lustre_csi_driver_configs", lustre_csi_driver_configs)
        pulumi.set(__self__, "network_policy_configs", network_policy_configs)
        pulumi.set(__self__, "parallelstore_csi_driver_configs", parallelstore_csi_driver_configs)
        pulumi.set(__self__, "ray_operator_configs", ray_operator_configs)
        pulumi.set(__self__, "stateful_ha_configs", stateful_ha_configs)

    @_builtins.property
    @pulumi.getter(name="cloudrunConfigs")
    def cloudrun_configs(self) -> Sequence['outputs.GetClusterAddonsConfigCloudrunConfigResult']:
        """
        The status of the CloudRun addon. It is disabled by default. Set disabled = false to enable.
        """
        return pulumi.get(self, "cloudrun_configs")

    @_builtins.property
    @pulumi.getter(name="configConnectorConfigs")
    def config_connector_configs(self) -> Sequence['outputs.GetClusterAddonsConfigConfigConnectorConfigResult']:
        """
        The of the Config Connector addon.
        """
        return pulumi.get(self, "config_connector_configs")

    @_builtins.property
    @pulumi.getter(name="dnsCacheConfigs")
    def dns_cache_configs(self) -> Sequence['outputs.GetClusterAddonsConfigDnsCacheConfigResult']:
        """
        The status of the NodeLocal DNSCache addon. It is disabled by default. Set enabled = true to enable.
        """
        return pulumi.get(self, "dns_cache_configs")

    @_builtins.property
    @pulumi.getter(name="gcePersistentDiskCsiDriverConfigs")
    def gce_persistent_disk_csi_driver_configs(self) -> Sequence['outputs.GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigResult']:
        """
        Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set enabled = true to enable. The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        """
        return pulumi.get(self, "gce_persistent_disk_csi_driver_configs")

    @_builtins.property
    @pulumi.getter(name="gcpFilestoreCsiDriverConfigs")
    def gcp_filestore_csi_driver_configs(self) -> Sequence['outputs.GetClusterAddonsConfigGcpFilestoreCsiDriverConfigResult']:
        """
        The status of the Filestore CSI driver addon, which allows the usage of filestore instance as volumes. Defaults to disabled for Standard clusters; set enabled = true to enable. It is enabled by default for Autopilot clusters; set enabled = true to enable it explicitly.
        """
        return pulumi.get(self, "gcp_filestore_csi_driver_configs")

    @_builtins.property
    @pulumi.getter(name="gcsFuseCsiDriverConfigs")
    def gcs_fuse_csi_driver_configs(self) -> Sequence['outputs.GetClusterAddonsConfigGcsFuseCsiDriverConfigResult']:
        """
        The status of the GCS Fuse CSI driver addon, which allows the usage of gcs bucket as volumes. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "gcs_fuse_csi_driver_configs")

    @_builtins.property
    @pulumi.getter(name="gkeBackupAgentConfigs")
    def gke_backup_agent_configs(self) -> Sequence['outputs.GetClusterAddonsConfigGkeBackupAgentConfigResult']:
        """
        The status of the Backup for GKE Agent addon. It is disabled by default. Set enabled = true to enable.
        """
        return pulumi.get(self, "gke_backup_agent_configs")

    @_builtins.property
    @pulumi.getter(name="horizontalPodAutoscalings")
    def horizontal_pod_autoscalings(self) -> Sequence['outputs.GetClusterAddonsConfigHorizontalPodAutoscalingResult']:
        """
        The status of the Horizontal Pod Autoscaling addon, which increases or decreases the number of replica pods a replication controller has based on the resource usage of the existing pods. It ensures that a Heapster pod is running in the cluster, which is also used by the Cloud Monitoring service. It is enabled by default; set disabled = true to disable.
        """
        return pulumi.get(self, "horizontal_pod_autoscalings")

    @_builtins.property
    @pulumi.getter(name="httpLoadBalancings")
    def http_load_balancings(self) -> Sequence['outputs.GetClusterAddonsConfigHttpLoadBalancingResult']:
        """
        The status of the HTTP (L7) load balancing controller addon, which makes it easy to set up HTTP load balancers for services in a cluster. It is enabled by default; set disabled = true to disable.
        """
        return pulumi.get(self, "http_load_balancings")

    @_builtins.property
    @pulumi.getter(name="istioConfigs")
    def istio_configs(self) -> Sequence['outputs.GetClusterAddonsConfigIstioConfigResult']:
        """
        The status of the Istio addon.
        """
        return pulumi.get(self, "istio_configs")

    @_builtins.property
    @pulumi.getter(name="kalmConfigs")
    def kalm_configs(self) -> Sequence['outputs.GetClusterAddonsConfigKalmConfigResult']:
        """
        Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set enabled = true to enable.
        """
        return pulumi.get(self, "kalm_configs")

    @_builtins.property
    @pulumi.getter(name="lustreCsiDriverConfigs")
    def lustre_csi_driver_configs(self) -> Sequence['outputs.GetClusterAddonsConfigLustreCsiDriverConfigResult']:
        """
        Configuration for the Lustre CSI driver. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "lustre_csi_driver_configs")

    @_builtins.property
    @pulumi.getter(name="networkPolicyConfigs")
    def network_policy_configs(self) -> Sequence['outputs.GetClusterAddonsConfigNetworkPolicyConfigResult']:
        """
        Whether we should enable the network policy addon for the master. This must be enabled in order to enable network policy for the nodes. To enable this, you must also define a network_policy block, otherwise nothing will happen. It can only be disabled if the nodes already do not have network policies enabled. Defaults to disabled; set disabled = false to enable.
        """
        return pulumi.get(self, "network_policy_configs")

    @_builtins.property
    @pulumi.getter(name="parallelstoreCsiDriverConfigs")
    def parallelstore_csi_driver_configs(self) -> Sequence['outputs.GetClusterAddonsConfigParallelstoreCsiDriverConfigResult']:
        """
        The status of the Parallelstore CSI driver addon, which allows the usage of Parallelstore instances as volumes. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "parallelstore_csi_driver_configs")

    @_builtins.property
    @pulumi.getter(name="rayOperatorConfigs")
    def ray_operator_configs(self) -> Sequence['outputs.GetClusterAddonsConfigRayOperatorConfigResult']:
        """
        The status of the Ray Operator addon, which enabled management of Ray AI/ML jobs on GKE. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "ray_operator_configs")

    @_builtins.property
    @pulumi.getter(name="statefulHaConfigs")
    def stateful_ha_configs(self) -> Sequence['outputs.GetClusterAddonsConfigStatefulHaConfigResult']:
        """
        The status of the Stateful HA addon, which provides automatic configurable failover for stateful applications. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "stateful_ha_configs")


@pulumi.output_type
class GetClusterAddonsConfigCloudrunConfigResult(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool,
                 load_balancer_type: _builtins.str):
        pulumi.set(__self__, "disabled", disabled)
        pulumi.set(__self__, "load_balancer_type", load_balancer_type)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        return pulumi.get(self, "disabled")

    @_builtins.property
    @pulumi.getter(name="loadBalancerType")
    def load_balancer_type(self) -> _builtins.str:
        return pulumi.get(self, "load_balancer_type")


@pulumi.output_type
class GetClusterAddonsConfigConfigConnectorConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigDnsCacheConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigGcePersistentDiskCsiDriverConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigGcpFilestoreCsiDriverConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigGcsFuseCsiDriverConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigGkeBackupAgentConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigHorizontalPodAutoscalingResult(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterAddonsConfigHttpLoadBalancingResult(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterAddonsConfigIstioConfigResult(dict):
    def __init__(__self__, *,
                 auth: _builtins.str,
                 disabled: _builtins.bool):
        """
        :param _builtins.str auth: The authentication type between services in Istio. Available options include AUTH_MUTUAL_TLS.
        :param _builtins.bool disabled: The status of the Istio addon, which makes it easy to set up Istio for services in a cluster. It is disabled by default. Set disabled = false to enable.
        """
        pulumi.set(__self__, "auth", auth)
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def auth(self) -> _builtins.str:
        """
        The authentication type between services in Istio. Available options include AUTH_MUTUAL_TLS.
        """
        return pulumi.get(self, "auth")

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        """
        The status of the Istio addon, which makes it easy to set up Istio for services in a cluster. It is disabled by default. Set disabled = false to enable.
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterAddonsConfigKalmConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigLustreCsiDriverConfigResult(dict):
    def __init__(__self__, *,
                 enable_legacy_lustre_port: _builtins.bool,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enable_legacy_lustre_port: If set to true, the Lustre CSI driver will initialize LNet (the virtual network layer for Lustre kernel module) using port 6988.
               										This flag is required to workaround a port conflict with the gke-metadata-server on GKE nodes.
        :param _builtins.bool enabled: Whether the Lustre CSI driver is enabled for this cluster.
        """
        pulumi.set(__self__, "enable_legacy_lustre_port", enable_legacy_lustre_port)
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter(name="enableLegacyLustrePort")
    def enable_legacy_lustre_port(self) -> _builtins.bool:
        """
        If set to true, the Lustre CSI driver will initialize LNet (the virtual network layer for Lustre kernel module) using port 6988.
        										This flag is required to workaround a port conflict with the gke-metadata-server on GKE nodes.
        """
        return pulumi.get(self, "enable_legacy_lustre_port")

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether the Lustre CSI driver is enabled for this cluster.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigNetworkPolicyConfigResult(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterAddonsConfigParallelstoreCsiDriverConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigRayOperatorConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 ray_cluster_logging_configs: Sequence['outputs.GetClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigResult'],
                 ray_cluster_monitoring_configs: Sequence['outputs.GetClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigResult']):
        """
        :param Sequence['GetClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgs'] ray_cluster_logging_configs: The status of Ray Logging, which scrapes Ray cluster logs to Cloud Logging. Defaults to disabled; set enabled = true to enable.
        :param Sequence['GetClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgs'] ray_cluster_monitoring_configs: The status of Ray Cluster monitoring, which shows Ray cluster metrics in Cloud Console. Defaults to disabled; set enabled = true to enable.
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "ray_cluster_logging_configs", ray_cluster_logging_configs)
        pulumi.set(__self__, "ray_cluster_monitoring_configs", ray_cluster_monitoring_configs)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="rayClusterLoggingConfigs")
    def ray_cluster_logging_configs(self) -> Sequence['outputs.GetClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigResult']:
        """
        The status of Ray Logging, which scrapes Ray cluster logs to Cloud Logging. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "ray_cluster_logging_configs")

    @_builtins.property
    @pulumi.getter(name="rayClusterMonitoringConfigs")
    def ray_cluster_monitoring_configs(self) -> Sequence['outputs.GetClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigResult']:
        """
        The status of Ray Cluster monitoring, which shows Ray cluster metrics in Cloud Console. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "ray_cluster_monitoring_configs")


@pulumi.output_type
class GetClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAddonsConfigStatefulHaConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterAnonymousAuthenticationConfigResult(dict):
    def __init__(__self__, *,
                 mode: _builtins.str):
        """
        :param _builtins.str mode: Setting this to LIMITED will restrict authentication of anonymous users to health check endpoints only.
                Accepted values are:
               * ENABLED: Authentication of anonymous users is enabled for all endpoints.
               * LIMITED: Anonymous access is only allowed for health check endpoints.
        """
        pulumi.set(__self__, "mode", mode)

    @_builtins.property
    @pulumi.getter
    def mode(self) -> _builtins.str:
        """
        Setting this to LIMITED will restrict authentication of anonymous users to health check endpoints only.
         Accepted values are:
        * ENABLED: Authentication of anonymous users is enabled for all endpoints.
        * LIMITED: Anonymous access is only allowed for health check endpoints.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class GetClusterAuthenticatorGroupsConfigResult(dict):
    def __init__(__self__, *,
                 security_group: _builtins.str):
        """
        :param _builtins.str security_group: The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format gke-security-groups@yourdomain.com.
        """
        pulumi.set(__self__, "security_group", security_group)

    @_builtins.property
    @pulumi.getter(name="securityGroup")
    def security_group(self) -> _builtins.str:
        """
        The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format gke-security-groups@yourdomain.com.
        """
        return pulumi.get(self, "security_group")


@pulumi.output_type
class GetClusterBinaryAuthorizationResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 evaluation_mode: _builtins.str):
        """
        :param _builtins.bool enabled: Enable Binary Authorization for this cluster.
        :param _builtins.str evaluation_mode: Mode of operation for Binary Authorization policy evaluation.
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable Binary Authorization for this cluster.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> _builtins.str:
        """
        Mode of operation for Binary Authorization policy evaluation.
        """
        return pulumi.get(self, "evaluation_mode")


@pulumi.output_type
class GetClusterClusterAutoscalingResult(dict):
    def __init__(__self__, *,
                 auto_provisioning_defaults: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultResult'],
                 auto_provisioning_locations: Sequence[_builtins.str],
                 autoscaling_profile: _builtins.str,
                 default_compute_class_enabled: _builtins.bool,
                 enabled: _builtins.bool,
                 resource_limits: Sequence['outputs.GetClusterClusterAutoscalingResourceLimitResult']):
        """
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultArgs'] auto_provisioning_defaults: Contains defaults for a node pool created by NAP.
        :param Sequence[_builtins.str] auto_provisioning_locations: The list of Google Compute Engine zones in which the NodePool's nodes can be created by NAP.
        :param _builtins.str autoscaling_profile: Configuration options for the Autoscaling profile feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability when deciding to remove nodes from a cluster. Can be BALANCED or OPTIMIZE_UTILIZATION. Defaults to BALANCED.
        :param _builtins.bool default_compute_class_enabled: Specifies whether default compute class behaviour is enabled. If enabled, cluster autoscaler will use Compute Class with name default for all the workloads, if not overriden.
        :param _builtins.bool enabled: Whether node auto-provisioning is enabled. Resource limits for cpu and memory must be defined to enable node auto-provisioning.
        :param Sequence['GetClusterClusterAutoscalingResourceLimitArgs'] resource_limits: Global constraints for machine resources in the cluster. Configuring the cpu and memory types is required if node auto-provisioning is enabled. These limits will apply to node pool autoscaling in addition to node auto-provisioning.
        """
        pulumi.set(__self__, "auto_provisioning_defaults", auto_provisioning_defaults)
        pulumi.set(__self__, "auto_provisioning_locations", auto_provisioning_locations)
        pulumi.set(__self__, "autoscaling_profile", autoscaling_profile)
        pulumi.set(__self__, "default_compute_class_enabled", default_compute_class_enabled)
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "resource_limits", resource_limits)

    @_builtins.property
    @pulumi.getter(name="autoProvisioningDefaults")
    def auto_provisioning_defaults(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultResult']:
        """
        Contains defaults for a node pool created by NAP.
        """
        return pulumi.get(self, "auto_provisioning_defaults")

    @_builtins.property
    @pulumi.getter(name="autoProvisioningLocations")
    def auto_provisioning_locations(self) -> Sequence[_builtins.str]:
        """
        The list of Google Compute Engine zones in which the NodePool's nodes can be created by NAP.
        """
        return pulumi.get(self, "auto_provisioning_locations")

    @_builtins.property
    @pulumi.getter(name="autoscalingProfile")
    def autoscaling_profile(self) -> _builtins.str:
        """
        Configuration options for the Autoscaling profile feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability when deciding to remove nodes from a cluster. Can be BALANCED or OPTIMIZE_UTILIZATION. Defaults to BALANCED.
        """
        return pulumi.get(self, "autoscaling_profile")

    @_builtins.property
    @pulumi.getter(name="defaultComputeClassEnabled")
    def default_compute_class_enabled(self) -> _builtins.bool:
        """
        Specifies whether default compute class behaviour is enabled. If enabled, cluster autoscaler will use Compute Class with name default for all the workloads, if not overriden.
        """
        return pulumi.get(self, "default_compute_class_enabled")

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether node auto-provisioning is enabled. Resource limits for cpu and memory must be defined to enable node auto-provisioning.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="resourceLimits")
    def resource_limits(self) -> Sequence['outputs.GetClusterClusterAutoscalingResourceLimitResult']:
        """
        Global constraints for machine resources in the cluster. Configuring the cpu and memory types is required if node auto-provisioning is enabled. These limits will apply to node pool autoscaling in addition to node auto-provisioning.
        """
        return pulumi.get(self, "resource_limits")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultResult(dict):
    def __init__(__self__, *,
                 boot_disk_kms_key: _builtins.str,
                 disk_size: _builtins.int,
                 disk_type: _builtins.str,
                 image_type: _builtins.str,
                 managements: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultManagementResult'],
                 min_cpu_platform: _builtins.str,
                 oauth_scopes: Sequence[_builtins.str],
                 service_account: _builtins.str,
                 shielded_instance_configs: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigResult'],
                 upgrade_settings: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingResult']):
        """
        :param _builtins.str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        :param _builtins.int disk_size: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        :param _builtins.str disk_type: Type of the disk attached to each node.
        :param _builtins.str image_type: The default image type used by NAP once a new node pool is being created.
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultManagementArgs'] managements: NodeManagement configuration for this NodePool.
        :param _builtins.str min_cpu_platform: Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such as Intel Haswell.
        :param Sequence[_builtins.str] oauth_scopes: Scopes that are used by NAP when creating node pools.
        :param _builtins.str service_account: The Google Cloud Platform Service Account to be used by the node VMs.
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigArgs'] shielded_instance_configs: Shielded Instance options.
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingArgs'] upgrade_settings: Specifies the upgrade settings for NAP created node pools
        """
        pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        pulumi.set(__self__, "disk_size", disk_size)
        pulumi.set(__self__, "disk_type", disk_type)
        pulumi.set(__self__, "image_type", image_type)
        pulumi.set(__self__, "managements", managements)
        pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        pulumi.set(__self__, "service_account", service_account)
        pulumi.set(__self__, "shielded_instance_configs", shielded_instance_configs)
        pulumi.set(__self__, "upgrade_settings", upgrade_settings)

    @_builtins.property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> _builtins.str:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @_builtins.property
    @pulumi.getter(name="diskSize")
    def disk_size(self) -> _builtins.int:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        return pulumi.get(self, "disk_size")

    @_builtins.property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> _builtins.str:
        """
        Type of the disk attached to each node.
        """
        return pulumi.get(self, "disk_type")

    @_builtins.property
    @pulumi.getter(name="imageType")
    def image_type(self) -> _builtins.str:
        """
        The default image type used by NAP once a new node pool is being created.
        """
        return pulumi.get(self, "image_type")

    @_builtins.property
    @pulumi.getter
    def managements(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultManagementResult']:
        """
        NodeManagement configuration for this NodePool.
        """
        return pulumi.get(self, "managements")

    @_builtins.property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> _builtins.str:
        """
        Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such as Intel Haswell.
        """
        return pulumi.get(self, "min_cpu_platform")

    @_builtins.property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Sequence[_builtins.str]:
        """
        Scopes that are used by NAP when creating node pools.
        """
        return pulumi.get(self, "oauth_scopes")

    @_builtins.property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> _builtins.str:
        """
        The Google Cloud Platform Service Account to be used by the node VMs.
        """
        return pulumi.get(self, "service_account")

    @_builtins.property
    @pulumi.getter(name="shieldedInstanceConfigs")
    def shielded_instance_configs(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigResult']:
        """
        Shielded Instance options.
        """
        return pulumi.get(self, "shielded_instance_configs")

    @_builtins.property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingResult']:
        """
        Specifies the upgrade settings for NAP created node pools
        """
        return pulumi.get(self, "upgrade_settings")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultManagementResult(dict):
    def __init__(__self__, *,
                 auto_repair: _builtins.bool,
                 auto_upgrade: _builtins.bool,
                 upgrade_options: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionResult']):
        """
        :param _builtins.bool auto_repair: Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
        :param _builtins.bool auto_upgrade: Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionArgs'] upgrade_options: Specifies the Auto Upgrade knobs for the node pool.
        """
        pulumi.set(__self__, "auto_repair", auto_repair)
        pulumi.set(__self__, "auto_upgrade", auto_upgrade)
        pulumi.set(__self__, "upgrade_options", upgrade_options)

    @_builtins.property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> _builtins.bool:
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
        """
        return pulumi.get(self, "auto_repair")

    @_builtins.property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> _builtins.bool:
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        return pulumi.get(self, "auto_upgrade")

    @_builtins.property
    @pulumi.getter(name="upgradeOptions")
    def upgrade_options(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionResult']:
        """
        Specifies the Auto Upgrade knobs for the node pool.
        """
        return pulumi.get(self, "upgrade_options")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultManagementUpgradeOptionResult(dict):
    def __init__(__self__, *,
                 auto_upgrade_start_time: _builtins.str,
                 description: _builtins.str):
        """
        :param _builtins.str auto_upgrade_start_time: This field is set when upgrades are about to commence with the approximate start time for the upgrades, in RFC3339 text format.
        :param _builtins.str description: This field is set when upgrades are about to commence with the description of the upgrade.
        """
        pulumi.set(__self__, "auto_upgrade_start_time", auto_upgrade_start_time)
        pulumi.set(__self__, "description", description)

    @_builtins.property
    @pulumi.getter(name="autoUpgradeStartTime")
    def auto_upgrade_start_time(self) -> _builtins.str:
        """
        This field is set when upgrades are about to commence with the approximate start time for the upgrades, in RFC3339 text format.
        """
        return pulumi.get(self, "auto_upgrade_start_time")

    @_builtins.property
    @pulumi.getter
    def description(self) -> _builtins.str:
        """
        This field is set when upgrades are about to commence with the description of the upgrade.
        """
        return pulumi.get(self, "description")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultShieldedInstanceConfigResult(dict):
    def __init__(__self__, *,
                 enable_integrity_monitoring: _builtins.bool,
                 enable_secure_boot: _builtins.bool):
        """
        :param _builtins.bool enable_integrity_monitoring: Defines whether the instance has integrity monitoring enabled.
        :param _builtins.bool enable_secure_boot: Defines whether the instance has Secure Boot enabled.
        """
        pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @_builtins.property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> _builtins.bool:
        """
        Defines whether the instance has integrity monitoring enabled.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @_builtins.property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> _builtins.bool:
        """
        Defines whether the instance has Secure Boot enabled.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingResult(dict):
    def __init__(__self__, *,
                 blue_green_settings: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingResult'],
                 max_surge: _builtins.int,
                 max_unavailable: _builtins.int,
                 strategy: _builtins.str):
        """
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingArgs'] blue_green_settings: Settings for blue-green upgrade strategy.
        :param _builtins.int max_surge: The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process.
        :param _builtins.int max_unavailable: The maximum number of nodes that can be simultaneously unavailable during the upgrade process.
        :param _builtins.str strategy: Update strategy of the node pool.
        """
        pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        pulumi.set(__self__, "max_surge", max_surge)
        pulumi.set(__self__, "max_unavailable", max_unavailable)
        pulumi.set(__self__, "strategy", strategy)

    @_builtins.property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingResult']:
        """
        Settings for blue-green upgrade strategy.
        """
        return pulumi.get(self, "blue_green_settings")

    @_builtins.property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> _builtins.int:
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process.
        """
        return pulumi.get(self, "max_surge")

    @_builtins.property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> _builtins.int:
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process.
        """
        return pulumi.get(self, "max_unavailable")

    @_builtins.property
    @pulumi.getter
    def strategy(self) -> _builtins.str:
        """
        Update strategy of the node pool.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingResult(dict):
    def __init__(__self__, *,
                 node_pool_soak_duration: _builtins.str,
                 standard_rollout_policies: Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult']):
        """
        :param _builtins.str node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up.
               
               																A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        :param Sequence['GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyArgs'] standard_rollout_policies: Standard policy for the blue-green upgrade.
        """
        pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        pulumi.set(__self__, "standard_rollout_policies", standard_rollout_policies)

    @_builtins.property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> _builtins.str:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up.

        																A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @_builtins.property
    @pulumi.getter(name="standardRolloutPolicies")
    def standard_rollout_policies(self) -> Sequence['outputs.GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult']:
        """
        Standard policy for the blue-green upgrade.
        """
        return pulumi.get(self, "standard_rollout_policies")


@pulumi.output_type
class GetClusterClusterAutoscalingAutoProvisioningDefaultUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult(dict):
    def __init__(__self__, *,
                 batch_node_count: _builtins.int,
                 batch_percentage: _builtins.float,
                 batch_soak_duration: _builtins.str):
        """
        :param _builtins.int batch_node_count: Number of blue nodes to drain in a batch.
        :param _builtins.float batch_percentage: Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0].
        :param _builtins.str batch_soak_duration: Soak time after each batch gets drained.
               
               																			A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        pulumi.set(__self__, "batch_node_count", batch_node_count)
        pulumi.set(__self__, "batch_percentage", batch_percentage)
        pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @_builtins.property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> _builtins.int:
        """
        Number of blue nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_node_count")

    @_builtins.property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> _builtins.float:
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0].
        """
        return pulumi.get(self, "batch_percentage")

    @_builtins.property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> _builtins.str:
        """
        Soak time after each batch gets drained.

        																			A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class GetClusterClusterAutoscalingResourceLimitResult(dict):
    def __init__(__self__, *,
                 maximum: _builtins.int,
                 minimum: _builtins.int,
                 resource_type: _builtins.str):
        """
        :param _builtins.int maximum: Maximum amount of the resource in the cluster.
        :param _builtins.int minimum: Minimum amount of the resource in the cluster.
        :param _builtins.str resource_type: The type of the resource. For example, cpu and memory. See the guide to using Node Auto-Provisioning for a list of types.
        """
        pulumi.set(__self__, "maximum", maximum)
        pulumi.set(__self__, "minimum", minimum)
        pulumi.set(__self__, "resource_type", resource_type)

    @_builtins.property
    @pulumi.getter
    def maximum(self) -> _builtins.int:
        """
        Maximum amount of the resource in the cluster.
        """
        return pulumi.get(self, "maximum")

    @_builtins.property
    @pulumi.getter
    def minimum(self) -> _builtins.int:
        """
        Minimum amount of the resource in the cluster.
        """
        return pulumi.get(self, "minimum")

    @_builtins.property
    @pulumi.getter(name="resourceType")
    def resource_type(self) -> _builtins.str:
        """
        The type of the resource. For example, cpu and memory. See the guide to using Node Auto-Provisioning for a list of types.
        """
        return pulumi.get(self, "resource_type")


@pulumi.output_type
class GetClusterClusterTelemetryResult(dict):
    def __init__(__self__, *,
                 type: _builtins.str):
        """
        :param _builtins.str type: Type of the integration.
        """
        pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        Type of the integration.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterConfidentialNodeResult(dict):
    def __init__(__self__, *,
                 confidential_instance_type: _builtins.str,
                 enabled: _builtins.bool):
        """
        :param _builtins.str confidential_instance_type: Defines the type of technology used by the confidential node.
        :param _builtins.bool enabled: Whether Confidential Nodes feature is enabled for all nodes in this cluster.
        """
        pulumi.set(__self__, "confidential_instance_type", confidential_instance_type)
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter(name="confidentialInstanceType")
    def confidential_instance_type(self) -> _builtins.str:
        """
        Defines the type of technology used by the confidential node.
        """
        return pulumi.get(self, "confidential_instance_type")

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether Confidential Nodes feature is enabled for all nodes in this cluster.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterControlPlaneEndpointsConfigResult(dict):
    def __init__(__self__, *,
                 dns_endpoint_configs: Sequence['outputs.GetClusterControlPlaneEndpointsConfigDnsEndpointConfigResult'],
                 ip_endpoints_configs: Sequence['outputs.GetClusterControlPlaneEndpointsConfigIpEndpointsConfigResult']):
        """
        :param Sequence['GetClusterControlPlaneEndpointsConfigDnsEndpointConfigArgs'] dns_endpoint_configs: DNS endpoint configuration.
        :param Sequence['GetClusterControlPlaneEndpointsConfigIpEndpointsConfigArgs'] ip_endpoints_configs: IP endpoint configuration.
        """
        pulumi.set(__self__, "dns_endpoint_configs", dns_endpoint_configs)
        pulumi.set(__self__, "ip_endpoints_configs", ip_endpoints_configs)

    @_builtins.property
    @pulumi.getter(name="dnsEndpointConfigs")
    def dns_endpoint_configs(self) -> Sequence['outputs.GetClusterControlPlaneEndpointsConfigDnsEndpointConfigResult']:
        """
        DNS endpoint configuration.
        """
        return pulumi.get(self, "dns_endpoint_configs")

    @_builtins.property
    @pulumi.getter(name="ipEndpointsConfigs")
    def ip_endpoints_configs(self) -> Sequence['outputs.GetClusterControlPlaneEndpointsConfigIpEndpointsConfigResult']:
        """
        IP endpoint configuration.
        """
        return pulumi.get(self, "ip_endpoints_configs")


@pulumi.output_type
class GetClusterControlPlaneEndpointsConfigDnsEndpointConfigResult(dict):
    def __init__(__self__, *,
                 allow_external_traffic: _builtins.bool,
                 enable_k8s_certs_via_dns: _builtins.bool,
                 enable_k8s_tokens_via_dns: _builtins.bool,
                 endpoint: _builtins.str):
        """
        :param _builtins.bool allow_external_traffic: Controls whether user traffic is allowed over this endpoint. Note that GCP-managed services may still use the endpoint even if this is false.
        :param _builtins.bool enable_k8s_certs_via_dns: Controls whether the k8s certs auth is allowed via dns.
        :param _builtins.bool enable_k8s_tokens_via_dns: Controls whether the k8s token auth is allowed via dns.
        :param _builtins.str endpoint: The cluster's DNS endpoint.
        """
        pulumi.set(__self__, "allow_external_traffic", allow_external_traffic)
        pulumi.set(__self__, "enable_k8s_certs_via_dns", enable_k8s_certs_via_dns)
        pulumi.set(__self__, "enable_k8s_tokens_via_dns", enable_k8s_tokens_via_dns)
        pulumi.set(__self__, "endpoint", endpoint)

    @_builtins.property
    @pulumi.getter(name="allowExternalTraffic")
    def allow_external_traffic(self) -> _builtins.bool:
        """
        Controls whether user traffic is allowed over this endpoint. Note that GCP-managed services may still use the endpoint even if this is false.
        """
        return pulumi.get(self, "allow_external_traffic")

    @_builtins.property
    @pulumi.getter(name="enableK8sCertsViaDns")
    def enable_k8s_certs_via_dns(self) -> _builtins.bool:
        """
        Controls whether the k8s certs auth is allowed via dns.
        """
        return pulumi.get(self, "enable_k8s_certs_via_dns")

    @_builtins.property
    @pulumi.getter(name="enableK8sTokensViaDns")
    def enable_k8s_tokens_via_dns(self) -> _builtins.bool:
        """
        Controls whether the k8s token auth is allowed via dns.
        """
        return pulumi.get(self, "enable_k8s_tokens_via_dns")

    @_builtins.property
    @pulumi.getter
    def endpoint(self) -> _builtins.str:
        """
        The cluster's DNS endpoint.
        """
        return pulumi.get(self, "endpoint")


@pulumi.output_type
class GetClusterControlPlaneEndpointsConfigIpEndpointsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Controls whether to allow direct IP access.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Controls whether to allow direct IP access.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterCostManagementConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether to enable GKE cost allocation. When you enable GKE cost allocation, the cluster name and namespace of your GKE workloads appear in the labels field of the billing export to BigQuery. Defaults to false.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether to enable GKE cost allocation. When you enable GKE cost allocation, the cluster name and namespace of your GKE workloads appear in the labels field of the billing export to BigQuery. Defaults to false.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterDatabaseEncryptionResult(dict):
    def __init__(__self__, *,
                 key_name: _builtins.str,
                 state: _builtins.str):
        """
        :param _builtins.str key_name: The key to use to encrypt/decrypt secrets.
        :param _builtins.str state: ENCRYPTED or DECRYPTED.
        """
        pulumi.set(__self__, "key_name", key_name)
        pulumi.set(__self__, "state", state)

    @_builtins.property
    @pulumi.getter(name="keyName")
    def key_name(self) -> _builtins.str:
        """
        The key to use to encrypt/decrypt secrets.
        """
        return pulumi.get(self, "key_name")

    @_builtins.property
    @pulumi.getter
    def state(self) -> _builtins.str:
        """
        ENCRYPTED or DECRYPTED.
        """
        return pulumi.get(self, "state")


@pulumi.output_type
class GetClusterDefaultSnatStatusResult(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        """
        :param _builtins.bool disabled: When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic.
        """
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        """
        When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic.
        """
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterDnsConfigResult(dict):
    def __init__(__self__, *,
                 additive_vpc_scope_dns_domain: _builtins.str,
                 cluster_dns: _builtins.str,
                 cluster_dns_domain: _builtins.str,
                 cluster_dns_scope: _builtins.str):
        """
        :param _builtins.str additive_vpc_scope_dns_domain: Enable additive VPC scope DNS in a GKE cluster.
        :param _builtins.str cluster_dns: Which in-cluster DNS provider should be used.
        :param _builtins.str cluster_dns_domain: The suffix used for all cluster service records.
        :param _builtins.str cluster_dns_scope: The scope of access to cluster DNS records.
        """
        pulumi.set(__self__, "additive_vpc_scope_dns_domain", additive_vpc_scope_dns_domain)
        pulumi.set(__self__, "cluster_dns", cluster_dns)
        pulumi.set(__self__, "cluster_dns_domain", cluster_dns_domain)
        pulumi.set(__self__, "cluster_dns_scope", cluster_dns_scope)

    @_builtins.property
    @pulumi.getter(name="additiveVpcScopeDnsDomain")
    def additive_vpc_scope_dns_domain(self) -> _builtins.str:
        """
        Enable additive VPC scope DNS in a GKE cluster.
        """
        return pulumi.get(self, "additive_vpc_scope_dns_domain")

    @_builtins.property
    @pulumi.getter(name="clusterDns")
    def cluster_dns(self) -> _builtins.str:
        """
        Which in-cluster DNS provider should be used.
        """
        return pulumi.get(self, "cluster_dns")

    @_builtins.property
    @pulumi.getter(name="clusterDnsDomain")
    def cluster_dns_domain(self) -> _builtins.str:
        """
        The suffix used for all cluster service records.
        """
        return pulumi.get(self, "cluster_dns_domain")

    @_builtins.property
    @pulumi.getter(name="clusterDnsScope")
    def cluster_dns_scope(self) -> _builtins.str:
        """
        The scope of access to cluster DNS records.
        """
        return pulumi.get(self, "cluster_dns_scope")


@pulumi.output_type
class GetClusterEnableK8sBetaApiResult(dict):
    def __init__(__self__, *,
                 enabled_apis: Sequence[_builtins.str]):
        """
        :param Sequence[_builtins.str] enabled_apis: Enabled Kubernetes Beta APIs.
        """
        pulumi.set(__self__, "enabled_apis", enabled_apis)

    @_builtins.property
    @pulumi.getter(name="enabledApis")
    def enabled_apis(self) -> Sequence[_builtins.str]:
        """
        Enabled Kubernetes Beta APIs.
        """
        return pulumi.get(self, "enabled_apis")


@pulumi.output_type
class GetClusterEnterpriseConfigResult(dict):
    def __init__(__self__, *,
                 cluster_tier: _builtins.str,
                 desired_tier: _builtins.str):
        """
        :param _builtins.str cluster_tier: Indicates the effective cluster tier. Available options include STANDARD and ENTERPRISE.
        :param _builtins.str desired_tier: Indicates the desired cluster tier. Available options include STANDARD and ENTERPRISE.
        """
        pulumi.set(__self__, "cluster_tier", cluster_tier)
        pulumi.set(__self__, "desired_tier", desired_tier)

    @_builtins.property
    @pulumi.getter(name="clusterTier")
    def cluster_tier(self) -> _builtins.str:
        """
        Indicates the effective cluster tier. Available options include STANDARD and ENTERPRISE.
        """
        return pulumi.get(self, "cluster_tier")

    @_builtins.property
    @pulumi.getter(name="desiredTier")
    def desired_tier(self) -> _builtins.str:
        """
        Indicates the desired cluster tier. Available options include STANDARD and ENTERPRISE.
        """
        return pulumi.get(self, "desired_tier")


@pulumi.output_type
class GetClusterFleetResult(dict):
    def __init__(__self__, *,
                 membership: _builtins.str,
                 membership_id: _builtins.str,
                 membership_location: _builtins.str,
                 membership_type: _builtins.str,
                 pre_registered: _builtins.bool,
                 project: _builtins.str):
        """
        :param _builtins.str membership: Full resource name of the registered fleet membership of the cluster.
        :param _builtins.str membership_id: Short name of the fleet membership, for example "member-1".
        :param _builtins.str membership_location: Location of the fleet membership, for example "us-central1".
        :param _builtins.str membership_type: The type of the cluster's fleet membership.
        :param _builtins.bool pre_registered: Whether the cluster has been registered via the fleet API.
        :param _builtins.str project: The project in which the resource belongs. If it
               is not provided, the provider project is used.
        """
        pulumi.set(__self__, "membership", membership)
        pulumi.set(__self__, "membership_id", membership_id)
        pulumi.set(__self__, "membership_location", membership_location)
        pulumi.set(__self__, "membership_type", membership_type)
        pulumi.set(__self__, "pre_registered", pre_registered)
        pulumi.set(__self__, "project", project)

    @_builtins.property
    @pulumi.getter
    def membership(self) -> _builtins.str:
        """
        Full resource name of the registered fleet membership of the cluster.
        """
        return pulumi.get(self, "membership")

    @_builtins.property
    @pulumi.getter(name="membershipId")
    def membership_id(self) -> _builtins.str:
        """
        Short name of the fleet membership, for example "member-1".
        """
        return pulumi.get(self, "membership_id")

    @_builtins.property
    @pulumi.getter(name="membershipLocation")
    def membership_location(self) -> _builtins.str:
        """
        Location of the fleet membership, for example "us-central1".
        """
        return pulumi.get(self, "membership_location")

    @_builtins.property
    @pulumi.getter(name="membershipType")
    def membership_type(self) -> _builtins.str:
        """
        The type of the cluster's fleet membership.
        """
        return pulumi.get(self, "membership_type")

    @_builtins.property
    @pulumi.getter(name="preRegistered")
    def pre_registered(self) -> _builtins.bool:
        """
        Whether the cluster has been registered via the fleet API.
        """
        return pulumi.get(self, "pre_registered")

    @_builtins.property
    @pulumi.getter
    def project(self) -> _builtins.str:
        """
        The project in which the resource belongs. If it
        is not provided, the provider project is used.
        """
        return pulumi.get(self, "project")


@pulumi.output_type
class GetClusterGatewayApiConfigResult(dict):
    def __init__(__self__, *,
                 channel: _builtins.str):
        """
        :param _builtins.str channel: The Gateway API release channel to use for Gateway API.
        """
        pulumi.set(__self__, "channel", channel)

    @_builtins.property
    @pulumi.getter
    def channel(self) -> _builtins.str:
        """
        The Gateway API release channel to use for Gateway API.
        """
        return pulumi.get(self, "channel")


@pulumi.output_type
class GetClusterGkeAutoUpgradeConfigResult(dict):
    def __init__(__self__, *,
                 patch_mode: _builtins.str):
        """
        :param _builtins.str patch_mode: The selected auto-upgrade patch type. Accepted values are:
               * ACCELERATED: Upgrades to the latest available patch version in a given minor and release channel.
        """
        pulumi.set(__self__, "patch_mode", patch_mode)

    @_builtins.property
    @pulumi.getter(name="patchMode")
    def patch_mode(self) -> _builtins.str:
        """
        The selected auto-upgrade patch type. Accepted values are:
        * ACCELERATED: Upgrades to the latest available patch version in a given minor and release channel.
        """
        return pulumi.get(self, "patch_mode")


@pulumi.output_type
class GetClusterIdentityServiceConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether to enable the Identity Service component.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether to enable the Identity Service component.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterIpAllocationPolicyResult(dict):
    def __init__(__self__, *,
                 additional_ip_ranges_configs: Sequence['outputs.GetClusterIpAllocationPolicyAdditionalIpRangesConfigResult'],
                 additional_pod_ranges_configs: Sequence['outputs.GetClusterIpAllocationPolicyAdditionalPodRangesConfigResult'],
                 auto_ipam_configs: Sequence['outputs.GetClusterIpAllocationPolicyAutoIpamConfigResult'],
                 cluster_ipv4_cidr_block: _builtins.str,
                 cluster_secondary_range_name: _builtins.str,
                 network_tier_configs: Sequence['outputs.GetClusterIpAllocationPolicyNetworkTierConfigResult'],
                 pod_cidr_overprovision_configs: Sequence['outputs.GetClusterIpAllocationPolicyPodCidrOverprovisionConfigResult'],
                 services_ipv4_cidr_block: _builtins.str,
                 services_secondary_range_name: _builtins.str,
                 stack_type: _builtins.str):
        """
        :param Sequence['GetClusterIpAllocationPolicyAdditionalIpRangesConfigArgs'] additional_ip_ranges_configs: AdditionalIPRangesConfig is the configuration for individual additional subnetworks attached to the cluster
        :param Sequence['GetClusterIpAllocationPolicyAdditionalPodRangesConfigArgs'] additional_pod_ranges_configs: AdditionalPodRangesConfig is the configuration for additional pod secondary ranges supporting the ClusterUpdate message.
        :param Sequence['GetClusterIpAllocationPolicyAutoIpamConfigArgs'] auto_ipam_configs: AutoIpamConfig contains all information related to Auto IPAM.
        :param _builtins.str cluster_ipv4_cidr_block: The IP address range for the cluster pod IPs. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to pick a specific range to use.
        :param _builtins.str cluster_secondary_range_name: The name of the existing secondary range in the cluster's subnetwork to use for pod IP addresses. Alternatively, cluster_ipv4_cidr_block can be used to automatically create a GKE-managed one.
        :param Sequence['GetClusterIpAllocationPolicyNetworkTierConfigArgs'] network_tier_configs: Used to determine the default network tier for external IP addresses on cluster resources, such as node pools and load balancers.
        :param Sequence['GetClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs'] pod_cidr_overprovision_configs: Configuration for cluster level pod cidr overprovision. Default is disabled=false.
        :param _builtins.str services_ipv4_cidr_block: The IP address range of the services IPs in this cluster. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to pick a specific range to use.
        :param _builtins.str services_secondary_range_name: The name of the existing secondary range in the cluster's subnetwork to use for service ClusterIPs. Alternatively, services_ipv4_cidr_block can be used to automatically create a GKE-managed one.
        :param _builtins.str stack_type: The IP Stack type of the cluster. Choose between IPV4 and IPV4_IPV6. Default type is IPV4 Only if not set
        """
        pulumi.set(__self__, "additional_ip_ranges_configs", additional_ip_ranges_configs)
        pulumi.set(__self__, "additional_pod_ranges_configs", additional_pod_ranges_configs)
        pulumi.set(__self__, "auto_ipam_configs", auto_ipam_configs)
        pulumi.set(__self__, "cluster_ipv4_cidr_block", cluster_ipv4_cidr_block)
        pulumi.set(__self__, "cluster_secondary_range_name", cluster_secondary_range_name)
        pulumi.set(__self__, "network_tier_configs", network_tier_configs)
        pulumi.set(__self__, "pod_cidr_overprovision_configs", pod_cidr_overprovision_configs)
        pulumi.set(__self__, "services_ipv4_cidr_block", services_ipv4_cidr_block)
        pulumi.set(__self__, "services_secondary_range_name", services_secondary_range_name)
        pulumi.set(__self__, "stack_type", stack_type)

    @_builtins.property
    @pulumi.getter(name="additionalIpRangesConfigs")
    def additional_ip_ranges_configs(self) -> Sequence['outputs.GetClusterIpAllocationPolicyAdditionalIpRangesConfigResult']:
        """
        AdditionalIPRangesConfig is the configuration for individual additional subnetworks attached to the cluster
        """
        return pulumi.get(self, "additional_ip_ranges_configs")

    @_builtins.property
    @pulumi.getter(name="additionalPodRangesConfigs")
    def additional_pod_ranges_configs(self) -> Sequence['outputs.GetClusterIpAllocationPolicyAdditionalPodRangesConfigResult']:
        """
        AdditionalPodRangesConfig is the configuration for additional pod secondary ranges supporting the ClusterUpdate message.
        """
        return pulumi.get(self, "additional_pod_ranges_configs")

    @_builtins.property
    @pulumi.getter(name="autoIpamConfigs")
    def auto_ipam_configs(self) -> Sequence['outputs.GetClusterIpAllocationPolicyAutoIpamConfigResult']:
        """
        AutoIpamConfig contains all information related to Auto IPAM.
        """
        return pulumi.get(self, "auto_ipam_configs")

    @_builtins.property
    @pulumi.getter(name="clusterIpv4CidrBlock")
    def cluster_ipv4_cidr_block(self) -> _builtins.str:
        """
        The IP address range for the cluster pod IPs. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to pick a specific range to use.
        """
        return pulumi.get(self, "cluster_ipv4_cidr_block")

    @_builtins.property
    @pulumi.getter(name="clusterSecondaryRangeName")
    def cluster_secondary_range_name(self) -> _builtins.str:
        """
        The name of the existing secondary range in the cluster's subnetwork to use for pod IP addresses. Alternatively, cluster_ipv4_cidr_block can be used to automatically create a GKE-managed one.
        """
        return pulumi.get(self, "cluster_secondary_range_name")

    @_builtins.property
    @pulumi.getter(name="networkTierConfigs")
    def network_tier_configs(self) -> Sequence['outputs.GetClusterIpAllocationPolicyNetworkTierConfigResult']:
        """
        Used to determine the default network tier for external IP addresses on cluster resources, such as node pools and load balancers.
        """
        return pulumi.get(self, "network_tier_configs")

    @_builtins.property
    @pulumi.getter(name="podCidrOverprovisionConfigs")
    def pod_cidr_overprovision_configs(self) -> Sequence['outputs.GetClusterIpAllocationPolicyPodCidrOverprovisionConfigResult']:
        """
        Configuration for cluster level pod cidr overprovision. Default is disabled=false.
        """
        return pulumi.get(self, "pod_cidr_overprovision_configs")

    @_builtins.property
    @pulumi.getter(name="servicesIpv4CidrBlock")
    def services_ipv4_cidr_block(self) -> _builtins.str:
        """
        The IP address range of the services IPs in this cluster. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to pick a specific range to use.
        """
        return pulumi.get(self, "services_ipv4_cidr_block")

    @_builtins.property
    @pulumi.getter(name="servicesSecondaryRangeName")
    def services_secondary_range_name(self) -> _builtins.str:
        """
        The name of the existing secondary range in the cluster's subnetwork to use for service ClusterIPs. Alternatively, services_ipv4_cidr_block can be used to automatically create a GKE-managed one.
        """
        return pulumi.get(self, "services_secondary_range_name")

    @_builtins.property
    @pulumi.getter(name="stackType")
    def stack_type(self) -> _builtins.str:
        """
        The IP Stack type of the cluster. Choose between IPV4 and IPV4_IPV6. Default type is IPV4 Only if not set
        """
        return pulumi.get(self, "stack_type")


@pulumi.output_type
class GetClusterIpAllocationPolicyAdditionalIpRangesConfigResult(dict):
    def __init__(__self__, *,
                 pod_ipv4_range_names: Sequence[_builtins.str],
                 subnetwork: _builtins.str):
        """
        :param Sequence[_builtins.str] pod_ipv4_range_names: List of secondary ranges names within this subnetwork that can be used for pod IPs.
        :param _builtins.str subnetwork: Name of the subnetwork. This can be the full path of the subnetwork or just the name.
        """
        pulumi.set(__self__, "pod_ipv4_range_names", pod_ipv4_range_names)
        pulumi.set(__self__, "subnetwork", subnetwork)

    @_builtins.property
    @pulumi.getter(name="podIpv4RangeNames")
    def pod_ipv4_range_names(self) -> Sequence[_builtins.str]:
        """
        List of secondary ranges names within this subnetwork that can be used for pod IPs.
        """
        return pulumi.get(self, "pod_ipv4_range_names")

    @_builtins.property
    @pulumi.getter
    def subnetwork(self) -> _builtins.str:
        """
        Name of the subnetwork. This can be the full path of the subnetwork or just the name.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class GetClusterIpAllocationPolicyAdditionalPodRangesConfigResult(dict):
    def __init__(__self__, *,
                 pod_range_names: Sequence[_builtins.str]):
        """
        :param Sequence[_builtins.str] pod_range_names: Name for pod secondary ipv4 range which has the actual range defined ahead.
        """
        pulumi.set(__self__, "pod_range_names", pod_range_names)

    @_builtins.property
    @pulumi.getter(name="podRangeNames")
    def pod_range_names(self) -> Sequence[_builtins.str]:
        """
        Name for pod secondary ipv4 range which has the actual range defined ahead.
        """
        return pulumi.get(self, "pod_range_names")


@pulumi.output_type
class GetClusterIpAllocationPolicyAutoIpamConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: The flag that enables Auto IPAM on this cluster.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        The flag that enables Auto IPAM on this cluster.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterIpAllocationPolicyNetworkTierConfigResult(dict):
    def __init__(__self__, *,
                 network_tier: _builtins.str):
        """
        :param _builtins.str network_tier: Network tier configuration.
        """
        pulumi.set(__self__, "network_tier", network_tier)

    @_builtins.property
    @pulumi.getter(name="networkTier")
    def network_tier(self) -> _builtins.str:
        """
        Network tier configuration.
        """
        return pulumi.get(self, "network_tier")


@pulumi.output_type
class GetClusterIpAllocationPolicyPodCidrOverprovisionConfigResult(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterLoggingConfigResult(dict):
    def __init__(__self__, *,
                 enable_components: Sequence[_builtins.str]):
        """
        :param Sequence[_builtins.str] enable_components: GKE components exposing logs. Valid values include SYSTEM_COMPONENTS, APISERVER, CONTROLLER_MANAGER, KCP_CONNECTION, KCP_SSHD, KCP_HPA, SCHEDULER, and WORKLOADS.
        """
        pulumi.set(__self__, "enable_components", enable_components)

    @_builtins.property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Sequence[_builtins.str]:
        """
        GKE components exposing logs. Valid values include SYSTEM_COMPONENTS, APISERVER, CONTROLLER_MANAGER, KCP_CONNECTION, KCP_SSHD, KCP_HPA, SCHEDULER, and WORKLOADS.
        """
        return pulumi.get(self, "enable_components")


@pulumi.output_type
class GetClusterMaintenancePolicyResult(dict):
    def __init__(__self__, *,
                 daily_maintenance_windows: Sequence['outputs.GetClusterMaintenancePolicyDailyMaintenanceWindowResult'],
                 maintenance_exclusions: Sequence['outputs.GetClusterMaintenancePolicyMaintenanceExclusionResult'],
                 recurring_windows: Sequence['outputs.GetClusterMaintenancePolicyRecurringWindowResult']):
        """
        :param Sequence['GetClusterMaintenancePolicyDailyMaintenanceWindowArgs'] daily_maintenance_windows: Time window specified for daily maintenance operations. Specify start_time in RFC3339 format "HH:MM, where HH : [00-23] and MM : [00-59] GMT.
        :param Sequence['GetClusterMaintenancePolicyMaintenanceExclusionArgs'] maintenance_exclusions: Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows.
        :param Sequence['GetClusterMaintenancePolicyRecurringWindowArgs'] recurring_windows: Time window for recurring maintenance operations.
        """
        pulumi.set(__self__, "daily_maintenance_windows", daily_maintenance_windows)
        pulumi.set(__self__, "maintenance_exclusions", maintenance_exclusions)
        pulumi.set(__self__, "recurring_windows", recurring_windows)

    @_builtins.property
    @pulumi.getter(name="dailyMaintenanceWindows")
    def daily_maintenance_windows(self) -> Sequence['outputs.GetClusterMaintenancePolicyDailyMaintenanceWindowResult']:
        """
        Time window specified for daily maintenance operations. Specify start_time in RFC3339 format "HH:MM, where HH : [00-23] and MM : [00-59] GMT.
        """
        return pulumi.get(self, "daily_maintenance_windows")

    @_builtins.property
    @pulumi.getter(name="maintenanceExclusions")
    def maintenance_exclusions(self) -> Sequence['outputs.GetClusterMaintenancePolicyMaintenanceExclusionResult']:
        """
        Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows.
        """
        return pulumi.get(self, "maintenance_exclusions")

    @_builtins.property
    @pulumi.getter(name="recurringWindows")
    def recurring_windows(self) -> Sequence['outputs.GetClusterMaintenancePolicyRecurringWindowResult']:
        """
        Time window for recurring maintenance operations.
        """
        return pulumi.get(self, "recurring_windows")


@pulumi.output_type
class GetClusterMaintenancePolicyDailyMaintenanceWindowResult(dict):
    def __init__(__self__, *,
                 duration: _builtins.str,
                 start_time: _builtins.str):
        pulumi.set(__self__, "duration", duration)
        pulumi.set(__self__, "start_time", start_time)

    @_builtins.property
    @pulumi.getter
    def duration(self) -> _builtins.str:
        return pulumi.get(self, "duration")

    @_builtins.property
    @pulumi.getter(name="startTime")
    def start_time(self) -> _builtins.str:
        return pulumi.get(self, "start_time")


@pulumi.output_type
class GetClusterMaintenancePolicyMaintenanceExclusionResult(dict):
    def __init__(__self__, *,
                 end_time: _builtins.str,
                 exclusion_name: _builtins.str,
                 exclusion_options: Sequence['outputs.GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionResult'],
                 start_time: _builtins.str):
        """
        :param Sequence['GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionArgs'] exclusion_options: Maintenance exclusion related options.
        """
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "exclusion_name", exclusion_name)
        pulumi.set(__self__, "exclusion_options", exclusion_options)
        pulumi.set(__self__, "start_time", start_time)

    @_builtins.property
    @pulumi.getter(name="endTime")
    def end_time(self) -> _builtins.str:
        return pulumi.get(self, "end_time")

    @_builtins.property
    @pulumi.getter(name="exclusionName")
    def exclusion_name(self) -> _builtins.str:
        return pulumi.get(self, "exclusion_name")

    @_builtins.property
    @pulumi.getter(name="exclusionOptions")
    def exclusion_options(self) -> Sequence['outputs.GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionResult']:
        """
        Maintenance exclusion related options.
        """
        return pulumi.get(self, "exclusion_options")

    @_builtins.property
    @pulumi.getter(name="startTime")
    def start_time(self) -> _builtins.str:
        return pulumi.get(self, "start_time")


@pulumi.output_type
class GetClusterMaintenancePolicyMaintenanceExclusionExclusionOptionResult(dict):
    def __init__(__self__, *,
                 end_time_behavior: _builtins.str,
                 scope: _builtins.str):
        """
        :param _builtins.str end_time_behavior: The behavior of the exclusion end time.
        :param _builtins.str scope: The scope of automatic upgrades to restrict in the exclusion window.
        """
        pulumi.set(__self__, "end_time_behavior", end_time_behavior)
        pulumi.set(__self__, "scope", scope)

    @_builtins.property
    @pulumi.getter(name="endTimeBehavior")
    def end_time_behavior(self) -> _builtins.str:
        """
        The behavior of the exclusion end time.
        """
        return pulumi.get(self, "end_time_behavior")

    @_builtins.property
    @pulumi.getter
    def scope(self) -> _builtins.str:
        """
        The scope of automatic upgrades to restrict in the exclusion window.
        """
        return pulumi.get(self, "scope")


@pulumi.output_type
class GetClusterMaintenancePolicyRecurringWindowResult(dict):
    def __init__(__self__, *,
                 end_time: _builtins.str,
                 recurrence: _builtins.str,
                 start_time: _builtins.str):
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "recurrence", recurrence)
        pulumi.set(__self__, "start_time", start_time)

    @_builtins.property
    @pulumi.getter(name="endTime")
    def end_time(self) -> _builtins.str:
        return pulumi.get(self, "end_time")

    @_builtins.property
    @pulumi.getter
    def recurrence(self) -> _builtins.str:
        return pulumi.get(self, "recurrence")

    @_builtins.property
    @pulumi.getter(name="startTime")
    def start_time(self) -> _builtins.str:
        return pulumi.get(self, "start_time")


@pulumi.output_type
class GetClusterMasterAuthResult(dict):
    def __init__(__self__, *,
                 client_certificate: _builtins.str,
                 client_certificate_configs: Sequence['outputs.GetClusterMasterAuthClientCertificateConfigResult'],
                 client_key: _builtins.str,
                 cluster_ca_certificate: _builtins.str):
        """
        :param _builtins.str client_certificate: Base64 encoded public certificate used by clients to authenticate to the cluster endpoint.
        :param Sequence['GetClusterMasterAuthClientCertificateConfigArgs'] client_certificate_configs: Whether client certificate authorization is enabled for this cluster.
        :param _builtins.str client_key: Base64 encoded private key used by clients to authenticate to the cluster endpoint.
        :param _builtins.str cluster_ca_certificate: Base64 encoded public certificate that is the root of trust for the cluster.
        """
        pulumi.set(__self__, "client_certificate", client_certificate)
        pulumi.set(__self__, "client_certificate_configs", client_certificate_configs)
        pulumi.set(__self__, "client_key", client_key)
        pulumi.set(__self__, "cluster_ca_certificate", cluster_ca_certificate)

    @_builtins.property
    @pulumi.getter(name="clientCertificate")
    def client_certificate(self) -> _builtins.str:
        """
        Base64 encoded public certificate used by clients to authenticate to the cluster endpoint.
        """
        return pulumi.get(self, "client_certificate")

    @_builtins.property
    @pulumi.getter(name="clientCertificateConfigs")
    def client_certificate_configs(self) -> Sequence['outputs.GetClusterMasterAuthClientCertificateConfigResult']:
        """
        Whether client certificate authorization is enabled for this cluster.
        """
        return pulumi.get(self, "client_certificate_configs")

    @_builtins.property
    @pulumi.getter(name="clientKey")
    def client_key(self) -> _builtins.str:
        """
        Base64 encoded private key used by clients to authenticate to the cluster endpoint.
        """
        return pulumi.get(self, "client_key")

    @_builtins.property
    @pulumi.getter(name="clusterCaCertificate")
    def cluster_ca_certificate(self) -> _builtins.str:
        """
        Base64 encoded public certificate that is the root of trust for the cluster.
        """
        return pulumi.get(self, "cluster_ca_certificate")


@pulumi.output_type
class GetClusterMasterAuthClientCertificateConfigResult(dict):
    def __init__(__self__, *,
                 issue_client_certificate: _builtins.bool):
        """
        :param _builtins.bool issue_client_certificate: Whether client certificate authorization is enabled for this cluster.
        """
        pulumi.set(__self__, "issue_client_certificate", issue_client_certificate)

    @_builtins.property
    @pulumi.getter(name="issueClientCertificate")
    def issue_client_certificate(self) -> _builtins.bool:
        """
        Whether client certificate authorization is enabled for this cluster.
        """
        return pulumi.get(self, "issue_client_certificate")


@pulumi.output_type
class GetClusterMasterAuthorizedNetworksConfigResult(dict):
    def __init__(__self__, *,
                 cidr_blocks: Sequence['outputs.GetClusterMasterAuthorizedNetworksConfigCidrBlockResult'],
                 gcp_public_cidrs_access_enabled: _builtins.bool,
                 private_endpoint_enforcement_enabled: _builtins.bool):
        """
        :param Sequence['GetClusterMasterAuthorizedNetworksConfigCidrBlockArgs'] cidr_blocks: External networks that can access the Kubernetes cluster master through HTTPS.
        :param _builtins.bool gcp_public_cidrs_access_enabled: Whether Kubernetes master is accessible via Google Compute Engine Public IPs.
        :param _builtins.bool private_endpoint_enforcement_enabled: Whether authorized networks is enforced on the private endpoint or not. Defaults to false.
        """
        pulumi.set(__self__, "cidr_blocks", cidr_blocks)
        pulumi.set(__self__, "gcp_public_cidrs_access_enabled", gcp_public_cidrs_access_enabled)
        pulumi.set(__self__, "private_endpoint_enforcement_enabled", private_endpoint_enforcement_enabled)

    @_builtins.property
    @pulumi.getter(name="cidrBlocks")
    def cidr_blocks(self) -> Sequence['outputs.GetClusterMasterAuthorizedNetworksConfigCidrBlockResult']:
        """
        External networks that can access the Kubernetes cluster master through HTTPS.
        """
        return pulumi.get(self, "cidr_blocks")

    @_builtins.property
    @pulumi.getter(name="gcpPublicCidrsAccessEnabled")
    def gcp_public_cidrs_access_enabled(self) -> _builtins.bool:
        """
        Whether Kubernetes master is accessible via Google Compute Engine Public IPs.
        """
        return pulumi.get(self, "gcp_public_cidrs_access_enabled")

    @_builtins.property
    @pulumi.getter(name="privateEndpointEnforcementEnabled")
    def private_endpoint_enforcement_enabled(self) -> _builtins.bool:
        """
        Whether authorized networks is enforced on the private endpoint or not. Defaults to false.
        """
        return pulumi.get(self, "private_endpoint_enforcement_enabled")


@pulumi.output_type
class GetClusterMasterAuthorizedNetworksConfigCidrBlockResult(dict):
    def __init__(__self__, *,
                 cidr_block: _builtins.str,
                 display_name: _builtins.str):
        """
        :param _builtins.str cidr_block: External network that can access Kubernetes master through HTTPS. Must be specified in CIDR notation.
        :param _builtins.str display_name: Field for users to identify CIDR blocks.
        """
        pulumi.set(__self__, "cidr_block", cidr_block)
        pulumi.set(__self__, "display_name", display_name)

    @_builtins.property
    @pulumi.getter(name="cidrBlock")
    def cidr_block(self) -> _builtins.str:
        """
        External network that can access Kubernetes master through HTTPS. Must be specified in CIDR notation.
        """
        return pulumi.get(self, "cidr_block")

    @_builtins.property
    @pulumi.getter(name="displayName")
    def display_name(self) -> _builtins.str:
        """
        Field for users to identify CIDR blocks.
        """
        return pulumi.get(self, "display_name")


@pulumi.output_type
class GetClusterMeshCertificateResult(dict):
    def __init__(__self__, *,
                 enable_certificates: _builtins.bool):
        """
        :param _builtins.bool enable_certificates: When enabled the GKE Workload Identity Certificates controller and node agent will be deployed in the cluster.
        """
        pulumi.set(__self__, "enable_certificates", enable_certificates)

    @_builtins.property
    @pulumi.getter(name="enableCertificates")
    def enable_certificates(self) -> _builtins.bool:
        """
        When enabled the GKE Workload Identity Certificates controller and node agent will be deployed in the cluster.
        """
        return pulumi.get(self, "enable_certificates")


@pulumi.output_type
class GetClusterMonitoringConfigResult(dict):
    def __init__(__self__, *,
                 advanced_datapath_observability_configs: Sequence['outputs.GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigResult'],
                 enable_components: Sequence[_builtins.str],
                 managed_prometheuses: Sequence['outputs.GetClusterMonitoringConfigManagedPrometheusResult']):
        """
        :param Sequence['GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs'] advanced_datapath_observability_configs: Configuration of Advanced Datapath Observability features.
        :param Sequence[_builtins.str] enable_components: GKE components exposing metrics. Valid values include SYSTEM_COMPONENTS, APISERVER, SCHEDULER, CONTROLLER_MANAGER, STORAGE, HPA, POD, DAEMONSET, DEPLOYMENT, STATEFULSET, WORKLOADS, KUBELET, CADVISOR, DCGM and JOBSET.
        :param Sequence['GetClusterMonitoringConfigManagedPrometheusArgs'] managed_prometheuses: Configuration for Google Cloud Managed Services for Prometheus.
        """
        pulumi.set(__self__, "advanced_datapath_observability_configs", advanced_datapath_observability_configs)
        pulumi.set(__self__, "enable_components", enable_components)
        pulumi.set(__self__, "managed_prometheuses", managed_prometheuses)

    @_builtins.property
    @pulumi.getter(name="advancedDatapathObservabilityConfigs")
    def advanced_datapath_observability_configs(self) -> Sequence['outputs.GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigResult']:
        """
        Configuration of Advanced Datapath Observability features.
        """
        return pulumi.get(self, "advanced_datapath_observability_configs")

    @_builtins.property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Sequence[_builtins.str]:
        """
        GKE components exposing metrics. Valid values include SYSTEM_COMPONENTS, APISERVER, SCHEDULER, CONTROLLER_MANAGER, STORAGE, HPA, POD, DAEMONSET, DEPLOYMENT, STATEFULSET, WORKLOADS, KUBELET, CADVISOR, DCGM and JOBSET.
        """
        return pulumi.get(self, "enable_components")

    @_builtins.property
    @pulumi.getter(name="managedPrometheuses")
    def managed_prometheuses(self) -> Sequence['outputs.GetClusterMonitoringConfigManagedPrometheusResult']:
        """
        Configuration for Google Cloud Managed Services for Prometheus.
        """
        return pulumi.get(self, "managed_prometheuses")


@pulumi.output_type
class GetClusterMonitoringConfigAdvancedDatapathObservabilityConfigResult(dict):
    def __init__(__self__, *,
                 enable_metrics: _builtins.bool,
                 enable_relay: _builtins.bool):
        """
        :param _builtins.bool enable_metrics: Whether or not the advanced datapath metrics are enabled.
        :param _builtins.bool enable_relay: Whether or not Relay is enabled.
        """
        pulumi.set(__self__, "enable_metrics", enable_metrics)
        pulumi.set(__self__, "enable_relay", enable_relay)

    @_builtins.property
    @pulumi.getter(name="enableMetrics")
    def enable_metrics(self) -> _builtins.bool:
        """
        Whether or not the advanced datapath metrics are enabled.
        """
        return pulumi.get(self, "enable_metrics")

    @_builtins.property
    @pulumi.getter(name="enableRelay")
    def enable_relay(self) -> _builtins.bool:
        """
        Whether or not Relay is enabled.
        """
        return pulumi.get(self, "enable_relay")


@pulumi.output_type
class GetClusterMonitoringConfigManagedPrometheusResult(dict):
    def __init__(__self__, *,
                 auto_monitoring_configs: Sequence['outputs.GetClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigResult'],
                 enabled: _builtins.bool):
        """
        :param Sequence['GetClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigArgs'] auto_monitoring_configs: Configuration for GKE Workload Auto-Monitoring.
        :param _builtins.bool enabled: Whether or not the managed collection is enabled.
        """
        pulumi.set(__self__, "auto_monitoring_configs", auto_monitoring_configs)
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter(name="autoMonitoringConfigs")
    def auto_monitoring_configs(self) -> Sequence['outputs.GetClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigResult']:
        """
        Configuration for GKE Workload Auto-Monitoring.
        """
        return pulumi.get(self, "auto_monitoring_configs")

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not the managed collection is enabled.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigResult(dict):
    def __init__(__self__, *,
                 scope: _builtins.str):
        """
        :param _builtins.str scope: The scope of auto-monitoring.
        """
        pulumi.set(__self__, "scope", scope)

    @_builtins.property
    @pulumi.getter
    def scope(self) -> _builtins.str:
        """
        The scope of auto-monitoring.
        """
        return pulumi.get(self, "scope")


@pulumi.output_type
class GetClusterNetworkPerformanceConfigResult(dict):
    def __init__(__self__, *,
                 total_egress_bandwidth_tier: _builtins.str):
        """
        :param _builtins.str total_egress_bandwidth_tier: Specifies the total network bandwidth tier for NodePools in the cluster.
        """
        pulumi.set(__self__, "total_egress_bandwidth_tier", total_egress_bandwidth_tier)

    @_builtins.property
    @pulumi.getter(name="totalEgressBandwidthTier")
    def total_egress_bandwidth_tier(self) -> _builtins.str:
        """
        Specifies the total network bandwidth tier for NodePools in the cluster.
        """
        return pulumi.get(self, "total_egress_bandwidth_tier")


@pulumi.output_type
class GetClusterNetworkPolicyResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 provider: _builtins.str):
        """
        :param _builtins.bool enabled: Whether network policy is enabled on the cluster.
        :param _builtins.str provider: The selected network policy provider.
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "provider", provider)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether network policy is enabled on the cluster.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter
    def provider(self) -> _builtins.str:
        """
        The selected network policy provider.
        """
        return pulumi.get(self, "provider")


@pulumi.output_type
class GetClusterNodeConfigResult(dict):
    def __init__(__self__, *,
                 advanced_machine_features: Sequence['outputs.GetClusterNodeConfigAdvancedMachineFeatureResult'],
                 boot_disk_kms_key: _builtins.str,
                 boot_disks: Sequence['outputs.GetClusterNodeConfigBootDiskResult'],
                 confidential_nodes: Sequence['outputs.GetClusterNodeConfigConfidentialNodeResult'],
                 containerd_configs: Sequence['outputs.GetClusterNodeConfigContainerdConfigResult'],
                 disk_size_gb: _builtins.int,
                 disk_type: _builtins.str,
                 effective_taints: Sequence['outputs.GetClusterNodeConfigEffectiveTaintResult'],
                 enable_confidential_storage: _builtins.bool,
                 ephemeral_storage_configs: Sequence['outputs.GetClusterNodeConfigEphemeralStorageConfigResult'],
                 ephemeral_storage_local_ssd_configs: Sequence['outputs.GetClusterNodeConfigEphemeralStorageLocalSsdConfigResult'],
                 fast_sockets: Sequence['outputs.GetClusterNodeConfigFastSocketResult'],
                 flex_start: _builtins.bool,
                 gcfs_configs: Sequence['outputs.GetClusterNodeConfigGcfsConfigResult'],
                 guest_accelerators: Sequence['outputs.GetClusterNodeConfigGuestAcceleratorResult'],
                 gvnics: Sequence['outputs.GetClusterNodeConfigGvnicResult'],
                 host_maintenance_policies: Sequence['outputs.GetClusterNodeConfigHostMaintenancePolicyResult'],
                 image_type: _builtins.str,
                 kubelet_configs: Sequence['outputs.GetClusterNodeConfigKubeletConfigResult'],
                 labels: Mapping[str, _builtins.str],
                 linux_node_configs: Sequence['outputs.GetClusterNodeConfigLinuxNodeConfigResult'],
                 local_nvme_ssd_block_configs: Sequence['outputs.GetClusterNodeConfigLocalNvmeSsdBlockConfigResult'],
                 local_ssd_count: _builtins.int,
                 local_ssd_encryption_mode: _builtins.str,
                 logging_variant: _builtins.str,
                 machine_type: _builtins.str,
                 max_run_duration: _builtins.str,
                 metadata: Mapping[str, _builtins.str],
                 min_cpu_platform: _builtins.str,
                 node_group: _builtins.str,
                 oauth_scopes: Sequence[_builtins.str],
                 preemptible: _builtins.bool,
                 reservation_affinities: Sequence['outputs.GetClusterNodeConfigReservationAffinityResult'],
                 resource_labels: Mapping[str, _builtins.str],
                 resource_manager_tags: Mapping[str, _builtins.str],
                 sandbox_configs: Sequence['outputs.GetClusterNodeConfigSandboxConfigResult'],
                 secondary_boot_disks: Sequence['outputs.GetClusterNodeConfigSecondaryBootDiskResult'],
                 service_account: _builtins.str,
                 shielded_instance_configs: Sequence['outputs.GetClusterNodeConfigShieldedInstanceConfigResult'],
                 sole_tenant_configs: Sequence['outputs.GetClusterNodeConfigSoleTenantConfigResult'],
                 spot: _builtins.bool,
                 storage_pools: Sequence[_builtins.str],
                 tags: Sequence[_builtins.str],
                 taints: Sequence['outputs.GetClusterNodeConfigTaintResult'],
                 windows_node_configs: Sequence['outputs.GetClusterNodeConfigWindowsNodeConfigResult'],
                 workload_metadata_configs: Sequence['outputs.GetClusterNodeConfigWorkloadMetadataConfigResult']):
        """
        :param Sequence['GetClusterNodeConfigAdvancedMachineFeatureArgs'] advanced_machine_features: Specifies options for controlling advanced machine features.
        :param _builtins.str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        :param Sequence['GetClusterNodeConfigBootDiskArgs'] boot_disks: Boot disk configuration for node pools nodes.
        :param Sequence['GetClusterNodeConfigConfidentialNodeArgs'] confidential_nodes: Configuration for the confidential nodes feature, which makes nodes run on confidential VMs.
        :param Sequence['GetClusterNodeConfigContainerdConfigArgs'] containerd_configs: Parameters for containerd configuration.
        :param _builtins.int disk_size_gb: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        :param _builtins.str disk_type: Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        :param Sequence['GetClusterNodeConfigEffectiveTaintArgs'] effective_taints: List of kubernetes taints applied to each node.
        :param _builtins.bool enable_confidential_storage: If enabled boot disks are configured with confidential mode.
        :param Sequence['GetClusterNodeConfigEphemeralStorageConfigArgs'] ephemeral_storage_configs: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param Sequence['GetClusterNodeConfigEphemeralStorageLocalSsdConfigArgs'] ephemeral_storage_local_ssd_configs: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param Sequence['GetClusterNodeConfigFastSocketArgs'] fast_sockets: Enable or disable NCCL Fast Socket in the node pool.
        :param _builtins.bool flex_start: Enables Flex Start provisioning model for the node pool
        :param Sequence['GetClusterNodeConfigGcfsConfigArgs'] gcfs_configs: GCFS configuration for this node.
        :param Sequence['GetClusterNodeConfigGuestAcceleratorArgs'] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
        :param Sequence['GetClusterNodeConfigGvnicArgs'] gvnics: Enable or disable gvnic in the node pool.
        :param Sequence['GetClusterNodeConfigHostMaintenancePolicyArgs'] host_maintenance_policies: The maintenance policy for the hosts on which the GKE VMs run on.
        :param _builtins.str image_type: The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        :param Sequence['GetClusterNodeConfigKubeletConfigArgs'] kubelet_configs: Node kubelet configs.
        :param Mapping[str, _builtins.str] labels: The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        :param Sequence['GetClusterNodeConfigLinuxNodeConfigArgs'] linux_node_configs: Parameters that can be configured on Linux nodes.
        :param Sequence['GetClusterNodeConfigLocalNvmeSsdBlockConfigArgs'] local_nvme_ssd_block_configs: Parameters for raw-block local NVMe SSDs.
        :param _builtins.int local_ssd_count: The number of local SSD disks to be attached to the node.
        :param _builtins.str local_ssd_encryption_mode: LocalSsdEncryptionMode specified the method used for encrypting the local SSDs attached to the node.
        :param _builtins.str logging_variant: Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        :param _builtins.str machine_type: The name of a Google Compute Engine machine type.
        :param _builtins.str max_run_duration: The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        :param Mapping[str, _builtins.str] metadata: The metadata key/value pairs assigned to instances in the cluster.
        :param _builtins.str min_cpu_platform: Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        :param _builtins.str node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        :param Sequence[_builtins.str] oauth_scopes: The set of Google API scopes to be made available on all of the node VMs.
        :param _builtins.bool preemptible: Whether the nodes are created as preemptible VM instances.
        :param Sequence['GetClusterNodeConfigReservationAffinityArgs'] reservation_affinities: The reservation affinity configuration for the node pool.
        :param Mapping[str, _builtins.str] resource_labels: The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        :param Mapping[str, _builtins.str] resource_manager_tags: A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        :param Sequence['GetClusterNodeConfigSandboxConfigArgs'] sandbox_configs: Sandbox configuration for this node.
        :param Sequence['GetClusterNodeConfigSecondaryBootDiskArgs'] secondary_boot_disks: Secondary boot disks for preloading data or container images.
        :param _builtins.str service_account: The Google Cloud Platform Service Account to be used by the node VMs.
        :param Sequence['GetClusterNodeConfigShieldedInstanceConfigArgs'] shielded_instance_configs: Shielded Instance options.
        :param Sequence['GetClusterNodeConfigSoleTenantConfigArgs'] sole_tenant_configs: Node affinity options for sole tenant node pools.
        :param _builtins.bool spot: Whether the nodes are created as spot VM instances.
        :param Sequence[_builtins.str] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param Sequence[_builtins.str] tags: The list of instance tags applied to all nodes.
        :param Sequence['GetClusterNodeConfigTaintArgs'] taints: List of Kubernetes taints to be applied to each node.
        :param Sequence['GetClusterNodeConfigWindowsNodeConfigArgs'] windows_node_configs: Parameters that can be configured on Windows nodes.
        :param Sequence['GetClusterNodeConfigWorkloadMetadataConfigArgs'] workload_metadata_configs: The workload metadata configuration for this node.
        """
        pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        pulumi.set(__self__, "boot_disks", boot_disks)
        pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        pulumi.set(__self__, "containerd_configs", containerd_configs)
        pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        pulumi.set(__self__, "disk_type", disk_type)
        pulumi.set(__self__, "effective_taints", effective_taints)
        pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        pulumi.set(__self__, "ephemeral_storage_configs", ephemeral_storage_configs)
        pulumi.set(__self__, "ephemeral_storage_local_ssd_configs", ephemeral_storage_local_ssd_configs)
        pulumi.set(__self__, "fast_sockets", fast_sockets)
        pulumi.set(__self__, "flex_start", flex_start)
        pulumi.set(__self__, "gcfs_configs", gcfs_configs)
        pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        pulumi.set(__self__, "gvnics", gvnics)
        pulumi.set(__self__, "host_maintenance_policies", host_maintenance_policies)
        pulumi.set(__self__, "image_type", image_type)
        pulumi.set(__self__, "kubelet_configs", kubelet_configs)
        pulumi.set(__self__, "labels", labels)
        pulumi.set(__self__, "linux_node_configs", linux_node_configs)
        pulumi.set(__self__, "local_nvme_ssd_block_configs", local_nvme_ssd_block_configs)
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        pulumi.set(__self__, "local_ssd_encryption_mode", local_ssd_encryption_mode)
        pulumi.set(__self__, "logging_variant", logging_variant)
        pulumi.set(__self__, "machine_type", machine_type)
        pulumi.set(__self__, "max_run_duration", max_run_duration)
        pulumi.set(__self__, "metadata", metadata)
        pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        pulumi.set(__self__, "node_group", node_group)
        pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        pulumi.set(__self__, "preemptible", preemptible)
        pulumi.set(__self__, "reservation_affinities", reservation_affinities)
        pulumi.set(__self__, "resource_labels", resource_labels)
        pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        pulumi.set(__self__, "sandbox_configs", sandbox_configs)
        pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        pulumi.set(__self__, "service_account", service_account)
        pulumi.set(__self__, "shielded_instance_configs", shielded_instance_configs)
        pulumi.set(__self__, "sole_tenant_configs", sole_tenant_configs)
        pulumi.set(__self__, "spot", spot)
        pulumi.set(__self__, "storage_pools", storage_pools)
        pulumi.set(__self__, "tags", tags)
        pulumi.set(__self__, "taints", taints)
        pulumi.set(__self__, "windows_node_configs", windows_node_configs)
        pulumi.set(__self__, "workload_metadata_configs", workload_metadata_configs)

    @_builtins.property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Sequence['outputs.GetClusterNodeConfigAdvancedMachineFeatureResult']:
        """
        Specifies options for controlling advanced machine features.
        """
        return pulumi.get(self, "advanced_machine_features")

    @_builtins.property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> _builtins.str:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @_builtins.property
    @pulumi.getter(name="bootDisks")
    def boot_disks(self) -> Sequence['outputs.GetClusterNodeConfigBootDiskResult']:
        """
        Boot disk configuration for node pools nodes.
        """
        return pulumi.get(self, "boot_disks")

    @_builtins.property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Sequence['outputs.GetClusterNodeConfigConfidentialNodeResult']:
        """
        Configuration for the confidential nodes feature, which makes nodes run on confidential VMs.
        """
        return pulumi.get(self, "confidential_nodes")

    @_builtins.property
    @pulumi.getter(name="containerdConfigs")
    def containerd_configs(self) -> Sequence['outputs.GetClusterNodeConfigContainerdConfigResult']:
        """
        Parameters for containerd configuration.
        """
        return pulumi.get(self, "containerd_configs")

    @_builtins.property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> _builtins.int:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @_builtins.property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> _builtins.str:
        """
        Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        """
        return pulumi.get(self, "disk_type")

    @_builtins.property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Sequence['outputs.GetClusterNodeConfigEffectiveTaintResult']:
        """
        List of kubernetes taints applied to each node.
        """
        return pulumi.get(self, "effective_taints")

    @_builtins.property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> _builtins.bool:
        """
        If enabled boot disks are configured with confidential mode.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @_builtins.property
    @pulumi.getter(name="ephemeralStorageConfigs")
    def ephemeral_storage_configs(self) -> Sequence['outputs.GetClusterNodeConfigEphemeralStorageConfigResult']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_configs")

    @_builtins.property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfigs")
    def ephemeral_storage_local_ssd_configs(self) -> Sequence['outputs.GetClusterNodeConfigEphemeralStorageLocalSsdConfigResult']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_configs")

    @_builtins.property
    @pulumi.getter(name="fastSockets")
    def fast_sockets(self) -> Sequence['outputs.GetClusterNodeConfigFastSocketResult']:
        """
        Enable or disable NCCL Fast Socket in the node pool.
        """
        return pulumi.get(self, "fast_sockets")

    @_builtins.property
    @pulumi.getter(name="flexStart")
    def flex_start(self) -> _builtins.bool:
        """
        Enables Flex Start provisioning model for the node pool
        """
        return pulumi.get(self, "flex_start")

    @_builtins.property
    @pulumi.getter(name="gcfsConfigs")
    def gcfs_configs(self) -> Sequence['outputs.GetClusterNodeConfigGcfsConfigResult']:
        """
        GCFS configuration for this node.
        """
        return pulumi.get(self, "gcfs_configs")

    @_builtins.property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Sequence['outputs.GetClusterNodeConfigGuestAcceleratorResult']:
        """
        List of the type and count of accelerator cards attached to the instance.
        """
        return pulumi.get(self, "guest_accelerators")

    @_builtins.property
    @pulumi.getter
    def gvnics(self) -> Sequence['outputs.GetClusterNodeConfigGvnicResult']:
        """
        Enable or disable gvnic in the node pool.
        """
        return pulumi.get(self, "gvnics")

    @_builtins.property
    @pulumi.getter(name="hostMaintenancePolicies")
    def host_maintenance_policies(self) -> Sequence['outputs.GetClusterNodeConfigHostMaintenancePolicyResult']:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policies")

    @_builtins.property
    @pulumi.getter(name="imageType")
    def image_type(self) -> _builtins.str:
        """
        The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        """
        return pulumi.get(self, "image_type")

    @_builtins.property
    @pulumi.getter(name="kubeletConfigs")
    def kubelet_configs(self) -> Sequence['outputs.GetClusterNodeConfigKubeletConfigResult']:
        """
        Node kubelet configs.
        """
        return pulumi.get(self, "kubelet_configs")

    @_builtins.property
    @pulumi.getter
    def labels(self) -> Mapping[str, _builtins.str]:
        """
        The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        """
        return pulumi.get(self, "labels")

    @_builtins.property
    @pulumi.getter(name="linuxNodeConfigs")
    def linux_node_configs(self) -> Sequence['outputs.GetClusterNodeConfigLinuxNodeConfigResult']:
        """
        Parameters that can be configured on Linux nodes.
        """
        return pulumi.get(self, "linux_node_configs")

    @_builtins.property
    @pulumi.getter(name="localNvmeSsdBlockConfigs")
    def local_nvme_ssd_block_configs(self) -> Sequence['outputs.GetClusterNodeConfigLocalNvmeSsdBlockConfigResult']:
        """
        Parameters for raw-block local NVMe SSDs.
        """
        return pulumi.get(self, "local_nvme_ssd_block_configs")

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        The number of local SSD disks to be attached to the node.
        """
        return pulumi.get(self, "local_ssd_count")

    @_builtins.property
    @pulumi.getter(name="localSsdEncryptionMode")
    def local_ssd_encryption_mode(self) -> _builtins.str:
        """
        LocalSsdEncryptionMode specified the method used for encrypting the local SSDs attached to the node.
        """
        return pulumi.get(self, "local_ssd_encryption_mode")

    @_builtins.property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> _builtins.str:
        """
        Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        """
        return pulumi.get(self, "logging_variant")

    @_builtins.property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> _builtins.str:
        """
        The name of a Google Compute Engine machine type.
        """
        return pulumi.get(self, "machine_type")

    @_builtins.property
    @pulumi.getter(name="maxRunDuration")
    def max_run_duration(self) -> _builtins.str:
        """
        The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        """
        return pulumi.get(self, "max_run_duration")

    @_builtins.property
    @pulumi.getter
    def metadata(self) -> Mapping[str, _builtins.str]:
        """
        The metadata key/value pairs assigned to instances in the cluster.
        """
        return pulumi.get(self, "metadata")

    @_builtins.property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> _builtins.str:
        """
        Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        """
        return pulumi.get(self, "min_cpu_platform")

    @_builtins.property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> _builtins.str:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        """
        return pulumi.get(self, "node_group")

    @_builtins.property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Sequence[_builtins.str]:
        """
        The set of Google API scopes to be made available on all of the node VMs.
        """
        return pulumi.get(self, "oauth_scopes")

    @_builtins.property
    @pulumi.getter
    def preemptible(self) -> _builtins.bool:
        """
        Whether the nodes are created as preemptible VM instances.
        """
        return pulumi.get(self, "preemptible")

    @_builtins.property
    @pulumi.getter(name="reservationAffinities")
    def reservation_affinities(self) -> Sequence['outputs.GetClusterNodeConfigReservationAffinityResult']:
        """
        The reservation affinity configuration for the node pool.
        """
        return pulumi.get(self, "reservation_affinities")

    @_builtins.property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Mapping[str, _builtins.str]:
        """
        The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        """
        return pulumi.get(self, "resource_labels")

    @_builtins.property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Mapping[str, _builtins.str]:
        """
        A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        """
        return pulumi.get(self, "resource_manager_tags")

    @_builtins.property
    @pulumi.getter(name="sandboxConfigs")
    def sandbox_configs(self) -> Sequence['outputs.GetClusterNodeConfigSandboxConfigResult']:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_configs")

    @_builtins.property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Sequence['outputs.GetClusterNodeConfigSecondaryBootDiskResult']:
        """
        Secondary boot disks for preloading data or container images.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @_builtins.property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> _builtins.str:
        """
        The Google Cloud Platform Service Account to be used by the node VMs.
        """
        return pulumi.get(self, "service_account")

    @_builtins.property
    @pulumi.getter(name="shieldedInstanceConfigs")
    def shielded_instance_configs(self) -> Sequence['outputs.GetClusterNodeConfigShieldedInstanceConfigResult']:
        """
        Shielded Instance options.
        """
        return pulumi.get(self, "shielded_instance_configs")

    @_builtins.property
    @pulumi.getter(name="soleTenantConfigs")
    def sole_tenant_configs(self) -> Sequence['outputs.GetClusterNodeConfigSoleTenantConfigResult']:
        """
        Node affinity options for sole tenant node pools.
        """
        return pulumi.get(self, "sole_tenant_configs")

    @_builtins.property
    @pulumi.getter
    def spot(self) -> _builtins.bool:
        """
        Whether the nodes are created as spot VM instances.
        """
        return pulumi.get(self, "spot")

    @_builtins.property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Sequence[_builtins.str]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Sequence[_builtins.str]:
        """
        The list of instance tags applied to all nodes.
        """
        return pulumi.get(self, "tags")

    @_builtins.property
    @pulumi.getter
    def taints(self) -> Sequence['outputs.GetClusterNodeConfigTaintResult']:
        """
        List of Kubernetes taints to be applied to each node.
        """
        return pulumi.get(self, "taints")

    @_builtins.property
    @pulumi.getter(name="windowsNodeConfigs")
    def windows_node_configs(self) -> Sequence['outputs.GetClusterNodeConfigWindowsNodeConfigResult']:
        """
        Parameters that can be configured on Windows nodes.
        """
        return pulumi.get(self, "windows_node_configs")

    @_builtins.property
    @pulumi.getter(name="workloadMetadataConfigs")
    def workload_metadata_configs(self) -> Sequence['outputs.GetClusterNodeConfigWorkloadMetadataConfigResult']:
        """
        The workload metadata configuration for this node.
        """
        return pulumi.get(self, "workload_metadata_configs")


@pulumi.output_type
class GetClusterNodeConfigAdvancedMachineFeatureResult(dict):
    def __init__(__self__, *,
                 enable_nested_virtualization: _builtins.bool,
                 performance_monitoring_unit: _builtins.str,
                 threads_per_core: _builtins.int):
        """
        :param _builtins.bool enable_nested_virtualization: Whether the node should have nested virtualization enabled.
        :param _builtins.str performance_monitoring_unit: Level of Performance Monitoring Unit (PMU) requested. If unset, no access to the PMU is assumed.
        :param _builtins.int threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)
        pulumi.set(__self__, "performance_monitoring_unit", performance_monitoring_unit)
        pulumi.set(__self__, "threads_per_core", threads_per_core)

    @_builtins.property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> _builtins.bool:
        """
        Whether the node should have nested virtualization enabled.
        """
        return pulumi.get(self, "enable_nested_virtualization")

    @_builtins.property
    @pulumi.getter(name="performanceMonitoringUnit")
    def performance_monitoring_unit(self) -> _builtins.str:
        """
        Level of Performance Monitoring Unit (PMU) requested. If unset, no access to the PMU is assumed.
        """
        return pulumi.get(self, "performance_monitoring_unit")

    @_builtins.property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> _builtins.int:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")


@pulumi.output_type
class GetClusterNodeConfigBootDiskResult(dict):
    def __init__(__self__, *,
                 disk_type: _builtins.str,
                 provisioned_iops: _builtins.int,
                 provisioned_throughput: _builtins.int,
                 size_gb: _builtins.int):
        """
        :param _builtins.str disk_type: Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        :param _builtins.int provisioned_iops: Configured IOPs provisioning. Only valid with disk type hyperdisk-balanced.
        :param _builtins.int provisioned_throughput: Configured throughput provisioning. Only valid with disk type hyperdisk-balanced.
        :param _builtins.int size_gb: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        pulumi.set(__self__, "disk_type", disk_type)
        pulumi.set(__self__, "provisioned_iops", provisioned_iops)
        pulumi.set(__self__, "provisioned_throughput", provisioned_throughput)
        pulumi.set(__self__, "size_gb", size_gb)

    @_builtins.property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> _builtins.str:
        """
        Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        """
        return pulumi.get(self, "disk_type")

    @_builtins.property
    @pulumi.getter(name="provisionedIops")
    def provisioned_iops(self) -> _builtins.int:
        """
        Configured IOPs provisioning. Only valid with disk type hyperdisk-balanced.
        """
        return pulumi.get(self, "provisioned_iops")

    @_builtins.property
    @pulumi.getter(name="provisionedThroughput")
    def provisioned_throughput(self) -> _builtins.int:
        """
        Configured throughput provisioning. Only valid with disk type hyperdisk-balanced.
        """
        return pulumi.get(self, "provisioned_throughput")

    @_builtins.property
    @pulumi.getter(name="sizeGb")
    def size_gb(self) -> _builtins.int:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        return pulumi.get(self, "size_gb")


@pulumi.output_type
class GetClusterNodeConfigConfidentialNodeResult(dict):
    def __init__(__self__, *,
                 confidential_instance_type: _builtins.str,
                 enabled: _builtins.bool):
        """
        :param _builtins.str confidential_instance_type: Defines the type of technology used by the confidential node.
        :param _builtins.bool enabled: Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        pulumi.set(__self__, "confidential_instance_type", confidential_instance_type)
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter(name="confidentialInstanceType")
    def confidential_instance_type(self) -> _builtins.str:
        """
        Defines the type of technology used by the confidential node.
        """
        return pulumi.get(self, "confidential_instance_type")

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigContainerdConfigResult(dict):
    def __init__(__self__, *,
                 private_registry_access_configs: Sequence['outputs.GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigResult'],
                 writable_cgroups: Sequence['outputs.GetClusterNodeConfigContainerdConfigWritableCgroupResult']):
        """
        :param Sequence['GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs'] private_registry_access_configs: Parameters for private container registries configuration.
        :param Sequence['GetClusterNodeConfigContainerdConfigWritableCgroupArgs'] writable_cgroups: Parameters for writable cgroups configuration.
        """
        pulumi.set(__self__, "private_registry_access_configs", private_registry_access_configs)
        pulumi.set(__self__, "writable_cgroups", writable_cgroups)

    @_builtins.property
    @pulumi.getter(name="privateRegistryAccessConfigs")
    def private_registry_access_configs(self) -> Sequence['outputs.GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigResult']:
        """
        Parameters for private container registries configuration.
        """
        return pulumi.get(self, "private_registry_access_configs")

    @_builtins.property
    @pulumi.getter(name="writableCgroups")
    def writable_cgroups(self) -> Sequence['outputs.GetClusterNodeConfigContainerdConfigWritableCgroupResult']:
        """
        Parameters for writable cgroups configuration.
        """
        return pulumi.get(self, "writable_cgroups")


@pulumi.output_type
class GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigResult(dict):
    def __init__(__self__, *,
                 certificate_authority_domain_configs: Sequence['outputs.GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult'],
                 enabled: _builtins.bool):
        """
        :param Sequence['GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: Parameters for configuring CA certificate and domains.
        :param _builtins.bool enabled: Whether or not private registries are configured.
        """
        pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Sequence['outputs.GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult']:
        """
        Parameters for configuring CA certificate and domains.
        """
        return pulumi.get(self, "certificate_authority_domain_configs")

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not private registries are configured.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult(dict):
    def __init__(__self__, *,
                 fqdns: Sequence[_builtins.str],
                 gcp_secret_manager_certificate_configs: Sequence['outputs.GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult']):
        """
        :param Sequence[_builtins.str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param Sequence['GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs'] gcp_secret_manager_certificate_configs: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_configs", gcp_secret_manager_certificate_configs)

    @_builtins.property
    @pulumi.getter
    def fqdns(self) -> Sequence[_builtins.str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @_builtins.property
    @pulumi.getter(name="gcpSecretManagerCertificateConfigs")
    def gcp_secret_manager_certificate_configs(self) -> Sequence['outputs.GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult']:
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_configs")


@pulumi.output_type
class GetClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult(dict):
    def __init__(__self__, *,
                 secret_uri: _builtins.str):
        """
        :param _builtins.str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @_builtins.property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> _builtins.str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class GetClusterNodeConfigContainerdConfigWritableCgroupResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether writable cgroups are enabled.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether writable cgroups are enabled.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigEffectiveTaintResult(dict):
    def __init__(__self__, *,
                 effect: _builtins.str,
                 key: _builtins.str,
                 value: _builtins.str):
        """
        :param _builtins.str effect: Effect for taint.
        :param _builtins.str key: Key for taint.
        :param _builtins.str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def effect(self) -> _builtins.str:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def value(self) -> _builtins.str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class GetClusterNodeConfigEphemeralStorageConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: _builtins.int):
        """
        :param _builtins.int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodeConfigEphemeralStorageLocalSsdConfigResult(dict):
    def __init__(__self__, *,
                 data_cache_count: _builtins.int,
                 local_ssd_count: _builtins.int):
        """
        :param _builtins.int data_cache_count: Number of local SSDs to be utilized for GKE Data Cache. Uses NVMe interfaces.
        :param _builtins.int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        pulumi.set(__self__, "data_cache_count", data_cache_count)
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @_builtins.property
    @pulumi.getter(name="dataCacheCount")
    def data_cache_count(self) -> _builtins.int:
        """
        Number of local SSDs to be utilized for GKE Data Cache. Uses NVMe interfaces.
        """
        return pulumi.get(self, "data_cache_count")

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodeConfigFastSocketResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigGcfsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not GCFS is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not GCFS is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigGuestAcceleratorResult(dict):
    def __init__(__self__, *,
                 count: _builtins.int,
                 gpu_driver_installation_configs: Sequence['outputs.GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult'],
                 gpu_partition_size: _builtins.str,
                 gpu_sharing_configs: Sequence['outputs.GetClusterNodeConfigGuestAcceleratorGpuSharingConfigResult'],
                 type: _builtins.str):
        """
        :param _builtins.int count: The number of the accelerator cards exposed to an instance.
        :param Sequence['GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs'] gpu_driver_installation_configs: Configuration for auto installation of GPU driver.
        :param _builtins.str gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        :param Sequence['GetClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs'] gpu_sharing_configs: Configuration for GPU sharing.
        :param _builtins.str type: The accelerator type resource name.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "gpu_driver_installation_configs", gpu_driver_installation_configs)
        pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        pulumi.set(__self__, "gpu_sharing_configs", gpu_sharing_configs)
        pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter
    def count(self) -> _builtins.int:
        """
        The number of the accelerator cards exposed to an instance.
        """
        return pulumi.get(self, "count")

    @_builtins.property
    @pulumi.getter(name="gpuDriverInstallationConfigs")
    def gpu_driver_installation_configs(self) -> Sequence['outputs.GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult']:
        """
        Configuration for auto installation of GPU driver.
        """
        return pulumi.get(self, "gpu_driver_installation_configs")

    @_builtins.property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> _builtins.str:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        """
        return pulumi.get(self, "gpu_partition_size")

    @_builtins.property
    @pulumi.getter(name="gpuSharingConfigs")
    def gpu_sharing_configs(self) -> Sequence['outputs.GetClusterNodeConfigGuestAcceleratorGpuSharingConfigResult']:
        """
        Configuration for GPU sharing.
        """
        return pulumi.get(self, "gpu_sharing_configs")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        The accelerator type resource name.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult(dict):
    def __init__(__self__, *,
                 gpu_driver_version: _builtins.str):
        """
        :param _builtins.str gpu_driver_version: Mode for how the GPU driver is installed.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @_builtins.property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> _builtins.str:
        """
        Mode for how the GPU driver is installed.
        """
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class GetClusterNodeConfigGuestAcceleratorGpuSharingConfigResult(dict):
    def __init__(__self__, *,
                 gpu_sharing_strategy: _builtins.str,
                 max_shared_clients_per_gpu: _builtins.int):
        """
        :param _builtins.str gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        :param _builtins.int max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @_builtins.property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> _builtins.str:
        """
        The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @_builtins.property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> _builtins.int:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class GetClusterNodeConfigGvnicResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not gvnic is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not gvnic is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodeConfigHostMaintenancePolicyResult(dict):
    def __init__(__self__, *,
                 maintenance_interval: _builtins.str):
        """
        :param _builtins.str maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @_builtins.property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> _builtins.str:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class GetClusterNodeConfigKubeletConfigResult(dict):
    def __init__(__self__, *,
                 allowed_unsafe_sysctls: Sequence[_builtins.str],
                 container_log_max_files: _builtins.int,
                 container_log_max_size: _builtins.str,
                 cpu_cfs_quota: _builtins.bool,
                 cpu_cfs_quota_period: _builtins.str,
                 cpu_manager_policy: _builtins.str,
                 eviction_max_pod_grace_period_seconds: _builtins.int,
                 eviction_minimum_reclaims: Sequence['outputs.GetClusterNodeConfigKubeletConfigEvictionMinimumReclaimResult'],
                 eviction_soft_grace_periods: Sequence['outputs.GetClusterNodeConfigKubeletConfigEvictionSoftGracePeriodResult'],
                 eviction_softs: Sequence['outputs.GetClusterNodeConfigKubeletConfigEvictionSoftResult'],
                 image_gc_high_threshold_percent: _builtins.int,
                 image_gc_low_threshold_percent: _builtins.int,
                 image_maximum_gc_age: _builtins.str,
                 image_minimum_gc_age: _builtins.str,
                 insecure_kubelet_readonly_port_enabled: _builtins.str,
                 max_parallel_image_pulls: _builtins.int,
                 memory_managers: Sequence['outputs.GetClusterNodeConfigKubeletConfigMemoryManagerResult'],
                 pod_pids_limit: _builtins.int,
                 single_process_oom_kill: _builtins.bool,
                 topology_managers: Sequence['outputs.GetClusterNodeConfigKubeletConfigTopologyManagerResult']):
        """
        :param Sequence[_builtins.str] allowed_unsafe_sysctls: Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods.
        :param _builtins.int container_log_max_files: Defines the maximum number of container log files that can be present for a container.
        :param _builtins.str container_log_max_size: Defines the maximum size of the container log file before it is rotated.
        :param _builtins.bool cpu_cfs_quota: Enable CPU CFS quota enforcement for containers that specify CPU limits.
        :param _builtins.str cpu_cfs_quota_period: Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        :param _builtins.str cpu_manager_policy: Control the CPU management policy on the node.
        :param _builtins.int eviction_max_pod_grace_period_seconds: Defines the maximum allowed grace period (in seconds) to use when terminating pods in response to a soft eviction threshold being met.
        :param Sequence['GetClusterNodeConfigKubeletConfigEvictionMinimumReclaimArgs'] eviction_minimum_reclaims: Defines a map of signal names to percentage that defines minimum reclaims. It describes the minimum amount of a given resource the kubelet will reclaim when performing a pod eviction.
        :param Sequence['GetClusterNodeConfigKubeletConfigEvictionSoftGracePeriodArgs'] eviction_soft_grace_periods: Defines a map of signal names to durations that defines grace periods for soft eviction thresholds. Each soft eviction threshold must have a corresponding grace period.
        :param Sequence['GetClusterNodeConfigKubeletConfigEvictionSoftArgs'] eviction_softs: Defines a map of signal names to quantities or percentage that defines soft eviction thresholds.
        :param _builtins.int image_gc_high_threshold_percent: Defines the percent of disk usage after which image garbage collection is always run.
        :param _builtins.int image_gc_low_threshold_percent: Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to.
        :param _builtins.str image_maximum_gc_age: Defines the maximum age an image can be unused before it is garbage collected.
        :param _builtins.str image_minimum_gc_age: Defines the minimum age for an unused image before it is garbage collected.
        :param _builtins.str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param _builtins.int max_parallel_image_pulls: Set the maximum number of image pulls in parallel.
        :param Sequence['GetClusterNodeConfigKubeletConfigMemoryManagerArgs'] memory_managers: Configuration for the Memory Manager on the node. The memory manager optimizes memory and hugepages allocation for pods, especially those in the Guaranteed QoS class, by influencing NUMA affinity.
        :param _builtins.int pod_pids_limit: Controls the maximum number of processes allowed to run in a pod.
        :param _builtins.bool single_process_oom_kill: Defines whether to enable single process OOM killer.
        :param Sequence['GetClusterNodeConfigKubeletConfigTopologyManagerArgs'] topology_managers: Configuration for the Topology Manager on the node. The Topology Manager aligns CPU, memory, and device resources on a node to optimize performance, especially for NUMA-aware workloads, by ensuring resource co-location.
        """
        pulumi.set(__self__, "allowed_unsafe_sysctls", allowed_unsafe_sysctls)
        pulumi.set(__self__, "container_log_max_files", container_log_max_files)
        pulumi.set(__self__, "container_log_max_size", container_log_max_size)
        pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        pulumi.set(__self__, "eviction_max_pod_grace_period_seconds", eviction_max_pod_grace_period_seconds)
        pulumi.set(__self__, "eviction_minimum_reclaims", eviction_minimum_reclaims)
        pulumi.set(__self__, "eviction_soft_grace_periods", eviction_soft_grace_periods)
        pulumi.set(__self__, "eviction_softs", eviction_softs)
        pulumi.set(__self__, "image_gc_high_threshold_percent", image_gc_high_threshold_percent)
        pulumi.set(__self__, "image_gc_low_threshold_percent", image_gc_low_threshold_percent)
        pulumi.set(__self__, "image_maximum_gc_age", image_maximum_gc_age)
        pulumi.set(__self__, "image_minimum_gc_age", image_minimum_gc_age)
        pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        pulumi.set(__self__, "max_parallel_image_pulls", max_parallel_image_pulls)
        pulumi.set(__self__, "memory_managers", memory_managers)
        pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)
        pulumi.set(__self__, "single_process_oom_kill", single_process_oom_kill)
        pulumi.set(__self__, "topology_managers", topology_managers)

    @_builtins.property
    @pulumi.getter(name="allowedUnsafeSysctls")
    def allowed_unsafe_sysctls(self) -> Sequence[_builtins.str]:
        """
        Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods.
        """
        return pulumi.get(self, "allowed_unsafe_sysctls")

    @_builtins.property
    @pulumi.getter(name="containerLogMaxFiles")
    def container_log_max_files(self) -> _builtins.int:
        """
        Defines the maximum number of container log files that can be present for a container.
        """
        return pulumi.get(self, "container_log_max_files")

    @_builtins.property
    @pulumi.getter(name="containerLogMaxSize")
    def container_log_max_size(self) -> _builtins.str:
        """
        Defines the maximum size of the container log file before it is rotated.
        """
        return pulumi.get(self, "container_log_max_size")

    @_builtins.property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> _builtins.bool:
        """
        Enable CPU CFS quota enforcement for containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @_builtins.property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> _builtins.str:
        """
        Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @_builtins.property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> _builtins.str:
        """
        Control the CPU management policy on the node.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @_builtins.property
    @pulumi.getter(name="evictionMaxPodGracePeriodSeconds")
    def eviction_max_pod_grace_period_seconds(self) -> _builtins.int:
        """
        Defines the maximum allowed grace period (in seconds) to use when terminating pods in response to a soft eviction threshold being met.
        """
        return pulumi.get(self, "eviction_max_pod_grace_period_seconds")

    @_builtins.property
    @pulumi.getter(name="evictionMinimumReclaims")
    def eviction_minimum_reclaims(self) -> Sequence['outputs.GetClusterNodeConfigKubeletConfigEvictionMinimumReclaimResult']:
        """
        Defines a map of signal names to percentage that defines minimum reclaims. It describes the minimum amount of a given resource the kubelet will reclaim when performing a pod eviction.
        """
        return pulumi.get(self, "eviction_minimum_reclaims")

    @_builtins.property
    @pulumi.getter(name="evictionSoftGracePeriods")
    def eviction_soft_grace_periods(self) -> Sequence['outputs.GetClusterNodeConfigKubeletConfigEvictionSoftGracePeriodResult']:
        """
        Defines a map of signal names to durations that defines grace periods for soft eviction thresholds. Each soft eviction threshold must have a corresponding grace period.
        """
        return pulumi.get(self, "eviction_soft_grace_periods")

    @_builtins.property
    @pulumi.getter(name="evictionSofts")
    def eviction_softs(self) -> Sequence['outputs.GetClusterNodeConfigKubeletConfigEvictionSoftResult']:
        """
        Defines a map of signal names to quantities or percentage that defines soft eviction thresholds.
        """
        return pulumi.get(self, "eviction_softs")

    @_builtins.property
    @pulumi.getter(name="imageGcHighThresholdPercent")
    def image_gc_high_threshold_percent(self) -> _builtins.int:
        """
        Defines the percent of disk usage after which image garbage collection is always run.
        """
        return pulumi.get(self, "image_gc_high_threshold_percent")

    @_builtins.property
    @pulumi.getter(name="imageGcLowThresholdPercent")
    def image_gc_low_threshold_percent(self) -> _builtins.int:
        """
        Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to.
        """
        return pulumi.get(self, "image_gc_low_threshold_percent")

    @_builtins.property
    @pulumi.getter(name="imageMaximumGcAge")
    def image_maximum_gc_age(self) -> _builtins.str:
        """
        Defines the maximum age an image can be unused before it is garbage collected.
        """
        return pulumi.get(self, "image_maximum_gc_age")

    @_builtins.property
    @pulumi.getter(name="imageMinimumGcAge")
    def image_minimum_gc_age(self) -> _builtins.str:
        """
        Defines the minimum age for an unused image before it is garbage collected.
        """
        return pulumi.get(self, "image_minimum_gc_age")

    @_builtins.property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> _builtins.str:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @_builtins.property
    @pulumi.getter(name="maxParallelImagePulls")
    def max_parallel_image_pulls(self) -> _builtins.int:
        """
        Set the maximum number of image pulls in parallel.
        """
        return pulumi.get(self, "max_parallel_image_pulls")

    @_builtins.property
    @pulumi.getter(name="memoryManagers")
    def memory_managers(self) -> Sequence['outputs.GetClusterNodeConfigKubeletConfigMemoryManagerResult']:
        """
        Configuration for the Memory Manager on the node. The memory manager optimizes memory and hugepages allocation for pods, especially those in the Guaranteed QoS class, by influencing NUMA affinity.
        """
        return pulumi.get(self, "memory_managers")

    @_builtins.property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> _builtins.int:
        """
        Controls the maximum number of processes allowed to run in a pod.
        """
        return pulumi.get(self, "pod_pids_limit")

    @_builtins.property
    @pulumi.getter(name="singleProcessOomKill")
    def single_process_oom_kill(self) -> _builtins.bool:
        """
        Defines whether to enable single process OOM killer.
        """
        return pulumi.get(self, "single_process_oom_kill")

    @_builtins.property
    @pulumi.getter(name="topologyManagers")
    def topology_managers(self) -> Sequence['outputs.GetClusterNodeConfigKubeletConfigTopologyManagerResult']:
        """
        Configuration for the Topology Manager on the node. The Topology Manager aligns CPU, memory, and device resources on a node to optimize performance, especially for NUMA-aware workloads, by ensuring resource co-location.
        """
        return pulumi.get(self, "topology_managers")


@pulumi.output_type
class GetClusterNodeConfigKubeletConfigEvictionMinimumReclaimResult(dict):
    def __init__(__self__, *,
                 imagefs_available: _builtins.str,
                 imagefs_inodes_free: _builtins.str,
                 memory_available: _builtins.str,
                 nodefs_available: _builtins.str,
                 nodefs_inodes_free: _builtins.str,
                 pid_available: _builtins.str):
        """
        :param _builtins.str imagefs_available: Defines percentage of minimum reclaim for imagefs.available.
        :param _builtins.str imagefs_inodes_free: Defines percentage of minimum reclaim for imagefs.inodesFree.
        :param _builtins.str memory_available: Defines percentage of minimum reclaim for memory.available.
        :param _builtins.str nodefs_available: Defines percentage of minimum reclaim for nodefs.available.
        :param _builtins.str nodefs_inodes_free: Defines percentage of minimum reclaim for nodefs.inodesFree.
        :param _builtins.str pid_available: Defines percentage of minimum reclaim for pid.available.
        """
        pulumi.set(__self__, "imagefs_available", imagefs_available)
        pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        pulumi.set(__self__, "memory_available", memory_available)
        pulumi.set(__self__, "nodefs_available", nodefs_available)
        pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> _builtins.str:
        """
        Defines percentage of minimum reclaim for imagefs.available.
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> _builtins.str:
        """
        Defines percentage of minimum reclaim for imagefs.inodesFree.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> _builtins.str:
        """
        Defines percentage of minimum reclaim for memory.available.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> _builtins.str:
        """
        Defines percentage of minimum reclaim for nodefs.available.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> _builtins.str:
        """
        Defines percentage of minimum reclaim for nodefs.inodesFree.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> _builtins.str:
        """
        Defines percentage of minimum reclaim for pid.available.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class GetClusterNodeConfigKubeletConfigEvictionSoftResult(dict):
    def __init__(__self__, *,
                 imagefs_available: _builtins.str,
                 imagefs_inodes_free: _builtins.str,
                 memory_available: _builtins.str,
                 nodefs_available: _builtins.str,
                 nodefs_inodes_free: _builtins.str,
                 pid_available: _builtins.str):
        """
        :param _builtins.str imagefs_available: Defines percentage of soft eviction threshold for imagefs.available.
        :param _builtins.str imagefs_inodes_free: Defines percentage of soft eviction threshold for imagefs.inodesFree.
        :param _builtins.str memory_available: Defines quantity of soft eviction threshold for memory.available.
        :param _builtins.str nodefs_available: Defines percentage of soft eviction threshold for nodefs.available.
        :param _builtins.str nodefs_inodes_free: Defines percentage of soft eviction threshold for nodefs.inodesFree.
        :param _builtins.str pid_available: Defines percentage of soft eviction threshold for pid.available.
        """
        pulumi.set(__self__, "imagefs_available", imagefs_available)
        pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        pulumi.set(__self__, "memory_available", memory_available)
        pulumi.set(__self__, "nodefs_available", nodefs_available)
        pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> _builtins.str:
        """
        Defines percentage of soft eviction threshold for imagefs.available.
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> _builtins.str:
        """
        Defines percentage of soft eviction threshold for imagefs.inodesFree.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> _builtins.str:
        """
        Defines quantity of soft eviction threshold for memory.available.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> _builtins.str:
        """
        Defines percentage of soft eviction threshold for nodefs.available.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> _builtins.str:
        """
        Defines percentage of soft eviction threshold for nodefs.inodesFree.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> _builtins.str:
        """
        Defines percentage of soft eviction threshold for pid.available.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class GetClusterNodeConfigKubeletConfigEvictionSoftGracePeriodResult(dict):
    def __init__(__self__, *,
                 imagefs_available: _builtins.str,
                 imagefs_inodes_free: _builtins.str,
                 memory_available: _builtins.str,
                 nodefs_available: _builtins.str,
                 nodefs_inodes_free: _builtins.str,
                 pid_available: _builtins.str):
        """
        :param _builtins.str imagefs_available: Defines grace period for the imagefs.available soft eviction threshold
        :param _builtins.str imagefs_inodes_free: Defines grace period for the imagefs.inodesFree soft eviction threshold.
        :param _builtins.str memory_available: Defines grace period for the memory.available soft eviction threshold.
        :param _builtins.str nodefs_available: Defines grace period for the nodefs.available soft eviction threshold.
        :param _builtins.str nodefs_inodes_free: Defines grace period for the nodefs.inodesFree soft eviction threshold.
        :param _builtins.str pid_available: Defines grace period for the pid.available soft eviction threshold.
        """
        pulumi.set(__self__, "imagefs_available", imagefs_available)
        pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        pulumi.set(__self__, "memory_available", memory_available)
        pulumi.set(__self__, "nodefs_available", nodefs_available)
        pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> _builtins.str:
        """
        Defines grace period for the imagefs.available soft eviction threshold
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> _builtins.str:
        """
        Defines grace period for the imagefs.inodesFree soft eviction threshold.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> _builtins.str:
        """
        Defines grace period for the memory.available soft eviction threshold.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> _builtins.str:
        """
        Defines grace period for the nodefs.available soft eviction threshold.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> _builtins.str:
        """
        Defines grace period for the nodefs.inodesFree soft eviction threshold.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> _builtins.str:
        """
        Defines grace period for the pid.available soft eviction threshold.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class GetClusterNodeConfigKubeletConfigMemoryManagerResult(dict):
    def __init__(__self__, *,
                 policy: _builtins.str):
        """
        :param _builtins.str policy: The Memory Manager policy to use. This policy guides how memory and hugepages are allocated and managed for pods on the node, influencing NUMA affinity.
        """
        pulumi.set(__self__, "policy", policy)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> _builtins.str:
        """
        The Memory Manager policy to use. This policy guides how memory and hugepages are allocated and managed for pods on the node, influencing NUMA affinity.
        """
        return pulumi.get(self, "policy")


@pulumi.output_type
class GetClusterNodeConfigKubeletConfigTopologyManagerResult(dict):
    def __init__(__self__, *,
                 policy: _builtins.str,
                 scope: _builtins.str):
        """
        :param _builtins.str policy: The Topology Manager policy to use. This policy dictates how resource alignment is handled on the node.
        :param _builtins.str scope: The Topology Manager scope, defining the granularity at which policy decisions are applied. Valid values are "container" (resources are aligned per container within a pod) or "pod" (resources are aligned for the entire pod).
        """
        pulumi.set(__self__, "policy", policy)
        pulumi.set(__self__, "scope", scope)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> _builtins.str:
        """
        The Topology Manager policy to use. This policy dictates how resource alignment is handled on the node.
        """
        return pulumi.get(self, "policy")

    @_builtins.property
    @pulumi.getter
    def scope(self) -> _builtins.str:
        """
        The Topology Manager scope, defining the granularity at which policy decisions are applied. Valid values are "container" (resources are aligned per container within a pod) or "pod" (resources are aligned for the entire pod).
        """
        return pulumi.get(self, "scope")


@pulumi.output_type
class GetClusterNodeConfigLinuxNodeConfigResult(dict):
    def __init__(__self__, *,
                 cgroup_mode: _builtins.str,
                 hugepages_configs: Sequence['outputs.GetClusterNodeConfigLinuxNodeConfigHugepagesConfigResult'],
                 node_kernel_module_loadings: Sequence['outputs.GetClusterNodeConfigLinuxNodeConfigNodeKernelModuleLoadingResult'],
                 sysctls: Mapping[str, _builtins.str],
                 transparent_hugepage_defrag: _builtins.str,
                 transparent_hugepage_enabled: _builtins.str):
        """
        :param _builtins.str cgroup_mode: cgroupMode specifies the cgroup mode to be used on the node.
        :param Sequence['GetClusterNodeConfigLinuxNodeConfigHugepagesConfigArgs'] hugepages_configs: Amounts for 2M and 1G hugepages.
        :param Sequence['GetClusterNodeConfigLinuxNodeConfigNodeKernelModuleLoadingArgs'] node_kernel_module_loadings: The settings for kernel module loading.
        :param Mapping[str, _builtins.str] sysctls: The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        :param _builtins.str transparent_hugepage_defrag: The Linux kernel transparent hugepage defrag setting.
        :param _builtins.str transparent_hugepage_enabled: The Linux kernel transparent hugepage setting.
        """
        pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        pulumi.set(__self__, "hugepages_configs", hugepages_configs)
        pulumi.set(__self__, "node_kernel_module_loadings", node_kernel_module_loadings)
        pulumi.set(__self__, "sysctls", sysctls)
        pulumi.set(__self__, "transparent_hugepage_defrag", transparent_hugepage_defrag)
        pulumi.set(__self__, "transparent_hugepage_enabled", transparent_hugepage_enabled)

    @_builtins.property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> _builtins.str:
        """
        cgroupMode specifies the cgroup mode to be used on the node.
        """
        return pulumi.get(self, "cgroup_mode")

    @_builtins.property
    @pulumi.getter(name="hugepagesConfigs")
    def hugepages_configs(self) -> Sequence['outputs.GetClusterNodeConfigLinuxNodeConfigHugepagesConfigResult']:
        """
        Amounts for 2M and 1G hugepages.
        """
        return pulumi.get(self, "hugepages_configs")

    @_builtins.property
    @pulumi.getter(name="nodeKernelModuleLoadings")
    def node_kernel_module_loadings(self) -> Sequence['outputs.GetClusterNodeConfigLinuxNodeConfigNodeKernelModuleLoadingResult']:
        """
        The settings for kernel module loading.
        """
        return pulumi.get(self, "node_kernel_module_loadings")

    @_builtins.property
    @pulumi.getter
    def sysctls(self) -> Mapping[str, _builtins.str]:
        """
        The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        """
        return pulumi.get(self, "sysctls")

    @_builtins.property
    @pulumi.getter(name="transparentHugepageDefrag")
    def transparent_hugepage_defrag(self) -> _builtins.str:
        """
        The Linux kernel transparent hugepage defrag setting.
        """
        return pulumi.get(self, "transparent_hugepage_defrag")

    @_builtins.property
    @pulumi.getter(name="transparentHugepageEnabled")
    def transparent_hugepage_enabled(self) -> _builtins.str:
        """
        The Linux kernel transparent hugepage setting.
        """
        return pulumi.get(self, "transparent_hugepage_enabled")


@pulumi.output_type
class GetClusterNodeConfigLinuxNodeConfigHugepagesConfigResult(dict):
    def __init__(__self__, *,
                 hugepage_size1g: _builtins.int,
                 hugepage_size2m: _builtins.int):
        """
        :param _builtins.int hugepage_size1g: Amount of 1G hugepages.
        :param _builtins.int hugepage_size2m: Amount of 2M hugepages.
        """
        pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @_builtins.property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> _builtins.int:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @_builtins.property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> _builtins.int:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")


@pulumi.output_type
class GetClusterNodeConfigLinuxNodeConfigNodeKernelModuleLoadingResult(dict):
    def __init__(__self__, *,
                 policy: _builtins.str):
        """
        :param _builtins.str policy: The policy for kernel module loading.
        """
        pulumi.set(__self__, "policy", policy)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> _builtins.str:
        """
        The policy for kernel module loading.
        """
        return pulumi.get(self, "policy")


@pulumi.output_type
class GetClusterNodeConfigLocalNvmeSsdBlockConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: _builtins.int):
        """
        :param _builtins.int local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodeConfigReservationAffinityResult(dict):
    def __init__(__self__, *,
                 consume_reservation_type: _builtins.str,
                 key: _builtins.str,
                 values: Sequence[_builtins.str]):
        """
        :param _builtins.str consume_reservation_type: Corresponds to the type of reservation consumption.
        :param _builtins.str key: The label key of a reservation resource.
        :param Sequence[_builtins.str] values: The label values of the reservation resource.
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "values", values)

    @_builtins.property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> _builtins.str:
        """
        Corresponds to the type of reservation consumption.
        """
        return pulumi.get(self, "consume_reservation_type")

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        The label key of a reservation resource.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def values(self) -> Sequence[_builtins.str]:
        """
        The label values of the reservation resource.
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class GetClusterNodeConfigSandboxConfigResult(dict):
    def __init__(__self__, *,
                 sandbox_type: _builtins.str):
        """
        :param _builtins.str sandbox_type: Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @_builtins.property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> _builtins.str:
        """
        Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class GetClusterNodeConfigSecondaryBootDiskResult(dict):
    def __init__(__self__, *,
                 disk_image: _builtins.str,
                 mode: _builtins.str):
        """
        :param _builtins.str disk_image: Disk image to create the secondary boot disk from
        :param _builtins.str mode: Mode for how the secondary boot disk is used.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        pulumi.set(__self__, "mode", mode)

    @_builtins.property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> _builtins.str:
        """
        Disk image to create the secondary boot disk from
        """
        return pulumi.get(self, "disk_image")

    @_builtins.property
    @pulumi.getter
    def mode(self) -> _builtins.str:
        """
        Mode for how the secondary boot disk is used.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class GetClusterNodeConfigShieldedInstanceConfigResult(dict):
    def __init__(__self__, *,
                 enable_integrity_monitoring: _builtins.bool,
                 enable_secure_boot: _builtins.bool):
        """
        :param _builtins.bool enable_integrity_monitoring: Defines whether the instance has integrity monitoring enabled.
        :param _builtins.bool enable_secure_boot: Defines whether the instance has Secure Boot enabled.
        """
        pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @_builtins.property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> _builtins.bool:
        """
        Defines whether the instance has integrity monitoring enabled.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @_builtins.property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> _builtins.bool:
        """
        Defines whether the instance has Secure Boot enabled.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class GetClusterNodeConfigSoleTenantConfigResult(dict):
    def __init__(__self__, *,
                 min_node_cpus: _builtins.int,
                 node_affinities: Sequence['outputs.GetClusterNodeConfigSoleTenantConfigNodeAffinityResult']):
        """
        :param _builtins.int min_node_cpus: Specifies the minimum number of vCPUs that each sole tenant node must have to use CPU overcommit. If not specified, the CPU overcommit feature is disabled.
        :param Sequence['GetClusterNodeConfigSoleTenantConfigNodeAffinityArgs'] node_affinities: .
        """
        pulumi.set(__self__, "min_node_cpus", min_node_cpus)
        pulumi.set(__self__, "node_affinities", node_affinities)

    @_builtins.property
    @pulumi.getter(name="minNodeCpus")
    def min_node_cpus(self) -> _builtins.int:
        """
        Specifies the minimum number of vCPUs that each sole tenant node must have to use CPU overcommit. If not specified, the CPU overcommit feature is disabled.
        """
        return pulumi.get(self, "min_node_cpus")

    @_builtins.property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.GetClusterNodeConfigSoleTenantConfigNodeAffinityResult']:
        """
        .
        """
        return pulumi.get(self, "node_affinities")


@pulumi.output_type
class GetClusterNodeConfigSoleTenantConfigNodeAffinityResult(dict):
    def __init__(__self__, *,
                 key: _builtins.str,
                 operator: _builtins.str,
                 values: Sequence[_builtins.str]):
        """
        :param _builtins.str key: .
        :param _builtins.str operator: .
        :param Sequence[_builtins.str] values: .
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        .
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def operator(self) -> _builtins.str:
        """
        .
        """
        return pulumi.get(self, "operator")

    @_builtins.property
    @pulumi.getter
    def values(self) -> Sequence[_builtins.str]:
        """
        .
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class GetClusterNodeConfigTaintResult(dict):
    def __init__(__self__, *,
                 effect: _builtins.str,
                 key: _builtins.str,
                 value: _builtins.str):
        """
        :param _builtins.str effect: Effect for taint.
        :param _builtins.str key: Key for taint.
        :param _builtins.str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def effect(self) -> _builtins.str:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def value(self) -> _builtins.str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class GetClusterNodeConfigWindowsNodeConfigResult(dict):
    def __init__(__self__, *,
                 osversion: _builtins.str):
        """
        :param _builtins.str osversion: The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        pulumi.set(__self__, "osversion", osversion)

    @_builtins.property
    @pulumi.getter
    def osversion(self) -> _builtins.str:
        """
        The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        return pulumi.get(self, "osversion")


@pulumi.output_type
class GetClusterNodeConfigWorkloadMetadataConfigResult(dict):
    def __init__(__self__, *,
                 mode: _builtins.str):
        """
        :param _builtins.str mode: Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        pulumi.set(__self__, "mode", mode)

    @_builtins.property
    @pulumi.getter
    def mode(self) -> _builtins.str:
        """
        Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class GetClusterNodePoolResult(dict):
    def __init__(__self__, *,
                 autoscalings: Sequence['outputs.GetClusterNodePoolAutoscalingResult'],
                 initial_node_count: _builtins.int,
                 instance_group_urls: Sequence[_builtins.str],
                 managed_instance_group_urls: Sequence[_builtins.str],
                 managements: Sequence['outputs.GetClusterNodePoolManagementResult'],
                 max_pods_per_node: _builtins.int,
                 name: _builtins.str,
                 name_prefix: _builtins.str,
                 network_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigResult'],
                 node_configs: Sequence['outputs.GetClusterNodePoolNodeConfigResult'],
                 node_count: _builtins.int,
                 node_locations: Sequence[_builtins.str],
                 placement_policies: Sequence['outputs.GetClusterNodePoolPlacementPolicyResult'],
                 queued_provisionings: Sequence['outputs.GetClusterNodePoolQueuedProvisioningResult'],
                 upgrade_settings: Sequence['outputs.GetClusterNodePoolUpgradeSettingResult'],
                 version: _builtins.str):
        """
        :param Sequence['GetClusterNodePoolAutoscalingArgs'] autoscalings: Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
        :param _builtins.int initial_node_count: The initial number of nodes for the pool. In regional or multi-zonal clusters, this is the number of nodes per zone. Changing this will force recreation of the resource.
        :param Sequence[_builtins.str] instance_group_urls: The resource URLs of the managed instance groups associated with this node pool.
        :param Sequence[_builtins.str] managed_instance_group_urls: List of instance group URLs which have been assigned to this node pool.
        :param Sequence['GetClusterNodePoolManagementArgs'] managements: Node management configuration, wherein auto-repair and auto-upgrade is configured.
        :param _builtins.int max_pods_per_node: The maximum number of pods per node in this node pool. Note that this does not work on node pools which are "route-based" - that is, node pools belonging to clusters that do not have IP Aliasing enabled.
        :param _builtins.str name: The name of the cluster.
        :param _builtins.str name_prefix: Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.
        :param Sequence['GetClusterNodePoolNetworkConfigArgs'] network_configs: Networking configuration for this NodePool. If specified, it overrides the cluster-level defaults.
        :param Sequence['GetClusterNodePoolNodeConfigArgs'] node_configs: The configuration of the nodepool
        :param _builtins.int node_count: The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.
        :param Sequence[_builtins.str] node_locations: The list of zones in which the node pool's nodes should be located. Nodes must be in the region of their regional cluster or in the same region as their cluster's zone for zonal clusters. If unspecified, the cluster-level node_locations will be used.
        :param Sequence['GetClusterNodePoolPlacementPolicyArgs'] placement_policies: Specifies the node placement policy
        :param Sequence['GetClusterNodePoolQueuedProvisioningArgs'] queued_provisionings: Specifies the configuration of queued provisioning
        :param Sequence['GetClusterNodePoolUpgradeSettingArgs'] upgrade_settings: Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of max_surge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.
        """
        pulumi.set(__self__, "autoscalings", autoscalings)
        pulumi.set(__self__, "initial_node_count", initial_node_count)
        pulumi.set(__self__, "instance_group_urls", instance_group_urls)
        pulumi.set(__self__, "managed_instance_group_urls", managed_instance_group_urls)
        pulumi.set(__self__, "managements", managements)
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "name_prefix", name_prefix)
        pulumi.set(__self__, "network_configs", network_configs)
        pulumi.set(__self__, "node_configs", node_configs)
        pulumi.set(__self__, "node_count", node_count)
        pulumi.set(__self__, "node_locations", node_locations)
        pulumi.set(__self__, "placement_policies", placement_policies)
        pulumi.set(__self__, "queued_provisionings", queued_provisionings)
        pulumi.set(__self__, "upgrade_settings", upgrade_settings)
        pulumi.set(__self__, "version", version)

    @_builtins.property
    @pulumi.getter
    def autoscalings(self) -> Sequence['outputs.GetClusterNodePoolAutoscalingResult']:
        """
        Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
        """
        return pulumi.get(self, "autoscalings")

    @_builtins.property
    @pulumi.getter(name="initialNodeCount")
    def initial_node_count(self) -> _builtins.int:
        """
        The initial number of nodes for the pool. In regional or multi-zonal clusters, this is the number of nodes per zone. Changing this will force recreation of the resource.
        """
        return pulumi.get(self, "initial_node_count")

    @_builtins.property
    @pulumi.getter(name="instanceGroupUrls")
    def instance_group_urls(self) -> Sequence[_builtins.str]:
        """
        The resource URLs of the managed instance groups associated with this node pool.
        """
        return pulumi.get(self, "instance_group_urls")

    @_builtins.property
    @pulumi.getter(name="managedInstanceGroupUrls")
    def managed_instance_group_urls(self) -> Sequence[_builtins.str]:
        """
        List of instance group URLs which have been assigned to this node pool.
        """
        return pulumi.get(self, "managed_instance_group_urls")

    @_builtins.property
    @pulumi.getter
    def managements(self) -> Sequence['outputs.GetClusterNodePoolManagementResult']:
        """
        Node management configuration, wherein auto-repair and auto-upgrade is configured.
        """
        return pulumi.get(self, "managements")

    @_builtins.property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> _builtins.int:
        """
        The maximum number of pods per node in this node pool. Note that this does not work on node pools which are "route-based" - that is, node pools belonging to clusters that do not have IP Aliasing enabled.
        """
        return pulumi.get(self, "max_pods_per_node")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        The name of the cluster.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter(name="namePrefix")
    def name_prefix(self) -> _builtins.str:
        """
        Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.
        """
        return pulumi.get(self, "name_prefix")

    @_builtins.property
    @pulumi.getter(name="networkConfigs")
    def network_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigResult']:
        """
        Networking configuration for this NodePool. If specified, it overrides the cluster-level defaults.
        """
        return pulumi.get(self, "network_configs")

    @_builtins.property
    @pulumi.getter(name="nodeConfigs")
    def node_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigResult']:
        """
        The configuration of the nodepool
        """
        return pulumi.get(self, "node_configs")

    @_builtins.property
    @pulumi.getter(name="nodeCount")
    def node_count(self) -> _builtins.int:
        """
        The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.
        """
        return pulumi.get(self, "node_count")

    @_builtins.property
    @pulumi.getter(name="nodeLocations")
    def node_locations(self) -> Sequence[_builtins.str]:
        """
        The list of zones in which the node pool's nodes should be located. Nodes must be in the region of their regional cluster or in the same region as their cluster's zone for zonal clusters. If unspecified, the cluster-level node_locations will be used.
        """
        return pulumi.get(self, "node_locations")

    @_builtins.property
    @pulumi.getter(name="placementPolicies")
    def placement_policies(self) -> Sequence['outputs.GetClusterNodePoolPlacementPolicyResult']:
        """
        Specifies the node placement policy
        """
        return pulumi.get(self, "placement_policies")

    @_builtins.property
    @pulumi.getter(name="queuedProvisionings")
    def queued_provisionings(self) -> Sequence['outputs.GetClusterNodePoolQueuedProvisioningResult']:
        """
        Specifies the configuration of queued provisioning
        """
        return pulumi.get(self, "queued_provisionings")

    @_builtins.property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Sequence['outputs.GetClusterNodePoolUpgradeSettingResult']:
        """
        Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of max_surge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.
        """
        return pulumi.get(self, "upgrade_settings")

    @_builtins.property
    @pulumi.getter
    def version(self) -> _builtins.str:
        return pulumi.get(self, "version")


@pulumi.output_type
class GetClusterNodePoolAutoConfigResult(dict):
    def __init__(__self__, *,
                 linux_node_configs: Sequence['outputs.GetClusterNodePoolAutoConfigLinuxNodeConfigResult'],
                 network_tags: Sequence['outputs.GetClusterNodePoolAutoConfigNetworkTagResult'],
                 node_kubelet_configs: Sequence['outputs.GetClusterNodePoolAutoConfigNodeKubeletConfigResult'],
                 resource_manager_tags: Mapping[str, _builtins.str]):
        """
        :param Sequence['GetClusterNodePoolAutoConfigLinuxNodeConfigArgs'] linux_node_configs: Linux node configuration options.
        :param Sequence['GetClusterNodePoolAutoConfigNetworkTagArgs'] network_tags: Collection of Compute Engine network tags that can be applied to a node's underlying VM instance.
        :param Sequence['GetClusterNodePoolAutoConfigNodeKubeletConfigArgs'] node_kubelet_configs: Node kubelet configs.
        :param Mapping[str, _builtins.str] resource_manager_tags: A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        """
        pulumi.set(__self__, "linux_node_configs", linux_node_configs)
        pulumi.set(__self__, "network_tags", network_tags)
        pulumi.set(__self__, "node_kubelet_configs", node_kubelet_configs)
        pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)

    @_builtins.property
    @pulumi.getter(name="linuxNodeConfigs")
    def linux_node_configs(self) -> Sequence['outputs.GetClusterNodePoolAutoConfigLinuxNodeConfigResult']:
        """
        Linux node configuration options.
        """
        return pulumi.get(self, "linux_node_configs")

    @_builtins.property
    @pulumi.getter(name="networkTags")
    def network_tags(self) -> Sequence['outputs.GetClusterNodePoolAutoConfigNetworkTagResult']:
        """
        Collection of Compute Engine network tags that can be applied to a node's underlying VM instance.
        """
        return pulumi.get(self, "network_tags")

    @_builtins.property
    @pulumi.getter(name="nodeKubeletConfigs")
    def node_kubelet_configs(self) -> Sequence['outputs.GetClusterNodePoolAutoConfigNodeKubeletConfigResult']:
        """
        Node kubelet configs.
        """
        return pulumi.get(self, "node_kubelet_configs")

    @_builtins.property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Mapping[str, _builtins.str]:
        """
        A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        """
        return pulumi.get(self, "resource_manager_tags")


@pulumi.output_type
class GetClusterNodePoolAutoConfigLinuxNodeConfigResult(dict):
    def __init__(__self__, *,
                 cgroup_mode: _builtins.str,
                 node_kernel_module_loadings: Sequence['outputs.GetClusterNodePoolAutoConfigLinuxNodeConfigNodeKernelModuleLoadingResult']):
        """
        :param _builtins.str cgroup_mode: cgroupMode specifies the cgroup mode to be used on the node.
        :param Sequence['GetClusterNodePoolAutoConfigLinuxNodeConfigNodeKernelModuleLoadingArgs'] node_kernel_module_loadings: The settings for kernel module loading.
        """
        pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        pulumi.set(__self__, "node_kernel_module_loadings", node_kernel_module_loadings)

    @_builtins.property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> _builtins.str:
        """
        cgroupMode specifies the cgroup mode to be used on the node.
        """
        return pulumi.get(self, "cgroup_mode")

    @_builtins.property
    @pulumi.getter(name="nodeKernelModuleLoadings")
    def node_kernel_module_loadings(self) -> Sequence['outputs.GetClusterNodePoolAutoConfigLinuxNodeConfigNodeKernelModuleLoadingResult']:
        """
        The settings for kernel module loading.
        """
        return pulumi.get(self, "node_kernel_module_loadings")


@pulumi.output_type
class GetClusterNodePoolAutoConfigLinuxNodeConfigNodeKernelModuleLoadingResult(dict):
    def __init__(__self__, *,
                 policy: _builtins.str):
        """
        :param _builtins.str policy: The policy for kernel module loading.
        """
        pulumi.set(__self__, "policy", policy)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> _builtins.str:
        """
        The policy for kernel module loading.
        """
        return pulumi.get(self, "policy")


@pulumi.output_type
class GetClusterNodePoolAutoConfigNetworkTagResult(dict):
    def __init__(__self__, *,
                 tags: Sequence[_builtins.str]):
        """
        :param Sequence[_builtins.str] tags: List of network tags applied to auto-provisioned node pools.
        """
        pulumi.set(__self__, "tags", tags)

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Sequence[_builtins.str]:
        """
        List of network tags applied to auto-provisioned node pools.
        """
        return pulumi.get(self, "tags")


@pulumi.output_type
class GetClusterNodePoolAutoConfigNodeKubeletConfigResult(dict):
    def __init__(__self__, *,
                 insecure_kubelet_readonly_port_enabled: _builtins.str):
        """
        :param _builtins.str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)

    @_builtins.property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> _builtins.str:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")


@pulumi.output_type
class GetClusterNodePoolAutoscalingResult(dict):
    def __init__(__self__, *,
                 location_policy: _builtins.str,
                 max_node_count: _builtins.int,
                 min_node_count: _builtins.int,
                 total_max_node_count: _builtins.int,
                 total_min_node_count: _builtins.int):
        """
        :param _builtins.str location_policy: Location policy specifies the algorithm used when scaling-up the node pool. "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones. "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations, and reduces preemption risk for Spot VMs.
        :param _builtins.int max_node_count: Maximum number of nodes per zone in the node pool. Must be >= min_node_count. Cannot be used with total limits.
        :param _builtins.int min_node_count: Minimum number of nodes per zone in the node pool. Must be >=0 and <= max_node_count. Cannot be used with total limits.
        :param _builtins.int total_max_node_count: Maximum number of all nodes in the node pool. Must be >= total_min_node_count. Cannot be used with per zone limits.
        :param _builtins.int total_min_node_count: Minimum number of all nodes in the node pool. Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
        """
        pulumi.set(__self__, "location_policy", location_policy)
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)
        pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @_builtins.property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> _builtins.str:
        """
        Location policy specifies the algorithm used when scaling-up the node pool. "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones. "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations, and reduces preemption risk for Spot VMs.
        """
        return pulumi.get(self, "location_policy")

    @_builtins.property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> _builtins.int:
        """
        Maximum number of nodes per zone in the node pool. Must be >= min_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "max_node_count")

    @_builtins.property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> _builtins.int:
        """
        Minimum number of nodes per zone in the node pool. Must be >=0 and <= max_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "min_node_count")

    @_builtins.property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> _builtins.int:
        """
        Maximum number of all nodes in the node pool. Must be >= total_min_node_count. Cannot be used with per zone limits.
        """
        return pulumi.get(self, "total_max_node_count")

    @_builtins.property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> _builtins.int:
        """
        Minimum number of all nodes in the node pool. Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
        """
        return pulumi.get(self, "total_min_node_count")


@pulumi.output_type
class GetClusterNodePoolDefaultResult(dict):
    def __init__(__self__, *,
                 node_config_defaults: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultResult']):
        """
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultArgs'] node_config_defaults: Subset of NodeConfig message that has defaults.
        """
        pulumi.set(__self__, "node_config_defaults", node_config_defaults)

    @_builtins.property
    @pulumi.getter(name="nodeConfigDefaults")
    def node_config_defaults(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultResult']:
        """
        Subset of NodeConfig message that has defaults.
        """
        return pulumi.get(self, "node_config_defaults")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultResult(dict):
    def __init__(__self__, *,
                 containerd_configs: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigResult'],
                 gcfs_configs: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigResult'],
                 insecure_kubelet_readonly_port_enabled: _builtins.str,
                 logging_variant: _builtins.str):
        """
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigArgs'] containerd_configs: Parameters for containerd configuration.
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigArgs'] gcfs_configs: GCFS configuration for this node.
        :param _builtins.str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param _builtins.str logging_variant: Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        """
        pulumi.set(__self__, "containerd_configs", containerd_configs)
        pulumi.set(__self__, "gcfs_configs", gcfs_configs)
        pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        pulumi.set(__self__, "logging_variant", logging_variant)

    @_builtins.property
    @pulumi.getter(name="containerdConfigs")
    def containerd_configs(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigResult']:
        """
        Parameters for containerd configuration.
        """
        return pulumi.get(self, "containerd_configs")

    @_builtins.property
    @pulumi.getter(name="gcfsConfigs")
    def gcfs_configs(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigResult']:
        """
        GCFS configuration for this node.
        """
        return pulumi.get(self, "gcfs_configs")

    @_builtins.property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> _builtins.str:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @_builtins.property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> _builtins.str:
        """
        Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        """
        return pulumi.get(self, "logging_variant")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigResult(dict):
    def __init__(__self__, *,
                 private_registry_access_configs: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigResult'],
                 writable_cgroups: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigWritableCgroupResult']):
        """
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigArgs'] private_registry_access_configs: Parameters for private container registries configuration.
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigWritableCgroupArgs'] writable_cgroups: Parameters for writable cgroups configuration.
        """
        pulumi.set(__self__, "private_registry_access_configs", private_registry_access_configs)
        pulumi.set(__self__, "writable_cgroups", writable_cgroups)

    @_builtins.property
    @pulumi.getter(name="privateRegistryAccessConfigs")
    def private_registry_access_configs(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigResult']:
        """
        Parameters for private container registries configuration.
        """
        return pulumi.get(self, "private_registry_access_configs")

    @_builtins.property
    @pulumi.getter(name="writableCgroups")
    def writable_cgroups(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigWritableCgroupResult']:
        """
        Parameters for writable cgroups configuration.
        """
        return pulumi.get(self, "writable_cgroups")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigResult(dict):
    def __init__(__self__, *,
                 certificate_authority_domain_configs: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult'],
                 enabled: _builtins.bool):
        """
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: Parameters for configuring CA certificate and domains.
        :param _builtins.bool enabled: Whether or not private registries are configured.
        """
        pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult']:
        """
        Parameters for configuring CA certificate and domains.
        """
        return pulumi.get(self, "certificate_authority_domain_configs")

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not private registries are configured.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult(dict):
    def __init__(__self__, *,
                 fqdns: Sequence[_builtins.str],
                 gcp_secret_manager_certificate_configs: Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult']):
        """
        :param Sequence[_builtins.str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param Sequence['GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs'] gcp_secret_manager_certificate_configs: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_configs", gcp_secret_manager_certificate_configs)

    @_builtins.property
    @pulumi.getter
    def fqdns(self) -> Sequence[_builtins.str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @_builtins.property
    @pulumi.getter(name="gcpSecretManagerCertificateConfigs")
    def gcp_secret_manager_certificate_configs(self) -> Sequence['outputs.GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult']:
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_configs")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult(dict):
    def __init__(__self__, *,
                 secret_uri: _builtins.str):
        """
        :param _builtins.str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @_builtins.property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> _builtins.str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultContainerdConfigWritableCgroupResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether writable cgroups are enabled.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether writable cgroups are enabled.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolDefaultNodeConfigDefaultGcfsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not GCFS is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not GCFS is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolManagementResult(dict):
    def __init__(__self__, *,
                 auto_repair: _builtins.bool,
                 auto_upgrade: _builtins.bool):
        """
        :param _builtins.bool auto_repair: Whether the nodes will be automatically repaired. Enabled by default.
        :param _builtins.bool auto_upgrade: Whether the nodes will be automatically upgraded. Enabled by default.
        """
        pulumi.set(__self__, "auto_repair", auto_repair)
        pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @_builtins.property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> _builtins.bool:
        """
        Whether the nodes will be automatically repaired. Enabled by default.
        """
        return pulumi.get(self, "auto_repair")

    @_builtins.property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> _builtins.bool:
        """
        Whether the nodes will be automatically upgraded. Enabled by default.
        """
        return pulumi.get(self, "auto_upgrade")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigResult(dict):
    def __init__(__self__, *,
                 additional_node_network_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigResult'],
                 additional_pod_network_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigResult'],
                 create_pod_range: _builtins.bool,
                 enable_private_nodes: _builtins.bool,
                 network_performance_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigNetworkPerformanceConfigResult'],
                 pod_cidr_overprovision_configs: Sequence['outputs.GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigResult'],
                 pod_ipv4_cidr_block: _builtins.str,
                 pod_range: _builtins.str,
                 subnetwork: _builtins.str):
        """
        :param Sequence['GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs'] additional_node_network_configs: We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface
        :param Sequence['GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs'] additional_pod_network_configs: We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node
        :param _builtins.bool create_pod_range: Whether to create a new range for pod IPs in this node pool. Defaults are provided for pod_range and pod_ipv4_cidr_block if they are not specified.
        :param _builtins.bool enable_private_nodes: Whether nodes have internal IP addresses only.
        :param Sequence['GetClusterNodePoolNetworkConfigNetworkPerformanceConfigArgs'] network_performance_configs: Network bandwidth tier configuration.
        :param Sequence['GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs'] pod_cidr_overprovision_configs: Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited
        :param _builtins.str pod_ipv4_cidr_block: The IP address range for pod IPs in this node pool. Only applicable if create_pod_range is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        :param _builtins.str pod_range: The ID of the secondary range for pod IPs. If create_pod_range is true, this ID is used for the new range. If create_pod_range is false, uses an existing secondary range with this ID.
        :param _builtins.str subnetwork: The subnetwork path for the node pool. Format: projects/{project}/regions/{region}/subnetworks/{subnetwork} . If the cluster is associated with multiple subnetworks, the subnetwork for the node pool is picked based on the IP utilization during node pool creation and is immutable.
        """
        pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        pulumi.set(__self__, "create_pod_range", create_pod_range)
        pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        pulumi.set(__self__, "network_performance_configs", network_performance_configs)
        pulumi.set(__self__, "pod_cidr_overprovision_configs", pod_cidr_overprovision_configs)
        pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        pulumi.set(__self__, "pod_range", pod_range)
        pulumi.set(__self__, "subnetwork", subnetwork)

    @_builtins.property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigResult']:
        """
        We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface
        """
        return pulumi.get(self, "additional_node_network_configs")

    @_builtins.property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigResult']:
        """
        We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node
        """
        return pulumi.get(self, "additional_pod_network_configs")

    @_builtins.property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> _builtins.bool:
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for pod_range and pod_ipv4_cidr_block if they are not specified.
        """
        return pulumi.get(self, "create_pod_range")

    @_builtins.property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> _builtins.bool:
        """
        Whether nodes have internal IP addresses only.
        """
        return pulumi.get(self, "enable_private_nodes")

    @_builtins.property
    @pulumi.getter(name="networkPerformanceConfigs")
    def network_performance_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigNetworkPerformanceConfigResult']:
        """
        Network bandwidth tier configuration.
        """
        return pulumi.get(self, "network_performance_configs")

    @_builtins.property
    @pulumi.getter(name="podCidrOverprovisionConfigs")
    def pod_cidr_overprovision_configs(self) -> Sequence['outputs.GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigResult']:
        """
        Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited
        """
        return pulumi.get(self, "pod_cidr_overprovision_configs")

    @_builtins.property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> _builtins.str:
        """
        The IP address range for pod IPs in this node pool. Only applicable if create_pod_range is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @_builtins.property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> _builtins.str:
        """
        The ID of the secondary range for pod IPs. If create_pod_range is true, this ID is used for the new range. If create_pod_range is false, uses an existing secondary range with this ID.
        """
        return pulumi.get(self, "pod_range")

    @_builtins.property
    @pulumi.getter
    def subnetwork(self) -> _builtins.str:
        """
        The subnetwork path for the node pool. Format: projects/{project}/regions/{region}/subnetworks/{subnetwork} . If the cluster is associated with multiple subnetworks, the subnetwork for the node pool is picked based on the IP utilization during node pool creation and is immutable.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigResult(dict):
    def __init__(__self__, *,
                 network: _builtins.str,
                 subnetwork: _builtins.str):
        """
        :param _builtins.str network: Name of the VPC where the additional interface belongs.
        :param _builtins.str subnetwork: Name of the subnetwork where the additional interface belongs.
        """
        pulumi.set(__self__, "network", network)
        pulumi.set(__self__, "subnetwork", subnetwork)

    @_builtins.property
    @pulumi.getter
    def network(self) -> _builtins.str:
        """
        Name of the VPC where the additional interface belongs.
        """
        return pulumi.get(self, "network")

    @_builtins.property
    @pulumi.getter
    def subnetwork(self) -> _builtins.str:
        """
        Name of the subnetwork where the additional interface belongs.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigAdditionalPodNetworkConfigResult(dict):
    def __init__(__self__, *,
                 max_pods_per_node: _builtins.int,
                 secondary_pod_range: _builtins.str,
                 subnetwork: _builtins.str):
        """
        :param _builtins.int max_pods_per_node: The maximum number of pods per node which use this pod network.
        :param _builtins.str secondary_pod_range: The name of the secondary range on the subnet which provides IP address for this pod range.
        :param _builtins.str subnetwork: Name of the subnetwork where the additional pod network belongs.
        """
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        pulumi.set(__self__, "subnetwork", subnetwork)

    @_builtins.property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> _builtins.int:
        """
        The maximum number of pods per node which use this pod network.
        """
        return pulumi.get(self, "max_pods_per_node")

    @_builtins.property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> _builtins.str:
        """
        The name of the secondary range on the subnet which provides IP address for this pod range.
        """
        return pulumi.get(self, "secondary_pod_range")

    @_builtins.property
    @pulumi.getter
    def subnetwork(self) -> _builtins.str:
        """
        Name of the subnetwork where the additional pod network belongs.
        """
        return pulumi.get(self, "subnetwork")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigNetworkPerformanceConfigResult(dict):
    def __init__(__self__, *,
                 total_egress_bandwidth_tier: _builtins.str):
        """
        :param _builtins.str total_egress_bandwidth_tier: Specifies the total network bandwidth tier for the NodePool. [Valid values](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/projects.locations.clusters.nodePools#NodePool.Tier) include: "TIER_1" and "TIER_UNSPECIFIED".
        """
        pulumi.set(__self__, "total_egress_bandwidth_tier", total_egress_bandwidth_tier)

    @_builtins.property
    @pulumi.getter(name="totalEgressBandwidthTier")
    def total_egress_bandwidth_tier(self) -> _builtins.str:
        """
        Specifies the total network bandwidth tier for the NodePool. [Valid values](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/projects.locations.clusters.nodePools#NodePool.Tier) include: "TIER_1" and "TIER_UNSPECIFIED".
        """
        return pulumi.get(self, "total_egress_bandwidth_tier")


@pulumi.output_type
class GetClusterNodePoolNetworkConfigPodCidrOverprovisionConfigResult(dict):
    def __init__(__self__, *,
                 disabled: _builtins.bool):
        pulumi.set(__self__, "disabled", disabled)

    @_builtins.property
    @pulumi.getter
    def disabled(self) -> _builtins.bool:
        return pulumi.get(self, "disabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigResult(dict):
    def __init__(__self__, *,
                 advanced_machine_features: Sequence['outputs.GetClusterNodePoolNodeConfigAdvancedMachineFeatureResult'],
                 boot_disk_kms_key: _builtins.str,
                 boot_disks: Sequence['outputs.GetClusterNodePoolNodeConfigBootDiskResult'],
                 confidential_nodes: Sequence['outputs.GetClusterNodePoolNodeConfigConfidentialNodeResult'],
                 containerd_configs: Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigResult'],
                 disk_size_gb: _builtins.int,
                 disk_type: _builtins.str,
                 effective_taints: Sequence['outputs.GetClusterNodePoolNodeConfigEffectiveTaintResult'],
                 enable_confidential_storage: _builtins.bool,
                 ephemeral_storage_configs: Sequence['outputs.GetClusterNodePoolNodeConfigEphemeralStorageConfigResult'],
                 ephemeral_storage_local_ssd_configs: Sequence['outputs.GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigResult'],
                 fast_sockets: Sequence['outputs.GetClusterNodePoolNodeConfigFastSocketResult'],
                 flex_start: _builtins.bool,
                 gcfs_configs: Sequence['outputs.GetClusterNodePoolNodeConfigGcfsConfigResult'],
                 guest_accelerators: Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorResult'],
                 gvnics: Sequence['outputs.GetClusterNodePoolNodeConfigGvnicResult'],
                 host_maintenance_policies: Sequence['outputs.GetClusterNodePoolNodeConfigHostMaintenancePolicyResult'],
                 image_type: _builtins.str,
                 kubelet_configs: Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigResult'],
                 labels: Mapping[str, _builtins.str],
                 linux_node_configs: Sequence['outputs.GetClusterNodePoolNodeConfigLinuxNodeConfigResult'],
                 local_nvme_ssd_block_configs: Sequence['outputs.GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigResult'],
                 local_ssd_count: _builtins.int,
                 local_ssd_encryption_mode: _builtins.str,
                 logging_variant: _builtins.str,
                 machine_type: _builtins.str,
                 max_run_duration: _builtins.str,
                 metadata: Mapping[str, _builtins.str],
                 min_cpu_platform: _builtins.str,
                 node_group: _builtins.str,
                 oauth_scopes: Sequence[_builtins.str],
                 preemptible: _builtins.bool,
                 reservation_affinities: Sequence['outputs.GetClusterNodePoolNodeConfigReservationAffinityResult'],
                 resource_labels: Mapping[str, _builtins.str],
                 resource_manager_tags: Mapping[str, _builtins.str],
                 sandbox_configs: Sequence['outputs.GetClusterNodePoolNodeConfigSandboxConfigResult'],
                 secondary_boot_disks: Sequence['outputs.GetClusterNodePoolNodeConfigSecondaryBootDiskResult'],
                 service_account: _builtins.str,
                 shielded_instance_configs: Sequence['outputs.GetClusterNodePoolNodeConfigShieldedInstanceConfigResult'],
                 sole_tenant_configs: Sequence['outputs.GetClusterNodePoolNodeConfigSoleTenantConfigResult'],
                 spot: _builtins.bool,
                 storage_pools: Sequence[_builtins.str],
                 tags: Sequence[_builtins.str],
                 taints: Sequence['outputs.GetClusterNodePoolNodeConfigTaintResult'],
                 windows_node_configs: Sequence['outputs.GetClusterNodePoolNodeConfigWindowsNodeConfigResult'],
                 workload_metadata_configs: Sequence['outputs.GetClusterNodePoolNodeConfigWorkloadMetadataConfigResult']):
        """
        :param Sequence['GetClusterNodePoolNodeConfigAdvancedMachineFeatureArgs'] advanced_machine_features: Specifies options for controlling advanced machine features.
        :param _builtins.str boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        :param Sequence['GetClusterNodePoolNodeConfigBootDiskArgs'] boot_disks: Boot disk configuration for node pools nodes.
        :param Sequence['GetClusterNodePoolNodeConfigConfidentialNodeArgs'] confidential_nodes: Configuration for the confidential nodes feature, which makes nodes run on confidential VMs.
        :param Sequence['GetClusterNodePoolNodeConfigContainerdConfigArgs'] containerd_configs: Parameters for containerd configuration.
        :param _builtins.int disk_size_gb: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        :param _builtins.str disk_type: Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        :param Sequence['GetClusterNodePoolNodeConfigEffectiveTaintArgs'] effective_taints: List of kubernetes taints applied to each node.
        :param _builtins.bool enable_confidential_storage: If enabled boot disks are configured with confidential mode.
        :param Sequence['GetClusterNodePoolNodeConfigEphemeralStorageConfigArgs'] ephemeral_storage_configs: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param Sequence['GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs'] ephemeral_storage_local_ssd_configs: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param Sequence['GetClusterNodePoolNodeConfigFastSocketArgs'] fast_sockets: Enable or disable NCCL Fast Socket in the node pool.
        :param _builtins.bool flex_start: Enables Flex Start provisioning model for the node pool
        :param Sequence['GetClusterNodePoolNodeConfigGcfsConfigArgs'] gcfs_configs: GCFS configuration for this node.
        :param Sequence['GetClusterNodePoolNodeConfigGuestAcceleratorArgs'] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
        :param Sequence['GetClusterNodePoolNodeConfigGvnicArgs'] gvnics: Enable or disable gvnic in the node pool.
        :param Sequence['GetClusterNodePoolNodeConfigHostMaintenancePolicyArgs'] host_maintenance_policies: The maintenance policy for the hosts on which the GKE VMs run on.
        :param _builtins.str image_type: The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        :param Sequence['GetClusterNodePoolNodeConfigKubeletConfigArgs'] kubelet_configs: Node kubelet configs.
        :param Mapping[str, _builtins.str] labels: The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        :param Sequence['GetClusterNodePoolNodeConfigLinuxNodeConfigArgs'] linux_node_configs: Parameters that can be configured on Linux nodes.
        :param Sequence['GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs'] local_nvme_ssd_block_configs: Parameters for raw-block local NVMe SSDs.
        :param _builtins.int local_ssd_count: The number of local SSD disks to be attached to the node.
        :param _builtins.str local_ssd_encryption_mode: LocalSsdEncryptionMode specified the method used for encrypting the local SSDs attached to the node.
        :param _builtins.str logging_variant: Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        :param _builtins.str machine_type: The name of a Google Compute Engine machine type.
        :param _builtins.str max_run_duration: The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        :param Mapping[str, _builtins.str] metadata: The metadata key/value pairs assigned to instances in the cluster.
        :param _builtins.str min_cpu_platform: Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        :param _builtins.str node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        :param Sequence[_builtins.str] oauth_scopes: The set of Google API scopes to be made available on all of the node VMs.
        :param _builtins.bool preemptible: Whether the nodes are created as preemptible VM instances.
        :param Sequence['GetClusterNodePoolNodeConfigReservationAffinityArgs'] reservation_affinities: The reservation affinity configuration for the node pool.
        :param Mapping[str, _builtins.str] resource_labels: The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        :param Mapping[str, _builtins.str] resource_manager_tags: A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        :param Sequence['GetClusterNodePoolNodeConfigSandboxConfigArgs'] sandbox_configs: Sandbox configuration for this node.
        :param Sequence['GetClusterNodePoolNodeConfigSecondaryBootDiskArgs'] secondary_boot_disks: Secondary boot disks for preloading data or container images.
        :param _builtins.str service_account: The Google Cloud Platform Service Account to be used by the node VMs.
        :param Sequence['GetClusterNodePoolNodeConfigShieldedInstanceConfigArgs'] shielded_instance_configs: Shielded Instance options.
        :param Sequence['GetClusterNodePoolNodeConfigSoleTenantConfigArgs'] sole_tenant_configs: Node affinity options for sole tenant node pools.
        :param _builtins.bool spot: Whether the nodes are created as spot VM instances.
        :param Sequence[_builtins.str] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param Sequence[_builtins.str] tags: The list of instance tags applied to all nodes.
        :param Sequence['GetClusterNodePoolNodeConfigTaintArgs'] taints: List of Kubernetes taints to be applied to each node.
        :param Sequence['GetClusterNodePoolNodeConfigWindowsNodeConfigArgs'] windows_node_configs: Parameters that can be configured on Windows nodes.
        :param Sequence['GetClusterNodePoolNodeConfigWorkloadMetadataConfigArgs'] workload_metadata_configs: The workload metadata configuration for this node.
        """
        pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        pulumi.set(__self__, "boot_disks", boot_disks)
        pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        pulumi.set(__self__, "containerd_configs", containerd_configs)
        pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        pulumi.set(__self__, "disk_type", disk_type)
        pulumi.set(__self__, "effective_taints", effective_taints)
        pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        pulumi.set(__self__, "ephemeral_storage_configs", ephemeral_storage_configs)
        pulumi.set(__self__, "ephemeral_storage_local_ssd_configs", ephemeral_storage_local_ssd_configs)
        pulumi.set(__self__, "fast_sockets", fast_sockets)
        pulumi.set(__self__, "flex_start", flex_start)
        pulumi.set(__self__, "gcfs_configs", gcfs_configs)
        pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        pulumi.set(__self__, "gvnics", gvnics)
        pulumi.set(__self__, "host_maintenance_policies", host_maintenance_policies)
        pulumi.set(__self__, "image_type", image_type)
        pulumi.set(__self__, "kubelet_configs", kubelet_configs)
        pulumi.set(__self__, "labels", labels)
        pulumi.set(__self__, "linux_node_configs", linux_node_configs)
        pulumi.set(__self__, "local_nvme_ssd_block_configs", local_nvme_ssd_block_configs)
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        pulumi.set(__self__, "local_ssd_encryption_mode", local_ssd_encryption_mode)
        pulumi.set(__self__, "logging_variant", logging_variant)
        pulumi.set(__self__, "machine_type", machine_type)
        pulumi.set(__self__, "max_run_duration", max_run_duration)
        pulumi.set(__self__, "metadata", metadata)
        pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        pulumi.set(__self__, "node_group", node_group)
        pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        pulumi.set(__self__, "preemptible", preemptible)
        pulumi.set(__self__, "reservation_affinities", reservation_affinities)
        pulumi.set(__self__, "resource_labels", resource_labels)
        pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        pulumi.set(__self__, "sandbox_configs", sandbox_configs)
        pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        pulumi.set(__self__, "service_account", service_account)
        pulumi.set(__self__, "shielded_instance_configs", shielded_instance_configs)
        pulumi.set(__self__, "sole_tenant_configs", sole_tenant_configs)
        pulumi.set(__self__, "spot", spot)
        pulumi.set(__self__, "storage_pools", storage_pools)
        pulumi.set(__self__, "tags", tags)
        pulumi.set(__self__, "taints", taints)
        pulumi.set(__self__, "windows_node_configs", windows_node_configs)
        pulumi.set(__self__, "workload_metadata_configs", workload_metadata_configs)

    @_builtins.property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigAdvancedMachineFeatureResult']:
        """
        Specifies options for controlling advanced machine features.
        """
        return pulumi.get(self, "advanced_machine_features")

    @_builtins.property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> _builtins.str:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @_builtins.property
    @pulumi.getter(name="bootDisks")
    def boot_disks(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigBootDiskResult']:
        """
        Boot disk configuration for node pools nodes.
        """
        return pulumi.get(self, "boot_disks")

    @_builtins.property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigConfidentialNodeResult']:
        """
        Configuration for the confidential nodes feature, which makes nodes run on confidential VMs.
        """
        return pulumi.get(self, "confidential_nodes")

    @_builtins.property
    @pulumi.getter(name="containerdConfigs")
    def containerd_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigResult']:
        """
        Parameters for containerd configuration.
        """
        return pulumi.get(self, "containerd_configs")

    @_builtins.property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> _builtins.int:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @_builtins.property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> _builtins.str:
        """
        Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        """
        return pulumi.get(self, "disk_type")

    @_builtins.property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigEffectiveTaintResult']:
        """
        List of kubernetes taints applied to each node.
        """
        return pulumi.get(self, "effective_taints")

    @_builtins.property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> _builtins.bool:
        """
        If enabled boot disks are configured with confidential mode.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @_builtins.property
    @pulumi.getter(name="ephemeralStorageConfigs")
    def ephemeral_storage_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigEphemeralStorageConfigResult']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_configs")

    @_builtins.property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfigs")
    def ephemeral_storage_local_ssd_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigResult']:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_configs")

    @_builtins.property
    @pulumi.getter(name="fastSockets")
    def fast_sockets(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigFastSocketResult']:
        """
        Enable or disable NCCL Fast Socket in the node pool.
        """
        return pulumi.get(self, "fast_sockets")

    @_builtins.property
    @pulumi.getter(name="flexStart")
    def flex_start(self) -> _builtins.bool:
        """
        Enables Flex Start provisioning model for the node pool
        """
        return pulumi.get(self, "flex_start")

    @_builtins.property
    @pulumi.getter(name="gcfsConfigs")
    def gcfs_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGcfsConfigResult']:
        """
        GCFS configuration for this node.
        """
        return pulumi.get(self, "gcfs_configs")

    @_builtins.property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorResult']:
        """
        List of the type and count of accelerator cards attached to the instance.
        """
        return pulumi.get(self, "guest_accelerators")

    @_builtins.property
    @pulumi.getter
    def gvnics(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGvnicResult']:
        """
        Enable or disable gvnic in the node pool.
        """
        return pulumi.get(self, "gvnics")

    @_builtins.property
    @pulumi.getter(name="hostMaintenancePolicies")
    def host_maintenance_policies(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigHostMaintenancePolicyResult']:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policies")

    @_builtins.property
    @pulumi.getter(name="imageType")
    def image_type(self) -> _builtins.str:
        """
        The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        """
        return pulumi.get(self, "image_type")

    @_builtins.property
    @pulumi.getter(name="kubeletConfigs")
    def kubelet_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigResult']:
        """
        Node kubelet configs.
        """
        return pulumi.get(self, "kubelet_configs")

    @_builtins.property
    @pulumi.getter
    def labels(self) -> Mapping[str, _builtins.str]:
        """
        The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        """
        return pulumi.get(self, "labels")

    @_builtins.property
    @pulumi.getter(name="linuxNodeConfigs")
    def linux_node_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigLinuxNodeConfigResult']:
        """
        Parameters that can be configured on Linux nodes.
        """
        return pulumi.get(self, "linux_node_configs")

    @_builtins.property
    @pulumi.getter(name="localNvmeSsdBlockConfigs")
    def local_nvme_ssd_block_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigResult']:
        """
        Parameters for raw-block local NVMe SSDs.
        """
        return pulumi.get(self, "local_nvme_ssd_block_configs")

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        The number of local SSD disks to be attached to the node.
        """
        return pulumi.get(self, "local_ssd_count")

    @_builtins.property
    @pulumi.getter(name="localSsdEncryptionMode")
    def local_ssd_encryption_mode(self) -> _builtins.str:
        """
        LocalSsdEncryptionMode specified the method used for encrypting the local SSDs attached to the node.
        """
        return pulumi.get(self, "local_ssd_encryption_mode")

    @_builtins.property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> _builtins.str:
        """
        Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        """
        return pulumi.get(self, "logging_variant")

    @_builtins.property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> _builtins.str:
        """
        The name of a Google Compute Engine machine type.
        """
        return pulumi.get(self, "machine_type")

    @_builtins.property
    @pulumi.getter(name="maxRunDuration")
    def max_run_duration(self) -> _builtins.str:
        """
        The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        """
        return pulumi.get(self, "max_run_duration")

    @_builtins.property
    @pulumi.getter
    def metadata(self) -> Mapping[str, _builtins.str]:
        """
        The metadata key/value pairs assigned to instances in the cluster.
        """
        return pulumi.get(self, "metadata")

    @_builtins.property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> _builtins.str:
        """
        Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        """
        return pulumi.get(self, "min_cpu_platform")

    @_builtins.property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> _builtins.str:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        """
        return pulumi.get(self, "node_group")

    @_builtins.property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Sequence[_builtins.str]:
        """
        The set of Google API scopes to be made available on all of the node VMs.
        """
        return pulumi.get(self, "oauth_scopes")

    @_builtins.property
    @pulumi.getter
    def preemptible(self) -> _builtins.bool:
        """
        Whether the nodes are created as preemptible VM instances.
        """
        return pulumi.get(self, "preemptible")

    @_builtins.property
    @pulumi.getter(name="reservationAffinities")
    def reservation_affinities(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigReservationAffinityResult']:
        """
        The reservation affinity configuration for the node pool.
        """
        return pulumi.get(self, "reservation_affinities")

    @_builtins.property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Mapping[str, _builtins.str]:
        """
        The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        """
        return pulumi.get(self, "resource_labels")

    @_builtins.property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Mapping[str, _builtins.str]:
        """
        A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        """
        return pulumi.get(self, "resource_manager_tags")

    @_builtins.property
    @pulumi.getter(name="sandboxConfigs")
    def sandbox_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigSandboxConfigResult']:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_configs")

    @_builtins.property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigSecondaryBootDiskResult']:
        """
        Secondary boot disks for preloading data or container images.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @_builtins.property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> _builtins.str:
        """
        The Google Cloud Platform Service Account to be used by the node VMs.
        """
        return pulumi.get(self, "service_account")

    @_builtins.property
    @pulumi.getter(name="shieldedInstanceConfigs")
    def shielded_instance_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigShieldedInstanceConfigResult']:
        """
        Shielded Instance options.
        """
        return pulumi.get(self, "shielded_instance_configs")

    @_builtins.property
    @pulumi.getter(name="soleTenantConfigs")
    def sole_tenant_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigSoleTenantConfigResult']:
        """
        Node affinity options for sole tenant node pools.
        """
        return pulumi.get(self, "sole_tenant_configs")

    @_builtins.property
    @pulumi.getter
    def spot(self) -> _builtins.bool:
        """
        Whether the nodes are created as spot VM instances.
        """
        return pulumi.get(self, "spot")

    @_builtins.property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Sequence[_builtins.str]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Sequence[_builtins.str]:
        """
        The list of instance tags applied to all nodes.
        """
        return pulumi.get(self, "tags")

    @_builtins.property
    @pulumi.getter
    def taints(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigTaintResult']:
        """
        List of Kubernetes taints to be applied to each node.
        """
        return pulumi.get(self, "taints")

    @_builtins.property
    @pulumi.getter(name="windowsNodeConfigs")
    def windows_node_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigWindowsNodeConfigResult']:
        """
        Parameters that can be configured on Windows nodes.
        """
        return pulumi.get(self, "windows_node_configs")

    @_builtins.property
    @pulumi.getter(name="workloadMetadataConfigs")
    def workload_metadata_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigWorkloadMetadataConfigResult']:
        """
        The workload metadata configuration for this node.
        """
        return pulumi.get(self, "workload_metadata_configs")


@pulumi.output_type
class GetClusterNodePoolNodeConfigAdvancedMachineFeatureResult(dict):
    def __init__(__self__, *,
                 enable_nested_virtualization: _builtins.bool,
                 performance_monitoring_unit: _builtins.str,
                 threads_per_core: _builtins.int):
        """
        :param _builtins.bool enable_nested_virtualization: Whether the node should have nested virtualization enabled.
        :param _builtins.str performance_monitoring_unit: Level of Performance Monitoring Unit (PMU) requested. If unset, no access to the PMU is assumed.
        :param _builtins.int threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)
        pulumi.set(__self__, "performance_monitoring_unit", performance_monitoring_unit)
        pulumi.set(__self__, "threads_per_core", threads_per_core)

    @_builtins.property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> _builtins.bool:
        """
        Whether the node should have nested virtualization enabled.
        """
        return pulumi.get(self, "enable_nested_virtualization")

    @_builtins.property
    @pulumi.getter(name="performanceMonitoringUnit")
    def performance_monitoring_unit(self) -> _builtins.str:
        """
        Level of Performance Monitoring Unit (PMU) requested. If unset, no access to the PMU is assumed.
        """
        return pulumi.get(self, "performance_monitoring_unit")

    @_builtins.property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> _builtins.int:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")


@pulumi.output_type
class GetClusterNodePoolNodeConfigBootDiskResult(dict):
    def __init__(__self__, *,
                 disk_type: _builtins.str,
                 provisioned_iops: _builtins.int,
                 provisioned_throughput: _builtins.int,
                 size_gb: _builtins.int):
        """
        :param _builtins.str disk_type: Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        :param _builtins.int provisioned_iops: Configured IOPs provisioning. Only valid with disk type hyperdisk-balanced.
        :param _builtins.int provisioned_throughput: Configured throughput provisioning. Only valid with disk type hyperdisk-balanced.
        :param _builtins.int size_gb: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        pulumi.set(__self__, "disk_type", disk_type)
        pulumi.set(__self__, "provisioned_iops", provisioned_iops)
        pulumi.set(__self__, "provisioned_throughput", provisioned_throughput)
        pulumi.set(__self__, "size_gb", size_gb)

    @_builtins.property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> _builtins.str:
        """
        Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        """
        return pulumi.get(self, "disk_type")

    @_builtins.property
    @pulumi.getter(name="provisionedIops")
    def provisioned_iops(self) -> _builtins.int:
        """
        Configured IOPs provisioning. Only valid with disk type hyperdisk-balanced.
        """
        return pulumi.get(self, "provisioned_iops")

    @_builtins.property
    @pulumi.getter(name="provisionedThroughput")
    def provisioned_throughput(self) -> _builtins.int:
        """
        Configured throughput provisioning. Only valid with disk type hyperdisk-balanced.
        """
        return pulumi.get(self, "provisioned_throughput")

    @_builtins.property
    @pulumi.getter(name="sizeGb")
    def size_gb(self) -> _builtins.int:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        return pulumi.get(self, "size_gb")


@pulumi.output_type
class GetClusterNodePoolNodeConfigConfidentialNodeResult(dict):
    def __init__(__self__, *,
                 confidential_instance_type: _builtins.str,
                 enabled: _builtins.bool):
        """
        :param _builtins.str confidential_instance_type: Defines the type of technology used by the confidential node.
        :param _builtins.bool enabled: Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        pulumi.set(__self__, "confidential_instance_type", confidential_instance_type)
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter(name="confidentialInstanceType")
    def confidential_instance_type(self) -> _builtins.str:
        """
        Defines the type of technology used by the confidential node.
        """
        return pulumi.get(self, "confidential_instance_type")

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigContainerdConfigResult(dict):
    def __init__(__self__, *,
                 private_registry_access_configs: Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigResult'],
                 writable_cgroups: Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigWritableCgroupResult']):
        """
        :param Sequence['GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs'] private_registry_access_configs: Parameters for private container registries configuration.
        :param Sequence['GetClusterNodePoolNodeConfigContainerdConfigWritableCgroupArgs'] writable_cgroups: Parameters for writable cgroups configuration.
        """
        pulumi.set(__self__, "private_registry_access_configs", private_registry_access_configs)
        pulumi.set(__self__, "writable_cgroups", writable_cgroups)

    @_builtins.property
    @pulumi.getter(name="privateRegistryAccessConfigs")
    def private_registry_access_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigResult']:
        """
        Parameters for private container registries configuration.
        """
        return pulumi.get(self, "private_registry_access_configs")

    @_builtins.property
    @pulumi.getter(name="writableCgroups")
    def writable_cgroups(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigWritableCgroupResult']:
        """
        Parameters for writable cgroups configuration.
        """
        return pulumi.get(self, "writable_cgroups")


@pulumi.output_type
class GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigResult(dict):
    def __init__(__self__, *,
                 certificate_authority_domain_configs: Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult'],
                 enabled: _builtins.bool):
        """
        :param Sequence['GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs'] certificate_authority_domain_configs: Parameters for configuring CA certificate and domains.
        :param _builtins.bool enabled: Whether or not private registries are configured.
        """
        pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult']:
        """
        Parameters for configuring CA certificate and domains.
        """
        return pulumi.get(self, "certificate_authority_domain_configs")

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not private registries are configured.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigResult(dict):
    def __init__(__self__, *,
                 fqdns: Sequence[_builtins.str],
                 gcp_secret_manager_certificate_configs: Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult']):
        """
        :param Sequence[_builtins.str] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param Sequence['GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs'] gcp_secret_manager_certificate_configs: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_configs", gcp_secret_manager_certificate_configs)

    @_builtins.property
    @pulumi.getter
    def fqdns(self) -> Sequence[_builtins.str]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @_builtins.property
    @pulumi.getter(name="gcpSecretManagerCertificateConfigs")
    def gcp_secret_manager_certificate_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult']:
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_configs")


@pulumi.output_type
class GetClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigResult(dict):
    def __init__(__self__, *,
                 secret_uri: _builtins.str):
        """
        :param _builtins.str secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @_builtins.property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> _builtins.str:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")


@pulumi.output_type
class GetClusterNodePoolNodeConfigContainerdConfigWritableCgroupResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether writable cgroups are enabled.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether writable cgroups are enabled.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigEffectiveTaintResult(dict):
    def __init__(__self__, *,
                 effect: _builtins.str,
                 key: _builtins.str,
                 value: _builtins.str):
        """
        :param _builtins.str effect: Effect for taint.
        :param _builtins.str key: Key for taint.
        :param _builtins.str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def effect(self) -> _builtins.str:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def value(self) -> _builtins.str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class GetClusterNodePoolNodeConfigEphemeralStorageConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: _builtins.int):
        """
        :param _builtins.int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigResult(dict):
    def __init__(__self__, *,
                 data_cache_count: _builtins.int,
                 local_ssd_count: _builtins.int):
        """
        :param _builtins.int data_cache_count: Number of local SSDs to be utilized for GKE Data Cache. Uses NVMe interfaces.
        :param _builtins.int local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        pulumi.set(__self__, "data_cache_count", data_cache_count)
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @_builtins.property
    @pulumi.getter(name="dataCacheCount")
    def data_cache_count(self) -> _builtins.int:
        """
        Number of local SSDs to be utilized for GKE Data Cache. Uses NVMe interfaces.
        """
        return pulumi.get(self, "data_cache_count")

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodePoolNodeConfigFastSocketResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGcfsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not GCFS is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not GCFS is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGuestAcceleratorResult(dict):
    def __init__(__self__, *,
                 count: _builtins.int,
                 gpu_driver_installation_configs: Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult'],
                 gpu_partition_size: _builtins.str,
                 gpu_sharing_configs: Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigResult'],
                 type: _builtins.str):
        """
        :param _builtins.int count: The number of the accelerator cards exposed to an instance.
        :param Sequence['GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs'] gpu_driver_installation_configs: Configuration for auto installation of GPU driver.
        :param _builtins.str gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        :param Sequence['GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs'] gpu_sharing_configs: Configuration for GPU sharing.
        :param _builtins.str type: The accelerator type resource name.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "gpu_driver_installation_configs", gpu_driver_installation_configs)
        pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        pulumi.set(__self__, "gpu_sharing_configs", gpu_sharing_configs)
        pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter
    def count(self) -> _builtins.int:
        """
        The number of the accelerator cards exposed to an instance.
        """
        return pulumi.get(self, "count")

    @_builtins.property
    @pulumi.getter(name="gpuDriverInstallationConfigs")
    def gpu_driver_installation_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult']:
        """
        Configuration for auto installation of GPU driver.
        """
        return pulumi.get(self, "gpu_driver_installation_configs")

    @_builtins.property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> _builtins.str:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        """
        return pulumi.get(self, "gpu_partition_size")

    @_builtins.property
    @pulumi.getter(name="gpuSharingConfigs")
    def gpu_sharing_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigResult']:
        """
        Configuration for GPU sharing.
        """
        return pulumi.get(self, "gpu_sharing_configs")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        The accelerator type resource name.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigResult(dict):
    def __init__(__self__, *,
                 gpu_driver_version: _builtins.str):
        """
        :param _builtins.str gpu_driver_version: Mode for how the GPU driver is installed.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @_builtins.property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> _builtins.str:
        """
        Mode for how the GPU driver is installed.
        """
        return pulumi.get(self, "gpu_driver_version")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigResult(dict):
    def __init__(__self__, *,
                 gpu_sharing_strategy: _builtins.str,
                 max_shared_clients_per_gpu: _builtins.int):
        """
        :param _builtins.str gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        :param _builtins.int max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @_builtins.property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> _builtins.str:
        """
        The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @_builtins.property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> _builtins.int:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")


@pulumi.output_type
class GetClusterNodePoolNodeConfigGvnicResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether or not gvnic is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not gvnic is enabled
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigHostMaintenancePolicyResult(dict):
    def __init__(__self__, *,
                 maintenance_interval: _builtins.str):
        """
        :param _builtins.str maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @_builtins.property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> _builtins.str:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")


@pulumi.output_type
class GetClusterNodePoolNodeConfigKubeletConfigResult(dict):
    def __init__(__self__, *,
                 allowed_unsafe_sysctls: Sequence[_builtins.str],
                 container_log_max_files: _builtins.int,
                 container_log_max_size: _builtins.str,
                 cpu_cfs_quota: _builtins.bool,
                 cpu_cfs_quota_period: _builtins.str,
                 cpu_manager_policy: _builtins.str,
                 eviction_max_pod_grace_period_seconds: _builtins.int,
                 eviction_minimum_reclaims: Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaimResult'],
                 eviction_soft_grace_periods: Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriodResult'],
                 eviction_softs: Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigEvictionSoftResult'],
                 image_gc_high_threshold_percent: _builtins.int,
                 image_gc_low_threshold_percent: _builtins.int,
                 image_maximum_gc_age: _builtins.str,
                 image_minimum_gc_age: _builtins.str,
                 insecure_kubelet_readonly_port_enabled: _builtins.str,
                 max_parallel_image_pulls: _builtins.int,
                 memory_managers: Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigMemoryManagerResult'],
                 pod_pids_limit: _builtins.int,
                 single_process_oom_kill: _builtins.bool,
                 topology_managers: Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigTopologyManagerResult']):
        """
        :param Sequence[_builtins.str] allowed_unsafe_sysctls: Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods.
        :param _builtins.int container_log_max_files: Defines the maximum number of container log files that can be present for a container.
        :param _builtins.str container_log_max_size: Defines the maximum size of the container log file before it is rotated.
        :param _builtins.bool cpu_cfs_quota: Enable CPU CFS quota enforcement for containers that specify CPU limits.
        :param _builtins.str cpu_cfs_quota_period: Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        :param _builtins.str cpu_manager_policy: Control the CPU management policy on the node.
        :param _builtins.int eviction_max_pod_grace_period_seconds: Defines the maximum allowed grace period (in seconds) to use when terminating pods in response to a soft eviction threshold being met.
        :param Sequence['GetClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaimArgs'] eviction_minimum_reclaims: Defines a map of signal names to percentage that defines minimum reclaims. It describes the minimum amount of a given resource the kubelet will reclaim when performing a pod eviction.
        :param Sequence['GetClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriodArgs'] eviction_soft_grace_periods: Defines a map of signal names to durations that defines grace periods for soft eviction thresholds. Each soft eviction threshold must have a corresponding grace period.
        :param Sequence['GetClusterNodePoolNodeConfigKubeletConfigEvictionSoftArgs'] eviction_softs: Defines a map of signal names to quantities or percentage that defines soft eviction thresholds.
        :param _builtins.int image_gc_high_threshold_percent: Defines the percent of disk usage after which image garbage collection is always run.
        :param _builtins.int image_gc_low_threshold_percent: Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to.
        :param _builtins.str image_maximum_gc_age: Defines the maximum age an image can be unused before it is garbage collected.
        :param _builtins.str image_minimum_gc_age: Defines the minimum age for an unused image before it is garbage collected.
        :param _builtins.str insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param _builtins.int max_parallel_image_pulls: Set the maximum number of image pulls in parallel.
        :param Sequence['GetClusterNodePoolNodeConfigKubeletConfigMemoryManagerArgs'] memory_managers: Configuration for the Memory Manager on the node. The memory manager optimizes memory and hugepages allocation for pods, especially those in the Guaranteed QoS class, by influencing NUMA affinity.
        :param _builtins.int pod_pids_limit: Controls the maximum number of processes allowed to run in a pod.
        :param _builtins.bool single_process_oom_kill: Defines whether to enable single process OOM killer.
        :param Sequence['GetClusterNodePoolNodeConfigKubeletConfigTopologyManagerArgs'] topology_managers: Configuration for the Topology Manager on the node. The Topology Manager aligns CPU, memory, and device resources on a node to optimize performance, especially for NUMA-aware workloads, by ensuring resource co-location.
        """
        pulumi.set(__self__, "allowed_unsafe_sysctls", allowed_unsafe_sysctls)
        pulumi.set(__self__, "container_log_max_files", container_log_max_files)
        pulumi.set(__self__, "container_log_max_size", container_log_max_size)
        pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        pulumi.set(__self__, "eviction_max_pod_grace_period_seconds", eviction_max_pod_grace_period_seconds)
        pulumi.set(__self__, "eviction_minimum_reclaims", eviction_minimum_reclaims)
        pulumi.set(__self__, "eviction_soft_grace_periods", eviction_soft_grace_periods)
        pulumi.set(__self__, "eviction_softs", eviction_softs)
        pulumi.set(__self__, "image_gc_high_threshold_percent", image_gc_high_threshold_percent)
        pulumi.set(__self__, "image_gc_low_threshold_percent", image_gc_low_threshold_percent)
        pulumi.set(__self__, "image_maximum_gc_age", image_maximum_gc_age)
        pulumi.set(__self__, "image_minimum_gc_age", image_minimum_gc_age)
        pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        pulumi.set(__self__, "max_parallel_image_pulls", max_parallel_image_pulls)
        pulumi.set(__self__, "memory_managers", memory_managers)
        pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)
        pulumi.set(__self__, "single_process_oom_kill", single_process_oom_kill)
        pulumi.set(__self__, "topology_managers", topology_managers)

    @_builtins.property
    @pulumi.getter(name="allowedUnsafeSysctls")
    def allowed_unsafe_sysctls(self) -> Sequence[_builtins.str]:
        """
        Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods.
        """
        return pulumi.get(self, "allowed_unsafe_sysctls")

    @_builtins.property
    @pulumi.getter(name="containerLogMaxFiles")
    def container_log_max_files(self) -> _builtins.int:
        """
        Defines the maximum number of container log files that can be present for a container.
        """
        return pulumi.get(self, "container_log_max_files")

    @_builtins.property
    @pulumi.getter(name="containerLogMaxSize")
    def container_log_max_size(self) -> _builtins.str:
        """
        Defines the maximum size of the container log file before it is rotated.
        """
        return pulumi.get(self, "container_log_max_size")

    @_builtins.property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> _builtins.bool:
        """
        Enable CPU CFS quota enforcement for containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @_builtins.property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> _builtins.str:
        """
        Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @_builtins.property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> _builtins.str:
        """
        Control the CPU management policy on the node.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @_builtins.property
    @pulumi.getter(name="evictionMaxPodGracePeriodSeconds")
    def eviction_max_pod_grace_period_seconds(self) -> _builtins.int:
        """
        Defines the maximum allowed grace period (in seconds) to use when terminating pods in response to a soft eviction threshold being met.
        """
        return pulumi.get(self, "eviction_max_pod_grace_period_seconds")

    @_builtins.property
    @pulumi.getter(name="evictionMinimumReclaims")
    def eviction_minimum_reclaims(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaimResult']:
        """
        Defines a map of signal names to percentage that defines minimum reclaims. It describes the minimum amount of a given resource the kubelet will reclaim when performing a pod eviction.
        """
        return pulumi.get(self, "eviction_minimum_reclaims")

    @_builtins.property
    @pulumi.getter(name="evictionSoftGracePeriods")
    def eviction_soft_grace_periods(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriodResult']:
        """
        Defines a map of signal names to durations that defines grace periods for soft eviction thresholds. Each soft eviction threshold must have a corresponding grace period.
        """
        return pulumi.get(self, "eviction_soft_grace_periods")

    @_builtins.property
    @pulumi.getter(name="evictionSofts")
    def eviction_softs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigEvictionSoftResult']:
        """
        Defines a map of signal names to quantities or percentage that defines soft eviction thresholds.
        """
        return pulumi.get(self, "eviction_softs")

    @_builtins.property
    @pulumi.getter(name="imageGcHighThresholdPercent")
    def image_gc_high_threshold_percent(self) -> _builtins.int:
        """
        Defines the percent of disk usage after which image garbage collection is always run.
        """
        return pulumi.get(self, "image_gc_high_threshold_percent")

    @_builtins.property
    @pulumi.getter(name="imageGcLowThresholdPercent")
    def image_gc_low_threshold_percent(self) -> _builtins.int:
        """
        Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to.
        """
        return pulumi.get(self, "image_gc_low_threshold_percent")

    @_builtins.property
    @pulumi.getter(name="imageMaximumGcAge")
    def image_maximum_gc_age(self) -> _builtins.str:
        """
        Defines the maximum age an image can be unused before it is garbage collected.
        """
        return pulumi.get(self, "image_maximum_gc_age")

    @_builtins.property
    @pulumi.getter(name="imageMinimumGcAge")
    def image_minimum_gc_age(self) -> _builtins.str:
        """
        Defines the minimum age for an unused image before it is garbage collected.
        """
        return pulumi.get(self, "image_minimum_gc_age")

    @_builtins.property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> _builtins.str:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @_builtins.property
    @pulumi.getter(name="maxParallelImagePulls")
    def max_parallel_image_pulls(self) -> _builtins.int:
        """
        Set the maximum number of image pulls in parallel.
        """
        return pulumi.get(self, "max_parallel_image_pulls")

    @_builtins.property
    @pulumi.getter(name="memoryManagers")
    def memory_managers(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigMemoryManagerResult']:
        """
        Configuration for the Memory Manager on the node. The memory manager optimizes memory and hugepages allocation for pods, especially those in the Guaranteed QoS class, by influencing NUMA affinity.
        """
        return pulumi.get(self, "memory_managers")

    @_builtins.property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> _builtins.int:
        """
        Controls the maximum number of processes allowed to run in a pod.
        """
        return pulumi.get(self, "pod_pids_limit")

    @_builtins.property
    @pulumi.getter(name="singleProcessOomKill")
    def single_process_oom_kill(self) -> _builtins.bool:
        """
        Defines whether to enable single process OOM killer.
        """
        return pulumi.get(self, "single_process_oom_kill")

    @_builtins.property
    @pulumi.getter(name="topologyManagers")
    def topology_managers(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigKubeletConfigTopologyManagerResult']:
        """
        Configuration for the Topology Manager on the node. The Topology Manager aligns CPU, memory, and device resources on a node to optimize performance, especially for NUMA-aware workloads, by ensuring resource co-location.
        """
        return pulumi.get(self, "topology_managers")


@pulumi.output_type
class GetClusterNodePoolNodeConfigKubeletConfigEvictionMinimumReclaimResult(dict):
    def __init__(__self__, *,
                 imagefs_available: _builtins.str,
                 imagefs_inodes_free: _builtins.str,
                 memory_available: _builtins.str,
                 nodefs_available: _builtins.str,
                 nodefs_inodes_free: _builtins.str,
                 pid_available: _builtins.str):
        """
        :param _builtins.str imagefs_available: Defines percentage of minimum reclaim for imagefs.available.
        :param _builtins.str imagefs_inodes_free: Defines percentage of minimum reclaim for imagefs.inodesFree.
        :param _builtins.str memory_available: Defines percentage of minimum reclaim for memory.available.
        :param _builtins.str nodefs_available: Defines percentage of minimum reclaim for nodefs.available.
        :param _builtins.str nodefs_inodes_free: Defines percentage of minimum reclaim for nodefs.inodesFree.
        :param _builtins.str pid_available: Defines percentage of minimum reclaim for pid.available.
        """
        pulumi.set(__self__, "imagefs_available", imagefs_available)
        pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        pulumi.set(__self__, "memory_available", memory_available)
        pulumi.set(__self__, "nodefs_available", nodefs_available)
        pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> _builtins.str:
        """
        Defines percentage of minimum reclaim for imagefs.available.
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> _builtins.str:
        """
        Defines percentage of minimum reclaim for imagefs.inodesFree.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> _builtins.str:
        """
        Defines percentage of minimum reclaim for memory.available.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> _builtins.str:
        """
        Defines percentage of minimum reclaim for nodefs.available.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> _builtins.str:
        """
        Defines percentage of minimum reclaim for nodefs.inodesFree.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> _builtins.str:
        """
        Defines percentage of minimum reclaim for pid.available.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class GetClusterNodePoolNodeConfigKubeletConfigEvictionSoftResult(dict):
    def __init__(__self__, *,
                 imagefs_available: _builtins.str,
                 imagefs_inodes_free: _builtins.str,
                 memory_available: _builtins.str,
                 nodefs_available: _builtins.str,
                 nodefs_inodes_free: _builtins.str,
                 pid_available: _builtins.str):
        """
        :param _builtins.str imagefs_available: Defines percentage of soft eviction threshold for imagefs.available.
        :param _builtins.str imagefs_inodes_free: Defines percentage of soft eviction threshold for imagefs.inodesFree.
        :param _builtins.str memory_available: Defines quantity of soft eviction threshold for memory.available.
        :param _builtins.str nodefs_available: Defines percentage of soft eviction threshold for nodefs.available.
        :param _builtins.str nodefs_inodes_free: Defines percentage of soft eviction threshold for nodefs.inodesFree.
        :param _builtins.str pid_available: Defines percentage of soft eviction threshold for pid.available.
        """
        pulumi.set(__self__, "imagefs_available", imagefs_available)
        pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        pulumi.set(__self__, "memory_available", memory_available)
        pulumi.set(__self__, "nodefs_available", nodefs_available)
        pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> _builtins.str:
        """
        Defines percentage of soft eviction threshold for imagefs.available.
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> _builtins.str:
        """
        Defines percentage of soft eviction threshold for imagefs.inodesFree.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> _builtins.str:
        """
        Defines quantity of soft eviction threshold for memory.available.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> _builtins.str:
        """
        Defines percentage of soft eviction threshold for nodefs.available.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> _builtins.str:
        """
        Defines percentage of soft eviction threshold for nodefs.inodesFree.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> _builtins.str:
        """
        Defines percentage of soft eviction threshold for pid.available.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class GetClusterNodePoolNodeConfigKubeletConfigEvictionSoftGracePeriodResult(dict):
    def __init__(__self__, *,
                 imagefs_available: _builtins.str,
                 imagefs_inodes_free: _builtins.str,
                 memory_available: _builtins.str,
                 nodefs_available: _builtins.str,
                 nodefs_inodes_free: _builtins.str,
                 pid_available: _builtins.str):
        """
        :param _builtins.str imagefs_available: Defines grace period for the imagefs.available soft eviction threshold
        :param _builtins.str imagefs_inodes_free: Defines grace period for the imagefs.inodesFree soft eviction threshold.
        :param _builtins.str memory_available: Defines grace period for the memory.available soft eviction threshold.
        :param _builtins.str nodefs_available: Defines grace period for the nodefs.available soft eviction threshold.
        :param _builtins.str nodefs_inodes_free: Defines grace period for the nodefs.inodesFree soft eviction threshold.
        :param _builtins.str pid_available: Defines grace period for the pid.available soft eviction threshold.
        """
        pulumi.set(__self__, "imagefs_available", imagefs_available)
        pulumi.set(__self__, "imagefs_inodes_free", imagefs_inodes_free)
        pulumi.set(__self__, "memory_available", memory_available)
        pulumi.set(__self__, "nodefs_available", nodefs_available)
        pulumi.set(__self__, "nodefs_inodes_free", nodefs_inodes_free)
        pulumi.set(__self__, "pid_available", pid_available)

    @_builtins.property
    @pulumi.getter(name="imagefsAvailable")
    def imagefs_available(self) -> _builtins.str:
        """
        Defines grace period for the imagefs.available soft eviction threshold
        """
        return pulumi.get(self, "imagefs_available")

    @_builtins.property
    @pulumi.getter(name="imagefsInodesFree")
    def imagefs_inodes_free(self) -> _builtins.str:
        """
        Defines grace period for the imagefs.inodesFree soft eviction threshold.
        """
        return pulumi.get(self, "imagefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="memoryAvailable")
    def memory_available(self) -> _builtins.str:
        """
        Defines grace period for the memory.available soft eviction threshold.
        """
        return pulumi.get(self, "memory_available")

    @_builtins.property
    @pulumi.getter(name="nodefsAvailable")
    def nodefs_available(self) -> _builtins.str:
        """
        Defines grace period for the nodefs.available soft eviction threshold.
        """
        return pulumi.get(self, "nodefs_available")

    @_builtins.property
    @pulumi.getter(name="nodefsInodesFree")
    def nodefs_inodes_free(self) -> _builtins.str:
        """
        Defines grace period for the nodefs.inodesFree soft eviction threshold.
        """
        return pulumi.get(self, "nodefs_inodes_free")

    @_builtins.property
    @pulumi.getter(name="pidAvailable")
    def pid_available(self) -> _builtins.str:
        """
        Defines grace period for the pid.available soft eviction threshold.
        """
        return pulumi.get(self, "pid_available")


@pulumi.output_type
class GetClusterNodePoolNodeConfigKubeletConfigMemoryManagerResult(dict):
    def __init__(__self__, *,
                 policy: _builtins.str):
        """
        :param _builtins.str policy: The Memory Manager policy to use. This policy guides how memory and hugepages are allocated and managed for pods on the node, influencing NUMA affinity.
        """
        pulumi.set(__self__, "policy", policy)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> _builtins.str:
        """
        The Memory Manager policy to use. This policy guides how memory and hugepages are allocated and managed for pods on the node, influencing NUMA affinity.
        """
        return pulumi.get(self, "policy")


@pulumi.output_type
class GetClusterNodePoolNodeConfigKubeletConfigTopologyManagerResult(dict):
    def __init__(__self__, *,
                 policy: _builtins.str,
                 scope: _builtins.str):
        """
        :param _builtins.str policy: The Topology Manager policy to use. This policy dictates how resource alignment is handled on the node.
        :param _builtins.str scope: The Topology Manager scope, defining the granularity at which policy decisions are applied. Valid values are "container" (resources are aligned per container within a pod) or "pod" (resources are aligned for the entire pod).
        """
        pulumi.set(__self__, "policy", policy)
        pulumi.set(__self__, "scope", scope)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> _builtins.str:
        """
        The Topology Manager policy to use. This policy dictates how resource alignment is handled on the node.
        """
        return pulumi.get(self, "policy")

    @_builtins.property
    @pulumi.getter
    def scope(self) -> _builtins.str:
        """
        The Topology Manager scope, defining the granularity at which policy decisions are applied. Valid values are "container" (resources are aligned per container within a pod) or "pod" (resources are aligned for the entire pod).
        """
        return pulumi.get(self, "scope")


@pulumi.output_type
class GetClusterNodePoolNodeConfigLinuxNodeConfigResult(dict):
    def __init__(__self__, *,
                 cgroup_mode: _builtins.str,
                 hugepages_configs: Sequence['outputs.GetClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigResult'],
                 node_kernel_module_loadings: Sequence['outputs.GetClusterNodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoadingResult'],
                 sysctls: Mapping[str, _builtins.str],
                 transparent_hugepage_defrag: _builtins.str,
                 transparent_hugepage_enabled: _builtins.str):
        """
        :param _builtins.str cgroup_mode: cgroupMode specifies the cgroup mode to be used on the node.
        :param Sequence['GetClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs'] hugepages_configs: Amounts for 2M and 1G hugepages.
        :param Sequence['GetClusterNodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoadingArgs'] node_kernel_module_loadings: The settings for kernel module loading.
        :param Mapping[str, _builtins.str] sysctls: The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        :param _builtins.str transparent_hugepage_defrag: The Linux kernel transparent hugepage defrag setting.
        :param _builtins.str transparent_hugepage_enabled: The Linux kernel transparent hugepage setting.
        """
        pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        pulumi.set(__self__, "hugepages_configs", hugepages_configs)
        pulumi.set(__self__, "node_kernel_module_loadings", node_kernel_module_loadings)
        pulumi.set(__self__, "sysctls", sysctls)
        pulumi.set(__self__, "transparent_hugepage_defrag", transparent_hugepage_defrag)
        pulumi.set(__self__, "transparent_hugepage_enabled", transparent_hugepage_enabled)

    @_builtins.property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> _builtins.str:
        """
        cgroupMode specifies the cgroup mode to be used on the node.
        """
        return pulumi.get(self, "cgroup_mode")

    @_builtins.property
    @pulumi.getter(name="hugepagesConfigs")
    def hugepages_configs(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigResult']:
        """
        Amounts for 2M and 1G hugepages.
        """
        return pulumi.get(self, "hugepages_configs")

    @_builtins.property
    @pulumi.getter(name="nodeKernelModuleLoadings")
    def node_kernel_module_loadings(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoadingResult']:
        """
        The settings for kernel module loading.
        """
        return pulumi.get(self, "node_kernel_module_loadings")

    @_builtins.property
    @pulumi.getter
    def sysctls(self) -> Mapping[str, _builtins.str]:
        """
        The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        """
        return pulumi.get(self, "sysctls")

    @_builtins.property
    @pulumi.getter(name="transparentHugepageDefrag")
    def transparent_hugepage_defrag(self) -> _builtins.str:
        """
        The Linux kernel transparent hugepage defrag setting.
        """
        return pulumi.get(self, "transparent_hugepage_defrag")

    @_builtins.property
    @pulumi.getter(name="transparentHugepageEnabled")
    def transparent_hugepage_enabled(self) -> _builtins.str:
        """
        The Linux kernel transparent hugepage setting.
        """
        return pulumi.get(self, "transparent_hugepage_enabled")


@pulumi.output_type
class GetClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigResult(dict):
    def __init__(__self__, *,
                 hugepage_size1g: _builtins.int,
                 hugepage_size2m: _builtins.int):
        """
        :param _builtins.int hugepage_size1g: Amount of 1G hugepages.
        :param _builtins.int hugepage_size2m: Amount of 2M hugepages.
        """
        pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @_builtins.property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> _builtins.int:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @_builtins.property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> _builtins.int:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")


@pulumi.output_type
class GetClusterNodePoolNodeConfigLinuxNodeConfigNodeKernelModuleLoadingResult(dict):
    def __init__(__self__, *,
                 policy: _builtins.str):
        """
        :param _builtins.str policy: The policy for kernel module loading.
        """
        pulumi.set(__self__, "policy", policy)

    @_builtins.property
    @pulumi.getter
    def policy(self) -> _builtins.str:
        """
        The policy for kernel module loading.
        """
        return pulumi.get(self, "policy")


@pulumi.output_type
class GetClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: _builtins.int):
        """
        :param _builtins.int local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @_builtins.property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> _builtins.int:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetClusterNodePoolNodeConfigReservationAffinityResult(dict):
    def __init__(__self__, *,
                 consume_reservation_type: _builtins.str,
                 key: _builtins.str,
                 values: Sequence[_builtins.str]):
        """
        :param _builtins.str consume_reservation_type: Corresponds to the type of reservation consumption.
        :param _builtins.str key: The label key of a reservation resource.
        :param Sequence[_builtins.str] values: The label values of the reservation resource.
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "values", values)

    @_builtins.property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> _builtins.str:
        """
        Corresponds to the type of reservation consumption.
        """
        return pulumi.get(self, "consume_reservation_type")

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        The label key of a reservation resource.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def values(self) -> Sequence[_builtins.str]:
        """
        The label values of the reservation resource.
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class GetClusterNodePoolNodeConfigSandboxConfigResult(dict):
    def __init__(__self__, *,
                 sandbox_type: _builtins.str):
        """
        :param _builtins.str sandbox_type: Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @_builtins.property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> _builtins.str:
        """
        Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        return pulumi.get(self, "sandbox_type")


@pulumi.output_type
class GetClusterNodePoolNodeConfigSecondaryBootDiskResult(dict):
    def __init__(__self__, *,
                 disk_image: _builtins.str,
                 mode: _builtins.str):
        """
        :param _builtins.str disk_image: Disk image to create the secondary boot disk from
        :param _builtins.str mode: Mode for how the secondary boot disk is used.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        pulumi.set(__self__, "mode", mode)

    @_builtins.property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> _builtins.str:
        """
        Disk image to create the secondary boot disk from
        """
        return pulumi.get(self, "disk_image")

    @_builtins.property
    @pulumi.getter
    def mode(self) -> _builtins.str:
        """
        Mode for how the secondary boot disk is used.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class GetClusterNodePoolNodeConfigShieldedInstanceConfigResult(dict):
    def __init__(__self__, *,
                 enable_integrity_monitoring: _builtins.bool,
                 enable_secure_boot: _builtins.bool):
        """
        :param _builtins.bool enable_integrity_monitoring: Defines whether the instance has integrity monitoring enabled.
        :param _builtins.bool enable_secure_boot: Defines whether the instance has Secure Boot enabled.
        """
        pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @_builtins.property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> _builtins.bool:
        """
        Defines whether the instance has integrity monitoring enabled.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @_builtins.property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> _builtins.bool:
        """
        Defines whether the instance has Secure Boot enabled.
        """
        return pulumi.get(self, "enable_secure_boot")


@pulumi.output_type
class GetClusterNodePoolNodeConfigSoleTenantConfigResult(dict):
    def __init__(__self__, *,
                 min_node_cpus: _builtins.int,
                 node_affinities: Sequence['outputs.GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityResult']):
        """
        :param _builtins.int min_node_cpus: Specifies the minimum number of vCPUs that each sole tenant node must have to use CPU overcommit. If not specified, the CPU overcommit feature is disabled.
        :param Sequence['GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs'] node_affinities: .
        """
        pulumi.set(__self__, "min_node_cpus", min_node_cpus)
        pulumi.set(__self__, "node_affinities", node_affinities)

    @_builtins.property
    @pulumi.getter(name="minNodeCpus")
    def min_node_cpus(self) -> _builtins.int:
        """
        Specifies the minimum number of vCPUs that each sole tenant node must have to use CPU overcommit. If not specified, the CPU overcommit feature is disabled.
        """
        return pulumi.get(self, "min_node_cpus")

    @_builtins.property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> Sequence['outputs.GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityResult']:
        """
        .
        """
        return pulumi.get(self, "node_affinities")


@pulumi.output_type
class GetClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityResult(dict):
    def __init__(__self__, *,
                 key: _builtins.str,
                 operator: _builtins.str,
                 values: Sequence[_builtins.str]):
        """
        :param _builtins.str key: .
        :param _builtins.str operator: .
        :param Sequence[_builtins.str] values: .
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        .
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def operator(self) -> _builtins.str:
        """
        .
        """
        return pulumi.get(self, "operator")

    @_builtins.property
    @pulumi.getter
    def values(self) -> Sequence[_builtins.str]:
        """
        .
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class GetClusterNodePoolNodeConfigTaintResult(dict):
    def __init__(__self__, *,
                 effect: _builtins.str,
                 key: _builtins.str,
                 value: _builtins.str):
        """
        :param _builtins.str effect: Effect for taint.
        :param _builtins.str key: Key for taint.
        :param _builtins.str value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def effect(self) -> _builtins.str:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def value(self) -> _builtins.str:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class GetClusterNodePoolNodeConfigWindowsNodeConfigResult(dict):
    def __init__(__self__, *,
                 osversion: _builtins.str):
        """
        :param _builtins.str osversion: The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        pulumi.set(__self__, "osversion", osversion)

    @_builtins.property
    @pulumi.getter
    def osversion(self) -> _builtins.str:
        """
        The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        return pulumi.get(self, "osversion")


@pulumi.output_type
class GetClusterNodePoolNodeConfigWorkloadMetadataConfigResult(dict):
    def __init__(__self__, *,
                 mode: _builtins.str):
        """
        :param _builtins.str mode: Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        pulumi.set(__self__, "mode", mode)

    @_builtins.property
    @pulumi.getter
    def mode(self) -> _builtins.str:
        """
        Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        return pulumi.get(self, "mode")


@pulumi.output_type
class GetClusterNodePoolPlacementPolicyResult(dict):
    def __init__(__self__, *,
                 policy_name: _builtins.str,
                 tpu_topology: _builtins.str,
                 type: _builtins.str):
        """
        :param _builtins.str policy_name: If set, refers to the name of a custom resource policy supplied by the user. The resource policy must be in the same project and region as the node pool. If not found, InvalidArgument error is returned.
        :param _builtins.str tpu_topology: The TPU topology like "2x4" or "2x2x2". https://cloud.google.com/kubernetes-engine/docs/concepts/plan-tpus#topology
        :param _builtins.str type: Type defines the type of placement policy
        """
        pulumi.set(__self__, "policy_name", policy_name)
        pulumi.set(__self__, "tpu_topology", tpu_topology)
        pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> _builtins.str:
        """
        If set, refers to the name of a custom resource policy supplied by the user. The resource policy must be in the same project and region as the node pool. If not found, InvalidArgument error is returned.
        """
        return pulumi.get(self, "policy_name")

    @_builtins.property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> _builtins.str:
        """
        The TPU topology like "2x4" or "2x2x2". https://cloud.google.com/kubernetes-engine/docs/concepts/plan-tpus#topology
        """
        return pulumi.get(self, "tpu_topology")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        Type defines the type of placement policy
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterNodePoolQueuedProvisioningResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether nodes in this node pool are obtainable solely through the ProvisioningRequest API
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether nodes in this node pool are obtainable solely through the ProvisioningRequest API
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterNodePoolUpgradeSettingResult(dict):
    def __init__(__self__, *,
                 blue_green_settings: Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingResult'],
                 max_surge: _builtins.int,
                 max_unavailable: _builtins.int,
                 strategy: _builtins.str):
        """
        :param Sequence['GetClusterNodePoolUpgradeSettingBlueGreenSettingArgs'] blue_green_settings: Settings for BlueGreen node pool upgrade.
        :param _builtins.int max_surge: The number of additional nodes that can be added to the node pool during an upgrade. Increasing max_surge raises the number of nodes that can be upgraded simultaneously. Can be set to 0 or greater.
        :param _builtins.int max_unavailable: The number of nodes that can be simultaneously unavailable during an upgrade. Increasing max_unavailable raises the number of nodes that can be upgraded in parallel. Can be set to 0 or greater.
        :param _builtins.str strategy: Update strategy for the given nodepool.
        """
        pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        pulumi.set(__self__, "max_surge", max_surge)
        pulumi.set(__self__, "max_unavailable", max_unavailable)
        pulumi.set(__self__, "strategy", strategy)

    @_builtins.property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingResult']:
        """
        Settings for BlueGreen node pool upgrade.
        """
        return pulumi.get(self, "blue_green_settings")

    @_builtins.property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> _builtins.int:
        """
        The number of additional nodes that can be added to the node pool during an upgrade. Increasing max_surge raises the number of nodes that can be upgraded simultaneously. Can be set to 0 or greater.
        """
        return pulumi.get(self, "max_surge")

    @_builtins.property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> _builtins.int:
        """
        The number of nodes that can be simultaneously unavailable during an upgrade. Increasing max_unavailable raises the number of nodes that can be upgraded in parallel. Can be set to 0 or greater.
        """
        return pulumi.get(self, "max_unavailable")

    @_builtins.property
    @pulumi.getter
    def strategy(self) -> _builtins.str:
        """
        Update strategy for the given nodepool.
        """
        return pulumi.get(self, "strategy")


@pulumi.output_type
class GetClusterNodePoolUpgradeSettingBlueGreenSettingResult(dict):
    def __init__(__self__, *,
                 autoscaled_rollout_policies: Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingAutoscaledRolloutPolicyResult'],
                 node_pool_soak_duration: _builtins.str,
                 standard_rollout_policies: Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult']):
        """
        :param Sequence['GetClusterNodePoolUpgradeSettingBlueGreenSettingAutoscaledRolloutPolicyArgs'] autoscaled_rollout_policies: Autoscaled rollout policy for blue-green upgrade.
        :param _builtins.str node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up.
        :param Sequence['GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyArgs'] standard_rollout_policies: Standard rollout policy is the default policy for blue-green.
        """
        pulumi.set(__self__, "autoscaled_rollout_policies", autoscaled_rollout_policies)
        pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        pulumi.set(__self__, "standard_rollout_policies", standard_rollout_policies)

    @_builtins.property
    @pulumi.getter(name="autoscaledRolloutPolicies")
    def autoscaled_rollout_policies(self) -> Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingAutoscaledRolloutPolicyResult']:
        """
        Autoscaled rollout policy for blue-green upgrade.
        """
        return pulumi.get(self, "autoscaled_rollout_policies")

    @_builtins.property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> _builtins.str:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up.
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @_builtins.property
    @pulumi.getter(name="standardRolloutPolicies")
    def standard_rollout_policies(self) -> Sequence['outputs.GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult']:
        """
        Standard rollout policy is the default policy for blue-green.
        """
        return pulumi.get(self, "standard_rollout_policies")


@pulumi.output_type
class GetClusterNodePoolUpgradeSettingBlueGreenSettingAutoscaledRolloutPolicyResult(dict):
    def __init__(__self__, *,
                 wait_for_drain_duration: _builtins.str):
        """
        :param _builtins.str wait_for_drain_duration: Time in seconds to wait after cordoning the blue pool before draining the nodes.
        """
        pulumi.set(__self__, "wait_for_drain_duration", wait_for_drain_duration)

    @_builtins.property
    @pulumi.getter(name="waitForDrainDuration")
    def wait_for_drain_duration(self) -> _builtins.str:
        """
        Time in seconds to wait after cordoning the blue pool before draining the nodes.
        """
        return pulumi.get(self, "wait_for_drain_duration")


@pulumi.output_type
class GetClusterNodePoolUpgradeSettingBlueGreenSettingStandardRolloutPolicyResult(dict):
    def __init__(__self__, *,
                 batch_node_count: _builtins.int,
                 batch_percentage: _builtins.float,
                 batch_soak_duration: _builtins.str):
        """
        :param _builtins.int batch_node_count: Number of blue nodes to drain in a batch.
        :param _builtins.float batch_percentage: Percentage of the blue pool nodes to drain in a batch.
        :param _builtins.str batch_soak_duration: Soak time after each batch gets drained.
        """
        pulumi.set(__self__, "batch_node_count", batch_node_count)
        pulumi.set(__self__, "batch_percentage", batch_percentage)
        pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @_builtins.property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> _builtins.int:
        """
        Number of blue nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_node_count")

    @_builtins.property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> _builtins.float:
        """
        Percentage of the blue pool nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_percentage")

    @_builtins.property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> _builtins.str:
        """
        Soak time after each batch gets drained.
        """
        return pulumi.get(self, "batch_soak_duration")


@pulumi.output_type
class GetClusterNotificationConfigResult(dict):
    def __init__(__self__, *,
                 pubsubs: Sequence['outputs.GetClusterNotificationConfigPubsubResult']):
        """
        :param Sequence['GetClusterNotificationConfigPubsubArgs'] pubsubs: Notification config for Cloud Pub/Sub
        """
        pulumi.set(__self__, "pubsubs", pubsubs)

    @_builtins.property
    @pulumi.getter
    def pubsubs(self) -> Sequence['outputs.GetClusterNotificationConfigPubsubResult']:
        """
        Notification config for Cloud Pub/Sub
        """
        return pulumi.get(self, "pubsubs")


@pulumi.output_type
class GetClusterNotificationConfigPubsubResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 filters: Sequence['outputs.GetClusterNotificationConfigPubsubFilterResult'],
                 topic: _builtins.str):
        """
        :param _builtins.bool enabled: Whether or not the notification config is enabled
        :param Sequence['GetClusterNotificationConfigPubsubFilterArgs'] filters: Allows filtering to one or more specific event types. If event types are present, those and only those event types will be transmitted to the cluster. Other types will be skipped. If no filter is specified, or no event types are present, all event types will be sent
        :param _builtins.str topic: The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: projects/{project}/topics/{topic}.
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "filters", filters)
        pulumi.set(__self__, "topic", topic)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether or not the notification config is enabled
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter
    def filters(self) -> Sequence['outputs.GetClusterNotificationConfigPubsubFilterResult']:
        """
        Allows filtering to one or more specific event types. If event types are present, those and only those event types will be transmitted to the cluster. Other types will be skipped. If no filter is specified, or no event types are present, all event types will be sent
        """
        return pulumi.get(self, "filters")

    @_builtins.property
    @pulumi.getter
    def topic(self) -> _builtins.str:
        """
        The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: projects/{project}/topics/{topic}.
        """
        return pulumi.get(self, "topic")


@pulumi.output_type
class GetClusterNotificationConfigPubsubFilterResult(dict):
    def __init__(__self__, *,
                 event_types: Sequence[_builtins.str]):
        """
        :param Sequence[_builtins.str] event_types: Can be used to filter what notifications are sent. Valid values include include UPGRADE_AVAILABLE_EVENT, UPGRADE_EVENT, SECURITY_BULLETIN_EVENT, and UPGRADE_INFO_EVENT
        """
        pulumi.set(__self__, "event_types", event_types)

    @_builtins.property
    @pulumi.getter(name="eventTypes")
    def event_types(self) -> Sequence[_builtins.str]:
        """
        Can be used to filter what notifications are sent. Valid values include include UPGRADE_AVAILABLE_EVENT, UPGRADE_EVENT, SECURITY_BULLETIN_EVENT, and UPGRADE_INFO_EVENT
        """
        return pulumi.get(self, "event_types")


@pulumi.output_type
class GetClusterPodAutoscalingResult(dict):
    def __init__(__self__, *,
                 hpa_profile: _builtins.str):
        """
        :param _builtins.str hpa_profile: HPA Profile is used to configure the Horizontal Pod Autoscaler (HPA) profile for the cluster.
               								Available options include:
               								- NONE: Customers explicitly opt-out of HPA profiles.
               								- PERFORMANCE: PERFORMANCE is used when customers opt-in to the performance HPA profile. In this profile we support a higher number of HPAs per cluster and faster metrics collection for workload autoscaling.
        """
        pulumi.set(__self__, "hpa_profile", hpa_profile)

    @_builtins.property
    @pulumi.getter(name="hpaProfile")
    def hpa_profile(self) -> _builtins.str:
        """
        HPA Profile is used to configure the Horizontal Pod Autoscaler (HPA) profile for the cluster.
        								Available options include:
        								- NONE: Customers explicitly opt-out of HPA profiles.
        								- PERFORMANCE: PERFORMANCE is used when customers opt-in to the performance HPA profile. In this profile we support a higher number of HPAs per cluster and faster metrics collection for workload autoscaling.
        """
        return pulumi.get(self, "hpa_profile")


@pulumi.output_type
class GetClusterPodSecurityPolicyConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Enable the PodSecurityPolicy controller for this cluster. If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable the PodSecurityPolicy controller for this cluster. If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterPrivateClusterConfigResult(dict):
    def __init__(__self__, *,
                 enable_private_endpoint: _builtins.bool,
                 enable_private_nodes: _builtins.bool,
                 master_global_access_configs: Sequence['outputs.GetClusterPrivateClusterConfigMasterGlobalAccessConfigResult'],
                 master_ipv4_cidr_block: _builtins.str,
                 peering_name: _builtins.str,
                 private_endpoint: _builtins.str,
                 private_endpoint_subnetwork: _builtins.str,
                 public_endpoint: _builtins.str):
        """
        :param _builtins.bool enable_private_endpoint: When true, the cluster's private endpoint is used as the cluster endpoint and access through the public endpoint is disabled. When false, either endpoint can be used.
        :param _builtins.bool enable_private_nodes: Enables the private cluster feature, creating a private endpoint on the cluster. In a private cluster, nodes only have RFC 1918 private addresses and communicate with the master's private endpoint via private networking.
        :param Sequence['GetClusterPrivateClusterConfigMasterGlobalAccessConfigArgs'] master_global_access_configs: Controls cluster master global access settings.
        :param _builtins.str master_ipv4_cidr_block: The IP range in CIDR notation to use for the hosted master network. This range will be used for assigning private IP addresses to the cluster master(s) and the ILB VIP. This range must not overlap with any other ranges in use within the cluster's network, and it must be a /28 subnet. See Private Cluster Limitations for more details. This field only applies to private clusters, when enable_private_nodes is true.
        :param _builtins.str peering_name: The name of the peering between this cluster and the Google owned VPC.
        :param _builtins.str private_endpoint: The internal IP address of this cluster's master endpoint.
        :param _builtins.str private_endpoint_subnetwork: Subnetwork in cluster's network where master's endpoint will be provisioned.
        :param _builtins.str public_endpoint: The external IP address of this cluster's master endpoint.
        """
        pulumi.set(__self__, "enable_private_endpoint", enable_private_endpoint)
        pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        pulumi.set(__self__, "master_global_access_configs", master_global_access_configs)
        pulumi.set(__self__, "master_ipv4_cidr_block", master_ipv4_cidr_block)
        pulumi.set(__self__, "peering_name", peering_name)
        pulumi.set(__self__, "private_endpoint", private_endpoint)
        pulumi.set(__self__, "private_endpoint_subnetwork", private_endpoint_subnetwork)
        pulumi.set(__self__, "public_endpoint", public_endpoint)

    @_builtins.property
    @pulumi.getter(name="enablePrivateEndpoint")
    def enable_private_endpoint(self) -> _builtins.bool:
        """
        When true, the cluster's private endpoint is used as the cluster endpoint and access through the public endpoint is disabled. When false, either endpoint can be used.
        """
        return pulumi.get(self, "enable_private_endpoint")

    @_builtins.property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> _builtins.bool:
        """
        Enables the private cluster feature, creating a private endpoint on the cluster. In a private cluster, nodes only have RFC 1918 private addresses and communicate with the master's private endpoint via private networking.
        """
        return pulumi.get(self, "enable_private_nodes")

    @_builtins.property
    @pulumi.getter(name="masterGlobalAccessConfigs")
    def master_global_access_configs(self) -> Sequence['outputs.GetClusterPrivateClusterConfigMasterGlobalAccessConfigResult']:
        """
        Controls cluster master global access settings.
        """
        return pulumi.get(self, "master_global_access_configs")

    @_builtins.property
    @pulumi.getter(name="masterIpv4CidrBlock")
    def master_ipv4_cidr_block(self) -> _builtins.str:
        """
        The IP range in CIDR notation to use for the hosted master network. This range will be used for assigning private IP addresses to the cluster master(s) and the ILB VIP. This range must not overlap with any other ranges in use within the cluster's network, and it must be a /28 subnet. See Private Cluster Limitations for more details. This field only applies to private clusters, when enable_private_nodes is true.
        """
        return pulumi.get(self, "master_ipv4_cidr_block")

    @_builtins.property
    @pulumi.getter(name="peeringName")
    def peering_name(self) -> _builtins.str:
        """
        The name of the peering between this cluster and the Google owned VPC.
        """
        return pulumi.get(self, "peering_name")

    @_builtins.property
    @pulumi.getter(name="privateEndpoint")
    def private_endpoint(self) -> _builtins.str:
        """
        The internal IP address of this cluster's master endpoint.
        """
        return pulumi.get(self, "private_endpoint")

    @_builtins.property
    @pulumi.getter(name="privateEndpointSubnetwork")
    def private_endpoint_subnetwork(self) -> _builtins.str:
        """
        Subnetwork in cluster's network where master's endpoint will be provisioned.
        """
        return pulumi.get(self, "private_endpoint_subnetwork")

    @_builtins.property
    @pulumi.getter(name="publicEndpoint")
    def public_endpoint(self) -> _builtins.str:
        """
        The external IP address of this cluster's master endpoint.
        """
        return pulumi.get(self, "public_endpoint")


@pulumi.output_type
class GetClusterPrivateClusterConfigMasterGlobalAccessConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether the cluster master is accessible globally or not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether the cluster master is accessible globally or not.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterProtectConfigResult(dict):
    def __init__(__self__, *,
                 workload_configs: Sequence['outputs.GetClusterProtectConfigWorkloadConfigResult'],
                 workload_vulnerability_mode: _builtins.str):
        """
        :param Sequence['GetClusterProtectConfigWorkloadConfigArgs'] workload_configs: WorkloadConfig defines which actions are enabled for a cluster's workload configurations.
        :param _builtins.str workload_vulnerability_mode: Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        pulumi.set(__self__, "workload_configs", workload_configs)
        pulumi.set(__self__, "workload_vulnerability_mode", workload_vulnerability_mode)

    @_builtins.property
    @pulumi.getter(name="workloadConfigs")
    def workload_configs(self) -> Sequence['outputs.GetClusterProtectConfigWorkloadConfigResult']:
        """
        WorkloadConfig defines which actions are enabled for a cluster's workload configurations.
        """
        return pulumi.get(self, "workload_configs")

    @_builtins.property
    @pulumi.getter(name="workloadVulnerabilityMode")
    def workload_vulnerability_mode(self) -> _builtins.str:
        """
        Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "workload_vulnerability_mode")


@pulumi.output_type
class GetClusterProtectConfigWorkloadConfigResult(dict):
    def __init__(__self__, *,
                 audit_mode: _builtins.str):
        """
        :param _builtins.str audit_mode: Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        pulumi.set(__self__, "audit_mode", audit_mode)

    @_builtins.property
    @pulumi.getter(name="auditMode")
    def audit_mode(self) -> _builtins.str:
        """
        Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "audit_mode")


@pulumi.output_type
class GetClusterRbacBindingConfigResult(dict):
    def __init__(__self__, *,
                 enable_insecure_binding_system_authenticated: _builtins.bool,
                 enable_insecure_binding_system_unauthenticated: _builtins.bool):
        """
        :param _builtins.bool enable_insecure_binding_system_authenticated: Setting this to true will allow any ClusterRoleBinding and RoleBinding with subjects system:authenticated.
        :param _builtins.bool enable_insecure_binding_system_unauthenticated: Setting this to true will allow any ClusterRoleBinding and RoleBinding with subjects system:anonymous or system:unauthenticated.
        """
        pulumi.set(__self__, "enable_insecure_binding_system_authenticated", enable_insecure_binding_system_authenticated)
        pulumi.set(__self__, "enable_insecure_binding_system_unauthenticated", enable_insecure_binding_system_unauthenticated)

    @_builtins.property
    @pulumi.getter(name="enableInsecureBindingSystemAuthenticated")
    def enable_insecure_binding_system_authenticated(self) -> _builtins.bool:
        """
        Setting this to true will allow any ClusterRoleBinding and RoleBinding with subjects system:authenticated.
        """
        return pulumi.get(self, "enable_insecure_binding_system_authenticated")

    @_builtins.property
    @pulumi.getter(name="enableInsecureBindingSystemUnauthenticated")
    def enable_insecure_binding_system_unauthenticated(self) -> _builtins.bool:
        """
        Setting this to true will allow any ClusterRoleBinding and RoleBinding with subjects system:anonymous or system:unauthenticated.
        """
        return pulumi.get(self, "enable_insecure_binding_system_unauthenticated")


@pulumi.output_type
class GetClusterReleaseChannelResult(dict):
    def __init__(__self__, *,
                 channel: _builtins.str):
        """
        :param _builtins.str channel: The selected release channel. Accepted values are:
               * UNSPECIFIED: Not set.
               * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
               * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
               * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
               * EXTENDED: GKE provides extended support for Kubernetes minor versions through the Extended channel. With this channel, you can stay on a minor version for up to 24 months.
        """
        pulumi.set(__self__, "channel", channel)

    @_builtins.property
    @pulumi.getter
    def channel(self) -> _builtins.str:
        """
        The selected release channel. Accepted values are:
        * UNSPECIFIED: Not set.
        * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
        * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
        * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
        * EXTENDED: GKE provides extended support for Kubernetes minor versions through the Extended channel. With this channel, you can stay on a minor version for up to 24 months.
        """
        return pulumi.get(self, "channel")


@pulumi.output_type
class GetClusterResourceUsageExportConfigResult(dict):
    def __init__(__self__, *,
                 bigquery_destinations: Sequence['outputs.GetClusterResourceUsageExportConfigBigqueryDestinationResult'],
                 enable_network_egress_metering: _builtins.bool,
                 enable_resource_consumption_metering: _builtins.bool):
        """
        :param Sequence['GetClusterResourceUsageExportConfigBigqueryDestinationArgs'] bigquery_destinations: Parameters for using BigQuery as the destination of resource usage export.
        :param _builtins.bool enable_network_egress_metering: Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created in the cluster to meter network egress traffic.
        :param _builtins.bool enable_resource_consumption_metering: Whether to enable resource consumption metering on this cluster. When enabled, a table will be created in the resource export BigQuery dataset to store resource consumption data. The resulting table can be joined with the resource usage table or with BigQuery billing export. Defaults to true.
        """
        pulumi.set(__self__, "bigquery_destinations", bigquery_destinations)
        pulumi.set(__self__, "enable_network_egress_metering", enable_network_egress_metering)
        pulumi.set(__self__, "enable_resource_consumption_metering", enable_resource_consumption_metering)

    @_builtins.property
    @pulumi.getter(name="bigqueryDestinations")
    def bigquery_destinations(self) -> Sequence['outputs.GetClusterResourceUsageExportConfigBigqueryDestinationResult']:
        """
        Parameters for using BigQuery as the destination of resource usage export.
        """
        return pulumi.get(self, "bigquery_destinations")

    @_builtins.property
    @pulumi.getter(name="enableNetworkEgressMetering")
    def enable_network_egress_metering(self) -> _builtins.bool:
        """
        Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created in the cluster to meter network egress traffic.
        """
        return pulumi.get(self, "enable_network_egress_metering")

    @_builtins.property
    @pulumi.getter(name="enableResourceConsumptionMetering")
    def enable_resource_consumption_metering(self) -> _builtins.bool:
        """
        Whether to enable resource consumption metering on this cluster. When enabled, a table will be created in the resource export BigQuery dataset to store resource consumption data. The resulting table can be joined with the resource usage table or with BigQuery billing export. Defaults to true.
        """
        return pulumi.get(self, "enable_resource_consumption_metering")


@pulumi.output_type
class GetClusterResourceUsageExportConfigBigqueryDestinationResult(dict):
    def __init__(__self__, *,
                 dataset_id: _builtins.str):
        """
        :param _builtins.str dataset_id: The ID of a BigQuery Dataset.
        """
        pulumi.set(__self__, "dataset_id", dataset_id)

    @_builtins.property
    @pulumi.getter(name="datasetId")
    def dataset_id(self) -> _builtins.str:
        """
        The ID of a BigQuery Dataset.
        """
        return pulumi.get(self, "dataset_id")


@pulumi.output_type
class GetClusterSecretManagerConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 rotation_configs: Sequence['outputs.GetClusterSecretManagerConfigRotationConfigResult']):
        """
        :param _builtins.bool enabled: Enable the Secret manager csi component.
        :param Sequence['GetClusterSecretManagerConfigRotationConfigArgs'] rotation_configs: Configuration for Secret Manager auto rotation.
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "rotation_configs", rotation_configs)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable the Secret manager csi component.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="rotationConfigs")
    def rotation_configs(self) -> Sequence['outputs.GetClusterSecretManagerConfigRotationConfigResult']:
        """
        Configuration for Secret Manager auto rotation.
        """
        return pulumi.get(self, "rotation_configs")


@pulumi.output_type
class GetClusterSecretManagerConfigRotationConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 rotation_interval: _builtins.str):
        """
        :param _builtins.bool enabled: Enable the Secret manager auto rotation.
        :param _builtins.str rotation_interval: The interval between two consecutive rotations. Default rotation interval is 2 minutes
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "rotation_interval", rotation_interval)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable the Secret manager auto rotation.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="rotationInterval")
    def rotation_interval(self) -> _builtins.str:
        """
        The interval between two consecutive rotations. Default rotation interval is 2 minutes
        """
        return pulumi.get(self, "rotation_interval")


@pulumi.output_type
class GetClusterSecretSyncConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 rotation_configs: Sequence['outputs.GetClusterSecretSyncConfigRotationConfigResult']):
        """
        :param _builtins.bool enabled: Enable the Sync as k8s secret add-on.
        :param Sequence['GetClusterSecretSyncConfigRotationConfigArgs'] rotation_configs: Configuration for Secret Sync auto rotation.
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "rotation_configs", rotation_configs)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable the Sync as k8s secret add-on.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="rotationConfigs")
    def rotation_configs(self) -> Sequence['outputs.GetClusterSecretSyncConfigRotationConfigResult']:
        """
        Configuration for Secret Sync auto rotation.
        """
        return pulumi.get(self, "rotation_configs")


@pulumi.output_type
class GetClusterSecretSyncConfigRotationConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 rotation_interval: _builtins.str):
        """
        :param _builtins.bool enabled: Enable the Secret sync auto rotation.
        :param _builtins.str rotation_interval: The interval between two consecutive rotations. Default rotation interval is 2 minutes
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "rotation_interval", rotation_interval)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enable the Secret sync auto rotation.
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="rotationInterval")
    def rotation_interval(self) -> _builtins.str:
        """
        The interval between two consecutive rotations. Default rotation interval is 2 minutes
        """
        return pulumi.get(self, "rotation_interval")


@pulumi.output_type
class GetClusterSecurityPostureConfigResult(dict):
    def __init__(__self__, *,
                 mode: _builtins.str,
                 vulnerability_mode: _builtins.str):
        """
        :param _builtins.str mode: Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include DISABLED, BASIC, and ENTERPRISE.
        :param _builtins.str vulnerability_mode: Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include VULNERABILITY_DISABLED, VULNERABILITY_BASIC and VULNERABILITY_ENTERPRISE.
        """
        pulumi.set(__self__, "mode", mode)
        pulumi.set(__self__, "vulnerability_mode", vulnerability_mode)

    @_builtins.property
    @pulumi.getter
    def mode(self) -> _builtins.str:
        """
        Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include DISABLED, BASIC, and ENTERPRISE.
        """
        return pulumi.get(self, "mode")

    @_builtins.property
    @pulumi.getter(name="vulnerabilityMode")
    def vulnerability_mode(self) -> _builtins.str:
        """
        Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include VULNERABILITY_DISABLED, VULNERABILITY_BASIC and VULNERABILITY_ENTERPRISE.
        """
        return pulumi.get(self, "vulnerability_mode")


@pulumi.output_type
class GetClusterServiceExternalIpsConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: When enabled, services with external ips specified will be allowed.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        When enabled, services with external ips specified will be allowed.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterTpuConfigResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool,
                 ipv4_cidr_block: _builtins.str,
                 use_service_networking: _builtins.bool):
        """
        :param _builtins.bool enabled: Whether Cloud TPU integration is enabled or not
        :param _builtins.str ipv4_cidr_block: IPv4 CIDR block reserved for Cloud TPU in the VPC.
        :param _builtins.bool use_service_networking: Whether to use service networking for Cloud TPU or not
        """
        pulumi.set(__self__, "enabled", enabled)
        pulumi.set(__self__, "ipv4_cidr_block", ipv4_cidr_block)
        pulumi.set(__self__, "use_service_networking", use_service_networking)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Whether Cloud TPU integration is enabled or not
        """
        return pulumi.get(self, "enabled")

    @_builtins.property
    @pulumi.getter(name="ipv4CidrBlock")
    def ipv4_cidr_block(self) -> _builtins.str:
        """
        IPv4 CIDR block reserved for Cloud TPU in the VPC.
        """
        return pulumi.get(self, "ipv4_cidr_block")

    @_builtins.property
    @pulumi.getter(name="useServiceNetworking")
    def use_service_networking(self) -> _builtins.bool:
        """
        Whether to use service networking for Cloud TPU or not
        """
        return pulumi.get(self, "use_service_networking")


@pulumi.output_type
class GetClusterUserManagedKeysConfigResult(dict):
    def __init__(__self__, *,
                 aggregation_ca: _builtins.str,
                 cluster_ca: _builtins.str,
                 control_plane_disk_encryption_key: _builtins.str,
                 etcd_api_ca: _builtins.str,
                 etcd_peer_ca: _builtins.str,
                 gkeops_etcd_backup_encryption_key: _builtins.str,
                 service_account_signing_keys: Sequence[_builtins.str],
                 service_account_verification_keys: Sequence[_builtins.str]):
        """
        :param _builtins.str aggregation_ca: The Certificate Authority Service caPool to use for the aggreation CA in this cluster.
        :param _builtins.str cluster_ca: The Certificate Authority Service caPool to use for the cluster CA in this cluster.
        :param _builtins.str control_plane_disk_encryption_key: The Cloud KMS cryptoKey to use for Confidential Hyperdisk on the control plane nodes.
        :param _builtins.str etcd_api_ca: The Certificate Authority Service caPool to use for the etcd API CA in this cluster.
        :param _builtins.str etcd_peer_ca: The Certificate Authority Service caPool to use for the etcd peer CA in this cluster.
        :param _builtins.str gkeops_etcd_backup_encryption_key: Resource path of the Cloud KMS cryptoKey to use for encryption of internal etcd backups.
        :param Sequence[_builtins.str] service_account_signing_keys: The Cloud KMS cryptoKeyVersions to use for signing service account JWTs issued by this cluster.
        :param Sequence[_builtins.str] service_account_verification_keys: The Cloud KMS cryptoKeyVersions to use for verifying service account JWTs issued by this cluster.
        """
        pulumi.set(__self__, "aggregation_ca", aggregation_ca)
        pulumi.set(__self__, "cluster_ca", cluster_ca)
        pulumi.set(__self__, "control_plane_disk_encryption_key", control_plane_disk_encryption_key)
        pulumi.set(__self__, "etcd_api_ca", etcd_api_ca)
        pulumi.set(__self__, "etcd_peer_ca", etcd_peer_ca)
        pulumi.set(__self__, "gkeops_etcd_backup_encryption_key", gkeops_etcd_backup_encryption_key)
        pulumi.set(__self__, "service_account_signing_keys", service_account_signing_keys)
        pulumi.set(__self__, "service_account_verification_keys", service_account_verification_keys)

    @_builtins.property
    @pulumi.getter(name="aggregationCa")
    def aggregation_ca(self) -> _builtins.str:
        """
        The Certificate Authority Service caPool to use for the aggreation CA in this cluster.
        """
        return pulumi.get(self, "aggregation_ca")

    @_builtins.property
    @pulumi.getter(name="clusterCa")
    def cluster_ca(self) -> _builtins.str:
        """
        The Certificate Authority Service caPool to use for the cluster CA in this cluster.
        """
        return pulumi.get(self, "cluster_ca")

    @_builtins.property
    @pulumi.getter(name="controlPlaneDiskEncryptionKey")
    def control_plane_disk_encryption_key(self) -> _builtins.str:
        """
        The Cloud KMS cryptoKey to use for Confidential Hyperdisk on the control plane nodes.
        """
        return pulumi.get(self, "control_plane_disk_encryption_key")

    @_builtins.property
    @pulumi.getter(name="etcdApiCa")
    def etcd_api_ca(self) -> _builtins.str:
        """
        The Certificate Authority Service caPool to use for the etcd API CA in this cluster.
        """
        return pulumi.get(self, "etcd_api_ca")

    @_builtins.property
    @pulumi.getter(name="etcdPeerCa")
    def etcd_peer_ca(self) -> _builtins.str:
        """
        The Certificate Authority Service caPool to use for the etcd peer CA in this cluster.
        """
        return pulumi.get(self, "etcd_peer_ca")

    @_builtins.property
    @pulumi.getter(name="gkeopsEtcdBackupEncryptionKey")
    def gkeops_etcd_backup_encryption_key(self) -> _builtins.str:
        """
        Resource path of the Cloud KMS cryptoKey to use for encryption of internal etcd backups.
        """
        return pulumi.get(self, "gkeops_etcd_backup_encryption_key")

    @_builtins.property
    @pulumi.getter(name="serviceAccountSigningKeys")
    def service_account_signing_keys(self) -> Sequence[_builtins.str]:
        """
        The Cloud KMS cryptoKeyVersions to use for signing service account JWTs issued by this cluster.
        """
        return pulumi.get(self, "service_account_signing_keys")

    @_builtins.property
    @pulumi.getter(name="serviceAccountVerificationKeys")
    def service_account_verification_keys(self) -> Sequence[_builtins.str]:
        """
        The Cloud KMS cryptoKeyVersions to use for verifying service account JWTs issued by this cluster.
        """
        return pulumi.get(self, "service_account_verification_keys")


@pulumi.output_type
class GetClusterVerticalPodAutoscalingResult(dict):
    def __init__(__self__, *,
                 enabled: _builtins.bool):
        """
        :param _builtins.bool enabled: Enables vertical pod autoscaling.
        """
        pulumi.set(__self__, "enabled", enabled)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> _builtins.bool:
        """
        Enables vertical pod autoscaling.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetClusterWorkloadAltsConfigResult(dict):
    def __init__(__self__, *,
                 enable_alts: _builtins.bool):
        """
        :param _builtins.bool enable_alts: Whether the alts handshaker should be enabled or not for direct-path. Requires Workload Identity (workloadPool must be non-empty).
        """
        pulumi.set(__self__, "enable_alts", enable_alts)

    @_builtins.property
    @pulumi.getter(name="enableAlts")
    def enable_alts(self) -> _builtins.bool:
        """
        Whether the alts handshaker should be enabled or not for direct-path. Requires Workload Identity (workloadPool must be non-empty).
        """
        return pulumi.get(self, "enable_alts")


@pulumi.output_type
class GetClusterWorkloadIdentityConfigResult(dict):
    def __init__(__self__, *,
                 workload_pool: _builtins.str):
        """
        :param _builtins.str workload_pool: The workload pool to attach all Kubernetes service accounts to.
        """
        pulumi.set(__self__, "workload_pool", workload_pool)

    @_builtins.property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> _builtins.str:
        """
        The workload pool to attach all Kubernetes service accounts to.
        """
        return pulumi.get(self, "workload_pool")


