# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins
import copy
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities

__all__ = [
    'AttachedClusterAuthorizationArgs',
    'AttachedClusterAuthorizationArgsDict',
    'AttachedClusterBinaryAuthorizationArgs',
    'AttachedClusterBinaryAuthorizationArgsDict',
    'AttachedClusterErrorArgs',
    'AttachedClusterErrorArgsDict',
    'AttachedClusterFleetArgs',
    'AttachedClusterFleetArgsDict',
    'AttachedClusterLoggingConfigArgs',
    'AttachedClusterLoggingConfigArgsDict',
    'AttachedClusterLoggingConfigComponentConfigArgs',
    'AttachedClusterLoggingConfigComponentConfigArgsDict',
    'AttachedClusterMonitoringConfigArgs',
    'AttachedClusterMonitoringConfigArgsDict',
    'AttachedClusterMonitoringConfigManagedPrometheusConfigArgs',
    'AttachedClusterMonitoringConfigManagedPrometheusConfigArgsDict',
    'AttachedClusterOidcConfigArgs',
    'AttachedClusterOidcConfigArgsDict',
    'AttachedClusterProxyConfigArgs',
    'AttachedClusterProxyConfigArgsDict',
    'AttachedClusterProxyConfigKubernetesSecretArgs',
    'AttachedClusterProxyConfigKubernetesSecretArgsDict',
    'AttachedClusterSecurityPostureConfigArgs',
    'AttachedClusterSecurityPostureConfigArgsDict',
    'AttachedClusterWorkloadIdentityConfigArgs',
    'AttachedClusterWorkloadIdentityConfigArgsDict',
    'AwsClusterAuthorizationArgs',
    'AwsClusterAuthorizationArgsDict',
    'AwsClusterAuthorizationAdminGroupArgs',
    'AwsClusterAuthorizationAdminGroupArgsDict',
    'AwsClusterAuthorizationAdminUserArgs',
    'AwsClusterAuthorizationAdminUserArgsDict',
    'AwsClusterBinaryAuthorizationArgs',
    'AwsClusterBinaryAuthorizationArgsDict',
    'AwsClusterControlPlaneArgs',
    'AwsClusterControlPlaneArgsDict',
    'AwsClusterControlPlaneAwsServicesAuthenticationArgs',
    'AwsClusterControlPlaneAwsServicesAuthenticationArgsDict',
    'AwsClusterControlPlaneConfigEncryptionArgs',
    'AwsClusterControlPlaneConfigEncryptionArgsDict',
    'AwsClusterControlPlaneDatabaseEncryptionArgs',
    'AwsClusterControlPlaneDatabaseEncryptionArgsDict',
    'AwsClusterControlPlaneInstancePlacementArgs',
    'AwsClusterControlPlaneInstancePlacementArgsDict',
    'AwsClusterControlPlaneMainVolumeArgs',
    'AwsClusterControlPlaneMainVolumeArgsDict',
    'AwsClusterControlPlaneProxyConfigArgs',
    'AwsClusterControlPlaneProxyConfigArgsDict',
    'AwsClusterControlPlaneRootVolumeArgs',
    'AwsClusterControlPlaneRootVolumeArgsDict',
    'AwsClusterControlPlaneSshConfigArgs',
    'AwsClusterControlPlaneSshConfigArgsDict',
    'AwsClusterFleetArgs',
    'AwsClusterFleetArgsDict',
    'AwsClusterLoggingConfigArgs',
    'AwsClusterLoggingConfigArgsDict',
    'AwsClusterLoggingConfigComponentConfigArgs',
    'AwsClusterLoggingConfigComponentConfigArgsDict',
    'AwsClusterNetworkingArgs',
    'AwsClusterNetworkingArgsDict',
    'AwsClusterWorkloadIdentityConfigArgs',
    'AwsClusterWorkloadIdentityConfigArgsDict',
    'AwsNodePoolAutoscalingArgs',
    'AwsNodePoolAutoscalingArgsDict',
    'AwsNodePoolConfigArgs',
    'AwsNodePoolConfigArgsDict',
    'AwsNodePoolConfigAutoscalingMetricsCollectionArgs',
    'AwsNodePoolConfigAutoscalingMetricsCollectionArgsDict',
    'AwsNodePoolConfigConfigEncryptionArgs',
    'AwsNodePoolConfigConfigEncryptionArgsDict',
    'AwsNodePoolConfigInstancePlacementArgs',
    'AwsNodePoolConfigInstancePlacementArgsDict',
    'AwsNodePoolConfigProxyConfigArgs',
    'AwsNodePoolConfigProxyConfigArgsDict',
    'AwsNodePoolConfigRootVolumeArgs',
    'AwsNodePoolConfigRootVolumeArgsDict',
    'AwsNodePoolConfigSpotConfigArgs',
    'AwsNodePoolConfigSpotConfigArgsDict',
    'AwsNodePoolConfigSshConfigArgs',
    'AwsNodePoolConfigSshConfigArgsDict',
    'AwsNodePoolConfigTaintArgs',
    'AwsNodePoolConfigTaintArgsDict',
    'AwsNodePoolKubeletConfigArgs',
    'AwsNodePoolKubeletConfigArgsDict',
    'AwsNodePoolManagementArgs',
    'AwsNodePoolManagementArgsDict',
    'AwsNodePoolMaxPodsConstraintArgs',
    'AwsNodePoolMaxPodsConstraintArgsDict',
    'AwsNodePoolUpdateSettingsArgs',
    'AwsNodePoolUpdateSettingsArgsDict',
    'AwsNodePoolUpdateSettingsSurgeSettingsArgs',
    'AwsNodePoolUpdateSettingsSurgeSettingsArgsDict',
    'AzureClusterAuthorizationArgs',
    'AzureClusterAuthorizationArgsDict',
    'AzureClusterAuthorizationAdminGroupArgs',
    'AzureClusterAuthorizationAdminGroupArgsDict',
    'AzureClusterAuthorizationAdminUserArgs',
    'AzureClusterAuthorizationAdminUserArgsDict',
    'AzureClusterAzureServicesAuthenticationArgs',
    'AzureClusterAzureServicesAuthenticationArgsDict',
    'AzureClusterControlPlaneArgs',
    'AzureClusterControlPlaneArgsDict',
    'AzureClusterControlPlaneDatabaseEncryptionArgs',
    'AzureClusterControlPlaneDatabaseEncryptionArgsDict',
    'AzureClusterControlPlaneMainVolumeArgs',
    'AzureClusterControlPlaneMainVolumeArgsDict',
    'AzureClusterControlPlaneProxyConfigArgs',
    'AzureClusterControlPlaneProxyConfigArgsDict',
    'AzureClusterControlPlaneReplicaPlacementArgs',
    'AzureClusterControlPlaneReplicaPlacementArgsDict',
    'AzureClusterControlPlaneRootVolumeArgs',
    'AzureClusterControlPlaneRootVolumeArgsDict',
    'AzureClusterControlPlaneSshConfigArgs',
    'AzureClusterControlPlaneSshConfigArgsDict',
    'AzureClusterFleetArgs',
    'AzureClusterFleetArgsDict',
    'AzureClusterLoggingConfigArgs',
    'AzureClusterLoggingConfigArgsDict',
    'AzureClusterLoggingConfigComponentConfigArgs',
    'AzureClusterLoggingConfigComponentConfigArgsDict',
    'AzureClusterNetworkingArgs',
    'AzureClusterNetworkingArgsDict',
    'AzureClusterWorkloadIdentityConfigArgs',
    'AzureClusterWorkloadIdentityConfigArgsDict',
    'AzureNodePoolAutoscalingArgs',
    'AzureNodePoolAutoscalingArgsDict',
    'AzureNodePoolConfigArgs',
    'AzureNodePoolConfigArgsDict',
    'AzureNodePoolConfigProxyConfigArgs',
    'AzureNodePoolConfigProxyConfigArgsDict',
    'AzureNodePoolConfigRootVolumeArgs',
    'AzureNodePoolConfigRootVolumeArgsDict',
    'AzureNodePoolConfigSshConfigArgs',
    'AzureNodePoolConfigSshConfigArgsDict',
    'AzureNodePoolManagementArgs',
    'AzureNodePoolManagementArgsDict',
    'AzureNodePoolMaxPodsConstraintArgs',
    'AzureNodePoolMaxPodsConstraintArgsDict',
    'ClusterAddonsConfigArgs',
    'ClusterAddonsConfigArgsDict',
    'ClusterAddonsConfigCloudrunConfigArgs',
    'ClusterAddonsConfigCloudrunConfigArgsDict',
    'ClusterAddonsConfigConfigConnectorConfigArgs',
    'ClusterAddonsConfigConfigConnectorConfigArgsDict',
    'ClusterAddonsConfigDnsCacheConfigArgs',
    'ClusterAddonsConfigDnsCacheConfigArgsDict',
    'ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs',
    'ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgsDict',
    'ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs',
    'ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgsDict',
    'ClusterAddonsConfigGcsFuseCsiDriverConfigArgs',
    'ClusterAddonsConfigGcsFuseCsiDriverConfigArgsDict',
    'ClusterAddonsConfigGkeBackupAgentConfigArgs',
    'ClusterAddonsConfigGkeBackupAgentConfigArgsDict',
    'ClusterAddonsConfigHorizontalPodAutoscalingArgs',
    'ClusterAddonsConfigHorizontalPodAutoscalingArgsDict',
    'ClusterAddonsConfigHttpLoadBalancingArgs',
    'ClusterAddonsConfigHttpLoadBalancingArgsDict',
    'ClusterAddonsConfigIstioConfigArgs',
    'ClusterAddonsConfigIstioConfigArgsDict',
    'ClusterAddonsConfigKalmConfigArgs',
    'ClusterAddonsConfigKalmConfigArgsDict',
    'ClusterAddonsConfigNetworkPolicyConfigArgs',
    'ClusterAddonsConfigNetworkPolicyConfigArgsDict',
    'ClusterAddonsConfigParallelstoreCsiDriverConfigArgs',
    'ClusterAddonsConfigParallelstoreCsiDriverConfigArgsDict',
    'ClusterAddonsConfigRayOperatorConfigArgs',
    'ClusterAddonsConfigRayOperatorConfigArgsDict',
    'ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgs',
    'ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgsDict',
    'ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgs',
    'ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgsDict',
    'ClusterAddonsConfigStatefulHaConfigArgs',
    'ClusterAddonsConfigStatefulHaConfigArgsDict',
    'ClusterAuthenticatorGroupsConfigArgs',
    'ClusterAuthenticatorGroupsConfigArgsDict',
    'ClusterBinaryAuthorizationArgs',
    'ClusterBinaryAuthorizationArgsDict',
    'ClusterClusterAutoscalingArgs',
    'ClusterClusterAutoscalingArgsDict',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsArgsDict',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgsDict',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgsDict',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgsDict',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgsDict',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgsDict',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgsDict',
    'ClusterClusterAutoscalingResourceLimitArgs',
    'ClusterClusterAutoscalingResourceLimitArgsDict',
    'ClusterClusterTelemetryArgs',
    'ClusterClusterTelemetryArgsDict',
    'ClusterConfidentialNodesArgs',
    'ClusterConfidentialNodesArgsDict',
    'ClusterControlPlaneEndpointsConfigArgs',
    'ClusterControlPlaneEndpointsConfigArgsDict',
    'ClusterControlPlaneEndpointsConfigDnsEndpointConfigArgs',
    'ClusterControlPlaneEndpointsConfigDnsEndpointConfigArgsDict',
    'ClusterControlPlaneEndpointsConfigIpEndpointsConfigArgs',
    'ClusterControlPlaneEndpointsConfigIpEndpointsConfigArgsDict',
    'ClusterCostManagementConfigArgs',
    'ClusterCostManagementConfigArgsDict',
    'ClusterDatabaseEncryptionArgs',
    'ClusterDatabaseEncryptionArgsDict',
    'ClusterDefaultSnatStatusArgs',
    'ClusterDefaultSnatStatusArgsDict',
    'ClusterDnsConfigArgs',
    'ClusterDnsConfigArgsDict',
    'ClusterEnableK8sBetaApisArgs',
    'ClusterEnableK8sBetaApisArgsDict',
    'ClusterEnterpriseConfigArgs',
    'ClusterEnterpriseConfigArgsDict',
    'ClusterFleetArgs',
    'ClusterFleetArgsDict',
    'ClusterGatewayApiConfigArgs',
    'ClusterGatewayApiConfigArgsDict',
    'ClusterIdentityServiceConfigArgs',
    'ClusterIdentityServiceConfigArgsDict',
    'ClusterIpAllocationPolicyArgs',
    'ClusterIpAllocationPolicyArgsDict',
    'ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs',
    'ClusterIpAllocationPolicyAdditionalPodRangesConfigArgsDict',
    'ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs',
    'ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgsDict',
    'ClusterLoggingConfigArgs',
    'ClusterLoggingConfigArgsDict',
    'ClusterMaintenancePolicyArgs',
    'ClusterMaintenancePolicyArgsDict',
    'ClusterMaintenancePolicyDailyMaintenanceWindowArgs',
    'ClusterMaintenancePolicyDailyMaintenanceWindowArgsDict',
    'ClusterMaintenancePolicyMaintenanceExclusionArgs',
    'ClusterMaintenancePolicyMaintenanceExclusionArgsDict',
    'ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs',
    'ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgsDict',
    'ClusterMaintenancePolicyRecurringWindowArgs',
    'ClusterMaintenancePolicyRecurringWindowArgsDict',
    'ClusterMasterAuthArgs',
    'ClusterMasterAuthArgsDict',
    'ClusterMasterAuthClientCertificateConfigArgs',
    'ClusterMasterAuthClientCertificateConfigArgsDict',
    'ClusterMasterAuthorizedNetworksConfigArgs',
    'ClusterMasterAuthorizedNetworksConfigArgsDict',
    'ClusterMasterAuthorizedNetworksConfigCidrBlockArgs',
    'ClusterMasterAuthorizedNetworksConfigCidrBlockArgsDict',
    'ClusterMeshCertificatesArgs',
    'ClusterMeshCertificatesArgsDict',
    'ClusterMonitoringConfigArgs',
    'ClusterMonitoringConfigArgsDict',
    'ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs',
    'ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgsDict',
    'ClusterMonitoringConfigManagedPrometheusArgs',
    'ClusterMonitoringConfigManagedPrometheusArgsDict',
    'ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigArgs',
    'ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigArgsDict',
    'ClusterNetworkPolicyArgs',
    'ClusterNetworkPolicyArgsDict',
    'ClusterNodeConfigArgs',
    'ClusterNodeConfigArgsDict',
    'ClusterNodeConfigAdvancedMachineFeaturesArgs',
    'ClusterNodeConfigAdvancedMachineFeaturesArgsDict',
    'ClusterNodeConfigConfidentialNodesArgs',
    'ClusterNodeConfigConfidentialNodesArgsDict',
    'ClusterNodeConfigContainerdConfigArgs',
    'ClusterNodeConfigContainerdConfigArgsDict',
    'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs',
    'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgsDict',
    'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs',
    'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict',
    'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs',
    'ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict',
    'ClusterNodeConfigEffectiveTaintArgs',
    'ClusterNodeConfigEffectiveTaintArgsDict',
    'ClusterNodeConfigEphemeralStorageConfigArgs',
    'ClusterNodeConfigEphemeralStorageConfigArgsDict',
    'ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs',
    'ClusterNodeConfigEphemeralStorageLocalSsdConfigArgsDict',
    'ClusterNodeConfigFastSocketArgs',
    'ClusterNodeConfigFastSocketArgsDict',
    'ClusterNodeConfigGcfsConfigArgs',
    'ClusterNodeConfigGcfsConfigArgsDict',
    'ClusterNodeConfigGuestAcceleratorArgs',
    'ClusterNodeConfigGuestAcceleratorArgsDict',
    'ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs',
    'ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgsDict',
    'ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs',
    'ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgsDict',
    'ClusterNodeConfigGvnicArgs',
    'ClusterNodeConfigGvnicArgsDict',
    'ClusterNodeConfigHostMaintenancePolicyArgs',
    'ClusterNodeConfigHostMaintenancePolicyArgsDict',
    'ClusterNodeConfigKubeletConfigArgs',
    'ClusterNodeConfigKubeletConfigArgsDict',
    'ClusterNodeConfigLinuxNodeConfigArgs',
    'ClusterNodeConfigLinuxNodeConfigArgsDict',
    'ClusterNodeConfigLinuxNodeConfigHugepagesConfigArgs',
    'ClusterNodeConfigLinuxNodeConfigHugepagesConfigArgsDict',
    'ClusterNodeConfigLocalNvmeSsdBlockConfigArgs',
    'ClusterNodeConfigLocalNvmeSsdBlockConfigArgsDict',
    'ClusterNodeConfigReservationAffinityArgs',
    'ClusterNodeConfigReservationAffinityArgsDict',
    'ClusterNodeConfigSandboxConfigArgs',
    'ClusterNodeConfigSandboxConfigArgsDict',
    'ClusterNodeConfigSecondaryBootDiskArgs',
    'ClusterNodeConfigSecondaryBootDiskArgsDict',
    'ClusterNodeConfigShieldedInstanceConfigArgs',
    'ClusterNodeConfigShieldedInstanceConfigArgsDict',
    'ClusterNodeConfigSoleTenantConfigArgs',
    'ClusterNodeConfigSoleTenantConfigArgsDict',
    'ClusterNodeConfigSoleTenantConfigNodeAffinityArgs',
    'ClusterNodeConfigSoleTenantConfigNodeAffinityArgsDict',
    'ClusterNodeConfigTaintArgs',
    'ClusterNodeConfigTaintArgsDict',
    'ClusterNodeConfigWindowsNodeConfigArgs',
    'ClusterNodeConfigWindowsNodeConfigArgsDict',
    'ClusterNodeConfigWorkloadMetadataConfigArgs',
    'ClusterNodeConfigWorkloadMetadataConfigArgsDict',
    'ClusterNodePoolArgs',
    'ClusterNodePoolArgsDict',
    'ClusterNodePoolAutoConfigArgs',
    'ClusterNodePoolAutoConfigArgsDict',
    'ClusterNodePoolAutoConfigLinuxNodeConfigArgs',
    'ClusterNodePoolAutoConfigLinuxNodeConfigArgsDict',
    'ClusterNodePoolAutoConfigNetworkTagsArgs',
    'ClusterNodePoolAutoConfigNetworkTagsArgsDict',
    'ClusterNodePoolAutoConfigNodeKubeletConfigArgs',
    'ClusterNodePoolAutoConfigNodeKubeletConfigArgsDict',
    'ClusterNodePoolAutoscalingArgs',
    'ClusterNodePoolAutoscalingArgsDict',
    'ClusterNodePoolDefaultsArgs',
    'ClusterNodePoolDefaultsArgsDict',
    'ClusterNodePoolDefaultsNodeConfigDefaultsArgs',
    'ClusterNodePoolDefaultsNodeConfigDefaultsArgsDict',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigArgs',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigArgsDict',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigArgs',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigArgsDict',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs',
    'ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict',
    'ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs',
    'ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgsDict',
    'ClusterNodePoolManagementArgs',
    'ClusterNodePoolManagementArgsDict',
    'ClusterNodePoolNetworkConfigArgs',
    'ClusterNodePoolNetworkConfigArgsDict',
    'ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs',
    'ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgsDict',
    'ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs',
    'ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgsDict',
    'ClusterNodePoolNetworkConfigNetworkPerformanceConfigArgs',
    'ClusterNodePoolNetworkConfigNetworkPerformanceConfigArgsDict',
    'ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs',
    'ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgsDict',
    'ClusterNodePoolNodeConfigArgs',
    'ClusterNodePoolNodeConfigArgsDict',
    'ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs',
    'ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgsDict',
    'ClusterNodePoolNodeConfigConfidentialNodesArgs',
    'ClusterNodePoolNodeConfigConfidentialNodesArgsDict',
    'ClusterNodePoolNodeConfigContainerdConfigArgs',
    'ClusterNodePoolNodeConfigContainerdConfigArgsDict',
    'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs',
    'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgsDict',
    'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs',
    'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict',
    'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs',
    'ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict',
    'ClusterNodePoolNodeConfigEffectiveTaintArgs',
    'ClusterNodePoolNodeConfigEffectiveTaintArgsDict',
    'ClusterNodePoolNodeConfigEphemeralStorageConfigArgs',
    'ClusterNodePoolNodeConfigEphemeralStorageConfigArgsDict',
    'ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs',
    'ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgsDict',
    'ClusterNodePoolNodeConfigFastSocketArgs',
    'ClusterNodePoolNodeConfigFastSocketArgsDict',
    'ClusterNodePoolNodeConfigGcfsConfigArgs',
    'ClusterNodePoolNodeConfigGcfsConfigArgsDict',
    'ClusterNodePoolNodeConfigGuestAcceleratorArgs',
    'ClusterNodePoolNodeConfigGuestAcceleratorArgsDict',
    'ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs',
    'ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgsDict',
    'ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs',
    'ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgsDict',
    'ClusterNodePoolNodeConfigGvnicArgs',
    'ClusterNodePoolNodeConfigGvnicArgsDict',
    'ClusterNodePoolNodeConfigHostMaintenancePolicyArgs',
    'ClusterNodePoolNodeConfigHostMaintenancePolicyArgsDict',
    'ClusterNodePoolNodeConfigKubeletConfigArgs',
    'ClusterNodePoolNodeConfigKubeletConfigArgsDict',
    'ClusterNodePoolNodeConfigLinuxNodeConfigArgs',
    'ClusterNodePoolNodeConfigLinuxNodeConfigArgsDict',
    'ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs',
    'ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgsDict',
    'ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs',
    'ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgsDict',
    'ClusterNodePoolNodeConfigReservationAffinityArgs',
    'ClusterNodePoolNodeConfigReservationAffinityArgsDict',
    'ClusterNodePoolNodeConfigSandboxConfigArgs',
    'ClusterNodePoolNodeConfigSandboxConfigArgsDict',
    'ClusterNodePoolNodeConfigSecondaryBootDiskArgs',
    'ClusterNodePoolNodeConfigSecondaryBootDiskArgsDict',
    'ClusterNodePoolNodeConfigShieldedInstanceConfigArgs',
    'ClusterNodePoolNodeConfigShieldedInstanceConfigArgsDict',
    'ClusterNodePoolNodeConfigSoleTenantConfigArgs',
    'ClusterNodePoolNodeConfigSoleTenantConfigArgsDict',
    'ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs',
    'ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgsDict',
    'ClusterNodePoolNodeConfigTaintArgs',
    'ClusterNodePoolNodeConfigTaintArgsDict',
    'ClusterNodePoolNodeConfigWindowsNodeConfigArgs',
    'ClusterNodePoolNodeConfigWindowsNodeConfigArgsDict',
    'ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs',
    'ClusterNodePoolNodeConfigWorkloadMetadataConfigArgsDict',
    'ClusterNodePoolPlacementPolicyArgs',
    'ClusterNodePoolPlacementPolicyArgsDict',
    'ClusterNodePoolQueuedProvisioningArgs',
    'ClusterNodePoolQueuedProvisioningArgsDict',
    'ClusterNodePoolUpgradeSettingsArgs',
    'ClusterNodePoolUpgradeSettingsArgsDict',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgsDict',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgsDict',
    'ClusterNotificationConfigArgs',
    'ClusterNotificationConfigArgsDict',
    'ClusterNotificationConfigPubsubArgs',
    'ClusterNotificationConfigPubsubArgsDict',
    'ClusterNotificationConfigPubsubFilterArgs',
    'ClusterNotificationConfigPubsubFilterArgsDict',
    'ClusterPodAutoscalingArgs',
    'ClusterPodAutoscalingArgsDict',
    'ClusterPodSecurityPolicyConfigArgs',
    'ClusterPodSecurityPolicyConfigArgsDict',
    'ClusterPrivateClusterConfigArgs',
    'ClusterPrivateClusterConfigArgsDict',
    'ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs',
    'ClusterPrivateClusterConfigMasterGlobalAccessConfigArgsDict',
    'ClusterProtectConfigArgs',
    'ClusterProtectConfigArgsDict',
    'ClusterProtectConfigWorkloadConfigArgs',
    'ClusterProtectConfigWorkloadConfigArgsDict',
    'ClusterReleaseChannelArgs',
    'ClusterReleaseChannelArgsDict',
    'ClusterResourceUsageExportConfigArgs',
    'ClusterResourceUsageExportConfigArgsDict',
    'ClusterResourceUsageExportConfigBigqueryDestinationArgs',
    'ClusterResourceUsageExportConfigBigqueryDestinationArgsDict',
    'ClusterSecretManagerConfigArgs',
    'ClusterSecretManagerConfigArgsDict',
    'ClusterSecurityPostureConfigArgs',
    'ClusterSecurityPostureConfigArgsDict',
    'ClusterServiceExternalIpsConfigArgs',
    'ClusterServiceExternalIpsConfigArgsDict',
    'ClusterTpuConfigArgs',
    'ClusterTpuConfigArgsDict',
    'ClusterUserManagedKeysConfigArgs',
    'ClusterUserManagedKeysConfigArgsDict',
    'ClusterVerticalPodAutoscalingArgs',
    'ClusterVerticalPodAutoscalingArgsDict',
    'ClusterWorkloadAltsConfigArgs',
    'ClusterWorkloadAltsConfigArgsDict',
    'ClusterWorkloadIdentityConfigArgs',
    'ClusterWorkloadIdentityConfigArgsDict',
    'NodePoolAutoscalingArgs',
    'NodePoolAutoscalingArgsDict',
    'NodePoolManagementArgs',
    'NodePoolManagementArgsDict',
    'NodePoolNetworkConfigArgs',
    'NodePoolNetworkConfigArgsDict',
    'NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs',
    'NodePoolNetworkConfigAdditionalNodeNetworkConfigArgsDict',
    'NodePoolNetworkConfigAdditionalPodNetworkConfigArgs',
    'NodePoolNetworkConfigAdditionalPodNetworkConfigArgsDict',
    'NodePoolNetworkConfigNetworkPerformanceConfigArgs',
    'NodePoolNetworkConfigNetworkPerformanceConfigArgsDict',
    'NodePoolNetworkConfigPodCidrOverprovisionConfigArgs',
    'NodePoolNetworkConfigPodCidrOverprovisionConfigArgsDict',
    'NodePoolNodeConfigArgs',
    'NodePoolNodeConfigArgsDict',
    'NodePoolNodeConfigAdvancedMachineFeaturesArgs',
    'NodePoolNodeConfigAdvancedMachineFeaturesArgsDict',
    'NodePoolNodeConfigConfidentialNodesArgs',
    'NodePoolNodeConfigConfidentialNodesArgsDict',
    'NodePoolNodeConfigContainerdConfigArgs',
    'NodePoolNodeConfigContainerdConfigArgsDict',
    'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs',
    'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgsDict',
    'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs',
    'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict',
    'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs',
    'NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict',
    'NodePoolNodeConfigEffectiveTaintArgs',
    'NodePoolNodeConfigEffectiveTaintArgsDict',
    'NodePoolNodeConfigEphemeralStorageConfigArgs',
    'NodePoolNodeConfigEphemeralStorageConfigArgsDict',
    'NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs',
    'NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgsDict',
    'NodePoolNodeConfigFastSocketArgs',
    'NodePoolNodeConfigFastSocketArgsDict',
    'NodePoolNodeConfigGcfsConfigArgs',
    'NodePoolNodeConfigGcfsConfigArgsDict',
    'NodePoolNodeConfigGuestAcceleratorArgs',
    'NodePoolNodeConfigGuestAcceleratorArgsDict',
    'NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs',
    'NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgsDict',
    'NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs',
    'NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgsDict',
    'NodePoolNodeConfigGvnicArgs',
    'NodePoolNodeConfigGvnicArgsDict',
    'NodePoolNodeConfigHostMaintenancePolicyArgs',
    'NodePoolNodeConfigHostMaintenancePolicyArgsDict',
    'NodePoolNodeConfigKubeletConfigArgs',
    'NodePoolNodeConfigKubeletConfigArgsDict',
    'NodePoolNodeConfigLinuxNodeConfigArgs',
    'NodePoolNodeConfigLinuxNodeConfigArgsDict',
    'NodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs',
    'NodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgsDict',
    'NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs',
    'NodePoolNodeConfigLocalNvmeSsdBlockConfigArgsDict',
    'NodePoolNodeConfigReservationAffinityArgs',
    'NodePoolNodeConfigReservationAffinityArgsDict',
    'NodePoolNodeConfigSandboxConfigArgs',
    'NodePoolNodeConfigSandboxConfigArgsDict',
    'NodePoolNodeConfigSecondaryBootDiskArgs',
    'NodePoolNodeConfigSecondaryBootDiskArgsDict',
    'NodePoolNodeConfigShieldedInstanceConfigArgs',
    'NodePoolNodeConfigShieldedInstanceConfigArgsDict',
    'NodePoolNodeConfigSoleTenantConfigArgs',
    'NodePoolNodeConfigSoleTenantConfigArgsDict',
    'NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs',
    'NodePoolNodeConfigSoleTenantConfigNodeAffinityArgsDict',
    'NodePoolNodeConfigTaintArgs',
    'NodePoolNodeConfigTaintArgsDict',
    'NodePoolNodeConfigWindowsNodeConfigArgs',
    'NodePoolNodeConfigWindowsNodeConfigArgsDict',
    'NodePoolNodeConfigWorkloadMetadataConfigArgs',
    'NodePoolNodeConfigWorkloadMetadataConfigArgsDict',
    'NodePoolPlacementPolicyArgs',
    'NodePoolPlacementPolicyArgsDict',
    'NodePoolQueuedProvisioningArgs',
    'NodePoolQueuedProvisioningArgsDict',
    'NodePoolUpgradeSettingsArgs',
    'NodePoolUpgradeSettingsArgsDict',
    'NodePoolUpgradeSettingsBlueGreenSettingsArgs',
    'NodePoolUpgradeSettingsBlueGreenSettingsArgsDict',
    'NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs',
    'NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgsDict',
]

MYPY = False

if not MYPY:
    class AttachedClusterAuthorizationArgsDict(TypedDict):
        admin_groups: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        Groups that can perform operations as a cluster admin. A managed
        ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
        to the groups. Up to ten admin groups can be provided.
        For more info on RBAC, see
        https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        admin_users: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        Users that can perform operations as a cluster admin. A managed
        ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
        to the users. Up to ten admin users can be provided.
        For more info on RBAC, see
        https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
elif False:
    AttachedClusterAuthorizationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterAuthorizationArgs:
    def __init__(__self__, *,
                 admin_groups: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 admin_users: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] admin_groups: Groups that can perform operations as a cluster admin. A managed
               ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
               to the groups. Up to ten admin groups can be provided.
               For more info on RBAC, see
               https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] admin_users: Users that can perform operations as a cluster admin. A managed
               ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
               to the users. Up to ten admin users can be provided.
               For more info on RBAC, see
               https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        if admin_groups is not None:
            pulumi.set(__self__, "admin_groups", admin_groups)
        if admin_users is not None:
            pulumi.set(__self__, "admin_users", admin_users)

    @property
    @pulumi.getter(name="adminGroups")
    def admin_groups(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        Groups that can perform operations as a cluster admin. A managed
        ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
        to the groups. Up to ten admin groups can be provided.
        For more info on RBAC, see
        https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_groups")

    @admin_groups.setter
    def admin_groups(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "admin_groups", value)

    @property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        Users that can perform operations as a cluster admin. A managed
        ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
        to the users. Up to ten admin users can be provided.
        For more info on RBAC, see
        https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")

    @admin_users.setter
    def admin_users(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "admin_users", value)


if not MYPY:
    class AttachedClusterBinaryAuthorizationArgsDict(TypedDict):
        evaluation_mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Configure Binary Authorization evaluation mode.
        Possible values are: `DISABLED`, `PROJECT_SINGLETON_POLICY_ENFORCE`.
        """
elif False:
    AttachedClusterBinaryAuthorizationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterBinaryAuthorizationArgs:
    def __init__(__self__, *,
                 evaluation_mode: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] evaluation_mode: Configure Binary Authorization evaluation mode.
               Possible values are: `DISABLED`, `PROJECT_SINGLETON_POLICY_ENFORCE`.
        """
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Configure Binary Authorization evaluation mode.
        Possible values are: `DISABLED`, `PROJECT_SINGLETON_POLICY_ENFORCE`.
        """
        return pulumi.get(self, "evaluation_mode")

    @evaluation_mode.setter
    def evaluation_mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "evaluation_mode", value)


if not MYPY:
    class AttachedClusterErrorArgsDict(TypedDict):
        message: NotRequired[pulumi.Input[builtins.str]]
        """
        Human-friendly description of the error.
        """
elif False:
    AttachedClusterErrorArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterErrorArgs:
    def __init__(__self__, *,
                 message: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] message: Human-friendly description of the error.
        """
        if message is not None:
            pulumi.set(__self__, "message", message)

    @property
    @pulumi.getter
    def message(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Human-friendly description of the error.
        """
        return pulumi.get(self, "message")

    @message.setter
    def message(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "message", value)


if not MYPY:
    class AttachedClusterFleetArgsDict(TypedDict):
        project: pulumi.Input[builtins.str]
        """
        The ID of the project in which the resource belongs.
        If it is not provided, the provider project is used.
        """
        membership: NotRequired[pulumi.Input[builtins.str]]
        """
        (Output)
        The name of the managed Hub Membership resource associated to this
        cluster. Membership names are formatted as
        projects/<project-number>/locations/global/membership/<cluster-id>.
        """
elif False:
    AttachedClusterFleetArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterFleetArgs:
    def __init__(__self__, *,
                 project: pulumi.Input[builtins.str],
                 membership: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] project: The ID of the project in which the resource belongs.
               If it is not provided, the provider project is used.
        :param pulumi.Input[builtins.str] membership: (Output)
               The name of the managed Hub Membership resource associated to this
               cluster. Membership names are formatted as
               projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        pulumi.set(__self__, "project", project)
        if membership is not None:
            pulumi.set(__self__, "membership", membership)

    @property
    @pulumi.getter
    def project(self) -> pulumi.Input[builtins.str]:
        """
        The ID of the project in which the resource belongs.
        If it is not provided, the provider project is used.
        """
        return pulumi.get(self, "project")

    @project.setter
    def project(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "project", value)

    @property
    @pulumi.getter
    def membership(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        (Output)
        The name of the managed Hub Membership resource associated to this
        cluster. Membership names are formatted as
        projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")

    @membership.setter
    def membership(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "membership", value)


if not MYPY:
    class AttachedClusterLoggingConfigArgsDict(TypedDict):
        component_config: NotRequired[pulumi.Input['AttachedClusterLoggingConfigComponentConfigArgsDict']]
        """
        The configuration of the logging components
        Structure is documented below.
        """
elif False:
    AttachedClusterLoggingConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterLoggingConfigArgs:
    def __init__(__self__, *,
                 component_config: Optional[pulumi.Input['AttachedClusterLoggingConfigComponentConfigArgs']] = None):
        """
        :param pulumi.Input['AttachedClusterLoggingConfigComponentConfigArgs'] component_config: The configuration of the logging components
               Structure is documented below.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional[pulumi.Input['AttachedClusterLoggingConfigComponentConfigArgs']]:
        """
        The configuration of the logging components
        Structure is documented below.
        """
        return pulumi.get(self, "component_config")

    @component_config.setter
    def component_config(self, value: Optional[pulumi.Input['AttachedClusterLoggingConfigComponentConfigArgs']]):
        pulumi.set(self, "component_config", value)


if not MYPY:
    class AttachedClusterLoggingConfigComponentConfigArgsDict(TypedDict):
        enable_components: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The components to be enabled.
        Each value may be one of: `SYSTEM_COMPONENTS`, `WORKLOADS`.
        """
elif False:
    AttachedClusterLoggingConfigComponentConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterLoggingConfigComponentConfigArgs:
    def __init__(__self__, *,
                 enable_components: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] enable_components: The components to be enabled.
               Each value may be one of: `SYSTEM_COMPONENTS`, `WORKLOADS`.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The components to be enabled.
        Each value may be one of: `SYSTEM_COMPONENTS`, `WORKLOADS`.
        """
        return pulumi.get(self, "enable_components")

    @enable_components.setter
    def enable_components(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "enable_components", value)


if not MYPY:
    class AttachedClusterMonitoringConfigArgsDict(TypedDict):
        managed_prometheus_config: NotRequired[pulumi.Input['AttachedClusterMonitoringConfigManagedPrometheusConfigArgsDict']]
        """
        Enable Google Cloud Managed Service for Prometheus in the cluster.
        Structure is documented below.
        """
elif False:
    AttachedClusterMonitoringConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterMonitoringConfigArgs:
    def __init__(__self__, *,
                 managed_prometheus_config: Optional[pulumi.Input['AttachedClusterMonitoringConfigManagedPrometheusConfigArgs']] = None):
        """
        :param pulumi.Input['AttachedClusterMonitoringConfigManagedPrometheusConfigArgs'] managed_prometheus_config: Enable Google Cloud Managed Service for Prometheus in the cluster.
               Structure is documented below.
        """
        if managed_prometheus_config is not None:
            pulumi.set(__self__, "managed_prometheus_config", managed_prometheus_config)

    @property
    @pulumi.getter(name="managedPrometheusConfig")
    def managed_prometheus_config(self) -> Optional[pulumi.Input['AttachedClusterMonitoringConfigManagedPrometheusConfigArgs']]:
        """
        Enable Google Cloud Managed Service for Prometheus in the cluster.
        Structure is documented below.
        """
        return pulumi.get(self, "managed_prometheus_config")

    @managed_prometheus_config.setter
    def managed_prometheus_config(self, value: Optional[pulumi.Input['AttachedClusterMonitoringConfigManagedPrometheusConfigArgs']]):
        pulumi.set(self, "managed_prometheus_config", value)


if not MYPY:
    class AttachedClusterMonitoringConfigManagedPrometheusConfigArgsDict(TypedDict):
        enabled: NotRequired[pulumi.Input[builtins.bool]]
        """
        Enable Managed Collection.
        """
elif False:
    AttachedClusterMonitoringConfigManagedPrometheusConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterMonitoringConfigManagedPrometheusConfigArgs:
    def __init__(__self__, *,
                 enabled: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.bool] enabled: Enable Managed Collection.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Enable Managed Collection.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class AttachedClusterOidcConfigArgsDict(TypedDict):
        issuer_url: pulumi.Input[builtins.str]
        """
        A JSON Web Token (JWT) issuer URI. `issuer` must start with `https://`
        """
        jwks: NotRequired[pulumi.Input[builtins.str]]
        """
        OIDC verification keys in JWKS format (RFC 7517).
        """
elif False:
    AttachedClusterOidcConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterOidcConfigArgs:
    def __init__(__self__, *,
                 issuer_url: pulumi.Input[builtins.str],
                 jwks: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] issuer_url: A JSON Web Token (JWT) issuer URI. `issuer` must start with `https://`
        :param pulumi.Input[builtins.str] jwks: OIDC verification keys in JWKS format (RFC 7517).
        """
        pulumi.set(__self__, "issuer_url", issuer_url)
        if jwks is not None:
            pulumi.set(__self__, "jwks", jwks)

    @property
    @pulumi.getter(name="issuerUrl")
    def issuer_url(self) -> pulumi.Input[builtins.str]:
        """
        A JSON Web Token (JWT) issuer URI. `issuer` must start with `https://`
        """
        return pulumi.get(self, "issuer_url")

    @issuer_url.setter
    def issuer_url(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "issuer_url", value)

    @property
    @pulumi.getter
    def jwks(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        OIDC verification keys in JWKS format (RFC 7517).
        """
        return pulumi.get(self, "jwks")

    @jwks.setter
    def jwks(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "jwks", value)


if not MYPY:
    class AttachedClusterProxyConfigArgsDict(TypedDict):
        kubernetes_secret: NotRequired[pulumi.Input['AttachedClusterProxyConfigKubernetesSecretArgsDict']]
        """
        The Kubernetes Secret resource that contains the HTTP(S) proxy configuration.
        Structure is documented below.
        """
elif False:
    AttachedClusterProxyConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterProxyConfigArgs:
    def __init__(__self__, *,
                 kubernetes_secret: Optional[pulumi.Input['AttachedClusterProxyConfigKubernetesSecretArgs']] = None):
        """
        :param pulumi.Input['AttachedClusterProxyConfigKubernetesSecretArgs'] kubernetes_secret: The Kubernetes Secret resource that contains the HTTP(S) proxy configuration.
               Structure is documented below.
        """
        if kubernetes_secret is not None:
            pulumi.set(__self__, "kubernetes_secret", kubernetes_secret)

    @property
    @pulumi.getter(name="kubernetesSecret")
    def kubernetes_secret(self) -> Optional[pulumi.Input['AttachedClusterProxyConfigKubernetesSecretArgs']]:
        """
        The Kubernetes Secret resource that contains the HTTP(S) proxy configuration.
        Structure is documented below.
        """
        return pulumi.get(self, "kubernetes_secret")

    @kubernetes_secret.setter
    def kubernetes_secret(self, value: Optional[pulumi.Input['AttachedClusterProxyConfigKubernetesSecretArgs']]):
        pulumi.set(self, "kubernetes_secret", value)


if not MYPY:
    class AttachedClusterProxyConfigKubernetesSecretArgsDict(TypedDict):
        name: pulumi.Input[builtins.str]
        """
        Name of the kubernetes secret containing the proxy config.
        """
        namespace: pulumi.Input[builtins.str]
        """
        Namespace of the kubernetes secret containing the proxy config.
        """
elif False:
    AttachedClusterProxyConfigKubernetesSecretArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterProxyConfigKubernetesSecretArgs:
    def __init__(__self__, *,
                 name: pulumi.Input[builtins.str],
                 namespace: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] name: Name of the kubernetes secret containing the proxy config.
        :param pulumi.Input[builtins.str] namespace: Namespace of the kubernetes secret containing the proxy config.
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "namespace", namespace)

    @property
    @pulumi.getter
    def name(self) -> pulumi.Input[builtins.str]:
        """
        Name of the kubernetes secret containing the proxy config.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter
    def namespace(self) -> pulumi.Input[builtins.str]:
        """
        Namespace of the kubernetes secret containing the proxy config.
        """
        return pulumi.get(self, "namespace")

    @namespace.setter
    def namespace(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "namespace", value)


if not MYPY:
    class AttachedClusterSecurityPostureConfigArgsDict(TypedDict):
        vulnerability_mode: pulumi.Input[builtins.str]
        """
        Sets the mode of the Kubernetes security posture API's workload vulnerability scanning.
        Possible values are: `VULNERABILITY_DISABLED`, `VULNERABILITY_ENTERPRISE`.
        """
elif False:
    AttachedClusterSecurityPostureConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterSecurityPostureConfigArgs:
    def __init__(__self__, *,
                 vulnerability_mode: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] vulnerability_mode: Sets the mode of the Kubernetes security posture API's workload vulnerability scanning.
               Possible values are: `VULNERABILITY_DISABLED`, `VULNERABILITY_ENTERPRISE`.
        """
        pulumi.set(__self__, "vulnerability_mode", vulnerability_mode)

    @property
    @pulumi.getter(name="vulnerabilityMode")
    def vulnerability_mode(self) -> pulumi.Input[builtins.str]:
        """
        Sets the mode of the Kubernetes security posture API's workload vulnerability scanning.
        Possible values are: `VULNERABILITY_DISABLED`, `VULNERABILITY_ENTERPRISE`.
        """
        return pulumi.get(self, "vulnerability_mode")

    @vulnerability_mode.setter
    def vulnerability_mode(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "vulnerability_mode", value)


if not MYPY:
    class AttachedClusterWorkloadIdentityConfigArgsDict(TypedDict):
        identity_provider: NotRequired[pulumi.Input[builtins.str]]
        """
        The ID of the OIDC Identity Provider (IdP) associated to
        the Workload Identity Pool.
        """
        issuer_uri: NotRequired[pulumi.Input[builtins.str]]
        """
        The OIDC issuer URL for this cluster.
        """
        workload_pool: NotRequired[pulumi.Input[builtins.str]]
        """
        The Workload Identity Pool associated to the cluster.
        """
elif False:
    AttachedClusterWorkloadIdentityConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AttachedClusterWorkloadIdentityConfigArgs:
    def __init__(__self__, *,
                 identity_provider: Optional[pulumi.Input[builtins.str]] = None,
                 issuer_uri: Optional[pulumi.Input[builtins.str]] = None,
                 workload_pool: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] identity_provider: The ID of the OIDC Identity Provider (IdP) associated to
               the Workload Identity Pool.
        :param pulumi.Input[builtins.str] issuer_uri: The OIDC issuer URL for this cluster.
        :param pulumi.Input[builtins.str] workload_pool: The Workload Identity Pool associated to the cluster.
        """
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The ID of the OIDC Identity Provider (IdP) associated to
        the Workload Identity Pool.
        """
        return pulumi.get(self, "identity_provider")

    @identity_provider.setter
    def identity_provider(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "identity_provider", value)

    @property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The OIDC issuer URL for this cluster.
        """
        return pulumi.get(self, "issuer_uri")

    @issuer_uri.setter
    def issuer_uri(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "issuer_uri", value)

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Workload Identity Pool associated to the cluster.
        """
        return pulumi.get(self, "workload_pool")

    @workload_pool.setter
    def workload_pool(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "workload_pool", value)


if not MYPY:
    class AwsClusterAuthorizationArgsDict(TypedDict):
        admin_users: pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminUserArgsDict']]]
        """
        Users to perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        admin_groups: NotRequired[pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminGroupArgsDict']]]]
        """
        Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
elif False:
    AwsClusterAuthorizationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterAuthorizationArgs:
    def __init__(__self__, *,
                 admin_users: pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminUserArgs']]],
                 admin_groups: Optional[pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminGroupArgs']]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminUserArgs']]] admin_users: Users to perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        :param pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminGroupArgs']]] admin_groups: Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        pulumi.set(__self__, "admin_users", admin_users)
        if admin_groups is not None:
            pulumi.set(__self__, "admin_groups", admin_groups)

    @property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminUserArgs']]]:
        """
        Users to perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")

    @admin_users.setter
    def admin_users(self, value: pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminUserArgs']]]):
        pulumi.set(self, "admin_users", value)

    @property
    @pulumi.getter(name="adminGroups")
    def admin_groups(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminGroupArgs']]]]:
        """
        Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_groups")

    @admin_groups.setter
    def admin_groups(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminGroupArgs']]]]):
        pulumi.set(self, "admin_groups", value)


if not MYPY:
    class AwsClusterAuthorizationAdminGroupArgsDict(TypedDict):
        group: pulumi.Input[builtins.str]
        """
        The name of the group, e.g. `my-group@domain.com`.
        """
elif False:
    AwsClusterAuthorizationAdminGroupArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterAuthorizationAdminGroupArgs:
    def __init__(__self__, *,
                 group: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] group: The name of the group, e.g. `my-group@domain.com`.
        """
        pulumi.set(__self__, "group", group)

    @property
    @pulumi.getter
    def group(self) -> pulumi.Input[builtins.str]:
        """
        The name of the group, e.g. `my-group@domain.com`.
        """
        return pulumi.get(self, "group")

    @group.setter
    def group(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "group", value)


if not MYPY:
    class AwsClusterAuthorizationAdminUserArgsDict(TypedDict):
        username: pulumi.Input[builtins.str]
        """
        The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
elif False:
    AwsClusterAuthorizationAdminUserArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterAuthorizationAdminUserArgs:
    def __init__(__self__, *,
                 username: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] username: The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def username(self) -> pulumi.Input[builtins.str]:
        """
        The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        return pulumi.get(self, "username")

    @username.setter
    def username(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "username", value)


if not MYPY:
    class AwsClusterBinaryAuthorizationArgsDict(TypedDict):
        evaluation_mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Mode of operation for Binary Authorization policy evaluation. Possible values: DISABLED, PROJECT_SINGLETON_POLICY_ENFORCE
        """
elif False:
    AwsClusterBinaryAuthorizationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterBinaryAuthorizationArgs:
    def __init__(__self__, *,
                 evaluation_mode: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] evaluation_mode: Mode of operation for Binary Authorization policy evaluation. Possible values: DISABLED, PROJECT_SINGLETON_POLICY_ENFORCE
        """
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Mode of operation for Binary Authorization policy evaluation. Possible values: DISABLED, PROJECT_SINGLETON_POLICY_ENFORCE
        """
        return pulumi.get(self, "evaluation_mode")

    @evaluation_mode.setter
    def evaluation_mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "evaluation_mode", value)


if not MYPY:
    class AwsClusterControlPlaneArgsDict(TypedDict):
        aws_services_authentication: pulumi.Input['AwsClusterControlPlaneAwsServicesAuthenticationArgsDict']
        """
        Authentication configuration for management of AWS resources.
        """
        config_encryption: pulumi.Input['AwsClusterControlPlaneConfigEncryptionArgsDict']
        """
        The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        database_encryption: pulumi.Input['AwsClusterControlPlaneDatabaseEncryptionArgsDict']
        """
        The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        iam_instance_profile: pulumi.Input[builtins.str]
        """
        The name of the AWS IAM instance pofile to assign to each control plane replica.
        """
        subnet_ids: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        The list of subnets where control plane replicas will run. A replica will be provisioned on each subnet and up to three values can be provided. Each subnet must be in a different AWS Availability Zone (AZ).
        """
        version: pulumi.Input[builtins.str]
        """
        The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling .
        """
        instance_placement: NotRequired[pulumi.Input['AwsClusterControlPlaneInstancePlacementArgsDict']]
        """
        Details of placement information for an instance.
        """
        instance_type: NotRequired[pulumi.Input[builtins.str]]
        """
        Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        """
        main_volume: NotRequired[pulumi.Input['AwsClusterControlPlaneMainVolumeArgsDict']]
        """
        Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 8 GiB with the GP2 volume type.
        """
        proxy_config: NotRequired[pulumi.Input['AwsClusterControlPlaneProxyConfigArgsDict']]
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        root_volume: NotRequired[pulumi.Input['AwsClusterControlPlaneRootVolumeArgsDict']]
        """
        Optional. Configuration related to the root volume provisioned for each control plane replica. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        """
        security_group_ids: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        Optional. The IDs of additional security groups to add to control plane replicas. The Anthos Multi-Cloud API will automatically create and manage security groups with the minimum rules needed for a functioning cluster.
        """
        ssh_config: NotRequired[pulumi.Input['AwsClusterControlPlaneSshConfigArgsDict']]
        """
        Optional. SSH configuration for how to access the underlying control plane machines.
        """
        tags: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        Optional. A set of AWS resource tags to propagate to all underlying managed AWS resources. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
elif False:
    AwsClusterControlPlaneArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterControlPlaneArgs:
    def __init__(__self__, *,
                 aws_services_authentication: pulumi.Input['AwsClusterControlPlaneAwsServicesAuthenticationArgs'],
                 config_encryption: pulumi.Input['AwsClusterControlPlaneConfigEncryptionArgs'],
                 database_encryption: pulumi.Input['AwsClusterControlPlaneDatabaseEncryptionArgs'],
                 iam_instance_profile: pulumi.Input[builtins.str],
                 subnet_ids: pulumi.Input[Sequence[pulumi.Input[builtins.str]]],
                 version: pulumi.Input[builtins.str],
                 instance_placement: Optional[pulumi.Input['AwsClusterControlPlaneInstancePlacementArgs']] = None,
                 instance_type: Optional[pulumi.Input[builtins.str]] = None,
                 main_volume: Optional[pulumi.Input['AwsClusterControlPlaneMainVolumeArgs']] = None,
                 proxy_config: Optional[pulumi.Input['AwsClusterControlPlaneProxyConfigArgs']] = None,
                 root_volume: Optional[pulumi.Input['AwsClusterControlPlaneRootVolumeArgs']] = None,
                 security_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 ssh_config: Optional[pulumi.Input['AwsClusterControlPlaneSshConfigArgs']] = None,
                 tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input['AwsClusterControlPlaneAwsServicesAuthenticationArgs'] aws_services_authentication: Authentication configuration for management of AWS resources.
        :param pulumi.Input['AwsClusterControlPlaneConfigEncryptionArgs'] config_encryption: The ARN of the AWS KMS key used to encrypt cluster configuration.
        :param pulumi.Input['AwsClusterControlPlaneDatabaseEncryptionArgs'] database_encryption: The ARN of the AWS KMS key used to encrypt cluster secrets.
        :param pulumi.Input[builtins.str] iam_instance_profile: The name of the AWS IAM instance pofile to assign to each control plane replica.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] subnet_ids: The list of subnets where control plane replicas will run. A replica will be provisioned on each subnet and up to three values can be provided. Each subnet must be in a different AWS Availability Zone (AZ).
        :param pulumi.Input[builtins.str] version: The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling .
        :param pulumi.Input['AwsClusterControlPlaneInstancePlacementArgs'] instance_placement: Details of placement information for an instance.
        :param pulumi.Input[builtins.str] instance_type: Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        :param pulumi.Input['AwsClusterControlPlaneMainVolumeArgs'] main_volume: Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 8 GiB with the GP2 volume type.
        :param pulumi.Input['AwsClusterControlPlaneProxyConfigArgs'] proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param pulumi.Input['AwsClusterControlPlaneRootVolumeArgs'] root_volume: Optional. Configuration related to the root volume provisioned for each control plane replica. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] security_group_ids: Optional. The IDs of additional security groups to add to control plane replicas. The Anthos Multi-Cloud API will automatically create and manage security groups with the minimum rules needed for a functioning cluster.
        :param pulumi.Input['AwsClusterControlPlaneSshConfigArgs'] ssh_config: Optional. SSH configuration for how to access the underlying control plane machines.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] tags: Optional. A set of AWS resource tags to propagate to all underlying managed AWS resources. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        pulumi.set(__self__, "aws_services_authentication", aws_services_authentication)
        pulumi.set(__self__, "config_encryption", config_encryption)
        pulumi.set(__self__, "database_encryption", database_encryption)
        pulumi.set(__self__, "iam_instance_profile", iam_instance_profile)
        pulumi.set(__self__, "subnet_ids", subnet_ids)
        pulumi.set(__self__, "version", version)
        if instance_placement is not None:
            pulumi.set(__self__, "instance_placement", instance_placement)
        if instance_type is not None:
            pulumi.set(__self__, "instance_type", instance_type)
        if main_volume is not None:
            pulumi.set(__self__, "main_volume", main_volume)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if security_group_ids is not None:
            pulumi.set(__self__, "security_group_ids", security_group_ids)
        if ssh_config is not None:
            pulumi.set(__self__, "ssh_config", ssh_config)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @property
    @pulumi.getter(name="awsServicesAuthentication")
    def aws_services_authentication(self) -> pulumi.Input['AwsClusterControlPlaneAwsServicesAuthenticationArgs']:
        """
        Authentication configuration for management of AWS resources.
        """
        return pulumi.get(self, "aws_services_authentication")

    @aws_services_authentication.setter
    def aws_services_authentication(self, value: pulumi.Input['AwsClusterControlPlaneAwsServicesAuthenticationArgs']):
        pulumi.set(self, "aws_services_authentication", value)

    @property
    @pulumi.getter(name="configEncryption")
    def config_encryption(self) -> pulumi.Input['AwsClusterControlPlaneConfigEncryptionArgs']:
        """
        The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        return pulumi.get(self, "config_encryption")

    @config_encryption.setter
    def config_encryption(self, value: pulumi.Input['AwsClusterControlPlaneConfigEncryptionArgs']):
        pulumi.set(self, "config_encryption", value)

    @property
    @pulumi.getter(name="databaseEncryption")
    def database_encryption(self) -> pulumi.Input['AwsClusterControlPlaneDatabaseEncryptionArgs']:
        """
        The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        return pulumi.get(self, "database_encryption")

    @database_encryption.setter
    def database_encryption(self, value: pulumi.Input['AwsClusterControlPlaneDatabaseEncryptionArgs']):
        pulumi.set(self, "database_encryption", value)

    @property
    @pulumi.getter(name="iamInstanceProfile")
    def iam_instance_profile(self) -> pulumi.Input[builtins.str]:
        """
        The name of the AWS IAM instance pofile to assign to each control plane replica.
        """
        return pulumi.get(self, "iam_instance_profile")

    @iam_instance_profile.setter
    def iam_instance_profile(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "iam_instance_profile", value)

    @property
    @pulumi.getter(name="subnetIds")
    def subnet_ids(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        The list of subnets where control plane replicas will run. A replica will be provisioned on each subnet and up to three values can be provided. Each subnet must be in a different AWS Availability Zone (AZ).
        """
        return pulumi.get(self, "subnet_ids")

    @subnet_ids.setter
    def subnet_ids(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "subnet_ids", value)

    @property
    @pulumi.getter
    def version(self) -> pulumi.Input[builtins.str]:
        """
        The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling .
        """
        return pulumi.get(self, "version")

    @version.setter
    def version(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "version", value)

    @property
    @pulumi.getter(name="instancePlacement")
    def instance_placement(self) -> Optional[pulumi.Input['AwsClusterControlPlaneInstancePlacementArgs']]:
        """
        Details of placement information for an instance.
        """
        return pulumi.get(self, "instance_placement")

    @instance_placement.setter
    def instance_placement(self, value: Optional[pulumi.Input['AwsClusterControlPlaneInstancePlacementArgs']]):
        pulumi.set(self, "instance_placement", value)

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        """
        return pulumi.get(self, "instance_type")

    @instance_type.setter
    def instance_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "instance_type", value)

    @property
    @pulumi.getter(name="mainVolume")
    def main_volume(self) -> Optional[pulumi.Input['AwsClusterControlPlaneMainVolumeArgs']]:
        """
        Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 8 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "main_volume")

    @main_volume.setter
    def main_volume(self, value: Optional[pulumi.Input['AwsClusterControlPlaneMainVolumeArgs']]):
        pulumi.set(self, "main_volume", value)

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional[pulumi.Input['AwsClusterControlPlaneProxyConfigArgs']]:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @proxy_config.setter
    def proxy_config(self, value: Optional[pulumi.Input['AwsClusterControlPlaneProxyConfigArgs']]):
        pulumi.set(self, "proxy_config", value)

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional[pulumi.Input['AwsClusterControlPlaneRootVolumeArgs']]:
        """
        Optional. Configuration related to the root volume provisioned for each control plane replica. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "root_volume")

    @root_volume.setter
    def root_volume(self, value: Optional[pulumi.Input['AwsClusterControlPlaneRootVolumeArgs']]):
        pulumi.set(self, "root_volume", value)

    @property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        Optional. The IDs of additional security groups to add to control plane replicas. The Anthos Multi-Cloud API will automatically create and manage security groups with the minimum rules needed for a functioning cluster.
        """
        return pulumi.get(self, "security_group_ids")

    @security_group_ids.setter
    def security_group_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "security_group_ids", value)

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> Optional[pulumi.Input['AwsClusterControlPlaneSshConfigArgs']]:
        """
        Optional. SSH configuration for how to access the underlying control plane machines.
        """
        return pulumi.get(self, "ssh_config")

    @ssh_config.setter
    def ssh_config(self, value: Optional[pulumi.Input['AwsClusterControlPlaneSshConfigArgs']]):
        pulumi.set(self, "ssh_config", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        Optional. A set of AWS resource tags to propagate to all underlying managed AWS resources. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "tags", value)


if not MYPY:
    class AwsClusterControlPlaneAwsServicesAuthenticationArgsDict(TypedDict):
        role_arn: pulumi.Input[builtins.str]
        """
        The Amazon Resource Name (ARN) of the role that the Anthos Multi-Cloud API will assume when managing AWS resources on your account.
        """
        role_session_name: NotRequired[pulumi.Input[builtins.str]]
        """
        Optional. An identifier for the assumed role session. When unspecified, it defaults to `multicloud-service-agent`.
        """
elif False:
    AwsClusterControlPlaneAwsServicesAuthenticationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterControlPlaneAwsServicesAuthenticationArgs:
    def __init__(__self__, *,
                 role_arn: pulumi.Input[builtins.str],
                 role_session_name: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] role_arn: The Amazon Resource Name (ARN) of the role that the Anthos Multi-Cloud API will assume when managing AWS resources on your account.
        :param pulumi.Input[builtins.str] role_session_name: Optional. An identifier for the assumed role session. When unspecified, it defaults to `multicloud-service-agent`.
        """
        pulumi.set(__self__, "role_arn", role_arn)
        if role_session_name is not None:
            pulumi.set(__self__, "role_session_name", role_session_name)

    @property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> pulumi.Input[builtins.str]:
        """
        The Amazon Resource Name (ARN) of the role that the Anthos Multi-Cloud API will assume when managing AWS resources on your account.
        """
        return pulumi.get(self, "role_arn")

    @role_arn.setter
    def role_arn(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "role_arn", value)

    @property
    @pulumi.getter(name="roleSessionName")
    def role_session_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Optional. An identifier for the assumed role session. When unspecified, it defaults to `multicloud-service-agent`.
        """
        return pulumi.get(self, "role_session_name")

    @role_session_name.setter
    def role_session_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "role_session_name", value)


if not MYPY:
    class AwsClusterControlPlaneConfigEncryptionArgsDict(TypedDict):
        kms_key_arn: pulumi.Input[builtins.str]
        """
        The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
elif False:
    AwsClusterControlPlaneConfigEncryptionArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterControlPlaneConfigEncryptionArgs:
    def __init__(__self__, *,
                 kms_key_arn: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] kms_key_arn: The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> pulumi.Input[builtins.str]:
        """
        The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        return pulumi.get(self, "kms_key_arn")

    @kms_key_arn.setter
    def kms_key_arn(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "kms_key_arn", value)


if not MYPY:
    class AwsClusterControlPlaneDatabaseEncryptionArgsDict(TypedDict):
        kms_key_arn: pulumi.Input[builtins.str]
        """
        The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
elif False:
    AwsClusterControlPlaneDatabaseEncryptionArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterControlPlaneDatabaseEncryptionArgs:
    def __init__(__self__, *,
                 kms_key_arn: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] kms_key_arn: The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> pulumi.Input[builtins.str]:
        """
        The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        return pulumi.get(self, "kms_key_arn")

    @kms_key_arn.setter
    def kms_key_arn(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "kms_key_arn", value)


if not MYPY:
    class AwsClusterControlPlaneInstancePlacementArgsDict(TypedDict):
        tenancy: NotRequired[pulumi.Input[builtins.str]]
        """
        The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
elif False:
    AwsClusterControlPlaneInstancePlacementArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterControlPlaneInstancePlacementArgs:
    def __init__(__self__, *,
                 tenancy: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] tenancy: The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        if tenancy is not None:
            pulumi.set(__self__, "tenancy", tenancy)

    @property
    @pulumi.getter
    def tenancy(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        return pulumi.get(self, "tenancy")

    @tenancy.setter
    def tenancy(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "tenancy", value)


if not MYPY:
    class AwsClusterControlPlaneMainVolumeArgsDict(TypedDict):
        iops: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        kms_key_arn: NotRequired[pulumi.Input[builtins.str]]
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        size_gib: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        throughput: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        """
        volume_type: NotRequired[pulumi.Input[builtins.str]]
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
elif False:
    AwsClusterControlPlaneMainVolumeArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterControlPlaneMainVolumeArgs:
    def __init__(__self__, *,
                 iops: Optional[pulumi.Input[builtins.int]] = None,
                 kms_key_arn: Optional[pulumi.Input[builtins.str]] = None,
                 size_gib: Optional[pulumi.Input[builtins.int]] = None,
                 throughput: Optional[pulumi.Input[builtins.int]] = None,
                 volume_type: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.int] iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param pulumi.Input[builtins.str] kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param pulumi.Input[builtins.int] size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param pulumi.Input[builtins.int] throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        :param pulumi.Input[builtins.str] volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter
    def iops(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @iops.setter
    def iops(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "iops", value)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @kms_key_arn.setter
    def kms_key_arn(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "kms_key_arn", value)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @size_gib.setter
    def size_gib(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "size_gib", value)

    @property
    @pulumi.getter
    def throughput(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        """
        return pulumi.get(self, "throughput")

    @throughput.setter
    def throughput(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "throughput", value)

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")

    @volume_type.setter
    def volume_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "volume_type", value)


if not MYPY:
    class AwsClusterControlPlaneProxyConfigArgsDict(TypedDict):
        secret_arn: pulumi.Input[builtins.str]
        """
        The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        secret_version: pulumi.Input[builtins.str]
        """
        The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
elif False:
    AwsClusterControlPlaneProxyConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterControlPlaneProxyConfigArgs:
    def __init__(__self__, *,
                 secret_arn: pulumi.Input[builtins.str],
                 secret_version: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] secret_arn: The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        :param pulumi.Input[builtins.str] secret_version: The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        pulumi.set(__self__, "secret_arn", secret_arn)
        pulumi.set(__self__, "secret_version", secret_version)

    @property
    @pulumi.getter(name="secretArn")
    def secret_arn(self) -> pulumi.Input[builtins.str]:
        """
        The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_arn")

    @secret_arn.setter
    def secret_arn(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "secret_arn", value)

    @property
    @pulumi.getter(name="secretVersion")
    def secret_version(self) -> pulumi.Input[builtins.str]:
        """
        The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_version")

    @secret_version.setter
    def secret_version(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "secret_version", value)


if not MYPY:
    class AwsClusterControlPlaneRootVolumeArgsDict(TypedDict):
        iops: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        kms_key_arn: NotRequired[pulumi.Input[builtins.str]]
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        size_gib: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        throughput: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        """
        volume_type: NotRequired[pulumi.Input[builtins.str]]
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
elif False:
    AwsClusterControlPlaneRootVolumeArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterControlPlaneRootVolumeArgs:
    def __init__(__self__, *,
                 iops: Optional[pulumi.Input[builtins.int]] = None,
                 kms_key_arn: Optional[pulumi.Input[builtins.str]] = None,
                 size_gib: Optional[pulumi.Input[builtins.int]] = None,
                 throughput: Optional[pulumi.Input[builtins.int]] = None,
                 volume_type: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.int] iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param pulumi.Input[builtins.str] kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param pulumi.Input[builtins.int] size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param pulumi.Input[builtins.int] throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        :param pulumi.Input[builtins.str] volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter
    def iops(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @iops.setter
    def iops(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "iops", value)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @kms_key_arn.setter
    def kms_key_arn(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "kms_key_arn", value)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @size_gib.setter
    def size_gib(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "size_gib", value)

    @property
    @pulumi.getter
    def throughput(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        """
        return pulumi.get(self, "throughput")

    @throughput.setter
    def throughput(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "throughput", value)

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")

    @volume_type.setter
    def volume_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "volume_type", value)


if not MYPY:
    class AwsClusterControlPlaneSshConfigArgsDict(TypedDict):
        ec2_key_pair: pulumi.Input[builtins.str]
        """
        The name of the EC2 key pair used to login into cluster machines.
        """
elif False:
    AwsClusterControlPlaneSshConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterControlPlaneSshConfigArgs:
    def __init__(__self__, *,
                 ec2_key_pair: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] ec2_key_pair: The name of the EC2 key pair used to login into cluster machines.
        """
        pulumi.set(__self__, "ec2_key_pair", ec2_key_pair)

    @property
    @pulumi.getter(name="ec2KeyPair")
    def ec2_key_pair(self) -> pulumi.Input[builtins.str]:
        """
        The name of the EC2 key pair used to login into cluster machines.
        """
        return pulumi.get(self, "ec2_key_pair")

    @ec2_key_pair.setter
    def ec2_key_pair(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "ec2_key_pair", value)


if not MYPY:
    class AwsClusterFleetArgsDict(TypedDict):
        membership: NotRequired[pulumi.Input[builtins.str]]
        """
        The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        project: NotRequired[pulumi.Input[builtins.str]]
        """
        The number of the Fleet host project where this cluster will be registered.
        """
elif False:
    AwsClusterFleetArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterFleetArgs:
    def __init__(__self__, *,
                 membership: Optional[pulumi.Input[builtins.str]] = None,
                 project: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] membership: The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        :param pulumi.Input[builtins.str] project: The number of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @property
    @pulumi.getter
    def membership(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")

    @membership.setter
    def membership(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "membership", value)

    @property
    @pulumi.getter
    def project(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The number of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")

    @project.setter
    def project(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "project", value)


if not MYPY:
    class AwsClusterLoggingConfigArgsDict(TypedDict):
        component_config: NotRequired[pulumi.Input['AwsClusterLoggingConfigComponentConfigArgsDict']]
        """
        Configuration of the logging components.
        """
elif False:
    AwsClusterLoggingConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterLoggingConfigArgs:
    def __init__(__self__, *,
                 component_config: Optional[pulumi.Input['AwsClusterLoggingConfigComponentConfigArgs']] = None):
        """
        :param pulumi.Input['AwsClusterLoggingConfigComponentConfigArgs'] component_config: Configuration of the logging components.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional[pulumi.Input['AwsClusterLoggingConfigComponentConfigArgs']]:
        """
        Configuration of the logging components.
        """
        return pulumi.get(self, "component_config")

    @component_config.setter
    def component_config(self, value: Optional[pulumi.Input['AwsClusterLoggingConfigComponentConfigArgs']]):
        pulumi.set(self, "component_config", value)


if not MYPY:
    class AwsClusterLoggingConfigComponentConfigArgsDict(TypedDict):
        enable_components: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        Components of the logging configuration to be enabled.
        """
elif False:
    AwsClusterLoggingConfigComponentConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterLoggingConfigComponentConfigArgs:
    def __init__(__self__, *,
                 enable_components: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] enable_components: Components of the logging configuration to be enabled.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        Components of the logging configuration to be enabled.
        """
        return pulumi.get(self, "enable_components")

    @enable_components.setter
    def enable_components(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "enable_components", value)


if not MYPY:
    class AwsClusterNetworkingArgsDict(TypedDict):
        pod_address_cidr_blocks: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        All pods in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        service_address_cidr_blocks: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        All services in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        vpc_id: pulumi.Input[builtins.str]
        """
        The VPC associated with the cluster. All component clusters (i.e. control plane and node pools) run on a single VPC. This field cannot be changed after creation.

        - - -
        """
        per_node_pool_sg_rules_disabled: NotRequired[pulumi.Input[builtins.bool]]
        """
        Disable the per node pool subnet security group rules on the control plane security group. When set to true, you must also provide one or more security groups that ensure node pools are able to send requests to the control plane on TCP/443 and TCP/8132. Failure to do so may result in unavailable node pools.
        """
elif False:
    AwsClusterNetworkingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterNetworkingArgs:
    def __init__(__self__, *,
                 pod_address_cidr_blocks: pulumi.Input[Sequence[pulumi.Input[builtins.str]]],
                 service_address_cidr_blocks: pulumi.Input[Sequence[pulumi.Input[builtins.str]]],
                 vpc_id: pulumi.Input[builtins.str],
                 per_node_pool_sg_rules_disabled: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] pod_address_cidr_blocks: All pods in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] service_address_cidr_blocks: All services in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param pulumi.Input[builtins.str] vpc_id: The VPC associated with the cluster. All component clusters (i.e. control plane and node pools) run on a single VPC. This field cannot be changed after creation.
               
               - - -
        :param pulumi.Input[builtins.bool] per_node_pool_sg_rules_disabled: Disable the per node pool subnet security group rules on the control plane security group. When set to true, you must also provide one or more security groups that ensure node pools are able to send requests to the control plane on TCP/443 and TCP/8132. Failure to do so may result in unavailable node pools.
        """
        pulumi.set(__self__, "pod_address_cidr_blocks", pod_address_cidr_blocks)
        pulumi.set(__self__, "service_address_cidr_blocks", service_address_cidr_blocks)
        pulumi.set(__self__, "vpc_id", vpc_id)
        if per_node_pool_sg_rules_disabled is not None:
            pulumi.set(__self__, "per_node_pool_sg_rules_disabled", per_node_pool_sg_rules_disabled)

    @property
    @pulumi.getter(name="podAddressCidrBlocks")
    def pod_address_cidr_blocks(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        All pods in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "pod_address_cidr_blocks")

    @pod_address_cidr_blocks.setter
    def pod_address_cidr_blocks(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "pod_address_cidr_blocks", value)

    @property
    @pulumi.getter(name="serviceAddressCidrBlocks")
    def service_address_cidr_blocks(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        All services in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "service_address_cidr_blocks")

    @service_address_cidr_blocks.setter
    def service_address_cidr_blocks(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "service_address_cidr_blocks", value)

    @property
    @pulumi.getter(name="vpcId")
    def vpc_id(self) -> pulumi.Input[builtins.str]:
        """
        The VPC associated with the cluster. All component clusters (i.e. control plane and node pools) run on a single VPC. This field cannot be changed after creation.

        - - -
        """
        return pulumi.get(self, "vpc_id")

    @vpc_id.setter
    def vpc_id(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "vpc_id", value)

    @property
    @pulumi.getter(name="perNodePoolSgRulesDisabled")
    def per_node_pool_sg_rules_disabled(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Disable the per node pool subnet security group rules on the control plane security group. When set to true, you must also provide one or more security groups that ensure node pools are able to send requests to the control plane on TCP/443 and TCP/8132. Failure to do so may result in unavailable node pools.
        """
        return pulumi.get(self, "per_node_pool_sg_rules_disabled")

    @per_node_pool_sg_rules_disabled.setter
    def per_node_pool_sg_rules_disabled(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "per_node_pool_sg_rules_disabled", value)


if not MYPY:
    class AwsClusterWorkloadIdentityConfigArgsDict(TypedDict):
        identity_provider: NotRequired[pulumi.Input[builtins.str]]
        """
        The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        """
        issuer_uri: NotRequired[pulumi.Input[builtins.str]]
        """
        The OIDC issuer URL for this cluster.
        """
        workload_pool: NotRequired[pulumi.Input[builtins.str]]
        """
        The Workload Identity Pool associated to the cluster.
        """
elif False:
    AwsClusterWorkloadIdentityConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsClusterWorkloadIdentityConfigArgs:
    def __init__(__self__, *,
                 identity_provider: Optional[pulumi.Input[builtins.str]] = None,
                 issuer_uri: Optional[pulumi.Input[builtins.str]] = None,
                 workload_pool: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] identity_provider: The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        :param pulumi.Input[builtins.str] issuer_uri: The OIDC issuer URL for this cluster.
        :param pulumi.Input[builtins.str] workload_pool: The Workload Identity Pool associated to the cluster.
        """
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        """
        return pulumi.get(self, "identity_provider")

    @identity_provider.setter
    def identity_provider(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "identity_provider", value)

    @property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The OIDC issuer URL for this cluster.
        """
        return pulumi.get(self, "issuer_uri")

    @issuer_uri.setter
    def issuer_uri(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "issuer_uri", value)

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Workload Identity Pool associated to the cluster.
        """
        return pulumi.get(self, "workload_pool")

    @workload_pool.setter
    def workload_pool(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "workload_pool", value)


if not MYPY:
    class AwsNodePoolAutoscalingArgsDict(TypedDict):
        max_node_count: pulumi.Input[builtins.int]
        """
        Maximum number of nodes in the NodePool. Must be >= min_node_count.
        """
        min_node_count: pulumi.Input[builtins.int]
        """
        Minimum number of nodes in the NodePool. Must be >= 1 and <= max_node_count.
        """
elif False:
    AwsNodePoolAutoscalingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolAutoscalingArgs:
    def __init__(__self__, *,
                 max_node_count: pulumi.Input[builtins.int],
                 min_node_count: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.int] max_node_count: Maximum number of nodes in the NodePool. Must be >= min_node_count.
        :param pulumi.Input[builtins.int] min_node_count: Minimum number of nodes in the NodePool. Must be >= 1 and <= max_node_count.
        """
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> pulumi.Input[builtins.int]:
        """
        Maximum number of nodes in the NodePool. Must be >= min_node_count.
        """
        return pulumi.get(self, "max_node_count")

    @max_node_count.setter
    def max_node_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "max_node_count", value)

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> pulumi.Input[builtins.int]:
        """
        Minimum number of nodes in the NodePool. Must be >= 1 and <= max_node_count.
        """
        return pulumi.get(self, "min_node_count")

    @min_node_count.setter
    def min_node_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "min_node_count", value)


if not MYPY:
    class AwsNodePoolConfigArgsDict(TypedDict):
        config_encryption: pulumi.Input['AwsNodePoolConfigConfigEncryptionArgsDict']
        """
        The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        iam_instance_profile: pulumi.Input[builtins.str]
        """
        The name of the AWS IAM role assigned to nodes in the pool.
        """
        autoscaling_metrics_collection: NotRequired[pulumi.Input['AwsNodePoolConfigAutoscalingMetricsCollectionArgsDict']]
        """
        Optional. Configuration related to CloudWatch metrics collection on the Auto Scaling group of the node pool. When unspecified, metrics collection is disabled.
        """
        image_type: NotRequired[pulumi.Input[builtins.str]]
        """
        The OS image type to use on node pool instances.
        """
        instance_placement: NotRequired[pulumi.Input['AwsNodePoolConfigInstancePlacementArgsDict']]
        """
        Details of placement information for an instance.
        """
        instance_type: NotRequired[pulumi.Input[builtins.str]]
        """
        Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        """
        labels: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        """
        proxy_config: NotRequired[pulumi.Input['AwsNodePoolConfigProxyConfigArgsDict']]
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        root_volume: NotRequired[pulumi.Input['AwsNodePoolConfigRootVolumeArgsDict']]
        """
        Optional. Template for the root volume provisioned for node pool nodes. Volumes will be provisioned in the availability zone assigned to the node pool subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        """
        security_group_ids: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        Optional. The IDs of additional security groups to add to nodes in this pool. The manager will automatically create security groups with minimum rules needed for a functioning cluster.
        """
        spot_config: NotRequired[pulumi.Input['AwsNodePoolConfigSpotConfigArgsDict']]
        """
        Optional. When specified, the node pool will provision Spot instances from the set of spot_config.instance_types. This field is mutually exclusive with `instance_type`
        """
        ssh_config: NotRequired[pulumi.Input['AwsNodePoolConfigSshConfigArgsDict']]
        """
        Optional. The SSH configuration.
        """
        tags: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        Optional. Key/value metadata to assign to each underlying AWS resource. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        taints: NotRequired[pulumi.Input[Sequence[pulumi.Input['AwsNodePoolConfigTaintArgsDict']]]]
        """
        Optional. The initial taints assigned to nodes of this node pool.
        """
elif False:
    AwsNodePoolConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolConfigArgs:
    def __init__(__self__, *,
                 config_encryption: pulumi.Input['AwsNodePoolConfigConfigEncryptionArgs'],
                 iam_instance_profile: pulumi.Input[builtins.str],
                 autoscaling_metrics_collection: Optional[pulumi.Input['AwsNodePoolConfigAutoscalingMetricsCollectionArgs']] = None,
                 image_type: Optional[pulumi.Input[builtins.str]] = None,
                 instance_placement: Optional[pulumi.Input['AwsNodePoolConfigInstancePlacementArgs']] = None,
                 instance_type: Optional[pulumi.Input[builtins.str]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 proxy_config: Optional[pulumi.Input['AwsNodePoolConfigProxyConfigArgs']] = None,
                 root_volume: Optional[pulumi.Input['AwsNodePoolConfigRootVolumeArgs']] = None,
                 security_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 spot_config: Optional[pulumi.Input['AwsNodePoolConfigSpotConfigArgs']] = None,
                 ssh_config: Optional[pulumi.Input['AwsNodePoolConfigSshConfigArgs']] = None,
                 tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 taints: Optional[pulumi.Input[Sequence[pulumi.Input['AwsNodePoolConfigTaintArgs']]]] = None):
        """
        :param pulumi.Input['AwsNodePoolConfigConfigEncryptionArgs'] config_encryption: The ARN of the AWS KMS key used to encrypt node pool configuration.
        :param pulumi.Input[builtins.str] iam_instance_profile: The name of the AWS IAM role assigned to nodes in the pool.
        :param pulumi.Input['AwsNodePoolConfigAutoscalingMetricsCollectionArgs'] autoscaling_metrics_collection: Optional. Configuration related to CloudWatch metrics collection on the Auto Scaling group of the node pool. When unspecified, metrics collection is disabled.
        :param pulumi.Input[builtins.str] image_type: The OS image type to use on node pool instances.
        :param pulumi.Input['AwsNodePoolConfigInstancePlacementArgs'] instance_placement: Details of placement information for an instance.
        :param pulumi.Input[builtins.str] instance_type: Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] labels: Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        :param pulumi.Input['AwsNodePoolConfigProxyConfigArgs'] proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param pulumi.Input['AwsNodePoolConfigRootVolumeArgs'] root_volume: Optional. Template for the root volume provisioned for node pool nodes. Volumes will be provisioned in the availability zone assigned to the node pool subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] security_group_ids: Optional. The IDs of additional security groups to add to nodes in this pool. The manager will automatically create security groups with minimum rules needed for a functioning cluster.
        :param pulumi.Input['AwsNodePoolConfigSpotConfigArgs'] spot_config: Optional. When specified, the node pool will provision Spot instances from the set of spot_config.instance_types. This field is mutually exclusive with `instance_type`
        :param pulumi.Input['AwsNodePoolConfigSshConfigArgs'] ssh_config: Optional. The SSH configuration.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] tags: Optional. Key/value metadata to assign to each underlying AWS resource. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        :param pulumi.Input[Sequence[pulumi.Input['AwsNodePoolConfigTaintArgs']]] taints: Optional. The initial taints assigned to nodes of this node pool.
        """
        pulumi.set(__self__, "config_encryption", config_encryption)
        pulumi.set(__self__, "iam_instance_profile", iam_instance_profile)
        if autoscaling_metrics_collection is not None:
            pulumi.set(__self__, "autoscaling_metrics_collection", autoscaling_metrics_collection)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if instance_placement is not None:
            pulumi.set(__self__, "instance_placement", instance_placement)
        if instance_type is not None:
            pulumi.set(__self__, "instance_type", instance_type)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if security_group_ids is not None:
            pulumi.set(__self__, "security_group_ids", security_group_ids)
        if spot_config is not None:
            pulumi.set(__self__, "spot_config", spot_config)
        if ssh_config is not None:
            pulumi.set(__self__, "ssh_config", ssh_config)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)

    @property
    @pulumi.getter(name="configEncryption")
    def config_encryption(self) -> pulumi.Input['AwsNodePoolConfigConfigEncryptionArgs']:
        """
        The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        return pulumi.get(self, "config_encryption")

    @config_encryption.setter
    def config_encryption(self, value: pulumi.Input['AwsNodePoolConfigConfigEncryptionArgs']):
        pulumi.set(self, "config_encryption", value)

    @property
    @pulumi.getter(name="iamInstanceProfile")
    def iam_instance_profile(self) -> pulumi.Input[builtins.str]:
        """
        The name of the AWS IAM role assigned to nodes in the pool.
        """
        return pulumi.get(self, "iam_instance_profile")

    @iam_instance_profile.setter
    def iam_instance_profile(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "iam_instance_profile", value)

    @property
    @pulumi.getter(name="autoscalingMetricsCollection")
    def autoscaling_metrics_collection(self) -> Optional[pulumi.Input['AwsNodePoolConfigAutoscalingMetricsCollectionArgs']]:
        """
        Optional. Configuration related to CloudWatch metrics collection on the Auto Scaling group of the node pool. When unspecified, metrics collection is disabled.
        """
        return pulumi.get(self, "autoscaling_metrics_collection")

    @autoscaling_metrics_collection.setter
    def autoscaling_metrics_collection(self, value: Optional[pulumi.Input['AwsNodePoolConfigAutoscalingMetricsCollectionArgs']]):
        pulumi.set(self, "autoscaling_metrics_collection", value)

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The OS image type to use on node pool instances.
        """
        return pulumi.get(self, "image_type")

    @image_type.setter
    def image_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "image_type", value)

    @property
    @pulumi.getter(name="instancePlacement")
    def instance_placement(self) -> Optional[pulumi.Input['AwsNodePoolConfigInstancePlacementArgs']]:
        """
        Details of placement information for an instance.
        """
        return pulumi.get(self, "instance_placement")

    @instance_placement.setter
    def instance_placement(self, value: Optional[pulumi.Input['AwsNodePoolConfigInstancePlacementArgs']]):
        pulumi.set(self, "instance_placement", value)

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        """
        return pulumi.get(self, "instance_type")

    @instance_type.setter
    def instance_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "instance_type", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional[pulumi.Input['AwsNodePoolConfigProxyConfigArgs']]:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @proxy_config.setter
    def proxy_config(self, value: Optional[pulumi.Input['AwsNodePoolConfigProxyConfigArgs']]):
        pulumi.set(self, "proxy_config", value)

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional[pulumi.Input['AwsNodePoolConfigRootVolumeArgs']]:
        """
        Optional. Template for the root volume provisioned for node pool nodes. Volumes will be provisioned in the availability zone assigned to the node pool subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "root_volume")

    @root_volume.setter
    def root_volume(self, value: Optional[pulumi.Input['AwsNodePoolConfigRootVolumeArgs']]):
        pulumi.set(self, "root_volume", value)

    @property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        Optional. The IDs of additional security groups to add to nodes in this pool. The manager will automatically create security groups with minimum rules needed for a functioning cluster.
        """
        return pulumi.get(self, "security_group_ids")

    @security_group_ids.setter
    def security_group_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "security_group_ids", value)

    @property
    @pulumi.getter(name="spotConfig")
    def spot_config(self) -> Optional[pulumi.Input['AwsNodePoolConfigSpotConfigArgs']]:
        """
        Optional. When specified, the node pool will provision Spot instances from the set of spot_config.instance_types. This field is mutually exclusive with `instance_type`
        """
        return pulumi.get(self, "spot_config")

    @spot_config.setter
    def spot_config(self, value: Optional[pulumi.Input['AwsNodePoolConfigSpotConfigArgs']]):
        pulumi.set(self, "spot_config", value)

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> Optional[pulumi.Input['AwsNodePoolConfigSshConfigArgs']]:
        """
        Optional. The SSH configuration.
        """
        return pulumi.get(self, "ssh_config")

    @ssh_config.setter
    def ssh_config(self, value: Optional[pulumi.Input['AwsNodePoolConfigSshConfigArgs']]):
        pulumi.set(self, "ssh_config", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        Optional. Key/value metadata to assign to each underlying AWS resource. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter
    def taints(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['AwsNodePoolConfigTaintArgs']]]]:
        """
        Optional. The initial taints assigned to nodes of this node pool.
        """
        return pulumi.get(self, "taints")

    @taints.setter
    def taints(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['AwsNodePoolConfigTaintArgs']]]]):
        pulumi.set(self, "taints", value)


if not MYPY:
    class AwsNodePoolConfigAutoscalingMetricsCollectionArgsDict(TypedDict):
        granularity: pulumi.Input[builtins.str]
        """
        The frequency at which EC2 Auto Scaling sends aggregated data to AWS CloudWatch. The only valid value is "1Minute".
        """
        metrics: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The metrics to enable. For a list of valid metrics, see https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html. If you specify granularity and don't specify any metrics, all metrics are enabled.
        """
elif False:
    AwsNodePoolConfigAutoscalingMetricsCollectionArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolConfigAutoscalingMetricsCollectionArgs:
    def __init__(__self__, *,
                 granularity: pulumi.Input[builtins.str],
                 metrics: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[builtins.str] granularity: The frequency at which EC2 Auto Scaling sends aggregated data to AWS CloudWatch. The only valid value is "1Minute".
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] metrics: The metrics to enable. For a list of valid metrics, see https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html. If you specify granularity and don't specify any metrics, all metrics are enabled.
        """
        pulumi.set(__self__, "granularity", granularity)
        if metrics is not None:
            pulumi.set(__self__, "metrics", metrics)

    @property
    @pulumi.getter
    def granularity(self) -> pulumi.Input[builtins.str]:
        """
        The frequency at which EC2 Auto Scaling sends aggregated data to AWS CloudWatch. The only valid value is "1Minute".
        """
        return pulumi.get(self, "granularity")

    @granularity.setter
    def granularity(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "granularity", value)

    @property
    @pulumi.getter
    def metrics(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The metrics to enable. For a list of valid metrics, see https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html. If you specify granularity and don't specify any metrics, all metrics are enabled.
        """
        return pulumi.get(self, "metrics")

    @metrics.setter
    def metrics(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "metrics", value)


if not MYPY:
    class AwsNodePoolConfigConfigEncryptionArgsDict(TypedDict):
        kms_key_arn: pulumi.Input[builtins.str]
        """
        The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
elif False:
    AwsNodePoolConfigConfigEncryptionArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolConfigConfigEncryptionArgs:
    def __init__(__self__, *,
                 kms_key_arn: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] kms_key_arn: The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> pulumi.Input[builtins.str]:
        """
        The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        return pulumi.get(self, "kms_key_arn")

    @kms_key_arn.setter
    def kms_key_arn(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "kms_key_arn", value)


if not MYPY:
    class AwsNodePoolConfigInstancePlacementArgsDict(TypedDict):
        tenancy: NotRequired[pulumi.Input[builtins.str]]
        """
        The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
elif False:
    AwsNodePoolConfigInstancePlacementArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolConfigInstancePlacementArgs:
    def __init__(__self__, *,
                 tenancy: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] tenancy: The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        if tenancy is not None:
            pulumi.set(__self__, "tenancy", tenancy)

    @property
    @pulumi.getter
    def tenancy(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        return pulumi.get(self, "tenancy")

    @tenancy.setter
    def tenancy(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "tenancy", value)


if not MYPY:
    class AwsNodePoolConfigProxyConfigArgsDict(TypedDict):
        secret_arn: pulumi.Input[builtins.str]
        """
        The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        secret_version: pulumi.Input[builtins.str]
        """
        The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
elif False:
    AwsNodePoolConfigProxyConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolConfigProxyConfigArgs:
    def __init__(__self__, *,
                 secret_arn: pulumi.Input[builtins.str],
                 secret_version: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] secret_arn: The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        :param pulumi.Input[builtins.str] secret_version: The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        pulumi.set(__self__, "secret_arn", secret_arn)
        pulumi.set(__self__, "secret_version", secret_version)

    @property
    @pulumi.getter(name="secretArn")
    def secret_arn(self) -> pulumi.Input[builtins.str]:
        """
        The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_arn")

    @secret_arn.setter
    def secret_arn(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "secret_arn", value)

    @property
    @pulumi.getter(name="secretVersion")
    def secret_version(self) -> pulumi.Input[builtins.str]:
        """
        The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_version")

    @secret_version.setter
    def secret_version(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "secret_version", value)


if not MYPY:
    class AwsNodePoolConfigRootVolumeArgsDict(TypedDict):
        iops: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        kms_key_arn: NotRequired[pulumi.Input[builtins.str]]
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        size_gib: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        throughput: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        """
        volume_type: NotRequired[pulumi.Input[builtins.str]]
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
elif False:
    AwsNodePoolConfigRootVolumeArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolConfigRootVolumeArgs:
    def __init__(__self__, *,
                 iops: Optional[pulumi.Input[builtins.int]] = None,
                 kms_key_arn: Optional[pulumi.Input[builtins.str]] = None,
                 size_gib: Optional[pulumi.Input[builtins.int]] = None,
                 throughput: Optional[pulumi.Input[builtins.int]] = None,
                 volume_type: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.int] iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param pulumi.Input[builtins.str] kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param pulumi.Input[builtins.int] size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param pulumi.Input[builtins.int] throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        :param pulumi.Input[builtins.str] volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter
    def iops(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @iops.setter
    def iops(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "iops", value)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @kms_key_arn.setter
    def kms_key_arn(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "kms_key_arn", value)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @size_gib.setter
    def size_gib(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "size_gib", value)

    @property
    @pulumi.getter
    def throughput(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3. If volume type is gp3 and throughput is not specified, the throughput will defaults to 125.
        """
        return pulumi.get(self, "throughput")

    @throughput.setter
    def throughput(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "throughput", value)

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")

    @volume_type.setter
    def volume_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "volume_type", value)


if not MYPY:
    class AwsNodePoolConfigSpotConfigArgsDict(TypedDict):
        instance_types: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        List of AWS EC2 instance types for creating a spot node pool's nodes. The specified instance types must have the same number of CPUs and memory. You can use the Amazon EC2 Instance Selector tool (https://github.com/aws/amazon-ec2-instance-selector) to choose instance types with matching CPU and memory
        """
elif False:
    AwsNodePoolConfigSpotConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolConfigSpotConfigArgs:
    def __init__(__self__, *,
                 instance_types: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] instance_types: List of AWS EC2 instance types for creating a spot node pool's nodes. The specified instance types must have the same number of CPUs and memory. You can use the Amazon EC2 Instance Selector tool (https://github.com/aws/amazon-ec2-instance-selector) to choose instance types with matching CPU and memory
        """
        pulumi.set(__self__, "instance_types", instance_types)

    @property
    @pulumi.getter(name="instanceTypes")
    def instance_types(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        List of AWS EC2 instance types for creating a spot node pool's nodes. The specified instance types must have the same number of CPUs and memory. You can use the Amazon EC2 Instance Selector tool (https://github.com/aws/amazon-ec2-instance-selector) to choose instance types with matching CPU and memory
        """
        return pulumi.get(self, "instance_types")

    @instance_types.setter
    def instance_types(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "instance_types", value)


if not MYPY:
    class AwsNodePoolConfigSshConfigArgsDict(TypedDict):
        ec2_key_pair: pulumi.Input[builtins.str]
        """
        The name of the EC2 key pair used to login into cluster machines.
        """
elif False:
    AwsNodePoolConfigSshConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolConfigSshConfigArgs:
    def __init__(__self__, *,
                 ec2_key_pair: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] ec2_key_pair: The name of the EC2 key pair used to login into cluster machines.
        """
        pulumi.set(__self__, "ec2_key_pair", ec2_key_pair)

    @property
    @pulumi.getter(name="ec2KeyPair")
    def ec2_key_pair(self) -> pulumi.Input[builtins.str]:
        """
        The name of the EC2 key pair used to login into cluster machines.
        """
        return pulumi.get(self, "ec2_key_pair")

    @ec2_key_pair.setter
    def ec2_key_pair(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "ec2_key_pair", value)


if not MYPY:
    class AwsNodePoolConfigTaintArgsDict(TypedDict):
        effect: pulumi.Input[builtins.str]
        """
        The taint effect. Possible values: EFFECT_UNSPECIFIED, NO_SCHEDULE, PREFER_NO_SCHEDULE, NO_EXECUTE
        """
        key: pulumi.Input[builtins.str]
        """
        Key for the taint.
        """
        value: pulumi.Input[builtins.str]
        """
        Value for the taint.
        """
elif False:
    AwsNodePoolConfigTaintArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolConfigTaintArgs:
    def __init__(__self__, *,
                 effect: pulumi.Input[builtins.str],
                 key: pulumi.Input[builtins.str],
                 value: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] effect: The taint effect. Possible values: EFFECT_UNSPECIFIED, NO_SCHEDULE, PREFER_NO_SCHEDULE, NO_EXECUTE
        :param pulumi.Input[builtins.str] key: Key for the taint.
        :param pulumi.Input[builtins.str] value: Value for the taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> pulumi.Input[builtins.str]:
        """
        The taint effect. Possible values: EFFECT_UNSPECIFIED, NO_SCHEDULE, PREFER_NO_SCHEDULE, NO_EXECUTE
        """
        return pulumi.get(self, "effect")

    @effect.setter
    def effect(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "effect", value)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[builtins.str]:
        """
        Key for the taint.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[builtins.str]:
        """
        Value for the taint.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "value", value)


if not MYPY:
    class AwsNodePoolKubeletConfigArgsDict(TypedDict):
        cpu_cfs_quota: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether or not to enable CPU CFS quota. Defaults to true.
        """
        cpu_cfs_quota_period: NotRequired[pulumi.Input[builtins.str]]
        """
        Optional. The CPU CFS quota period to use for the node. Defaults to "100ms".
        """
        cpu_manager_policy: NotRequired[pulumi.Input[builtins.str]]
        """
        The CpuManagerPolicy to use for the node. Defaults to "none".
        """
        pod_pids_limit: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The maximum number of PIDs in each pod running on the node. The limit scales automatically based on underlying machine size if left unset.
        """
elif False:
    AwsNodePoolKubeletConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolKubeletConfigArgs:
    def __init__(__self__, *,
                 cpu_cfs_quota: Optional[pulumi.Input[builtins.bool]] = None,
                 cpu_cfs_quota_period: Optional[pulumi.Input[builtins.str]] = None,
                 cpu_manager_policy: Optional[pulumi.Input[builtins.str]] = None,
                 pod_pids_limit: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.bool] cpu_cfs_quota: Whether or not to enable CPU CFS quota. Defaults to true.
        :param pulumi.Input[builtins.str] cpu_cfs_quota_period: Optional. The CPU CFS quota period to use for the node. Defaults to "100ms".
        :param pulumi.Input[builtins.str] cpu_manager_policy: The CpuManagerPolicy to use for the node. Defaults to "none".
        :param pulumi.Input[builtins.int] pod_pids_limit: Optional. The maximum number of PIDs in each pod running on the node. The limit scales automatically based on underlying machine size if left unset.
        """
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if cpu_manager_policy is not None:
            pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether or not to enable CPU CFS quota. Defaults to true.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @cpu_cfs_quota.setter
    def cpu_cfs_quota(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "cpu_cfs_quota", value)

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Optional. The CPU CFS quota period to use for the node. Defaults to "100ms".
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @cpu_cfs_quota_period.setter
    def cpu_cfs_quota_period(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cpu_cfs_quota_period", value)

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The CpuManagerPolicy to use for the node. Defaults to "none".
        """
        return pulumi.get(self, "cpu_manager_policy")

    @cpu_manager_policy.setter
    def cpu_manager_policy(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cpu_manager_policy", value)

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The maximum number of PIDs in each pod running on the node. The limit scales automatically based on underlying machine size if left unset.
        """
        return pulumi.get(self, "pod_pids_limit")

    @pod_pids_limit.setter
    def pod_pids_limit(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "pod_pids_limit", value)


if not MYPY:
    class AwsNodePoolManagementArgsDict(TypedDict):
        auto_repair: NotRequired[pulumi.Input[builtins.bool]]
        """
        Optional. Whether or not the nodes will be automatically repaired.
        """
elif False:
    AwsNodePoolManagementArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolManagementArgs:
    def __init__(__self__, *,
                 auto_repair: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.bool] auto_repair: Optional. Whether or not the nodes will be automatically repaired.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Optional. Whether or not the nodes will be automatically repaired.
        """
        return pulumi.get(self, "auto_repair")

    @auto_repair.setter
    def auto_repair(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "auto_repair", value)


if not MYPY:
    class AwsNodePoolMaxPodsConstraintArgsDict(TypedDict):
        max_pods_per_node: pulumi.Input[builtins.int]
        """
        The maximum number of pods to schedule on a single node.

        - - -
        """
elif False:
    AwsNodePoolMaxPodsConstraintArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolMaxPodsConstraintArgs:
    def __init__(__self__, *,
                 max_pods_per_node: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.int] max_pods_per_node: The maximum number of pods to schedule on a single node.
               
               - - -
        """
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> pulumi.Input[builtins.int]:
        """
        The maximum number of pods to schedule on a single node.

        - - -
        """
        return pulumi.get(self, "max_pods_per_node")

    @max_pods_per_node.setter
    def max_pods_per_node(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "max_pods_per_node", value)


if not MYPY:
    class AwsNodePoolUpdateSettingsArgsDict(TypedDict):
        surge_settings: NotRequired[pulumi.Input['AwsNodePoolUpdateSettingsSurgeSettingsArgsDict']]
        """
        Optional. Settings for surge update.
        """
elif False:
    AwsNodePoolUpdateSettingsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolUpdateSettingsArgs:
    def __init__(__self__, *,
                 surge_settings: Optional[pulumi.Input['AwsNodePoolUpdateSettingsSurgeSettingsArgs']] = None):
        """
        :param pulumi.Input['AwsNodePoolUpdateSettingsSurgeSettingsArgs'] surge_settings: Optional. Settings for surge update.
        """
        if surge_settings is not None:
            pulumi.set(__self__, "surge_settings", surge_settings)

    @property
    @pulumi.getter(name="surgeSettings")
    def surge_settings(self) -> Optional[pulumi.Input['AwsNodePoolUpdateSettingsSurgeSettingsArgs']]:
        """
        Optional. Settings for surge update.
        """
        return pulumi.get(self, "surge_settings")

    @surge_settings.setter
    def surge_settings(self, value: Optional[pulumi.Input['AwsNodePoolUpdateSettingsSurgeSettingsArgs']]):
        pulumi.set(self, "surge_settings", value)


if not MYPY:
    class AwsNodePoolUpdateSettingsSurgeSettingsArgsDict(TypedDict):
        max_surge: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The maximum number of nodes that can be created beyond the current size of the node pool during the update process.
        """
        max_unavailable: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The maximum number of nodes that can be simultaneously unavailable during the update process. A node is considered unavailable if its status is not Ready.
        """
elif False:
    AwsNodePoolUpdateSettingsSurgeSettingsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AwsNodePoolUpdateSettingsSurgeSettingsArgs:
    def __init__(__self__, *,
                 max_surge: Optional[pulumi.Input[builtins.int]] = None,
                 max_unavailable: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.int] max_surge: Optional. The maximum number of nodes that can be created beyond the current size of the node pool during the update process.
        :param pulumi.Input[builtins.int] max_unavailable: Optional. The maximum number of nodes that can be simultaneously unavailable during the update process. A node is considered unavailable if its status is not Ready.
        """
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The maximum number of nodes that can be created beyond the current size of the node pool during the update process.
        """
        return pulumi.get(self, "max_surge")

    @max_surge.setter
    def max_surge(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_surge", value)

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The maximum number of nodes that can be simultaneously unavailable during the update process. A node is considered unavailable if its status is not Ready.
        """
        return pulumi.get(self, "max_unavailable")

    @max_unavailable.setter
    def max_unavailable(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_unavailable", value)


if not MYPY:
    class AzureClusterAuthorizationArgsDict(TypedDict):
        admin_users: pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminUserArgsDict']]]
        """
        Users that can perform operations as a cluster admin. A new ClusterRoleBinding will be created to grant the cluster-admin ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        admin_groups: NotRequired[pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminGroupArgsDict']]]]
        """
        Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
elif False:
    AzureClusterAuthorizationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterAuthorizationArgs:
    def __init__(__self__, *,
                 admin_users: pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminUserArgs']]],
                 admin_groups: Optional[pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminGroupArgs']]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminUserArgs']]] admin_users: Users that can perform operations as a cluster admin. A new ClusterRoleBinding will be created to grant the cluster-admin ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        :param pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminGroupArgs']]] admin_groups: Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        pulumi.set(__self__, "admin_users", admin_users)
        if admin_groups is not None:
            pulumi.set(__self__, "admin_groups", admin_groups)

    @property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminUserArgs']]]:
        """
        Users that can perform operations as a cluster admin. A new ClusterRoleBinding will be created to grant the cluster-admin ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")

    @admin_users.setter
    def admin_users(self, value: pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminUserArgs']]]):
        pulumi.set(self, "admin_users", value)

    @property
    @pulumi.getter(name="adminGroups")
    def admin_groups(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminGroupArgs']]]]:
        """
        Groups of users that can perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the groups. Up to ten admin groups can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_groups")

    @admin_groups.setter
    def admin_groups(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminGroupArgs']]]]):
        pulumi.set(self, "admin_groups", value)


if not MYPY:
    class AzureClusterAuthorizationAdminGroupArgsDict(TypedDict):
        group: pulumi.Input[builtins.str]
        """
        The name of the group, e.g. `my-group@domain.com`.
        """
elif False:
    AzureClusterAuthorizationAdminGroupArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterAuthorizationAdminGroupArgs:
    def __init__(__self__, *,
                 group: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] group: The name of the group, e.g. `my-group@domain.com`.
        """
        pulumi.set(__self__, "group", group)

    @property
    @pulumi.getter
    def group(self) -> pulumi.Input[builtins.str]:
        """
        The name of the group, e.g. `my-group@domain.com`.
        """
        return pulumi.get(self, "group")

    @group.setter
    def group(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "group", value)


if not MYPY:
    class AzureClusterAuthorizationAdminUserArgsDict(TypedDict):
        username: pulumi.Input[builtins.str]
        """
        The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
elif False:
    AzureClusterAuthorizationAdminUserArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterAuthorizationAdminUserArgs:
    def __init__(__self__, *,
                 username: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] username: The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def username(self) -> pulumi.Input[builtins.str]:
        """
        The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        return pulumi.get(self, "username")

    @username.setter
    def username(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "username", value)


if not MYPY:
    class AzureClusterAzureServicesAuthenticationArgsDict(TypedDict):
        application_id: pulumi.Input[builtins.str]
        """
        The Azure Active Directory Application ID for Authentication configuration.
        """
        tenant_id: pulumi.Input[builtins.str]
        """
        The Azure Active Directory Tenant ID for Authentication configuration.
        """
elif False:
    AzureClusterAzureServicesAuthenticationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterAzureServicesAuthenticationArgs:
    def __init__(__self__, *,
                 application_id: pulumi.Input[builtins.str],
                 tenant_id: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] application_id: The Azure Active Directory Application ID for Authentication configuration.
        :param pulumi.Input[builtins.str] tenant_id: The Azure Active Directory Tenant ID for Authentication configuration.
        """
        pulumi.set(__self__, "application_id", application_id)
        pulumi.set(__self__, "tenant_id", tenant_id)

    @property
    @pulumi.getter(name="applicationId")
    def application_id(self) -> pulumi.Input[builtins.str]:
        """
        The Azure Active Directory Application ID for Authentication configuration.
        """
        return pulumi.get(self, "application_id")

    @application_id.setter
    def application_id(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "application_id", value)

    @property
    @pulumi.getter(name="tenantId")
    def tenant_id(self) -> pulumi.Input[builtins.str]:
        """
        The Azure Active Directory Tenant ID for Authentication configuration.
        """
        return pulumi.get(self, "tenant_id")

    @tenant_id.setter
    def tenant_id(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "tenant_id", value)


if not MYPY:
    class AzureClusterControlPlaneArgsDict(TypedDict):
        ssh_config: pulumi.Input['AzureClusterControlPlaneSshConfigArgsDict']
        """
        SSH configuration for how to access the underlying control plane machines.
        """
        subnet_id: pulumi.Input[builtins.str]
        """
        The ARM ID of the subnet where the control plane VMs are deployed. Example: `/subscriptions//resourceGroups//providers/Microsoft.Network/virtualNetworks//subnets/default`.
        """
        version: pulumi.Input[builtins.str]
        """
        The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling GetAzureServerConfig.
        """
        database_encryption: NotRequired[pulumi.Input['AzureClusterControlPlaneDatabaseEncryptionArgsDict']]
        """
        Optional. Configuration related to application-layer secrets encryption.
        """
        main_volume: NotRequired[pulumi.Input['AzureClusterControlPlaneMainVolumeArgsDict']]
        """
        Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. When unspecified, it defaults to a 8-GiB Azure Disk.
        """
        proxy_config: NotRequired[pulumi.Input['AzureClusterControlPlaneProxyConfigArgsDict']]
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        replica_placements: NotRequired[pulumi.Input[Sequence[pulumi.Input['AzureClusterControlPlaneReplicaPlacementArgsDict']]]]
        """
        Configuration for where to place the control plane replicas. Up to three replica placement instances can be specified. If replica_placements is set, the replica placement instances will be applied to the three control plane replicas as evenly as possible.
        """
        root_volume: NotRequired[pulumi.Input['AzureClusterControlPlaneRootVolumeArgsDict']]
        """
        Optional. Configuration related to the root volume provisioned for each control plane replica. When unspecified, it defaults to 32-GiB Azure Disk.
        """
        tags: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        Optional. A set of tags to apply to all underlying control plane Azure resources.
        """
        vm_size: NotRequired[pulumi.Input[builtins.str]]
        """
        Optional. The Azure VM size name. Example: `Standard_DS2_v2`. For available VM sizes, see https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions. When unspecified, it defaults to `Standard_DS2_v2`.
        """
elif False:
    AzureClusterControlPlaneArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterControlPlaneArgs:
    def __init__(__self__, *,
                 ssh_config: pulumi.Input['AzureClusterControlPlaneSshConfigArgs'],
                 subnet_id: pulumi.Input[builtins.str],
                 version: pulumi.Input[builtins.str],
                 database_encryption: Optional[pulumi.Input['AzureClusterControlPlaneDatabaseEncryptionArgs']] = None,
                 main_volume: Optional[pulumi.Input['AzureClusterControlPlaneMainVolumeArgs']] = None,
                 proxy_config: Optional[pulumi.Input['AzureClusterControlPlaneProxyConfigArgs']] = None,
                 replica_placements: Optional[pulumi.Input[Sequence[pulumi.Input['AzureClusterControlPlaneReplicaPlacementArgs']]]] = None,
                 root_volume: Optional[pulumi.Input['AzureClusterControlPlaneRootVolumeArgs']] = None,
                 tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 vm_size: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input['AzureClusterControlPlaneSshConfigArgs'] ssh_config: SSH configuration for how to access the underlying control plane machines.
        :param pulumi.Input[builtins.str] subnet_id: The ARM ID of the subnet where the control plane VMs are deployed. Example: `/subscriptions//resourceGroups//providers/Microsoft.Network/virtualNetworks//subnets/default`.
        :param pulumi.Input[builtins.str] version: The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling GetAzureServerConfig.
        :param pulumi.Input['AzureClusterControlPlaneDatabaseEncryptionArgs'] database_encryption: Optional. Configuration related to application-layer secrets encryption.
        :param pulumi.Input['AzureClusterControlPlaneMainVolumeArgs'] main_volume: Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. When unspecified, it defaults to a 8-GiB Azure Disk.
        :param pulumi.Input['AzureClusterControlPlaneProxyConfigArgs'] proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param pulumi.Input[Sequence[pulumi.Input['AzureClusterControlPlaneReplicaPlacementArgs']]] replica_placements: Configuration for where to place the control plane replicas. Up to three replica placement instances can be specified. If replica_placements is set, the replica placement instances will be applied to the three control plane replicas as evenly as possible.
        :param pulumi.Input['AzureClusterControlPlaneRootVolumeArgs'] root_volume: Optional. Configuration related to the root volume provisioned for each control plane replica. When unspecified, it defaults to 32-GiB Azure Disk.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] tags: Optional. A set of tags to apply to all underlying control plane Azure resources.
        :param pulumi.Input[builtins.str] vm_size: Optional. The Azure VM size name. Example: `Standard_DS2_v2`. For available VM sizes, see https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        pulumi.set(__self__, "ssh_config", ssh_config)
        pulumi.set(__self__, "subnet_id", subnet_id)
        pulumi.set(__self__, "version", version)
        if database_encryption is not None:
            pulumi.set(__self__, "database_encryption", database_encryption)
        if main_volume is not None:
            pulumi.set(__self__, "main_volume", main_volume)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if replica_placements is not None:
            pulumi.set(__self__, "replica_placements", replica_placements)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if vm_size is not None:
            pulumi.set(__self__, "vm_size", vm_size)

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> pulumi.Input['AzureClusterControlPlaneSshConfigArgs']:
        """
        SSH configuration for how to access the underlying control plane machines.
        """
        return pulumi.get(self, "ssh_config")

    @ssh_config.setter
    def ssh_config(self, value: pulumi.Input['AzureClusterControlPlaneSshConfigArgs']):
        pulumi.set(self, "ssh_config", value)

    @property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> pulumi.Input[builtins.str]:
        """
        The ARM ID of the subnet where the control plane VMs are deployed. Example: `/subscriptions//resourceGroups//providers/Microsoft.Network/virtualNetworks//subnets/default`.
        """
        return pulumi.get(self, "subnet_id")

    @subnet_id.setter
    def subnet_id(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "subnet_id", value)

    @property
    @pulumi.getter
    def version(self) -> pulumi.Input[builtins.str]:
        """
        The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling GetAzureServerConfig.
        """
        return pulumi.get(self, "version")

    @version.setter
    def version(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "version", value)

    @property
    @pulumi.getter(name="databaseEncryption")
    def database_encryption(self) -> Optional[pulumi.Input['AzureClusterControlPlaneDatabaseEncryptionArgs']]:
        """
        Optional. Configuration related to application-layer secrets encryption.
        """
        return pulumi.get(self, "database_encryption")

    @database_encryption.setter
    def database_encryption(self, value: Optional[pulumi.Input['AzureClusterControlPlaneDatabaseEncryptionArgs']]):
        pulumi.set(self, "database_encryption", value)

    @property
    @pulumi.getter(name="mainVolume")
    def main_volume(self) -> Optional[pulumi.Input['AzureClusterControlPlaneMainVolumeArgs']]:
        """
        Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. When unspecified, it defaults to a 8-GiB Azure Disk.
        """
        return pulumi.get(self, "main_volume")

    @main_volume.setter
    def main_volume(self, value: Optional[pulumi.Input['AzureClusterControlPlaneMainVolumeArgs']]):
        pulumi.set(self, "main_volume", value)

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional[pulumi.Input['AzureClusterControlPlaneProxyConfigArgs']]:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @proxy_config.setter
    def proxy_config(self, value: Optional[pulumi.Input['AzureClusterControlPlaneProxyConfigArgs']]):
        pulumi.set(self, "proxy_config", value)

    @property
    @pulumi.getter(name="replicaPlacements")
    def replica_placements(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['AzureClusterControlPlaneReplicaPlacementArgs']]]]:
        """
        Configuration for where to place the control plane replicas. Up to three replica placement instances can be specified. If replica_placements is set, the replica placement instances will be applied to the three control plane replicas as evenly as possible.
        """
        return pulumi.get(self, "replica_placements")

    @replica_placements.setter
    def replica_placements(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['AzureClusterControlPlaneReplicaPlacementArgs']]]]):
        pulumi.set(self, "replica_placements", value)

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional[pulumi.Input['AzureClusterControlPlaneRootVolumeArgs']]:
        """
        Optional. Configuration related to the root volume provisioned for each control plane replica. When unspecified, it defaults to 32-GiB Azure Disk.
        """
        return pulumi.get(self, "root_volume")

    @root_volume.setter
    def root_volume(self, value: Optional[pulumi.Input['AzureClusterControlPlaneRootVolumeArgs']]):
        pulumi.set(self, "root_volume", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        Optional. A set of tags to apply to all underlying control plane Azure resources.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter(name="vmSize")
    def vm_size(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Optional. The Azure VM size name. Example: `Standard_DS2_v2`. For available VM sizes, see https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        return pulumi.get(self, "vm_size")

    @vm_size.setter
    def vm_size(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "vm_size", value)


if not MYPY:
    class AzureClusterControlPlaneDatabaseEncryptionArgsDict(TypedDict):
        key_id: pulumi.Input[builtins.str]
        """
        The ARM ID of the Azure Key Vault key to encrypt / decrypt data. For example: `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>` Encryption will always take the latest version of the key and hence specific version is not supported.
        """
elif False:
    AzureClusterControlPlaneDatabaseEncryptionArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterControlPlaneDatabaseEncryptionArgs:
    def __init__(__self__, *,
                 key_id: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] key_id: The ARM ID of the Azure Key Vault key to encrypt / decrypt data. For example: `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>` Encryption will always take the latest version of the key and hence specific version is not supported.
        """
        pulumi.set(__self__, "key_id", key_id)

    @property
    @pulumi.getter(name="keyId")
    def key_id(self) -> pulumi.Input[builtins.str]:
        """
        The ARM ID of the Azure Key Vault key to encrypt / decrypt data. For example: `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>` Encryption will always take the latest version of the key and hence specific version is not supported.
        """
        return pulumi.get(self, "key_id")

    @key_id.setter
    def key_id(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "key_id", value)


if not MYPY:
    class AzureClusterControlPlaneMainVolumeArgsDict(TypedDict):
        size_gib: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
elif False:
    AzureClusterControlPlaneMainVolumeArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterControlPlaneMainVolumeArgs:
    def __init__(__self__, *,
                 size_gib: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.int] size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @size_gib.setter
    def size_gib(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "size_gib", value)


if not MYPY:
    class AzureClusterControlPlaneProxyConfigArgsDict(TypedDict):
        resource_group_id: pulumi.Input[builtins.str]
        """
        The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        """
        secret_id: pulumi.Input[builtins.str]
        """
        The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
elif False:
    AzureClusterControlPlaneProxyConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterControlPlaneProxyConfigArgs:
    def __init__(__self__, *,
                 resource_group_id: pulumi.Input[builtins.str],
                 secret_id: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] resource_group_id: The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        :param pulumi.Input[builtins.str] secret_id: The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        pulumi.set(__self__, "resource_group_id", resource_group_id)
        pulumi.set(__self__, "secret_id", secret_id)

    @property
    @pulumi.getter(name="resourceGroupId")
    def resource_group_id(self) -> pulumi.Input[builtins.str]:
        """
        The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        """
        return pulumi.get(self, "resource_group_id")

    @resource_group_id.setter
    def resource_group_id(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "resource_group_id", value)

    @property
    @pulumi.getter(name="secretId")
    def secret_id(self) -> pulumi.Input[builtins.str]:
        """
        The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        return pulumi.get(self, "secret_id")

    @secret_id.setter
    def secret_id(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "secret_id", value)


if not MYPY:
    class AzureClusterControlPlaneReplicaPlacementArgsDict(TypedDict):
        azure_availability_zone: pulumi.Input[builtins.str]
        """
        For a given replica, the Azure availability zone where to provision the control plane VM and the ETCD disk.
        """
        subnet_id: pulumi.Input[builtins.str]
        """
        For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
        """
elif False:
    AzureClusterControlPlaneReplicaPlacementArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterControlPlaneReplicaPlacementArgs:
    def __init__(__self__, *,
                 azure_availability_zone: pulumi.Input[builtins.str],
                 subnet_id: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] azure_availability_zone: For a given replica, the Azure availability zone where to provision the control plane VM and the ETCD disk.
        :param pulumi.Input[builtins.str] subnet_id: For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
        """
        pulumi.set(__self__, "azure_availability_zone", azure_availability_zone)
        pulumi.set(__self__, "subnet_id", subnet_id)

    @property
    @pulumi.getter(name="azureAvailabilityZone")
    def azure_availability_zone(self) -> pulumi.Input[builtins.str]:
        """
        For a given replica, the Azure availability zone where to provision the control plane VM and the ETCD disk.
        """
        return pulumi.get(self, "azure_availability_zone")

    @azure_availability_zone.setter
    def azure_availability_zone(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "azure_availability_zone", value)

    @property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> pulumi.Input[builtins.str]:
        """
        For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
        """
        return pulumi.get(self, "subnet_id")

    @subnet_id.setter
    def subnet_id(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "subnet_id", value)


if not MYPY:
    class AzureClusterControlPlaneRootVolumeArgsDict(TypedDict):
        size_gib: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
elif False:
    AzureClusterControlPlaneRootVolumeArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterControlPlaneRootVolumeArgs:
    def __init__(__self__, *,
                 size_gib: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.int] size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @size_gib.setter
    def size_gib(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "size_gib", value)


if not MYPY:
    class AzureClusterControlPlaneSshConfigArgsDict(TypedDict):
        authorized_key: pulumi.Input[builtins.str]
        """
        The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
elif False:
    AzureClusterControlPlaneSshConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterControlPlaneSshConfigArgs:
    def __init__(__self__, *,
                 authorized_key: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] authorized_key: The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        pulumi.set(__self__, "authorized_key", authorized_key)

    @property
    @pulumi.getter(name="authorizedKey")
    def authorized_key(self) -> pulumi.Input[builtins.str]:
        """
        The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        return pulumi.get(self, "authorized_key")

    @authorized_key.setter
    def authorized_key(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "authorized_key", value)


if not MYPY:
    class AzureClusterFleetArgsDict(TypedDict):
        membership: NotRequired[pulumi.Input[builtins.str]]
        """
        The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        project: NotRequired[pulumi.Input[builtins.str]]
        """
        The number of the Fleet host project where this cluster will be registered.
        """
elif False:
    AzureClusterFleetArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterFleetArgs:
    def __init__(__self__, *,
                 membership: Optional[pulumi.Input[builtins.str]] = None,
                 project: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] membership: The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        :param pulumi.Input[builtins.str] project: The number of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @property
    @pulumi.getter
    def membership(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")

    @membership.setter
    def membership(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "membership", value)

    @property
    @pulumi.getter
    def project(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The number of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")

    @project.setter
    def project(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "project", value)


if not MYPY:
    class AzureClusterLoggingConfigArgsDict(TypedDict):
        component_config: NotRequired[pulumi.Input['AzureClusterLoggingConfigComponentConfigArgsDict']]
        """
        Configuration of the logging components.
        """
elif False:
    AzureClusterLoggingConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterLoggingConfigArgs:
    def __init__(__self__, *,
                 component_config: Optional[pulumi.Input['AzureClusterLoggingConfigComponentConfigArgs']] = None):
        """
        :param pulumi.Input['AzureClusterLoggingConfigComponentConfigArgs'] component_config: Configuration of the logging components.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional[pulumi.Input['AzureClusterLoggingConfigComponentConfigArgs']]:
        """
        Configuration of the logging components.
        """
        return pulumi.get(self, "component_config")

    @component_config.setter
    def component_config(self, value: Optional[pulumi.Input['AzureClusterLoggingConfigComponentConfigArgs']]):
        pulumi.set(self, "component_config", value)


if not MYPY:
    class AzureClusterLoggingConfigComponentConfigArgsDict(TypedDict):
        enable_components: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        Components of the logging configuration to be enabled.
        """
elif False:
    AzureClusterLoggingConfigComponentConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterLoggingConfigComponentConfigArgs:
    def __init__(__self__, *,
                 enable_components: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] enable_components: Components of the logging configuration to be enabled.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        Components of the logging configuration to be enabled.
        """
        return pulumi.get(self, "enable_components")

    @enable_components.setter
    def enable_components(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "enable_components", value)


if not MYPY:
    class AzureClusterNetworkingArgsDict(TypedDict):
        pod_address_cidr_blocks: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        The IP address range of the pods in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All pods in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        service_address_cidr_blocks: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        The IP address range for services in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All services in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creating a cluster.
        """
        virtual_network_id: pulumi.Input[builtins.str]
        """
        The Azure Resource Manager (ARM) ID of the VNet associated with your cluster. All components in the cluster (i.e. control plane and node pools) run on a single VNet. Example: `/subscriptions/*/resourceGroups/*/providers/Microsoft.Network/virtualNetworks/*` This field cannot be changed after creation.

        - - -
        """
elif False:
    AzureClusterNetworkingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterNetworkingArgs:
    def __init__(__self__, *,
                 pod_address_cidr_blocks: pulumi.Input[Sequence[pulumi.Input[builtins.str]]],
                 service_address_cidr_blocks: pulumi.Input[Sequence[pulumi.Input[builtins.str]]],
                 virtual_network_id: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] pod_address_cidr_blocks: The IP address range of the pods in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All pods in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] service_address_cidr_blocks: The IP address range for services in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All services in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creating a cluster.
        :param pulumi.Input[builtins.str] virtual_network_id: The Azure Resource Manager (ARM) ID of the VNet associated with your cluster. All components in the cluster (i.e. control plane and node pools) run on a single VNet. Example: `/subscriptions/*/resourceGroups/*/providers/Microsoft.Network/virtualNetworks/*` This field cannot be changed after creation.
               
               - - -
        """
        pulumi.set(__self__, "pod_address_cidr_blocks", pod_address_cidr_blocks)
        pulumi.set(__self__, "service_address_cidr_blocks", service_address_cidr_blocks)
        pulumi.set(__self__, "virtual_network_id", virtual_network_id)

    @property
    @pulumi.getter(name="podAddressCidrBlocks")
    def pod_address_cidr_blocks(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        The IP address range of the pods in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All pods in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "pod_address_cidr_blocks")

    @pod_address_cidr_blocks.setter
    def pod_address_cidr_blocks(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "pod_address_cidr_blocks", value)

    @property
    @pulumi.getter(name="serviceAddressCidrBlocks")
    def service_address_cidr_blocks(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        The IP address range for services in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All services in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creating a cluster.
        """
        return pulumi.get(self, "service_address_cidr_blocks")

    @service_address_cidr_blocks.setter
    def service_address_cidr_blocks(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "service_address_cidr_blocks", value)

    @property
    @pulumi.getter(name="virtualNetworkId")
    def virtual_network_id(self) -> pulumi.Input[builtins.str]:
        """
        The Azure Resource Manager (ARM) ID of the VNet associated with your cluster. All components in the cluster (i.e. control plane and node pools) run on a single VNet. Example: `/subscriptions/*/resourceGroups/*/providers/Microsoft.Network/virtualNetworks/*` This field cannot be changed after creation.

        - - -
        """
        return pulumi.get(self, "virtual_network_id")

    @virtual_network_id.setter
    def virtual_network_id(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "virtual_network_id", value)


if not MYPY:
    class AzureClusterWorkloadIdentityConfigArgsDict(TypedDict):
        identity_provider: NotRequired[pulumi.Input[builtins.str]]
        """
        The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        """
        issuer_uri: NotRequired[pulumi.Input[builtins.str]]
        """
        The OIDC issuer URL for this cluster.
        """
        workload_pool: NotRequired[pulumi.Input[builtins.str]]
        """
        The Workload Identity Pool associated to the cluster.
        """
elif False:
    AzureClusterWorkloadIdentityConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureClusterWorkloadIdentityConfigArgs:
    def __init__(__self__, *,
                 identity_provider: Optional[pulumi.Input[builtins.str]] = None,
                 issuer_uri: Optional[pulumi.Input[builtins.str]] = None,
                 workload_pool: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] identity_provider: The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        :param pulumi.Input[builtins.str] issuer_uri: The OIDC issuer URL for this cluster.
        :param pulumi.Input[builtins.str] workload_pool: The Workload Identity Pool associated to the cluster.
        """
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The ID of the OIDC Identity Provider (IdP) associated to the Workload Identity Pool.
        """
        return pulumi.get(self, "identity_provider")

    @identity_provider.setter
    def identity_provider(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "identity_provider", value)

    @property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The OIDC issuer URL for this cluster.
        """
        return pulumi.get(self, "issuer_uri")

    @issuer_uri.setter
    def issuer_uri(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "issuer_uri", value)

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Workload Identity Pool associated to the cluster.
        """
        return pulumi.get(self, "workload_pool")

    @workload_pool.setter
    def workload_pool(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "workload_pool", value)


if not MYPY:
    class AzureNodePoolAutoscalingArgsDict(TypedDict):
        max_node_count: pulumi.Input[builtins.int]
        """
        Maximum number of nodes in the node pool. Must be >= min_node_count.
        """
        min_node_count: pulumi.Input[builtins.int]
        """
        Minimum number of nodes in the node pool. Must be >= 1 and <= max_node_count.
        """
elif False:
    AzureNodePoolAutoscalingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureNodePoolAutoscalingArgs:
    def __init__(__self__, *,
                 max_node_count: pulumi.Input[builtins.int],
                 min_node_count: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.int] max_node_count: Maximum number of nodes in the node pool. Must be >= min_node_count.
        :param pulumi.Input[builtins.int] min_node_count: Minimum number of nodes in the node pool. Must be >= 1 and <= max_node_count.
        """
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> pulumi.Input[builtins.int]:
        """
        Maximum number of nodes in the node pool. Must be >= min_node_count.
        """
        return pulumi.get(self, "max_node_count")

    @max_node_count.setter
    def max_node_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "max_node_count", value)

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> pulumi.Input[builtins.int]:
        """
        Minimum number of nodes in the node pool. Must be >= 1 and <= max_node_count.
        """
        return pulumi.get(self, "min_node_count")

    @min_node_count.setter
    def min_node_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "min_node_count", value)


if not MYPY:
    class AzureNodePoolConfigArgsDict(TypedDict):
        ssh_config: pulumi.Input['AzureNodePoolConfigSshConfigArgsDict']
        """
        SSH configuration for how to access the node pool machines.
        """
        image_type: NotRequired[pulumi.Input[builtins.str]]
        """
        The OS image type to use on node pool instances.
        """
        labels: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        """
        proxy_config: NotRequired[pulumi.Input['AzureNodePoolConfigProxyConfigArgsDict']]
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        root_volume: NotRequired[pulumi.Input['AzureNodePoolConfigRootVolumeArgsDict']]
        """
        Optional. Configuration related to the root volume provisioned for each node pool machine. When unspecified, it defaults to a 32-GiB Azure Disk.
        """
        tags: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        Optional. A set of tags to apply to all underlying Azure resources for this node pool. This currently only includes Virtual Machine Scale Sets. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        vm_size: NotRequired[pulumi.Input[builtins.str]]
        """
        Optional. The Azure VM size name. Example: `Standard_DS2_v2`. See (/anthos/clusters/docs/azure/reference/supported-vms) for options. When unspecified, it defaults to `Standard_DS2_v2`.
        """
elif False:
    AzureNodePoolConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureNodePoolConfigArgs:
    def __init__(__self__, *,
                 ssh_config: pulumi.Input['AzureNodePoolConfigSshConfigArgs'],
                 image_type: Optional[pulumi.Input[builtins.str]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 proxy_config: Optional[pulumi.Input['AzureNodePoolConfigProxyConfigArgs']] = None,
                 root_volume: Optional[pulumi.Input['AzureNodePoolConfigRootVolumeArgs']] = None,
                 tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 vm_size: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input['AzureNodePoolConfigSshConfigArgs'] ssh_config: SSH configuration for how to access the node pool machines.
        :param pulumi.Input[builtins.str] image_type: The OS image type to use on node pool instances.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] labels: Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        :param pulumi.Input['AzureNodePoolConfigProxyConfigArgs'] proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param pulumi.Input['AzureNodePoolConfigRootVolumeArgs'] root_volume: Optional. Configuration related to the root volume provisioned for each node pool machine. When unspecified, it defaults to a 32-GiB Azure Disk.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] tags: Optional. A set of tags to apply to all underlying Azure resources for this node pool. This currently only includes Virtual Machine Scale Sets. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        :param pulumi.Input[builtins.str] vm_size: Optional. The Azure VM size name. Example: `Standard_DS2_v2`. See (/anthos/clusters/docs/azure/reference/supported-vms) for options. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        pulumi.set(__self__, "ssh_config", ssh_config)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if vm_size is not None:
            pulumi.set(__self__, "vm_size", vm_size)

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> pulumi.Input['AzureNodePoolConfigSshConfigArgs']:
        """
        SSH configuration for how to access the node pool machines.
        """
        return pulumi.get(self, "ssh_config")

    @ssh_config.setter
    def ssh_config(self, value: pulumi.Input['AzureNodePoolConfigSshConfigArgs']):
        pulumi.set(self, "ssh_config", value)

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The OS image type to use on node pool instances.
        """
        return pulumi.get(self, "image_type")

    @image_type.setter
    def image_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "image_type", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional[pulumi.Input['AzureNodePoolConfigProxyConfigArgs']]:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @proxy_config.setter
    def proxy_config(self, value: Optional[pulumi.Input['AzureNodePoolConfigProxyConfigArgs']]):
        pulumi.set(self, "proxy_config", value)

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional[pulumi.Input['AzureNodePoolConfigRootVolumeArgs']]:
        """
        Optional. Configuration related to the root volume provisioned for each node pool machine. When unspecified, it defaults to a 32-GiB Azure Disk.
        """
        return pulumi.get(self, "root_volume")

    @root_volume.setter
    def root_volume(self, value: Optional[pulumi.Input['AzureNodePoolConfigRootVolumeArgs']]):
        pulumi.set(self, "root_volume", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        Optional. A set of tags to apply to all underlying Azure resources for this node pool. This currently only includes Virtual Machine Scale Sets. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter(name="vmSize")
    def vm_size(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Optional. The Azure VM size name. Example: `Standard_DS2_v2`. See (/anthos/clusters/docs/azure/reference/supported-vms) for options. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        return pulumi.get(self, "vm_size")

    @vm_size.setter
    def vm_size(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "vm_size", value)


if not MYPY:
    class AzureNodePoolConfigProxyConfigArgsDict(TypedDict):
        resource_group_id: pulumi.Input[builtins.str]
        """
        The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        """
        secret_id: pulumi.Input[builtins.str]
        """
        The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
elif False:
    AzureNodePoolConfigProxyConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureNodePoolConfigProxyConfigArgs:
    def __init__(__self__, *,
                 resource_group_id: pulumi.Input[builtins.str],
                 secret_id: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] resource_group_id: The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        :param pulumi.Input[builtins.str] secret_id: The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        pulumi.set(__self__, "resource_group_id", resource_group_id)
        pulumi.set(__self__, "secret_id", secret_id)

    @property
    @pulumi.getter(name="resourceGroupId")
    def resource_group_id(self) -> pulumi.Input[builtins.str]:
        """
        The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        """
        return pulumi.get(self, "resource_group_id")

    @resource_group_id.setter
    def resource_group_id(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "resource_group_id", value)

    @property
    @pulumi.getter(name="secretId")
    def secret_id(self) -> pulumi.Input[builtins.str]:
        """
        The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        return pulumi.get(self, "secret_id")

    @secret_id.setter
    def secret_id(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "secret_id", value)


if not MYPY:
    class AzureNodePoolConfigRootVolumeArgsDict(TypedDict):
        size_gib: NotRequired[pulumi.Input[builtins.int]]
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
elif False:
    AzureNodePoolConfigRootVolumeArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureNodePoolConfigRootVolumeArgs:
    def __init__(__self__, *,
                 size_gib: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.int] size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @size_gib.setter
    def size_gib(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "size_gib", value)


if not MYPY:
    class AzureNodePoolConfigSshConfigArgsDict(TypedDict):
        authorized_key: pulumi.Input[builtins.str]
        """
        The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
elif False:
    AzureNodePoolConfigSshConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureNodePoolConfigSshConfigArgs:
    def __init__(__self__, *,
                 authorized_key: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] authorized_key: The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        pulumi.set(__self__, "authorized_key", authorized_key)

    @property
    @pulumi.getter(name="authorizedKey")
    def authorized_key(self) -> pulumi.Input[builtins.str]:
        """
        The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        return pulumi.get(self, "authorized_key")

    @authorized_key.setter
    def authorized_key(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "authorized_key", value)


if not MYPY:
    class AzureNodePoolManagementArgsDict(TypedDict):
        auto_repair: NotRequired[pulumi.Input[builtins.bool]]
        """
        Optional. Whether or not the nodes will be automatically repaired.
        """
elif False:
    AzureNodePoolManagementArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureNodePoolManagementArgs:
    def __init__(__self__, *,
                 auto_repair: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.bool] auto_repair: Optional. Whether or not the nodes will be automatically repaired.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Optional. Whether or not the nodes will be automatically repaired.
        """
        return pulumi.get(self, "auto_repair")

    @auto_repair.setter
    def auto_repair(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "auto_repair", value)


if not MYPY:
    class AzureNodePoolMaxPodsConstraintArgsDict(TypedDict):
        max_pods_per_node: pulumi.Input[builtins.int]
        """
        The maximum number of pods to schedule on a single node.

        - - -
        """
elif False:
    AzureNodePoolMaxPodsConstraintArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class AzureNodePoolMaxPodsConstraintArgs:
    def __init__(__self__, *,
                 max_pods_per_node: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.int] max_pods_per_node: The maximum number of pods to schedule on a single node.
               
               - - -
        """
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> pulumi.Input[builtins.int]:
        """
        The maximum number of pods to schedule on a single node.

        - - -
        """
        return pulumi.get(self, "max_pods_per_node")

    @max_pods_per_node.setter
    def max_pods_per_node(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "max_pods_per_node", value)


if not MYPY:
    class ClusterAddonsConfigArgsDict(TypedDict):
        cloudrun_config: NotRequired[pulumi.Input['ClusterAddonsConfigCloudrunConfigArgsDict']]
        """
        . Structure is documented below.
        """
        config_connector_config: NotRequired[pulumi.Input['ClusterAddonsConfigConfigConnectorConfigArgsDict']]
        """
        .
        The status of the ConfigConnector addon. It is disabled by default; Set `enabled = true` to enable.
        """
        dns_cache_config: NotRequired[pulumi.Input['ClusterAddonsConfigDnsCacheConfigArgsDict']]
        """
        .
        The status of the NodeLocal DNSCache addon. It is disabled by default.
        Set `enabled = true` to enable.

        **Enabling/Disabling NodeLocal DNSCache in an existing cluster is a disruptive operation.
        All cluster nodes running GKE 1.15 and higher are recreated.**
        """
        gce_persistent_disk_csi_driver_config: NotRequired[pulumi.Input['ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgsDict']]
        """
        .
        Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set `enabled = true` to enable.

        **Note:** The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        """
        gcp_filestore_csi_driver_config: NotRequired[pulumi.Input['ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgsDict']]
        """
        The status of the Filestore CSI driver addon,
        which allows the usage of filestore instance as volumes.
        It is disabled by default; set `enabled = true` to enable.
        """
        gcs_fuse_csi_driver_config: NotRequired[pulumi.Input['ClusterAddonsConfigGcsFuseCsiDriverConfigArgsDict']]
        """
        The status of the GCSFuse CSI driver addon,
        which allows the usage of a gcs bucket as volumes.
        It is disabled by default for Standard clusters; set `enabled = true` to enable.
        It is enabled by default for Autopilot clusters with version 1.24 or later; set `enabled = true` to enable it explicitly.
        See [Enable the Cloud Storage FUSE CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver#enable) for more information.
        """
        gke_backup_agent_config: NotRequired[pulumi.Input['ClusterAddonsConfigGkeBackupAgentConfigArgsDict']]
        """
        .
        The status of the Backup for GKE agent addon. It is disabled by default; Set `enabled = true` to enable.
        """
        horizontal_pod_autoscaling: NotRequired[pulumi.Input['ClusterAddonsConfigHorizontalPodAutoscalingArgsDict']]
        """
        The status of the Horizontal Pod Autoscaling
        addon, which increases or decreases the number of replica pods a replication controller
        has based on the resource usage of the existing pods.
        It is enabled by default;
        set `disabled = true` to disable.
        """
        http_load_balancing: NotRequired[pulumi.Input['ClusterAddonsConfigHttpLoadBalancingArgsDict']]
        """
        The status of the HTTP (L7) load balancing
        controller addon, which makes it easy to set up HTTP load balancers for services in a
        cluster. It is enabled by default; set `disabled = true` to disable.
        """
        istio_config: NotRequired[pulumi.Input['ClusterAddonsConfigIstioConfigArgsDict']]
        """
        .
        Structure is documented below.
        """
        kalm_config: NotRequired[pulumi.Input['ClusterAddonsConfigKalmConfigArgsDict']]
        """
        .
        Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set `enabled = true` to enable.
        """
        network_policy_config: NotRequired[pulumi.Input['ClusterAddonsConfigNetworkPolicyConfigArgsDict']]
        """
        Whether we should enable the network policy addon
        for the master.  This must be enabled in order to enable network policy for the nodes.
        To enable this, you must also define a `network_policy` block,
        otherwise nothing will happen.
        It can only be disabled if the nodes already do not have network policies enabled.
        Defaults to disabled; set `disabled = false` to enable.
        """
        parallelstore_csi_driver_config: NotRequired[pulumi.Input['ClusterAddonsConfigParallelstoreCsiDriverConfigArgsDict']]
        """
        The status of the Parallelstore CSI driver addon,
        which allows the usage of a Parallelstore instances as volumes.
        It is disabled by default for Standard clusters; set `enabled = true` to enable.
        It is enabled by default for Autopilot clusters with version 1.29 or later; set `enabled = true` to enable it explicitly.
        See [Enable the Parallelstore CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/parallelstore-csi-new-volume#enable) for more information.

        This example `addons_config` disables two addons:
        """
        ray_operator_configs: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterAddonsConfigRayOperatorConfigArgsDict']]]]
        """
        . The status of the [Ray Operator
        addon](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/concepts/overview).
        It is disabled by default. Set `enabled = true` to enable. The minimum
        cluster version to enable Ray is 1.30.0-gke.1747000.

        Ray Operator config has optional subfields
        `ray_cluster_logging_config.enabled` and
        `ray_cluster_monitoring_config.enabled` which control Ray Cluster logging
        and monitoring respectively. See [Collect and view logs and metrics for Ray
        clusters on
        GKE](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/how-to/collect-view-logs-metrics)
        for more information.
        """
        stateful_ha_config: NotRequired[pulumi.Input['ClusterAddonsConfigStatefulHaConfigArgsDict']]
        """
        .
        The status of the Stateful HA addon, which provides automatic configurable failover for stateful applications.
        It is disabled by default for Standard clusters. Set `enabled = true` to enable.
        """
elif False:
    ClusterAddonsConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigArgs:
    def __init__(__self__, *,
                 cloudrun_config: Optional[pulumi.Input['ClusterAddonsConfigCloudrunConfigArgs']] = None,
                 config_connector_config: Optional[pulumi.Input['ClusterAddonsConfigConfigConnectorConfigArgs']] = None,
                 dns_cache_config: Optional[pulumi.Input['ClusterAddonsConfigDnsCacheConfigArgs']] = None,
                 gce_persistent_disk_csi_driver_config: Optional[pulumi.Input['ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs']] = None,
                 gcp_filestore_csi_driver_config: Optional[pulumi.Input['ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs']] = None,
                 gcs_fuse_csi_driver_config: Optional[pulumi.Input['ClusterAddonsConfigGcsFuseCsiDriverConfigArgs']] = None,
                 gke_backup_agent_config: Optional[pulumi.Input['ClusterAddonsConfigGkeBackupAgentConfigArgs']] = None,
                 horizontal_pod_autoscaling: Optional[pulumi.Input['ClusterAddonsConfigHorizontalPodAutoscalingArgs']] = None,
                 http_load_balancing: Optional[pulumi.Input['ClusterAddonsConfigHttpLoadBalancingArgs']] = None,
                 istio_config: Optional[pulumi.Input['ClusterAddonsConfigIstioConfigArgs']] = None,
                 kalm_config: Optional[pulumi.Input['ClusterAddonsConfigKalmConfigArgs']] = None,
                 network_policy_config: Optional[pulumi.Input['ClusterAddonsConfigNetworkPolicyConfigArgs']] = None,
                 parallelstore_csi_driver_config: Optional[pulumi.Input['ClusterAddonsConfigParallelstoreCsiDriverConfigArgs']] = None,
                 ray_operator_configs: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterAddonsConfigRayOperatorConfigArgs']]]] = None,
                 stateful_ha_config: Optional[pulumi.Input['ClusterAddonsConfigStatefulHaConfigArgs']] = None):
        """
        :param pulumi.Input['ClusterAddonsConfigCloudrunConfigArgs'] cloudrun_config: . Structure is documented below.
        :param pulumi.Input['ClusterAddonsConfigConfigConnectorConfigArgs'] config_connector_config: .
               The status of the ConfigConnector addon. It is disabled by default; Set `enabled = true` to enable.
        :param pulumi.Input['ClusterAddonsConfigDnsCacheConfigArgs'] dns_cache_config: .
               The status of the NodeLocal DNSCache addon. It is disabled by default.
               Set `enabled = true` to enable.
               
               **Enabling/Disabling NodeLocal DNSCache in an existing cluster is a disruptive operation.
               All cluster nodes running GKE 1.15 and higher are recreated.**
        :param pulumi.Input['ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs'] gce_persistent_disk_csi_driver_config: .
               Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set `enabled = true` to enable.
               
               **Note:** The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        :param pulumi.Input['ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs'] gcp_filestore_csi_driver_config: The status of the Filestore CSI driver addon,
               which allows the usage of filestore instance as volumes.
               It is disabled by default; set `enabled = true` to enable.
        :param pulumi.Input['ClusterAddonsConfigGcsFuseCsiDriverConfigArgs'] gcs_fuse_csi_driver_config: The status of the GCSFuse CSI driver addon,
               which allows the usage of a gcs bucket as volumes.
               It is disabled by default for Standard clusters; set `enabled = true` to enable.
               It is enabled by default for Autopilot clusters with version 1.24 or later; set `enabled = true` to enable it explicitly.
               See [Enable the Cloud Storage FUSE CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver#enable) for more information.
        :param pulumi.Input['ClusterAddonsConfigGkeBackupAgentConfigArgs'] gke_backup_agent_config: .
               The status of the Backup for GKE agent addon. It is disabled by default; Set `enabled = true` to enable.
        :param pulumi.Input['ClusterAddonsConfigHorizontalPodAutoscalingArgs'] horizontal_pod_autoscaling: The status of the Horizontal Pod Autoscaling
               addon, which increases or decreases the number of replica pods a replication controller
               has based on the resource usage of the existing pods.
               It is enabled by default;
               set `disabled = true` to disable.
        :param pulumi.Input['ClusterAddonsConfigHttpLoadBalancingArgs'] http_load_balancing: The status of the HTTP (L7) load balancing
               controller addon, which makes it easy to set up HTTP load balancers for services in a
               cluster. It is enabled by default; set `disabled = true` to disable.
        :param pulumi.Input['ClusterAddonsConfigIstioConfigArgs'] istio_config: .
               Structure is documented below.
        :param pulumi.Input['ClusterAddonsConfigKalmConfigArgs'] kalm_config: .
               Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set `enabled = true` to enable.
        :param pulumi.Input['ClusterAddonsConfigNetworkPolicyConfigArgs'] network_policy_config: Whether we should enable the network policy addon
               for the master.  This must be enabled in order to enable network policy for the nodes.
               To enable this, you must also define a `network_policy` block,
               otherwise nothing will happen.
               It can only be disabled if the nodes already do not have network policies enabled.
               Defaults to disabled; set `disabled = false` to enable.
        :param pulumi.Input['ClusterAddonsConfigParallelstoreCsiDriverConfigArgs'] parallelstore_csi_driver_config: The status of the Parallelstore CSI driver addon,
               which allows the usage of a Parallelstore instances as volumes.
               It is disabled by default for Standard clusters; set `enabled = true` to enable.
               It is enabled by default for Autopilot clusters with version 1.29 or later; set `enabled = true` to enable it explicitly.
               See [Enable the Parallelstore CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/parallelstore-csi-new-volume#enable) for more information.
               
               This example `addons_config` disables two addons:
        :param pulumi.Input[Sequence[pulumi.Input['ClusterAddonsConfigRayOperatorConfigArgs']]] ray_operator_configs: . The status of the [Ray Operator
               addon](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/concepts/overview).
               It is disabled by default. Set `enabled = true` to enable. The minimum
               cluster version to enable Ray is 1.30.0-gke.1747000.
               
               Ray Operator config has optional subfields
               `ray_cluster_logging_config.enabled` and
               `ray_cluster_monitoring_config.enabled` which control Ray Cluster logging
               and monitoring respectively. See [Collect and view logs and metrics for Ray
               clusters on
               GKE](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/how-to/collect-view-logs-metrics)
               for more information.
        :param pulumi.Input['ClusterAddonsConfigStatefulHaConfigArgs'] stateful_ha_config: .
               The status of the Stateful HA addon, which provides automatic configurable failover for stateful applications.
               It is disabled by default for Standard clusters. Set `enabled = true` to enable.
        """
        if cloudrun_config is not None:
            pulumi.set(__self__, "cloudrun_config", cloudrun_config)
        if config_connector_config is not None:
            pulumi.set(__self__, "config_connector_config", config_connector_config)
        if dns_cache_config is not None:
            pulumi.set(__self__, "dns_cache_config", dns_cache_config)
        if gce_persistent_disk_csi_driver_config is not None:
            pulumi.set(__self__, "gce_persistent_disk_csi_driver_config", gce_persistent_disk_csi_driver_config)
        if gcp_filestore_csi_driver_config is not None:
            pulumi.set(__self__, "gcp_filestore_csi_driver_config", gcp_filestore_csi_driver_config)
        if gcs_fuse_csi_driver_config is not None:
            pulumi.set(__self__, "gcs_fuse_csi_driver_config", gcs_fuse_csi_driver_config)
        if gke_backup_agent_config is not None:
            pulumi.set(__self__, "gke_backup_agent_config", gke_backup_agent_config)
        if horizontal_pod_autoscaling is not None:
            pulumi.set(__self__, "horizontal_pod_autoscaling", horizontal_pod_autoscaling)
        if http_load_balancing is not None:
            pulumi.set(__self__, "http_load_balancing", http_load_balancing)
        if istio_config is not None:
            pulumi.set(__self__, "istio_config", istio_config)
        if kalm_config is not None:
            pulumi.set(__self__, "kalm_config", kalm_config)
        if network_policy_config is not None:
            pulumi.set(__self__, "network_policy_config", network_policy_config)
        if parallelstore_csi_driver_config is not None:
            pulumi.set(__self__, "parallelstore_csi_driver_config", parallelstore_csi_driver_config)
        if ray_operator_configs is not None:
            pulumi.set(__self__, "ray_operator_configs", ray_operator_configs)
        if stateful_ha_config is not None:
            pulumi.set(__self__, "stateful_ha_config", stateful_ha_config)

    @property
    @pulumi.getter(name="cloudrunConfig")
    def cloudrun_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigCloudrunConfigArgs']]:
        """
        . Structure is documented below.
        """
        return pulumi.get(self, "cloudrun_config")

    @cloudrun_config.setter
    def cloudrun_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigCloudrunConfigArgs']]):
        pulumi.set(self, "cloudrun_config", value)

    @property
    @pulumi.getter(name="configConnectorConfig")
    def config_connector_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigConfigConnectorConfigArgs']]:
        """
        .
        The status of the ConfigConnector addon. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "config_connector_config")

    @config_connector_config.setter
    def config_connector_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigConfigConnectorConfigArgs']]):
        pulumi.set(self, "config_connector_config", value)

    @property
    @pulumi.getter(name="dnsCacheConfig")
    def dns_cache_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigDnsCacheConfigArgs']]:
        """
        .
        The status of the NodeLocal DNSCache addon. It is disabled by default.
        Set `enabled = true` to enable.

        **Enabling/Disabling NodeLocal DNSCache in an existing cluster is a disruptive operation.
        All cluster nodes running GKE 1.15 and higher are recreated.**
        """
        return pulumi.get(self, "dns_cache_config")

    @dns_cache_config.setter
    def dns_cache_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigDnsCacheConfigArgs']]):
        pulumi.set(self, "dns_cache_config", value)

    @property
    @pulumi.getter(name="gcePersistentDiskCsiDriverConfig")
    def gce_persistent_disk_csi_driver_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs']]:
        """
        .
        Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set `enabled = true` to enable.

        **Note:** The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        """
        return pulumi.get(self, "gce_persistent_disk_csi_driver_config")

    @gce_persistent_disk_csi_driver_config.setter
    def gce_persistent_disk_csi_driver_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs']]):
        pulumi.set(self, "gce_persistent_disk_csi_driver_config", value)

    @property
    @pulumi.getter(name="gcpFilestoreCsiDriverConfig")
    def gcp_filestore_csi_driver_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs']]:
        """
        The status of the Filestore CSI driver addon,
        which allows the usage of filestore instance as volumes.
        It is disabled by default; set `enabled = true` to enable.
        """
        return pulumi.get(self, "gcp_filestore_csi_driver_config")

    @gcp_filestore_csi_driver_config.setter
    def gcp_filestore_csi_driver_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs']]):
        pulumi.set(self, "gcp_filestore_csi_driver_config", value)

    @property
    @pulumi.getter(name="gcsFuseCsiDriverConfig")
    def gcs_fuse_csi_driver_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigGcsFuseCsiDriverConfigArgs']]:
        """
        The status of the GCSFuse CSI driver addon,
        which allows the usage of a gcs bucket as volumes.
        It is disabled by default for Standard clusters; set `enabled = true` to enable.
        It is enabled by default for Autopilot clusters with version 1.24 or later; set `enabled = true` to enable it explicitly.
        See [Enable the Cloud Storage FUSE CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver#enable) for more information.
        """
        return pulumi.get(self, "gcs_fuse_csi_driver_config")

    @gcs_fuse_csi_driver_config.setter
    def gcs_fuse_csi_driver_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigGcsFuseCsiDriverConfigArgs']]):
        pulumi.set(self, "gcs_fuse_csi_driver_config", value)

    @property
    @pulumi.getter(name="gkeBackupAgentConfig")
    def gke_backup_agent_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigGkeBackupAgentConfigArgs']]:
        """
        .
        The status of the Backup for GKE agent addon. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "gke_backup_agent_config")

    @gke_backup_agent_config.setter
    def gke_backup_agent_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigGkeBackupAgentConfigArgs']]):
        pulumi.set(self, "gke_backup_agent_config", value)

    @property
    @pulumi.getter(name="horizontalPodAutoscaling")
    def horizontal_pod_autoscaling(self) -> Optional[pulumi.Input['ClusterAddonsConfigHorizontalPodAutoscalingArgs']]:
        """
        The status of the Horizontal Pod Autoscaling
        addon, which increases or decreases the number of replica pods a replication controller
        has based on the resource usage of the existing pods.
        It is enabled by default;
        set `disabled = true` to disable.
        """
        return pulumi.get(self, "horizontal_pod_autoscaling")

    @horizontal_pod_autoscaling.setter
    def horizontal_pod_autoscaling(self, value: Optional[pulumi.Input['ClusterAddonsConfigHorizontalPodAutoscalingArgs']]):
        pulumi.set(self, "horizontal_pod_autoscaling", value)

    @property
    @pulumi.getter(name="httpLoadBalancing")
    def http_load_balancing(self) -> Optional[pulumi.Input['ClusterAddonsConfigHttpLoadBalancingArgs']]:
        """
        The status of the HTTP (L7) load balancing
        controller addon, which makes it easy to set up HTTP load balancers for services in a
        cluster. It is enabled by default; set `disabled = true` to disable.
        """
        return pulumi.get(self, "http_load_balancing")

    @http_load_balancing.setter
    def http_load_balancing(self, value: Optional[pulumi.Input['ClusterAddonsConfigHttpLoadBalancingArgs']]):
        pulumi.set(self, "http_load_balancing", value)

    @property
    @pulumi.getter(name="istioConfig")
    def istio_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigIstioConfigArgs']]:
        """
        .
        Structure is documented below.
        """
        return pulumi.get(self, "istio_config")

    @istio_config.setter
    def istio_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigIstioConfigArgs']]):
        pulumi.set(self, "istio_config", value)

    @property
    @pulumi.getter(name="kalmConfig")
    def kalm_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigKalmConfigArgs']]:
        """
        .
        Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "kalm_config")

    @kalm_config.setter
    def kalm_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigKalmConfigArgs']]):
        pulumi.set(self, "kalm_config", value)

    @property
    @pulumi.getter(name="networkPolicyConfig")
    def network_policy_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigNetworkPolicyConfigArgs']]:
        """
        Whether we should enable the network policy addon
        for the master.  This must be enabled in order to enable network policy for the nodes.
        To enable this, you must also define a `network_policy` block,
        otherwise nothing will happen.
        It can only be disabled if the nodes already do not have network policies enabled.
        Defaults to disabled; set `disabled = false` to enable.
        """
        return pulumi.get(self, "network_policy_config")

    @network_policy_config.setter
    def network_policy_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigNetworkPolicyConfigArgs']]):
        pulumi.set(self, "network_policy_config", value)

    @property
    @pulumi.getter(name="parallelstoreCsiDriverConfig")
    def parallelstore_csi_driver_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigParallelstoreCsiDriverConfigArgs']]:
        """
        The status of the Parallelstore CSI driver addon,
        which allows the usage of a Parallelstore instances as volumes.
        It is disabled by default for Standard clusters; set `enabled = true` to enable.
        It is enabled by default for Autopilot clusters with version 1.29 or later; set `enabled = true` to enable it explicitly.
        See [Enable the Parallelstore CSI driver](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/parallelstore-csi-new-volume#enable) for more information.

        This example `addons_config` disables two addons:
        """
        return pulumi.get(self, "parallelstore_csi_driver_config")

    @parallelstore_csi_driver_config.setter
    def parallelstore_csi_driver_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigParallelstoreCsiDriverConfigArgs']]):
        pulumi.set(self, "parallelstore_csi_driver_config", value)

    @property
    @pulumi.getter(name="rayOperatorConfigs")
    def ray_operator_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterAddonsConfigRayOperatorConfigArgs']]]]:
        """
        . The status of the [Ray Operator
        addon](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/concepts/overview).
        It is disabled by default. Set `enabled = true` to enable. The minimum
        cluster version to enable Ray is 1.30.0-gke.1747000.

        Ray Operator config has optional subfields
        `ray_cluster_logging_config.enabled` and
        `ray_cluster_monitoring_config.enabled` which control Ray Cluster logging
        and monitoring respectively. See [Collect and view logs and metrics for Ray
        clusters on
        GKE](https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/how-to/collect-view-logs-metrics)
        for more information.
        """
        return pulumi.get(self, "ray_operator_configs")

    @ray_operator_configs.setter
    def ray_operator_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterAddonsConfigRayOperatorConfigArgs']]]]):
        pulumi.set(self, "ray_operator_configs", value)

    @property
    @pulumi.getter(name="statefulHaConfig")
    def stateful_ha_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigStatefulHaConfigArgs']]:
        """
        .
        The status of the Stateful HA addon, which provides automatic configurable failover for stateful applications.
        It is disabled by default for Standard clusters. Set `enabled = true` to enable.
        """
        return pulumi.get(self, "stateful_ha_config")

    @stateful_ha_config.setter
    def stateful_ha_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigStatefulHaConfigArgs']]):
        pulumi.set(self, "stateful_ha_config", value)


if not MYPY:
    class ClusterAddonsConfigCloudrunConfigArgsDict(TypedDict):
        disabled: pulumi.Input[builtins.bool]
        """
        The status of the CloudRun addon. It is disabled by default. Set `disabled=false` to enable.
        """
        load_balancer_type: NotRequired[pulumi.Input[builtins.str]]
        """
        The load balancer type of CloudRun ingress service. It is external load balancer by default.
        Set `load_balancer_type=LOAD_BALANCER_TYPE_INTERNAL` to configure it as internal load balancer.
        """
elif False:
    ClusterAddonsConfigCloudrunConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigCloudrunConfigArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[builtins.bool],
                 load_balancer_type: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.bool] disabled: The status of the CloudRun addon. It is disabled by default. Set `disabled=false` to enable.
        :param pulumi.Input[builtins.str] load_balancer_type: The load balancer type of CloudRun ingress service. It is external load balancer by default.
               Set `load_balancer_type=LOAD_BALANCER_TYPE_INTERNAL` to configure it as internal load balancer.
        """
        pulumi.set(__self__, "disabled", disabled)
        if load_balancer_type is not None:
            pulumi.set(__self__, "load_balancer_type", load_balancer_type)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[builtins.bool]:
        """
        The status of the CloudRun addon. It is disabled by default. Set `disabled=false` to enable.
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "disabled", value)

    @property
    @pulumi.getter(name="loadBalancerType")
    def load_balancer_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The load balancer type of CloudRun ingress service. It is external load balancer by default.
        Set `load_balancer_type=LOAD_BALANCER_TYPE_INTERNAL` to configure it as internal load balancer.
        """
        return pulumi.get(self, "load_balancer_type")

    @load_balancer_type.setter
    def load_balancer_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "load_balancer_type", value)


if not MYPY:
    class ClusterAddonsConfigConfigConnectorConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
elif False:
    ClusterAddonsConfigConfigConnectorConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigConfigConnectorConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterAddonsConfigDnsCacheConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
elif False:
    ClusterAddonsConfigDnsCacheConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigDnsCacheConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
elif False:
    ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
elif False:
    ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterAddonsConfigGcsFuseCsiDriverConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
elif False:
    ClusterAddonsConfigGcsFuseCsiDriverConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigGcsFuseCsiDriverConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterAddonsConfigGkeBackupAgentConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
elif False:
    ClusterAddonsConfigGkeBackupAgentConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigGkeBackupAgentConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterAddonsConfigHorizontalPodAutoscalingArgsDict(TypedDict):
        disabled: pulumi.Input[builtins.bool]
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
elif False:
    ClusterAddonsConfigHorizontalPodAutoscalingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigHorizontalPodAutoscalingArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "disabled", value)


if not MYPY:
    class ClusterAddonsConfigHttpLoadBalancingArgsDict(TypedDict):
        disabled: pulumi.Input[builtins.bool]
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
elif False:
    ClusterAddonsConfigHttpLoadBalancingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigHttpLoadBalancingArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "disabled", value)


if not MYPY:
    class ClusterAddonsConfigIstioConfigArgsDict(TypedDict):
        disabled: pulumi.Input[builtins.bool]
        """
        The status of the Istio addon, which makes it easy to set up Istio for services in a
        cluster. It is disabled by default. Set `disabled = false` to enable.
        """
        auth: NotRequired[pulumi.Input[builtins.str]]
        """
        The authentication type between services in Istio. Available options include `AUTH_MUTUAL_TLS`.
        """
elif False:
    ClusterAddonsConfigIstioConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigIstioConfigArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[builtins.bool],
                 auth: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.bool] disabled: The status of the Istio addon, which makes it easy to set up Istio for services in a
               cluster. It is disabled by default. Set `disabled = false` to enable.
        :param pulumi.Input[builtins.str] auth: The authentication type between services in Istio. Available options include `AUTH_MUTUAL_TLS`.
        """
        pulumi.set(__self__, "disabled", disabled)
        if auth is not None:
            pulumi.set(__self__, "auth", auth)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[builtins.bool]:
        """
        The status of the Istio addon, which makes it easy to set up Istio for services in a
        cluster. It is disabled by default. Set `disabled = false` to enable.
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "disabled", value)

    @property
    @pulumi.getter
    def auth(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The authentication type between services in Istio. Available options include `AUTH_MUTUAL_TLS`.
        """
        return pulumi.get(self, "auth")

    @auth.setter
    def auth(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "auth", value)


if not MYPY:
    class ClusterAddonsConfigKalmConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
elif False:
    ClusterAddonsConfigKalmConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigKalmConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterAddonsConfigNetworkPolicyConfigArgsDict(TypedDict):
        disabled: pulumi.Input[builtins.bool]
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
elif False:
    ClusterAddonsConfigNetworkPolicyConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigNetworkPolicyConfigArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "disabled", value)


if not MYPY:
    class ClusterAddonsConfigParallelstoreCsiDriverConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
elif False:
    ClusterAddonsConfigParallelstoreCsiDriverConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigParallelstoreCsiDriverConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterAddonsConfigRayOperatorConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        ray_cluster_logging_config: NotRequired[pulumi.Input['ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgsDict']]
        """
        The status of Ray Logging, which scrapes Ray cluster logs to Cloud Logging. Defaults to disabled; set enabled = true to enable.
        """
        ray_cluster_monitoring_config: NotRequired[pulumi.Input['ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgsDict']]
        """
        The status of Ray Cluster monitoring, which shows Ray cluster metrics in Cloud Console. Defaults to disabled; set enabled = true to enable.
        """
elif False:
    ClusterAddonsConfigRayOperatorConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigRayOperatorConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool],
                 ray_cluster_logging_config: Optional[pulumi.Input['ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgs']] = None,
                 ray_cluster_monitoring_config: Optional[pulumi.Input['ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgs']] = None):
        """
        :param pulumi.Input['ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgs'] ray_cluster_logging_config: The status of Ray Logging, which scrapes Ray cluster logs to Cloud Logging. Defaults to disabled; set enabled = true to enable.
        :param pulumi.Input['ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgs'] ray_cluster_monitoring_config: The status of Ray Cluster monitoring, which shows Ray cluster metrics in Cloud Console. Defaults to disabled; set enabled = true to enable.
        """
        pulumi.set(__self__, "enabled", enabled)
        if ray_cluster_logging_config is not None:
            pulumi.set(__self__, "ray_cluster_logging_config", ray_cluster_logging_config)
        if ray_cluster_monitoring_config is not None:
            pulumi.set(__self__, "ray_cluster_monitoring_config", ray_cluster_monitoring_config)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter(name="rayClusterLoggingConfig")
    def ray_cluster_logging_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgs']]:
        """
        The status of Ray Logging, which scrapes Ray cluster logs to Cloud Logging. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "ray_cluster_logging_config")

    @ray_cluster_logging_config.setter
    def ray_cluster_logging_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgs']]):
        pulumi.set(self, "ray_cluster_logging_config", value)

    @property
    @pulumi.getter(name="rayClusterMonitoringConfig")
    def ray_cluster_monitoring_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgs']]:
        """
        The status of Ray Cluster monitoring, which shows Ray cluster metrics in Cloud Console. Defaults to disabled; set enabled = true to enable.
        """
        return pulumi.get(self, "ray_cluster_monitoring_config")

    @ray_cluster_monitoring_config.setter
    def ray_cluster_monitoring_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgs']]):
        pulumi.set(self, "ray_cluster_monitoring_config", value)


if not MYPY:
    class ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
elif False:
    ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigRayOperatorConfigRayClusterLoggingConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
elif False:
    ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigRayOperatorConfigRayClusterMonitoringConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterAddonsConfigStatefulHaConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
elif False:
    ClusterAddonsConfigStatefulHaConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAddonsConfigStatefulHaConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterAuthenticatorGroupsConfigArgsDict(TypedDict):
        security_group: pulumi.Input[builtins.str]
        """
        The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format `gke-security-groups@yourdomain.com`.
        """
elif False:
    ClusterAuthenticatorGroupsConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAuthenticatorGroupsConfigArgs:
    def __init__(__self__, *,
                 security_group: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] security_group: The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format `gke-security-groups@yourdomain.com`.
        """
        pulumi.set(__self__, "security_group", security_group)

    @property
    @pulumi.getter(name="securityGroup")
    def security_group(self) -> pulumi.Input[builtins.str]:
        """
        The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format `gke-security-groups@yourdomain.com`.
        """
        return pulumi.get(self, "security_group")

    @security_group.setter
    def security_group(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "security_group", value)


if not MYPY:
    class ClusterBinaryAuthorizationArgsDict(TypedDict):
        enabled: NotRequired[pulumi.Input[builtins.bool]]
        """
        Enable Binary Authorization for this cluster.
        """
        evaluation_mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Mode of operation for Binary Authorization policy evaluation.
        """
elif False:
    ClusterBinaryAuthorizationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterBinaryAuthorizationArgs:
    def __init__(__self__, *,
                 enabled: Optional[pulumi.Input[builtins.bool]] = None,
                 evaluation_mode: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.bool] enabled: Enable Binary Authorization for this cluster.
        :param pulumi.Input[builtins.str] evaluation_mode: Mode of operation for Binary Authorization policy evaluation.
        """
        if enabled is not None:
            warnings.warn("""Deprecated in favor of evaluation_mode.""", DeprecationWarning)
            pulumi.log.warn("""enabled is deprecated: Deprecated in favor of evaluation_mode.""")
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @property
    @pulumi.getter
    @_utilities.deprecated("""Deprecated in favor of evaluation_mode.""")
    def enabled(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Enable Binary Authorization for this cluster.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Mode of operation for Binary Authorization policy evaluation.
        """
        return pulumi.get(self, "evaluation_mode")

    @evaluation_mode.setter
    def evaluation_mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "evaluation_mode", value)


if not MYPY:
    class ClusterClusterAutoscalingArgsDict(TypedDict):
        auto_provisioning_defaults: NotRequired[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsArgsDict']]
        """
        Contains defaults for a node pool created by NAP. A subset of fields also apply to
        GKE Autopilot clusters.
        Structure is documented below.
        """
        auto_provisioning_locations: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The list of Google Compute Engine
        [zones](https://cloud.google.com/compute/docs/zones#available) in which the
        NodePool's nodes can be created by NAP.
        """
        autoscaling_profile: NotRequired[pulumi.Input[builtins.str]]
        """
        Configuration
        options for the [Autoscaling profile](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler#autoscaling_profiles)
        feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability
        when deciding to remove nodes from a cluster. Can be `BALANCED` or `OPTIMIZE_UTILIZATION`. Defaults to `BALANCED`.
        """
        enabled: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether node auto-provisioning is enabled. Must be supplied for GKE Standard clusters, `true` is implied
        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
        """
        resource_limits: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingResourceLimitArgsDict']]]]
        """
        Global constraints for machine resources in the
        cluster. Configuring the `cpu` and `memory` types is required if node
        auto-provisioning is enabled. These limits will apply to node pool autoscaling
        in addition to node auto-provisioning. Structure is documented below.
        """
elif False:
    ClusterClusterAutoscalingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterClusterAutoscalingArgs:
    def __init__(__self__, *,
                 auto_provisioning_defaults: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsArgs']] = None,
                 auto_provisioning_locations: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 autoscaling_profile: Optional[pulumi.Input[builtins.str]] = None,
                 enabled: Optional[pulumi.Input[builtins.bool]] = None,
                 resource_limits: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingResourceLimitArgs']]]] = None):
        """
        :param pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsArgs'] auto_provisioning_defaults: Contains defaults for a node pool created by NAP. A subset of fields also apply to
               GKE Autopilot clusters.
               Structure is documented below.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] auto_provisioning_locations: The list of Google Compute Engine
               [zones](https://cloud.google.com/compute/docs/zones#available) in which the
               NodePool's nodes can be created by NAP.
        :param pulumi.Input[builtins.str] autoscaling_profile: Configuration
               options for the [Autoscaling profile](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler#autoscaling_profiles)
               feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability
               when deciding to remove nodes from a cluster. Can be `BALANCED` or `OPTIMIZE_UTILIZATION`. Defaults to `BALANCED`.
        :param pulumi.Input[builtins.bool] enabled: Whether node auto-provisioning is enabled. Must be supplied for GKE Standard clusters, `true` is implied
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingResourceLimitArgs']]] resource_limits: Global constraints for machine resources in the
               cluster. Configuring the `cpu` and `memory` types is required if node
               auto-provisioning is enabled. These limits will apply to node pool autoscaling
               in addition to node auto-provisioning. Structure is documented below.
        """
        if auto_provisioning_defaults is not None:
            pulumi.set(__self__, "auto_provisioning_defaults", auto_provisioning_defaults)
        if auto_provisioning_locations is not None:
            pulumi.set(__self__, "auto_provisioning_locations", auto_provisioning_locations)
        if autoscaling_profile is not None:
            pulumi.set(__self__, "autoscaling_profile", autoscaling_profile)
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if resource_limits is not None:
            pulumi.set(__self__, "resource_limits", resource_limits)

    @property
    @pulumi.getter(name="autoProvisioningDefaults")
    def auto_provisioning_defaults(self) -> Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsArgs']]:
        """
        Contains defaults for a node pool created by NAP. A subset of fields also apply to
        GKE Autopilot clusters.
        Structure is documented below.
        """
        return pulumi.get(self, "auto_provisioning_defaults")

    @auto_provisioning_defaults.setter
    def auto_provisioning_defaults(self, value: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsArgs']]):
        pulumi.set(self, "auto_provisioning_defaults", value)

    @property
    @pulumi.getter(name="autoProvisioningLocations")
    def auto_provisioning_locations(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The list of Google Compute Engine
        [zones](https://cloud.google.com/compute/docs/zones#available) in which the
        NodePool's nodes can be created by NAP.
        """
        return pulumi.get(self, "auto_provisioning_locations")

    @auto_provisioning_locations.setter
    def auto_provisioning_locations(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "auto_provisioning_locations", value)

    @property
    @pulumi.getter(name="autoscalingProfile")
    def autoscaling_profile(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Configuration
        options for the [Autoscaling profile](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler#autoscaling_profiles)
        feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability
        when deciding to remove nodes from a cluster. Can be `BALANCED` or `OPTIMIZE_UTILIZATION`. Defaults to `BALANCED`.
        """
        return pulumi.get(self, "autoscaling_profile")

    @autoscaling_profile.setter
    def autoscaling_profile(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "autoscaling_profile", value)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether node auto-provisioning is enabled. Must be supplied for GKE Standard clusters, `true` is implied
        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter(name="resourceLimits")
    def resource_limits(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingResourceLimitArgs']]]]:
        """
        Global constraints for machine resources in the
        cluster. Configuring the `cpu` and `memory` types is required if node
        auto-provisioning is enabled. These limits will apply to node pool autoscaling
        in addition to node auto-provisioning. Structure is documented below.
        """
        return pulumi.get(self, "resource_limits")

    @resource_limits.setter
    def resource_limits(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingResourceLimitArgs']]]]):
        pulumi.set(self, "resource_limits", value)


if not MYPY:
    class ClusterClusterAutoscalingAutoProvisioningDefaultsArgsDict(TypedDict):
        boot_disk_kms_key: NotRequired[pulumi.Input[builtins.str]]
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
        """
        disk_size: NotRequired[pulumi.Input[builtins.int]]
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. Defaults to `100`
        """
        disk_type: NotRequired[pulumi.Input[builtins.str]]
        """
        Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd', 'pd-balanced', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`.
        """
        image_type: NotRequired[pulumi.Input[builtins.str]]
        """
        The default image type used by NAP once a new node pool is being created. Please note that according to the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning#default-image-type) the value must be one of the [COS_CONTAINERD, COS, UBUNTU_CONTAINERD, UBUNTU]. __NOTE__ : COS AND UBUNTU are deprecated as of `GKE 1.24`
        """
        management: NotRequired[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgsDict']]
        """
        NodeManagement configuration for this NodePool. Structure is documented below.
        """
        min_cpu_platform: NotRequired[pulumi.Input[builtins.str]]
        """
        Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the
        specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such
        as "Intel Haswell" or "Intel Sandy Bridge".
        """
        oauth_scopes: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        Scopes that are used by NAP and GKE Autopilot when creating node pools. Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        > `monitoring.write` is always enabled regardless of user input.  `monitoring` and `logging.write` may also be enabled depending on the values for `monitoring_service` and `logging_service`.
        """
        service_account: NotRequired[pulumi.Input[builtins.str]]
        """
        The `email` of the Google Cloud Platform Service Account to be used by the node VMs created by GKE Autopilot or NAP.
        """
        shielded_instance_config: NotRequired[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgsDict']]
        """
        Shielded Instance options. Structure is documented below.
        """
        upgrade_settings: NotRequired[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgsDict']]
        """
        Specifies the upgrade settings for NAP created node pools
        """
elif False:
    ClusterClusterAutoscalingAutoProvisioningDefaultsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsArgs:
    def __init__(__self__, *,
                 boot_disk_kms_key: Optional[pulumi.Input[builtins.str]] = None,
                 disk_size: Optional[pulumi.Input[builtins.int]] = None,
                 disk_type: Optional[pulumi.Input[builtins.str]] = None,
                 image_type: Optional[pulumi.Input[builtins.str]] = None,
                 management: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs']] = None,
                 min_cpu_platform: Optional[pulumi.Input[builtins.str]] = None,
                 oauth_scopes: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 service_account: Optional[pulumi.Input[builtins.str]] = None,
                 shielded_instance_config: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs']] = None,
                 upgrade_settings: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs']] = None):
        """
        :param pulumi.Input[builtins.str] boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
        :param pulumi.Input[builtins.int] disk_size: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. Defaults to `100`
        :param pulumi.Input[builtins.str] disk_type: Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd', 'pd-balanced', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`.
        :param pulumi.Input[builtins.str] image_type: The default image type used by NAP once a new node pool is being created. Please note that according to the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning#default-image-type) the value must be one of the [COS_CONTAINERD, COS, UBUNTU_CONTAINERD, UBUNTU]. __NOTE__ : COS AND UBUNTU are deprecated as of `GKE 1.24`
        :param pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs'] management: NodeManagement configuration for this NodePool. Structure is documented below.
        :param pulumi.Input[builtins.str] min_cpu_platform: Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the
               specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such
               as "Intel Haswell" or "Intel Sandy Bridge".
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] oauth_scopes: Scopes that are used by NAP and GKE Autopilot when creating node pools. Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               > `monitoring.write` is always enabled regardless of user input.  `monitoring` and `logging.write` may also be enabled depending on the values for `monitoring_service` and `logging_service`.
        :param pulumi.Input[builtins.str] service_account: The `email` of the Google Cloud Platform Service Account to be used by the node VMs created by GKE Autopilot or NAP.
        :param pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs'] shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs'] upgrade_settings: Specifies the upgrade settings for NAP created node pools
        """
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if disk_size is not None:
            pulumi.set(__self__, "disk_size", disk_size)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if management is not None:
            pulumi.set(__self__, "management", management)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if upgrade_settings is not None:
            pulumi.set(__self__, "upgrade_settings", upgrade_settings)

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @boot_disk_kms_key.setter
    def boot_disk_kms_key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "boot_disk_kms_key", value)

    @property
    @pulumi.getter(name="diskSize")
    def disk_size(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. Defaults to `100`
        """
        return pulumi.get(self, "disk_size")

    @disk_size.setter
    def disk_size(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "disk_size", value)

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd', 'pd-balanced', or 'hyperdisk-balanced'). Defaults to `hyperdisk-balanced` if `hyperdisk-balanced` is supported and `pd-balanced` is not supported for the machine type; otherwise defaults to `pd-balanced`.
        """
        return pulumi.get(self, "disk_type")

    @disk_type.setter
    def disk_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "disk_type", value)

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The default image type used by NAP once a new node pool is being created. Please note that according to the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning#default-image-type) the value must be one of the [COS_CONTAINERD, COS, UBUNTU_CONTAINERD, UBUNTU]. __NOTE__ : COS AND UBUNTU are deprecated as of `GKE 1.24`
        """
        return pulumi.get(self, "image_type")

    @image_type.setter
    def image_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "image_type", value)

    @property
    @pulumi.getter
    def management(self) -> Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs']]:
        """
        NodeManagement configuration for this NodePool. Structure is documented below.
        """
        return pulumi.get(self, "management")

    @management.setter
    def management(self, value: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs']]):
        pulumi.set(self, "management", value)

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the
        specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such
        as "Intel Haswell" or "Intel Sandy Bridge".
        """
        return pulumi.get(self, "min_cpu_platform")

    @min_cpu_platform.setter
    def min_cpu_platform(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "min_cpu_platform", value)

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        Scopes that are used by NAP and GKE Autopilot when creating node pools. Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        > `monitoring.write` is always enabled regardless of user input.  `monitoring` and `logging.write` may also be enabled depending on the values for `monitoring_service` and `logging_service`.
        """
        return pulumi.get(self, "oauth_scopes")

    @oauth_scopes.setter
    def oauth_scopes(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "oauth_scopes", value)

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The `email` of the Google Cloud Platform Service Account to be used by the node VMs created by GKE Autopilot or NAP.
        """
        return pulumi.get(self, "service_account")

    @service_account.setter
    def service_account(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "service_account", value)

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs']]:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @shielded_instance_config.setter
    def shielded_instance_config(self, value: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs']]):
        pulumi.set(self, "shielded_instance_config", value)

    @property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs']]:
        """
        Specifies the upgrade settings for NAP created node pools
        """
        return pulumi.get(self, "upgrade_settings")

    @upgrade_settings.setter
    def upgrade_settings(self, value: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs']]):
        pulumi.set(self, "upgrade_settings", value)


if not MYPY:
    class ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgsDict(TypedDict):
        auto_repair: NotRequired[pulumi.Input[builtins.bool]]
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.

        This block also contains several computed attributes, documented below.
        """
        auto_upgrade: NotRequired[pulumi.Input[builtins.bool]]
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        upgrade_options: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgsDict']]]]
        """
        Specifies the [Auto Upgrade knobs](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/NodeManagement#AutoUpgradeOptions) for the node pool.
        """
elif False:
    ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs:
    def __init__(__self__, *,
                 auto_repair: Optional[pulumi.Input[builtins.bool]] = None,
                 auto_upgrade: Optional[pulumi.Input[builtins.bool]] = None,
                 upgrade_options: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs']]]] = None):
        """
        :param pulumi.Input[builtins.bool] auto_repair: Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
               
               This block also contains several computed attributes, documented below.
        :param pulumi.Input[builtins.bool] auto_upgrade: Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs']]] upgrade_options: Specifies the [Auto Upgrade knobs](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/NodeManagement#AutoUpgradeOptions) for the node pool.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)
        if upgrade_options is not None:
            pulumi.set(__self__, "upgrade_options", upgrade_options)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.

        This block also contains several computed attributes, documented below.
        """
        return pulumi.get(self, "auto_repair")

    @auto_repair.setter
    def auto_repair(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "auto_repair", value)

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        return pulumi.get(self, "auto_upgrade")

    @auto_upgrade.setter
    def auto_upgrade(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "auto_upgrade", value)

    @property
    @pulumi.getter(name="upgradeOptions")
    def upgrade_options(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs']]]]:
        """
        Specifies the [Auto Upgrade knobs](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/NodeManagement#AutoUpgradeOptions) for the node pool.
        """
        return pulumi.get(self, "upgrade_options")

    @upgrade_options.setter
    def upgrade_options(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs']]]]):
        pulumi.set(self, "upgrade_options", value)


if not MYPY:
    class ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgsDict(TypedDict):
        auto_upgrade_start_time: NotRequired[pulumi.Input[builtins.str]]
        """
        This field is set when upgrades are about to commence with the approximate start time for the upgrades, in RFC3339 text format.
        """
        description: NotRequired[pulumi.Input[builtins.str]]
        """
        Description of the cluster.
        """
elif False:
    ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs:
    def __init__(__self__, *,
                 auto_upgrade_start_time: Optional[pulumi.Input[builtins.str]] = None,
                 description: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] auto_upgrade_start_time: This field is set when upgrades are about to commence with the approximate start time for the upgrades, in RFC3339 text format.
        :param pulumi.Input[builtins.str] description: Description of the cluster.
        """
        if auto_upgrade_start_time is not None:
            pulumi.set(__self__, "auto_upgrade_start_time", auto_upgrade_start_time)
        if description is not None:
            pulumi.set(__self__, "description", description)

    @property
    @pulumi.getter(name="autoUpgradeStartTime")
    def auto_upgrade_start_time(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        This field is set when upgrades are about to commence with the approximate start time for the upgrades, in RFC3339 text format.
        """
        return pulumi.get(self, "auto_upgrade_start_time")

    @auto_upgrade_start_time.setter
    def auto_upgrade_start_time(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "auto_upgrade_start_time", value)

    @property
    @pulumi.getter
    def description(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Description of the cluster.
        """
        return pulumi.get(self, "description")

    @description.setter
    def description(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "description", value)


if not MYPY:
    class ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgsDict(TypedDict):
        enable_integrity_monitoring: NotRequired[pulumi.Input[builtins.bool]]
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        enable_secure_boot: NotRequired[pulumi.Input[builtins.bool]]
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
elif False:
    ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs:
    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[pulumi.Input[builtins.bool]] = None,
                 enable_secure_boot: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.bool] enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param pulumi.Input[builtins.bool] enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @enable_integrity_monitoring.setter
    def enable_integrity_monitoring(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_integrity_monitoring", value)

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")

    @enable_secure_boot.setter
    def enable_secure_boot(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_secure_boot", value)


if not MYPY:
    class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgsDict(TypedDict):
        blue_green_settings: NotRequired[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgsDict']]
        """
        Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        max_surge: NotRequired[pulumi.Input[builtins.int]]
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        max_unavailable: NotRequired[pulumi.Input[builtins.int]]
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        strategy: NotRequired[pulumi.Input[builtins.str]]
        """
        Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
elif False:
    ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs:
    def __init__(__self__, *,
                 blue_green_settings: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs']] = None,
                 max_surge: Optional[pulumi.Input[builtins.int]] = None,
                 max_unavailable: Optional[pulumi.Input[builtins.int]] = None,
                 strategy: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs'] blue_green_settings: Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param pulumi.Input[builtins.int] max_surge: The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param pulumi.Input[builtins.int] max_unavailable: The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param pulumi.Input[builtins.str] strategy: Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs']]:
        """
        Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "blue_green_settings")

    @blue_green_settings.setter
    def blue_green_settings(self, value: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs']]):
        pulumi.set(self, "blue_green_settings", value)

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_surge")

    @max_surge.setter
    def max_surge(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_surge", value)

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_unavailable")

    @max_unavailable.setter
    def max_unavailable(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_unavailable", value)

    @property
    @pulumi.getter
    def strategy(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        return pulumi.get(self, "strategy")

    @strategy.setter
    def strategy(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "strategy", value)


if not MYPY:
    class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgsDict(TypedDict):
        node_pool_soak_duration: NotRequired[pulumi.Input[builtins.str]]
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        standard_rollout_policy: NotRequired[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgsDict']]
        """
        Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
elif False:
    ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs:
    def __init__(__self__, *,
                 node_pool_soak_duration: Optional[pulumi.Input[builtins.str]] = None,
                 standard_rollout_policy: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']] = None):
        """
        :param pulumi.Input[builtins.str] node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        :param pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs'] standard_rollout_policy: Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        if standard_rollout_policy is not None:
            pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @node_pool_soak_duration.setter
    def node_pool_soak_duration(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "node_pool_soak_duration", value)

    @property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']]:
        """
        Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "standard_rollout_policy")

    @standard_rollout_policy.setter
    def standard_rollout_policy(self, value: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']]):
        pulumi.set(self, "standard_rollout_policy", value)


if not MYPY:
    class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgsDict(TypedDict):
        batch_node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        """
        batch_percentage: NotRequired[pulumi.Input[builtins.float]]
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        """
        batch_soak_duration: NotRequired[pulumi.Input[builtins.str]]
        """
        Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
elif False:
    ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs:
    def __init__(__self__, *,
                 batch_node_count: Optional[pulumi.Input[builtins.int]] = None,
                 batch_percentage: Optional[pulumi.Input[builtins.float]] = None,
                 batch_soak_duration: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.int] batch_node_count: Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        :param pulumi.Input[builtins.float] batch_percentage: Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        :param pulumi.Input[builtins.str] batch_soak_duration: Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_node_count")

    @batch_node_count.setter
    def batch_node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "batch_node_count", value)

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[pulumi.Input[builtins.float]]:
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_percentage")

    @batch_percentage.setter
    def batch_percentage(self, value: Optional[pulumi.Input[builtins.float]]):
        pulumi.set(self, "batch_percentage", value)

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        return pulumi.get(self, "batch_soak_duration")

    @batch_soak_duration.setter
    def batch_soak_duration(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "batch_soak_duration", value)


if not MYPY:
    class ClusterClusterAutoscalingResourceLimitArgsDict(TypedDict):
        maximum: pulumi.Input[builtins.int]
        """
        Maximum amount of the resource in the cluster.
        """
        resource_type: pulumi.Input[builtins.str]
        """
        The type of the resource. For example, `cpu` and
        `memory`.  See the [guide to using Node Auto-Provisioning](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)
        for a list of types.
        """
        minimum: NotRequired[pulumi.Input[builtins.int]]
        """
        Minimum amount of the resource in the cluster.
        """
elif False:
    ClusterClusterAutoscalingResourceLimitArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterClusterAutoscalingResourceLimitArgs:
    def __init__(__self__, *,
                 maximum: pulumi.Input[builtins.int],
                 resource_type: pulumi.Input[builtins.str],
                 minimum: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.int] maximum: Maximum amount of the resource in the cluster.
        :param pulumi.Input[builtins.str] resource_type: The type of the resource. For example, `cpu` and
               `memory`.  See the [guide to using Node Auto-Provisioning](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)
               for a list of types.
        :param pulumi.Input[builtins.int] minimum: Minimum amount of the resource in the cluster.
        """
        pulumi.set(__self__, "maximum", maximum)
        pulumi.set(__self__, "resource_type", resource_type)
        if minimum is not None:
            pulumi.set(__self__, "minimum", minimum)

    @property
    @pulumi.getter
    def maximum(self) -> pulumi.Input[builtins.int]:
        """
        Maximum amount of the resource in the cluster.
        """
        return pulumi.get(self, "maximum")

    @maximum.setter
    def maximum(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "maximum", value)

    @property
    @pulumi.getter(name="resourceType")
    def resource_type(self) -> pulumi.Input[builtins.str]:
        """
        The type of the resource. For example, `cpu` and
        `memory`.  See the [guide to using Node Auto-Provisioning](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)
        for a list of types.
        """
        return pulumi.get(self, "resource_type")

    @resource_type.setter
    def resource_type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "resource_type", value)

    @property
    @pulumi.getter
    def minimum(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Minimum amount of the resource in the cluster.
        """
        return pulumi.get(self, "minimum")

    @minimum.setter
    def minimum(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "minimum", value)


if not MYPY:
    class ClusterClusterTelemetryArgsDict(TypedDict):
        type: pulumi.Input[builtins.str]
        """
        Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
        `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
elif False:
    ClusterClusterTelemetryArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterClusterTelemetryArgs:
    def __init__(__self__, *,
                 type: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] type: Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
               `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input[builtins.str]:
        """
        Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
        `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "type", value)


if not MYPY:
    class ClusterConfidentialNodesArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
elif False:
    ClusterConfidentialNodesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterConfidentialNodesArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterControlPlaneEndpointsConfigArgsDict(TypedDict):
        dns_endpoint_config: NotRequired[pulumi.Input['ClusterControlPlaneEndpointsConfigDnsEndpointConfigArgsDict']]
        """
        DNS endpoint configuration.
        """
        ip_endpoints_config: NotRequired[pulumi.Input['ClusterControlPlaneEndpointsConfigIpEndpointsConfigArgsDict']]
        """
        IP endpoint configuration.
        """
elif False:
    ClusterControlPlaneEndpointsConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterControlPlaneEndpointsConfigArgs:
    def __init__(__self__, *,
                 dns_endpoint_config: Optional[pulumi.Input['ClusterControlPlaneEndpointsConfigDnsEndpointConfigArgs']] = None,
                 ip_endpoints_config: Optional[pulumi.Input['ClusterControlPlaneEndpointsConfigIpEndpointsConfigArgs']] = None):
        """
        :param pulumi.Input['ClusterControlPlaneEndpointsConfigDnsEndpointConfigArgs'] dns_endpoint_config: DNS endpoint configuration.
        :param pulumi.Input['ClusterControlPlaneEndpointsConfigIpEndpointsConfigArgs'] ip_endpoints_config: IP endpoint configuration.
        """
        if dns_endpoint_config is not None:
            pulumi.set(__self__, "dns_endpoint_config", dns_endpoint_config)
        if ip_endpoints_config is not None:
            pulumi.set(__self__, "ip_endpoints_config", ip_endpoints_config)

    @property
    @pulumi.getter(name="dnsEndpointConfig")
    def dns_endpoint_config(self) -> Optional[pulumi.Input['ClusterControlPlaneEndpointsConfigDnsEndpointConfigArgs']]:
        """
        DNS endpoint configuration.
        """
        return pulumi.get(self, "dns_endpoint_config")

    @dns_endpoint_config.setter
    def dns_endpoint_config(self, value: Optional[pulumi.Input['ClusterControlPlaneEndpointsConfigDnsEndpointConfigArgs']]):
        pulumi.set(self, "dns_endpoint_config", value)

    @property
    @pulumi.getter(name="ipEndpointsConfig")
    def ip_endpoints_config(self) -> Optional[pulumi.Input['ClusterControlPlaneEndpointsConfigIpEndpointsConfigArgs']]:
        """
        IP endpoint configuration.
        """
        return pulumi.get(self, "ip_endpoints_config")

    @ip_endpoints_config.setter
    def ip_endpoints_config(self, value: Optional[pulumi.Input['ClusterControlPlaneEndpointsConfigIpEndpointsConfigArgs']]):
        pulumi.set(self, "ip_endpoints_config", value)


if not MYPY:
    class ClusterControlPlaneEndpointsConfigDnsEndpointConfigArgsDict(TypedDict):
        allow_external_traffic: NotRequired[pulumi.Input[builtins.bool]]
        """
        Controls whether user traffic is allowed over this endpoint. Note that GCP-managed services may still use the endpoint even if this is false.
        """
        endpoint: NotRequired[pulumi.Input[builtins.str]]
        """
        The cluster's DNS endpoint.
        """
elif False:
    ClusterControlPlaneEndpointsConfigDnsEndpointConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterControlPlaneEndpointsConfigDnsEndpointConfigArgs:
    def __init__(__self__, *,
                 allow_external_traffic: Optional[pulumi.Input[builtins.bool]] = None,
                 endpoint: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.bool] allow_external_traffic: Controls whether user traffic is allowed over this endpoint. Note that GCP-managed services may still use the endpoint even if this is false.
        :param pulumi.Input[builtins.str] endpoint: The cluster's DNS endpoint.
        """
        if allow_external_traffic is not None:
            pulumi.set(__self__, "allow_external_traffic", allow_external_traffic)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)

    @property
    @pulumi.getter(name="allowExternalTraffic")
    def allow_external_traffic(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Controls whether user traffic is allowed over this endpoint. Note that GCP-managed services may still use the endpoint even if this is false.
        """
        return pulumi.get(self, "allow_external_traffic")

    @allow_external_traffic.setter
    def allow_external_traffic(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "allow_external_traffic", value)

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The cluster's DNS endpoint.
        """
        return pulumi.get(self, "endpoint")

    @endpoint.setter
    def endpoint(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "endpoint", value)


if not MYPY:
    class ClusterControlPlaneEndpointsConfigIpEndpointsConfigArgsDict(TypedDict):
        enabled: NotRequired[pulumi.Input[builtins.bool]]
        """
        Controls whether to allow direct IP access. Defaults to `true`.
        """
elif False:
    ClusterControlPlaneEndpointsConfigIpEndpointsConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterControlPlaneEndpointsConfigIpEndpointsConfigArgs:
    def __init__(__self__, *,
                 enabled: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.bool] enabled: Controls whether to allow direct IP access. Defaults to `true`.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Controls whether to allow direct IP access. Defaults to `true`.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterCostManagementConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether to enable the [cost allocation](https://cloud.google.com/kubernetes-engine/docs/how-to/cost-allocations) feature.
        """
elif False:
    ClusterCostManagementConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterCostManagementConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether to enable the [cost allocation](https://cloud.google.com/kubernetes-engine/docs/how-to/cost-allocations) feature.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether to enable the [cost allocation](https://cloud.google.com/kubernetes-engine/docs/how-to/cost-allocations) feature.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterDatabaseEncryptionArgsDict(TypedDict):
        state: pulumi.Input[builtins.str]
        """
        `ENCRYPTED` or `DECRYPTED`
        """
        key_name: NotRequired[pulumi.Input[builtins.str]]
        """
        the key to use to encrypt/decrypt secrets.  See the [DatabaseEncryption definition](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.DatabaseEncryption) for more information.

        <a name="nested_enable_k8s_beta_apis"></a>The `enable_k8s_beta_apis` block supports:
        """
elif False:
    ClusterDatabaseEncryptionArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterDatabaseEncryptionArgs:
    def __init__(__self__, *,
                 state: pulumi.Input[builtins.str],
                 key_name: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] state: `ENCRYPTED` or `DECRYPTED`
        :param pulumi.Input[builtins.str] key_name: the key to use to encrypt/decrypt secrets.  See the [DatabaseEncryption definition](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.DatabaseEncryption) for more information.
               
               <a name="nested_enable_k8s_beta_apis"></a>The `enable_k8s_beta_apis` block supports:
        """
        pulumi.set(__self__, "state", state)
        if key_name is not None:
            pulumi.set(__self__, "key_name", key_name)

    @property
    @pulumi.getter
    def state(self) -> pulumi.Input[builtins.str]:
        """
        `ENCRYPTED` or `DECRYPTED`
        """
        return pulumi.get(self, "state")

    @state.setter
    def state(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "state", value)

    @property
    @pulumi.getter(name="keyName")
    def key_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        the key to use to encrypt/decrypt secrets.  See the [DatabaseEncryption definition](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.DatabaseEncryption) for more information.

        <a name="nested_enable_k8s_beta_apis"></a>The `enable_k8s_beta_apis` block supports:
        """
        return pulumi.get(self, "key_name")

    @key_name.setter
    def key_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "key_name", value)


if not MYPY:
    class ClusterDefaultSnatStatusArgsDict(TypedDict):
        disabled: pulumi.Input[builtins.bool]
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
elif False:
    ClusterDefaultSnatStatusArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterDefaultSnatStatusArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "disabled", value)


if not MYPY:
    class ClusterDnsConfigArgsDict(TypedDict):
        additive_vpc_scope_dns_domain: NotRequired[pulumi.Input[builtins.str]]
        """
        This will enable Cloud DNS additive VPC scope. Must provide a domain name that is unique within the VPC. For this to work `cluster_dns = "CLOUD_DNS"` and `cluster_dns_scope = "CLUSTER_SCOPE"` must both be set as well.
        """
        cluster_dns: NotRequired[pulumi.Input[builtins.str]]
        """
        Which in-cluster DNS provider should be used. `PROVIDER_UNSPECIFIED` (default) or `PLATFORM_DEFAULT` or `CLOUD_DNS`.
        """
        cluster_dns_domain: NotRequired[pulumi.Input[builtins.str]]
        """
        The suffix used for all cluster service records.
        """
        cluster_dns_scope: NotRequired[pulumi.Input[builtins.str]]
        """
        The scope of access to cluster DNS records. `DNS_SCOPE_UNSPECIFIED` or `CLUSTER_SCOPE` or `VPC_SCOPE`. If the `cluster_dns` field is set to `CLOUD_DNS`, `DNS_SCOPE_UNSPECIFIED` and empty/null behave like `CLUSTER_SCOPE`.
        """
elif False:
    ClusterDnsConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterDnsConfigArgs:
    def __init__(__self__, *,
                 additive_vpc_scope_dns_domain: Optional[pulumi.Input[builtins.str]] = None,
                 cluster_dns: Optional[pulumi.Input[builtins.str]] = None,
                 cluster_dns_domain: Optional[pulumi.Input[builtins.str]] = None,
                 cluster_dns_scope: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] additive_vpc_scope_dns_domain: This will enable Cloud DNS additive VPC scope. Must provide a domain name that is unique within the VPC. For this to work `cluster_dns = "CLOUD_DNS"` and `cluster_dns_scope = "CLUSTER_SCOPE"` must both be set as well.
        :param pulumi.Input[builtins.str] cluster_dns: Which in-cluster DNS provider should be used. `PROVIDER_UNSPECIFIED` (default) or `PLATFORM_DEFAULT` or `CLOUD_DNS`.
        :param pulumi.Input[builtins.str] cluster_dns_domain: The suffix used for all cluster service records.
        :param pulumi.Input[builtins.str] cluster_dns_scope: The scope of access to cluster DNS records. `DNS_SCOPE_UNSPECIFIED` or `CLUSTER_SCOPE` or `VPC_SCOPE`. If the `cluster_dns` field is set to `CLOUD_DNS`, `DNS_SCOPE_UNSPECIFIED` and empty/null behave like `CLUSTER_SCOPE`.
        """
        if additive_vpc_scope_dns_domain is not None:
            pulumi.set(__self__, "additive_vpc_scope_dns_domain", additive_vpc_scope_dns_domain)
        if cluster_dns is not None:
            pulumi.set(__self__, "cluster_dns", cluster_dns)
        if cluster_dns_domain is not None:
            pulumi.set(__self__, "cluster_dns_domain", cluster_dns_domain)
        if cluster_dns_scope is not None:
            pulumi.set(__self__, "cluster_dns_scope", cluster_dns_scope)

    @property
    @pulumi.getter(name="additiveVpcScopeDnsDomain")
    def additive_vpc_scope_dns_domain(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        This will enable Cloud DNS additive VPC scope. Must provide a domain name that is unique within the VPC. For this to work `cluster_dns = "CLOUD_DNS"` and `cluster_dns_scope = "CLUSTER_SCOPE"` must both be set as well.
        """
        return pulumi.get(self, "additive_vpc_scope_dns_domain")

    @additive_vpc_scope_dns_domain.setter
    def additive_vpc_scope_dns_domain(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "additive_vpc_scope_dns_domain", value)

    @property
    @pulumi.getter(name="clusterDns")
    def cluster_dns(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Which in-cluster DNS provider should be used. `PROVIDER_UNSPECIFIED` (default) or `PLATFORM_DEFAULT` or `CLOUD_DNS`.
        """
        return pulumi.get(self, "cluster_dns")

    @cluster_dns.setter
    def cluster_dns(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cluster_dns", value)

    @property
    @pulumi.getter(name="clusterDnsDomain")
    def cluster_dns_domain(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The suffix used for all cluster service records.
        """
        return pulumi.get(self, "cluster_dns_domain")

    @cluster_dns_domain.setter
    def cluster_dns_domain(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cluster_dns_domain", value)

    @property
    @pulumi.getter(name="clusterDnsScope")
    def cluster_dns_scope(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The scope of access to cluster DNS records. `DNS_SCOPE_UNSPECIFIED` or `CLUSTER_SCOPE` or `VPC_SCOPE`. If the `cluster_dns` field is set to `CLOUD_DNS`, `DNS_SCOPE_UNSPECIFIED` and empty/null behave like `CLUSTER_SCOPE`.
        """
        return pulumi.get(self, "cluster_dns_scope")

    @cluster_dns_scope.setter
    def cluster_dns_scope(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cluster_dns_scope", value)


if not MYPY:
    class ClusterEnableK8sBetaApisArgsDict(TypedDict):
        enabled_apis: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        Enabled Kubernetes Beta APIs.
        """
elif False:
    ClusterEnableK8sBetaApisArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterEnableK8sBetaApisArgs:
    def __init__(__self__, *,
                 enabled_apis: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] enabled_apis: Enabled Kubernetes Beta APIs.
        """
        pulumi.set(__self__, "enabled_apis", enabled_apis)

    @property
    @pulumi.getter(name="enabledApis")
    def enabled_apis(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        Enabled Kubernetes Beta APIs.
        """
        return pulumi.get(self, "enabled_apis")

    @enabled_apis.setter
    def enabled_apis(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "enabled_apis", value)


if not MYPY:
    class ClusterEnterpriseConfigArgsDict(TypedDict):
        cluster_tier: NotRequired[pulumi.Input[builtins.str]]
        """
        The effective tier of the cluster.
        """
        desired_tier: NotRequired[pulumi.Input[builtins.str]]
        """
        Sets the tier of the cluster. Available options include `STANDARD` and `ENTERPRISE`.
        """
elif False:
    ClusterEnterpriseConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterEnterpriseConfigArgs:
    def __init__(__self__, *,
                 cluster_tier: Optional[pulumi.Input[builtins.str]] = None,
                 desired_tier: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] cluster_tier: The effective tier of the cluster.
        :param pulumi.Input[builtins.str] desired_tier: Sets the tier of the cluster. Available options include `STANDARD` and `ENTERPRISE`.
        """
        if cluster_tier is not None:
            pulumi.set(__self__, "cluster_tier", cluster_tier)
        if desired_tier is not None:
            pulumi.set(__self__, "desired_tier", desired_tier)

    @property
    @pulumi.getter(name="clusterTier")
    def cluster_tier(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The effective tier of the cluster.
        """
        return pulumi.get(self, "cluster_tier")

    @cluster_tier.setter
    def cluster_tier(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cluster_tier", value)

    @property
    @pulumi.getter(name="desiredTier")
    def desired_tier(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Sets the tier of the cluster. Available options include `STANDARD` and `ENTERPRISE`.
        """
        return pulumi.get(self, "desired_tier")

    @desired_tier.setter
    def desired_tier(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "desired_tier", value)


if not MYPY:
    class ClusterFleetArgsDict(TypedDict):
        membership: NotRequired[pulumi.Input[builtins.str]]
        """
        The resource name of the fleet Membership resource associated to this cluster with format `//gkehub.googleapis.com/projects/{{project}}/locations/{{location}}/memberships/{{name}}`. See the official doc for [fleet management](https://cloud.google.com/kubernetes-engine/docs/fleets-overview).
        """
        membership_id: NotRequired[pulumi.Input[builtins.str]]
        """
        The short name of the fleet membership, extracted from `fleet.0.membership`. You can use this field to configure `membership_id` under google_gkehub_feature_membership.
        """
        membership_location: NotRequired[pulumi.Input[builtins.str]]
        """
        The location of the fleet membership,  extracted from `fleet.0.membership`. You can use this field to configure `membership_location` under google_gkehub_feature_membership.
        """
        pre_registered: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether the cluster has been registered via the fleet API.
        """
        project: NotRequired[pulumi.Input[builtins.str]]
        """
        The name of the Fleet host project where this cluster will be registered.
        """
elif False:
    ClusterFleetArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterFleetArgs:
    def __init__(__self__, *,
                 membership: Optional[pulumi.Input[builtins.str]] = None,
                 membership_id: Optional[pulumi.Input[builtins.str]] = None,
                 membership_location: Optional[pulumi.Input[builtins.str]] = None,
                 pre_registered: Optional[pulumi.Input[builtins.bool]] = None,
                 project: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] membership: The resource name of the fleet Membership resource associated to this cluster with format `//gkehub.googleapis.com/projects/{{project}}/locations/{{location}}/memberships/{{name}}`. See the official doc for [fleet management](https://cloud.google.com/kubernetes-engine/docs/fleets-overview).
        :param pulumi.Input[builtins.str] membership_id: The short name of the fleet membership, extracted from `fleet.0.membership`. You can use this field to configure `membership_id` under google_gkehub_feature_membership.
        :param pulumi.Input[builtins.str] membership_location: The location of the fleet membership,  extracted from `fleet.0.membership`. You can use this field to configure `membership_location` under google_gkehub_feature_membership.
        :param pulumi.Input[builtins.bool] pre_registered: Whether the cluster has been registered via the fleet API.
        :param pulumi.Input[builtins.str] project: The name of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if membership_id is not None:
            pulumi.set(__self__, "membership_id", membership_id)
        if membership_location is not None:
            pulumi.set(__self__, "membership_location", membership_location)
        if pre_registered is not None:
            pulumi.set(__self__, "pre_registered", pre_registered)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @property
    @pulumi.getter
    def membership(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The resource name of the fleet Membership resource associated to this cluster with format `//gkehub.googleapis.com/projects/{{project}}/locations/{{location}}/memberships/{{name}}`. See the official doc for [fleet management](https://cloud.google.com/kubernetes-engine/docs/fleets-overview).
        """
        return pulumi.get(self, "membership")

    @membership.setter
    def membership(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "membership", value)

    @property
    @pulumi.getter(name="membershipId")
    def membership_id(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The short name of the fleet membership, extracted from `fleet.0.membership`. You can use this field to configure `membership_id` under google_gkehub_feature_membership.
        """
        return pulumi.get(self, "membership_id")

    @membership_id.setter
    def membership_id(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "membership_id", value)

    @property
    @pulumi.getter(name="membershipLocation")
    def membership_location(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The location of the fleet membership,  extracted from `fleet.0.membership`. You can use this field to configure `membership_location` under google_gkehub_feature_membership.
        """
        return pulumi.get(self, "membership_location")

    @membership_location.setter
    def membership_location(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "membership_location", value)

    @property
    @pulumi.getter(name="preRegistered")
    def pre_registered(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether the cluster has been registered via the fleet API.
        """
        return pulumi.get(self, "pre_registered")

    @pre_registered.setter
    def pre_registered(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "pre_registered", value)

    @property
    @pulumi.getter
    def project(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")

    @project.setter
    def project(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "project", value)


if not MYPY:
    class ClusterGatewayApiConfigArgsDict(TypedDict):
        channel: pulumi.Input[builtins.str]
        """
        Which Gateway Api channel should be used. `CHANNEL_DISABLED`, `CHANNEL_EXPERIMENTAL` or `CHANNEL_STANDARD`.
        """
elif False:
    ClusterGatewayApiConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterGatewayApiConfigArgs:
    def __init__(__self__, *,
                 channel: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] channel: Which Gateway Api channel should be used. `CHANNEL_DISABLED`, `CHANNEL_EXPERIMENTAL` or `CHANNEL_STANDARD`.
        """
        pulumi.set(__self__, "channel", channel)

    @property
    @pulumi.getter
    def channel(self) -> pulumi.Input[builtins.str]:
        """
        Which Gateway Api channel should be used. `CHANNEL_DISABLED`, `CHANNEL_EXPERIMENTAL` or `CHANNEL_STANDARD`.
        """
        return pulumi.get(self, "channel")

    @channel.setter
    def channel(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "channel", value)


if not MYPY:
    class ClusterIdentityServiceConfigArgsDict(TypedDict):
        enabled: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether to enable the Identity Service component. It is disabled by default. Set `enabled=true` to enable.
        """
elif False:
    ClusterIdentityServiceConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterIdentityServiceConfigArgs:
    def __init__(__self__, *,
                 enabled: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether to enable the Identity Service component. It is disabled by default. Set `enabled=true` to enable.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether to enable the Identity Service component. It is disabled by default. Set `enabled=true` to enable.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterIpAllocationPolicyArgsDict(TypedDict):
        additional_pod_ranges_config: NotRequired[pulumi.Input['ClusterIpAllocationPolicyAdditionalPodRangesConfigArgsDict']]
        """
        The configuration for additional pod secondary ranges at
        the cluster level. Used for Autopilot clusters and Standard clusters with which control of the
        secondary Pod IP address assignment to node pools isn't needed. Structure is documented below.
        """
        cluster_ipv4_cidr_block: NotRequired[pulumi.Input[builtins.str]]
        """
        The IP address range for the cluster pod IPs.
        Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
        to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
        from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
        pick a specific range to use.
        """
        cluster_secondary_range_name: NotRequired[pulumi.Input[builtins.str]]
        """
        The name of the existing secondary
        range in the cluster's subnetwork to use for pod IP addresses. Alternatively,
        `cluster_ipv4_cidr_block` can be used to automatically create a GKE-managed one.
        """
        pod_cidr_overprovision_config: NotRequired[pulumi.Input['ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgsDict']]
        """
        Configuration for cluster level pod cidr overprovision. Default is disabled=false.
        """
        services_ipv4_cidr_block: NotRequired[pulumi.Input[builtins.str]]
        """
        The IP address range of the services IPs in this cluster.
        Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
        to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
        from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
        pick a specific range to use.
        """
        services_secondary_range_name: NotRequired[pulumi.Input[builtins.str]]
        """
        The name of the existing
        secondary range in the cluster's subnetwork to use for service `ClusterIP`s.
        Alternatively, `services_ipv4_cidr_block` can be used to automatically create a
        GKE-managed one.
        """
        stack_type: NotRequired[pulumi.Input[builtins.str]]
        """
        The IP Stack Type of the cluster.
        Default value is `IPV4`.
        Possible values are `IPV4` and `IPV4_IPV6`.
        """
elif False:
    ClusterIpAllocationPolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterIpAllocationPolicyArgs:
    def __init__(__self__, *,
                 additional_pod_ranges_config: Optional[pulumi.Input['ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs']] = None,
                 cluster_ipv4_cidr_block: Optional[pulumi.Input[builtins.str]] = None,
                 cluster_secondary_range_name: Optional[pulumi.Input[builtins.str]] = None,
                 pod_cidr_overprovision_config: Optional[pulumi.Input['ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs']] = None,
                 services_ipv4_cidr_block: Optional[pulumi.Input[builtins.str]] = None,
                 services_secondary_range_name: Optional[pulumi.Input[builtins.str]] = None,
                 stack_type: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input['ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs'] additional_pod_ranges_config: The configuration for additional pod secondary ranges at
               the cluster level. Used for Autopilot clusters and Standard clusters with which control of the
               secondary Pod IP address assignment to node pools isn't needed. Structure is documented below.
        :param pulumi.Input[builtins.str] cluster_ipv4_cidr_block: The IP address range for the cluster pod IPs.
               Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
               to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
               from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
               pick a specific range to use.
        :param pulumi.Input[builtins.str] cluster_secondary_range_name: The name of the existing secondary
               range in the cluster's subnetwork to use for pod IP addresses. Alternatively,
               `cluster_ipv4_cidr_block` can be used to automatically create a GKE-managed one.
        :param pulumi.Input['ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs'] pod_cidr_overprovision_config: Configuration for cluster level pod cidr overprovision. Default is disabled=false.
        :param pulumi.Input[builtins.str] services_ipv4_cidr_block: The IP address range of the services IPs in this cluster.
               Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
               to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
               from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
               pick a specific range to use.
        :param pulumi.Input[builtins.str] services_secondary_range_name: The name of the existing
               secondary range in the cluster's subnetwork to use for service `ClusterIP`s.
               Alternatively, `services_ipv4_cidr_block` can be used to automatically create a
               GKE-managed one.
        :param pulumi.Input[builtins.str] stack_type: The IP Stack Type of the cluster.
               Default value is `IPV4`.
               Possible values are `IPV4` and `IPV4_IPV6`.
        """
        if additional_pod_ranges_config is not None:
            pulumi.set(__self__, "additional_pod_ranges_config", additional_pod_ranges_config)
        if cluster_ipv4_cidr_block is not None:
            pulumi.set(__self__, "cluster_ipv4_cidr_block", cluster_ipv4_cidr_block)
        if cluster_secondary_range_name is not None:
            pulumi.set(__self__, "cluster_secondary_range_name", cluster_secondary_range_name)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if services_ipv4_cidr_block is not None:
            pulumi.set(__self__, "services_ipv4_cidr_block", services_ipv4_cidr_block)
        if services_secondary_range_name is not None:
            pulumi.set(__self__, "services_secondary_range_name", services_secondary_range_name)
        if stack_type is not None:
            pulumi.set(__self__, "stack_type", stack_type)

    @property
    @pulumi.getter(name="additionalPodRangesConfig")
    def additional_pod_ranges_config(self) -> Optional[pulumi.Input['ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs']]:
        """
        The configuration for additional pod secondary ranges at
        the cluster level. Used for Autopilot clusters and Standard clusters with which control of the
        secondary Pod IP address assignment to node pools isn't needed. Structure is documented below.
        """
        return pulumi.get(self, "additional_pod_ranges_config")

    @additional_pod_ranges_config.setter
    def additional_pod_ranges_config(self, value: Optional[pulumi.Input['ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs']]):
        pulumi.set(self, "additional_pod_ranges_config", value)

    @property
    @pulumi.getter(name="clusterIpv4CidrBlock")
    def cluster_ipv4_cidr_block(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The IP address range for the cluster pod IPs.
        Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
        to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
        from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
        pick a specific range to use.
        """
        return pulumi.get(self, "cluster_ipv4_cidr_block")

    @cluster_ipv4_cidr_block.setter
    def cluster_ipv4_cidr_block(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cluster_ipv4_cidr_block", value)

    @property
    @pulumi.getter(name="clusterSecondaryRangeName")
    def cluster_secondary_range_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of the existing secondary
        range in the cluster's subnetwork to use for pod IP addresses. Alternatively,
        `cluster_ipv4_cidr_block` can be used to automatically create a GKE-managed one.
        """
        return pulumi.get(self, "cluster_secondary_range_name")

    @cluster_secondary_range_name.setter
    def cluster_secondary_range_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cluster_secondary_range_name", value)

    @property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional[pulumi.Input['ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs']]:
        """
        Configuration for cluster level pod cidr overprovision. Default is disabled=false.
        """
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @pod_cidr_overprovision_config.setter
    def pod_cidr_overprovision_config(self, value: Optional[pulumi.Input['ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs']]):
        pulumi.set(self, "pod_cidr_overprovision_config", value)

    @property
    @pulumi.getter(name="servicesIpv4CidrBlock")
    def services_ipv4_cidr_block(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The IP address range of the services IPs in this cluster.
        Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
        to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
        from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
        pick a specific range to use.
        """
        return pulumi.get(self, "services_ipv4_cidr_block")

    @services_ipv4_cidr_block.setter
    def services_ipv4_cidr_block(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "services_ipv4_cidr_block", value)

    @property
    @pulumi.getter(name="servicesSecondaryRangeName")
    def services_secondary_range_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of the existing
        secondary range in the cluster's subnetwork to use for service `ClusterIP`s.
        Alternatively, `services_ipv4_cidr_block` can be used to automatically create a
        GKE-managed one.
        """
        return pulumi.get(self, "services_secondary_range_name")

    @services_secondary_range_name.setter
    def services_secondary_range_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "services_secondary_range_name", value)

    @property
    @pulumi.getter(name="stackType")
    def stack_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The IP Stack Type of the cluster.
        Default value is `IPV4`.
        Possible values are `IPV4` and `IPV4_IPV6`.
        """
        return pulumi.get(self, "stack_type")

    @stack_type.setter
    def stack_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "stack_type", value)


if not MYPY:
    class ClusterIpAllocationPolicyAdditionalPodRangesConfigArgsDict(TypedDict):
        pod_range_names: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        The names of the Pod ranges to add to the cluster.
        """
elif False:
    ClusterIpAllocationPolicyAdditionalPodRangesConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs:
    def __init__(__self__, *,
                 pod_range_names: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] pod_range_names: The names of the Pod ranges to add to the cluster.
        """
        pulumi.set(__self__, "pod_range_names", pod_range_names)

    @property
    @pulumi.getter(name="podRangeNames")
    def pod_range_names(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        The names of the Pod ranges to add to the cluster.
        """
        return pulumi.get(self, "pod_range_names")

    @pod_range_names.setter
    def pod_range_names(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "pod_range_names", value)


if not MYPY:
    class ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgsDict(TypedDict):
        disabled: pulumi.Input[builtins.bool]
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
elif False:
    ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "disabled", value)


if not MYPY:
    class ClusterLoggingConfigArgsDict(TypedDict):
        enable_components: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        The GKE components exposing logs. Supported values include:
        `SYSTEM_COMPONENTS`, `APISERVER`, `CONTROLLER_MANAGER`, `SCHEDULER`, and `WORKLOADS`.
        """
elif False:
    ClusterLoggingConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterLoggingConfigArgs:
    def __init__(__self__, *,
                 enable_components: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] enable_components: The GKE components exposing logs. Supported values include:
               `SYSTEM_COMPONENTS`, `APISERVER`, `CONTROLLER_MANAGER`, `SCHEDULER`, and `WORKLOADS`.
        """
        pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        The GKE components exposing logs. Supported values include:
        `SYSTEM_COMPONENTS`, `APISERVER`, `CONTROLLER_MANAGER`, `SCHEDULER`, and `WORKLOADS`.
        """
        return pulumi.get(self, "enable_components")

    @enable_components.setter
    def enable_components(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "enable_components", value)


if not MYPY:
    class ClusterMaintenancePolicyArgsDict(TypedDict):
        daily_maintenance_window: NotRequired[pulumi.Input['ClusterMaintenancePolicyDailyMaintenanceWindowArgsDict']]
        """
        Time window specified for daily maintenance operations.
        Specify `start_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM,
        where HH : \\[00-23\\] and MM : \\[00-59\\] GMT. For example:

        Examples:
        """
        maintenance_exclusions: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionArgsDict']]]]
        """
        Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows. A cluster can have up to 20 maintenance exclusions at a time [Maintenance Window and Exclusions](https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions)
        """
        recurring_window: NotRequired[pulumi.Input['ClusterMaintenancePolicyRecurringWindowArgsDict']]
        """
        Time window for recurring maintenance operations.

        Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
        the initial date that the window starts, and the end time is used for calculating duration.  Specify `recurrence` in
        [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
        Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.

        Examples:
        ```
        maintenance_policy {
        recurring_window {
        start_time = "2019-08-01T02:00:00Z"
        end_time = "2019-08-01T06:00:00Z"
        recurrence = "FREQ=DAILY"
        }
        }
        ```

        ```
        maintenance_policy {
        recurring_window {
        start_time = "2019-01-01T09:00:00Z"
        end_time = "2019-01-01T17:00:00Z"
        recurrence = "FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR"
        }
        }
        ```
        """
elif False:
    ClusterMaintenancePolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMaintenancePolicyArgs:
    def __init__(__self__, *,
                 daily_maintenance_window: Optional[pulumi.Input['ClusterMaintenancePolicyDailyMaintenanceWindowArgs']] = None,
                 maintenance_exclusions: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionArgs']]]] = None,
                 recurring_window: Optional[pulumi.Input['ClusterMaintenancePolicyRecurringWindowArgs']] = None):
        """
        :param pulumi.Input['ClusterMaintenancePolicyDailyMaintenanceWindowArgs'] daily_maintenance_window: Time window specified for daily maintenance operations.
               Specify `start_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM,
               where HH : \\[00-23\\] and MM : \\[00-59\\] GMT. For example:
               
               Examples:
        :param pulumi.Input[Sequence[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionArgs']]] maintenance_exclusions: Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows. A cluster can have up to 20 maintenance exclusions at a time [Maintenance Window and Exclusions](https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions)
        :param pulumi.Input['ClusterMaintenancePolicyRecurringWindowArgs'] recurring_window: Time window for recurring maintenance operations.
               
               Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
               the initial date that the window starts, and the end time is used for calculating duration.  Specify `recurrence` in
               [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
               Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.
               
               Examples:
               ```
               maintenance_policy {
               recurring_window {
               start_time = "2019-08-01T02:00:00Z"
               end_time = "2019-08-01T06:00:00Z"
               recurrence = "FREQ=DAILY"
               }
               }
               ```
               
               ```
               maintenance_policy {
               recurring_window {
               start_time = "2019-01-01T09:00:00Z"
               end_time = "2019-01-01T17:00:00Z"
               recurrence = "FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR"
               }
               }
               ```
        """
        if daily_maintenance_window is not None:
            pulumi.set(__self__, "daily_maintenance_window", daily_maintenance_window)
        if maintenance_exclusions is not None:
            pulumi.set(__self__, "maintenance_exclusions", maintenance_exclusions)
        if recurring_window is not None:
            pulumi.set(__self__, "recurring_window", recurring_window)

    @property
    @pulumi.getter(name="dailyMaintenanceWindow")
    def daily_maintenance_window(self) -> Optional[pulumi.Input['ClusterMaintenancePolicyDailyMaintenanceWindowArgs']]:
        """
        Time window specified for daily maintenance operations.
        Specify `start_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM,
        where HH : \\[00-23\\] and MM : \\[00-59\\] GMT. For example:

        Examples:
        """
        return pulumi.get(self, "daily_maintenance_window")

    @daily_maintenance_window.setter
    def daily_maintenance_window(self, value: Optional[pulumi.Input['ClusterMaintenancePolicyDailyMaintenanceWindowArgs']]):
        pulumi.set(self, "daily_maintenance_window", value)

    @property
    @pulumi.getter(name="maintenanceExclusions")
    def maintenance_exclusions(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionArgs']]]]:
        """
        Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows. A cluster can have up to 20 maintenance exclusions at a time [Maintenance Window and Exclusions](https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions)
        """
        return pulumi.get(self, "maintenance_exclusions")

    @maintenance_exclusions.setter
    def maintenance_exclusions(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionArgs']]]]):
        pulumi.set(self, "maintenance_exclusions", value)

    @property
    @pulumi.getter(name="recurringWindow")
    def recurring_window(self) -> Optional[pulumi.Input['ClusterMaintenancePolicyRecurringWindowArgs']]:
        """
        Time window for recurring maintenance operations.

        Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
        the initial date that the window starts, and the end time is used for calculating duration.  Specify `recurrence` in
        [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
        Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.

        Examples:
        ```
        maintenance_policy {
        recurring_window {
        start_time = "2019-08-01T02:00:00Z"
        end_time = "2019-08-01T06:00:00Z"
        recurrence = "FREQ=DAILY"
        }
        }
        ```

        ```
        maintenance_policy {
        recurring_window {
        start_time = "2019-01-01T09:00:00Z"
        end_time = "2019-01-01T17:00:00Z"
        recurrence = "FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR"
        }
        }
        ```
        """
        return pulumi.get(self, "recurring_window")

    @recurring_window.setter
    def recurring_window(self, value: Optional[pulumi.Input['ClusterMaintenancePolicyRecurringWindowArgs']]):
        pulumi.set(self, "recurring_window", value)


if not MYPY:
    class ClusterMaintenancePolicyDailyMaintenanceWindowArgsDict(TypedDict):
        start_time: pulumi.Input[builtins.str]
        duration: NotRequired[pulumi.Input[builtins.str]]
        """
        Duration of the time window, automatically chosen to be
        smallest possible in the given scenario.
        Duration will be in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "PTnHnMnS".
        """
elif False:
    ClusterMaintenancePolicyDailyMaintenanceWindowArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMaintenancePolicyDailyMaintenanceWindowArgs:
    def __init__(__self__, *,
                 start_time: pulumi.Input[builtins.str],
                 duration: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] duration: Duration of the time window, automatically chosen to be
               smallest possible in the given scenario.
               Duration will be in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "PTnHnMnS".
        """
        pulumi.set(__self__, "start_time", start_time)
        if duration is not None:
            pulumi.set(__self__, "duration", duration)

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> pulumi.Input[builtins.str]:
        return pulumi.get(self, "start_time")

    @start_time.setter
    def start_time(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "start_time", value)

    @property
    @pulumi.getter
    def duration(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Duration of the time window, automatically chosen to be
        smallest possible in the given scenario.
        Duration will be in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "PTnHnMnS".
        """
        return pulumi.get(self, "duration")

    @duration.setter
    def duration(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "duration", value)


if not MYPY:
    class ClusterMaintenancePolicyMaintenanceExclusionArgsDict(TypedDict):
        end_time: pulumi.Input[builtins.str]
        exclusion_name: pulumi.Input[builtins.str]
        start_time: pulumi.Input[builtins.str]
        exclusion_options: NotRequired[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgsDict']]
        """
        MaintenanceExclusionOptions provides maintenance exclusion related options.
        """
elif False:
    ClusterMaintenancePolicyMaintenanceExclusionArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMaintenancePolicyMaintenanceExclusionArgs:
    def __init__(__self__, *,
                 end_time: pulumi.Input[builtins.str],
                 exclusion_name: pulumi.Input[builtins.str],
                 start_time: pulumi.Input[builtins.str],
                 exclusion_options: Optional[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs']] = None):
        """
        :param pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs'] exclusion_options: MaintenanceExclusionOptions provides maintenance exclusion related options.
        """
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "exclusion_name", exclusion_name)
        pulumi.set(__self__, "start_time", start_time)
        if exclusion_options is not None:
            pulumi.set(__self__, "exclusion_options", exclusion_options)

    @property
    @pulumi.getter(name="endTime")
    def end_time(self) -> pulumi.Input[builtins.str]:
        return pulumi.get(self, "end_time")

    @end_time.setter
    def end_time(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "end_time", value)

    @property
    @pulumi.getter(name="exclusionName")
    def exclusion_name(self) -> pulumi.Input[builtins.str]:
        return pulumi.get(self, "exclusion_name")

    @exclusion_name.setter
    def exclusion_name(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "exclusion_name", value)

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> pulumi.Input[builtins.str]:
        return pulumi.get(self, "start_time")

    @start_time.setter
    def start_time(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "start_time", value)

    @property
    @pulumi.getter(name="exclusionOptions")
    def exclusion_options(self) -> Optional[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs']]:
        """
        MaintenanceExclusionOptions provides maintenance exclusion related options.
        """
        return pulumi.get(self, "exclusion_options")

    @exclusion_options.setter
    def exclusion_options(self, value: Optional[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs']]):
        pulumi.set(self, "exclusion_options", value)


if not MYPY:
    class ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgsDict(TypedDict):
        scope: pulumi.Input[builtins.str]
        """
        The scope of automatic upgrades to restrict in the exclusion window. One of: **NO_UPGRADES | NO_MINOR_UPGRADES | NO_MINOR_OR_NODE_UPGRADES**

        Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
        the initial date that the window starts, and the end time is used for calculating duration.Specify `recurrence` in
        [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
        Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.

        Examples:

        ```
        maintenance_policy {
        recurring_window {
        start_time = "2019-01-01T00:00:00Z"
        end_time = "2019-01-02T00:00:00Z"
        recurrence = "FREQ=DAILY"
        }
        maintenance_exclusion{
        exclusion_name = "batch job"
        start_time = "2019-01-01T00:00:00Z"
        end_time = "2019-01-02T00:00:00Z"
        exclusion_options {
        scope = "NO_UPGRADES"
        }
        }
        maintenance_exclusion{
        exclusion_name = "holiday data load"
        start_time = "2019-05-01T00:00:00Z"
        end_time = "2019-05-02T00:00:00Z"
        exclusion_options {
        scope = "NO_MINOR_UPGRADES"
        }
        }
        }
        ```
        """
elif False:
    ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs:
    def __init__(__self__, *,
                 scope: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] scope: The scope of automatic upgrades to restrict in the exclusion window. One of: **NO_UPGRADES | NO_MINOR_UPGRADES | NO_MINOR_OR_NODE_UPGRADES**
               
               Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
               the initial date that the window starts, and the end time is used for calculating duration.Specify `recurrence` in
               [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
               Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.
               
               Examples:
               
               ```
               maintenance_policy {
               recurring_window {
               start_time = "2019-01-01T00:00:00Z"
               end_time = "2019-01-02T00:00:00Z"
               recurrence = "FREQ=DAILY"
               }
               maintenance_exclusion{
               exclusion_name = "batch job"
               start_time = "2019-01-01T00:00:00Z"
               end_time = "2019-01-02T00:00:00Z"
               exclusion_options {
               scope = "NO_UPGRADES"
               }
               }
               maintenance_exclusion{
               exclusion_name = "holiday data load"
               start_time = "2019-05-01T00:00:00Z"
               end_time = "2019-05-02T00:00:00Z"
               exclusion_options {
               scope = "NO_MINOR_UPGRADES"
               }
               }
               }
               ```
        """
        pulumi.set(__self__, "scope", scope)

    @property
    @pulumi.getter
    def scope(self) -> pulumi.Input[builtins.str]:
        """
        The scope of automatic upgrades to restrict in the exclusion window. One of: **NO_UPGRADES | NO_MINOR_UPGRADES | NO_MINOR_OR_NODE_UPGRADES**

        Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
        the initial date that the window starts, and the end time is used for calculating duration.Specify `recurrence` in
        [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
        Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.

        Examples:

        ```
        maintenance_policy {
        recurring_window {
        start_time = "2019-01-01T00:00:00Z"
        end_time = "2019-01-02T00:00:00Z"
        recurrence = "FREQ=DAILY"
        }
        maintenance_exclusion{
        exclusion_name = "batch job"
        start_time = "2019-01-01T00:00:00Z"
        end_time = "2019-01-02T00:00:00Z"
        exclusion_options {
        scope = "NO_UPGRADES"
        }
        }
        maintenance_exclusion{
        exclusion_name = "holiday data load"
        start_time = "2019-05-01T00:00:00Z"
        end_time = "2019-05-02T00:00:00Z"
        exclusion_options {
        scope = "NO_MINOR_UPGRADES"
        }
        }
        }
        ```
        """
        return pulumi.get(self, "scope")

    @scope.setter
    def scope(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "scope", value)


if not MYPY:
    class ClusterMaintenancePolicyRecurringWindowArgsDict(TypedDict):
        end_time: pulumi.Input[builtins.str]
        recurrence: pulumi.Input[builtins.str]
        start_time: pulumi.Input[builtins.str]
elif False:
    ClusterMaintenancePolicyRecurringWindowArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMaintenancePolicyRecurringWindowArgs:
    def __init__(__self__, *,
                 end_time: pulumi.Input[builtins.str],
                 recurrence: pulumi.Input[builtins.str],
                 start_time: pulumi.Input[builtins.str]):
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "recurrence", recurrence)
        pulumi.set(__self__, "start_time", start_time)

    @property
    @pulumi.getter(name="endTime")
    def end_time(self) -> pulumi.Input[builtins.str]:
        return pulumi.get(self, "end_time")

    @end_time.setter
    def end_time(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "end_time", value)

    @property
    @pulumi.getter
    def recurrence(self) -> pulumi.Input[builtins.str]:
        return pulumi.get(self, "recurrence")

    @recurrence.setter
    def recurrence(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "recurrence", value)

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> pulumi.Input[builtins.str]:
        return pulumi.get(self, "start_time")

    @start_time.setter
    def start_time(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "start_time", value)


if not MYPY:
    class ClusterMasterAuthArgsDict(TypedDict):
        client_certificate_config: pulumi.Input['ClusterMasterAuthClientCertificateConfigArgsDict']
        """
        Whether client certificate authorization is enabled for this cluster.  For example:
        """
        client_certificate: NotRequired[pulumi.Input[builtins.str]]
        """
        Base64 encoded public certificate
        used by clients to authenticate to the cluster endpoint.
        """
        client_key: NotRequired[pulumi.Input[builtins.str]]
        """
        Base64 encoded private key used by clients
        to authenticate to the cluster endpoint.
        """
        cluster_ca_certificate: NotRequired[pulumi.Input[builtins.str]]
        """
        Base64 encoded public certificate
        that is the root certificate of the cluster.
        """
elif False:
    ClusterMasterAuthArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMasterAuthArgs:
    def __init__(__self__, *,
                 client_certificate_config: pulumi.Input['ClusterMasterAuthClientCertificateConfigArgs'],
                 client_certificate: Optional[pulumi.Input[builtins.str]] = None,
                 client_key: Optional[pulumi.Input[builtins.str]] = None,
                 cluster_ca_certificate: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input['ClusterMasterAuthClientCertificateConfigArgs'] client_certificate_config: Whether client certificate authorization is enabled for this cluster.  For example:
        :param pulumi.Input[builtins.str] client_certificate: Base64 encoded public certificate
               used by clients to authenticate to the cluster endpoint.
        :param pulumi.Input[builtins.str] client_key: Base64 encoded private key used by clients
               to authenticate to the cluster endpoint.
        :param pulumi.Input[builtins.str] cluster_ca_certificate: Base64 encoded public certificate
               that is the root certificate of the cluster.
        """
        pulumi.set(__self__, "client_certificate_config", client_certificate_config)
        if client_certificate is not None:
            pulumi.set(__self__, "client_certificate", client_certificate)
        if client_key is not None:
            pulumi.set(__self__, "client_key", client_key)
        if cluster_ca_certificate is not None:
            pulumi.set(__self__, "cluster_ca_certificate", cluster_ca_certificate)

    @property
    @pulumi.getter(name="clientCertificateConfig")
    def client_certificate_config(self) -> pulumi.Input['ClusterMasterAuthClientCertificateConfigArgs']:
        """
        Whether client certificate authorization is enabled for this cluster.  For example:
        """
        return pulumi.get(self, "client_certificate_config")

    @client_certificate_config.setter
    def client_certificate_config(self, value: pulumi.Input['ClusterMasterAuthClientCertificateConfigArgs']):
        pulumi.set(self, "client_certificate_config", value)

    @property
    @pulumi.getter(name="clientCertificate")
    def client_certificate(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Base64 encoded public certificate
        used by clients to authenticate to the cluster endpoint.
        """
        return pulumi.get(self, "client_certificate")

    @client_certificate.setter
    def client_certificate(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "client_certificate", value)

    @property
    @pulumi.getter(name="clientKey")
    def client_key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Base64 encoded private key used by clients
        to authenticate to the cluster endpoint.
        """
        return pulumi.get(self, "client_key")

    @client_key.setter
    def client_key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "client_key", value)

    @property
    @pulumi.getter(name="clusterCaCertificate")
    def cluster_ca_certificate(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Base64 encoded public certificate
        that is the root certificate of the cluster.
        """
        return pulumi.get(self, "cluster_ca_certificate")

    @cluster_ca_certificate.setter
    def cluster_ca_certificate(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cluster_ca_certificate", value)


if not MYPY:
    class ClusterMasterAuthClientCertificateConfigArgsDict(TypedDict):
        issue_client_certificate: pulumi.Input[builtins.bool]
        """
        Whether client certificate authorization is enabled for this cluster.
        """
elif False:
    ClusterMasterAuthClientCertificateConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMasterAuthClientCertificateConfigArgs:
    def __init__(__self__, *,
                 issue_client_certificate: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] issue_client_certificate: Whether client certificate authorization is enabled for this cluster.
        """
        pulumi.set(__self__, "issue_client_certificate", issue_client_certificate)

    @property
    @pulumi.getter(name="issueClientCertificate")
    def issue_client_certificate(self) -> pulumi.Input[builtins.bool]:
        """
        Whether client certificate authorization is enabled for this cluster.
        """
        return pulumi.get(self, "issue_client_certificate")

    @issue_client_certificate.setter
    def issue_client_certificate(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "issue_client_certificate", value)


if not MYPY:
    class ClusterMasterAuthorizedNetworksConfigArgsDict(TypedDict):
        cidr_blocks: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterMasterAuthorizedNetworksConfigCidrBlockArgsDict']]]]
        """
        External networks that can access the
        Kubernetes cluster master through HTTPS.
        """
        gcp_public_cidrs_access_enabled: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether Kubernetes master is
        accessible via Google Compute Engine Public IPs.
        """
        private_endpoint_enforcement_enabled: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether authorized networks is enforced on the private endpoint or not.
        """
elif False:
    ClusterMasterAuthorizedNetworksConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMasterAuthorizedNetworksConfigArgs:
    def __init__(__self__, *,
                 cidr_blocks: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMasterAuthorizedNetworksConfigCidrBlockArgs']]]] = None,
                 gcp_public_cidrs_access_enabled: Optional[pulumi.Input[builtins.bool]] = None,
                 private_endpoint_enforcement_enabled: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input['ClusterMasterAuthorizedNetworksConfigCidrBlockArgs']]] cidr_blocks: External networks that can access the
               Kubernetes cluster master through HTTPS.
        :param pulumi.Input[builtins.bool] gcp_public_cidrs_access_enabled: Whether Kubernetes master is
               accessible via Google Compute Engine Public IPs.
        :param pulumi.Input[builtins.bool] private_endpoint_enforcement_enabled: Whether authorized networks is enforced on the private endpoint or not.
        """
        if cidr_blocks is not None:
            pulumi.set(__self__, "cidr_blocks", cidr_blocks)
        if gcp_public_cidrs_access_enabled is not None:
            pulumi.set(__self__, "gcp_public_cidrs_access_enabled", gcp_public_cidrs_access_enabled)
        if private_endpoint_enforcement_enabled is not None:
            pulumi.set(__self__, "private_endpoint_enforcement_enabled", private_endpoint_enforcement_enabled)

    @property
    @pulumi.getter(name="cidrBlocks")
    def cidr_blocks(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMasterAuthorizedNetworksConfigCidrBlockArgs']]]]:
        """
        External networks that can access the
        Kubernetes cluster master through HTTPS.
        """
        return pulumi.get(self, "cidr_blocks")

    @cidr_blocks.setter
    def cidr_blocks(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMasterAuthorizedNetworksConfigCidrBlockArgs']]]]):
        pulumi.set(self, "cidr_blocks", value)

    @property
    @pulumi.getter(name="gcpPublicCidrsAccessEnabled")
    def gcp_public_cidrs_access_enabled(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether Kubernetes master is
        accessible via Google Compute Engine Public IPs.
        """
        return pulumi.get(self, "gcp_public_cidrs_access_enabled")

    @gcp_public_cidrs_access_enabled.setter
    def gcp_public_cidrs_access_enabled(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "gcp_public_cidrs_access_enabled", value)

    @property
    @pulumi.getter(name="privateEndpointEnforcementEnabled")
    def private_endpoint_enforcement_enabled(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether authorized networks is enforced on the private endpoint or not.
        """
        return pulumi.get(self, "private_endpoint_enforcement_enabled")

    @private_endpoint_enforcement_enabled.setter
    def private_endpoint_enforcement_enabled(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "private_endpoint_enforcement_enabled", value)


if not MYPY:
    class ClusterMasterAuthorizedNetworksConfigCidrBlockArgsDict(TypedDict):
        cidr_block: pulumi.Input[builtins.str]
        """
        External network that can access Kubernetes master through HTTPS.
        Must be specified in CIDR notation.
        """
        display_name: NotRequired[pulumi.Input[builtins.str]]
        """
        Field for users to identify CIDR blocks.
        """
elif False:
    ClusterMasterAuthorizedNetworksConfigCidrBlockArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMasterAuthorizedNetworksConfigCidrBlockArgs:
    def __init__(__self__, *,
                 cidr_block: pulumi.Input[builtins.str],
                 display_name: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] cidr_block: External network that can access Kubernetes master through HTTPS.
               Must be specified in CIDR notation.
        :param pulumi.Input[builtins.str] display_name: Field for users to identify CIDR blocks.
        """
        pulumi.set(__self__, "cidr_block", cidr_block)
        if display_name is not None:
            pulumi.set(__self__, "display_name", display_name)

    @property
    @pulumi.getter(name="cidrBlock")
    def cidr_block(self) -> pulumi.Input[builtins.str]:
        """
        External network that can access Kubernetes master through HTTPS.
        Must be specified in CIDR notation.
        """
        return pulumi.get(self, "cidr_block")

    @cidr_block.setter
    def cidr_block(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "cidr_block", value)

    @property
    @pulumi.getter(name="displayName")
    def display_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Field for users to identify CIDR blocks.
        """
        return pulumi.get(self, "display_name")

    @display_name.setter
    def display_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "display_name", value)


if not MYPY:
    class ClusterMeshCertificatesArgsDict(TypedDict):
        enable_certificates: pulumi.Input[builtins.bool]
        """
        Controls the issuance of workload mTLS certificates. It is enabled by default. Workload Identity is required, see workload_config.
        """
elif False:
    ClusterMeshCertificatesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMeshCertificatesArgs:
    def __init__(__self__, *,
                 enable_certificates: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enable_certificates: Controls the issuance of workload mTLS certificates. It is enabled by default. Workload Identity is required, see workload_config.
        """
        pulumi.set(__self__, "enable_certificates", enable_certificates)

    @property
    @pulumi.getter(name="enableCertificates")
    def enable_certificates(self) -> pulumi.Input[builtins.bool]:
        """
        Controls the issuance of workload mTLS certificates. It is enabled by default. Workload Identity is required, see workload_config.
        """
        return pulumi.get(self, "enable_certificates")

    @enable_certificates.setter
    def enable_certificates(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enable_certificates", value)


if not MYPY:
    class ClusterMonitoringConfigArgsDict(TypedDict):
        advanced_datapath_observability_config: NotRequired[pulumi.Input['ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgsDict']]
        """
        Configuration for Advanced Datapath Monitoring. Structure is documented below.
        """
        enable_components: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The GKE components exposing metrics. Supported values include: `SYSTEM_COMPONENTS`, `APISERVER`, `SCHEDULER`, `CONTROLLER_MANAGER`, `STORAGE`, `HPA`, `POD`, `DAEMONSET`, `DEPLOYMENT`, `STATEFULSET`, `KUBELET`, `CADVISOR`, `DCGM` and `JOBSET`. In beta provider, `WORKLOADS` is supported on top of those 12 values. (`WORKLOADS` is deprecated and removed in GKE 1.24.) `KUBELET` and `CADVISOR` are only supported in GKE 1.29.3-gke.1093000 and above. `JOBSET` is only supported in GKE 1.32.1-gke.1357001 and above.
        """
        managed_prometheus: NotRequired[pulumi.Input['ClusterMonitoringConfigManagedPrometheusArgsDict']]
        """
        Configuration for Managed Service for Prometheus. Structure is documented below.
        """
elif False:
    ClusterMonitoringConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMonitoringConfigArgs:
    def __init__(__self__, *,
                 advanced_datapath_observability_config: Optional[pulumi.Input['ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs']] = None,
                 enable_components: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 managed_prometheus: Optional[pulumi.Input['ClusterMonitoringConfigManagedPrometheusArgs']] = None):
        """
        :param pulumi.Input['ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs'] advanced_datapath_observability_config: Configuration for Advanced Datapath Monitoring. Structure is documented below.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] enable_components: The GKE components exposing metrics. Supported values include: `SYSTEM_COMPONENTS`, `APISERVER`, `SCHEDULER`, `CONTROLLER_MANAGER`, `STORAGE`, `HPA`, `POD`, `DAEMONSET`, `DEPLOYMENT`, `STATEFULSET`, `KUBELET`, `CADVISOR`, `DCGM` and `JOBSET`. In beta provider, `WORKLOADS` is supported on top of those 12 values. (`WORKLOADS` is deprecated and removed in GKE 1.24.) `KUBELET` and `CADVISOR` are only supported in GKE 1.29.3-gke.1093000 and above. `JOBSET` is only supported in GKE 1.32.1-gke.1357001 and above.
        :param pulumi.Input['ClusterMonitoringConfigManagedPrometheusArgs'] managed_prometheus: Configuration for Managed Service for Prometheus. Structure is documented below.
        """
        if advanced_datapath_observability_config is not None:
            pulumi.set(__self__, "advanced_datapath_observability_config", advanced_datapath_observability_config)
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)
        if managed_prometheus is not None:
            pulumi.set(__self__, "managed_prometheus", managed_prometheus)

    @property
    @pulumi.getter(name="advancedDatapathObservabilityConfig")
    def advanced_datapath_observability_config(self) -> Optional[pulumi.Input['ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs']]:
        """
        Configuration for Advanced Datapath Monitoring. Structure is documented below.
        """
        return pulumi.get(self, "advanced_datapath_observability_config")

    @advanced_datapath_observability_config.setter
    def advanced_datapath_observability_config(self, value: Optional[pulumi.Input['ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs']]):
        pulumi.set(self, "advanced_datapath_observability_config", value)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The GKE components exposing metrics. Supported values include: `SYSTEM_COMPONENTS`, `APISERVER`, `SCHEDULER`, `CONTROLLER_MANAGER`, `STORAGE`, `HPA`, `POD`, `DAEMONSET`, `DEPLOYMENT`, `STATEFULSET`, `KUBELET`, `CADVISOR`, `DCGM` and `JOBSET`. In beta provider, `WORKLOADS` is supported on top of those 12 values. (`WORKLOADS` is deprecated and removed in GKE 1.24.) `KUBELET` and `CADVISOR` are only supported in GKE 1.29.3-gke.1093000 and above. `JOBSET` is only supported in GKE 1.32.1-gke.1357001 and above.
        """
        return pulumi.get(self, "enable_components")

    @enable_components.setter
    def enable_components(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "enable_components", value)

    @property
    @pulumi.getter(name="managedPrometheus")
    def managed_prometheus(self) -> Optional[pulumi.Input['ClusterMonitoringConfigManagedPrometheusArgs']]:
        """
        Configuration for Managed Service for Prometheus. Structure is documented below.
        """
        return pulumi.get(self, "managed_prometheus")

    @managed_prometheus.setter
    def managed_prometheus(self, value: Optional[pulumi.Input['ClusterMonitoringConfigManagedPrometheusArgs']]):
        pulumi.set(self, "managed_prometheus", value)


if not MYPY:
    class ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgsDict(TypedDict):
        enable_metrics: pulumi.Input[builtins.bool]
        """
        Whether or not to enable advanced datapath metrics.
        """
        enable_relay: pulumi.Input[builtins.bool]
        """
        Whether or not Relay is enabled.
        """
elif False:
    ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs:
    def __init__(__self__, *,
                 enable_metrics: pulumi.Input[builtins.bool],
                 enable_relay: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enable_metrics: Whether or not to enable advanced datapath metrics.
        :param pulumi.Input[builtins.bool] enable_relay: Whether or not Relay is enabled.
        """
        pulumi.set(__self__, "enable_metrics", enable_metrics)
        pulumi.set(__self__, "enable_relay", enable_relay)

    @property
    @pulumi.getter(name="enableMetrics")
    def enable_metrics(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not to enable advanced datapath metrics.
        """
        return pulumi.get(self, "enable_metrics")

    @enable_metrics.setter
    def enable_metrics(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enable_metrics", value)

    @property
    @pulumi.getter(name="enableRelay")
    def enable_relay(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not Relay is enabled.
        """
        return pulumi.get(self, "enable_relay")

    @enable_relay.setter
    def enable_relay(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enable_relay", value)


if not MYPY:
    class ClusterMonitoringConfigManagedPrometheusArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not the managed collection is enabled.
        """
        auto_monitoring_config: NotRequired[pulumi.Input['ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigArgsDict']]
        """
        Configuration options for GKE Auto-Monitoring.
        """
elif False:
    ClusterMonitoringConfigManagedPrometheusArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMonitoringConfigManagedPrometheusArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool],
                 auto_monitoring_config: Optional[pulumi.Input['ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigArgs']] = None):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not the managed collection is enabled.
        :param pulumi.Input['ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigArgs'] auto_monitoring_config: Configuration options for GKE Auto-Monitoring.
        """
        pulumi.set(__self__, "enabled", enabled)
        if auto_monitoring_config is not None:
            pulumi.set(__self__, "auto_monitoring_config", auto_monitoring_config)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not the managed collection is enabled.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter(name="autoMonitoringConfig")
    def auto_monitoring_config(self) -> Optional[pulumi.Input['ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigArgs']]:
        """
        Configuration options for GKE Auto-Monitoring.
        """
        return pulumi.get(self, "auto_monitoring_config")

    @auto_monitoring_config.setter
    def auto_monitoring_config(self, value: Optional[pulumi.Input['ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigArgs']]):
        pulumi.set(self, "auto_monitoring_config", value)


if not MYPY:
    class ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigArgsDict(TypedDict):
        scope: pulumi.Input[builtins.str]
        """
        Whether or not to enable GKE Auto-Monitoring. Supported values include: `ALL`, `NONE`.
        """
elif False:
    ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMonitoringConfigManagedPrometheusAutoMonitoringConfigArgs:
    def __init__(__self__, *,
                 scope: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] scope: Whether or not to enable GKE Auto-Monitoring. Supported values include: `ALL`, `NONE`.
        """
        pulumi.set(__self__, "scope", scope)

    @property
    @pulumi.getter
    def scope(self) -> pulumi.Input[builtins.str]:
        """
        Whether or not to enable GKE Auto-Monitoring. Supported values include: `ALL`, `NONE`.
        """
        return pulumi.get(self, "scope")

    @scope.setter
    def scope(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "scope", value)


if not MYPY:
    class ClusterNetworkPolicyArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether network policy is enabled on the cluster.
        """
        provider: NotRequired[pulumi.Input[builtins.str]]
        """
        The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.
        """
elif False:
    ClusterNetworkPolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNetworkPolicyArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool],
                 provider: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether network policy is enabled on the cluster.
        :param pulumi.Input[builtins.str] provider: The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.
        """
        pulumi.set(__self__, "enabled", enabled)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether network policy is enabled on the cluster.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter
    def provider(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.
        """
        return pulumi.get(self, "provider")

    @provider.setter
    def provider(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "provider", value)


if not MYPY:
    class ClusterNodeConfigArgsDict(TypedDict):
        advanced_machine_features: NotRequired[pulumi.Input['ClusterNodeConfigAdvancedMachineFeaturesArgsDict']]
        """
        Specifies options for controlling
        advanced machine features. Structure is documented below.
        """
        boot_disk_kms_key: NotRequired[pulumi.Input[builtins.str]]
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        """
        confidential_nodes: NotRequired[pulumi.Input['ClusterNodeConfigConfidentialNodesArgsDict']]
        """
        Configuration for Confidential Nodes feature. Structure is documented below.
        """
        containerd_config: NotRequired[pulumi.Input['ClusterNodeConfigContainerdConfigArgsDict']]
        """
        Parameters to customize containerd runtime. Structure is documented below.
        """
        disk_size_gb: NotRequired[pulumi.Input[builtins.int]]
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        """
        disk_type: NotRequired[pulumi.Input[builtins.str]]
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        """
        effective_taints: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigEffectiveTaintArgsDict']]]]
        """
        List of kubernetes taints applied to each node. Structure is documented above.
        """
        enable_confidential_storage: NotRequired[pulumi.Input[builtins.bool]]
        """
        Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        """
        ephemeral_storage_config: NotRequired[pulumi.Input['ClusterNodeConfigEphemeralStorageConfigArgsDict']]
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        ephemeral_storage_local_ssd_config: NotRequired[pulumi.Input['ClusterNodeConfigEphemeralStorageLocalSsdConfigArgsDict']]
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        fast_socket: NotRequired[pulumi.Input['ClusterNodeConfigFastSocketArgsDict']]
        """
        Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
        Node Pool must enable gvnic.
        GKE version 1.25.2-gke.1700 or later.
        Structure is documented below.
        """
        flex_start: NotRequired[pulumi.Input[builtins.bool]]
        """
        ) Enables Flex Start provisioning model for the node pool.
        """
        gcfs_config: NotRequired[pulumi.Input['ClusterNodeConfigGcfsConfigArgsDict']]
        """
        Parameters for the Google Container Filesystem (GCFS).
        If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
        For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
        A `machine_type` that has more than 16 GiB of memory is also recommended.
        GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
        Structure is documented below.
        """
        guest_accelerators: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigGuestAcceleratorArgsDict']]]]
        """
        List of the type and count of accelerator cards attached to the instance.
        Structure documented below.
        """
        gvnic: NotRequired[pulumi.Input['ClusterNodeConfigGvnicArgsDict']]
        """
        Google Virtual NIC (gVNIC) is a virtual network interface.
        Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
        gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
        GKE node version 1.15.11-gke.15 or later
        Structure is documented below.
        """
        host_maintenance_policy: NotRequired[pulumi.Input['ClusterNodeConfigHostMaintenancePolicyArgsDict']]
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        image_type: NotRequired[pulumi.Input[builtins.str]]
        """
        The image type to use for this node. Note that changing the image type
        will delete and recreate all nodes in the node pool.
        """
        kubelet_config: NotRequired[pulumi.Input['ClusterNodeConfigKubeletConfigArgsDict']]
        """
        Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Structure is documented below.

        ```
        kubelet_config {
        cpu_manager_policy   = "static"
        cpu_cfs_quota        = true
        cpu_cfs_quota_period = "100us"
        pod_pids_limit       = 1024
        }
        ```
        """
        labels: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
        reserved by Kubernetes Core components and cannot be specified.
        """
        linux_node_config: NotRequired[pulumi.Input['ClusterNodeConfigLinuxNodeConfigArgsDict']]
        """
        Parameters that can be configured on Linux nodes. Structure is documented below.
        """
        local_nvme_ssd_block_config: NotRequired[pulumi.Input['ClusterNodeConfigLocalNvmeSsdBlockConfigArgsDict']]
        """
        Parameters for the local NVMe SSDs. Structure is documented below.
        """
        local_ssd_count: NotRequired[pulumi.Input[builtins.int]]
        """
        The amount of local SSD disks that will be
        attached to each cluster node. Defaults to 0.
        """
        local_ssd_encryption_mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Possible Local SSD encryption modes:
        Accepted values are:
        * `STANDARD_ENCRYPTION`: The given node will be encrypted using keys managed by Google infrastructure and the keys wll be deleted when the node is deleted.
        * `EPHEMERAL_KEY_ENCRYPTION`: The given node will opt-in for using ephemeral key for encrypting Local SSDs. The Local SSDs will not be able to recover data in case of node crash.
        """
        logging_variant: NotRequired[pulumi.Input[builtins.str]]
        """
        Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        machine_type: NotRequired[pulumi.Input[builtins.str]]
        """
        The name of a Google Compute Engine machine type.
        Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
        [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        """
        max_run_duration: NotRequired[pulumi.Input[builtins.str]]
        """
        The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        """
        metadata: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        The metadata key/value pairs assigned to instances in
        the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
        `true` by the API; if `metadata` is set but that default value is not
        included, the provider will attempt to unset the value. To avoid this, set the
        value in your config.
        """
        min_cpu_platform: NotRequired[pulumi.Input[builtins.str]]
        """
        Minimum CPU platform to be used by this instance.
        The instance may be scheduled on the specified or newer CPU platform. Applicable
        values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
        [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
        for more information.
        """
        node_group: NotRequired[pulumi.Input[builtins.str]]
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        """
        oauth_scopes: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The set of Google API scopes to be made available
        on all of the node VMs under the "default" service account.
        Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        """
        preemptible: NotRequired[pulumi.Input[builtins.bool]]
        """
        A boolean that represents whether or not the underlying node VMs
        are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
        for more information. Defaults to false.
        """
        reservation_affinity: NotRequired[pulumi.Input['ClusterNodeConfigReservationAffinityArgsDict']]
        """
        The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        """
        resource_labels: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
        for how these labels are applied to clusters, node pools and nodes.
        """
        resource_manager_tags: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        sandbox_config: NotRequired[pulumi.Input['ClusterNodeConfigSandboxConfigArgsDict']]
        """
        Sandbox configuration for this node.
        """
        secondary_boot_disks: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSecondaryBootDiskArgsDict']]]]
        """
        Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        """
        service_account: NotRequired[pulumi.Input[builtins.str]]
        """
        The service account to be used by the Node VMs.
        If not specified, the "default" service account is used.
        """
        shielded_instance_config: NotRequired[pulumi.Input['ClusterNodeConfigShieldedInstanceConfigArgsDict']]
        """
        Shielded Instance options. Structure is documented below.
        """
        sole_tenant_config: NotRequired[pulumi.Input['ClusterNodeConfigSoleTenantConfigArgsDict']]
        """
        Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
        """
        spot: NotRequired[pulumi.Input[builtins.bool]]
        """
        A boolean that represents whether the underlying node VMs are spot.
        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
        for more information. Defaults to false.
        """
        storage_pools: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        tags: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The list of instance tags applied to all nodes. Tags are used to identify
        valid sources or targets for network firewalls.
        """
        taints: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigTaintArgsDict']]]]
        """
        A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
        to apply to nodes. GKE's API can only set this field on cluster creation.
        However, GKE will add taints to your nodes if you enable certain features such
        as GPUs. If this field is set, any diffs on this field will cause the provider to
        recreate the underlying resource. Taint values can be updated safely in
        Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
        this field to manage taints. If you do, `lifecycle.ignore_changes` is
        recommended. Structure is documented below.
        """
        windows_node_config: NotRequired[pulumi.Input['ClusterNodeConfigWindowsNodeConfigArgsDict']]
        """
        Windows node configuration, currently supporting OSVersion [attribute](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/NodeConfig#osversion). The value must be one of [OS_VERSION_UNSPECIFIED, OS_VERSION_LTSC2019, OS_VERSION_LTSC2022]. For example:
        """
        workload_metadata_config: NotRequired[pulumi.Input['ClusterNodeConfigWorkloadMetadataConfigArgsDict']]
        """
        Metadata configuration to expose to workloads on the node pool.
        Structure is documented below.
        """
elif False:
    ClusterNodeConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigArgs:
    def __init__(__self__, *,
                 advanced_machine_features: Optional[pulumi.Input['ClusterNodeConfigAdvancedMachineFeaturesArgs']] = None,
                 boot_disk_kms_key: Optional[pulumi.Input[builtins.str]] = None,
                 confidential_nodes: Optional[pulumi.Input['ClusterNodeConfigConfidentialNodesArgs']] = None,
                 containerd_config: Optional[pulumi.Input['ClusterNodeConfigContainerdConfigArgs']] = None,
                 disk_size_gb: Optional[pulumi.Input[builtins.int]] = None,
                 disk_type: Optional[pulumi.Input[builtins.str]] = None,
                 effective_taints: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigEffectiveTaintArgs']]]] = None,
                 enable_confidential_storage: Optional[pulumi.Input[builtins.bool]] = None,
                 ephemeral_storage_config: Optional[pulumi.Input['ClusterNodeConfigEphemeralStorageConfigArgs']] = None,
                 ephemeral_storage_local_ssd_config: Optional[pulumi.Input['ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs']] = None,
                 fast_socket: Optional[pulumi.Input['ClusterNodeConfigFastSocketArgs']] = None,
                 flex_start: Optional[pulumi.Input[builtins.bool]] = None,
                 gcfs_config: Optional[pulumi.Input['ClusterNodeConfigGcfsConfigArgs']] = None,
                 guest_accelerators: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigGuestAcceleratorArgs']]]] = None,
                 gvnic: Optional[pulumi.Input['ClusterNodeConfigGvnicArgs']] = None,
                 host_maintenance_policy: Optional[pulumi.Input['ClusterNodeConfigHostMaintenancePolicyArgs']] = None,
                 image_type: Optional[pulumi.Input[builtins.str]] = None,
                 kubelet_config: Optional[pulumi.Input['ClusterNodeConfigKubeletConfigArgs']] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 linux_node_config: Optional[pulumi.Input['ClusterNodeConfigLinuxNodeConfigArgs']] = None,
                 local_nvme_ssd_block_config: Optional[pulumi.Input['ClusterNodeConfigLocalNvmeSsdBlockConfigArgs']] = None,
                 local_ssd_count: Optional[pulumi.Input[builtins.int]] = None,
                 local_ssd_encryption_mode: Optional[pulumi.Input[builtins.str]] = None,
                 logging_variant: Optional[pulumi.Input[builtins.str]] = None,
                 machine_type: Optional[pulumi.Input[builtins.str]] = None,
                 max_run_duration: Optional[pulumi.Input[builtins.str]] = None,
                 metadata: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 min_cpu_platform: Optional[pulumi.Input[builtins.str]] = None,
                 node_group: Optional[pulumi.Input[builtins.str]] = None,
                 oauth_scopes: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 preemptible: Optional[pulumi.Input[builtins.bool]] = None,
                 reservation_affinity: Optional[pulumi.Input['ClusterNodeConfigReservationAffinityArgs']] = None,
                 resource_labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 resource_manager_tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 sandbox_config: Optional[pulumi.Input['ClusterNodeConfigSandboxConfigArgs']] = None,
                 secondary_boot_disks: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSecondaryBootDiskArgs']]]] = None,
                 service_account: Optional[pulumi.Input[builtins.str]] = None,
                 shielded_instance_config: Optional[pulumi.Input['ClusterNodeConfigShieldedInstanceConfigArgs']] = None,
                 sole_tenant_config: Optional[pulumi.Input['ClusterNodeConfigSoleTenantConfigArgs']] = None,
                 spot: Optional[pulumi.Input[builtins.bool]] = None,
                 storage_pools: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 tags: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 taints: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigTaintArgs']]]] = None,
                 windows_node_config: Optional[pulumi.Input['ClusterNodeConfigWindowsNodeConfigArgs']] = None,
                 workload_metadata_config: Optional[pulumi.Input['ClusterNodeConfigWorkloadMetadataConfigArgs']] = None):
        """
        :param pulumi.Input['ClusterNodeConfigAdvancedMachineFeaturesArgs'] advanced_machine_features: Specifies options for controlling
               advanced machine features. Structure is documented below.
        :param pulumi.Input[builtins.str] boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        :param pulumi.Input['ClusterNodeConfigConfidentialNodesArgs'] confidential_nodes: Configuration for Confidential Nodes feature. Structure is documented below.
        :param pulumi.Input['ClusterNodeConfigContainerdConfigArgs'] containerd_config: Parameters to customize containerd runtime. Structure is documented below.
        :param pulumi.Input[builtins.int] disk_size_gb: Size of the disk attached to each node, specified
               in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        :param pulumi.Input[builtins.str] disk_type: Type of the disk attached to each node
               (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigEffectiveTaintArgs']]] effective_taints: List of kubernetes taints applied to each node. Structure is documented above.
        :param pulumi.Input[builtins.bool] enable_confidential_storage: Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        :param pulumi.Input['ClusterNodeConfigEphemeralStorageConfigArgs'] ephemeral_storage_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        :param pulumi.Input['ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs'] ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        :param pulumi.Input['ClusterNodeConfigFastSocketArgs'] fast_socket: Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
               Node Pool must enable gvnic.
               GKE version 1.25.2-gke.1700 or later.
               Structure is documented below.
        :param pulumi.Input[builtins.bool] flex_start: ) Enables Flex Start provisioning model for the node pool.
        :param pulumi.Input['ClusterNodeConfigGcfsConfigArgs'] gcfs_config: Parameters for the Google Container Filesystem (GCFS).
               If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
               For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
               A `machine_type` that has more than 16 GiB of memory is also recommended.
               GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
               Structure is documented below.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigGuestAcceleratorArgs']]] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
               Structure documented below.
        :param pulumi.Input['ClusterNodeConfigGvnicArgs'] gvnic: Google Virtual NIC (gVNIC) is a virtual network interface.
               Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
               gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
               GKE node version 1.15.11-gke.15 or later
               Structure is documented below.
        :param pulumi.Input['ClusterNodeConfigHostMaintenancePolicyArgs'] host_maintenance_policy: The maintenance policy for the hosts on which the GKE VMs run on.
        :param pulumi.Input[builtins.str] image_type: The image type to use for this node. Note that changing the image type
               will delete and recreate all nodes in the node pool.
        :param pulumi.Input['ClusterNodeConfigKubeletConfigArgs'] kubelet_config: Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Structure is documented below.
               
               ```
               kubelet_config {
               cpu_manager_policy   = "static"
               cpu_cfs_quota        = true
               cpu_cfs_quota_period = "100us"
               pod_pids_limit       = 1024
               }
               ```
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] labels: The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
               reserved by Kubernetes Core components and cannot be specified.
        :param pulumi.Input['ClusterNodeConfigLinuxNodeConfigArgs'] linux_node_config: Parameters that can be configured on Linux nodes. Structure is documented below.
        :param pulumi.Input['ClusterNodeConfigLocalNvmeSsdBlockConfigArgs'] local_nvme_ssd_block_config: Parameters for the local NVMe SSDs. Structure is documented below.
        :param pulumi.Input[builtins.int] local_ssd_count: The amount of local SSD disks that will be
               attached to each cluster node. Defaults to 0.
        :param pulumi.Input[builtins.str] local_ssd_encryption_mode: Possible Local SSD encryption modes:
               Accepted values are:
               * `STANDARD_ENCRYPTION`: The given node will be encrypted using keys managed by Google infrastructure and the keys wll be deleted when the node is deleted.
               * `EPHEMERAL_KEY_ENCRYPTION`: The given node will opt-in for using ephemeral key for encrypting Local SSDs. The Local SSDs will not be able to recover data in case of node crash.
        :param pulumi.Input[builtins.str] logging_variant: Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        :param pulumi.Input[builtins.str] machine_type: The name of a Google Compute Engine machine type.
               Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
               [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        :param pulumi.Input[builtins.str] max_run_duration: The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] metadata: The metadata key/value pairs assigned to instances in
               the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
               `true` by the API; if `metadata` is set but that default value is not
               included, the provider will attempt to unset the value. To avoid this, set the
               value in your config.
        :param pulumi.Input[builtins.str] min_cpu_platform: Minimum CPU platform to be used by this instance.
               The instance may be scheduled on the specified or newer CPU platform. Applicable
               values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
               [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
               for more information.
        :param pulumi.Input[builtins.str] node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] oauth_scopes: The set of Google API scopes to be made available
               on all of the node VMs under the "default" service account.
               Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        :param pulumi.Input[builtins.bool] preemptible: A boolean that represents whether or not the underlying node VMs
               are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
               for more information. Defaults to false.
        :param pulumi.Input['ClusterNodeConfigReservationAffinityArgs'] reservation_affinity: The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] resource_labels: The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
               for how these labels are applied to clusters, node pools and nodes.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] resource_manager_tags: A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        :param pulumi.Input['ClusterNodeConfigSandboxConfigArgs'] sandbox_config: Sandbox configuration for this node.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSecondaryBootDiskArgs']]] secondary_boot_disks: Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        :param pulumi.Input[builtins.str] service_account: The service account to be used by the Node VMs.
               If not specified, the "default" service account is used.
        :param pulumi.Input['ClusterNodeConfigShieldedInstanceConfigArgs'] shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param pulumi.Input['ClusterNodeConfigSoleTenantConfigArgs'] sole_tenant_config: Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
        :param pulumi.Input[builtins.bool] spot: A boolean that represents whether the underlying node VMs are spot.
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
               for more information. Defaults to false.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] tags: The list of instance tags applied to all nodes. Tags are used to identify
               valid sources or targets for network firewalls.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigTaintArgs']]] taints: A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
               to apply to nodes. GKE's API can only set this field on cluster creation.
               However, GKE will add taints to your nodes if you enable certain features such
               as GPUs. If this field is set, any diffs on this field will cause the provider to
               recreate the underlying resource. Taint values can be updated safely in
               Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
               this field to manage taints. If you do, `lifecycle.ignore_changes` is
               recommended. Structure is documented below.
        :param pulumi.Input['ClusterNodeConfigWindowsNodeConfigArgs'] windows_node_config: Windows node configuration, currently supporting OSVersion [attribute](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/NodeConfig#osversion). The value must be one of [OS_VERSION_UNSPECIFIED, OS_VERSION_LTSC2019, OS_VERSION_LTSC2022]. For example:
        :param pulumi.Input['ClusterNodeConfigWorkloadMetadataConfigArgs'] workload_metadata_config: Metadata configuration to expose to workloads on the node pool.
               Structure is documented below.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if containerd_config is not None:
            pulumi.set(__self__, "containerd_config", containerd_config)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if effective_taints is not None:
            pulumi.set(__self__, "effective_taints", effective_taints)
        if enable_confidential_storage is not None:
            pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if flex_start is not None:
            pulumi.set(__self__, "flex_start", flex_start)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if local_ssd_encryption_mode is not None:
            pulumi.set(__self__, "local_ssd_encryption_mode", local_ssd_encryption_mode)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if max_run_duration is not None:
            pulumi.set(__self__, "max_run_duration", max_run_duration)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if resource_manager_tags is not None:
            pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if secondary_boot_disks is not None:
            pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if storage_pools is not None:
            pulumi.set(__self__, "storage_pools", storage_pools)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if windows_node_config is not None:
            pulumi.set(__self__, "windows_node_config", windows_node_config)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional[pulumi.Input['ClusterNodeConfigAdvancedMachineFeaturesArgs']]:
        """
        Specifies options for controlling
        advanced machine features. Structure is documented below.
        """
        return pulumi.get(self, "advanced_machine_features")

    @advanced_machine_features.setter
    def advanced_machine_features(self, value: Optional[pulumi.Input['ClusterNodeConfigAdvancedMachineFeaturesArgs']]):
        pulumi.set(self, "advanced_machine_features", value)

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @boot_disk_kms_key.setter
    def boot_disk_kms_key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "boot_disk_kms_key", value)

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional[pulumi.Input['ClusterNodeConfigConfidentialNodesArgs']]:
        """
        Configuration for Confidential Nodes feature. Structure is documented below.
        """
        return pulumi.get(self, "confidential_nodes")

    @confidential_nodes.setter
    def confidential_nodes(self, value: Optional[pulumi.Input['ClusterNodeConfigConfidentialNodesArgs']]):
        pulumi.set(self, "confidential_nodes", value)

    @property
    @pulumi.getter(name="containerdConfig")
    def containerd_config(self) -> Optional[pulumi.Input['ClusterNodeConfigContainerdConfigArgs']]:
        """
        Parameters to customize containerd runtime. Structure is documented below.
        """
        return pulumi.get(self, "containerd_config")

    @containerd_config.setter
    def containerd_config(self, value: Optional[pulumi.Input['ClusterNodeConfigContainerdConfigArgs']]):
        pulumi.set(self, "containerd_config", value)

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @disk_size_gb.setter
    def disk_size_gb(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "disk_size_gb", value)

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        """
        return pulumi.get(self, "disk_type")

    @disk_type.setter
    def disk_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "disk_type", value)

    @property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigEffectiveTaintArgs']]]]:
        """
        List of kubernetes taints applied to each node. Structure is documented above.
        """
        return pulumi.get(self, "effective_taints")

    @effective_taints.setter
    def effective_taints(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigEffectiveTaintArgs']]]]):
        pulumi.set(self, "effective_taints", value)

    @property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @enable_confidential_storage.setter
    def enable_confidential_storage(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_confidential_storage", value)

    @property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional[pulumi.Input['ClusterNodeConfigEphemeralStorageConfigArgs']]:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @ephemeral_storage_config.setter
    def ephemeral_storage_config(self, value: Optional[pulumi.Input['ClusterNodeConfigEphemeralStorageConfigArgs']]):
        pulumi.set(self, "ephemeral_storage_config", value)

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional[pulumi.Input['ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs']]:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @ephemeral_storage_local_ssd_config.setter
    def ephemeral_storage_local_ssd_config(self, value: Optional[pulumi.Input['ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs']]):
        pulumi.set(self, "ephemeral_storage_local_ssd_config", value)

    @property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional[pulumi.Input['ClusterNodeConfigFastSocketArgs']]:
        """
        Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
        Node Pool must enable gvnic.
        GKE version 1.25.2-gke.1700 or later.
        Structure is documented below.
        """
        return pulumi.get(self, "fast_socket")

    @fast_socket.setter
    def fast_socket(self, value: Optional[pulumi.Input['ClusterNodeConfigFastSocketArgs']]):
        pulumi.set(self, "fast_socket", value)

    @property
    @pulumi.getter(name="flexStart")
    def flex_start(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        ) Enables Flex Start provisioning model for the node pool.
        """
        return pulumi.get(self, "flex_start")

    @flex_start.setter
    def flex_start(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "flex_start", value)

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional[pulumi.Input['ClusterNodeConfigGcfsConfigArgs']]:
        """
        Parameters for the Google Container Filesystem (GCFS).
        If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
        For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
        A `machine_type` that has more than 16 GiB of memory is also recommended.
        GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
        Structure is documented below.
        """
        return pulumi.get(self, "gcfs_config")

    @gcfs_config.setter
    def gcfs_config(self, value: Optional[pulumi.Input['ClusterNodeConfigGcfsConfigArgs']]):
        pulumi.set(self, "gcfs_config", value)

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigGuestAcceleratorArgs']]]]:
        """
        List of the type and count of accelerator cards attached to the instance.
        Structure documented below.
        """
        return pulumi.get(self, "guest_accelerators")

    @guest_accelerators.setter
    def guest_accelerators(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigGuestAcceleratorArgs']]]]):
        pulumi.set(self, "guest_accelerators", value)

    @property
    @pulumi.getter
    def gvnic(self) -> Optional[pulumi.Input['ClusterNodeConfigGvnicArgs']]:
        """
        Google Virtual NIC (gVNIC) is a virtual network interface.
        Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
        gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
        GKE node version 1.15.11-gke.15 or later
        Structure is documented below.
        """
        return pulumi.get(self, "gvnic")

    @gvnic.setter
    def gvnic(self, value: Optional[pulumi.Input['ClusterNodeConfigGvnicArgs']]):
        pulumi.set(self, "gvnic", value)

    @property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional[pulumi.Input['ClusterNodeConfigHostMaintenancePolicyArgs']]:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policy")

    @host_maintenance_policy.setter
    def host_maintenance_policy(self, value: Optional[pulumi.Input['ClusterNodeConfigHostMaintenancePolicyArgs']]):
        pulumi.set(self, "host_maintenance_policy", value)

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The image type to use for this node. Note that changing the image type
        will delete and recreate all nodes in the node pool.
        """
        return pulumi.get(self, "image_type")

    @image_type.setter
    def image_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "image_type", value)

    @property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional[pulumi.Input['ClusterNodeConfigKubeletConfigArgs']]:
        """
        Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Structure is documented below.

        ```
        kubelet_config {
        cpu_manager_policy   = "static"
        cpu_cfs_quota        = true
        cpu_cfs_quota_period = "100us"
        pod_pids_limit       = 1024
        }
        ```
        """
        return pulumi.get(self, "kubelet_config")

    @kubelet_config.setter
    def kubelet_config(self, value: Optional[pulumi.Input['ClusterNodeConfigKubeletConfigArgs']]):
        pulumi.set(self, "kubelet_config", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
        reserved by Kubernetes Core components and cannot be specified.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional[pulumi.Input['ClusterNodeConfigLinuxNodeConfigArgs']]:
        """
        Parameters that can be configured on Linux nodes. Structure is documented below.
        """
        return pulumi.get(self, "linux_node_config")

    @linux_node_config.setter
    def linux_node_config(self, value: Optional[pulumi.Input['ClusterNodeConfigLinuxNodeConfigArgs']]):
        pulumi.set(self, "linux_node_config", value)

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional[pulumi.Input['ClusterNodeConfigLocalNvmeSsdBlockConfigArgs']]:
        """
        Parameters for the local NVMe SSDs. Structure is documented below.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @local_nvme_ssd_block_config.setter
    def local_nvme_ssd_block_config(self, value: Optional[pulumi.Input['ClusterNodeConfigLocalNvmeSsdBlockConfigArgs']]):
        pulumi.set(self, "local_nvme_ssd_block_config", value)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The amount of local SSD disks that will be
        attached to each cluster node. Defaults to 0.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "local_ssd_count", value)

    @property
    @pulumi.getter(name="localSsdEncryptionMode")
    def local_ssd_encryption_mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Possible Local SSD encryption modes:
        Accepted values are:
        * `STANDARD_ENCRYPTION`: The given node will be encrypted using keys managed by Google infrastructure and the keys wll be deleted when the node is deleted.
        * `EPHEMERAL_KEY_ENCRYPTION`: The given node will opt-in for using ephemeral key for encrypting Local SSDs. The Local SSDs will not be able to recover data in case of node crash.
        """
        return pulumi.get(self, "local_ssd_encryption_mode")

    @local_ssd_encryption_mode.setter
    def local_ssd_encryption_mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "local_ssd_encryption_mode", value)

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")

    @logging_variant.setter
    def logging_variant(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "logging_variant", value)

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of a Google Compute Engine machine type.
        Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
        [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        """
        return pulumi.get(self, "machine_type")

    @machine_type.setter
    def machine_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "machine_type", value)

    @property
    @pulumi.getter(name="maxRunDuration")
    def max_run_duration(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        """
        return pulumi.get(self, "max_run_duration")

    @max_run_duration.setter
    def max_run_duration(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "max_run_duration", value)

    @property
    @pulumi.getter
    def metadata(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The metadata key/value pairs assigned to instances in
        the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
        `true` by the API; if `metadata` is set but that default value is not
        included, the provider will attempt to unset the value. To avoid this, set the
        value in your config.
        """
        return pulumi.get(self, "metadata")

    @metadata.setter
    def metadata(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "metadata", value)

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Minimum CPU platform to be used by this instance.
        The instance may be scheduled on the specified or newer CPU platform. Applicable
        values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
        [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
        for more information.
        """
        return pulumi.get(self, "min_cpu_platform")

    @min_cpu_platform.setter
    def min_cpu_platform(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "min_cpu_platform", value)

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        """
        return pulumi.get(self, "node_group")

    @node_group.setter
    def node_group(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "node_group", value)

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The set of Google API scopes to be made available
        on all of the node VMs under the "default" service account.
        Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        """
        return pulumi.get(self, "oauth_scopes")

    @oauth_scopes.setter
    def oauth_scopes(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "oauth_scopes", value)

    @property
    @pulumi.getter
    def preemptible(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        A boolean that represents whether or not the underlying node VMs
        are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "preemptible")

    @preemptible.setter
    def preemptible(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "preemptible", value)

    @property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional[pulumi.Input['ClusterNodeConfigReservationAffinityArgs']]:
        """
        The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        """
        return pulumi.get(self, "reservation_affinity")

    @reservation_affinity.setter
    def reservation_affinity(self, value: Optional[pulumi.Input['ClusterNodeConfigReservationAffinityArgs']]):
        pulumi.set(self, "reservation_affinity", value)

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
        for how these labels are applied to clusters, node pools and nodes.
        """
        return pulumi.get(self, "resource_labels")

    @resource_labels.setter
    def resource_labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "resource_labels", value)

    @property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        return pulumi.get(self, "resource_manager_tags")

    @resource_manager_tags.setter
    def resource_manager_tags(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "resource_manager_tags", value)

    @property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional[pulumi.Input['ClusterNodeConfigSandboxConfigArgs']]:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_config")

    @sandbox_config.setter
    def sandbox_config(self, value: Optional[pulumi.Input['ClusterNodeConfigSandboxConfigArgs']]):
        pulumi.set(self, "sandbox_config", value)

    @property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSecondaryBootDiskArgs']]]]:
        """
        Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @secondary_boot_disks.setter
    def secondary_boot_disks(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSecondaryBootDiskArgs']]]]):
        pulumi.set(self, "secondary_boot_disks", value)

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The service account to be used by the Node VMs.
        If not specified, the "default" service account is used.
        """
        return pulumi.get(self, "service_account")

    @service_account.setter
    def service_account(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "service_account", value)

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional[pulumi.Input['ClusterNodeConfigShieldedInstanceConfigArgs']]:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @shielded_instance_config.setter
    def shielded_instance_config(self, value: Optional[pulumi.Input['ClusterNodeConfigShieldedInstanceConfigArgs']]):
        pulumi.set(self, "shielded_instance_config", value)

    @property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional[pulumi.Input['ClusterNodeConfigSoleTenantConfigArgs']]:
        """
        Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
        """
        return pulumi.get(self, "sole_tenant_config")

    @sole_tenant_config.setter
    def sole_tenant_config(self, value: Optional[pulumi.Input['ClusterNodeConfigSoleTenantConfigArgs']]):
        pulumi.set(self, "sole_tenant_config", value)

    @property
    @pulumi.getter
    def spot(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        A boolean that represents whether the underlying node VMs are spot.
        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "spot")

    @spot.setter
    def spot(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "spot", value)

    @property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @storage_pools.setter
    def storage_pools(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "storage_pools", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The list of instance tags applied to all nodes. Tags are used to identify
        valid sources or targets for network firewalls.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter
    def taints(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigTaintArgs']]]]:
        """
        A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
        to apply to nodes. GKE's API can only set this field on cluster creation.
        However, GKE will add taints to your nodes if you enable certain features such
        as GPUs. If this field is set, any diffs on this field will cause the provider to
        recreate the underlying resource. Taint values can be updated safely in
        Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
        this field to manage taints. If you do, `lifecycle.ignore_changes` is
        recommended. Structure is documented below.
        """
        return pulumi.get(self, "taints")

    @taints.setter
    def taints(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigTaintArgs']]]]):
        pulumi.set(self, "taints", value)

    @property
    @pulumi.getter(name="windowsNodeConfig")
    def windows_node_config(self) -> Optional[pulumi.Input['ClusterNodeConfigWindowsNodeConfigArgs']]:
        """
        Windows node configuration, currently supporting OSVersion [attribute](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/NodeConfig#osversion). The value must be one of [OS_VERSION_UNSPECIFIED, OS_VERSION_LTSC2019, OS_VERSION_LTSC2022]. For example:
        """
        return pulumi.get(self, "windows_node_config")

    @windows_node_config.setter
    def windows_node_config(self, value: Optional[pulumi.Input['ClusterNodeConfigWindowsNodeConfigArgs']]):
        pulumi.set(self, "windows_node_config", value)

    @property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional[pulumi.Input['ClusterNodeConfigWorkloadMetadataConfigArgs']]:
        """
        Metadata configuration to expose to workloads on the node pool.
        Structure is documented below.
        """
        return pulumi.get(self, "workload_metadata_config")

    @workload_metadata_config.setter
    def workload_metadata_config(self, value: Optional[pulumi.Input['ClusterNodeConfigWorkloadMetadataConfigArgs']]):
        pulumi.set(self, "workload_metadata_config", value)


if not MYPY:
    class ClusterNodeConfigAdvancedMachineFeaturesArgsDict(TypedDict):
        threads_per_core: pulumi.Input[builtins.int]
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        enable_nested_virtualization: NotRequired[pulumi.Input[builtins.bool]]
        """
        Defines whether the instance should have nested virtualization enabled. Defaults to false.
        """
elif False:
    ClusterNodeConfigAdvancedMachineFeaturesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigAdvancedMachineFeaturesArgs:
    def __init__(__self__, *,
                 threads_per_core: pulumi.Input[builtins.int],
                 enable_nested_virtualization: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.int] threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        :param pulumi.Input[builtins.bool] enable_nested_virtualization: Defines whether the instance should have nested virtualization enabled. Defaults to false.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)
        if enable_nested_virtualization is not None:
            pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> pulumi.Input[builtins.int]:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")

    @threads_per_core.setter
    def threads_per_core(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "threads_per_core", value)

    @property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Defines whether the instance should have nested virtualization enabled. Defaults to false.
        """
        return pulumi.get(self, "enable_nested_virtualization")

    @enable_nested_virtualization.setter
    def enable_nested_virtualization(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_nested_virtualization", value)


if not MYPY:
    class ClusterNodeConfigConfidentialNodesArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
elif False:
    ClusterNodeConfigConfidentialNodesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigConfidentialNodesArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterNodeConfigContainerdConfigArgsDict(TypedDict):
        private_registry_access_config: NotRequired[pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgsDict']]
        """
        Configuration for private container registries. There are two fields in this config:
        """
elif False:
    ClusterNodeConfigContainerdConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigContainerdConfigArgs:
    def __init__(__self__, *,
                 private_registry_access_config: Optional[pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs']] = None):
        """
        :param pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs'] private_registry_access_config: Configuration for private container registries. There are two fields in this config:
        """
        if private_registry_access_config is not None:
            pulumi.set(__self__, "private_registry_access_config", private_registry_access_config)

    @property
    @pulumi.getter(name="privateRegistryAccessConfig")
    def private_registry_access_config(self) -> Optional[pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs']]:
        """
        Configuration for private container registries. There are two fields in this config:
        """
        return pulumi.get(self, "private_registry_access_config")

    @private_registry_access_config.setter
    def private_registry_access_config(self, value: Optional[pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs']]):
        pulumi.set(self, "private_registry_access_config", value)


if not MYPY:
    class ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Enables private registry config. If set to false, all other fields in this object must not be set.
        """
        certificate_authority_domain_configs: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict']]]]
        """
        List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
elif False:
    ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool],
                 certificate_authority_domain_configs: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]]] = None):
        """
        :param pulumi.Input[builtins.bool] enabled: Enables private registry config. If set to false, all other fields in this object must not be set.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]] certificate_authority_domain_configs: List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
        pulumi.set(__self__, "enabled", enabled)
        if certificate_authority_domain_configs is not None:
            pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Enables private registry config. If set to false, all other fields in this object must not be set.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]]]:
        """
        List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
        return pulumi.get(self, "certificate_authority_domain_configs")

    @certificate_authority_domain_configs.setter
    def certificate_authority_domain_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]]]):
        pulumi.set(self, "certificate_authority_domain_configs", value)


if not MYPY:
    class ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict(TypedDict):
        fqdns: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        gcp_secret_manager_certificate_config: pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict']
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
elif False:
    ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs:
    def __init__(__self__, *,
                 fqdns: pulumi.Input[Sequence[pulumi.Input[builtins.str]]],
                 gcp_secret_manager_certificate_config: pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs']):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs'] gcp_secret_manager_certificate_config: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_config", gcp_secret_manager_certificate_config)

    @property
    @pulumi.getter
    def fqdns(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @fqdns.setter
    def fqdns(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "fqdns", value)

    @property
    @pulumi.getter(name="gcpSecretManagerCertificateConfig")
    def gcp_secret_manager_certificate_config(self) -> pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs']:
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_config")

    @gcp_secret_manager_certificate_config.setter
    def gcp_secret_manager_certificate_config(self, value: pulumi.Input['ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs']):
        pulumi.set(self, "gcp_secret_manager_certificate_config", value)


if not MYPY:
    class ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict(TypedDict):
        secret_uri: pulumi.Input[builtins.str]
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
elif False:
    ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs:
    def __init__(__self__, *,
                 secret_uri: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> pulumi.Input[builtins.str]:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")

    @secret_uri.setter
    def secret_uri(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "secret_uri", value)


if not MYPY:
    class ClusterNodeConfigEffectiveTaintArgsDict(TypedDict):
        effect: NotRequired[pulumi.Input[builtins.str]]
        """
        Effect for taint.
        """
        key: NotRequired[pulumi.Input[builtins.str]]
        """
        Key for taint.
        """
        value: NotRequired[pulumi.Input[builtins.str]]
        """
        Value for taint.
        """
elif False:
    ClusterNodeConfigEffectiveTaintArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigEffectiveTaintArgs:
    def __init__(__self__, *,
                 effect: Optional[pulumi.Input[builtins.str]] = None,
                 key: Optional[pulumi.Input[builtins.str]] = None,
                 value: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] effect: Effect for taint.
        :param pulumi.Input[builtins.str] key: Key for taint.
        :param pulumi.Input[builtins.str] value: Value for taint.
        """
        if effect is not None:
            pulumi.set(__self__, "effect", effect)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @effect.setter
    def effect(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "effect", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "value", value)


if not MYPY:
    class ClusterNodeConfigEphemeralStorageConfigArgsDict(TypedDict):
        local_ssd_count: pulumi.Input[builtins.int]
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
elif False:
    ClusterNodeConfigEphemeralStorageConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigEphemeralStorageConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.int] local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[builtins.int]:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "local_ssd_count", value)


if not MYPY:
    class ClusterNodeConfigEphemeralStorageLocalSsdConfigArgsDict(TypedDict):
        local_ssd_count: pulumi.Input[builtins.int]
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        data_cache_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Number of raw-block local NVMe SSD disks to be attached to the node utilized for GKE Data Cache. If zero, then GKE Data Cache will not be enabled in the nodes.
        """
elif False:
    ClusterNodeConfigEphemeralStorageLocalSsdConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[builtins.int],
                 data_cache_count: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.int] local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        :param pulumi.Input[builtins.int] data_cache_count: Number of raw-block local NVMe SSD disks to be attached to the node utilized for GKE Data Cache. If zero, then GKE Data Cache will not be enabled in the nodes.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if data_cache_count is not None:
            pulumi.set(__self__, "data_cache_count", data_cache_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[builtins.int]:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "local_ssd_count", value)

    @property
    @pulumi.getter(name="dataCacheCount")
    def data_cache_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node utilized for GKE Data Cache. If zero, then GKE Data Cache will not be enabled in the nodes.
        """
        return pulumi.get(self, "data_cache_count")

    @data_cache_count.setter
    def data_cache_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "data_cache_count", value)


if not MYPY:
    class ClusterNodeConfigFastSocketArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not the NCCL Fast Socket is enabled
        """
elif False:
    ClusterNodeConfigFastSocketArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigFastSocketArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not the NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not the NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterNodeConfigGcfsConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
elif False:
    ClusterNodeConfigGcfsConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigGcfsConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterNodeConfigGuestAcceleratorArgsDict(TypedDict):
        count: pulumi.Input[builtins.int]
        """
        The number of the guest accelerator cards exposed to this instance.
        """
        type: pulumi.Input[builtins.str]
        """
        The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        """
        gpu_driver_installation_config: NotRequired[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgsDict']]
        """
        Configuration for auto installation of GPU driver. Structure is documented below.
        """
        gpu_partition_size: NotRequired[pulumi.Input[builtins.str]]
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        """
        gpu_sharing_config: NotRequired[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgsDict']]
        """
        Configuration for GPU sharing. Structure is documented below.
        """
elif False:
    ClusterNodeConfigGuestAcceleratorArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigGuestAcceleratorArgs:
    def __init__(__self__, *,
                 count: pulumi.Input[builtins.int],
                 type: pulumi.Input[builtins.str],
                 gpu_driver_installation_config: Optional[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']] = None,
                 gpu_partition_size: Optional[pulumi.Input[builtins.str]] = None,
                 gpu_sharing_config: Optional[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs']] = None):
        """
        :param pulumi.Input[builtins.int] count: The number of the guest accelerator cards exposed to this instance.
        :param pulumi.Input[builtins.str] type: The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        :param pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs'] gpu_driver_installation_config: Configuration for auto installation of GPU driver. Structure is documented below.
        :param pulumi.Input[builtins.str] gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        :param pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs'] gpu_sharing_config: Configuration for GPU sharing. Structure is documented below.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @property
    @pulumi.getter
    def count(self) -> pulumi.Input[builtins.int]:
        """
        The number of the guest accelerator cards exposed to this instance.
        """
        return pulumi.get(self, "count")

    @count.setter
    def count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "count", value)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input[builtins.str]:
        """
        The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']]:
        """
        Configuration for auto installation of GPU driver. Structure is documented below.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @gpu_driver_installation_config.setter
    def gpu_driver_installation_config(self, value: Optional[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']]):
        pulumi.set(self, "gpu_driver_installation_config", value)

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        """
        return pulumi.get(self, "gpu_partition_size")

    @gpu_partition_size.setter
    def gpu_partition_size(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "gpu_partition_size", value)

    @property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs']]:
        """
        Configuration for GPU sharing. Structure is documented below.
        """
        return pulumi.get(self, "gpu_sharing_config")

    @gpu_sharing_config.setter
    def gpu_sharing_config(self, value: Optional[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs']]):
        pulumi.set(self, "gpu_sharing_config", value)


if not MYPY:
    class ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgsDict(TypedDict):
        gpu_driver_version: pulumi.Input[builtins.str]
        """
        Mode for how the GPU driver is installed.
        Accepted values are:
        * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to install the "Default" GPU driver. Before GKE `1.30.1-gke.1156000`, the default value is to not install any GPU driver.
        * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
        * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
        * `"LATEST"`: "Latest" GPU driver in COS.
        """
elif False:
    ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs:
    def __init__(__self__, *,
                 gpu_driver_version: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] gpu_driver_version: Mode for how the GPU driver is installed.
               Accepted values are:
               * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to install the "Default" GPU driver. Before GKE `1.30.1-gke.1156000`, the default value is to not install any GPU driver.
               * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
               * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
               * `"LATEST"`: "Latest" GPU driver in COS.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> pulumi.Input[builtins.str]:
        """
        Mode for how the GPU driver is installed.
        Accepted values are:
        * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to install the "Default" GPU driver. Before GKE `1.30.1-gke.1156000`, the default value is to not install any GPU driver.
        * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
        * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
        * `"LATEST"`: "Latest" GPU driver in COS.
        """
        return pulumi.get(self, "gpu_driver_version")

    @gpu_driver_version.setter
    def gpu_driver_version(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "gpu_driver_version", value)


if not MYPY:
    class ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgsDict(TypedDict):
        gpu_sharing_strategy: pulumi.Input[builtins.str]
        """
        The type of GPU sharing strategy to enable on the GPU node.
        Accepted values are:
        * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        """
        max_shared_clients_per_gpu: pulumi.Input[builtins.int]
        """
        The maximum number of containers that can share a GPU.
        """
elif False:
    ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs:
    def __init__(__self__, *,
                 gpu_sharing_strategy: pulumi.Input[builtins.str],
                 max_shared_clients_per_gpu: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.str] gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node.
               Accepted values are:
               * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
               * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        :param pulumi.Input[builtins.int] max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> pulumi.Input[builtins.str]:
        """
        The type of GPU sharing strategy to enable on the GPU node.
        Accepted values are:
        * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @gpu_sharing_strategy.setter
    def gpu_sharing_strategy(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "gpu_sharing_strategy", value)

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> pulumi.Input[builtins.int]:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")

    @max_shared_clients_per_gpu.setter
    def max_shared_clients_per_gpu(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "max_shared_clients_per_gpu", value)


if not MYPY:
    class ClusterNodeConfigGvnicArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
elif False:
    ClusterNodeConfigGvnicArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigGvnicArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterNodeConfigHostMaintenancePolicyArgsDict(TypedDict):
        maintenance_interval: pulumi.Input[builtins.str]
        """
        .
        """
elif False:
    ClusterNodeConfigHostMaintenancePolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigHostMaintenancePolicyArgs:
    def __init__(__self__, *,
                 maintenance_interval: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> pulumi.Input[builtins.str]:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")

    @maintenance_interval.setter
    def maintenance_interval(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "maintenance_interval", value)


if not MYPY:
    class ClusterNodeConfigKubeletConfigArgsDict(TypedDict):
        allowed_unsafe_sysctls: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods. The allowed sysctl groups are `kernel.shm*`, `kernel.msg*`, `kernel.sem`, `fs.mqueue.*`, and `net.*`.
        """
        container_log_max_files: NotRequired[pulumi.Input[builtins.int]]
        """
        Defines the maximum number of container log files that can be present for a container. The integer must be between 2 and 10, inclusive.
        """
        container_log_max_size: NotRequired[pulumi.Input[builtins.str]]
        """
        Defines the maximum size of the
        container log file before it is rotated. Specified as a positive number and a
        unit suffix, such as `"100Ki"`, `"10Mi"`. Valid units are "Ki", "Mi", "Gi".
        The value must be between `"10Mi"` and `"500Mi"`, inclusive. And the total container log size
        (`container_log_max_size` * `container_log_max_files`) cannot exceed 1% of the total storage of the node.
        """
        cpu_cfs_quota: NotRequired[pulumi.Input[builtins.bool]]
        """
        If true, enables CPU CFS quota enforcement for
        containers that specify CPU limits.
        """
        cpu_cfs_quota_period: NotRequired[pulumi.Input[builtins.str]]
        """
        The CPU CFS quota period value. Specified
        as a sequence of decimal numbers, each with optional fraction and a unit suffix,
        such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
        "h". The value must be a positive duration.
        """
        cpu_manager_policy: NotRequired[pulumi.Input[builtins.str]]
        """
        The CPU management policy on the node. See
        [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
        One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
        Prior to the 6.4.0 this field was marked as required. The workaround for the required field
        is setting the empty string `""`, which will function identically to not setting this field.
        """
        image_gc_high_threshold_percent: NotRequired[pulumi.Input[builtins.int]]
        """
        Defines the percent of disk usage after which image garbage collection is always run. The integer must be between 10 and 85, inclusive.
        """
        image_gc_low_threshold_percent: NotRequired[pulumi.Input[builtins.int]]
        """
        Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to. The integer must be between 10 and 85, inclusive.
        """
        image_maximum_gc_age: NotRequired[pulumi.Input[builtins.str]]
        """
        Defines the maximum age an image can be unused before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`, and `"2h45m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h". The value must be a positive duration.
        """
        image_minimum_gc_age: NotRequired[pulumi.Input[builtins.str]]
        """
        Defines the minimum age for an unused image before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`. The value cannot be greater than "2m".
        """
        insecure_kubelet_readonly_port_enabled: NotRequired[pulumi.Input[builtins.str]]
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        pod_pids_limit: NotRequired[pulumi.Input[builtins.int]]
        """
        Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
elif False:
    ClusterNodeConfigKubeletConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigKubeletConfigArgs:
    def __init__(__self__, *,
                 allowed_unsafe_sysctls: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 container_log_max_files: Optional[pulumi.Input[builtins.int]] = None,
                 container_log_max_size: Optional[pulumi.Input[builtins.str]] = None,
                 cpu_cfs_quota: Optional[pulumi.Input[builtins.bool]] = None,
                 cpu_cfs_quota_period: Optional[pulumi.Input[builtins.str]] = None,
                 cpu_manager_policy: Optional[pulumi.Input[builtins.str]] = None,
                 image_gc_high_threshold_percent: Optional[pulumi.Input[builtins.int]] = None,
                 image_gc_low_threshold_percent: Optional[pulumi.Input[builtins.int]] = None,
                 image_maximum_gc_age: Optional[pulumi.Input[builtins.str]] = None,
                 image_minimum_gc_age: Optional[pulumi.Input[builtins.str]] = None,
                 insecure_kubelet_readonly_port_enabled: Optional[pulumi.Input[builtins.str]] = None,
                 pod_pids_limit: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] allowed_unsafe_sysctls: Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods. The allowed sysctl groups are `kernel.shm*`, `kernel.msg*`, `kernel.sem`, `fs.mqueue.*`, and `net.*`.
        :param pulumi.Input[builtins.int] container_log_max_files: Defines the maximum number of container log files that can be present for a container. The integer must be between 2 and 10, inclusive.
        :param pulumi.Input[builtins.str] container_log_max_size: Defines the maximum size of the
               container log file before it is rotated. Specified as a positive number and a
               unit suffix, such as `"100Ki"`, `"10Mi"`. Valid units are "Ki", "Mi", "Gi".
               The value must be between `"10Mi"` and `"500Mi"`, inclusive. And the total container log size
               (`container_log_max_size` * `container_log_max_files`) cannot exceed 1% of the total storage of the node.
        :param pulumi.Input[builtins.bool] cpu_cfs_quota: If true, enables CPU CFS quota enforcement for
               containers that specify CPU limits.
        :param pulumi.Input[builtins.str] cpu_cfs_quota_period: The CPU CFS quota period value. Specified
               as a sequence of decimal numbers, each with optional fraction and a unit suffix,
               such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
               "h". The value must be a positive duration.
        :param pulumi.Input[builtins.str] cpu_manager_policy: The CPU management policy on the node. See
               [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
               One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
               Prior to the 6.4.0 this field was marked as required. The workaround for the required field
               is setting the empty string `""`, which will function identically to not setting this field.
        :param pulumi.Input[builtins.int] image_gc_high_threshold_percent: Defines the percent of disk usage after which image garbage collection is always run. The integer must be between 10 and 85, inclusive.
        :param pulumi.Input[builtins.int] image_gc_low_threshold_percent: Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to. The integer must be between 10 and 85, inclusive.
        :param pulumi.Input[builtins.str] image_maximum_gc_age: Defines the maximum age an image can be unused before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`, and `"2h45m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h". The value must be a positive duration.
        :param pulumi.Input[builtins.str] image_minimum_gc_age: Defines the minimum age for an unused image before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`. The value cannot be greater than "2m".
        :param pulumi.Input[builtins.str] insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param pulumi.Input[builtins.int] pod_pids_limit: Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        if allowed_unsafe_sysctls is not None:
            pulumi.set(__self__, "allowed_unsafe_sysctls", allowed_unsafe_sysctls)
        if container_log_max_files is not None:
            pulumi.set(__self__, "container_log_max_files", container_log_max_files)
        if container_log_max_size is not None:
            pulumi.set(__self__, "container_log_max_size", container_log_max_size)
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if cpu_manager_policy is not None:
            pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if image_gc_high_threshold_percent is not None:
            pulumi.set(__self__, "image_gc_high_threshold_percent", image_gc_high_threshold_percent)
        if image_gc_low_threshold_percent is not None:
            pulumi.set(__self__, "image_gc_low_threshold_percent", image_gc_low_threshold_percent)
        if image_maximum_gc_age is not None:
            pulumi.set(__self__, "image_maximum_gc_age", image_maximum_gc_age)
        if image_minimum_gc_age is not None:
            pulumi.set(__self__, "image_minimum_gc_age", image_minimum_gc_age)
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="allowedUnsafeSysctls")
    def allowed_unsafe_sysctls(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods. The allowed sysctl groups are `kernel.shm*`, `kernel.msg*`, `kernel.sem`, `fs.mqueue.*`, and `net.*`.
        """
        return pulumi.get(self, "allowed_unsafe_sysctls")

    @allowed_unsafe_sysctls.setter
    def allowed_unsafe_sysctls(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "allowed_unsafe_sysctls", value)

    @property
    @pulumi.getter(name="containerLogMaxFiles")
    def container_log_max_files(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Defines the maximum number of container log files that can be present for a container. The integer must be between 2 and 10, inclusive.
        """
        return pulumi.get(self, "container_log_max_files")

    @container_log_max_files.setter
    def container_log_max_files(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "container_log_max_files", value)

    @property
    @pulumi.getter(name="containerLogMaxSize")
    def container_log_max_size(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Defines the maximum size of the
        container log file before it is rotated. Specified as a positive number and a
        unit suffix, such as `"100Ki"`, `"10Mi"`. Valid units are "Ki", "Mi", "Gi".
        The value must be between `"10Mi"` and `"500Mi"`, inclusive. And the total container log size
        (`container_log_max_size` * `container_log_max_files`) cannot exceed 1% of the total storage of the node.
        """
        return pulumi.get(self, "container_log_max_size")

    @container_log_max_size.setter
    def container_log_max_size(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "container_log_max_size", value)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        If true, enables CPU CFS quota enforcement for
        containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @cpu_cfs_quota.setter
    def cpu_cfs_quota(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "cpu_cfs_quota", value)

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The CPU CFS quota period value. Specified
        as a sequence of decimal numbers, each with optional fraction and a unit suffix,
        such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
        "h". The value must be a positive duration.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @cpu_cfs_quota_period.setter
    def cpu_cfs_quota_period(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cpu_cfs_quota_period", value)

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The CPU management policy on the node. See
        [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
        One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
        Prior to the 6.4.0 this field was marked as required. The workaround for the required field
        is setting the empty string `""`, which will function identically to not setting this field.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @cpu_manager_policy.setter
    def cpu_manager_policy(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cpu_manager_policy", value)

    @property
    @pulumi.getter(name="imageGcHighThresholdPercent")
    def image_gc_high_threshold_percent(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Defines the percent of disk usage after which image garbage collection is always run. The integer must be between 10 and 85, inclusive.
        """
        return pulumi.get(self, "image_gc_high_threshold_percent")

    @image_gc_high_threshold_percent.setter
    def image_gc_high_threshold_percent(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "image_gc_high_threshold_percent", value)

    @property
    @pulumi.getter(name="imageGcLowThresholdPercent")
    def image_gc_low_threshold_percent(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to. The integer must be between 10 and 85, inclusive.
        """
        return pulumi.get(self, "image_gc_low_threshold_percent")

    @image_gc_low_threshold_percent.setter
    def image_gc_low_threshold_percent(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "image_gc_low_threshold_percent", value)

    @property
    @pulumi.getter(name="imageMaximumGcAge")
    def image_maximum_gc_age(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Defines the maximum age an image can be unused before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`, and `"2h45m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h". The value must be a positive duration.
        """
        return pulumi.get(self, "image_maximum_gc_age")

    @image_maximum_gc_age.setter
    def image_maximum_gc_age(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "image_maximum_gc_age", value)

    @property
    @pulumi.getter(name="imageMinimumGcAge")
    def image_minimum_gc_age(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Defines the minimum age for an unused image before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`. The value cannot be greater than "2m".
        """
        return pulumi.get(self, "image_minimum_gc_age")

    @image_minimum_gc_age.setter
    def image_minimum_gc_age(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "image_minimum_gc_age", value)

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @insecure_kubelet_readonly_port_enabled.setter
    def insecure_kubelet_readonly_port_enabled(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "insecure_kubelet_readonly_port_enabled", value)

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        return pulumi.get(self, "pod_pids_limit")

    @pod_pids_limit.setter
    def pod_pids_limit(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "pod_pids_limit", value)


if not MYPY:
    class ClusterNodeConfigLinuxNodeConfigArgsDict(TypedDict):
        cgroup_mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Possible cgroup modes that can be used.
        Accepted values are:
        * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
        * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
        * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        """
        hugepages_config: NotRequired[pulumi.Input['ClusterNodeConfigLinuxNodeConfigHugepagesConfigArgsDict']]
        """
        Amounts for 2M and 1G hugepages. Structure is documented below.
        """
        sysctls: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        The Linux kernel parameters to be applied to the nodes
        and all pods running on the nodes. Specified as a map from the key, such as
        `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Note that validations happen all server side. All attributes are optional.
        """
elif False:
    ClusterNodeConfigLinuxNodeConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigLinuxNodeConfigArgs:
    def __init__(__self__, *,
                 cgroup_mode: Optional[pulumi.Input[builtins.str]] = None,
                 hugepages_config: Optional[pulumi.Input['ClusterNodeConfigLinuxNodeConfigHugepagesConfigArgs']] = None,
                 sysctls: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[builtins.str] cgroup_mode: Possible cgroup modes that can be used.
               Accepted values are:
               * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
               * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
               * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        :param pulumi.Input['ClusterNodeConfigLinuxNodeConfigHugepagesConfigArgs'] hugepages_config: Amounts for 2M and 1G hugepages. Structure is documented below.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] sysctls: The Linux kernel parameters to be applied to the nodes
               and all pods running on the nodes. Specified as a map from the key, such as
               `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Note that validations happen all server side. All attributes are optional.
        """
        if cgroup_mode is not None:
            pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        if hugepages_config is not None:
            pulumi.set(__self__, "hugepages_config", hugepages_config)
        if sysctls is not None:
            pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Possible cgroup modes that can be used.
        Accepted values are:
        * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
        * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
        * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        """
        return pulumi.get(self, "cgroup_mode")

    @cgroup_mode.setter
    def cgroup_mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cgroup_mode", value)

    @property
    @pulumi.getter(name="hugepagesConfig")
    def hugepages_config(self) -> Optional[pulumi.Input['ClusterNodeConfigLinuxNodeConfigHugepagesConfigArgs']]:
        """
        Amounts for 2M and 1G hugepages. Structure is documented below.
        """
        return pulumi.get(self, "hugepages_config")

    @hugepages_config.setter
    def hugepages_config(self, value: Optional[pulumi.Input['ClusterNodeConfigLinuxNodeConfigHugepagesConfigArgs']]):
        pulumi.set(self, "hugepages_config", value)

    @property
    @pulumi.getter
    def sysctls(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The Linux kernel parameters to be applied to the nodes
        and all pods running on the nodes. Specified as a map from the key, such as
        `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Note that validations happen all server side. All attributes are optional.
        """
        return pulumi.get(self, "sysctls")

    @sysctls.setter
    def sysctls(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "sysctls", value)


if not MYPY:
    class ClusterNodeConfigLinuxNodeConfigHugepagesConfigArgsDict(TypedDict):
        hugepage_size1g: NotRequired[pulumi.Input[builtins.int]]
        """
        Amount of 1G hugepages.
        """
        hugepage_size2m: NotRequired[pulumi.Input[builtins.int]]
        """
        Amount of 2M hugepages.
        """
elif False:
    ClusterNodeConfigLinuxNodeConfigHugepagesConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigLinuxNodeConfigHugepagesConfigArgs:
    def __init__(__self__, *,
                 hugepage_size1g: Optional[pulumi.Input[builtins.int]] = None,
                 hugepage_size2m: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.int] hugepage_size1g: Amount of 1G hugepages.
        :param pulumi.Input[builtins.int] hugepage_size2m: Amount of 2M hugepages.
        """
        if hugepage_size1g is not None:
            pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        if hugepage_size2m is not None:
            pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @hugepage_size1g.setter
    def hugepage_size1g(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "hugepage_size1g", value)

    @property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")

    @hugepage_size2m.setter
    def hugepage_size2m(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "hugepage_size2m", value)


if not MYPY:
    class ClusterNodeConfigLocalNvmeSsdBlockConfigArgsDict(TypedDict):
        local_ssd_count: pulumi.Input[builtins.int]
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
        > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
elif False:
    ClusterNodeConfigLocalNvmeSsdBlockConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigLocalNvmeSsdBlockConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.int] local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
               > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[builtins.int]:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
        > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "local_ssd_count", value)


if not MYPY:
    class ClusterNodeConfigReservationAffinityArgsDict(TypedDict):
        consume_reservation_type: pulumi.Input[builtins.str]
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        key: NotRequired[pulumi.Input[builtins.str]]
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        values: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
elif False:
    ClusterNodeConfigReservationAffinityArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigReservationAffinityArgs:
    def __init__(__self__, *,
                 consume_reservation_type: pulumi.Input[builtins.str],
                 key: Optional[pulumi.Input[builtins.str]] = None,
                 values: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[builtins.str] consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param pulumi.Input[builtins.str] key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> pulumi.Input[builtins.str]:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @consume_reservation_type.setter
    def consume_reservation_type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "consume_reservation_type", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "values", value)


if not MYPY:
    class ClusterNodeConfigSandboxConfigArgsDict(TypedDict):
        sandbox_type: pulumi.Input[builtins.str]
        """
        Which sandbox to use for pods in the node pool.
        Accepted values are:

        * `"gvisor"`: Pods run within a gVisor sandbox.
        """
elif False:
    ClusterNodeConfigSandboxConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigSandboxConfigArgs:
    def __init__(__self__, *,
                 sandbox_type: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] sandbox_type: Which sandbox to use for pods in the node pool.
               Accepted values are:
               
               * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> pulumi.Input[builtins.str]:
        """
        Which sandbox to use for pods in the node pool.
        Accepted values are:

        * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        return pulumi.get(self, "sandbox_type")

    @sandbox_type.setter
    def sandbox_type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "sandbox_type", value)


if not MYPY:
    class ClusterNodeConfigSecondaryBootDiskArgsDict(TypedDict):
        disk_image: pulumi.Input[builtins.str]
        """
        Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        """
        mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
elif False:
    ClusterNodeConfigSecondaryBootDiskArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigSecondaryBootDiskArgs:
    def __init__(__self__, *,
                 disk_image: pulumi.Input[builtins.str],
                 mode: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] disk_image: Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        :param pulumi.Input[builtins.str] mode: Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        if mode is not None:
            pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> pulumi.Input[builtins.str]:
        """
        Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        """
        return pulumi.get(self, "disk_image")

    @disk_image.setter
    def disk_image(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "disk_image", value)

    @property
    @pulumi.getter
    def mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
        return pulumi.get(self, "mode")

    @mode.setter
    def mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "mode", value)


if not MYPY:
    class ClusterNodeConfigShieldedInstanceConfigArgsDict(TypedDict):
        enable_integrity_monitoring: NotRequired[pulumi.Input[builtins.bool]]
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        enable_secure_boot: NotRequired[pulumi.Input[builtins.bool]]
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
elif False:
    ClusterNodeConfigShieldedInstanceConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigShieldedInstanceConfigArgs:
    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[pulumi.Input[builtins.bool]] = None,
                 enable_secure_boot: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.bool] enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param pulumi.Input[builtins.bool] enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @enable_integrity_monitoring.setter
    def enable_integrity_monitoring(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_integrity_monitoring", value)

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")

    @enable_secure_boot.setter
    def enable_secure_boot(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_secure_boot", value)


if not MYPY:
    class ClusterNodeConfigSoleTenantConfigArgsDict(TypedDict):
        node_affinities: pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSoleTenantConfigNodeAffinityArgsDict']]]
        """
        .
        """
elif False:
    ClusterNodeConfigSoleTenantConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigSoleTenantConfigArgs:
    def __init__(__self__, *,
                 node_affinities: pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSoleTenantConfigNodeAffinityArgs']]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSoleTenantConfigNodeAffinityArgs']]] node_affinities: .
        """
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSoleTenantConfigNodeAffinityArgs']]]:
        """
        .
        """
        return pulumi.get(self, "node_affinities")

    @node_affinities.setter
    def node_affinities(self, value: pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSoleTenantConfigNodeAffinityArgs']]]):
        pulumi.set(self, "node_affinities", value)


if not MYPY:
    class ClusterNodeConfigSoleTenantConfigNodeAffinityArgsDict(TypedDict):
        key: pulumi.Input[builtins.str]
        """
        The default or custom node affinity label key name.
        """
        operator: pulumi.Input[builtins.str]
        """
        Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        """
        values: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        List of node affinity label values as strings.
        """
elif False:
    ClusterNodeConfigSoleTenantConfigNodeAffinityArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigSoleTenantConfigNodeAffinityArgs:
    def __init__(__self__, *,
                 key: pulumi.Input[builtins.str],
                 operator: pulumi.Input[builtins.str],
                 values: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        """
        :param pulumi.Input[builtins.str] key: The default or custom node affinity label key name.
        :param pulumi.Input[builtins.str] operator: Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] values: List of node affinity label values as strings.
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[builtins.str]:
        """
        The default or custom node affinity label key name.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def operator(self) -> pulumi.Input[builtins.str]:
        """
        Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        """
        return pulumi.get(self, "operator")

    @operator.setter
    def operator(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "operator", value)

    @property
    @pulumi.getter
    def values(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        List of node affinity label values as strings.
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "values", value)


if not MYPY:
    class ClusterNodeConfigTaintArgsDict(TypedDict):
        effect: pulumi.Input[builtins.str]
        """
        Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        """
        key: pulumi.Input[builtins.str]
        """
        Key for taint.
        """
        value: pulumi.Input[builtins.str]
        """
        Value for taint.
        """
elif False:
    ClusterNodeConfigTaintArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigTaintArgs:
    def __init__(__self__, *,
                 effect: pulumi.Input[builtins.str],
                 key: pulumi.Input[builtins.str],
                 value: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] effect: Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        :param pulumi.Input[builtins.str] key: Key for taint.
        :param pulumi.Input[builtins.str] value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> pulumi.Input[builtins.str]:
        """
        Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        """
        return pulumi.get(self, "effect")

    @effect.setter
    def effect(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "effect", value)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[builtins.str]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[builtins.str]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "value", value)


if not MYPY:
    class ClusterNodeConfigWindowsNodeConfigArgsDict(TypedDict):
        osversion: NotRequired[pulumi.Input[builtins.str]]
        """
        The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
elif False:
    ClusterNodeConfigWindowsNodeConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigWindowsNodeConfigArgs:
    def __init__(__self__, *,
                 osversion: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] osversion: The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        if osversion is not None:
            pulumi.set(__self__, "osversion", osversion)

    @property
    @pulumi.getter
    def osversion(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        return pulumi.get(self, "osversion")

    @osversion.setter
    def osversion(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "osversion", value)


if not MYPY:
    class ClusterNodeConfigWorkloadMetadataConfigArgsDict(TypedDict):
        mode: pulumi.Input[builtins.str]
        """
        How to expose the node metadata to the workload running on the node.
        Accepted values are:
        * UNSPECIFIED: Not Set
        * GCE_METADATA: Expose all Compute Engine metadata to pods.
        * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
elif False:
    ClusterNodeConfigWorkloadMetadataConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodeConfigWorkloadMetadataConfigArgs:
    def __init__(__self__, *,
                 mode: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] mode: How to expose the node metadata to the workload running on the node.
               Accepted values are:
               * UNSPECIFIED: Not Set
               * GCE_METADATA: Expose all Compute Engine metadata to pods.
               * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> pulumi.Input[builtins.str]:
        """
        How to expose the node metadata to the workload running on the node.
        Accepted values are:
        * UNSPECIFIED: Not Set
        * GCE_METADATA: Expose all Compute Engine metadata to pods.
        * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        return pulumi.get(self, "mode")

    @mode.setter
    def mode(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "mode", value)


if not MYPY:
    class ClusterNodePoolArgsDict(TypedDict):
        autoscaling: NotRequired[pulumi.Input['ClusterNodePoolAutoscalingArgsDict']]
        """
        Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
        """
        initial_node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        The number of nodes to create in this
        cluster's default node pool. In regional or multi-zonal clusters, this is the
        number of nodes per zone. Must be set if `node_pool` is not set. If you're using
        `container.NodePool` objects with no default node pool, you'll need to
        set this to a value of at least `1`, alongside setting
        `remove_default_node_pool` to `true`.
        """
        instance_group_urls: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The resource URLs of the managed instance groups associated with this node pool.
        """
        managed_instance_group_urls: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        List of instance group URLs which have been assigned to this node pool.
        """
        management: NotRequired[pulumi.Input['ClusterNodePoolManagementArgsDict']]
        """
        Node management configuration, wherein auto-repair and auto-upgrade is configured.
        """
        max_pods_per_node: NotRequired[pulumi.Input[builtins.int]]
        """
        The maximum number of pods per node in this node pool. Note that this does not work on node pools which are "route-based" - that is, node pools belonging to clusters that do not have IP Aliasing enabled.
        """
        name: NotRequired[pulumi.Input[builtins.str]]
        """
        The name of the cluster, unique within the project and
        location.

        - - -
        """
        name_prefix: NotRequired[pulumi.Input[builtins.str]]
        """
        Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.
        """
        network_config: NotRequired[pulumi.Input['ClusterNodePoolNetworkConfigArgsDict']]
        """
        Configuration for
        [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
        """
        node_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigArgsDict']]
        """
        Parameters used in creating the default node pool.
        Generally, this field should not be used at the same time as a
        `container.NodePool` or a `node_pool` block; this configuration
        manages the default node pool, which isn't recommended to be used.
        Structure is documented below.
        """
        node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.
        """
        node_locations: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The list of zones in which the cluster's nodes
        are located. Nodes must be in the region of their regional cluster or in the
        same region as their cluster's zone for zonal clusters. If this is specified for
        a zonal cluster, omit the cluster's zone.

        > A "multi-zonal" cluster is a zonal cluster with at least one additional zone
        defined; in a multi-zonal cluster, the cluster master is only present in a
        single zone while nodes are present in each of the primary zone and the node
        locations. In contrast, in a regional cluster, cluster master nodes are present
        in multiple zones in the region. For that reason, regional clusters should be
        preferred.
        """
        placement_policy: NotRequired[pulumi.Input['ClusterNodePoolPlacementPolicyArgsDict']]
        """
        Specifies the node placement policy
        """
        queued_provisioning: NotRequired[pulumi.Input['ClusterNodePoolQueuedProvisioningArgsDict']]
        """
        Specifies the configuration of queued provisioning
        """
        upgrade_settings: NotRequired[pulumi.Input['ClusterNodePoolUpgradeSettingsArgsDict']]
        """
        Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of max_surge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.
        """
        version: NotRequired[pulumi.Input[builtins.str]]
elif False:
    ClusterNodePoolArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolArgs:
    def __init__(__self__, *,
                 autoscaling: Optional[pulumi.Input['ClusterNodePoolAutoscalingArgs']] = None,
                 initial_node_count: Optional[pulumi.Input[builtins.int]] = None,
                 instance_group_urls: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 managed_instance_group_urls: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 management: Optional[pulumi.Input['ClusterNodePoolManagementArgs']] = None,
                 max_pods_per_node: Optional[pulumi.Input[builtins.int]] = None,
                 name: Optional[pulumi.Input[builtins.str]] = None,
                 name_prefix: Optional[pulumi.Input[builtins.str]] = None,
                 network_config: Optional[pulumi.Input['ClusterNodePoolNetworkConfigArgs']] = None,
                 node_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigArgs']] = None,
                 node_count: Optional[pulumi.Input[builtins.int]] = None,
                 node_locations: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 placement_policy: Optional[pulumi.Input['ClusterNodePoolPlacementPolicyArgs']] = None,
                 queued_provisioning: Optional[pulumi.Input['ClusterNodePoolQueuedProvisioningArgs']] = None,
                 upgrade_settings: Optional[pulumi.Input['ClusterNodePoolUpgradeSettingsArgs']] = None,
                 version: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input['ClusterNodePoolAutoscalingArgs'] autoscaling: Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
        :param pulumi.Input[builtins.int] initial_node_count: The number of nodes to create in this
               cluster's default node pool. In regional or multi-zonal clusters, this is the
               number of nodes per zone. Must be set if `node_pool` is not set. If you're using
               `container.NodePool` objects with no default node pool, you'll need to
               set this to a value of at least `1`, alongside setting
               `remove_default_node_pool` to `true`.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] instance_group_urls: The resource URLs of the managed instance groups associated with this node pool.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] managed_instance_group_urls: List of instance group URLs which have been assigned to this node pool.
        :param pulumi.Input['ClusterNodePoolManagementArgs'] management: Node management configuration, wherein auto-repair and auto-upgrade is configured.
        :param pulumi.Input[builtins.int] max_pods_per_node: The maximum number of pods per node in this node pool. Note that this does not work on node pools which are "route-based" - that is, node pools belonging to clusters that do not have IP Aliasing enabled.
        :param pulumi.Input[builtins.str] name: The name of the cluster, unique within the project and
               location.
               
               - - -
        :param pulumi.Input[builtins.str] name_prefix: Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.
        :param pulumi.Input['ClusterNodePoolNetworkConfigArgs'] network_config: Configuration for
               [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
        :param pulumi.Input['ClusterNodePoolNodeConfigArgs'] node_config: Parameters used in creating the default node pool.
               Generally, this field should not be used at the same time as a
               `container.NodePool` or a `node_pool` block; this configuration
               manages the default node pool, which isn't recommended to be used.
               Structure is documented below.
        :param pulumi.Input[builtins.int] node_count: The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] node_locations: The list of zones in which the cluster's nodes
               are located. Nodes must be in the region of their regional cluster or in the
               same region as their cluster's zone for zonal clusters. If this is specified for
               a zonal cluster, omit the cluster's zone.
               
               > A "multi-zonal" cluster is a zonal cluster with at least one additional zone
               defined; in a multi-zonal cluster, the cluster master is only present in a
               single zone while nodes are present in each of the primary zone and the node
               locations. In contrast, in a regional cluster, cluster master nodes are present
               in multiple zones in the region. For that reason, regional clusters should be
               preferred.
        :param pulumi.Input['ClusterNodePoolPlacementPolicyArgs'] placement_policy: Specifies the node placement policy
        :param pulumi.Input['ClusterNodePoolQueuedProvisioningArgs'] queued_provisioning: Specifies the configuration of queued provisioning
        :param pulumi.Input['ClusterNodePoolUpgradeSettingsArgs'] upgrade_settings: Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of max_surge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.
        """
        if autoscaling is not None:
            pulumi.set(__self__, "autoscaling", autoscaling)
        if initial_node_count is not None:
            pulumi.set(__self__, "initial_node_count", initial_node_count)
        if instance_group_urls is not None:
            pulumi.set(__self__, "instance_group_urls", instance_group_urls)
        if managed_instance_group_urls is not None:
            pulumi.set(__self__, "managed_instance_group_urls", managed_instance_group_urls)
        if management is not None:
            pulumi.set(__self__, "management", management)
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if name_prefix is not None:
            pulumi.set(__self__, "name_prefix", name_prefix)
        if network_config is not None:
            pulumi.set(__self__, "network_config", network_config)
        if node_config is not None:
            pulumi.set(__self__, "node_config", node_config)
        if node_count is not None:
            pulumi.set(__self__, "node_count", node_count)
        if node_locations is not None:
            pulumi.set(__self__, "node_locations", node_locations)
        if placement_policy is not None:
            pulumi.set(__self__, "placement_policy", placement_policy)
        if queued_provisioning is not None:
            pulumi.set(__self__, "queued_provisioning", queued_provisioning)
        if upgrade_settings is not None:
            pulumi.set(__self__, "upgrade_settings", upgrade_settings)
        if version is not None:
            pulumi.set(__self__, "version", version)

    @property
    @pulumi.getter
    def autoscaling(self) -> Optional[pulumi.Input['ClusterNodePoolAutoscalingArgs']]:
        """
        Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
        """
        return pulumi.get(self, "autoscaling")

    @autoscaling.setter
    def autoscaling(self, value: Optional[pulumi.Input['ClusterNodePoolAutoscalingArgs']]):
        pulumi.set(self, "autoscaling", value)

    @property
    @pulumi.getter(name="initialNodeCount")
    def initial_node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The number of nodes to create in this
        cluster's default node pool. In regional or multi-zonal clusters, this is the
        number of nodes per zone. Must be set if `node_pool` is not set. If you're using
        `container.NodePool` objects with no default node pool, you'll need to
        set this to a value of at least `1`, alongside setting
        `remove_default_node_pool` to `true`.
        """
        return pulumi.get(self, "initial_node_count")

    @initial_node_count.setter
    def initial_node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "initial_node_count", value)

    @property
    @pulumi.getter(name="instanceGroupUrls")
    def instance_group_urls(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The resource URLs of the managed instance groups associated with this node pool.
        """
        return pulumi.get(self, "instance_group_urls")

    @instance_group_urls.setter
    def instance_group_urls(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "instance_group_urls", value)

    @property
    @pulumi.getter(name="managedInstanceGroupUrls")
    def managed_instance_group_urls(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        List of instance group URLs which have been assigned to this node pool.
        """
        return pulumi.get(self, "managed_instance_group_urls")

    @managed_instance_group_urls.setter
    def managed_instance_group_urls(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "managed_instance_group_urls", value)

    @property
    @pulumi.getter
    def management(self) -> Optional[pulumi.Input['ClusterNodePoolManagementArgs']]:
        """
        Node management configuration, wherein auto-repair and auto-upgrade is configured.
        """
        return pulumi.get(self, "management")

    @management.setter
    def management(self, value: Optional[pulumi.Input['ClusterNodePoolManagementArgs']]):
        pulumi.set(self, "management", value)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The maximum number of pods per node in this node pool. Note that this does not work on node pools which are "route-based" - that is, node pools belonging to clusters that do not have IP Aliasing enabled.
        """
        return pulumi.get(self, "max_pods_per_node")

    @max_pods_per_node.setter
    def max_pods_per_node(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_pods_per_node", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of the cluster, unique within the project and
        location.

        - - -
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter(name="namePrefix")
    def name_prefix(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.
        """
        return pulumi.get(self, "name_prefix")

    @name_prefix.setter
    def name_prefix(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "name_prefix", value)

    @property
    @pulumi.getter(name="networkConfig")
    def network_config(self) -> Optional[pulumi.Input['ClusterNodePoolNetworkConfigArgs']]:
        """
        Configuration for
        [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
        """
        return pulumi.get(self, "network_config")

    @network_config.setter
    def network_config(self, value: Optional[pulumi.Input['ClusterNodePoolNetworkConfigArgs']]):
        pulumi.set(self, "network_config", value)

    @property
    @pulumi.getter(name="nodeConfig")
    def node_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigArgs']]:
        """
        Parameters used in creating the default node pool.
        Generally, this field should not be used at the same time as a
        `container.NodePool` or a `node_pool` block; this configuration
        manages the default node pool, which isn't recommended to be used.
        Structure is documented below.
        """
        return pulumi.get(self, "node_config")

    @node_config.setter
    def node_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigArgs']]):
        pulumi.set(self, "node_config", value)

    @property
    @pulumi.getter(name="nodeCount")
    def node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.
        """
        return pulumi.get(self, "node_count")

    @node_count.setter
    def node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "node_count", value)

    @property
    @pulumi.getter(name="nodeLocations")
    def node_locations(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The list of zones in which the cluster's nodes
        are located. Nodes must be in the region of their regional cluster or in the
        same region as their cluster's zone for zonal clusters. If this is specified for
        a zonal cluster, omit the cluster's zone.

        > A "multi-zonal" cluster is a zonal cluster with at least one additional zone
        defined; in a multi-zonal cluster, the cluster master is only present in a
        single zone while nodes are present in each of the primary zone and the node
        locations. In contrast, in a regional cluster, cluster master nodes are present
        in multiple zones in the region. For that reason, regional clusters should be
        preferred.
        """
        return pulumi.get(self, "node_locations")

    @node_locations.setter
    def node_locations(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "node_locations", value)

    @property
    @pulumi.getter(name="placementPolicy")
    def placement_policy(self) -> Optional[pulumi.Input['ClusterNodePoolPlacementPolicyArgs']]:
        """
        Specifies the node placement policy
        """
        return pulumi.get(self, "placement_policy")

    @placement_policy.setter
    def placement_policy(self, value: Optional[pulumi.Input['ClusterNodePoolPlacementPolicyArgs']]):
        pulumi.set(self, "placement_policy", value)

    @property
    @pulumi.getter(name="queuedProvisioning")
    def queued_provisioning(self) -> Optional[pulumi.Input['ClusterNodePoolQueuedProvisioningArgs']]:
        """
        Specifies the configuration of queued provisioning
        """
        return pulumi.get(self, "queued_provisioning")

    @queued_provisioning.setter
    def queued_provisioning(self, value: Optional[pulumi.Input['ClusterNodePoolQueuedProvisioningArgs']]):
        pulumi.set(self, "queued_provisioning", value)

    @property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Optional[pulumi.Input['ClusterNodePoolUpgradeSettingsArgs']]:
        """
        Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of max_surge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.
        """
        return pulumi.get(self, "upgrade_settings")

    @upgrade_settings.setter
    def upgrade_settings(self, value: Optional[pulumi.Input['ClusterNodePoolUpgradeSettingsArgs']]):
        pulumi.set(self, "upgrade_settings", value)

    @property
    @pulumi.getter
    def version(self) -> Optional[pulumi.Input[builtins.str]]:
        return pulumi.get(self, "version")

    @version.setter
    def version(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "version", value)


if not MYPY:
    class ClusterNodePoolAutoConfigArgsDict(TypedDict):
        linux_node_config: NotRequired[pulumi.Input['ClusterNodePoolAutoConfigLinuxNodeConfigArgsDict']]
        """
        Linux system configuration for the cluster's automatically provisioned node pools. Only `cgroup_mode` field is supported in `node_pool_auto_config`. Structure is documented below.
        """
        network_tags: NotRequired[pulumi.Input['ClusterNodePoolAutoConfigNetworkTagsArgsDict']]
        """
        The network tag config for the cluster's automatically provisioned node pools. Structure is documented below.
        """
        node_kubelet_config: NotRequired[pulumi.Input['ClusterNodePoolAutoConfigNodeKubeletConfigArgsDict']]
        """
        Kubelet configuration for Autopilot clusters. Currently, only `insecure_kubelet_readonly_port_enabled` is supported here.
        Structure is documented below.
        """
        resource_manager_tags: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
elif False:
    ClusterNodePoolAutoConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolAutoConfigArgs:
    def __init__(__self__, *,
                 linux_node_config: Optional[pulumi.Input['ClusterNodePoolAutoConfigLinuxNodeConfigArgs']] = None,
                 network_tags: Optional[pulumi.Input['ClusterNodePoolAutoConfigNetworkTagsArgs']] = None,
                 node_kubelet_config: Optional[pulumi.Input['ClusterNodePoolAutoConfigNodeKubeletConfigArgs']] = None,
                 resource_manager_tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input['ClusterNodePoolAutoConfigLinuxNodeConfigArgs'] linux_node_config: Linux system configuration for the cluster's automatically provisioned node pools. Only `cgroup_mode` field is supported in `node_pool_auto_config`. Structure is documented below.
        :param pulumi.Input['ClusterNodePoolAutoConfigNetworkTagsArgs'] network_tags: The network tag config for the cluster's automatically provisioned node pools. Structure is documented below.
        :param pulumi.Input['ClusterNodePoolAutoConfigNodeKubeletConfigArgs'] node_kubelet_config: Kubelet configuration for Autopilot clusters. Currently, only `insecure_kubelet_readonly_port_enabled` is supported here.
               Structure is documented below.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] resource_manager_tags: A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if network_tags is not None:
            pulumi.set(__self__, "network_tags", network_tags)
        if node_kubelet_config is not None:
            pulumi.set(__self__, "node_kubelet_config", node_kubelet_config)
        if resource_manager_tags is not None:
            pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional[pulumi.Input['ClusterNodePoolAutoConfigLinuxNodeConfigArgs']]:
        """
        Linux system configuration for the cluster's automatically provisioned node pools. Only `cgroup_mode` field is supported in `node_pool_auto_config`. Structure is documented below.
        """
        return pulumi.get(self, "linux_node_config")

    @linux_node_config.setter
    def linux_node_config(self, value: Optional[pulumi.Input['ClusterNodePoolAutoConfigLinuxNodeConfigArgs']]):
        pulumi.set(self, "linux_node_config", value)

    @property
    @pulumi.getter(name="networkTags")
    def network_tags(self) -> Optional[pulumi.Input['ClusterNodePoolAutoConfigNetworkTagsArgs']]:
        """
        The network tag config for the cluster's automatically provisioned node pools. Structure is documented below.
        """
        return pulumi.get(self, "network_tags")

    @network_tags.setter
    def network_tags(self, value: Optional[pulumi.Input['ClusterNodePoolAutoConfigNetworkTagsArgs']]):
        pulumi.set(self, "network_tags", value)

    @property
    @pulumi.getter(name="nodeKubeletConfig")
    def node_kubelet_config(self) -> Optional[pulumi.Input['ClusterNodePoolAutoConfigNodeKubeletConfigArgs']]:
        """
        Kubelet configuration for Autopilot clusters. Currently, only `insecure_kubelet_readonly_port_enabled` is supported here.
        Structure is documented below.
        """
        return pulumi.get(self, "node_kubelet_config")

    @node_kubelet_config.setter
    def node_kubelet_config(self, value: Optional[pulumi.Input['ClusterNodePoolAutoConfigNodeKubeletConfigArgs']]):
        pulumi.set(self, "node_kubelet_config", value)

    @property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        return pulumi.get(self, "resource_manager_tags")

    @resource_manager_tags.setter
    def resource_manager_tags(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "resource_manager_tags", value)


if not MYPY:
    class ClusterNodePoolAutoConfigLinuxNodeConfigArgsDict(TypedDict):
        cgroup_mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Possible cgroup modes that can be used.
        Accepted values are:
        * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
        * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
        * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        """
elif False:
    ClusterNodePoolAutoConfigLinuxNodeConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolAutoConfigLinuxNodeConfigArgs:
    def __init__(__self__, *,
                 cgroup_mode: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] cgroup_mode: Possible cgroup modes that can be used.
               Accepted values are:
               * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
               * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
               * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        """
        if cgroup_mode is not None:
            pulumi.set(__self__, "cgroup_mode", cgroup_mode)

    @property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Possible cgroup modes that can be used.
        Accepted values are:
        * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
        * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
        * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        """
        return pulumi.get(self, "cgroup_mode")

    @cgroup_mode.setter
    def cgroup_mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cgroup_mode", value)


if not MYPY:
    class ClusterNodePoolAutoConfigNetworkTagsArgsDict(TypedDict):
        tags: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        List of network tags applied to auto-provisioned node pools.
        """
elif False:
    ClusterNodePoolAutoConfigNetworkTagsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolAutoConfigNetworkTagsArgs:
    def __init__(__self__, *,
                 tags: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] tags: List of network tags applied to auto-provisioned node pools.
        """
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        List of network tags applied to auto-provisioned node pools.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "tags", value)


if not MYPY:
    class ClusterNodePoolAutoConfigNodeKubeletConfigArgsDict(TypedDict):
        insecure_kubelet_readonly_port_enabled: NotRequired[pulumi.Input[builtins.str]]
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
elif False:
    ClusterNodePoolAutoConfigNodeKubeletConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolAutoConfigNodeKubeletConfigArgs:
    def __init__(__self__, *,
                 insecure_kubelet_readonly_port_enabled: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @insecure_kubelet_readonly_port_enabled.setter
    def insecure_kubelet_readonly_port_enabled(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "insecure_kubelet_readonly_port_enabled", value)


if not MYPY:
    class ClusterNodePoolAutoscalingArgsDict(TypedDict):
        location_policy: NotRequired[pulumi.Input[builtins.str]]
        """
        Location policy specifies the algorithm used when scaling-up the node pool. "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones. "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations, and reduces preemption risk for Spot VMs.
        """
        max_node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Maximum number of nodes per zone in the node pool. Must be >= min_node_count. Cannot be used with total limits.
        """
        min_node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Minimum number of nodes per zone in the node pool. Must be >=0 and <= max_node_count. Cannot be used with total limits.
        """
        total_max_node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Maximum number of all nodes in the node pool. Must be >= total_min_node_count. Cannot be used with per zone limits.
        """
        total_min_node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Minimum number of all nodes in the node pool. Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
        """
elif False:
    ClusterNodePoolAutoscalingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolAutoscalingArgs:
    def __init__(__self__, *,
                 location_policy: Optional[pulumi.Input[builtins.str]] = None,
                 max_node_count: Optional[pulumi.Input[builtins.int]] = None,
                 min_node_count: Optional[pulumi.Input[builtins.int]] = None,
                 total_max_node_count: Optional[pulumi.Input[builtins.int]] = None,
                 total_min_node_count: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.str] location_policy: Location policy specifies the algorithm used when scaling-up the node pool. "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones. "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations, and reduces preemption risk for Spot VMs.
        :param pulumi.Input[builtins.int] max_node_count: Maximum number of nodes per zone in the node pool. Must be >= min_node_count. Cannot be used with total limits.
        :param pulumi.Input[builtins.int] min_node_count: Minimum number of nodes per zone in the node pool. Must be >=0 and <= max_node_count. Cannot be used with total limits.
        :param pulumi.Input[builtins.int] total_max_node_count: Maximum number of all nodes in the node pool. Must be >= total_min_node_count. Cannot be used with per zone limits.
        :param pulumi.Input[builtins.int] total_min_node_count: Minimum number of all nodes in the node pool. Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
        """
        if location_policy is not None:
            pulumi.set(__self__, "location_policy", location_policy)
        if max_node_count is not None:
            pulumi.set(__self__, "max_node_count", max_node_count)
        if min_node_count is not None:
            pulumi.set(__self__, "min_node_count", min_node_count)
        if total_max_node_count is not None:
            pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        if total_min_node_count is not None:
            pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Location policy specifies the algorithm used when scaling-up the node pool. "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones. "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations, and reduces preemption risk for Spot VMs.
        """
        return pulumi.get(self, "location_policy")

    @location_policy.setter
    def location_policy(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "location_policy", value)

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Maximum number of nodes per zone in the node pool. Must be >= min_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "max_node_count")

    @max_node_count.setter
    def max_node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_node_count", value)

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Minimum number of nodes per zone in the node pool. Must be >=0 and <= max_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "min_node_count")

    @min_node_count.setter
    def min_node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "min_node_count", value)

    @property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Maximum number of all nodes in the node pool. Must be >= total_min_node_count. Cannot be used with per zone limits.
        """
        return pulumi.get(self, "total_max_node_count")

    @total_max_node_count.setter
    def total_max_node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "total_max_node_count", value)

    @property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Minimum number of all nodes in the node pool. Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
        """
        return pulumi.get(self, "total_min_node_count")

    @total_min_node_count.setter
    def total_min_node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "total_min_node_count", value)


if not MYPY:
    class ClusterNodePoolDefaultsArgsDict(TypedDict):
        node_config_defaults: NotRequired[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsArgsDict']]
        """
        Subset of NodeConfig message that has defaults.
        """
elif False:
    ClusterNodePoolDefaultsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolDefaultsArgs:
    def __init__(__self__, *,
                 node_config_defaults: Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsArgs']] = None):
        """
        :param pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsArgs'] node_config_defaults: Subset of NodeConfig message that has defaults.
        """
        if node_config_defaults is not None:
            pulumi.set(__self__, "node_config_defaults", node_config_defaults)

    @property
    @pulumi.getter(name="nodeConfigDefaults")
    def node_config_defaults(self) -> Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsArgs']]:
        """
        Subset of NodeConfig message that has defaults.
        """
        return pulumi.get(self, "node_config_defaults")

    @node_config_defaults.setter
    def node_config_defaults(self, value: Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsArgs']]):
        pulumi.set(self, "node_config_defaults", value)


if not MYPY:
    class ClusterNodePoolDefaultsNodeConfigDefaultsArgsDict(TypedDict):
        containerd_config: NotRequired[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigArgsDict']]
        """
        Parameters for containerd configuration.
        """
        gcfs_config: NotRequired[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgsDict']]
        """
        The default Google Container Filesystem (GCFS) configuration at the cluster level. e.g. enable [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming) across all the node pools within the cluster. Structure is documented below.
        """
        insecure_kubelet_readonly_port_enabled: NotRequired[pulumi.Input[builtins.str]]
        """
        Controls whether the kubelet read-only port is enabled for newly created node pools in the cluster. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        logging_variant: NotRequired[pulumi.Input[builtins.str]]
        """
        The type of logging agent that is deployed by default for newly created node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
elif False:
    ClusterNodePoolDefaultsNodeConfigDefaultsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolDefaultsNodeConfigDefaultsArgs:
    def __init__(__self__, *,
                 containerd_config: Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigArgs']] = None,
                 gcfs_config: Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs']] = None,
                 insecure_kubelet_readonly_port_enabled: Optional[pulumi.Input[builtins.str]] = None,
                 logging_variant: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigArgs'] containerd_config: Parameters for containerd configuration.
        :param pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs'] gcfs_config: The default Google Container Filesystem (GCFS) configuration at the cluster level. e.g. enable [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming) across all the node pools within the cluster. Structure is documented below.
        :param pulumi.Input[builtins.str] insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled for newly created node pools in the cluster. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param pulumi.Input[builtins.str] logging_variant: The type of logging agent that is deployed by default for newly created node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        if containerd_config is not None:
            pulumi.set(__self__, "containerd_config", containerd_config)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)

    @property
    @pulumi.getter(name="containerdConfig")
    def containerd_config(self) -> Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigArgs']]:
        """
        Parameters for containerd configuration.
        """
        return pulumi.get(self, "containerd_config")

    @containerd_config.setter
    def containerd_config(self, value: Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigArgs']]):
        pulumi.set(self, "containerd_config", value)

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs']]:
        """
        The default Google Container Filesystem (GCFS) configuration at the cluster level. e.g. enable [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming) across all the node pools within the cluster. Structure is documented below.
        """
        return pulumi.get(self, "gcfs_config")

    @gcfs_config.setter
    def gcfs_config(self, value: Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs']]):
        pulumi.set(self, "gcfs_config", value)

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Controls whether the kubelet read-only port is enabled for newly created node pools in the cluster. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @insecure_kubelet_readonly_port_enabled.setter
    def insecure_kubelet_readonly_port_enabled(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "insecure_kubelet_readonly_port_enabled", value)

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The type of logging agent that is deployed by default for newly created node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")

    @logging_variant.setter
    def logging_variant(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "logging_variant", value)


if not MYPY:
    class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigArgsDict(TypedDict):
        private_registry_access_config: NotRequired[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigArgsDict']]
        """
        Configuration for private container registries. There are two fields in this config:
        """
elif False:
    ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigArgs:
    def __init__(__self__, *,
                 private_registry_access_config: Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigArgs']] = None):
        """
        :param pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigArgs'] private_registry_access_config: Configuration for private container registries. There are two fields in this config:
        """
        if private_registry_access_config is not None:
            pulumi.set(__self__, "private_registry_access_config", private_registry_access_config)

    @property
    @pulumi.getter(name="privateRegistryAccessConfig")
    def private_registry_access_config(self) -> Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigArgs']]:
        """
        Configuration for private container registries. There are two fields in this config:
        """
        return pulumi.get(self, "private_registry_access_config")

    @private_registry_access_config.setter
    def private_registry_access_config(self, value: Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigArgs']]):
        pulumi.set(self, "private_registry_access_config", value)


if not MYPY:
    class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Enables private registry config. If set to false, all other fields in this object must not be set.
        """
        certificate_authority_domain_configs: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict']]]]
        """
        List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
elif False:
    ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool],
                 certificate_authority_domain_configs: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]]] = None):
        """
        :param pulumi.Input[builtins.bool] enabled: Enables private registry config. If set to false, all other fields in this object must not be set.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]] certificate_authority_domain_configs: List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
        pulumi.set(__self__, "enabled", enabled)
        if certificate_authority_domain_configs is not None:
            pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Enables private registry config. If set to false, all other fields in this object must not be set.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]]]:
        """
        List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
        return pulumi.get(self, "certificate_authority_domain_configs")

    @certificate_authority_domain_configs.setter
    def certificate_authority_domain_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]]]):
        pulumi.set(self, "certificate_authority_domain_configs", value)


if not MYPY:
    class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict(TypedDict):
        fqdns: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        gcp_secret_manager_certificate_config: pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict']
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
elif False:
    ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs:
    def __init__(__self__, *,
                 fqdns: pulumi.Input[Sequence[pulumi.Input[builtins.str]]],
                 gcp_secret_manager_certificate_config: pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs']):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs'] gcp_secret_manager_certificate_config: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_config", gcp_secret_manager_certificate_config)

    @property
    @pulumi.getter
    def fqdns(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @fqdns.setter
    def fqdns(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "fqdns", value)

    @property
    @pulumi.getter(name="gcpSecretManagerCertificateConfig")
    def gcp_secret_manager_certificate_config(self) -> pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs']:
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_config")

    @gcp_secret_manager_certificate_config.setter
    def gcp_secret_manager_certificate_config(self, value: pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs']):
        pulumi.set(self, "gcp_secret_manager_certificate_config", value)


if not MYPY:
    class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict(TypedDict):
        secret_uri: pulumi.Input[builtins.str]
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
elif False:
    ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolDefaultsNodeConfigDefaultsContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs:
    def __init__(__self__, *,
                 secret_uri: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> pulumi.Input[builtins.str]:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")

    @secret_uri.setter
    def secret_uri(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "secret_uri", value)


if not MYPY:
    class ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
elif False:
    ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterNodePoolManagementArgsDict(TypedDict):
        auto_repair: NotRequired[pulumi.Input[builtins.bool]]
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.

        This block also contains several computed attributes, documented below.
        """
        auto_upgrade: NotRequired[pulumi.Input[builtins.bool]]
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
elif False:
    ClusterNodePoolManagementArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolManagementArgs:
    def __init__(__self__, *,
                 auto_repair: Optional[pulumi.Input[builtins.bool]] = None,
                 auto_upgrade: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.bool] auto_repair: Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
               
               This block also contains several computed attributes, documented below.
        :param pulumi.Input[builtins.bool] auto_upgrade: Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.

        This block also contains several computed attributes, documented below.
        """
        return pulumi.get(self, "auto_repair")

    @auto_repair.setter
    def auto_repair(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "auto_repair", value)

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        return pulumi.get(self, "auto_upgrade")

    @auto_upgrade.setter
    def auto_upgrade(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "auto_upgrade", value)


if not MYPY:
    class ClusterNodePoolNetworkConfigArgsDict(TypedDict):
        additional_node_network_configs: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgsDict']]]]
        """
        We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface
        """
        additional_pod_network_configs: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgsDict']]]]
        """
        We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node
        """
        create_pod_range: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        """
        enable_private_nodes: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether nodes have internal IP addresses only.
        """
        network_performance_config: NotRequired[pulumi.Input['ClusterNodePoolNetworkConfigNetworkPerformanceConfigArgsDict']]
        """
        Network bandwidth tier configuration.
        """
        pod_cidr_overprovision_config: NotRequired[pulumi.Input['ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgsDict']]
        """
        Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited
        """
        pod_ipv4_cidr_block: NotRequired[pulumi.Input[builtins.str]]
        """
        The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        pod_range: NotRequired[pulumi.Input[builtins.str]]
        """
        The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
elif False:
    ClusterNodePoolNetworkConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNetworkConfigArgs:
    def __init__(__self__, *,
                 additional_node_network_configs: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]]] = None,
                 additional_pod_network_configs: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]]] = None,
                 create_pod_range: Optional[pulumi.Input[builtins.bool]] = None,
                 enable_private_nodes: Optional[pulumi.Input[builtins.bool]] = None,
                 network_performance_config: Optional[pulumi.Input['ClusterNodePoolNetworkConfigNetworkPerformanceConfigArgs']] = None,
                 pod_cidr_overprovision_config: Optional[pulumi.Input['ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs']] = None,
                 pod_ipv4_cidr_block: Optional[pulumi.Input[builtins.str]] = None,
                 pod_range: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]] additional_node_network_configs: We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]] additional_pod_network_configs: We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node
        :param pulumi.Input[builtins.bool] create_pod_range: Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        :param pulumi.Input[builtins.bool] enable_private_nodes: Whether nodes have internal IP addresses only.
        :param pulumi.Input['ClusterNodePoolNetworkConfigNetworkPerformanceConfigArgs'] network_performance_config: Network bandwidth tier configuration.
        :param pulumi.Input['ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs'] pod_cidr_overprovision_config: Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited
        :param pulumi.Input[builtins.str] pod_ipv4_cidr_block: The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        :param pulumi.Input[builtins.str] pod_range: The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        if additional_node_network_configs is not None:
            pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        if additional_pod_network_configs is not None:
            pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        if create_pod_range is not None:
            pulumi.set(__self__, "create_pod_range", create_pod_range)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if network_performance_config is not None:
            pulumi.set(__self__, "network_performance_config", network_performance_config)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if pod_ipv4_cidr_block is not None:
            pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        if pod_range is not None:
            pulumi.set(__self__, "pod_range", pod_range)

    @property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]]]:
        """
        We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface
        """
        return pulumi.get(self, "additional_node_network_configs")

    @additional_node_network_configs.setter
    def additional_node_network_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]]]):
        pulumi.set(self, "additional_node_network_configs", value)

    @property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]]]:
        """
        We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node
        """
        return pulumi.get(self, "additional_pod_network_configs")

    @additional_pod_network_configs.setter
    def additional_pod_network_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]]]):
        pulumi.set(self, "additional_pod_network_configs", value)

    @property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        """
        return pulumi.get(self, "create_pod_range")

    @create_pod_range.setter
    def create_pod_range(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "create_pod_range", value)

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether nodes have internal IP addresses only.
        """
        return pulumi.get(self, "enable_private_nodes")

    @enable_private_nodes.setter
    def enable_private_nodes(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_private_nodes", value)

    @property
    @pulumi.getter(name="networkPerformanceConfig")
    def network_performance_config(self) -> Optional[pulumi.Input['ClusterNodePoolNetworkConfigNetworkPerformanceConfigArgs']]:
        """
        Network bandwidth tier configuration.
        """
        return pulumi.get(self, "network_performance_config")

    @network_performance_config.setter
    def network_performance_config(self, value: Optional[pulumi.Input['ClusterNodePoolNetworkConfigNetworkPerformanceConfigArgs']]):
        pulumi.set(self, "network_performance_config", value)

    @property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional[pulumi.Input['ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs']]:
        """
        Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited
        """
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @pod_cidr_overprovision_config.setter
    def pod_cidr_overprovision_config(self, value: Optional[pulumi.Input['ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs']]):
        pulumi.set(self, "pod_cidr_overprovision_config", value)

    @property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @pod_ipv4_cidr_block.setter
    def pod_ipv4_cidr_block(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "pod_ipv4_cidr_block", value)

    @property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        return pulumi.get(self, "pod_range")

    @pod_range.setter
    def pod_range(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "pod_range", value)


if not MYPY:
    class ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgsDict(TypedDict):
        network: NotRequired[pulumi.Input[builtins.str]]
        """
        The name or self_link of the Google Compute Engine
        network to which the cluster is connected. For Shared VPC, set this to the self link of the
        shared network.
        """
        subnetwork: NotRequired[pulumi.Input[builtins.str]]
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
elif False:
    ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs:
    def __init__(__self__, *,
                 network: Optional[pulumi.Input[builtins.str]] = None,
                 subnetwork: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] network: The name or self_link of the Google Compute Engine
               network to which the cluster is connected. For Shared VPC, set this to the self link of the
               shared network.
        :param pulumi.Input[builtins.str] subnetwork: The name or self_link of the Google Compute Engine
               subnetwork in which the cluster's instances are launched.
        """
        if network is not None:
            pulumi.set(__self__, "network", network)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter
    def network(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name or self_link of the Google Compute Engine
        network to which the cluster is connected. For Shared VPC, set this to the self link of the
        shared network.
        """
        return pulumi.get(self, "network")

    @network.setter
    def network(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "network", value)

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
        return pulumi.get(self, "subnetwork")

    @subnetwork.setter
    def subnetwork(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "subnetwork", value)


if not MYPY:
    class ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgsDict(TypedDict):
        max_pods_per_node: NotRequired[pulumi.Input[builtins.int]]
        """
        The maximum number of pods per node which use this pod network.
        """
        secondary_pod_range: NotRequired[pulumi.Input[builtins.str]]
        """
        The name of the secondary range on the subnet which provides IP address for this pod range.
        """
        subnetwork: NotRequired[pulumi.Input[builtins.str]]
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
elif False:
    ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs:
    def __init__(__self__, *,
                 max_pods_per_node: Optional[pulumi.Input[builtins.int]] = None,
                 secondary_pod_range: Optional[pulumi.Input[builtins.str]] = None,
                 subnetwork: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.int] max_pods_per_node: The maximum number of pods per node which use this pod network.
        :param pulumi.Input[builtins.str] secondary_pod_range: The name of the secondary range on the subnet which provides IP address for this pod range.
        :param pulumi.Input[builtins.str] subnetwork: The name or self_link of the Google Compute Engine
               subnetwork in which the cluster's instances are launched.
        """
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if secondary_pod_range is not None:
            pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The maximum number of pods per node which use this pod network.
        """
        return pulumi.get(self, "max_pods_per_node")

    @max_pods_per_node.setter
    def max_pods_per_node(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_pods_per_node", value)

    @property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of the secondary range on the subnet which provides IP address for this pod range.
        """
        return pulumi.get(self, "secondary_pod_range")

    @secondary_pod_range.setter
    def secondary_pod_range(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "secondary_pod_range", value)

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
        return pulumi.get(self, "subnetwork")

    @subnetwork.setter
    def subnetwork(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "subnetwork", value)


if not MYPY:
    class ClusterNodePoolNetworkConfigNetworkPerformanceConfigArgsDict(TypedDict):
        total_egress_bandwidth_tier: pulumi.Input[builtins.str]
        """
        Specifies the total network bandwidth tier for the NodePool.
        """
elif False:
    ClusterNodePoolNetworkConfigNetworkPerformanceConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNetworkConfigNetworkPerformanceConfigArgs:
    def __init__(__self__, *,
                 total_egress_bandwidth_tier: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] total_egress_bandwidth_tier: Specifies the total network bandwidth tier for the NodePool.
        """
        pulumi.set(__self__, "total_egress_bandwidth_tier", total_egress_bandwidth_tier)

    @property
    @pulumi.getter(name="totalEgressBandwidthTier")
    def total_egress_bandwidth_tier(self) -> pulumi.Input[builtins.str]:
        """
        Specifies the total network bandwidth tier for the NodePool.
        """
        return pulumi.get(self, "total_egress_bandwidth_tier")

    @total_egress_bandwidth_tier.setter
    def total_egress_bandwidth_tier(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "total_egress_bandwidth_tier", value)


if not MYPY:
    class ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgsDict(TypedDict):
        disabled: pulumi.Input[builtins.bool]
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
elif False:
    ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "disabled", value)


if not MYPY:
    class ClusterNodePoolNodeConfigArgsDict(TypedDict):
        advanced_machine_features: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgsDict']]
        """
        Specifies options for controlling
        advanced machine features. Structure is documented below.
        """
        boot_disk_kms_key: NotRequired[pulumi.Input[builtins.str]]
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        """
        confidential_nodes: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigConfidentialNodesArgsDict']]
        """
        Configuration for Confidential Nodes feature. Structure is documented below.
        """
        containerd_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigArgsDict']]
        """
        Parameters to customize containerd runtime. Structure is documented below.
        """
        disk_size_gb: NotRequired[pulumi.Input[builtins.int]]
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        """
        disk_type: NotRequired[pulumi.Input[builtins.str]]
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        """
        effective_taints: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigEffectiveTaintArgsDict']]]]
        """
        List of kubernetes taints applied to each node. Structure is documented above.
        """
        enable_confidential_storage: NotRequired[pulumi.Input[builtins.bool]]
        """
        Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        """
        ephemeral_storage_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageConfigArgsDict']]
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        ephemeral_storage_local_ssd_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgsDict']]
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        fast_socket: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigFastSocketArgsDict']]
        """
        Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
        Node Pool must enable gvnic.
        GKE version 1.25.2-gke.1700 or later.
        Structure is documented below.
        """
        flex_start: NotRequired[pulumi.Input[builtins.bool]]
        """
        ) Enables Flex Start provisioning model for the node pool.
        """
        gcfs_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigGcfsConfigArgsDict']]
        """
        Parameters for the Google Container Filesystem (GCFS).
        If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
        For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
        A `machine_type` that has more than 16 GiB of memory is also recommended.
        GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
        Structure is documented below.
        """
        guest_accelerators: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorArgsDict']]]]
        """
        List of the type and count of accelerator cards attached to the instance.
        Structure documented below.
        """
        gvnic: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigGvnicArgsDict']]
        """
        Google Virtual NIC (gVNIC) is a virtual network interface.
        Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
        gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
        GKE node version 1.15.11-gke.15 or later
        Structure is documented below.
        """
        host_maintenance_policy: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigHostMaintenancePolicyArgsDict']]
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        image_type: NotRequired[pulumi.Input[builtins.str]]
        """
        The image type to use for this node. Note that changing the image type
        will delete and recreate all nodes in the node pool.
        """
        kubelet_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigKubeletConfigArgsDict']]
        """
        Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Structure is documented below.

        ```
        kubelet_config {
        cpu_manager_policy   = "static"
        cpu_cfs_quota        = true
        cpu_cfs_quota_period = "100us"
        pod_pids_limit       = 1024
        }
        ```
        """
        labels: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
        reserved by Kubernetes Core components and cannot be specified.
        """
        linux_node_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigArgsDict']]
        """
        Parameters that can be configured on Linux nodes. Structure is documented below.
        """
        local_nvme_ssd_block_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgsDict']]
        """
        Parameters for the local NVMe SSDs. Structure is documented below.
        """
        local_ssd_count: NotRequired[pulumi.Input[builtins.int]]
        """
        The amount of local SSD disks that will be
        attached to each cluster node. Defaults to 0.
        """
        local_ssd_encryption_mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Possible Local SSD encryption modes:
        Accepted values are:
        * `STANDARD_ENCRYPTION`: The given node will be encrypted using keys managed by Google infrastructure and the keys wll be deleted when the node is deleted.
        * `EPHEMERAL_KEY_ENCRYPTION`: The given node will opt-in for using ephemeral key for encrypting Local SSDs. The Local SSDs will not be able to recover data in case of node crash.
        """
        logging_variant: NotRequired[pulumi.Input[builtins.str]]
        """
        Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        machine_type: NotRequired[pulumi.Input[builtins.str]]
        """
        The name of a Google Compute Engine machine type.
        Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
        [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        """
        max_run_duration: NotRequired[pulumi.Input[builtins.str]]
        """
        The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        """
        metadata: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        The metadata key/value pairs assigned to instances in
        the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
        `true` by the API; if `metadata` is set but that default value is not
        included, the provider will attempt to unset the value. To avoid this, set the
        value in your config.
        """
        min_cpu_platform: NotRequired[pulumi.Input[builtins.str]]
        """
        Minimum CPU platform to be used by this instance.
        The instance may be scheduled on the specified or newer CPU platform. Applicable
        values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
        [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
        for more information.
        """
        node_group: NotRequired[pulumi.Input[builtins.str]]
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        """
        oauth_scopes: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The set of Google API scopes to be made available
        on all of the node VMs under the "default" service account.
        Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        """
        preemptible: NotRequired[pulumi.Input[builtins.bool]]
        """
        A boolean that represents whether or not the underlying node VMs
        are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
        for more information. Defaults to false.
        """
        reservation_affinity: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigReservationAffinityArgsDict']]
        """
        The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        """
        resource_labels: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
        for how these labels are applied to clusters, node pools and nodes.
        """
        resource_manager_tags: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        sandbox_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigSandboxConfigArgsDict']]
        """
        Sandbox configuration for this node.
        """
        secondary_boot_disks: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSecondaryBootDiskArgsDict']]]]
        """
        Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        """
        service_account: NotRequired[pulumi.Input[builtins.str]]
        """
        The service account to be used by the Node VMs.
        If not specified, the "default" service account is used.
        """
        shielded_instance_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigShieldedInstanceConfigArgsDict']]
        """
        Shielded Instance options. Structure is documented below.
        """
        sole_tenant_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigArgsDict']]
        """
        Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
        """
        spot: NotRequired[pulumi.Input[builtins.bool]]
        """
        A boolean that represents whether the underlying node VMs are spot.
        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
        for more information. Defaults to false.
        """
        storage_pools: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        tags: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The list of instance tags applied to all nodes. Tags are used to identify
        valid sources or targets for network firewalls.
        """
        taints: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigTaintArgsDict']]]]
        """
        A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
        to apply to nodes. GKE's API can only set this field on cluster creation.
        However, GKE will add taints to your nodes if you enable certain features such
        as GPUs. If this field is set, any diffs on this field will cause the provider to
        recreate the underlying resource. Taint values can be updated safely in
        Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
        this field to manage taints. If you do, `lifecycle.ignore_changes` is
        recommended. Structure is documented below.
        """
        windows_node_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigWindowsNodeConfigArgsDict']]
        """
        Windows node configuration, currently supporting OSVersion [attribute](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/NodeConfig#osversion). The value must be one of [OS_VERSION_UNSPECIFIED, OS_VERSION_LTSC2019, OS_VERSION_LTSC2022]. For example:
        """
        workload_metadata_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigWorkloadMetadataConfigArgsDict']]
        """
        Metadata configuration to expose to workloads on the node pool.
        Structure is documented below.
        """
elif False:
    ClusterNodePoolNodeConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigArgs:
    def __init__(__self__, *,
                 advanced_machine_features: Optional[pulumi.Input['ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs']] = None,
                 boot_disk_kms_key: Optional[pulumi.Input[builtins.str]] = None,
                 confidential_nodes: Optional[pulumi.Input['ClusterNodePoolNodeConfigConfidentialNodesArgs']] = None,
                 containerd_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigArgs']] = None,
                 disk_size_gb: Optional[pulumi.Input[builtins.int]] = None,
                 disk_type: Optional[pulumi.Input[builtins.str]] = None,
                 effective_taints: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigEffectiveTaintArgs']]]] = None,
                 enable_confidential_storage: Optional[pulumi.Input[builtins.bool]] = None,
                 ephemeral_storage_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageConfigArgs']] = None,
                 ephemeral_storage_local_ssd_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs']] = None,
                 fast_socket: Optional[pulumi.Input['ClusterNodePoolNodeConfigFastSocketArgs']] = None,
                 flex_start: Optional[pulumi.Input[builtins.bool]] = None,
                 gcfs_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigGcfsConfigArgs']] = None,
                 guest_accelerators: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorArgs']]]] = None,
                 gvnic: Optional[pulumi.Input['ClusterNodePoolNodeConfigGvnicArgs']] = None,
                 host_maintenance_policy: Optional[pulumi.Input['ClusterNodePoolNodeConfigHostMaintenancePolicyArgs']] = None,
                 image_type: Optional[pulumi.Input[builtins.str]] = None,
                 kubelet_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigKubeletConfigArgs']] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 linux_node_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigArgs']] = None,
                 local_nvme_ssd_block_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs']] = None,
                 local_ssd_count: Optional[pulumi.Input[builtins.int]] = None,
                 local_ssd_encryption_mode: Optional[pulumi.Input[builtins.str]] = None,
                 logging_variant: Optional[pulumi.Input[builtins.str]] = None,
                 machine_type: Optional[pulumi.Input[builtins.str]] = None,
                 max_run_duration: Optional[pulumi.Input[builtins.str]] = None,
                 metadata: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 min_cpu_platform: Optional[pulumi.Input[builtins.str]] = None,
                 node_group: Optional[pulumi.Input[builtins.str]] = None,
                 oauth_scopes: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 preemptible: Optional[pulumi.Input[builtins.bool]] = None,
                 reservation_affinity: Optional[pulumi.Input['ClusterNodePoolNodeConfigReservationAffinityArgs']] = None,
                 resource_labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 resource_manager_tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 sandbox_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigSandboxConfigArgs']] = None,
                 secondary_boot_disks: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSecondaryBootDiskArgs']]]] = None,
                 service_account: Optional[pulumi.Input[builtins.str]] = None,
                 shielded_instance_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigShieldedInstanceConfigArgs']] = None,
                 sole_tenant_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigArgs']] = None,
                 spot: Optional[pulumi.Input[builtins.bool]] = None,
                 storage_pools: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 tags: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 taints: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigTaintArgs']]]] = None,
                 windows_node_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigWindowsNodeConfigArgs']] = None,
                 workload_metadata_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs']] = None):
        """
        :param pulumi.Input['ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs'] advanced_machine_features: Specifies options for controlling
               advanced machine features. Structure is documented below.
        :param pulumi.Input[builtins.str] boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        :param pulumi.Input['ClusterNodePoolNodeConfigConfidentialNodesArgs'] confidential_nodes: Configuration for Confidential Nodes feature. Structure is documented below.
        :param pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigArgs'] containerd_config: Parameters to customize containerd runtime. Structure is documented below.
        :param pulumi.Input[builtins.int] disk_size_gb: Size of the disk attached to each node, specified
               in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        :param pulumi.Input[builtins.str] disk_type: Type of the disk attached to each node
               (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigEffectiveTaintArgs']]] effective_taints: List of kubernetes taints applied to each node. Structure is documented above.
        :param pulumi.Input[builtins.bool] enable_confidential_storage: Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        :param pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageConfigArgs'] ephemeral_storage_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        :param pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs'] ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        :param pulumi.Input['ClusterNodePoolNodeConfigFastSocketArgs'] fast_socket: Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
               Node Pool must enable gvnic.
               GKE version 1.25.2-gke.1700 or later.
               Structure is documented below.
        :param pulumi.Input[builtins.bool] flex_start: ) Enables Flex Start provisioning model for the node pool.
        :param pulumi.Input['ClusterNodePoolNodeConfigGcfsConfigArgs'] gcfs_config: Parameters for the Google Container Filesystem (GCFS).
               If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
               For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
               A `machine_type` that has more than 16 GiB of memory is also recommended.
               GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
               Structure is documented below.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorArgs']]] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
               Structure documented below.
        :param pulumi.Input['ClusterNodePoolNodeConfigGvnicArgs'] gvnic: Google Virtual NIC (gVNIC) is a virtual network interface.
               Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
               gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
               GKE node version 1.15.11-gke.15 or later
               Structure is documented below.
        :param pulumi.Input['ClusterNodePoolNodeConfigHostMaintenancePolicyArgs'] host_maintenance_policy: The maintenance policy for the hosts on which the GKE VMs run on.
        :param pulumi.Input[builtins.str] image_type: The image type to use for this node. Note that changing the image type
               will delete and recreate all nodes in the node pool.
        :param pulumi.Input['ClusterNodePoolNodeConfigKubeletConfigArgs'] kubelet_config: Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Structure is documented below.
               
               ```
               kubelet_config {
               cpu_manager_policy   = "static"
               cpu_cfs_quota        = true
               cpu_cfs_quota_period = "100us"
               pod_pids_limit       = 1024
               }
               ```
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] labels: The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
               reserved by Kubernetes Core components and cannot be specified.
        :param pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigArgs'] linux_node_config: Parameters that can be configured on Linux nodes. Structure is documented below.
        :param pulumi.Input['ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs'] local_nvme_ssd_block_config: Parameters for the local NVMe SSDs. Structure is documented below.
        :param pulumi.Input[builtins.int] local_ssd_count: The amount of local SSD disks that will be
               attached to each cluster node. Defaults to 0.
        :param pulumi.Input[builtins.str] local_ssd_encryption_mode: Possible Local SSD encryption modes:
               Accepted values are:
               * `STANDARD_ENCRYPTION`: The given node will be encrypted using keys managed by Google infrastructure and the keys wll be deleted when the node is deleted.
               * `EPHEMERAL_KEY_ENCRYPTION`: The given node will opt-in for using ephemeral key for encrypting Local SSDs. The Local SSDs will not be able to recover data in case of node crash.
        :param pulumi.Input[builtins.str] logging_variant: Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        :param pulumi.Input[builtins.str] machine_type: The name of a Google Compute Engine machine type.
               Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
               [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        :param pulumi.Input[builtins.str] max_run_duration: The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] metadata: The metadata key/value pairs assigned to instances in
               the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
               `true` by the API; if `metadata` is set but that default value is not
               included, the provider will attempt to unset the value. To avoid this, set the
               value in your config.
        :param pulumi.Input[builtins.str] min_cpu_platform: Minimum CPU platform to be used by this instance.
               The instance may be scheduled on the specified or newer CPU platform. Applicable
               values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
               [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
               for more information.
        :param pulumi.Input[builtins.str] node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] oauth_scopes: The set of Google API scopes to be made available
               on all of the node VMs under the "default" service account.
               Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        :param pulumi.Input[builtins.bool] preemptible: A boolean that represents whether or not the underlying node VMs
               are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
               for more information. Defaults to false.
        :param pulumi.Input['ClusterNodePoolNodeConfigReservationAffinityArgs'] reservation_affinity: The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] resource_labels: The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
               for how these labels are applied to clusters, node pools and nodes.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] resource_manager_tags: A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        :param pulumi.Input['ClusterNodePoolNodeConfigSandboxConfigArgs'] sandbox_config: Sandbox configuration for this node.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSecondaryBootDiskArgs']]] secondary_boot_disks: Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        :param pulumi.Input[builtins.str] service_account: The service account to be used by the Node VMs.
               If not specified, the "default" service account is used.
        :param pulumi.Input['ClusterNodePoolNodeConfigShieldedInstanceConfigArgs'] shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigArgs'] sole_tenant_config: Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
        :param pulumi.Input[builtins.bool] spot: A boolean that represents whether the underlying node VMs are spot.
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
               for more information. Defaults to false.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] tags: The list of instance tags applied to all nodes. Tags are used to identify
               valid sources or targets for network firewalls.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigTaintArgs']]] taints: A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
               to apply to nodes. GKE's API can only set this field on cluster creation.
               However, GKE will add taints to your nodes if you enable certain features such
               as GPUs. If this field is set, any diffs on this field will cause the provider to
               recreate the underlying resource. Taint values can be updated safely in
               Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
               this field to manage taints. If you do, `lifecycle.ignore_changes` is
               recommended. Structure is documented below.
        :param pulumi.Input['ClusterNodePoolNodeConfigWindowsNodeConfigArgs'] windows_node_config: Windows node configuration, currently supporting OSVersion [attribute](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/NodeConfig#osversion). The value must be one of [OS_VERSION_UNSPECIFIED, OS_VERSION_LTSC2019, OS_VERSION_LTSC2022]. For example:
        :param pulumi.Input['ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs'] workload_metadata_config: Metadata configuration to expose to workloads on the node pool.
               Structure is documented below.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if containerd_config is not None:
            pulumi.set(__self__, "containerd_config", containerd_config)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if effective_taints is not None:
            pulumi.set(__self__, "effective_taints", effective_taints)
        if enable_confidential_storage is not None:
            pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if flex_start is not None:
            pulumi.set(__self__, "flex_start", flex_start)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if local_ssd_encryption_mode is not None:
            pulumi.set(__self__, "local_ssd_encryption_mode", local_ssd_encryption_mode)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if max_run_duration is not None:
            pulumi.set(__self__, "max_run_duration", max_run_duration)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if resource_manager_tags is not None:
            pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if secondary_boot_disks is not None:
            pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if storage_pools is not None:
            pulumi.set(__self__, "storage_pools", storage_pools)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if windows_node_config is not None:
            pulumi.set(__self__, "windows_node_config", windows_node_config)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs']]:
        """
        Specifies options for controlling
        advanced machine features. Structure is documented below.
        """
        return pulumi.get(self, "advanced_machine_features")

    @advanced_machine_features.setter
    def advanced_machine_features(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs']]):
        pulumi.set(self, "advanced_machine_features", value)

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @boot_disk_kms_key.setter
    def boot_disk_kms_key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "boot_disk_kms_key", value)

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigConfidentialNodesArgs']]:
        """
        Configuration for Confidential Nodes feature. Structure is documented below.
        """
        return pulumi.get(self, "confidential_nodes")

    @confidential_nodes.setter
    def confidential_nodes(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigConfidentialNodesArgs']]):
        pulumi.set(self, "confidential_nodes", value)

    @property
    @pulumi.getter(name="containerdConfig")
    def containerd_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigArgs']]:
        """
        Parameters to customize containerd runtime. Structure is documented below.
        """
        return pulumi.get(self, "containerd_config")

    @containerd_config.setter
    def containerd_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigArgs']]):
        pulumi.set(self, "containerd_config", value)

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @disk_size_gb.setter
    def disk_size_gb(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "disk_size_gb", value)

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        """
        return pulumi.get(self, "disk_type")

    @disk_type.setter
    def disk_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "disk_type", value)

    @property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigEffectiveTaintArgs']]]]:
        """
        List of kubernetes taints applied to each node. Structure is documented above.
        """
        return pulumi.get(self, "effective_taints")

    @effective_taints.setter
    def effective_taints(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigEffectiveTaintArgs']]]]):
        pulumi.set(self, "effective_taints", value)

    @property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Enabling Confidential Storage will create boot disk with confidential mode. It is disabled by default.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @enable_confidential_storage.setter
    def enable_confidential_storage(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_confidential_storage", value)

    @property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageConfigArgs']]:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @ephemeral_storage_config.setter
    def ephemeral_storage_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageConfigArgs']]):
        pulumi.set(self, "ephemeral_storage_config", value)

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs']]:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @ephemeral_storage_local_ssd_config.setter
    def ephemeral_storage_local_ssd_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs']]):
        pulumi.set(self, "ephemeral_storage_local_ssd_config", value)

    @property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigFastSocketArgs']]:
        """
        Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
        Node Pool must enable gvnic.
        GKE version 1.25.2-gke.1700 or later.
        Structure is documented below.
        """
        return pulumi.get(self, "fast_socket")

    @fast_socket.setter
    def fast_socket(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigFastSocketArgs']]):
        pulumi.set(self, "fast_socket", value)

    @property
    @pulumi.getter(name="flexStart")
    def flex_start(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        ) Enables Flex Start provisioning model for the node pool.
        """
        return pulumi.get(self, "flex_start")

    @flex_start.setter
    def flex_start(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "flex_start", value)

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigGcfsConfigArgs']]:
        """
        Parameters for the Google Container Filesystem (GCFS).
        If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
        For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
        A `machine_type` that has more than 16 GiB of memory is also recommended.
        GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
        Structure is documented below.
        """
        return pulumi.get(self, "gcfs_config")

    @gcfs_config.setter
    def gcfs_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigGcfsConfigArgs']]):
        pulumi.set(self, "gcfs_config", value)

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorArgs']]]]:
        """
        List of the type and count of accelerator cards attached to the instance.
        Structure documented below.
        """
        return pulumi.get(self, "guest_accelerators")

    @guest_accelerators.setter
    def guest_accelerators(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorArgs']]]]):
        pulumi.set(self, "guest_accelerators", value)

    @property
    @pulumi.getter
    def gvnic(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigGvnicArgs']]:
        """
        Google Virtual NIC (gVNIC) is a virtual network interface.
        Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
        gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
        GKE node version 1.15.11-gke.15 or later
        Structure is documented below.
        """
        return pulumi.get(self, "gvnic")

    @gvnic.setter
    def gvnic(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigGvnicArgs']]):
        pulumi.set(self, "gvnic", value)

    @property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigHostMaintenancePolicyArgs']]:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policy")

    @host_maintenance_policy.setter
    def host_maintenance_policy(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigHostMaintenancePolicyArgs']]):
        pulumi.set(self, "host_maintenance_policy", value)

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The image type to use for this node. Note that changing the image type
        will delete and recreate all nodes in the node pool.
        """
        return pulumi.get(self, "image_type")

    @image_type.setter
    def image_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "image_type", value)

    @property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigKubeletConfigArgs']]:
        """
        Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Structure is documented below.

        ```
        kubelet_config {
        cpu_manager_policy   = "static"
        cpu_cfs_quota        = true
        cpu_cfs_quota_period = "100us"
        pod_pids_limit       = 1024
        }
        ```
        """
        return pulumi.get(self, "kubelet_config")

    @kubelet_config.setter
    def kubelet_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigKubeletConfigArgs']]):
        pulumi.set(self, "kubelet_config", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
        reserved by Kubernetes Core components and cannot be specified.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigArgs']]:
        """
        Parameters that can be configured on Linux nodes. Structure is documented below.
        """
        return pulumi.get(self, "linux_node_config")

    @linux_node_config.setter
    def linux_node_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigArgs']]):
        pulumi.set(self, "linux_node_config", value)

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs']]:
        """
        Parameters for the local NVMe SSDs. Structure is documented below.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @local_nvme_ssd_block_config.setter
    def local_nvme_ssd_block_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs']]):
        pulumi.set(self, "local_nvme_ssd_block_config", value)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The amount of local SSD disks that will be
        attached to each cluster node. Defaults to 0.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "local_ssd_count", value)

    @property
    @pulumi.getter(name="localSsdEncryptionMode")
    def local_ssd_encryption_mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Possible Local SSD encryption modes:
        Accepted values are:
        * `STANDARD_ENCRYPTION`: The given node will be encrypted using keys managed by Google infrastructure and the keys wll be deleted when the node is deleted.
        * `EPHEMERAL_KEY_ENCRYPTION`: The given node will opt-in for using ephemeral key for encrypting Local SSDs. The Local SSDs will not be able to recover data in case of node crash.
        """
        return pulumi.get(self, "local_ssd_encryption_mode")

    @local_ssd_encryption_mode.setter
    def local_ssd_encryption_mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "local_ssd_encryption_mode", value)

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")

    @logging_variant.setter
    def logging_variant(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "logging_variant", value)

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of a Google Compute Engine machine type.
        Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
        [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        """
        return pulumi.get(self, "machine_type")

    @machine_type.setter
    def machine_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "machine_type", value)

    @property
    @pulumi.getter(name="maxRunDuration")
    def max_run_duration(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        """
        return pulumi.get(self, "max_run_duration")

    @max_run_duration.setter
    def max_run_duration(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "max_run_duration", value)

    @property
    @pulumi.getter
    def metadata(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The metadata key/value pairs assigned to instances in
        the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
        `true` by the API; if `metadata` is set but that default value is not
        included, the provider will attempt to unset the value. To avoid this, set the
        value in your config.
        """
        return pulumi.get(self, "metadata")

    @metadata.setter
    def metadata(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "metadata", value)

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Minimum CPU platform to be used by this instance.
        The instance may be scheduled on the specified or newer CPU platform. Applicable
        values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
        [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
        for more information.
        """
        return pulumi.get(self, "min_cpu_platform")

    @min_cpu_platform.setter
    def min_cpu_platform(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "min_cpu_platform", value)

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        """
        return pulumi.get(self, "node_group")

    @node_group.setter
    def node_group(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "node_group", value)

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The set of Google API scopes to be made available
        on all of the node VMs under the "default" service account.
        Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        """
        return pulumi.get(self, "oauth_scopes")

    @oauth_scopes.setter
    def oauth_scopes(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "oauth_scopes", value)

    @property
    @pulumi.getter
    def preemptible(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        A boolean that represents whether or not the underlying node VMs
        are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "preemptible")

    @preemptible.setter
    def preemptible(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "preemptible", value)

    @property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigReservationAffinityArgs']]:
        """
        The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        """
        return pulumi.get(self, "reservation_affinity")

    @reservation_affinity.setter
    def reservation_affinity(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigReservationAffinityArgs']]):
        pulumi.set(self, "reservation_affinity", value)

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
        for how these labels are applied to clusters, node pools and nodes.
        """
        return pulumi.get(self, "resource_labels")

    @resource_labels.setter
    def resource_labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "resource_labels", value)

    @property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        A map of resource manager tag keys and values to be attached to the nodes for managing Compute Engine firewalls using Network Firewall Policies. Tags must be according to specifications found [here](https://cloud.google.com/vpc/docs/tags-firewalls-overview#specifications). A maximum of 5 tag key-value pairs can be specified. Existing tags will be replaced with new values. Tags must be in one of the following formats ([KEY]=[VALUE]) 1. `tagKeys/{tag_key_id}=tagValues/{tag_value_id}` 2. `{org_id}/{tag_key_name}={tag_value_name}` 3. `{project_id}/{tag_key_name}={tag_value_name}`.
        """
        return pulumi.get(self, "resource_manager_tags")

    @resource_manager_tags.setter
    def resource_manager_tags(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "resource_manager_tags", value)

    @property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigSandboxConfigArgs']]:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_config")

    @sandbox_config.setter
    def sandbox_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigSandboxConfigArgs']]):
        pulumi.set(self, "sandbox_config", value)

    @property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSecondaryBootDiskArgs']]]]:
        """
        Parameters for secondary boot disks to preload container images and data on new nodes. Structure is documented below. `gcfs_config` must be `enabled=true` for this feature to work. `min_master_version` must also be set to use GKE 1.28.3-gke.106700 or later versions.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @secondary_boot_disks.setter
    def secondary_boot_disks(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSecondaryBootDiskArgs']]]]):
        pulumi.set(self, "secondary_boot_disks", value)

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The service account to be used by the Node VMs.
        If not specified, the "default" service account is used.
        """
        return pulumi.get(self, "service_account")

    @service_account.setter
    def service_account(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "service_account", value)

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigShieldedInstanceConfigArgs']]:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @shielded_instance_config.setter
    def shielded_instance_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigShieldedInstanceConfigArgs']]):
        pulumi.set(self, "shielded_instance_config", value)

    @property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigArgs']]:
        """
        Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
        """
        return pulumi.get(self, "sole_tenant_config")

    @sole_tenant_config.setter
    def sole_tenant_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigArgs']]):
        pulumi.set(self, "sole_tenant_config", value)

    @property
    @pulumi.getter
    def spot(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        A boolean that represents whether the underlying node VMs are spot.
        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "spot")

    @spot.setter
    def spot(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "spot", value)

    @property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @storage_pools.setter
    def storage_pools(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "storage_pools", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The list of instance tags applied to all nodes. Tags are used to identify
        valid sources or targets for network firewalls.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter
    def taints(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigTaintArgs']]]]:
        """
        A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
        to apply to nodes. GKE's API can only set this field on cluster creation.
        However, GKE will add taints to your nodes if you enable certain features such
        as GPUs. If this field is set, any diffs on this field will cause the provider to
        recreate the underlying resource. Taint values can be updated safely in
        Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
        this field to manage taints. If you do, `lifecycle.ignore_changes` is
        recommended. Structure is documented below.
        """
        return pulumi.get(self, "taints")

    @taints.setter
    def taints(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigTaintArgs']]]]):
        pulumi.set(self, "taints", value)

    @property
    @pulumi.getter(name="windowsNodeConfig")
    def windows_node_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigWindowsNodeConfigArgs']]:
        """
        Windows node configuration, currently supporting OSVersion [attribute](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/NodeConfig#osversion). The value must be one of [OS_VERSION_UNSPECIFIED, OS_VERSION_LTSC2019, OS_VERSION_LTSC2022]. For example:
        """
        return pulumi.get(self, "windows_node_config")

    @windows_node_config.setter
    def windows_node_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigWindowsNodeConfigArgs']]):
        pulumi.set(self, "windows_node_config", value)

    @property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs']]:
        """
        Metadata configuration to expose to workloads on the node pool.
        Structure is documented below.
        """
        return pulumi.get(self, "workload_metadata_config")

    @workload_metadata_config.setter
    def workload_metadata_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs']]):
        pulumi.set(self, "workload_metadata_config", value)


if not MYPY:
    class ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgsDict(TypedDict):
        threads_per_core: pulumi.Input[builtins.int]
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        enable_nested_virtualization: NotRequired[pulumi.Input[builtins.bool]]
        """
        Defines whether the instance should have nested virtualization enabled. Defaults to false.
        """
elif False:
    ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs:
    def __init__(__self__, *,
                 threads_per_core: pulumi.Input[builtins.int],
                 enable_nested_virtualization: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.int] threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        :param pulumi.Input[builtins.bool] enable_nested_virtualization: Defines whether the instance should have nested virtualization enabled. Defaults to false.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)
        if enable_nested_virtualization is not None:
            pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> pulumi.Input[builtins.int]:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")

    @threads_per_core.setter
    def threads_per_core(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "threads_per_core", value)

    @property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Defines whether the instance should have nested virtualization enabled. Defaults to false.
        """
        return pulumi.get(self, "enable_nested_virtualization")

    @enable_nested_virtualization.setter
    def enable_nested_virtualization(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_nested_virtualization", value)


if not MYPY:
    class ClusterNodePoolNodeConfigConfidentialNodesArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
elif False:
    ClusterNodePoolNodeConfigConfidentialNodesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigConfidentialNodesArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterNodePoolNodeConfigContainerdConfigArgsDict(TypedDict):
        private_registry_access_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgsDict']]
        """
        Configuration for private container registries. There are two fields in this config:
        """
elif False:
    ClusterNodePoolNodeConfigContainerdConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigContainerdConfigArgs:
    def __init__(__self__, *,
                 private_registry_access_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs']] = None):
        """
        :param pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs'] private_registry_access_config: Configuration for private container registries. There are two fields in this config:
        """
        if private_registry_access_config is not None:
            pulumi.set(__self__, "private_registry_access_config", private_registry_access_config)

    @property
    @pulumi.getter(name="privateRegistryAccessConfig")
    def private_registry_access_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs']]:
        """
        Configuration for private container registries. There are two fields in this config:
        """
        return pulumi.get(self, "private_registry_access_config")

    @private_registry_access_config.setter
    def private_registry_access_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs']]):
        pulumi.set(self, "private_registry_access_config", value)


if not MYPY:
    class ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Enables private registry config. If set to false, all other fields in this object must not be set.
        """
        certificate_authority_domain_configs: NotRequired[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict']]]]
        """
        List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
elif False:
    ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool],
                 certificate_authority_domain_configs: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]]] = None):
        """
        :param pulumi.Input[builtins.bool] enabled: Enables private registry config. If set to false, all other fields in this object must not be set.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]] certificate_authority_domain_configs: List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
        pulumi.set(__self__, "enabled", enabled)
        if certificate_authority_domain_configs is not None:
            pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Enables private registry config. If set to false, all other fields in this object must not be set.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]]]:
        """
        List of configuration objects for CA and domains. Each object identifies a certificate and its assigned domains. See [how to configure for private container registries](https://cloud.google.com/kubernetes-engine/docs/how-to/access-private-registries-private-certificates) for more detail. Example:
        """
        return pulumi.get(self, "certificate_authority_domain_configs")

    @certificate_authority_domain_configs.setter
    def certificate_authority_domain_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]]]):
        pulumi.set(self, "certificate_authority_domain_configs", value)


if not MYPY:
    class ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict(TypedDict):
        fqdns: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        gcp_secret_manager_certificate_config: pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict']
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
elif False:
    ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs:
    def __init__(__self__, *,
                 fqdns: pulumi.Input[Sequence[pulumi.Input[builtins.str]]],
                 gcp_secret_manager_certificate_config: pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs']):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs'] gcp_secret_manager_certificate_config: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_config", gcp_secret_manager_certificate_config)

    @property
    @pulumi.getter
    def fqdns(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @fqdns.setter
    def fqdns(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "fqdns", value)

    @property
    @pulumi.getter(name="gcpSecretManagerCertificateConfig")
    def gcp_secret_manager_certificate_config(self) -> pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs']:
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_config")

    @gcp_secret_manager_certificate_config.setter
    def gcp_secret_manager_certificate_config(self, value: pulumi.Input['ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs']):
        pulumi.set(self, "gcp_secret_manager_certificate_config", value)


if not MYPY:
    class ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict(TypedDict):
        secret_uri: pulumi.Input[builtins.str]
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
elif False:
    ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs:
    def __init__(__self__, *,
                 secret_uri: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> pulumi.Input[builtins.str]:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")

    @secret_uri.setter
    def secret_uri(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "secret_uri", value)


if not MYPY:
    class ClusterNodePoolNodeConfigEffectiveTaintArgsDict(TypedDict):
        effect: NotRequired[pulumi.Input[builtins.str]]
        """
        Effect for taint.
        """
        key: NotRequired[pulumi.Input[builtins.str]]
        """
        Key for taint.
        """
        value: NotRequired[pulumi.Input[builtins.str]]
        """
        Value for taint.
        """
elif False:
    ClusterNodePoolNodeConfigEffectiveTaintArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigEffectiveTaintArgs:
    def __init__(__self__, *,
                 effect: Optional[pulumi.Input[builtins.str]] = None,
                 key: Optional[pulumi.Input[builtins.str]] = None,
                 value: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] effect: Effect for taint.
        :param pulumi.Input[builtins.str] key: Key for taint.
        :param pulumi.Input[builtins.str] value: Value for taint.
        """
        if effect is not None:
            pulumi.set(__self__, "effect", effect)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @effect.setter
    def effect(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "effect", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "value", value)


if not MYPY:
    class ClusterNodePoolNodeConfigEphemeralStorageConfigArgsDict(TypedDict):
        local_ssd_count: pulumi.Input[builtins.int]
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
elif False:
    ClusterNodePoolNodeConfigEphemeralStorageConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigEphemeralStorageConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.int] local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[builtins.int]:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "local_ssd_count", value)


if not MYPY:
    class ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgsDict(TypedDict):
        local_ssd_count: pulumi.Input[builtins.int]
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        data_cache_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Number of raw-block local NVMe SSD disks to be attached to the node utilized for GKE Data Cache. If zero, then GKE Data Cache will not be enabled in the nodes.
        """
elif False:
    ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[builtins.int],
                 data_cache_count: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.int] local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        :param pulumi.Input[builtins.int] data_cache_count: Number of raw-block local NVMe SSD disks to be attached to the node utilized for GKE Data Cache. If zero, then GKE Data Cache will not be enabled in the nodes.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if data_cache_count is not None:
            pulumi.set(__self__, "data_cache_count", data_cache_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[builtins.int]:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "local_ssd_count", value)

    @property
    @pulumi.getter(name="dataCacheCount")
    def data_cache_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node utilized for GKE Data Cache. If zero, then GKE Data Cache will not be enabled in the nodes.
        """
        return pulumi.get(self, "data_cache_count")

    @data_cache_count.setter
    def data_cache_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "data_cache_count", value)


if not MYPY:
    class ClusterNodePoolNodeConfigFastSocketArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not the NCCL Fast Socket is enabled
        """
elif False:
    ClusterNodePoolNodeConfigFastSocketArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigFastSocketArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not the NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not the NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterNodePoolNodeConfigGcfsConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
elif False:
    ClusterNodePoolNodeConfigGcfsConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigGcfsConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterNodePoolNodeConfigGuestAcceleratorArgsDict(TypedDict):
        count: pulumi.Input[builtins.int]
        """
        The number of the guest accelerator cards exposed to this instance.
        """
        type: pulumi.Input[builtins.str]
        """
        The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        """
        gpu_driver_installation_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgsDict']]
        """
        Configuration for auto installation of GPU driver. Structure is documented below.
        """
        gpu_partition_size: NotRequired[pulumi.Input[builtins.str]]
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        """
        gpu_sharing_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgsDict']]
        """
        Configuration for GPU sharing. Structure is documented below.
        """
elif False:
    ClusterNodePoolNodeConfigGuestAcceleratorArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigGuestAcceleratorArgs:
    def __init__(__self__, *,
                 count: pulumi.Input[builtins.int],
                 type: pulumi.Input[builtins.str],
                 gpu_driver_installation_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']] = None,
                 gpu_partition_size: Optional[pulumi.Input[builtins.str]] = None,
                 gpu_sharing_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs']] = None):
        """
        :param pulumi.Input[builtins.int] count: The number of the guest accelerator cards exposed to this instance.
        :param pulumi.Input[builtins.str] type: The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        :param pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs'] gpu_driver_installation_config: Configuration for auto installation of GPU driver. Structure is documented below.
        :param pulumi.Input[builtins.str] gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        :param pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs'] gpu_sharing_config: Configuration for GPU sharing. Structure is documented below.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @property
    @pulumi.getter
    def count(self) -> pulumi.Input[builtins.int]:
        """
        The number of the guest accelerator cards exposed to this instance.
        """
        return pulumi.get(self, "count")

    @count.setter
    def count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "count", value)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input[builtins.str]:
        """
        The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']]:
        """
        Configuration for auto installation of GPU driver. Structure is documented below.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @gpu_driver_installation_config.setter
    def gpu_driver_installation_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']]):
        pulumi.set(self, "gpu_driver_installation_config", value)

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        """
        return pulumi.get(self, "gpu_partition_size")

    @gpu_partition_size.setter
    def gpu_partition_size(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "gpu_partition_size", value)

    @property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs']]:
        """
        Configuration for GPU sharing. Structure is documented below.
        """
        return pulumi.get(self, "gpu_sharing_config")

    @gpu_sharing_config.setter
    def gpu_sharing_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs']]):
        pulumi.set(self, "gpu_sharing_config", value)


if not MYPY:
    class ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgsDict(TypedDict):
        gpu_driver_version: pulumi.Input[builtins.str]
        """
        Mode for how the GPU driver is installed.
        Accepted values are:
        * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to install the "Default" GPU driver. Before GKE `1.30.1-gke.1156000`, the default value is to not install any GPU driver.
        * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
        * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
        * `"LATEST"`: "Latest" GPU driver in COS.
        """
elif False:
    ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs:
    def __init__(__self__, *,
                 gpu_driver_version: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] gpu_driver_version: Mode for how the GPU driver is installed.
               Accepted values are:
               * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to install the "Default" GPU driver. Before GKE `1.30.1-gke.1156000`, the default value is to not install any GPU driver.
               * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
               * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
               * `"LATEST"`: "Latest" GPU driver in COS.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> pulumi.Input[builtins.str]:
        """
        Mode for how the GPU driver is installed.
        Accepted values are:
        * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to install the "Default" GPU driver. Before GKE `1.30.1-gke.1156000`, the default value is to not install any GPU driver.
        * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
        * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
        * `"LATEST"`: "Latest" GPU driver in COS.
        """
        return pulumi.get(self, "gpu_driver_version")

    @gpu_driver_version.setter
    def gpu_driver_version(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "gpu_driver_version", value)


if not MYPY:
    class ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgsDict(TypedDict):
        gpu_sharing_strategy: pulumi.Input[builtins.str]
        """
        The type of GPU sharing strategy to enable on the GPU node.
        Accepted values are:
        * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        """
        max_shared_clients_per_gpu: pulumi.Input[builtins.int]
        """
        The maximum number of containers that can share a GPU.
        """
elif False:
    ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs:
    def __init__(__self__, *,
                 gpu_sharing_strategy: pulumi.Input[builtins.str],
                 max_shared_clients_per_gpu: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.str] gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node.
               Accepted values are:
               * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
               * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        :param pulumi.Input[builtins.int] max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> pulumi.Input[builtins.str]:
        """
        The type of GPU sharing strategy to enable on the GPU node.
        Accepted values are:
        * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        * `"MPS"`: Enable co-operative multi-process CUDA workloads to run concurrently on a single GPU device with [MPS](https://cloud.google.com/kubernetes-engine/docs/how-to/nvidia-mps-gpus)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @gpu_sharing_strategy.setter
    def gpu_sharing_strategy(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "gpu_sharing_strategy", value)

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> pulumi.Input[builtins.int]:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")

    @max_shared_clients_per_gpu.setter
    def max_shared_clients_per_gpu(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "max_shared_clients_per_gpu", value)


if not MYPY:
    class ClusterNodePoolNodeConfigGvnicArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
elif False:
    ClusterNodePoolNodeConfigGvnicArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigGvnicArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterNodePoolNodeConfigHostMaintenancePolicyArgsDict(TypedDict):
        maintenance_interval: pulumi.Input[builtins.str]
        """
        .
        """
elif False:
    ClusterNodePoolNodeConfigHostMaintenancePolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigHostMaintenancePolicyArgs:
    def __init__(__self__, *,
                 maintenance_interval: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> pulumi.Input[builtins.str]:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")

    @maintenance_interval.setter
    def maintenance_interval(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "maintenance_interval", value)


if not MYPY:
    class ClusterNodePoolNodeConfigKubeletConfigArgsDict(TypedDict):
        allowed_unsafe_sysctls: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods. The allowed sysctl groups are `kernel.shm*`, `kernel.msg*`, `kernel.sem`, `fs.mqueue.*`, and `net.*`.
        """
        container_log_max_files: NotRequired[pulumi.Input[builtins.int]]
        """
        Defines the maximum number of container log files that can be present for a container. The integer must be between 2 and 10, inclusive.
        """
        container_log_max_size: NotRequired[pulumi.Input[builtins.str]]
        """
        Defines the maximum size of the
        container log file before it is rotated. Specified as a positive number and a
        unit suffix, such as `"100Ki"`, `"10Mi"`. Valid units are "Ki", "Mi", "Gi".
        The value must be between `"10Mi"` and `"500Mi"`, inclusive. And the total container log size
        (`container_log_max_size` * `container_log_max_files`) cannot exceed 1% of the total storage of the node.
        """
        cpu_cfs_quota: NotRequired[pulumi.Input[builtins.bool]]
        """
        If true, enables CPU CFS quota enforcement for
        containers that specify CPU limits.
        """
        cpu_cfs_quota_period: NotRequired[pulumi.Input[builtins.str]]
        """
        The CPU CFS quota period value. Specified
        as a sequence of decimal numbers, each with optional fraction and a unit suffix,
        such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
        "h". The value must be a positive duration.
        """
        cpu_manager_policy: NotRequired[pulumi.Input[builtins.str]]
        """
        The CPU management policy on the node. See
        [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
        One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
        Prior to the 6.4.0 this field was marked as required. The workaround for the required field
        is setting the empty string `""`, which will function identically to not setting this field.
        """
        image_gc_high_threshold_percent: NotRequired[pulumi.Input[builtins.int]]
        """
        Defines the percent of disk usage after which image garbage collection is always run. The integer must be between 10 and 85, inclusive.
        """
        image_gc_low_threshold_percent: NotRequired[pulumi.Input[builtins.int]]
        """
        Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to. The integer must be between 10 and 85, inclusive.
        """
        image_maximum_gc_age: NotRequired[pulumi.Input[builtins.str]]
        """
        Defines the maximum age an image can be unused before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`, and `"2h45m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h". The value must be a positive duration.
        """
        image_minimum_gc_age: NotRequired[pulumi.Input[builtins.str]]
        """
        Defines the minimum age for an unused image before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`. The value cannot be greater than "2m".
        """
        insecure_kubelet_readonly_port_enabled: NotRequired[pulumi.Input[builtins.str]]
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        pod_pids_limit: NotRequired[pulumi.Input[builtins.int]]
        """
        Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
elif False:
    ClusterNodePoolNodeConfigKubeletConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigKubeletConfigArgs:
    def __init__(__self__, *,
                 allowed_unsafe_sysctls: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 container_log_max_files: Optional[pulumi.Input[builtins.int]] = None,
                 container_log_max_size: Optional[pulumi.Input[builtins.str]] = None,
                 cpu_cfs_quota: Optional[pulumi.Input[builtins.bool]] = None,
                 cpu_cfs_quota_period: Optional[pulumi.Input[builtins.str]] = None,
                 cpu_manager_policy: Optional[pulumi.Input[builtins.str]] = None,
                 image_gc_high_threshold_percent: Optional[pulumi.Input[builtins.int]] = None,
                 image_gc_low_threshold_percent: Optional[pulumi.Input[builtins.int]] = None,
                 image_maximum_gc_age: Optional[pulumi.Input[builtins.str]] = None,
                 image_minimum_gc_age: Optional[pulumi.Input[builtins.str]] = None,
                 insecure_kubelet_readonly_port_enabled: Optional[pulumi.Input[builtins.str]] = None,
                 pod_pids_limit: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] allowed_unsafe_sysctls: Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods. The allowed sysctl groups are `kernel.shm*`, `kernel.msg*`, `kernel.sem`, `fs.mqueue.*`, and `net.*`.
        :param pulumi.Input[builtins.int] container_log_max_files: Defines the maximum number of container log files that can be present for a container. The integer must be between 2 and 10, inclusive.
        :param pulumi.Input[builtins.str] container_log_max_size: Defines the maximum size of the
               container log file before it is rotated. Specified as a positive number and a
               unit suffix, such as `"100Ki"`, `"10Mi"`. Valid units are "Ki", "Mi", "Gi".
               The value must be between `"10Mi"` and `"500Mi"`, inclusive. And the total container log size
               (`container_log_max_size` * `container_log_max_files`) cannot exceed 1% of the total storage of the node.
        :param pulumi.Input[builtins.bool] cpu_cfs_quota: If true, enables CPU CFS quota enforcement for
               containers that specify CPU limits.
        :param pulumi.Input[builtins.str] cpu_cfs_quota_period: The CPU CFS quota period value. Specified
               as a sequence of decimal numbers, each with optional fraction and a unit suffix,
               such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
               "h". The value must be a positive duration.
        :param pulumi.Input[builtins.str] cpu_manager_policy: The CPU management policy on the node. See
               [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
               One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
               Prior to the 6.4.0 this field was marked as required. The workaround for the required field
               is setting the empty string `""`, which will function identically to not setting this field.
        :param pulumi.Input[builtins.int] image_gc_high_threshold_percent: Defines the percent of disk usage after which image garbage collection is always run. The integer must be between 10 and 85, inclusive.
        :param pulumi.Input[builtins.int] image_gc_low_threshold_percent: Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to. The integer must be between 10 and 85, inclusive.
        :param pulumi.Input[builtins.str] image_maximum_gc_age: Defines the maximum age an image can be unused before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`, and `"2h45m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h". The value must be a positive duration.
        :param pulumi.Input[builtins.str] image_minimum_gc_age: Defines the minimum age for an unused image before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`. The value cannot be greater than "2m".
        :param pulumi.Input[builtins.str] insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param pulumi.Input[builtins.int] pod_pids_limit: Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        if allowed_unsafe_sysctls is not None:
            pulumi.set(__self__, "allowed_unsafe_sysctls", allowed_unsafe_sysctls)
        if container_log_max_files is not None:
            pulumi.set(__self__, "container_log_max_files", container_log_max_files)
        if container_log_max_size is not None:
            pulumi.set(__self__, "container_log_max_size", container_log_max_size)
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if cpu_manager_policy is not None:
            pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if image_gc_high_threshold_percent is not None:
            pulumi.set(__self__, "image_gc_high_threshold_percent", image_gc_high_threshold_percent)
        if image_gc_low_threshold_percent is not None:
            pulumi.set(__self__, "image_gc_low_threshold_percent", image_gc_low_threshold_percent)
        if image_maximum_gc_age is not None:
            pulumi.set(__self__, "image_maximum_gc_age", image_maximum_gc_age)
        if image_minimum_gc_age is not None:
            pulumi.set(__self__, "image_minimum_gc_age", image_minimum_gc_age)
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="allowedUnsafeSysctls")
    def allowed_unsafe_sysctls(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods. The allowed sysctl groups are `kernel.shm*`, `kernel.msg*`, `kernel.sem`, `fs.mqueue.*`, and `net.*`.
        """
        return pulumi.get(self, "allowed_unsafe_sysctls")

    @allowed_unsafe_sysctls.setter
    def allowed_unsafe_sysctls(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "allowed_unsafe_sysctls", value)

    @property
    @pulumi.getter(name="containerLogMaxFiles")
    def container_log_max_files(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Defines the maximum number of container log files that can be present for a container. The integer must be between 2 and 10, inclusive.
        """
        return pulumi.get(self, "container_log_max_files")

    @container_log_max_files.setter
    def container_log_max_files(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "container_log_max_files", value)

    @property
    @pulumi.getter(name="containerLogMaxSize")
    def container_log_max_size(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Defines the maximum size of the
        container log file before it is rotated. Specified as a positive number and a
        unit suffix, such as `"100Ki"`, `"10Mi"`. Valid units are "Ki", "Mi", "Gi".
        The value must be between `"10Mi"` and `"500Mi"`, inclusive. And the total container log size
        (`container_log_max_size` * `container_log_max_files`) cannot exceed 1% of the total storage of the node.
        """
        return pulumi.get(self, "container_log_max_size")

    @container_log_max_size.setter
    def container_log_max_size(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "container_log_max_size", value)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        If true, enables CPU CFS quota enforcement for
        containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @cpu_cfs_quota.setter
    def cpu_cfs_quota(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "cpu_cfs_quota", value)

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The CPU CFS quota period value. Specified
        as a sequence of decimal numbers, each with optional fraction and a unit suffix,
        such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
        "h". The value must be a positive duration.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @cpu_cfs_quota_period.setter
    def cpu_cfs_quota_period(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cpu_cfs_quota_period", value)

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The CPU management policy on the node. See
        [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
        One of `"none"` or `"static"`. If unset (or set to the empty string `""`), the API will treat the field as if set to "none".
        Prior to the 6.4.0 this field was marked as required. The workaround for the required field
        is setting the empty string `""`, which will function identically to not setting this field.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @cpu_manager_policy.setter
    def cpu_manager_policy(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cpu_manager_policy", value)

    @property
    @pulumi.getter(name="imageGcHighThresholdPercent")
    def image_gc_high_threshold_percent(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Defines the percent of disk usage after which image garbage collection is always run. The integer must be between 10 and 85, inclusive.
        """
        return pulumi.get(self, "image_gc_high_threshold_percent")

    @image_gc_high_threshold_percent.setter
    def image_gc_high_threshold_percent(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "image_gc_high_threshold_percent", value)

    @property
    @pulumi.getter(name="imageGcLowThresholdPercent")
    def image_gc_low_threshold_percent(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to. The integer must be between 10 and 85, inclusive.
        """
        return pulumi.get(self, "image_gc_low_threshold_percent")

    @image_gc_low_threshold_percent.setter
    def image_gc_low_threshold_percent(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "image_gc_low_threshold_percent", value)

    @property
    @pulumi.getter(name="imageMaximumGcAge")
    def image_maximum_gc_age(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Defines the maximum age an image can be unused before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`, and `"2h45m"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m", "h". The value must be a positive duration.
        """
        return pulumi.get(self, "image_maximum_gc_age")

    @image_maximum_gc_age.setter
    def image_maximum_gc_age(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "image_maximum_gc_age", value)

    @property
    @pulumi.getter(name="imageMinimumGcAge")
    def image_minimum_gc_age(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Defines the minimum age for an unused image before it is garbage collected. Specified as a sequence of decimal numbers, each with optional fraction and a unit suffix, such as `"300s"`, `"1.5m"`. The value cannot be greater than "2m".
        """
        return pulumi.get(self, "image_minimum_gc_age")

    @image_minimum_gc_age.setter
    def image_minimum_gc_age(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "image_minimum_gc_age", value)

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @insecure_kubelet_readonly_port_enabled.setter
    def insecure_kubelet_readonly_port_enabled(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "insecure_kubelet_readonly_port_enabled", value)

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        return pulumi.get(self, "pod_pids_limit")

    @pod_pids_limit.setter
    def pod_pids_limit(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "pod_pids_limit", value)


if not MYPY:
    class ClusterNodePoolNodeConfigLinuxNodeConfigArgsDict(TypedDict):
        cgroup_mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Possible cgroup modes that can be used.
        Accepted values are:
        * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
        * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
        * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        """
        hugepages_config: NotRequired[pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgsDict']]
        """
        Amounts for 2M and 1G hugepages. Structure is documented below.
        """
        sysctls: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        The Linux kernel parameters to be applied to the nodes
        and all pods running on the nodes. Specified as a map from the key, such as
        `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Note that validations happen all server side. All attributes are optional.
        """
elif False:
    ClusterNodePoolNodeConfigLinuxNodeConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigLinuxNodeConfigArgs:
    def __init__(__self__, *,
                 cgroup_mode: Optional[pulumi.Input[builtins.str]] = None,
                 hugepages_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs']] = None,
                 sysctls: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[builtins.str] cgroup_mode: Possible cgroup modes that can be used.
               Accepted values are:
               * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
               * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
               * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        :param pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs'] hugepages_config: Amounts for 2M and 1G hugepages. Structure is documented below.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] sysctls: The Linux kernel parameters to be applied to the nodes
               and all pods running on the nodes. Specified as a map from the key, such as
               `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Note that validations happen all server side. All attributes are optional.
        """
        if cgroup_mode is not None:
            pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        if hugepages_config is not None:
            pulumi.set(__self__, "hugepages_config", hugepages_config)
        if sysctls is not None:
            pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Possible cgroup modes that can be used.
        Accepted values are:
        * `CGROUP_MODE_UNSPECIFIED`: CGROUP_MODE_UNSPECIFIED is when unspecified cgroup configuration is used. The default for the GKE node OS image will be used.
        * `CGROUP_MODE_V1`: CGROUP_MODE_V1 specifies to use cgroupv1 for the cgroup configuration on the node image.
        * `CGROUP_MODE_V2`: CGROUP_MODE_V2 specifies to use cgroupv2 for the cgroup configuration on the node image.
        """
        return pulumi.get(self, "cgroup_mode")

    @cgroup_mode.setter
    def cgroup_mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cgroup_mode", value)

    @property
    @pulumi.getter(name="hugepagesConfig")
    def hugepages_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs']]:
        """
        Amounts for 2M and 1G hugepages. Structure is documented below.
        """
        return pulumi.get(self, "hugepages_config")

    @hugepages_config.setter
    def hugepages_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs']]):
        pulumi.set(self, "hugepages_config", value)

    @property
    @pulumi.getter
    def sysctls(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The Linux kernel parameters to be applied to the nodes
        and all pods running on the nodes. Specified as a map from the key, such as
        `net.core.wmem_max`, to a string value. Currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Note that validations happen all server side. All attributes are optional.
        """
        return pulumi.get(self, "sysctls")

    @sysctls.setter
    def sysctls(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "sysctls", value)


if not MYPY:
    class ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgsDict(TypedDict):
        hugepage_size1g: NotRequired[pulumi.Input[builtins.int]]
        """
        Amount of 1G hugepages.
        """
        hugepage_size2m: NotRequired[pulumi.Input[builtins.int]]
        """
        Amount of 2M hugepages.
        """
elif False:
    ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs:
    def __init__(__self__, *,
                 hugepage_size1g: Optional[pulumi.Input[builtins.int]] = None,
                 hugepage_size2m: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.int] hugepage_size1g: Amount of 1G hugepages.
        :param pulumi.Input[builtins.int] hugepage_size2m: Amount of 2M hugepages.
        """
        if hugepage_size1g is not None:
            pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        if hugepage_size2m is not None:
            pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @hugepage_size1g.setter
    def hugepage_size1g(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "hugepage_size1g", value)

    @property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")

    @hugepage_size2m.setter
    def hugepage_size2m(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "hugepage_size2m", value)


if not MYPY:
    class ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgsDict(TypedDict):
        local_ssd_count: pulumi.Input[builtins.int]
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
        > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
elif False:
    ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.int] local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
               > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[builtins.int]:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
        > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "local_ssd_count", value)


if not MYPY:
    class ClusterNodePoolNodeConfigReservationAffinityArgsDict(TypedDict):
        consume_reservation_type: pulumi.Input[builtins.str]
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        key: NotRequired[pulumi.Input[builtins.str]]
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        values: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
elif False:
    ClusterNodePoolNodeConfigReservationAffinityArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigReservationAffinityArgs:
    def __init__(__self__, *,
                 consume_reservation_type: pulumi.Input[builtins.str],
                 key: Optional[pulumi.Input[builtins.str]] = None,
                 values: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[builtins.str] consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param pulumi.Input[builtins.str] key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> pulumi.Input[builtins.str]:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @consume_reservation_type.setter
    def consume_reservation_type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "consume_reservation_type", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "values", value)


if not MYPY:
    class ClusterNodePoolNodeConfigSandboxConfigArgsDict(TypedDict):
        sandbox_type: pulumi.Input[builtins.str]
        """
        Which sandbox to use for pods in the node pool.
        Accepted values are:

        * `"gvisor"`: Pods run within a gVisor sandbox.
        """
elif False:
    ClusterNodePoolNodeConfigSandboxConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigSandboxConfigArgs:
    def __init__(__self__, *,
                 sandbox_type: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] sandbox_type: Which sandbox to use for pods in the node pool.
               Accepted values are:
               
               * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> pulumi.Input[builtins.str]:
        """
        Which sandbox to use for pods in the node pool.
        Accepted values are:

        * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        return pulumi.get(self, "sandbox_type")

    @sandbox_type.setter
    def sandbox_type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "sandbox_type", value)


if not MYPY:
    class ClusterNodePoolNodeConfigSecondaryBootDiskArgsDict(TypedDict):
        disk_image: pulumi.Input[builtins.str]
        """
        Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        """
        mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
elif False:
    ClusterNodePoolNodeConfigSecondaryBootDiskArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigSecondaryBootDiskArgs:
    def __init__(__self__, *,
                 disk_image: pulumi.Input[builtins.str],
                 mode: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] disk_image: Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        :param pulumi.Input[builtins.str] mode: Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        if mode is not None:
            pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> pulumi.Input[builtins.str]:
        """
        Path to disk image to create the secondary boot disk from. After using the [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder), this argument should be `global/images/DISK_IMAGE_NAME`.
        """
        return pulumi.get(self, "disk_image")

    @disk_image.setter
    def disk_image(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "disk_image", value)

    @property
    @pulumi.getter
    def mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Mode for how the secondary boot disk is used. An example mode is `CONTAINER_IMAGE_CACHE`.
        """
        return pulumi.get(self, "mode")

    @mode.setter
    def mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "mode", value)


if not MYPY:
    class ClusterNodePoolNodeConfigShieldedInstanceConfigArgsDict(TypedDict):
        enable_integrity_monitoring: NotRequired[pulumi.Input[builtins.bool]]
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        enable_secure_boot: NotRequired[pulumi.Input[builtins.bool]]
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
elif False:
    ClusterNodePoolNodeConfigShieldedInstanceConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigShieldedInstanceConfigArgs:
    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[pulumi.Input[builtins.bool]] = None,
                 enable_secure_boot: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.bool] enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param pulumi.Input[builtins.bool] enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @enable_integrity_monitoring.setter
    def enable_integrity_monitoring(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_integrity_monitoring", value)

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")

    @enable_secure_boot.setter
    def enable_secure_boot(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_secure_boot", value)


if not MYPY:
    class ClusterNodePoolNodeConfigSoleTenantConfigArgsDict(TypedDict):
        node_affinities: pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgsDict']]]
        """
        .
        """
elif False:
    ClusterNodePoolNodeConfigSoleTenantConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigSoleTenantConfigArgs:
    def __init__(__self__, *,
                 node_affinities: pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]] node_affinities: .
        """
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]]:
        """
        .
        """
        return pulumi.get(self, "node_affinities")

    @node_affinities.setter
    def node_affinities(self, value: pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]]):
        pulumi.set(self, "node_affinities", value)


if not MYPY:
    class ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgsDict(TypedDict):
        key: pulumi.Input[builtins.str]
        """
        The default or custom node affinity label key name.
        """
        operator: pulumi.Input[builtins.str]
        """
        Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        """
        values: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        List of node affinity label values as strings.
        """
elif False:
    ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs:
    def __init__(__self__, *,
                 key: pulumi.Input[builtins.str],
                 operator: pulumi.Input[builtins.str],
                 values: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        """
        :param pulumi.Input[builtins.str] key: The default or custom node affinity label key name.
        :param pulumi.Input[builtins.str] operator: Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] values: List of node affinity label values as strings.
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[builtins.str]:
        """
        The default or custom node affinity label key name.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def operator(self) -> pulumi.Input[builtins.str]:
        """
        Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        """
        return pulumi.get(self, "operator")

    @operator.setter
    def operator(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "operator", value)

    @property
    @pulumi.getter
    def values(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        List of node affinity label values as strings.
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "values", value)


if not MYPY:
    class ClusterNodePoolNodeConfigTaintArgsDict(TypedDict):
        effect: pulumi.Input[builtins.str]
        """
        Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        """
        key: pulumi.Input[builtins.str]
        """
        Key for taint.
        """
        value: pulumi.Input[builtins.str]
        """
        Value for taint.
        """
elif False:
    ClusterNodePoolNodeConfigTaintArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigTaintArgs:
    def __init__(__self__, *,
                 effect: pulumi.Input[builtins.str],
                 key: pulumi.Input[builtins.str],
                 value: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] effect: Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        :param pulumi.Input[builtins.str] key: Key for taint.
        :param pulumi.Input[builtins.str] value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> pulumi.Input[builtins.str]:
        """
        Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        """
        return pulumi.get(self, "effect")

    @effect.setter
    def effect(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "effect", value)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[builtins.str]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[builtins.str]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "value", value)


if not MYPY:
    class ClusterNodePoolNodeConfigWindowsNodeConfigArgsDict(TypedDict):
        osversion: NotRequired[pulumi.Input[builtins.str]]
        """
        The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
elif False:
    ClusterNodePoolNodeConfigWindowsNodeConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigWindowsNodeConfigArgs:
    def __init__(__self__, *,
                 osversion: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] osversion: The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        if osversion is not None:
            pulumi.set(__self__, "osversion", osversion)

    @property
    @pulumi.getter
    def osversion(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        return pulumi.get(self, "osversion")

    @osversion.setter
    def osversion(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "osversion", value)


if not MYPY:
    class ClusterNodePoolNodeConfigWorkloadMetadataConfigArgsDict(TypedDict):
        mode: pulumi.Input[builtins.str]
        """
        How to expose the node metadata to the workload running on the node.
        Accepted values are:
        * UNSPECIFIED: Not Set
        * GCE_METADATA: Expose all Compute Engine metadata to pods.
        * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
elif False:
    ClusterNodePoolNodeConfigWorkloadMetadataConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs:
    def __init__(__self__, *,
                 mode: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] mode: How to expose the node metadata to the workload running on the node.
               Accepted values are:
               * UNSPECIFIED: Not Set
               * GCE_METADATA: Expose all Compute Engine metadata to pods.
               * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> pulumi.Input[builtins.str]:
        """
        How to expose the node metadata to the workload running on the node.
        Accepted values are:
        * UNSPECIFIED: Not Set
        * GCE_METADATA: Expose all Compute Engine metadata to pods.
        * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        return pulumi.get(self, "mode")

    @mode.setter
    def mode(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "mode", value)


if not MYPY:
    class ClusterNodePoolPlacementPolicyArgsDict(TypedDict):
        type: pulumi.Input[builtins.str]
        """
        Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
        `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        policy_name: NotRequired[pulumi.Input[builtins.str]]
        """
        If set, refers to the name of a custom resource policy supplied by the user. The resource policy must be in the same project and region as the node pool. If not found, InvalidArgument error is returned.
        """
        tpu_topology: NotRequired[pulumi.Input[builtins.str]]
        """
        TPU placement topology for pod slice node pool. https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies
        """
elif False:
    ClusterNodePoolPlacementPolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolPlacementPolicyArgs:
    def __init__(__self__, *,
                 type: pulumi.Input[builtins.str],
                 policy_name: Optional[pulumi.Input[builtins.str]] = None,
                 tpu_topology: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] type: Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
               `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        :param pulumi.Input[builtins.str] policy_name: If set, refers to the name of a custom resource policy supplied by the user. The resource policy must be in the same project and region as the node pool. If not found, InvalidArgument error is returned.
        :param pulumi.Input[builtins.str] tpu_topology: TPU placement topology for pod slice node pool. https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies
        """
        pulumi.set(__self__, "type", type)
        if policy_name is not None:
            pulumi.set(__self__, "policy_name", policy_name)
        if tpu_topology is not None:
            pulumi.set(__self__, "tpu_topology", tpu_topology)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input[builtins.str]:
        """
        Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
        `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        If set, refers to the name of a custom resource policy supplied by the user. The resource policy must be in the same project and region as the node pool. If not found, InvalidArgument error is returned.
        """
        return pulumi.get(self, "policy_name")

    @policy_name.setter
    def policy_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "policy_name", value)

    @property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        TPU placement topology for pod slice node pool. https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies
        """
        return pulumi.get(self, "tpu_topology")

    @tpu_topology.setter
    def tpu_topology(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "tpu_topology", value)


if not MYPY:
    class ClusterNodePoolQueuedProvisioningArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether nodes in this node pool are obtainable solely through the ProvisioningRequest API
        """
elif False:
    ClusterNodePoolQueuedProvisioningArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolQueuedProvisioningArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether nodes in this node pool are obtainable solely through the ProvisioningRequest API
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether nodes in this node pool are obtainable solely through the ProvisioningRequest API
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterNodePoolUpgradeSettingsArgsDict(TypedDict):
        blue_green_settings: NotRequired[pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgsDict']]
        """
        Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        max_surge: NotRequired[pulumi.Input[builtins.int]]
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        max_unavailable: NotRequired[pulumi.Input[builtins.int]]
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        strategy: NotRequired[pulumi.Input[builtins.str]]
        """
        Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
elif False:
    ClusterNodePoolUpgradeSettingsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolUpgradeSettingsArgs:
    def __init__(__self__, *,
                 blue_green_settings: Optional[pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs']] = None,
                 max_surge: Optional[pulumi.Input[builtins.int]] = None,
                 max_unavailable: Optional[pulumi.Input[builtins.int]] = None,
                 strategy: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs'] blue_green_settings: Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param pulumi.Input[builtins.int] max_surge: The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param pulumi.Input[builtins.int] max_unavailable: The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param pulumi.Input[builtins.str] strategy: Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional[pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs']]:
        """
        Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "blue_green_settings")

    @blue_green_settings.setter
    def blue_green_settings(self, value: Optional[pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs']]):
        pulumi.set(self, "blue_green_settings", value)

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_surge")

    @max_surge.setter
    def max_surge(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_surge", value)

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_unavailable")

    @max_unavailable.setter
    def max_unavailable(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_unavailable", value)

    @property
    @pulumi.getter
    def strategy(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        return pulumi.get(self, "strategy")

    @strategy.setter
    def strategy(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "strategy", value)


if not MYPY:
    class ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgsDict(TypedDict):
        standard_rollout_policy: pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgsDict']
        """
        Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        node_pool_soak_duration: NotRequired[pulumi.Input[builtins.str]]
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
elif False:
    ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs:
    def __init__(__self__, *,
                 standard_rollout_policy: pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs'],
                 node_pool_soak_duration: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs'] standard_rollout_policy: Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param pulumi.Input[builtins.str] node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)

    @property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']:
        """
        Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "standard_rollout_policy")

    @standard_rollout_policy.setter
    def standard_rollout_policy(self, value: pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']):
        pulumi.set(self, "standard_rollout_policy", value)

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @node_pool_soak_duration.setter
    def node_pool_soak_duration(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "node_pool_soak_duration", value)


if not MYPY:
    class ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgsDict(TypedDict):
        batch_node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        """
        batch_percentage: NotRequired[pulumi.Input[builtins.float]]
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        """
        batch_soak_duration: NotRequired[pulumi.Input[builtins.str]]
        """
        Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
elif False:
    ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs:
    def __init__(__self__, *,
                 batch_node_count: Optional[pulumi.Input[builtins.int]] = None,
                 batch_percentage: Optional[pulumi.Input[builtins.float]] = None,
                 batch_soak_duration: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.int] batch_node_count: Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        :param pulumi.Input[builtins.float] batch_percentage: Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        :param pulumi.Input[builtins.str] batch_soak_duration: Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_node_count")

    @batch_node_count.setter
    def batch_node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "batch_node_count", value)

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[pulumi.Input[builtins.float]]:
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_percentage")

    @batch_percentage.setter
    def batch_percentage(self, value: Optional[pulumi.Input[builtins.float]]):
        pulumi.set(self, "batch_percentage", value)

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        return pulumi.get(self, "batch_soak_duration")

    @batch_soak_duration.setter
    def batch_soak_duration(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "batch_soak_duration", value)


if not MYPY:
    class ClusterNotificationConfigArgsDict(TypedDict):
        pubsub: pulumi.Input['ClusterNotificationConfigPubsubArgsDict']
        """
        The pubsub config for the cluster's upgrade notifications.
        """
elif False:
    ClusterNotificationConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNotificationConfigArgs:
    def __init__(__self__, *,
                 pubsub: pulumi.Input['ClusterNotificationConfigPubsubArgs']):
        """
        :param pulumi.Input['ClusterNotificationConfigPubsubArgs'] pubsub: The pubsub config for the cluster's upgrade notifications.
        """
        pulumi.set(__self__, "pubsub", pubsub)

    @property
    @pulumi.getter
    def pubsub(self) -> pulumi.Input['ClusterNotificationConfigPubsubArgs']:
        """
        The pubsub config for the cluster's upgrade notifications.
        """
        return pulumi.get(self, "pubsub")

    @pubsub.setter
    def pubsub(self, value: pulumi.Input['ClusterNotificationConfigPubsubArgs']):
        pulumi.set(self, "pubsub", value)


if not MYPY:
    class ClusterNotificationConfigPubsubArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not the notification config is enabled
        """
        filter: NotRequired[pulumi.Input['ClusterNotificationConfigPubsubFilterArgsDict']]
        """
        Choose what type of notifications you want to receive. If no filters are applied, you'll receive all notification types. Structure is documented below.
        """
        topic: NotRequired[pulumi.Input[builtins.str]]
        """
        The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: `projects/{project}/topics/{topic}`.
        """
elif False:
    ClusterNotificationConfigPubsubArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNotificationConfigPubsubArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool],
                 filter: Optional[pulumi.Input['ClusterNotificationConfigPubsubFilterArgs']] = None,
                 topic: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not the notification config is enabled
        :param pulumi.Input['ClusterNotificationConfigPubsubFilterArgs'] filter: Choose what type of notifications you want to receive. If no filters are applied, you'll receive all notification types. Structure is documented below.
        :param pulumi.Input[builtins.str] topic: The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: `projects/{project}/topics/{topic}`.
        """
        pulumi.set(__self__, "enabled", enabled)
        if filter is not None:
            pulumi.set(__self__, "filter", filter)
        if topic is not None:
            pulumi.set(__self__, "topic", topic)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not the notification config is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter
    def filter(self) -> Optional[pulumi.Input['ClusterNotificationConfigPubsubFilterArgs']]:
        """
        Choose what type of notifications you want to receive. If no filters are applied, you'll receive all notification types. Structure is documented below.
        """
        return pulumi.get(self, "filter")

    @filter.setter
    def filter(self, value: Optional[pulumi.Input['ClusterNotificationConfigPubsubFilterArgs']]):
        pulumi.set(self, "filter", value)

    @property
    @pulumi.getter
    def topic(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: `projects/{project}/topics/{topic}`.
        """
        return pulumi.get(self, "topic")

    @topic.setter
    def topic(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "topic", value)


if not MYPY:
    class ClusterNotificationConfigPubsubFilterArgsDict(TypedDict):
        event_types: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        Can be used to filter what notifications are sent. Accepted values are `UPGRADE_AVAILABLE_EVENT`, `UPGRADE_EVENT`, `SECURITY_BULLETIN_EVENT` and `UPGRADE_INFO_EVENT`. See [Filtering notifications](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-notifications#filtering) for more details.
        """
elif False:
    ClusterNotificationConfigPubsubFilterArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterNotificationConfigPubsubFilterArgs:
    def __init__(__self__, *,
                 event_types: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] event_types: Can be used to filter what notifications are sent. Accepted values are `UPGRADE_AVAILABLE_EVENT`, `UPGRADE_EVENT`, `SECURITY_BULLETIN_EVENT` and `UPGRADE_INFO_EVENT`. See [Filtering notifications](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-notifications#filtering) for more details.
        """
        pulumi.set(__self__, "event_types", event_types)

    @property
    @pulumi.getter(name="eventTypes")
    def event_types(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        Can be used to filter what notifications are sent. Accepted values are `UPGRADE_AVAILABLE_EVENT`, `UPGRADE_EVENT`, `SECURITY_BULLETIN_EVENT` and `UPGRADE_INFO_EVENT`. See [Filtering notifications](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-notifications#filtering) for more details.
        """
        return pulumi.get(self, "event_types")

    @event_types.setter
    def event_types(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "event_types", value)


if not MYPY:
    class ClusterPodAutoscalingArgsDict(TypedDict):
        hpa_profile: pulumi.Input[builtins.str]
        """
        Enable the Horizontal Pod Autoscaling profile for this cluster.
        Acceptable values are:
        * `"NONE"`: Customers explicitly opt-out of HPA profiles.
        * `"PERFORMANCE"`: PERFORMANCE is used when customers opt-in to the performance HPA profile. In this profile we support a higher number of HPAs per cluster and faster metrics collection for workload autoscaling.
        See [HPAProfile](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#hpaprofile) for more details.
        """
elif False:
    ClusterPodAutoscalingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterPodAutoscalingArgs:
    def __init__(__self__, *,
                 hpa_profile: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] hpa_profile: Enable the Horizontal Pod Autoscaling profile for this cluster.
               Acceptable values are:
               * `"NONE"`: Customers explicitly opt-out of HPA profiles.
               * `"PERFORMANCE"`: PERFORMANCE is used when customers opt-in to the performance HPA profile. In this profile we support a higher number of HPAs per cluster and faster metrics collection for workload autoscaling.
               See [HPAProfile](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#hpaprofile) for more details.
        """
        pulumi.set(__self__, "hpa_profile", hpa_profile)

    @property
    @pulumi.getter(name="hpaProfile")
    def hpa_profile(self) -> pulumi.Input[builtins.str]:
        """
        Enable the Horizontal Pod Autoscaling profile for this cluster.
        Acceptable values are:
        * `"NONE"`: Customers explicitly opt-out of HPA profiles.
        * `"PERFORMANCE"`: PERFORMANCE is used when customers opt-in to the performance HPA profile. In this profile we support a higher number of HPAs per cluster and faster metrics collection for workload autoscaling.
        See [HPAProfile](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#hpaprofile) for more details.
        """
        return pulumi.get(self, "hpa_profile")

    @hpa_profile.setter
    def hpa_profile(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "hpa_profile", value)


if not MYPY:
    class ClusterPodSecurityPolicyConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Enable the PodSecurityPolicy controller for this cluster.
        If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
elif False:
    ClusterPodSecurityPolicyConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterPodSecurityPolicyConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Enable the PodSecurityPolicy controller for this cluster.
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Enable the PodSecurityPolicy controller for this cluster.
        If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterPrivateClusterConfigArgsDict(TypedDict):
        enable_private_endpoint: NotRequired[pulumi.Input[builtins.bool]]
        """
        When `true`, the cluster's private
        endpoint is used as the cluster endpoint and access through the public endpoint
        is disabled. When `false`, either endpoint can be used. This field only applies
        to private clusters, when `enable_private_nodes` is `true`.
        """
        enable_private_nodes: NotRequired[pulumi.Input[builtins.bool]]
        """
        Enables the private cluster feature,
        creating a private endpoint on the cluster. In a private cluster, nodes only
        have RFC 1918 private addresses and communicate with the master's private
        endpoint via private networking.
        """
        master_global_access_config: NotRequired[pulumi.Input['ClusterPrivateClusterConfigMasterGlobalAccessConfigArgsDict']]
        """
        Controls cluster master global
        access settings. If unset, the provider will no longer manage this field and will
        not modify the previously-set value. Structure is documented below.
        """
        master_ipv4_cidr_block: NotRequired[pulumi.Input[builtins.str]]
        """
        The IP range in CIDR notation to use for
        the hosted master network. This range will be used for assigning private IP
        addresses to the cluster master(s) and the ILB VIP. This range must not overlap
        with any other ranges in use within the cluster's network, and it must be a /28
        subnet. See [Private Cluster Limitations](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#req_res_lim)
        for more details. This field only applies to private clusters, when
        `enable_private_nodes` is `true`.
        """
        peering_name: NotRequired[pulumi.Input[builtins.str]]
        """
        The name of the peering between this cluster and the Google owned VPC.
        """
        private_endpoint: NotRequired[pulumi.Input[builtins.str]]
        """
        The internal IP address of this cluster's master endpoint.
        """
        private_endpoint_subnetwork: NotRequired[pulumi.Input[builtins.str]]
        """
        Subnetwork in cluster's network where master's endpoint will be provisioned.
        """
        public_endpoint: NotRequired[pulumi.Input[builtins.str]]
        """
        The external IP address of this cluster's master endpoint.

        !> The Google provider is unable to validate certain configurations of
        `private_cluster_config` when `enable_private_nodes` is `false`. It's
        recommended that you omit the block entirely if the field is not set to `true`.
        """
elif False:
    ClusterPrivateClusterConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterPrivateClusterConfigArgs:
    def __init__(__self__, *,
                 enable_private_endpoint: Optional[pulumi.Input[builtins.bool]] = None,
                 enable_private_nodes: Optional[pulumi.Input[builtins.bool]] = None,
                 master_global_access_config: Optional[pulumi.Input['ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs']] = None,
                 master_ipv4_cidr_block: Optional[pulumi.Input[builtins.str]] = None,
                 peering_name: Optional[pulumi.Input[builtins.str]] = None,
                 private_endpoint: Optional[pulumi.Input[builtins.str]] = None,
                 private_endpoint_subnetwork: Optional[pulumi.Input[builtins.str]] = None,
                 public_endpoint: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.bool] enable_private_endpoint: When `true`, the cluster's private
               endpoint is used as the cluster endpoint and access through the public endpoint
               is disabled. When `false`, either endpoint can be used. This field only applies
               to private clusters, when `enable_private_nodes` is `true`.
        :param pulumi.Input[builtins.bool] enable_private_nodes: Enables the private cluster feature,
               creating a private endpoint on the cluster. In a private cluster, nodes only
               have RFC 1918 private addresses and communicate with the master's private
               endpoint via private networking.
        :param pulumi.Input['ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs'] master_global_access_config: Controls cluster master global
               access settings. If unset, the provider will no longer manage this field and will
               not modify the previously-set value. Structure is documented below.
        :param pulumi.Input[builtins.str] master_ipv4_cidr_block: The IP range in CIDR notation to use for
               the hosted master network. This range will be used for assigning private IP
               addresses to the cluster master(s) and the ILB VIP. This range must not overlap
               with any other ranges in use within the cluster's network, and it must be a /28
               subnet. See [Private Cluster Limitations](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#req_res_lim)
               for more details. This field only applies to private clusters, when
               `enable_private_nodes` is `true`.
        :param pulumi.Input[builtins.str] peering_name: The name of the peering between this cluster and the Google owned VPC.
        :param pulumi.Input[builtins.str] private_endpoint: The internal IP address of this cluster's master endpoint.
        :param pulumi.Input[builtins.str] private_endpoint_subnetwork: Subnetwork in cluster's network where master's endpoint will be provisioned.
        :param pulumi.Input[builtins.str] public_endpoint: The external IP address of this cluster's master endpoint.
               
               !> The Google provider is unable to validate certain configurations of
               `private_cluster_config` when `enable_private_nodes` is `false`. It's
               recommended that you omit the block entirely if the field is not set to `true`.
        """
        if enable_private_endpoint is not None:
            pulumi.set(__self__, "enable_private_endpoint", enable_private_endpoint)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if master_global_access_config is not None:
            pulumi.set(__self__, "master_global_access_config", master_global_access_config)
        if master_ipv4_cidr_block is not None:
            pulumi.set(__self__, "master_ipv4_cidr_block", master_ipv4_cidr_block)
        if peering_name is not None:
            pulumi.set(__self__, "peering_name", peering_name)
        if private_endpoint is not None:
            pulumi.set(__self__, "private_endpoint", private_endpoint)
        if private_endpoint_subnetwork is not None:
            pulumi.set(__self__, "private_endpoint_subnetwork", private_endpoint_subnetwork)
        if public_endpoint is not None:
            pulumi.set(__self__, "public_endpoint", public_endpoint)

    @property
    @pulumi.getter(name="enablePrivateEndpoint")
    def enable_private_endpoint(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        When `true`, the cluster's private
        endpoint is used as the cluster endpoint and access through the public endpoint
        is disabled. When `false`, either endpoint can be used. This field only applies
        to private clusters, when `enable_private_nodes` is `true`.
        """
        return pulumi.get(self, "enable_private_endpoint")

    @enable_private_endpoint.setter
    def enable_private_endpoint(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_private_endpoint", value)

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Enables the private cluster feature,
        creating a private endpoint on the cluster. In a private cluster, nodes only
        have RFC 1918 private addresses and communicate with the master's private
        endpoint via private networking.
        """
        return pulumi.get(self, "enable_private_nodes")

    @enable_private_nodes.setter
    def enable_private_nodes(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_private_nodes", value)

    @property
    @pulumi.getter(name="masterGlobalAccessConfig")
    def master_global_access_config(self) -> Optional[pulumi.Input['ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs']]:
        """
        Controls cluster master global
        access settings. If unset, the provider will no longer manage this field and will
        not modify the previously-set value. Structure is documented below.
        """
        return pulumi.get(self, "master_global_access_config")

    @master_global_access_config.setter
    def master_global_access_config(self, value: Optional[pulumi.Input['ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs']]):
        pulumi.set(self, "master_global_access_config", value)

    @property
    @pulumi.getter(name="masterIpv4CidrBlock")
    def master_ipv4_cidr_block(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The IP range in CIDR notation to use for
        the hosted master network. This range will be used for assigning private IP
        addresses to the cluster master(s) and the ILB VIP. This range must not overlap
        with any other ranges in use within the cluster's network, and it must be a /28
        subnet. See [Private Cluster Limitations](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#req_res_lim)
        for more details. This field only applies to private clusters, when
        `enable_private_nodes` is `true`.
        """
        return pulumi.get(self, "master_ipv4_cidr_block")

    @master_ipv4_cidr_block.setter
    def master_ipv4_cidr_block(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "master_ipv4_cidr_block", value)

    @property
    @pulumi.getter(name="peeringName")
    def peering_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of the peering between this cluster and the Google owned VPC.
        """
        return pulumi.get(self, "peering_name")

    @peering_name.setter
    def peering_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "peering_name", value)

    @property
    @pulumi.getter(name="privateEndpoint")
    def private_endpoint(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The internal IP address of this cluster's master endpoint.
        """
        return pulumi.get(self, "private_endpoint")

    @private_endpoint.setter
    def private_endpoint(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "private_endpoint", value)

    @property
    @pulumi.getter(name="privateEndpointSubnetwork")
    def private_endpoint_subnetwork(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Subnetwork in cluster's network where master's endpoint will be provisioned.
        """
        return pulumi.get(self, "private_endpoint_subnetwork")

    @private_endpoint_subnetwork.setter
    def private_endpoint_subnetwork(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "private_endpoint_subnetwork", value)

    @property
    @pulumi.getter(name="publicEndpoint")
    def public_endpoint(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The external IP address of this cluster's master endpoint.

        !> The Google provider is unable to validate certain configurations of
        `private_cluster_config` when `enable_private_nodes` is `false`. It's
        recommended that you omit the block entirely if the field is not set to `true`.
        """
        return pulumi.get(self, "public_endpoint")

    @public_endpoint.setter
    def public_endpoint(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "public_endpoint", value)


if not MYPY:
    class ClusterPrivateClusterConfigMasterGlobalAccessConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether the cluster master is accessible globally or
        not.
        """
elif False:
    ClusterPrivateClusterConfigMasterGlobalAccessConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether the cluster master is accessible globally or
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether the cluster master is accessible globally or
        not.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterProtectConfigArgsDict(TypedDict):
        workload_config: NotRequired[pulumi.Input['ClusterProtectConfigWorkloadConfigArgsDict']]
        """
        WorkloadConfig defines which actions are enabled for a cluster's workload configurations. Structure is documented below
        """
        workload_vulnerability_mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
elif False:
    ClusterProtectConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterProtectConfigArgs:
    def __init__(__self__, *,
                 workload_config: Optional[pulumi.Input['ClusterProtectConfigWorkloadConfigArgs']] = None,
                 workload_vulnerability_mode: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input['ClusterProtectConfigWorkloadConfigArgs'] workload_config: WorkloadConfig defines which actions are enabled for a cluster's workload configurations. Structure is documented below
        :param pulumi.Input[builtins.str] workload_vulnerability_mode: Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        if workload_config is not None:
            pulumi.set(__self__, "workload_config", workload_config)
        if workload_vulnerability_mode is not None:
            pulumi.set(__self__, "workload_vulnerability_mode", workload_vulnerability_mode)

    @property
    @pulumi.getter(name="workloadConfig")
    def workload_config(self) -> Optional[pulumi.Input['ClusterProtectConfigWorkloadConfigArgs']]:
        """
        WorkloadConfig defines which actions are enabled for a cluster's workload configurations. Structure is documented below
        """
        return pulumi.get(self, "workload_config")

    @workload_config.setter
    def workload_config(self, value: Optional[pulumi.Input['ClusterProtectConfigWorkloadConfigArgs']]):
        pulumi.set(self, "workload_config", value)

    @property
    @pulumi.getter(name="workloadVulnerabilityMode")
    def workload_vulnerability_mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "workload_vulnerability_mode")

    @workload_vulnerability_mode.setter
    def workload_vulnerability_mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "workload_vulnerability_mode", value)


if not MYPY:
    class ClusterProtectConfigWorkloadConfigArgsDict(TypedDict):
        audit_mode: pulumi.Input[builtins.str]
        """
        Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
elif False:
    ClusterProtectConfigWorkloadConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterProtectConfigWorkloadConfigArgs:
    def __init__(__self__, *,
                 audit_mode: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] audit_mode: Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        pulumi.set(__self__, "audit_mode", audit_mode)

    @property
    @pulumi.getter(name="auditMode")
    def audit_mode(self) -> pulumi.Input[builtins.str]:
        """
        Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "audit_mode")

    @audit_mode.setter
    def audit_mode(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "audit_mode", value)


if not MYPY:
    class ClusterReleaseChannelArgsDict(TypedDict):
        channel: pulumi.Input[builtins.str]
        """
        The selected release channel.
        Accepted values are:
        * UNSPECIFIED: Not set.
        * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
        * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
        * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
        * EXTENDED: GKE provides extended support for Kubernetes minor versions through the Extended channel. With this channel, you can stay on a minor version for up to 24 months.
        """
elif False:
    ClusterReleaseChannelArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterReleaseChannelArgs:
    def __init__(__self__, *,
                 channel: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] channel: The selected release channel.
               Accepted values are:
               * UNSPECIFIED: Not set.
               * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
               * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
               * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
               * EXTENDED: GKE provides extended support for Kubernetes minor versions through the Extended channel. With this channel, you can stay on a minor version for up to 24 months.
        """
        pulumi.set(__self__, "channel", channel)

    @property
    @pulumi.getter
    def channel(self) -> pulumi.Input[builtins.str]:
        """
        The selected release channel.
        Accepted values are:
        * UNSPECIFIED: Not set.
        * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
        * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
        * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
        * EXTENDED: GKE provides extended support for Kubernetes minor versions through the Extended channel. With this channel, you can stay on a minor version for up to 24 months.
        """
        return pulumi.get(self, "channel")

    @channel.setter
    def channel(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "channel", value)


if not MYPY:
    class ClusterResourceUsageExportConfigArgsDict(TypedDict):
        bigquery_destination: pulumi.Input['ClusterResourceUsageExportConfigBigqueryDestinationArgsDict']
        """
        Parameters for using BigQuery as the destination of resource usage export.

        * `bigquery_destination.dataset_id` (Required) - The ID of a BigQuery Dataset. For Example:
        """
        enable_network_egress_metering: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created
        in the cluster to meter network egress traffic.
        """
        enable_resource_consumption_metering: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether to enable resource
        consumption metering on this cluster. When enabled, a table will be created in
        the resource export BigQuery dataset to store resource consumption data. The
        resulting table can be joined with the resource usage table or with BigQuery
        billing export. Defaults to `true`.
        """
elif False:
    ClusterResourceUsageExportConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterResourceUsageExportConfigArgs:
    def __init__(__self__, *,
                 bigquery_destination: pulumi.Input['ClusterResourceUsageExportConfigBigqueryDestinationArgs'],
                 enable_network_egress_metering: Optional[pulumi.Input[builtins.bool]] = None,
                 enable_resource_consumption_metering: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input['ClusterResourceUsageExportConfigBigqueryDestinationArgs'] bigquery_destination: Parameters for using BigQuery as the destination of resource usage export.
               
               * `bigquery_destination.dataset_id` (Required) - The ID of a BigQuery Dataset. For Example:
        :param pulumi.Input[builtins.bool] enable_network_egress_metering: Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created
               in the cluster to meter network egress traffic.
        :param pulumi.Input[builtins.bool] enable_resource_consumption_metering: Whether to enable resource
               consumption metering on this cluster. When enabled, a table will be created in
               the resource export BigQuery dataset to store resource consumption data. The
               resulting table can be joined with the resource usage table or with BigQuery
               billing export. Defaults to `true`.
        """
        pulumi.set(__self__, "bigquery_destination", bigquery_destination)
        if enable_network_egress_metering is not None:
            pulumi.set(__self__, "enable_network_egress_metering", enable_network_egress_metering)
        if enable_resource_consumption_metering is not None:
            pulumi.set(__self__, "enable_resource_consumption_metering", enable_resource_consumption_metering)

    @property
    @pulumi.getter(name="bigqueryDestination")
    def bigquery_destination(self) -> pulumi.Input['ClusterResourceUsageExportConfigBigqueryDestinationArgs']:
        """
        Parameters for using BigQuery as the destination of resource usage export.

        * `bigquery_destination.dataset_id` (Required) - The ID of a BigQuery Dataset. For Example:
        """
        return pulumi.get(self, "bigquery_destination")

    @bigquery_destination.setter
    def bigquery_destination(self, value: pulumi.Input['ClusterResourceUsageExportConfigBigqueryDestinationArgs']):
        pulumi.set(self, "bigquery_destination", value)

    @property
    @pulumi.getter(name="enableNetworkEgressMetering")
    def enable_network_egress_metering(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created
        in the cluster to meter network egress traffic.
        """
        return pulumi.get(self, "enable_network_egress_metering")

    @enable_network_egress_metering.setter
    def enable_network_egress_metering(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_network_egress_metering", value)

    @property
    @pulumi.getter(name="enableResourceConsumptionMetering")
    def enable_resource_consumption_metering(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether to enable resource
        consumption metering on this cluster. When enabled, a table will be created in
        the resource export BigQuery dataset to store resource consumption data. The
        resulting table can be joined with the resource usage table or with BigQuery
        billing export. Defaults to `true`.
        """
        return pulumi.get(self, "enable_resource_consumption_metering")

    @enable_resource_consumption_metering.setter
    def enable_resource_consumption_metering(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_resource_consumption_metering", value)


if not MYPY:
    class ClusterResourceUsageExportConfigBigqueryDestinationArgsDict(TypedDict):
        dataset_id: pulumi.Input[builtins.str]
        """
        The ID of a BigQuery Dataset.
        """
elif False:
    ClusterResourceUsageExportConfigBigqueryDestinationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterResourceUsageExportConfigBigqueryDestinationArgs:
    def __init__(__self__, *,
                 dataset_id: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] dataset_id: The ID of a BigQuery Dataset.
        """
        pulumi.set(__self__, "dataset_id", dataset_id)

    @property
    @pulumi.getter(name="datasetId")
    def dataset_id(self) -> pulumi.Input[builtins.str]:
        """
        The ID of a BigQuery Dataset.
        """
        return pulumi.get(self, "dataset_id")

    @dataset_id.setter
    def dataset_id(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "dataset_id", value)


if not MYPY:
    class ClusterSecretManagerConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Enable the Secret Manager add-on for this cluster.
        """
elif False:
    ClusterSecretManagerConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterSecretManagerConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Enable the Secret Manager add-on for this cluster.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Enable the Secret Manager add-on for this cluster.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterSecurityPostureConfigArgsDict(TypedDict):
        mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include `DISABLED`, `BASIC`, and `ENTERPRISE`.
        """
        vulnerability_mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include `VULNERABILITY_DISABLED`, `VULNERABILITY_BASIC` and `VULNERABILITY_ENTERPRISE`.
        """
elif False:
    ClusterSecurityPostureConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterSecurityPostureConfigArgs:
    def __init__(__self__, *,
                 mode: Optional[pulumi.Input[builtins.str]] = None,
                 vulnerability_mode: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] mode: Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include `DISABLED`, `BASIC`, and `ENTERPRISE`.
        :param pulumi.Input[builtins.str] vulnerability_mode: Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include `VULNERABILITY_DISABLED`, `VULNERABILITY_BASIC` and `VULNERABILITY_ENTERPRISE`.
        """
        if mode is not None:
            pulumi.set(__self__, "mode", mode)
        if vulnerability_mode is not None:
            pulumi.set(__self__, "vulnerability_mode", vulnerability_mode)

    @property
    @pulumi.getter
    def mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include `DISABLED`, `BASIC`, and `ENTERPRISE`.
        """
        return pulumi.get(self, "mode")

    @mode.setter
    def mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "mode", value)

    @property
    @pulumi.getter(name="vulnerabilityMode")
    def vulnerability_mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include `VULNERABILITY_DISABLED`, `VULNERABILITY_BASIC` and `VULNERABILITY_ENTERPRISE`.
        """
        return pulumi.get(self, "vulnerability_mode")

    @vulnerability_mode.setter
    def vulnerability_mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "vulnerability_mode", value)


if not MYPY:
    class ClusterServiceExternalIpsConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Controls whether external ips specified by a service will be allowed. It is enabled by default.
        """
elif False:
    ClusterServiceExternalIpsConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterServiceExternalIpsConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Controls whether external ips specified by a service will be allowed. It is enabled by default.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Controls whether external ips specified by a service will be allowed. It is enabled by default.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterTpuConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether Cloud TPU integration is enabled or not
        """
        ipv4_cidr_block: NotRequired[pulumi.Input[builtins.str]]
        """
        IPv4 CIDR block reserved for Cloud TPU in the VPC.
        """
        use_service_networking: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether to use service networking for Cloud TPU or not
        """
elif False:
    ClusterTpuConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterTpuConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool],
                 ipv4_cidr_block: Optional[pulumi.Input[builtins.str]] = None,
                 use_service_networking: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether Cloud TPU integration is enabled or not
        :param pulumi.Input[builtins.str] ipv4_cidr_block: IPv4 CIDR block reserved for Cloud TPU in the VPC.
        :param pulumi.Input[builtins.bool] use_service_networking: Whether to use service networking for Cloud TPU or not
        """
        pulumi.set(__self__, "enabled", enabled)
        if ipv4_cidr_block is not None:
            pulumi.set(__self__, "ipv4_cidr_block", ipv4_cidr_block)
        if use_service_networking is not None:
            pulumi.set(__self__, "use_service_networking", use_service_networking)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether Cloud TPU integration is enabled or not
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter(name="ipv4CidrBlock")
    def ipv4_cidr_block(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        IPv4 CIDR block reserved for Cloud TPU in the VPC.
        """
        return pulumi.get(self, "ipv4_cidr_block")

    @ipv4_cidr_block.setter
    def ipv4_cidr_block(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "ipv4_cidr_block", value)

    @property
    @pulumi.getter(name="useServiceNetworking")
    def use_service_networking(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether to use service networking for Cloud TPU or not
        """
        return pulumi.get(self, "use_service_networking")

    @use_service_networking.setter
    def use_service_networking(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "use_service_networking", value)


if not MYPY:
    class ClusterUserManagedKeysConfigArgsDict(TypedDict):
        aggregation_ca: NotRequired[pulumi.Input[builtins.str]]
        """
        The Certificate Authority Service caPool to use for the aggreation CA in this cluster.
        """
        cluster_ca: NotRequired[pulumi.Input[builtins.str]]
        """
        The Certificate Authority Service caPool to use for the cluster CA in this cluster.
        """
        control_plane_disk_encryption_key: NotRequired[pulumi.Input[builtins.str]]
        """
        The Cloud KMS cryptoKey to use for Confidential Hyperdisk on the control plane nodes.
        """
        etcd_api_ca: NotRequired[pulumi.Input[builtins.str]]
        """
        The Certificate Authority Service caPool to use for the etcd API CA in this cluster.
        """
        etcd_peer_ca: NotRequired[pulumi.Input[builtins.str]]
        """
        The Certificate Authority Service caPool to use for the etcd peer CA in this cluster.
        """
        gkeops_etcd_backup_encryption_key: NotRequired[pulumi.Input[builtins.str]]
        """
        Resource path of the Cloud KMS cryptoKey to use for encryption of internal etcd backups.
        """
        service_account_signing_keys: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The Cloud KMS cryptoKeyVersions to use for signing service account JWTs issued by this cluster.
        """
        service_account_verification_keys: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The Cloud KMS cryptoKeyVersions to use for verifying service account JWTs issued by this cluster.
        """
elif False:
    ClusterUserManagedKeysConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterUserManagedKeysConfigArgs:
    def __init__(__self__, *,
                 aggregation_ca: Optional[pulumi.Input[builtins.str]] = None,
                 cluster_ca: Optional[pulumi.Input[builtins.str]] = None,
                 control_plane_disk_encryption_key: Optional[pulumi.Input[builtins.str]] = None,
                 etcd_api_ca: Optional[pulumi.Input[builtins.str]] = None,
                 etcd_peer_ca: Optional[pulumi.Input[builtins.str]] = None,
                 gkeops_etcd_backup_encryption_key: Optional[pulumi.Input[builtins.str]] = None,
                 service_account_signing_keys: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 service_account_verification_keys: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[builtins.str] aggregation_ca: The Certificate Authority Service caPool to use for the aggreation CA in this cluster.
        :param pulumi.Input[builtins.str] cluster_ca: The Certificate Authority Service caPool to use for the cluster CA in this cluster.
        :param pulumi.Input[builtins.str] control_plane_disk_encryption_key: The Cloud KMS cryptoKey to use for Confidential Hyperdisk on the control plane nodes.
        :param pulumi.Input[builtins.str] etcd_api_ca: The Certificate Authority Service caPool to use for the etcd API CA in this cluster.
        :param pulumi.Input[builtins.str] etcd_peer_ca: The Certificate Authority Service caPool to use for the etcd peer CA in this cluster.
        :param pulumi.Input[builtins.str] gkeops_etcd_backup_encryption_key: Resource path of the Cloud KMS cryptoKey to use for encryption of internal etcd backups.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] service_account_signing_keys: The Cloud KMS cryptoKeyVersions to use for signing service account JWTs issued by this cluster.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] service_account_verification_keys: The Cloud KMS cryptoKeyVersions to use for verifying service account JWTs issued by this cluster.
        """
        if aggregation_ca is not None:
            pulumi.set(__self__, "aggregation_ca", aggregation_ca)
        if cluster_ca is not None:
            pulumi.set(__self__, "cluster_ca", cluster_ca)
        if control_plane_disk_encryption_key is not None:
            pulumi.set(__self__, "control_plane_disk_encryption_key", control_plane_disk_encryption_key)
        if etcd_api_ca is not None:
            pulumi.set(__self__, "etcd_api_ca", etcd_api_ca)
        if etcd_peer_ca is not None:
            pulumi.set(__self__, "etcd_peer_ca", etcd_peer_ca)
        if gkeops_etcd_backup_encryption_key is not None:
            pulumi.set(__self__, "gkeops_etcd_backup_encryption_key", gkeops_etcd_backup_encryption_key)
        if service_account_signing_keys is not None:
            pulumi.set(__self__, "service_account_signing_keys", service_account_signing_keys)
        if service_account_verification_keys is not None:
            pulumi.set(__self__, "service_account_verification_keys", service_account_verification_keys)

    @property
    @pulumi.getter(name="aggregationCa")
    def aggregation_ca(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Certificate Authority Service caPool to use for the aggreation CA in this cluster.
        """
        return pulumi.get(self, "aggregation_ca")

    @aggregation_ca.setter
    def aggregation_ca(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "aggregation_ca", value)

    @property
    @pulumi.getter(name="clusterCa")
    def cluster_ca(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Certificate Authority Service caPool to use for the cluster CA in this cluster.
        """
        return pulumi.get(self, "cluster_ca")

    @cluster_ca.setter
    def cluster_ca(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cluster_ca", value)

    @property
    @pulumi.getter(name="controlPlaneDiskEncryptionKey")
    def control_plane_disk_encryption_key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Cloud KMS cryptoKey to use for Confidential Hyperdisk on the control plane nodes.
        """
        return pulumi.get(self, "control_plane_disk_encryption_key")

    @control_plane_disk_encryption_key.setter
    def control_plane_disk_encryption_key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "control_plane_disk_encryption_key", value)

    @property
    @pulumi.getter(name="etcdApiCa")
    def etcd_api_ca(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Certificate Authority Service caPool to use for the etcd API CA in this cluster.
        """
        return pulumi.get(self, "etcd_api_ca")

    @etcd_api_ca.setter
    def etcd_api_ca(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "etcd_api_ca", value)

    @property
    @pulumi.getter(name="etcdPeerCa")
    def etcd_peer_ca(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Certificate Authority Service caPool to use for the etcd peer CA in this cluster.
        """
        return pulumi.get(self, "etcd_peer_ca")

    @etcd_peer_ca.setter
    def etcd_peer_ca(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "etcd_peer_ca", value)

    @property
    @pulumi.getter(name="gkeopsEtcdBackupEncryptionKey")
    def gkeops_etcd_backup_encryption_key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Resource path of the Cloud KMS cryptoKey to use for encryption of internal etcd backups.
        """
        return pulumi.get(self, "gkeops_etcd_backup_encryption_key")

    @gkeops_etcd_backup_encryption_key.setter
    def gkeops_etcd_backup_encryption_key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "gkeops_etcd_backup_encryption_key", value)

    @property
    @pulumi.getter(name="serviceAccountSigningKeys")
    def service_account_signing_keys(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The Cloud KMS cryptoKeyVersions to use for signing service account JWTs issued by this cluster.
        """
        return pulumi.get(self, "service_account_signing_keys")

    @service_account_signing_keys.setter
    def service_account_signing_keys(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "service_account_signing_keys", value)

    @property
    @pulumi.getter(name="serviceAccountVerificationKeys")
    def service_account_verification_keys(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The Cloud KMS cryptoKeyVersions to use for verifying service account JWTs issued by this cluster.
        """
        return pulumi.get(self, "service_account_verification_keys")

    @service_account_verification_keys.setter
    def service_account_verification_keys(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "service_account_verification_keys", value)


if not MYPY:
    class ClusterVerticalPodAutoscalingArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Enables vertical pod autoscaling
        """
elif False:
    ClusterVerticalPodAutoscalingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterVerticalPodAutoscalingArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Enables vertical pod autoscaling
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Enables vertical pod autoscaling
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class ClusterWorkloadAltsConfigArgsDict(TypedDict):
        enable_alts: pulumi.Input[builtins.bool]
        """
        Whether the alts handshaker should be enabled or not for direct-path. Requires Workload Identity (workloadPool) must be non-empty).
        """
elif False:
    ClusterWorkloadAltsConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterWorkloadAltsConfigArgs:
    def __init__(__self__, *,
                 enable_alts: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enable_alts: Whether the alts handshaker should be enabled or not for direct-path. Requires Workload Identity (workloadPool) must be non-empty).
        """
        pulumi.set(__self__, "enable_alts", enable_alts)

    @property
    @pulumi.getter(name="enableAlts")
    def enable_alts(self) -> pulumi.Input[builtins.bool]:
        """
        Whether the alts handshaker should be enabled or not for direct-path. Requires Workload Identity (workloadPool) must be non-empty).
        """
        return pulumi.get(self, "enable_alts")

    @enable_alts.setter
    def enable_alts(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enable_alts", value)


if not MYPY:
    class ClusterWorkloadIdentityConfigArgsDict(TypedDict):
        workload_pool: NotRequired[pulumi.Input[builtins.str]]
        """
        The workload pool to attach all Kubernetes service accounts to.
        """
elif False:
    ClusterWorkloadIdentityConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterWorkloadIdentityConfigArgs:
    def __init__(__self__, *,
                 workload_pool: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] workload_pool: The workload pool to attach all Kubernetes service accounts to.
        """
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The workload pool to attach all Kubernetes service accounts to.
        """
        return pulumi.get(self, "workload_pool")

    @workload_pool.setter
    def workload_pool(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "workload_pool", value)


if not MYPY:
    class NodePoolAutoscalingArgsDict(TypedDict):
        location_policy: NotRequired[pulumi.Input[builtins.str]]
        """
        Location policy specifies the algorithm used when
        scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
        * "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones.
        * "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations,
        and reduce preemption risk for Spot VMs.
        """
        max_node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Maximum number of nodes per zone in the NodePool.
        Must be >= min_node_count. Cannot be used with total limits.
        """
        min_node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Minimum number of nodes per zone in the NodePool.
        Must be >=0 and <= `max_node_count`. Cannot be used with total limits.
        """
        total_max_node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Total maximum number of nodes in the NodePool.
        Must be >= total_min_node_count. Cannot be used with per zone limits.
        Total size limits are supported only in 1.24.1+ clusters.
        """
        total_min_node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Total minimum number of nodes in the NodePool.
        Must be >=0 and <= `total_max_node_count`. Cannot be used with per zone limits.
        Total size limits are supported only in 1.24.1+ clusters.
        """
elif False:
    NodePoolAutoscalingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolAutoscalingArgs:
    def __init__(__self__, *,
                 location_policy: Optional[pulumi.Input[builtins.str]] = None,
                 max_node_count: Optional[pulumi.Input[builtins.int]] = None,
                 min_node_count: Optional[pulumi.Input[builtins.int]] = None,
                 total_max_node_count: Optional[pulumi.Input[builtins.int]] = None,
                 total_min_node_count: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.str] location_policy: Location policy specifies the algorithm used when
               scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
               * "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones.
               * "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations,
               and reduce preemption risk for Spot VMs.
        :param pulumi.Input[builtins.int] max_node_count: Maximum number of nodes per zone in the NodePool.
               Must be >= min_node_count. Cannot be used with total limits.
        :param pulumi.Input[builtins.int] min_node_count: Minimum number of nodes per zone in the NodePool.
               Must be >=0 and <= `max_node_count`. Cannot be used with total limits.
        :param pulumi.Input[builtins.int] total_max_node_count: Total maximum number of nodes in the NodePool.
               Must be >= total_min_node_count. Cannot be used with per zone limits.
               Total size limits are supported only in 1.24.1+ clusters.
        :param pulumi.Input[builtins.int] total_min_node_count: Total minimum number of nodes in the NodePool.
               Must be >=0 and <= `total_max_node_count`. Cannot be used with per zone limits.
               Total size limits are supported only in 1.24.1+ clusters.
        """
        if location_policy is not None:
            pulumi.set(__self__, "location_policy", location_policy)
        if max_node_count is not None:
            pulumi.set(__self__, "max_node_count", max_node_count)
        if min_node_count is not None:
            pulumi.set(__self__, "min_node_count", min_node_count)
        if total_max_node_count is not None:
            pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        if total_min_node_count is not None:
            pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Location policy specifies the algorithm used when
        scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
        * "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones.
        * "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations,
        and reduce preemption risk for Spot VMs.
        """
        return pulumi.get(self, "location_policy")

    @location_policy.setter
    def location_policy(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "location_policy", value)

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Maximum number of nodes per zone in the NodePool.
        Must be >= min_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "max_node_count")

    @max_node_count.setter
    def max_node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_node_count", value)

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Minimum number of nodes per zone in the NodePool.
        Must be >=0 and <= `max_node_count`. Cannot be used with total limits.
        """
        return pulumi.get(self, "min_node_count")

    @min_node_count.setter
    def min_node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "min_node_count", value)

    @property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Total maximum number of nodes in the NodePool.
        Must be >= total_min_node_count. Cannot be used with per zone limits.
        Total size limits are supported only in 1.24.1+ clusters.
        """
        return pulumi.get(self, "total_max_node_count")

    @total_max_node_count.setter
    def total_max_node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "total_max_node_count", value)

    @property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Total minimum number of nodes in the NodePool.
        Must be >=0 and <= `total_max_node_count`. Cannot be used with per zone limits.
        Total size limits are supported only in 1.24.1+ clusters.
        """
        return pulumi.get(self, "total_min_node_count")

    @total_min_node_count.setter
    def total_min_node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "total_min_node_count", value)


if not MYPY:
    class NodePoolManagementArgsDict(TypedDict):
        auto_repair: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether the nodes will be automatically repaired. Enabled by default.
        """
        auto_upgrade: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether the nodes will be automatically upgraded. Enabled by default.
        """
elif False:
    NodePoolManagementArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolManagementArgs:
    def __init__(__self__, *,
                 auto_repair: Optional[pulumi.Input[builtins.bool]] = None,
                 auto_upgrade: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.bool] auto_repair: Whether the nodes will be automatically repaired. Enabled by default.
        :param pulumi.Input[builtins.bool] auto_upgrade: Whether the nodes will be automatically upgraded. Enabled by default.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether the nodes will be automatically repaired. Enabled by default.
        """
        return pulumi.get(self, "auto_repair")

    @auto_repair.setter
    def auto_repair(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "auto_repair", value)

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether the nodes will be automatically upgraded. Enabled by default.
        """
        return pulumi.get(self, "auto_upgrade")

    @auto_upgrade.setter
    def auto_upgrade(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "auto_upgrade", value)


if not MYPY:
    class NodePoolNetworkConfigArgsDict(TypedDict):
        additional_node_network_configs: NotRequired[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalNodeNetworkConfigArgsDict']]]]
        """
        We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface.
        Structure is documented below
        """
        additional_pod_network_configs: NotRequired[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalPodNetworkConfigArgsDict']]]]
        """
        We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node.
        Structure is documented below
        """
        create_pod_range: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        """
        enable_private_nodes: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether nodes have internal IP addresses only.
        """
        network_performance_config: NotRequired[pulumi.Input['NodePoolNetworkConfigNetworkPerformanceConfigArgsDict']]
        """
        Network bandwidth tier configuration. Structure is documented below.
        """
        pod_cidr_overprovision_config: NotRequired[pulumi.Input['NodePoolNetworkConfigPodCidrOverprovisionConfigArgsDict']]
        """
        Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited. Structure is documented below.
        """
        pod_ipv4_cidr_block: NotRequired[pulumi.Input[builtins.str]]
        """
        The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        pod_range: NotRequired[pulumi.Input[builtins.str]]
        """
        The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
elif False:
    NodePoolNetworkConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNetworkConfigArgs:
    def __init__(__self__, *,
                 additional_node_network_configs: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]]] = None,
                 additional_pod_network_configs: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]]] = None,
                 create_pod_range: Optional[pulumi.Input[builtins.bool]] = None,
                 enable_private_nodes: Optional[pulumi.Input[builtins.bool]] = None,
                 network_performance_config: Optional[pulumi.Input['NodePoolNetworkConfigNetworkPerformanceConfigArgs']] = None,
                 pod_cidr_overprovision_config: Optional[pulumi.Input['NodePoolNetworkConfigPodCidrOverprovisionConfigArgs']] = None,
                 pod_ipv4_cidr_block: Optional[pulumi.Input[builtins.str]] = None,
                 pod_range: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]] additional_node_network_configs: We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface.
               Structure is documented below
        :param pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]] additional_pod_network_configs: We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node.
               Structure is documented below
        :param pulumi.Input[builtins.bool] create_pod_range: Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        :param pulumi.Input[builtins.bool] enable_private_nodes: Whether nodes have internal IP addresses only.
        :param pulumi.Input['NodePoolNetworkConfigNetworkPerformanceConfigArgs'] network_performance_config: Network bandwidth tier configuration. Structure is documented below.
        :param pulumi.Input['NodePoolNetworkConfigPodCidrOverprovisionConfigArgs'] pod_cidr_overprovision_config: Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited. Structure is documented below.
        :param pulumi.Input[builtins.str] pod_ipv4_cidr_block: The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        :param pulumi.Input[builtins.str] pod_range: The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        if additional_node_network_configs is not None:
            pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        if additional_pod_network_configs is not None:
            pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        if create_pod_range is not None:
            pulumi.set(__self__, "create_pod_range", create_pod_range)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if network_performance_config is not None:
            pulumi.set(__self__, "network_performance_config", network_performance_config)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if pod_ipv4_cidr_block is not None:
            pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        if pod_range is not None:
            pulumi.set(__self__, "pod_range", pod_range)

    @property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]]]:
        """
        We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface.
        Structure is documented below
        """
        return pulumi.get(self, "additional_node_network_configs")

    @additional_node_network_configs.setter
    def additional_node_network_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]]]):
        pulumi.set(self, "additional_node_network_configs", value)

    @property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]]]:
        """
        We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node.
        Structure is documented below
        """
        return pulumi.get(self, "additional_pod_network_configs")

    @additional_pod_network_configs.setter
    def additional_pod_network_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]]]):
        pulumi.set(self, "additional_pod_network_configs", value)

    @property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        """
        return pulumi.get(self, "create_pod_range")

    @create_pod_range.setter
    def create_pod_range(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "create_pod_range", value)

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether nodes have internal IP addresses only.
        """
        return pulumi.get(self, "enable_private_nodes")

    @enable_private_nodes.setter
    def enable_private_nodes(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_private_nodes", value)

    @property
    @pulumi.getter(name="networkPerformanceConfig")
    def network_performance_config(self) -> Optional[pulumi.Input['NodePoolNetworkConfigNetworkPerformanceConfigArgs']]:
        """
        Network bandwidth tier configuration. Structure is documented below.
        """
        return pulumi.get(self, "network_performance_config")

    @network_performance_config.setter
    def network_performance_config(self, value: Optional[pulumi.Input['NodePoolNetworkConfigNetworkPerformanceConfigArgs']]):
        pulumi.set(self, "network_performance_config", value)

    @property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional[pulumi.Input['NodePoolNetworkConfigPodCidrOverprovisionConfigArgs']]:
        """
        Configuration for node-pool level pod cidr overprovision. If not set, the cluster level setting will be inherited. Structure is documented below.
        """
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @pod_cidr_overprovision_config.setter
    def pod_cidr_overprovision_config(self, value: Optional[pulumi.Input['NodePoolNetworkConfigPodCidrOverprovisionConfigArgs']]):
        pulumi.set(self, "pod_cidr_overprovision_config", value)

    @property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @pod_ipv4_cidr_block.setter
    def pod_ipv4_cidr_block(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "pod_ipv4_cidr_block", value)

    @property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        return pulumi.get(self, "pod_range")

    @pod_range.setter
    def pod_range(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "pod_range", value)


if not MYPY:
    class NodePoolNetworkConfigAdditionalNodeNetworkConfigArgsDict(TypedDict):
        network: NotRequired[pulumi.Input[builtins.str]]
        """
        Name of the VPC where the additional interface belongs.
        """
        subnetwork: NotRequired[pulumi.Input[builtins.str]]
        """
        Name of the subnetwork where the additional interface belongs.
        """
elif False:
    NodePoolNetworkConfigAdditionalNodeNetworkConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs:
    def __init__(__self__, *,
                 network: Optional[pulumi.Input[builtins.str]] = None,
                 subnetwork: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] network: Name of the VPC where the additional interface belongs.
        :param pulumi.Input[builtins.str] subnetwork: Name of the subnetwork where the additional interface belongs.
        """
        if network is not None:
            pulumi.set(__self__, "network", network)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter
    def network(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Name of the VPC where the additional interface belongs.
        """
        return pulumi.get(self, "network")

    @network.setter
    def network(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "network", value)

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Name of the subnetwork where the additional interface belongs.
        """
        return pulumi.get(self, "subnetwork")

    @subnetwork.setter
    def subnetwork(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "subnetwork", value)


if not MYPY:
    class NodePoolNetworkConfigAdditionalPodNetworkConfigArgsDict(TypedDict):
        max_pods_per_node: NotRequired[pulumi.Input[builtins.int]]
        """
        The maximum number of pods per node which use this pod network.
        """
        secondary_pod_range: NotRequired[pulumi.Input[builtins.str]]
        """
        The name of the secondary range on the subnet which provides IP address for this pod range.
        """
        subnetwork: NotRequired[pulumi.Input[builtins.str]]
        """
        Name of the subnetwork where the additional pod network belongs.
        """
elif False:
    NodePoolNetworkConfigAdditionalPodNetworkConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNetworkConfigAdditionalPodNetworkConfigArgs:
    def __init__(__self__, *,
                 max_pods_per_node: Optional[pulumi.Input[builtins.int]] = None,
                 secondary_pod_range: Optional[pulumi.Input[builtins.str]] = None,
                 subnetwork: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.int] max_pods_per_node: The maximum number of pods per node which use this pod network.
        :param pulumi.Input[builtins.str] secondary_pod_range: The name of the secondary range on the subnet which provides IP address for this pod range.
        :param pulumi.Input[builtins.str] subnetwork: Name of the subnetwork where the additional pod network belongs.
        """
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if secondary_pod_range is not None:
            pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The maximum number of pods per node which use this pod network.
        """
        return pulumi.get(self, "max_pods_per_node")

    @max_pods_per_node.setter
    def max_pods_per_node(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_pods_per_node", value)

    @property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of the secondary range on the subnet which provides IP address for this pod range.
        """
        return pulumi.get(self, "secondary_pod_range")

    @secondary_pod_range.setter
    def secondary_pod_range(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "secondary_pod_range", value)

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Name of the subnetwork where the additional pod network belongs.
        """
        return pulumi.get(self, "subnetwork")

    @subnetwork.setter
    def subnetwork(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "subnetwork", value)


if not MYPY:
    class NodePoolNetworkConfigNetworkPerformanceConfigArgsDict(TypedDict):
        total_egress_bandwidth_tier: pulumi.Input[builtins.str]
        """
        Specifies the total network bandwidth tier for the NodePool.
        """
elif False:
    NodePoolNetworkConfigNetworkPerformanceConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNetworkConfigNetworkPerformanceConfigArgs:
    def __init__(__self__, *,
                 total_egress_bandwidth_tier: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] total_egress_bandwidth_tier: Specifies the total network bandwidth tier for the NodePool.
        """
        pulumi.set(__self__, "total_egress_bandwidth_tier", total_egress_bandwidth_tier)

    @property
    @pulumi.getter(name="totalEgressBandwidthTier")
    def total_egress_bandwidth_tier(self) -> pulumi.Input[builtins.str]:
        """
        Specifies the total network bandwidth tier for the NodePool.
        """
        return pulumi.get(self, "total_egress_bandwidth_tier")

    @total_egress_bandwidth_tier.setter
    def total_egress_bandwidth_tier(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "total_egress_bandwidth_tier", value)


if not MYPY:
    class NodePoolNetworkConfigPodCidrOverprovisionConfigArgsDict(TypedDict):
        disabled: pulumi.Input[builtins.bool]
        """
        Whether pod cidr overprovision is disabled.
        """
elif False:
    NodePoolNetworkConfigPodCidrOverprovisionConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNetworkConfigPodCidrOverprovisionConfigArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] disabled: Whether pod cidr overprovision is disabled.
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether pod cidr overprovision is disabled.
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "disabled", value)


if not MYPY:
    class NodePoolNodeConfigArgsDict(TypedDict):
        advanced_machine_features: NotRequired[pulumi.Input['NodePoolNodeConfigAdvancedMachineFeaturesArgsDict']]
        """
        Specifies options for controlling advanced machine features.
        """
        boot_disk_kms_key: NotRequired[pulumi.Input[builtins.str]]
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        """
        confidential_nodes: NotRequired[pulumi.Input['NodePoolNodeConfigConfidentialNodesArgsDict']]
        """
        Configuration for the confidential nodes feature, which makes nodes run on confidential VMs.
        """
        containerd_config: NotRequired[pulumi.Input['NodePoolNodeConfigContainerdConfigArgsDict']]
        """
        Parameters for containerd configuration.
        """
        disk_size_gb: NotRequired[pulumi.Input[builtins.int]]
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        disk_type: NotRequired[pulumi.Input[builtins.str]]
        """
        Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        """
        effective_taints: NotRequired[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigEffectiveTaintArgsDict']]]]
        """
        List of kubernetes taints applied to each node.
        """
        enable_confidential_storage: NotRequired[pulumi.Input[builtins.bool]]
        """
        If enabled boot disks are configured with confidential mode.
        """
        ephemeral_storage_config: NotRequired[pulumi.Input['NodePoolNodeConfigEphemeralStorageConfigArgsDict']]
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        ephemeral_storage_local_ssd_config: NotRequired[pulumi.Input['NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgsDict']]
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        fast_socket: NotRequired[pulumi.Input['NodePoolNodeConfigFastSocketArgsDict']]
        """
        Enable or disable NCCL Fast Socket in the node pool.
        """
        flex_start: NotRequired[pulumi.Input[builtins.bool]]
        """
        Enables Flex Start provisioning model for the node pool
        """
        gcfs_config: NotRequired[pulumi.Input['NodePoolNodeConfigGcfsConfigArgsDict']]
        """
        GCFS configuration for this node.
        """
        guest_accelerators: NotRequired[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigGuestAcceleratorArgsDict']]]]
        """
        List of the type and count of accelerator cards attached to the instance.
        """
        gvnic: NotRequired[pulumi.Input['NodePoolNodeConfigGvnicArgsDict']]
        """
        Enable or disable gvnic in the node pool.
        """
        host_maintenance_policy: NotRequired[pulumi.Input['NodePoolNodeConfigHostMaintenancePolicyArgsDict']]
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        image_type: NotRequired[pulumi.Input[builtins.str]]
        """
        The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        """
        kubelet_config: NotRequired[pulumi.Input['NodePoolNodeConfigKubeletConfigArgsDict']]
        """
        Node kubelet configs.
        """
        labels: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        """
        linux_node_config: NotRequired[pulumi.Input['NodePoolNodeConfigLinuxNodeConfigArgsDict']]
        """
        Parameters that can be configured on Linux nodes.
        """
        local_nvme_ssd_block_config: NotRequired[pulumi.Input['NodePoolNodeConfigLocalNvmeSsdBlockConfigArgsDict']]
        """
        Parameters for raw-block local NVMe SSDs.
        """
        local_ssd_count: NotRequired[pulumi.Input[builtins.int]]
        """
        The number of local SSD disks to be attached to the node.
        """
        local_ssd_encryption_mode: NotRequired[pulumi.Input[builtins.str]]
        """
        LocalSsdEncryptionMode specified the method used for encrypting the local SSDs attached to the node.
        """
        logging_variant: NotRequired[pulumi.Input[builtins.str]]
        """
        Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        """
        machine_type: NotRequired[pulumi.Input[builtins.str]]
        """
        The name of a Google Compute Engine machine type.
        """
        max_run_duration: NotRequired[pulumi.Input[builtins.str]]
        """
        The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        """
        metadata: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        The metadata key/value pairs assigned to instances in the cluster.
        """
        min_cpu_platform: NotRequired[pulumi.Input[builtins.str]]
        """
        Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        """
        node_group: NotRequired[pulumi.Input[builtins.str]]
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        """
        oauth_scopes: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The set of Google API scopes to be made available on all of the node VMs.
        """
        preemptible: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether the nodes are created as preemptible VM instances.
        """
        reservation_affinity: NotRequired[pulumi.Input['NodePoolNodeConfigReservationAffinityArgsDict']]
        """
        The configuration of the desired reservation which instances could take capacity from.
        Structure is documented below.

        <a name="nested_autoscaling"></a>The `autoscaling` block supports (either total or per zone limits are required):
        """
        resource_labels: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        """
        resource_manager_tags: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        """
        sandbox_config: NotRequired[pulumi.Input['NodePoolNodeConfigSandboxConfigArgsDict']]
        """
        Sandbox configuration for this node.
        """
        secondary_boot_disks: NotRequired[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSecondaryBootDiskArgsDict']]]]
        """
        Secondary boot disks for preloading data or container images.
        """
        service_account: NotRequired[pulumi.Input[builtins.str]]
        """
        The Google Cloud Platform Service Account to be used by the node VMs.
        """
        shielded_instance_config: NotRequired[pulumi.Input['NodePoolNodeConfigShieldedInstanceConfigArgsDict']]
        """
        Shielded Instance options.
        """
        sole_tenant_config: NotRequired[pulumi.Input['NodePoolNodeConfigSoleTenantConfigArgsDict']]
        """
        Node affinity options for sole tenant node pools.
        """
        spot: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether the nodes are created as spot VM instances.
        """
        storage_pools: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        tags: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The list of instance tags applied to all nodes.
        """
        taints: NotRequired[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigTaintArgsDict']]]]
        """
        List of Kubernetes taints to be applied to each node.
        """
        windows_node_config: NotRequired[pulumi.Input['NodePoolNodeConfigWindowsNodeConfigArgsDict']]
        """
        Parameters that can be configured on Windows nodes.
        """
        workload_metadata_config: NotRequired[pulumi.Input['NodePoolNodeConfigWorkloadMetadataConfigArgsDict']]
        """
        The workload metadata configuration for this node.
        """
elif False:
    NodePoolNodeConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigArgs:
    def __init__(__self__, *,
                 advanced_machine_features: Optional[pulumi.Input['NodePoolNodeConfigAdvancedMachineFeaturesArgs']] = None,
                 boot_disk_kms_key: Optional[pulumi.Input[builtins.str]] = None,
                 confidential_nodes: Optional[pulumi.Input['NodePoolNodeConfigConfidentialNodesArgs']] = None,
                 containerd_config: Optional[pulumi.Input['NodePoolNodeConfigContainerdConfigArgs']] = None,
                 disk_size_gb: Optional[pulumi.Input[builtins.int]] = None,
                 disk_type: Optional[pulumi.Input[builtins.str]] = None,
                 effective_taints: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigEffectiveTaintArgs']]]] = None,
                 enable_confidential_storage: Optional[pulumi.Input[builtins.bool]] = None,
                 ephemeral_storage_config: Optional[pulumi.Input['NodePoolNodeConfigEphemeralStorageConfigArgs']] = None,
                 ephemeral_storage_local_ssd_config: Optional[pulumi.Input['NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs']] = None,
                 fast_socket: Optional[pulumi.Input['NodePoolNodeConfigFastSocketArgs']] = None,
                 flex_start: Optional[pulumi.Input[builtins.bool]] = None,
                 gcfs_config: Optional[pulumi.Input['NodePoolNodeConfigGcfsConfigArgs']] = None,
                 guest_accelerators: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigGuestAcceleratorArgs']]]] = None,
                 gvnic: Optional[pulumi.Input['NodePoolNodeConfigGvnicArgs']] = None,
                 host_maintenance_policy: Optional[pulumi.Input['NodePoolNodeConfigHostMaintenancePolicyArgs']] = None,
                 image_type: Optional[pulumi.Input[builtins.str]] = None,
                 kubelet_config: Optional[pulumi.Input['NodePoolNodeConfigKubeletConfigArgs']] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 linux_node_config: Optional[pulumi.Input['NodePoolNodeConfigLinuxNodeConfigArgs']] = None,
                 local_nvme_ssd_block_config: Optional[pulumi.Input['NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs']] = None,
                 local_ssd_count: Optional[pulumi.Input[builtins.int]] = None,
                 local_ssd_encryption_mode: Optional[pulumi.Input[builtins.str]] = None,
                 logging_variant: Optional[pulumi.Input[builtins.str]] = None,
                 machine_type: Optional[pulumi.Input[builtins.str]] = None,
                 max_run_duration: Optional[pulumi.Input[builtins.str]] = None,
                 metadata: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 min_cpu_platform: Optional[pulumi.Input[builtins.str]] = None,
                 node_group: Optional[pulumi.Input[builtins.str]] = None,
                 oauth_scopes: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 preemptible: Optional[pulumi.Input[builtins.bool]] = None,
                 reservation_affinity: Optional[pulumi.Input['NodePoolNodeConfigReservationAffinityArgs']] = None,
                 resource_labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 resource_manager_tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 sandbox_config: Optional[pulumi.Input['NodePoolNodeConfigSandboxConfigArgs']] = None,
                 secondary_boot_disks: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSecondaryBootDiskArgs']]]] = None,
                 service_account: Optional[pulumi.Input[builtins.str]] = None,
                 shielded_instance_config: Optional[pulumi.Input['NodePoolNodeConfigShieldedInstanceConfigArgs']] = None,
                 sole_tenant_config: Optional[pulumi.Input['NodePoolNodeConfigSoleTenantConfigArgs']] = None,
                 spot: Optional[pulumi.Input[builtins.bool]] = None,
                 storage_pools: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 tags: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 taints: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigTaintArgs']]]] = None,
                 windows_node_config: Optional[pulumi.Input['NodePoolNodeConfigWindowsNodeConfigArgs']] = None,
                 workload_metadata_config: Optional[pulumi.Input['NodePoolNodeConfigWorkloadMetadataConfigArgs']] = None):
        """
        :param pulumi.Input['NodePoolNodeConfigAdvancedMachineFeaturesArgs'] advanced_machine_features: Specifies options for controlling advanced machine features.
        :param pulumi.Input[builtins.str] boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        :param pulumi.Input['NodePoolNodeConfigConfidentialNodesArgs'] confidential_nodes: Configuration for the confidential nodes feature, which makes nodes run on confidential VMs.
        :param pulumi.Input['NodePoolNodeConfigContainerdConfigArgs'] containerd_config: Parameters for containerd configuration.
        :param pulumi.Input[builtins.int] disk_size_gb: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        :param pulumi.Input[builtins.str] disk_type: Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        :param pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigEffectiveTaintArgs']]] effective_taints: List of kubernetes taints applied to each node.
        :param pulumi.Input[builtins.bool] enable_confidential_storage: If enabled boot disks are configured with confidential mode.
        :param pulumi.Input['NodePoolNodeConfigEphemeralStorageConfigArgs'] ephemeral_storage_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param pulumi.Input['NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs'] ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        :param pulumi.Input['NodePoolNodeConfigFastSocketArgs'] fast_socket: Enable or disable NCCL Fast Socket in the node pool.
        :param pulumi.Input[builtins.bool] flex_start: Enables Flex Start provisioning model for the node pool
        :param pulumi.Input['NodePoolNodeConfigGcfsConfigArgs'] gcfs_config: GCFS configuration for this node.
        :param pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigGuestAcceleratorArgs']]] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
        :param pulumi.Input['NodePoolNodeConfigGvnicArgs'] gvnic: Enable or disable gvnic in the node pool.
        :param pulumi.Input['NodePoolNodeConfigHostMaintenancePolicyArgs'] host_maintenance_policy: The maintenance policy for the hosts on which the GKE VMs run on.
        :param pulumi.Input[builtins.str] image_type: The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        :param pulumi.Input['NodePoolNodeConfigKubeletConfigArgs'] kubelet_config: Node kubelet configs.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] labels: The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        :param pulumi.Input['NodePoolNodeConfigLinuxNodeConfigArgs'] linux_node_config: Parameters that can be configured on Linux nodes.
        :param pulumi.Input['NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs'] local_nvme_ssd_block_config: Parameters for raw-block local NVMe SSDs.
        :param pulumi.Input[builtins.int] local_ssd_count: The number of local SSD disks to be attached to the node.
        :param pulumi.Input[builtins.str] local_ssd_encryption_mode: LocalSsdEncryptionMode specified the method used for encrypting the local SSDs attached to the node.
        :param pulumi.Input[builtins.str] logging_variant: Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        :param pulumi.Input[builtins.str] machine_type: The name of a Google Compute Engine machine type.
        :param pulumi.Input[builtins.str] max_run_duration: The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] metadata: The metadata key/value pairs assigned to instances in the cluster.
        :param pulumi.Input[builtins.str] min_cpu_platform: Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        :param pulumi.Input[builtins.str] node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] oauth_scopes: The set of Google API scopes to be made available on all of the node VMs.
        :param pulumi.Input[builtins.bool] preemptible: Whether the nodes are created as preemptible VM instances.
        :param pulumi.Input['NodePoolNodeConfigReservationAffinityArgs'] reservation_affinity: The configuration of the desired reservation which instances could take capacity from.
               Structure is documented below.
               
               <a name="nested_autoscaling"></a>The `autoscaling` block supports (either total or per zone limits are required):
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] resource_labels: The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] resource_manager_tags: A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        :param pulumi.Input['NodePoolNodeConfigSandboxConfigArgs'] sandbox_config: Sandbox configuration for this node.
        :param pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSecondaryBootDiskArgs']]] secondary_boot_disks: Secondary boot disks for preloading data or container images.
        :param pulumi.Input[builtins.str] service_account: The Google Cloud Platform Service Account to be used by the node VMs.
        :param pulumi.Input['NodePoolNodeConfigShieldedInstanceConfigArgs'] shielded_instance_config: Shielded Instance options.
        :param pulumi.Input['NodePoolNodeConfigSoleTenantConfigArgs'] sole_tenant_config: Node affinity options for sole tenant node pools.
        :param pulumi.Input[builtins.bool] spot: Whether the nodes are created as spot VM instances.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] storage_pools: The list of Storage Pools where boot disks are provisioned.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] tags: The list of instance tags applied to all nodes.
        :param pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigTaintArgs']]] taints: List of Kubernetes taints to be applied to each node.
        :param pulumi.Input['NodePoolNodeConfigWindowsNodeConfigArgs'] windows_node_config: Parameters that can be configured on Windows nodes.
        :param pulumi.Input['NodePoolNodeConfigWorkloadMetadataConfigArgs'] workload_metadata_config: The workload metadata configuration for this node.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if containerd_config is not None:
            pulumi.set(__self__, "containerd_config", containerd_config)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if effective_taints is not None:
            pulumi.set(__self__, "effective_taints", effective_taints)
        if enable_confidential_storage is not None:
            pulumi.set(__self__, "enable_confidential_storage", enable_confidential_storage)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if flex_start is not None:
            pulumi.set(__self__, "flex_start", flex_start)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if local_ssd_encryption_mode is not None:
            pulumi.set(__self__, "local_ssd_encryption_mode", local_ssd_encryption_mode)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if max_run_duration is not None:
            pulumi.set(__self__, "max_run_duration", max_run_duration)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if resource_manager_tags is not None:
            pulumi.set(__self__, "resource_manager_tags", resource_manager_tags)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if secondary_boot_disks is not None:
            pulumi.set(__self__, "secondary_boot_disks", secondary_boot_disks)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if storage_pools is not None:
            pulumi.set(__self__, "storage_pools", storage_pools)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if windows_node_config is not None:
            pulumi.set(__self__, "windows_node_config", windows_node_config)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional[pulumi.Input['NodePoolNodeConfigAdvancedMachineFeaturesArgs']]:
        """
        Specifies options for controlling advanced machine features.
        """
        return pulumi.get(self, "advanced_machine_features")

    @advanced_machine_features.setter
    def advanced_machine_features(self, value: Optional[pulumi.Input['NodePoolNodeConfigAdvancedMachineFeaturesArgs']]):
        pulumi.set(self, "advanced_machine_features", value)

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @boot_disk_kms_key.setter
    def boot_disk_kms_key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "boot_disk_kms_key", value)

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional[pulumi.Input['NodePoolNodeConfigConfidentialNodesArgs']]:
        """
        Configuration for the confidential nodes feature, which makes nodes run on confidential VMs.
        """
        return pulumi.get(self, "confidential_nodes")

    @confidential_nodes.setter
    def confidential_nodes(self, value: Optional[pulumi.Input['NodePoolNodeConfigConfidentialNodesArgs']]):
        pulumi.set(self, "confidential_nodes", value)

    @property
    @pulumi.getter(name="containerdConfig")
    def containerd_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigContainerdConfigArgs']]:
        """
        Parameters for containerd configuration.
        """
        return pulumi.get(self, "containerd_config")

    @containerd_config.setter
    def containerd_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigContainerdConfigArgs']]):
        pulumi.set(self, "containerd_config", value)

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @disk_size_gb.setter
    def disk_size_gb(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "disk_size_gb", value)

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd
        """
        return pulumi.get(self, "disk_type")

    @disk_type.setter
    def disk_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "disk_type", value)

    @property
    @pulumi.getter(name="effectiveTaints")
    def effective_taints(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigEffectiveTaintArgs']]]]:
        """
        List of kubernetes taints applied to each node.
        """
        return pulumi.get(self, "effective_taints")

    @effective_taints.setter
    def effective_taints(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigEffectiveTaintArgs']]]]):
        pulumi.set(self, "effective_taints", value)

    @property
    @pulumi.getter(name="enableConfidentialStorage")
    def enable_confidential_storage(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        If enabled boot disks are configured with confidential mode.
        """
        return pulumi.get(self, "enable_confidential_storage")

    @enable_confidential_storage.setter
    def enable_confidential_storage(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_confidential_storage", value)

    @property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigEphemeralStorageConfigArgs']]:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @ephemeral_storage_config.setter
    def ephemeral_storage_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigEphemeralStorageConfigArgs']]):
        pulumi.set(self, "ephemeral_storage_config", value)

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs']]:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @ephemeral_storage_local_ssd_config.setter
    def ephemeral_storage_local_ssd_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs']]):
        pulumi.set(self, "ephemeral_storage_local_ssd_config", value)

    @property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional[pulumi.Input['NodePoolNodeConfigFastSocketArgs']]:
        """
        Enable or disable NCCL Fast Socket in the node pool.
        """
        return pulumi.get(self, "fast_socket")

    @fast_socket.setter
    def fast_socket(self, value: Optional[pulumi.Input['NodePoolNodeConfigFastSocketArgs']]):
        pulumi.set(self, "fast_socket", value)

    @property
    @pulumi.getter(name="flexStart")
    def flex_start(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Enables Flex Start provisioning model for the node pool
        """
        return pulumi.get(self, "flex_start")

    @flex_start.setter
    def flex_start(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "flex_start", value)

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigGcfsConfigArgs']]:
        """
        GCFS configuration for this node.
        """
        return pulumi.get(self, "gcfs_config")

    @gcfs_config.setter
    def gcfs_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigGcfsConfigArgs']]):
        pulumi.set(self, "gcfs_config", value)

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigGuestAcceleratorArgs']]]]:
        """
        List of the type and count of accelerator cards attached to the instance.
        """
        return pulumi.get(self, "guest_accelerators")

    @guest_accelerators.setter
    def guest_accelerators(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigGuestAcceleratorArgs']]]]):
        pulumi.set(self, "guest_accelerators", value)

    @property
    @pulumi.getter
    def gvnic(self) -> Optional[pulumi.Input['NodePoolNodeConfigGvnicArgs']]:
        """
        Enable or disable gvnic in the node pool.
        """
        return pulumi.get(self, "gvnic")

    @gvnic.setter
    def gvnic(self, value: Optional[pulumi.Input['NodePoolNodeConfigGvnicArgs']]):
        pulumi.set(self, "gvnic", value)

    @property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional[pulumi.Input['NodePoolNodeConfigHostMaintenancePolicyArgs']]:
        """
        The maintenance policy for the hosts on which the GKE VMs run on.
        """
        return pulumi.get(self, "host_maintenance_policy")

    @host_maintenance_policy.setter
    def host_maintenance_policy(self, value: Optional[pulumi.Input['NodePoolNodeConfigHostMaintenancePolicyArgs']]):
        pulumi.set(self, "host_maintenance_policy", value)

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The image type to use for this node. Note that for a given image type, the latest version of it will be used.
        """
        return pulumi.get(self, "image_type")

    @image_type.setter
    def image_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "image_type", value)

    @property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigKubeletConfigArgs']]:
        """
        Node kubelet configs.
        """
        return pulumi.get(self, "kubelet_config")

    @kubelet_config.setter
    def kubelet_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigKubeletConfigArgs']]):
        pulumi.set(self, "kubelet_config", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigLinuxNodeConfigArgs']]:
        """
        Parameters that can be configured on Linux nodes.
        """
        return pulumi.get(self, "linux_node_config")

    @linux_node_config.setter
    def linux_node_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigLinuxNodeConfigArgs']]):
        pulumi.set(self, "linux_node_config", value)

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs']]:
        """
        Parameters for raw-block local NVMe SSDs.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @local_nvme_ssd_block_config.setter
    def local_nvme_ssd_block_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs']]):
        pulumi.set(self, "local_nvme_ssd_block_config", value)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The number of local SSD disks to be attached to the node.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "local_ssd_count", value)

    @property
    @pulumi.getter(name="localSsdEncryptionMode")
    def local_ssd_encryption_mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        LocalSsdEncryptionMode specified the method used for encrypting the local SSDs attached to the node.
        """
        return pulumi.get(self, "local_ssd_encryption_mode")

    @local_ssd_encryption_mode.setter
    def local_ssd_encryption_mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "local_ssd_encryption_mode", value)

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.
        """
        return pulumi.get(self, "logging_variant")

    @logging_variant.setter
    def logging_variant(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "logging_variant", value)

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of a Google Compute Engine machine type.
        """
        return pulumi.get(self, "machine_type")

    @machine_type.setter
    def machine_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "machine_type", value)

    @property
    @pulumi.getter(name="maxRunDuration")
    def max_run_duration(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".
        """
        return pulumi.get(self, "max_run_duration")

    @max_run_duration.setter
    def max_run_duration(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "max_run_duration", value)

    @property
    @pulumi.getter
    def metadata(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The metadata key/value pairs assigned to instances in the cluster.
        """
        return pulumi.get(self, "metadata")

    @metadata.setter
    def metadata(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "metadata", value)

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.
        """
        return pulumi.get(self, "min_cpu_platform")

    @min_cpu_platform.setter
    def min_cpu_platform(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "min_cpu_platform", value)

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.
        """
        return pulumi.get(self, "node_group")

    @node_group.setter
    def node_group(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "node_group", value)

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The set of Google API scopes to be made available on all of the node VMs.
        """
        return pulumi.get(self, "oauth_scopes")

    @oauth_scopes.setter
    def oauth_scopes(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "oauth_scopes", value)

    @property
    @pulumi.getter
    def preemptible(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether the nodes are created as preemptible VM instances.
        """
        return pulumi.get(self, "preemptible")

    @preemptible.setter
    def preemptible(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "preemptible", value)

    @property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional[pulumi.Input['NodePoolNodeConfigReservationAffinityArgs']]:
        """
        The configuration of the desired reservation which instances could take capacity from.
        Structure is documented below.

        <a name="nested_autoscaling"></a>The `autoscaling` block supports (either total or per zone limits are required):
        """
        return pulumi.get(self, "reservation_affinity")

    @reservation_affinity.setter
    def reservation_affinity(self, value: Optional[pulumi.Input['NodePoolNodeConfigReservationAffinityArgs']]):
        pulumi.set(self, "reservation_affinity", value)

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The GCE resource labels (a map of key/value pairs) to be applied to the node pool.
        """
        return pulumi.get(self, "resource_labels")

    @resource_labels.setter
    def resource_labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "resource_labels", value)

    @property
    @pulumi.getter(name="resourceManagerTags")
    def resource_manager_tags(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.
        """
        return pulumi.get(self, "resource_manager_tags")

    @resource_manager_tags.setter
    def resource_manager_tags(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "resource_manager_tags", value)

    @property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigSandboxConfigArgs']]:
        """
        Sandbox configuration for this node.
        """
        return pulumi.get(self, "sandbox_config")

    @sandbox_config.setter
    def sandbox_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigSandboxConfigArgs']]):
        pulumi.set(self, "sandbox_config", value)

    @property
    @pulumi.getter(name="secondaryBootDisks")
    def secondary_boot_disks(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSecondaryBootDiskArgs']]]]:
        """
        Secondary boot disks for preloading data or container images.
        """
        return pulumi.get(self, "secondary_boot_disks")

    @secondary_boot_disks.setter
    def secondary_boot_disks(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSecondaryBootDiskArgs']]]]):
        pulumi.set(self, "secondary_boot_disks", value)

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Google Cloud Platform Service Account to be used by the node VMs.
        """
        return pulumi.get(self, "service_account")

    @service_account.setter
    def service_account(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "service_account", value)

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigShieldedInstanceConfigArgs']]:
        """
        Shielded Instance options.
        """
        return pulumi.get(self, "shielded_instance_config")

    @shielded_instance_config.setter
    def shielded_instance_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigShieldedInstanceConfigArgs']]):
        pulumi.set(self, "shielded_instance_config", value)

    @property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigSoleTenantConfigArgs']]:
        """
        Node affinity options for sole tenant node pools.
        """
        return pulumi.get(self, "sole_tenant_config")

    @sole_tenant_config.setter
    def sole_tenant_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigSoleTenantConfigArgs']]):
        pulumi.set(self, "sole_tenant_config", value)

    @property
    @pulumi.getter
    def spot(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether the nodes are created as spot VM instances.
        """
        return pulumi.get(self, "spot")

    @spot.setter
    def spot(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "spot", value)

    @property
    @pulumi.getter(name="storagePools")
    def storage_pools(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The list of Storage Pools where boot disks are provisioned.
        """
        return pulumi.get(self, "storage_pools")

    @storage_pools.setter
    def storage_pools(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "storage_pools", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The list of instance tags applied to all nodes.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter
    def taints(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigTaintArgs']]]]:
        """
        List of Kubernetes taints to be applied to each node.
        """
        return pulumi.get(self, "taints")

    @taints.setter
    def taints(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigTaintArgs']]]]):
        pulumi.set(self, "taints", value)

    @property
    @pulumi.getter(name="windowsNodeConfig")
    def windows_node_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigWindowsNodeConfigArgs']]:
        """
        Parameters that can be configured on Windows nodes.
        """
        return pulumi.get(self, "windows_node_config")

    @windows_node_config.setter
    def windows_node_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigWindowsNodeConfigArgs']]):
        pulumi.set(self, "windows_node_config", value)

    @property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigWorkloadMetadataConfigArgs']]:
        """
        The workload metadata configuration for this node.
        """
        return pulumi.get(self, "workload_metadata_config")

    @workload_metadata_config.setter
    def workload_metadata_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigWorkloadMetadataConfigArgs']]):
        pulumi.set(self, "workload_metadata_config", value)


if not MYPY:
    class NodePoolNodeConfigAdvancedMachineFeaturesArgsDict(TypedDict):
        threads_per_core: pulumi.Input[builtins.int]
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        enable_nested_virtualization: NotRequired[pulumi.Input[builtins.bool]]
        """
        Whether the node should have nested virtualization enabled.
        """
elif False:
    NodePoolNodeConfigAdvancedMachineFeaturesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigAdvancedMachineFeaturesArgs:
    def __init__(__self__, *,
                 threads_per_core: pulumi.Input[builtins.int],
                 enable_nested_virtualization: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.int] threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        :param pulumi.Input[builtins.bool] enable_nested_virtualization: Whether the node should have nested virtualization enabled.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)
        if enable_nested_virtualization is not None:
            pulumi.set(__self__, "enable_nested_virtualization", enable_nested_virtualization)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> pulumi.Input[builtins.int]:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")

    @threads_per_core.setter
    def threads_per_core(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "threads_per_core", value)

    @property
    @pulumi.getter(name="enableNestedVirtualization")
    def enable_nested_virtualization(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether the node should have nested virtualization enabled.
        """
        return pulumi.get(self, "enable_nested_virtualization")

    @enable_nested_virtualization.setter
    def enable_nested_virtualization(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_nested_virtualization", value)


if not MYPY:
    class NodePoolNodeConfigConfidentialNodesArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
elif False:
    NodePoolNodeConfigConfidentialNodesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigConfidentialNodesArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether Confidential Nodes feature is enabled for all nodes in this pool.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class NodePoolNodeConfigContainerdConfigArgsDict(TypedDict):
        private_registry_access_config: NotRequired[pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgsDict']]
        """
        Parameters for private container registries configuration.
        """
elif False:
    NodePoolNodeConfigContainerdConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigContainerdConfigArgs:
    def __init__(__self__, *,
                 private_registry_access_config: Optional[pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs']] = None):
        """
        :param pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs'] private_registry_access_config: Parameters for private container registries configuration.
        """
        if private_registry_access_config is not None:
            pulumi.set(__self__, "private_registry_access_config", private_registry_access_config)

    @property
    @pulumi.getter(name="privateRegistryAccessConfig")
    def private_registry_access_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs']]:
        """
        Parameters for private container registries configuration.
        """
        return pulumi.get(self, "private_registry_access_config")

    @private_registry_access_config.setter
    def private_registry_access_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs']]):
        pulumi.set(self, "private_registry_access_config", value)


if not MYPY:
    class NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not private registries are configured.
        """
        certificate_authority_domain_configs: NotRequired[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict']]]]
        """
        Parameters for configuring CA certificate and domains.
        """
elif False:
    NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool],
                 certificate_authority_domain_configs: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]]] = None):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not private registries are configured.
        :param pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]] certificate_authority_domain_configs: Parameters for configuring CA certificate and domains.
        """
        pulumi.set(__self__, "enabled", enabled)
        if certificate_authority_domain_configs is not None:
            pulumi.set(__self__, "certificate_authority_domain_configs", certificate_authority_domain_configs)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not private registries are configured.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter(name="certificateAuthorityDomainConfigs")
    def certificate_authority_domain_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]]]:
        """
        Parameters for configuring CA certificate and domains.
        """
        return pulumi.get(self, "certificate_authority_domain_configs")

    @certificate_authority_domain_configs.setter
    def certificate_authority_domain_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs']]]]):
        pulumi.set(self, "certificate_authority_domain_configs", value)


if not MYPY:
    class NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict(TypedDict):
        fqdns: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        gcp_secret_manager_certificate_config: pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict']
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
elif False:
    NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigArgs:
    def __init__(__self__, *,
                 fqdns: pulumi.Input[Sequence[pulumi.Input[builtins.str]]],
                 gcp_secret_manager_certificate_config: pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs']):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] fqdns: List of fully-qualified-domain-names. IPv4s and port specification are supported.
        :param pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs'] gcp_secret_manager_certificate_config: Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        pulumi.set(__self__, "fqdns", fqdns)
        pulumi.set(__self__, "gcp_secret_manager_certificate_config", gcp_secret_manager_certificate_config)

    @property
    @pulumi.getter
    def fqdns(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        List of fully-qualified-domain-names. IPv4s and port specification are supported.
        """
        return pulumi.get(self, "fqdns")

    @fqdns.setter
    def fqdns(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "fqdns", value)

    @property
    @pulumi.getter(name="gcpSecretManagerCertificateConfig")
    def gcp_secret_manager_certificate_config(self) -> pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs']:
        """
        Parameters for configuring a certificate hosted in GCP SecretManager.
        """
        return pulumi.get(self, "gcp_secret_manager_certificate_config")

    @gcp_secret_manager_certificate_config.setter
    def gcp_secret_manager_certificate_config(self, value: pulumi.Input['NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs']):
        pulumi.set(self, "gcp_secret_manager_certificate_config", value)


if not MYPY:
    class NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict(TypedDict):
        secret_uri: pulumi.Input[builtins.str]
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
elif False:
    NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigContainerdConfigPrivateRegistryAccessConfigCertificateAuthorityDomainConfigGcpSecretManagerCertificateConfigArgs:
    def __init__(__self__, *,
                 secret_uri: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] secret_uri: URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        pulumi.set(__self__, "secret_uri", secret_uri)

    @property
    @pulumi.getter(name="secretUri")
    def secret_uri(self) -> pulumi.Input[builtins.str]:
        """
        URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.
        """
        return pulumi.get(self, "secret_uri")

    @secret_uri.setter
    def secret_uri(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "secret_uri", value)


if not MYPY:
    class NodePoolNodeConfigEffectiveTaintArgsDict(TypedDict):
        effect: NotRequired[pulumi.Input[builtins.str]]
        """
        Effect for taint.
        """
        key: NotRequired[pulumi.Input[builtins.str]]
        """
        Key for taint.
        """
        value: NotRequired[pulumi.Input[builtins.str]]
        """
        Value for taint.
        """
elif False:
    NodePoolNodeConfigEffectiveTaintArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigEffectiveTaintArgs:
    def __init__(__self__, *,
                 effect: Optional[pulumi.Input[builtins.str]] = None,
                 key: Optional[pulumi.Input[builtins.str]] = None,
                 value: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] effect: Effect for taint.
        :param pulumi.Input[builtins.str] key: Key for taint.
        :param pulumi.Input[builtins.str] value: Value for taint.
        """
        if effect is not None:
            pulumi.set(__self__, "effect", effect)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @effect.setter
    def effect(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "effect", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "value", value)


if not MYPY:
    class NodePoolNodeConfigEphemeralStorageConfigArgsDict(TypedDict):
        local_ssd_count: pulumi.Input[builtins.int]
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
elif False:
    NodePoolNodeConfigEphemeralStorageConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigEphemeralStorageConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.int] local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[builtins.int]:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "local_ssd_count", value)


if not MYPY:
    class NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgsDict(TypedDict):
        local_ssd_count: pulumi.Input[builtins.int]
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        data_cache_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Number of local SSDs to be utilized for GKE Data Cache. Uses NVMe interfaces.
        """
elif False:
    NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[builtins.int],
                 data_cache_count: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.int] local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        :param pulumi.Input[builtins.int] data_cache_count: Number of local SSDs to be utilized for GKE Data Cache. Uses NVMe interfaces.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if data_cache_count is not None:
            pulumi.set(__self__, "data_cache_count", data_cache_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[builtins.int]:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "local_ssd_count", value)

    @property
    @pulumi.getter(name="dataCacheCount")
    def data_cache_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Number of local SSDs to be utilized for GKE Data Cache. Uses NVMe interfaces.
        """
        return pulumi.get(self, "data_cache_count")

    @data_cache_count.setter
    def data_cache_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "data_cache_count", value)


if not MYPY:
    class NodePoolNodeConfigFastSocketArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not NCCL Fast Socket is enabled
        """
elif False:
    NodePoolNodeConfigFastSocketArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigFastSocketArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class NodePoolNodeConfigGcfsConfigArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not GCFS is enabled
        """
elif False:
    NodePoolNodeConfigGcfsConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigGcfsConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not GCFS is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not GCFS is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class NodePoolNodeConfigGuestAcceleratorArgsDict(TypedDict):
        count: pulumi.Input[builtins.int]
        """
        The number of the accelerator cards exposed to an instance.
        """
        type: pulumi.Input[builtins.str]
        """
        The accelerator type resource name.
        """
        gpu_driver_installation_config: NotRequired[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgsDict']]
        """
        Configuration for auto installation of GPU driver.
        """
        gpu_partition_size: NotRequired[pulumi.Input[builtins.str]]
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        """
        gpu_sharing_config: NotRequired[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgsDict']]
        """
        Configuration for GPU sharing.
        """
elif False:
    NodePoolNodeConfigGuestAcceleratorArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigGuestAcceleratorArgs:
    def __init__(__self__, *,
                 count: pulumi.Input[builtins.int],
                 type: pulumi.Input[builtins.str],
                 gpu_driver_installation_config: Optional[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']] = None,
                 gpu_partition_size: Optional[pulumi.Input[builtins.str]] = None,
                 gpu_sharing_config: Optional[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs']] = None):
        """
        :param pulumi.Input[builtins.int] count: The number of the accelerator cards exposed to an instance.
        :param pulumi.Input[builtins.str] type: The accelerator type resource name.
        :param pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs'] gpu_driver_installation_config: Configuration for auto installation of GPU driver.
        :param pulumi.Input[builtins.str] gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        :param pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs'] gpu_sharing_config: Configuration for GPU sharing.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @property
    @pulumi.getter
    def count(self) -> pulumi.Input[builtins.int]:
        """
        The number of the accelerator cards exposed to an instance.
        """
        return pulumi.get(self, "count")

    @count.setter
    def count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "count", value)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input[builtins.str]:
        """
        The accelerator type resource name.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']]:
        """
        Configuration for auto installation of GPU driver.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @gpu_driver_installation_config.setter
    def gpu_driver_installation_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']]):
        pulumi.set(self, "gpu_driver_installation_config", value)

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)
        """
        return pulumi.get(self, "gpu_partition_size")

    @gpu_partition_size.setter
    def gpu_partition_size(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "gpu_partition_size", value)

    @property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs']]:
        """
        Configuration for GPU sharing.
        """
        return pulumi.get(self, "gpu_sharing_config")

    @gpu_sharing_config.setter
    def gpu_sharing_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs']]):
        pulumi.set(self, "gpu_sharing_config", value)


if not MYPY:
    class NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgsDict(TypedDict):
        gpu_driver_version: pulumi.Input[builtins.str]
        """
        Mode for how the GPU driver is installed.
        """
elif False:
    NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs:
    def __init__(__self__, *,
                 gpu_driver_version: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] gpu_driver_version: Mode for how the GPU driver is installed.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> pulumi.Input[builtins.str]:
        """
        Mode for how the GPU driver is installed.
        """
        return pulumi.get(self, "gpu_driver_version")

    @gpu_driver_version.setter
    def gpu_driver_version(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "gpu_driver_version", value)


if not MYPY:
    class NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgsDict(TypedDict):
        gpu_sharing_strategy: pulumi.Input[builtins.str]
        """
        The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        """
        max_shared_clients_per_gpu: pulumi.Input[builtins.int]
        """
        The maximum number of containers that can share a GPU.
        """
elif False:
    NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs:
    def __init__(__self__, *,
                 gpu_sharing_strategy: pulumi.Input[builtins.str],
                 max_shared_clients_per_gpu: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.str] gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        :param pulumi.Input[builtins.int] max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> pulumi.Input[builtins.str]:
        """
        The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @gpu_sharing_strategy.setter
    def gpu_sharing_strategy(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "gpu_sharing_strategy", value)

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> pulumi.Input[builtins.int]:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")

    @max_shared_clients_per_gpu.setter
    def max_shared_clients_per_gpu(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "max_shared_clients_per_gpu", value)


if not MYPY:
    class NodePoolNodeConfigGvnicArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Whether or not gvnic is enabled
        """
elif False:
    NodePoolNodeConfigGvnicArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigGvnicArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Whether or not gvnic is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Whether or not gvnic is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class NodePoolNodeConfigHostMaintenancePolicyArgsDict(TypedDict):
        maintenance_interval: pulumi.Input[builtins.str]
        """
        .
        """
elif False:
    NodePoolNodeConfigHostMaintenancePolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigHostMaintenancePolicyArgs:
    def __init__(__self__, *,
                 maintenance_interval: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] maintenance_interval: .
        """
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> pulumi.Input[builtins.str]:
        """
        .
        """
        return pulumi.get(self, "maintenance_interval")

    @maintenance_interval.setter
    def maintenance_interval(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "maintenance_interval", value)


if not MYPY:
    class NodePoolNodeConfigKubeletConfigArgsDict(TypedDict):
        allowed_unsafe_sysctls: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods.
        """
        container_log_max_files: NotRequired[pulumi.Input[builtins.int]]
        """
        Defines the maximum number of container log files that can be present for a container.
        """
        container_log_max_size: NotRequired[pulumi.Input[builtins.str]]
        """
        Defines the maximum size of the container log file before it is rotated.
        """
        cpu_cfs_quota: NotRequired[pulumi.Input[builtins.bool]]
        """
        Enable CPU CFS quota enforcement for containers that specify CPU limits.
        """
        cpu_cfs_quota_period: NotRequired[pulumi.Input[builtins.str]]
        """
        Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        """
        cpu_manager_policy: NotRequired[pulumi.Input[builtins.str]]
        """
        Control the CPU management policy on the node.
        """
        image_gc_high_threshold_percent: NotRequired[pulumi.Input[builtins.int]]
        """
        Defines the percent of disk usage after which image garbage collection is always run.
        """
        image_gc_low_threshold_percent: NotRequired[pulumi.Input[builtins.int]]
        """
        Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to.
        """
        image_maximum_gc_age: NotRequired[pulumi.Input[builtins.str]]
        """
        Defines the maximum age an image can be unused before it is garbage collected.
        """
        image_minimum_gc_age: NotRequired[pulumi.Input[builtins.str]]
        """
        Defines the minimum age for an unused image before it is garbage collected.
        """
        insecure_kubelet_readonly_port_enabled: NotRequired[pulumi.Input[builtins.str]]
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        pod_pids_limit: NotRequired[pulumi.Input[builtins.int]]
        """
        Controls the maximum number of processes allowed to run in a pod.
        """
elif False:
    NodePoolNodeConfigKubeletConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigKubeletConfigArgs:
    def __init__(__self__, *,
                 allowed_unsafe_sysctls: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 container_log_max_files: Optional[pulumi.Input[builtins.int]] = None,
                 container_log_max_size: Optional[pulumi.Input[builtins.str]] = None,
                 cpu_cfs_quota: Optional[pulumi.Input[builtins.bool]] = None,
                 cpu_cfs_quota_period: Optional[pulumi.Input[builtins.str]] = None,
                 cpu_manager_policy: Optional[pulumi.Input[builtins.str]] = None,
                 image_gc_high_threshold_percent: Optional[pulumi.Input[builtins.int]] = None,
                 image_gc_low_threshold_percent: Optional[pulumi.Input[builtins.int]] = None,
                 image_maximum_gc_age: Optional[pulumi.Input[builtins.str]] = None,
                 image_minimum_gc_age: Optional[pulumi.Input[builtins.str]] = None,
                 insecure_kubelet_readonly_port_enabled: Optional[pulumi.Input[builtins.str]] = None,
                 pod_pids_limit: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] allowed_unsafe_sysctls: Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods.
        :param pulumi.Input[builtins.int] container_log_max_files: Defines the maximum number of container log files that can be present for a container.
        :param pulumi.Input[builtins.str] container_log_max_size: Defines the maximum size of the container log file before it is rotated.
        :param pulumi.Input[builtins.bool] cpu_cfs_quota: Enable CPU CFS quota enforcement for containers that specify CPU limits.
        :param pulumi.Input[builtins.str] cpu_cfs_quota_period: Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        :param pulumi.Input[builtins.str] cpu_manager_policy: Control the CPU management policy on the node.
        :param pulumi.Input[builtins.int] image_gc_high_threshold_percent: Defines the percent of disk usage after which image garbage collection is always run.
        :param pulumi.Input[builtins.int] image_gc_low_threshold_percent: Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to.
        :param pulumi.Input[builtins.str] image_maximum_gc_age: Defines the maximum age an image can be unused before it is garbage collected.
        :param pulumi.Input[builtins.str] image_minimum_gc_age: Defines the minimum age for an unused image before it is garbage collected.
        :param pulumi.Input[builtins.str] insecure_kubelet_readonly_port_enabled: Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        :param pulumi.Input[builtins.int] pod_pids_limit: Controls the maximum number of processes allowed to run in a pod.
        """
        if allowed_unsafe_sysctls is not None:
            pulumi.set(__self__, "allowed_unsafe_sysctls", allowed_unsafe_sysctls)
        if container_log_max_files is not None:
            pulumi.set(__self__, "container_log_max_files", container_log_max_files)
        if container_log_max_size is not None:
            pulumi.set(__self__, "container_log_max_size", container_log_max_size)
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if cpu_manager_policy is not None:
            pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if image_gc_high_threshold_percent is not None:
            pulumi.set(__self__, "image_gc_high_threshold_percent", image_gc_high_threshold_percent)
        if image_gc_low_threshold_percent is not None:
            pulumi.set(__self__, "image_gc_low_threshold_percent", image_gc_low_threshold_percent)
        if image_maximum_gc_age is not None:
            pulumi.set(__self__, "image_maximum_gc_age", image_maximum_gc_age)
        if image_minimum_gc_age is not None:
            pulumi.set(__self__, "image_minimum_gc_age", image_minimum_gc_age)
        if insecure_kubelet_readonly_port_enabled is not None:
            pulumi.set(__self__, "insecure_kubelet_readonly_port_enabled", insecure_kubelet_readonly_port_enabled)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="allowedUnsafeSysctls")
    def allowed_unsafe_sysctls(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods.
        """
        return pulumi.get(self, "allowed_unsafe_sysctls")

    @allowed_unsafe_sysctls.setter
    def allowed_unsafe_sysctls(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "allowed_unsafe_sysctls", value)

    @property
    @pulumi.getter(name="containerLogMaxFiles")
    def container_log_max_files(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Defines the maximum number of container log files that can be present for a container.
        """
        return pulumi.get(self, "container_log_max_files")

    @container_log_max_files.setter
    def container_log_max_files(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "container_log_max_files", value)

    @property
    @pulumi.getter(name="containerLogMaxSize")
    def container_log_max_size(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Defines the maximum size of the container log file before it is rotated.
        """
        return pulumi.get(self, "container_log_max_size")

    @container_log_max_size.setter
    def container_log_max_size(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "container_log_max_size", value)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Enable CPU CFS quota enforcement for containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @cpu_cfs_quota.setter
    def cpu_cfs_quota(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "cpu_cfs_quota", value)

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Set the CPU CFS quota period value 'cpu.cfs_period_us'.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @cpu_cfs_quota_period.setter
    def cpu_cfs_quota_period(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cpu_cfs_quota_period", value)

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Control the CPU management policy on the node.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @cpu_manager_policy.setter
    def cpu_manager_policy(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cpu_manager_policy", value)

    @property
    @pulumi.getter(name="imageGcHighThresholdPercent")
    def image_gc_high_threshold_percent(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Defines the percent of disk usage after which image garbage collection is always run.
        """
        return pulumi.get(self, "image_gc_high_threshold_percent")

    @image_gc_high_threshold_percent.setter
    def image_gc_high_threshold_percent(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "image_gc_high_threshold_percent", value)

    @property
    @pulumi.getter(name="imageGcLowThresholdPercent")
    def image_gc_low_threshold_percent(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to.
        """
        return pulumi.get(self, "image_gc_low_threshold_percent")

    @image_gc_low_threshold_percent.setter
    def image_gc_low_threshold_percent(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "image_gc_low_threshold_percent", value)

    @property
    @pulumi.getter(name="imageMaximumGcAge")
    def image_maximum_gc_age(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Defines the maximum age an image can be unused before it is garbage collected.
        """
        return pulumi.get(self, "image_maximum_gc_age")

    @image_maximum_gc_age.setter
    def image_maximum_gc_age(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "image_maximum_gc_age", value)

    @property
    @pulumi.getter(name="imageMinimumGcAge")
    def image_minimum_gc_age(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Defines the minimum age for an unused image before it is garbage collected.
        """
        return pulumi.get(self, "image_minimum_gc_age")

    @image_minimum_gc_age.setter
    def image_minimum_gc_age(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "image_minimum_gc_age", value)

    @property
    @pulumi.getter(name="insecureKubeletReadonlyPortEnabled")
    def insecure_kubelet_readonly_port_enabled(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.
        """
        return pulumi.get(self, "insecure_kubelet_readonly_port_enabled")

    @insecure_kubelet_readonly_port_enabled.setter
    def insecure_kubelet_readonly_port_enabled(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "insecure_kubelet_readonly_port_enabled", value)

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Controls the maximum number of processes allowed to run in a pod.
        """
        return pulumi.get(self, "pod_pids_limit")

    @pod_pids_limit.setter
    def pod_pids_limit(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "pod_pids_limit", value)


if not MYPY:
    class NodePoolNodeConfigLinuxNodeConfigArgsDict(TypedDict):
        cgroup_mode: NotRequired[pulumi.Input[builtins.str]]
        """
        cgroupMode specifies the cgroup mode to be used on the node.
        """
        hugepages_config: NotRequired[pulumi.Input['NodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgsDict']]
        """
        Amounts for 2M and 1G hugepages.
        """
        sysctls: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]
        """
        The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        """
elif False:
    NodePoolNodeConfigLinuxNodeConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigLinuxNodeConfigArgs:
    def __init__(__self__, *,
                 cgroup_mode: Optional[pulumi.Input[builtins.str]] = None,
                 hugepages_config: Optional[pulumi.Input['NodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs']] = None,
                 sysctls: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[builtins.str] cgroup_mode: cgroupMode specifies the cgroup mode to be used on the node.
        :param pulumi.Input['NodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs'] hugepages_config: Amounts for 2M and 1G hugepages.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] sysctls: The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        """
        if cgroup_mode is not None:
            pulumi.set(__self__, "cgroup_mode", cgroup_mode)
        if hugepages_config is not None:
            pulumi.set(__self__, "hugepages_config", hugepages_config)
        if sysctls is not None:
            pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter(name="cgroupMode")
    def cgroup_mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        cgroupMode specifies the cgroup mode to be used on the node.
        """
        return pulumi.get(self, "cgroup_mode")

    @cgroup_mode.setter
    def cgroup_mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cgroup_mode", value)

    @property
    @pulumi.getter(name="hugepagesConfig")
    def hugepages_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs']]:
        """
        Amounts for 2M and 1G hugepages.
        """
        return pulumi.get(self, "hugepages_config")

    @hugepages_config.setter
    def hugepages_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs']]):
        pulumi.set(self, "hugepages_config", value)

    @property
    @pulumi.getter
    def sysctls(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.
        """
        return pulumi.get(self, "sysctls")

    @sysctls.setter
    def sysctls(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "sysctls", value)


if not MYPY:
    class NodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgsDict(TypedDict):
        hugepage_size1g: NotRequired[pulumi.Input[builtins.int]]
        """
        Amount of 1G hugepages.
        """
        hugepage_size2m: NotRequired[pulumi.Input[builtins.int]]
        """
        Amount of 2M hugepages.
        """
elif False:
    NodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigLinuxNodeConfigHugepagesConfigArgs:
    def __init__(__self__, *,
                 hugepage_size1g: Optional[pulumi.Input[builtins.int]] = None,
                 hugepage_size2m: Optional[pulumi.Input[builtins.int]] = None):
        """
        :param pulumi.Input[builtins.int] hugepage_size1g: Amount of 1G hugepages.
        :param pulumi.Input[builtins.int] hugepage_size2m: Amount of 2M hugepages.
        """
        if hugepage_size1g is not None:
            pulumi.set(__self__, "hugepage_size1g", hugepage_size1g)
        if hugepage_size2m is not None:
            pulumi.set(__self__, "hugepage_size2m", hugepage_size2m)

    @property
    @pulumi.getter(name="hugepageSize1g")
    def hugepage_size1g(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Amount of 1G hugepages.
        """
        return pulumi.get(self, "hugepage_size1g")

    @hugepage_size1g.setter
    def hugepage_size1g(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "hugepage_size1g", value)

    @property
    @pulumi.getter(name="hugepageSize2m")
    def hugepage_size2m(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Amount of 2M hugepages.
        """
        return pulumi.get(self, "hugepage_size2m")

    @hugepage_size2m.setter
    def hugepage_size2m(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "hugepage_size2m", value)


if not MYPY:
    class NodePoolNodeConfigLocalNvmeSsdBlockConfigArgsDict(TypedDict):
        local_ssd_count: pulumi.Input[builtins.int]
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
elif False:
    NodePoolNodeConfigLocalNvmeSsdBlockConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[builtins.int]):
        """
        :param pulumi.Input[builtins.int] local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[builtins.int]:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[builtins.int]):
        pulumi.set(self, "local_ssd_count", value)


if not MYPY:
    class NodePoolNodeConfigReservationAffinityArgsDict(TypedDict):
        consume_reservation_type: pulumi.Input[builtins.str]
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        key: NotRequired[pulumi.Input[builtins.str]]
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        values: NotRequired[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
elif False:
    NodePoolNodeConfigReservationAffinityArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigReservationAffinityArgs:
    def __init__(__self__, *,
                 consume_reservation_type: pulumi.Input[builtins.str],
                 key: Optional[pulumi.Input[builtins.str]] = None,
                 values: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None):
        """
        :param pulumi.Input[builtins.str] consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param pulumi.Input[builtins.str] key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> pulumi.Input[builtins.str]:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @consume_reservation_type.setter
    def consume_reservation_type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "consume_reservation_type", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "values", value)


if not MYPY:
    class NodePoolNodeConfigSandboxConfigArgsDict(TypedDict):
        sandbox_type: pulumi.Input[builtins.str]
        """
        Type of the sandbox to use for the node (e.g. 'gvisor')
        """
elif False:
    NodePoolNodeConfigSandboxConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigSandboxConfigArgs:
    def __init__(__self__, *,
                 sandbox_type: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] sandbox_type: Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> pulumi.Input[builtins.str]:
        """
        Type of the sandbox to use for the node (e.g. 'gvisor')
        """
        return pulumi.get(self, "sandbox_type")

    @sandbox_type.setter
    def sandbox_type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "sandbox_type", value)


if not MYPY:
    class NodePoolNodeConfigSecondaryBootDiskArgsDict(TypedDict):
        disk_image: pulumi.Input[builtins.str]
        """
        Disk image to create the secondary boot disk from
        """
        mode: NotRequired[pulumi.Input[builtins.str]]
        """
        Mode for how the secondary boot disk is used.
        """
elif False:
    NodePoolNodeConfigSecondaryBootDiskArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigSecondaryBootDiskArgs:
    def __init__(__self__, *,
                 disk_image: pulumi.Input[builtins.str],
                 mode: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] disk_image: Disk image to create the secondary boot disk from
        :param pulumi.Input[builtins.str] mode: Mode for how the secondary boot disk is used.
        """
        pulumi.set(__self__, "disk_image", disk_image)
        if mode is not None:
            pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter(name="diskImage")
    def disk_image(self) -> pulumi.Input[builtins.str]:
        """
        Disk image to create the secondary boot disk from
        """
        return pulumi.get(self, "disk_image")

    @disk_image.setter
    def disk_image(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "disk_image", value)

    @property
    @pulumi.getter
    def mode(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Mode for how the secondary boot disk is used.
        """
        return pulumi.get(self, "mode")

    @mode.setter
    def mode(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "mode", value)


if not MYPY:
    class NodePoolNodeConfigShieldedInstanceConfigArgsDict(TypedDict):
        enable_integrity_monitoring: NotRequired[pulumi.Input[builtins.bool]]
        """
        Defines whether the instance has integrity monitoring enabled.
        """
        enable_secure_boot: NotRequired[pulumi.Input[builtins.bool]]
        """
        Defines whether the instance has Secure Boot enabled.
        """
elif False:
    NodePoolNodeConfigShieldedInstanceConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigShieldedInstanceConfigArgs:
    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[pulumi.Input[builtins.bool]] = None,
                 enable_secure_boot: Optional[pulumi.Input[builtins.bool]] = None):
        """
        :param pulumi.Input[builtins.bool] enable_integrity_monitoring: Defines whether the instance has integrity monitoring enabled.
        :param pulumi.Input[builtins.bool] enable_secure_boot: Defines whether the instance has Secure Boot enabled.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Defines whether the instance has integrity monitoring enabled.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @enable_integrity_monitoring.setter
    def enable_integrity_monitoring(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_integrity_monitoring", value)

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Defines whether the instance has Secure Boot enabled.
        """
        return pulumi.get(self, "enable_secure_boot")

    @enable_secure_boot.setter
    def enable_secure_boot(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "enable_secure_boot", value)


if not MYPY:
    class NodePoolNodeConfigSoleTenantConfigArgsDict(TypedDict):
        node_affinities: pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSoleTenantConfigNodeAffinityArgsDict']]]
        """
        .
        """
elif False:
    NodePoolNodeConfigSoleTenantConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigSoleTenantConfigArgs:
    def __init__(__self__, *,
                 node_affinities: pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]] node_affinities: .
        """
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]]:
        """
        .
        """
        return pulumi.get(self, "node_affinities")

    @node_affinities.setter
    def node_affinities(self, value: pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]]):
        pulumi.set(self, "node_affinities", value)


if not MYPY:
    class NodePoolNodeConfigSoleTenantConfigNodeAffinityArgsDict(TypedDict):
        key: pulumi.Input[builtins.str]
        """
        .
        """
        operator: pulumi.Input[builtins.str]
        """
        .
        """
        values: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]
        """
        .
        """
elif False:
    NodePoolNodeConfigSoleTenantConfigNodeAffinityArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs:
    def __init__(__self__, *,
                 key: pulumi.Input[builtins.str],
                 operator: pulumi.Input[builtins.str],
                 values: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        """
        :param pulumi.Input[builtins.str] key: .
        :param pulumi.Input[builtins.str] operator: .
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] values: .
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[builtins.str]:
        """
        .
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def operator(self) -> pulumi.Input[builtins.str]:
        """
        .
        """
        return pulumi.get(self, "operator")

    @operator.setter
    def operator(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "operator", value)

    @property
    @pulumi.getter
    def values(self) -> pulumi.Input[Sequence[pulumi.Input[builtins.str]]]:
        """
        .
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: pulumi.Input[Sequence[pulumi.Input[builtins.str]]]):
        pulumi.set(self, "values", value)


if not MYPY:
    class NodePoolNodeConfigTaintArgsDict(TypedDict):
        effect: pulumi.Input[builtins.str]
        """
        Effect for taint.
        """
        key: pulumi.Input[builtins.str]
        """
        Key for taint.
        """
        value: pulumi.Input[builtins.str]
        """
        Value for taint.
        """
elif False:
    NodePoolNodeConfigTaintArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigTaintArgs:
    def __init__(__self__, *,
                 effect: pulumi.Input[builtins.str],
                 key: pulumi.Input[builtins.str],
                 value: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] effect: Effect for taint.
        :param pulumi.Input[builtins.str] key: Key for taint.
        :param pulumi.Input[builtins.str] value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> pulumi.Input[builtins.str]:
        """
        Effect for taint.
        """
        return pulumi.get(self, "effect")

    @effect.setter
    def effect(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "effect", value)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[builtins.str]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[builtins.str]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "value", value)


if not MYPY:
    class NodePoolNodeConfigWindowsNodeConfigArgsDict(TypedDict):
        osversion: NotRequired[pulumi.Input[builtins.str]]
        """
        The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
elif False:
    NodePoolNodeConfigWindowsNodeConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigWindowsNodeConfigArgs:
    def __init__(__self__, *,
                 osversion: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] osversion: The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        if osversion is not None:
            pulumi.set(__self__, "osversion", osversion)

    @property
    @pulumi.getter
    def osversion(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022
        """
        return pulumi.get(self, "osversion")

    @osversion.setter
    def osversion(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "osversion", value)


if not MYPY:
    class NodePoolNodeConfigWorkloadMetadataConfigArgsDict(TypedDict):
        mode: pulumi.Input[builtins.str]
        """
        Mode is the configuration for how to expose metadata to workloads running on the node.
        """
elif False:
    NodePoolNodeConfigWorkloadMetadataConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolNodeConfigWorkloadMetadataConfigArgs:
    def __init__(__self__, *,
                 mode: pulumi.Input[builtins.str]):
        """
        :param pulumi.Input[builtins.str] mode: Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> pulumi.Input[builtins.str]:
        """
        Mode is the configuration for how to expose metadata to workloads running on the node.
        """
        return pulumi.get(self, "mode")

    @mode.setter
    def mode(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "mode", value)


if not MYPY:
    class NodePoolPlacementPolicyArgsDict(TypedDict):
        type: pulumi.Input[builtins.str]
        """
        The type of the policy. Supports a single value: COMPACT.
        Specifying COMPACT placement policy type places node pool's nodes in a closer
        physical proximity in order to reduce network latency between nodes.
        """
        policy_name: NotRequired[pulumi.Input[builtins.str]]
        """
        If set, refers to the name of a custom resource policy supplied by the user.
        The resource policy must be in the same project and region as the node pool.
        If not found, InvalidArgument error is returned.
        """
        tpu_topology: NotRequired[pulumi.Input[builtins.str]]
        """
        The [TPU placement topology](https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies) for pod slice node pool.
        """
elif False:
    NodePoolPlacementPolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolPlacementPolicyArgs:
    def __init__(__self__, *,
                 type: pulumi.Input[builtins.str],
                 policy_name: Optional[pulumi.Input[builtins.str]] = None,
                 tpu_topology: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.str] type: The type of the policy. Supports a single value: COMPACT.
               Specifying COMPACT placement policy type places node pool's nodes in a closer
               physical proximity in order to reduce network latency between nodes.
        :param pulumi.Input[builtins.str] policy_name: If set, refers to the name of a custom resource policy supplied by the user.
               The resource policy must be in the same project and region as the node pool.
               If not found, InvalidArgument error is returned.
        :param pulumi.Input[builtins.str] tpu_topology: The [TPU placement topology](https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies) for pod slice node pool.
        """
        pulumi.set(__self__, "type", type)
        if policy_name is not None:
            pulumi.set(__self__, "policy_name", policy_name)
        if tpu_topology is not None:
            pulumi.set(__self__, "tpu_topology", tpu_topology)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input[builtins.str]:
        """
        The type of the policy. Supports a single value: COMPACT.
        Specifying COMPACT placement policy type places node pool's nodes in a closer
        physical proximity in order to reduce network latency between nodes.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        If set, refers to the name of a custom resource policy supplied by the user.
        The resource policy must be in the same project and region as the node pool.
        If not found, InvalidArgument error is returned.
        """
        return pulumi.get(self, "policy_name")

    @policy_name.setter
    def policy_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "policy_name", value)

    @property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The [TPU placement topology](https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies) for pod slice node pool.
        """
        return pulumi.get(self, "tpu_topology")

    @tpu_topology.setter
    def tpu_topology(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "tpu_topology", value)


if not MYPY:
    class NodePoolQueuedProvisioningArgsDict(TypedDict):
        enabled: pulumi.Input[builtins.bool]
        """
        Makes nodes obtainable through the [ProvisioningRequest API](https://cloud.google.com/kubernetes-engine/docs/how-to/provisioningrequest) exclusively.
        """
elif False:
    NodePoolQueuedProvisioningArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolQueuedProvisioningArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[builtins.bool]):
        """
        :param pulumi.Input[builtins.bool] enabled: Makes nodes obtainable through the [ProvisioningRequest API](https://cloud.google.com/kubernetes-engine/docs/how-to/provisioningrequest) exclusively.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[builtins.bool]:
        """
        Makes nodes obtainable through the [ProvisioningRequest API](https://cloud.google.com/kubernetes-engine/docs/how-to/provisioningrequest) exclusively.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[builtins.bool]):
        pulumi.set(self, "enabled", value)


if not MYPY:
    class NodePoolUpgradeSettingsArgsDict(TypedDict):
        blue_green_settings: NotRequired[pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsArgsDict']]
        """
        The settings to adjust [blue green upgrades](https://cloud.google.com/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy).
        Structure is documented below
        """
        max_surge: NotRequired[pulumi.Input[builtins.int]]
        """
        The number of additional nodes that can be added to the node pool during
        an upgrade. Increasing `max_surge` raises the number of nodes that can be upgraded simultaneously.
        Can be set to 0 or greater.
        """
        max_unavailable: NotRequired[pulumi.Input[builtins.int]]
        """
        The number of nodes that can be simultaneously unavailable during
        an upgrade. Increasing `max_unavailable` raises the number of nodes that can be upgraded in
        parallel. Can be set to 0 or greater.

        `max_surge` and `max_unavailable` must not be negative and at least one of them must be greater than zero.
        """
        strategy: NotRequired[pulumi.Input[builtins.str]]
        """
        The upgrade strategy to be used for upgrading the nodes.
        """
elif False:
    NodePoolUpgradeSettingsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolUpgradeSettingsArgs:
    def __init__(__self__, *,
                 blue_green_settings: Optional[pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsArgs']] = None,
                 max_surge: Optional[pulumi.Input[builtins.int]] = None,
                 max_unavailable: Optional[pulumi.Input[builtins.int]] = None,
                 strategy: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsArgs'] blue_green_settings: The settings to adjust [blue green upgrades](https://cloud.google.com/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy).
               Structure is documented below
        :param pulumi.Input[builtins.int] max_surge: The number of additional nodes that can be added to the node pool during
               an upgrade. Increasing `max_surge` raises the number of nodes that can be upgraded simultaneously.
               Can be set to 0 or greater.
        :param pulumi.Input[builtins.int] max_unavailable: The number of nodes that can be simultaneously unavailable during
               an upgrade. Increasing `max_unavailable` raises the number of nodes that can be upgraded in
               parallel. Can be set to 0 or greater.
               
               `max_surge` and `max_unavailable` must not be negative and at least one of them must be greater than zero.
        :param pulumi.Input[builtins.str] strategy: The upgrade strategy to be used for upgrading the nodes.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional[pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsArgs']]:
        """
        The settings to adjust [blue green upgrades](https://cloud.google.com/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy).
        Structure is documented below
        """
        return pulumi.get(self, "blue_green_settings")

    @blue_green_settings.setter
    def blue_green_settings(self, value: Optional[pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsArgs']]):
        pulumi.set(self, "blue_green_settings", value)

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The number of additional nodes that can be added to the node pool during
        an upgrade. Increasing `max_surge` raises the number of nodes that can be upgraded simultaneously.
        Can be set to 0 or greater.
        """
        return pulumi.get(self, "max_surge")

    @max_surge.setter
    def max_surge(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_surge", value)

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The number of nodes that can be simultaneously unavailable during
        an upgrade. Increasing `max_unavailable` raises the number of nodes that can be upgraded in
        parallel. Can be set to 0 or greater.

        `max_surge` and `max_unavailable` must not be negative and at least one of them must be greater than zero.
        """
        return pulumi.get(self, "max_unavailable")

    @max_unavailable.setter
    def max_unavailable(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "max_unavailable", value)

    @property
    @pulumi.getter
    def strategy(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The upgrade strategy to be used for upgrading the nodes.
        """
        return pulumi.get(self, "strategy")

    @strategy.setter
    def strategy(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "strategy", value)


if not MYPY:
    class NodePoolUpgradeSettingsBlueGreenSettingsArgsDict(TypedDict):
        standard_rollout_policy: pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgsDict']
        """
        Specifies the standard policy settings for blue-green upgrades.
        """
        node_pool_soak_duration: NotRequired[pulumi.Input[builtins.str]]
        """
        Time needed after draining the entire blue pool.
        After this period, the blue pool will be cleaned up.
        """
elif False:
    NodePoolUpgradeSettingsBlueGreenSettingsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolUpgradeSettingsBlueGreenSettingsArgs:
    def __init__(__self__, *,
                 standard_rollout_policy: pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs'],
                 node_pool_soak_duration: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs'] standard_rollout_policy: Specifies the standard policy settings for blue-green upgrades.
        :param pulumi.Input[builtins.str] node_pool_soak_duration: Time needed after draining the entire blue pool.
               After this period, the blue pool will be cleaned up.
        """
        pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)

    @property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']:
        """
        Specifies the standard policy settings for blue-green upgrades.
        """
        return pulumi.get(self, "standard_rollout_policy")

    @standard_rollout_policy.setter
    def standard_rollout_policy(self, value: pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']):
        pulumi.set(self, "standard_rollout_policy", value)

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Time needed after draining the entire blue pool.
        After this period, the blue pool will be cleaned up.
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @node_pool_soak_duration.setter
    def node_pool_soak_duration(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "node_pool_soak_duration", value)


if not MYPY:
    class NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgsDict(TypedDict):
        batch_node_count: NotRequired[pulumi.Input[builtins.int]]
        """
        Number of blue nodes to drain in a batch.
        """
        batch_percentage: NotRequired[pulumi.Input[builtins.float]]
        """
        Percentage of the blue pool nodes to drain in a batch.
        """
        batch_soak_duration: NotRequired[pulumi.Input[builtins.str]]
        """
        Soak time after each batch gets drained.
        """
elif False:
    NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs:
    def __init__(__self__, *,
                 batch_node_count: Optional[pulumi.Input[builtins.int]] = None,
                 batch_percentage: Optional[pulumi.Input[builtins.float]] = None,
                 batch_soak_duration: Optional[pulumi.Input[builtins.str]] = None):
        """
        :param pulumi.Input[builtins.int] batch_node_count: Number of blue nodes to drain in a batch.
        :param pulumi.Input[builtins.float] batch_percentage: Percentage of the blue pool nodes to drain in a batch.
        :param pulumi.Input[builtins.str] batch_soak_duration: Soak time after each batch gets drained.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        Number of blue nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_node_count")

    @batch_node_count.setter
    def batch_node_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "batch_node_count", value)

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[pulumi.Input[builtins.float]]:
        """
        Percentage of the blue pool nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_percentage")

    @batch_percentage.setter
    def batch_percentage(self, value: Optional[pulumi.Input[builtins.float]]):
        pulumi.set(self, "batch_percentage", value)

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Soak time after each batch gets drained.
        """
        return pulumi.get(self, "batch_soak_duration")

    @batch_soak_duration.setter
    def batch_soak_duration(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "batch_soak_duration", value)


