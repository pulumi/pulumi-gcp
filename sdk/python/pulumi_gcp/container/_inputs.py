# coding=utf-8
# *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import copy
import warnings
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
from .. import _utilities

__all__ = [
    'AttachedClusterAuthorizationArgs',
    'AttachedClusterBinaryAuthorizationArgs',
    'AttachedClusterErrorArgs',
    'AttachedClusterFleetArgs',
    'AttachedClusterLoggingConfigArgs',
    'AttachedClusterLoggingConfigComponentConfigArgs',
    'AttachedClusterMonitoringConfigArgs',
    'AttachedClusterMonitoringConfigManagedPrometheusConfigArgs',
    'AttachedClusterOidcConfigArgs',
    'AttachedClusterWorkloadIdentityConfigArgs',
    'AwsClusterAuthorizationArgs',
    'AwsClusterAuthorizationAdminUserArgs',
    'AwsClusterControlPlaneArgs',
    'AwsClusterControlPlaneAwsServicesAuthenticationArgs',
    'AwsClusterControlPlaneConfigEncryptionArgs',
    'AwsClusterControlPlaneDatabaseEncryptionArgs',
    'AwsClusterControlPlaneInstancePlacementArgs',
    'AwsClusterControlPlaneMainVolumeArgs',
    'AwsClusterControlPlaneProxyConfigArgs',
    'AwsClusterControlPlaneRootVolumeArgs',
    'AwsClusterControlPlaneSshConfigArgs',
    'AwsClusterFleetArgs',
    'AwsClusterLoggingConfigArgs',
    'AwsClusterLoggingConfigComponentConfigArgs',
    'AwsClusterNetworkingArgs',
    'AwsClusterWorkloadIdentityConfigArgs',
    'AwsNodePoolAutoscalingArgs',
    'AwsNodePoolConfigArgs',
    'AwsNodePoolConfigAutoscalingMetricsCollectionArgs',
    'AwsNodePoolConfigConfigEncryptionArgs',
    'AwsNodePoolConfigInstancePlacementArgs',
    'AwsNodePoolConfigProxyConfigArgs',
    'AwsNodePoolConfigRootVolumeArgs',
    'AwsNodePoolConfigSpotConfigArgs',
    'AwsNodePoolConfigSshConfigArgs',
    'AwsNodePoolConfigTaintArgs',
    'AwsNodePoolManagementArgs',
    'AwsNodePoolMaxPodsConstraintArgs',
    'AzureClusterAuthorizationArgs',
    'AzureClusterAuthorizationAdminUserArgs',
    'AzureClusterAzureServicesAuthenticationArgs',
    'AzureClusterControlPlaneArgs',
    'AzureClusterControlPlaneDatabaseEncryptionArgs',
    'AzureClusterControlPlaneMainVolumeArgs',
    'AzureClusterControlPlaneProxyConfigArgs',
    'AzureClusterControlPlaneReplicaPlacementArgs',
    'AzureClusterControlPlaneRootVolumeArgs',
    'AzureClusterControlPlaneSshConfigArgs',
    'AzureClusterFleetArgs',
    'AzureClusterLoggingConfigArgs',
    'AzureClusterLoggingConfigComponentConfigArgs',
    'AzureClusterNetworkingArgs',
    'AzureClusterWorkloadIdentityConfigArgs',
    'AzureNodePoolAutoscalingArgs',
    'AzureNodePoolConfigArgs',
    'AzureNodePoolConfigProxyConfigArgs',
    'AzureNodePoolConfigRootVolumeArgs',
    'AzureNodePoolConfigSshConfigArgs',
    'AzureNodePoolManagementArgs',
    'AzureNodePoolMaxPodsConstraintArgs',
    'ClusterAddonsConfigArgs',
    'ClusterAddonsConfigCloudrunConfigArgs',
    'ClusterAddonsConfigConfigConnectorConfigArgs',
    'ClusterAddonsConfigDnsCacheConfigArgs',
    'ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs',
    'ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs',
    'ClusterAddonsConfigGcsFuseCsiDriverConfigArgs',
    'ClusterAddonsConfigGkeBackupAgentConfigArgs',
    'ClusterAddonsConfigHorizontalPodAutoscalingArgs',
    'ClusterAddonsConfigHttpLoadBalancingArgs',
    'ClusterAddonsConfigIstioConfigArgs',
    'ClusterAddonsConfigKalmConfigArgs',
    'ClusterAddonsConfigNetworkPolicyConfigArgs',
    'ClusterAuthenticatorGroupsConfigArgs',
    'ClusterBinaryAuthorizationArgs',
    'ClusterClusterAutoscalingArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs',
    'ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs',
    'ClusterClusterAutoscalingResourceLimitArgs',
    'ClusterClusterTelemetryArgs',
    'ClusterConfidentialNodesArgs',
    'ClusterCostManagementConfigArgs',
    'ClusterDatabaseEncryptionArgs',
    'ClusterDefaultSnatStatusArgs',
    'ClusterDnsConfigArgs',
    'ClusterEnableK8sBetaApisArgs',
    'ClusterGatewayApiConfigArgs',
    'ClusterIdentityServiceConfigArgs',
    'ClusterIpAllocationPolicyArgs',
    'ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs',
    'ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs',
    'ClusterLoggingConfigArgs',
    'ClusterMaintenancePolicyArgs',
    'ClusterMaintenancePolicyDailyMaintenanceWindowArgs',
    'ClusterMaintenancePolicyMaintenanceExclusionArgs',
    'ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs',
    'ClusterMaintenancePolicyRecurringWindowArgs',
    'ClusterMasterAuthArgs',
    'ClusterMasterAuthClientCertificateConfigArgs',
    'ClusterMasterAuthorizedNetworksConfigArgs',
    'ClusterMasterAuthorizedNetworksConfigCidrBlockArgs',
    'ClusterMeshCertificatesArgs',
    'ClusterMonitoringConfigArgs',
    'ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs',
    'ClusterMonitoringConfigManagedPrometheusArgs',
    'ClusterNetworkPolicyArgs',
    'ClusterNodeConfigArgs',
    'ClusterNodeConfigAdvancedMachineFeaturesArgs',
    'ClusterNodeConfigConfidentialNodesArgs',
    'ClusterNodeConfigEphemeralStorageConfigArgs',
    'ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs',
    'ClusterNodeConfigFastSocketArgs',
    'ClusterNodeConfigGcfsConfigArgs',
    'ClusterNodeConfigGuestAcceleratorArgs',
    'ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs',
    'ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs',
    'ClusterNodeConfigGvnicArgs',
    'ClusterNodeConfigHostMaintenancePolicyArgs',
    'ClusterNodeConfigKubeletConfigArgs',
    'ClusterNodeConfigLinuxNodeConfigArgs',
    'ClusterNodeConfigLocalNvmeSsdBlockConfigArgs',
    'ClusterNodeConfigReservationAffinityArgs',
    'ClusterNodeConfigSandboxConfigArgs',
    'ClusterNodeConfigShieldedInstanceConfigArgs',
    'ClusterNodeConfigSoleTenantConfigArgs',
    'ClusterNodeConfigSoleTenantConfigNodeAffinityArgs',
    'ClusterNodeConfigTaintArgs',
    'ClusterNodeConfigWorkloadMetadataConfigArgs',
    'ClusterNodePoolArgs',
    'ClusterNodePoolAutoConfigArgs',
    'ClusterNodePoolAutoConfigNetworkTagsArgs',
    'ClusterNodePoolAutoscalingArgs',
    'ClusterNodePoolDefaultsArgs',
    'ClusterNodePoolDefaultsNodeConfigDefaultsArgs',
    'ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs',
    'ClusterNodePoolManagementArgs',
    'ClusterNodePoolNetworkConfigArgs',
    'ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs',
    'ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs',
    'ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs',
    'ClusterNodePoolNodeConfigArgs',
    'ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs',
    'ClusterNodePoolNodeConfigConfidentialNodesArgs',
    'ClusterNodePoolNodeConfigEphemeralStorageConfigArgs',
    'ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs',
    'ClusterNodePoolNodeConfigFastSocketArgs',
    'ClusterNodePoolNodeConfigGcfsConfigArgs',
    'ClusterNodePoolNodeConfigGuestAcceleratorArgs',
    'ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs',
    'ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs',
    'ClusterNodePoolNodeConfigGvnicArgs',
    'ClusterNodePoolNodeConfigHostMaintenancePolicyArgs',
    'ClusterNodePoolNodeConfigKubeletConfigArgs',
    'ClusterNodePoolNodeConfigLinuxNodeConfigArgs',
    'ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs',
    'ClusterNodePoolNodeConfigReservationAffinityArgs',
    'ClusterNodePoolNodeConfigSandboxConfigArgs',
    'ClusterNodePoolNodeConfigShieldedInstanceConfigArgs',
    'ClusterNodePoolNodeConfigSoleTenantConfigArgs',
    'ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs',
    'ClusterNodePoolNodeConfigTaintArgs',
    'ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs',
    'ClusterNodePoolPlacementPolicyArgs',
    'ClusterNodePoolUpgradeSettingsArgs',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs',
    'ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs',
    'ClusterNotificationConfigArgs',
    'ClusterNotificationConfigPubsubArgs',
    'ClusterNotificationConfigPubsubFilterArgs',
    'ClusterPodSecurityPolicyConfigArgs',
    'ClusterPrivateClusterConfigArgs',
    'ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs',
    'ClusterProtectConfigArgs',
    'ClusterProtectConfigWorkloadConfigArgs',
    'ClusterReleaseChannelArgs',
    'ClusterResourceUsageExportConfigArgs',
    'ClusterResourceUsageExportConfigBigqueryDestinationArgs',
    'ClusterSecurityPostureConfigArgs',
    'ClusterServiceExternalIpsConfigArgs',
    'ClusterTpuConfigArgs',
    'ClusterVerticalPodAutoscalingArgs',
    'ClusterWorkloadIdentityConfigArgs',
    'NodePoolAutoscalingArgs',
    'NodePoolManagementArgs',
    'NodePoolNetworkConfigArgs',
    'NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs',
    'NodePoolNetworkConfigAdditionalPodNetworkConfigArgs',
    'NodePoolNetworkConfigPodCidrOverprovisionConfigArgs',
    'NodePoolNodeConfigArgs',
    'NodePoolNodeConfigAdvancedMachineFeaturesArgs',
    'NodePoolNodeConfigConfidentialNodesArgs',
    'NodePoolNodeConfigEphemeralStorageConfigArgs',
    'NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs',
    'NodePoolNodeConfigFastSocketArgs',
    'NodePoolNodeConfigGcfsConfigArgs',
    'NodePoolNodeConfigGuestAcceleratorArgs',
    'NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs',
    'NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs',
    'NodePoolNodeConfigGvnicArgs',
    'NodePoolNodeConfigHostMaintenancePolicyArgs',
    'NodePoolNodeConfigKubeletConfigArgs',
    'NodePoolNodeConfigLinuxNodeConfigArgs',
    'NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs',
    'NodePoolNodeConfigReservationAffinityArgs',
    'NodePoolNodeConfigSandboxConfigArgs',
    'NodePoolNodeConfigShieldedInstanceConfigArgs',
    'NodePoolNodeConfigSoleTenantConfigArgs',
    'NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs',
    'NodePoolNodeConfigTaintArgs',
    'NodePoolNodeConfigWorkloadMetadataConfigArgs',
    'NodePoolPlacementPolicyArgs',
    'NodePoolUpgradeSettingsArgs',
    'NodePoolUpgradeSettingsBlueGreenSettingsArgs',
    'NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs',
]

@pulumi.input_type
class AttachedClusterAuthorizationArgs:
    def __init__(__self__, *,
                 admin_users: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] admin_users: Users that can perform operations as a cluster admin. A managed
               ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
               to the users. Up to ten admin users can be provided.
               For more info on RBAC, see
               https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        if admin_users is not None:
            pulumi.set(__self__, "admin_users", admin_users)

    @property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Users that can perform operations as a cluster admin. A managed
        ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole
        to the users. Up to ten admin users can be provided.
        For more info on RBAC, see
        https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")

    @admin_users.setter
    def admin_users(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "admin_users", value)


@pulumi.input_type
class AttachedClusterBinaryAuthorizationArgs:
    def __init__(__self__, *,
                 evaluation_mode: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] evaluation_mode: Configure Binary Authorization evaluation mode.
               Possible values are: `DISABLED`, `PROJECT_SINGLETON_POLICY_ENFORCE`.
        """
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[pulumi.Input[str]]:
        """
        Configure Binary Authorization evaluation mode.
        Possible values are: `DISABLED`, `PROJECT_SINGLETON_POLICY_ENFORCE`.
        """
        return pulumi.get(self, "evaluation_mode")

    @evaluation_mode.setter
    def evaluation_mode(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "evaluation_mode", value)


@pulumi.input_type
class AttachedClusterErrorArgs:
    def __init__(__self__, *,
                 message: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] message: Human-friendly description of the error.
        """
        if message is not None:
            pulumi.set(__self__, "message", message)

    @property
    @pulumi.getter
    def message(self) -> Optional[pulumi.Input[str]]:
        """
        Human-friendly description of the error.
        """
        return pulumi.get(self, "message")

    @message.setter
    def message(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "message", value)


@pulumi.input_type
class AttachedClusterFleetArgs:
    def __init__(__self__, *,
                 project: pulumi.Input[str],
                 membership: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] project: The ID of the project in which the resource belongs.
               If it is not provided, the provider project is used.
        :param pulumi.Input[str] membership: (Output)
               The name of the managed Hub Membership resource associated to this
               cluster. Membership names are formatted as
               projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        pulumi.set(__self__, "project", project)
        if membership is not None:
            pulumi.set(__self__, "membership", membership)

    @property
    @pulumi.getter
    def project(self) -> pulumi.Input[str]:
        """
        The ID of the project in which the resource belongs.
        If it is not provided, the provider project is used.
        """
        return pulumi.get(self, "project")

    @project.setter
    def project(self, value: pulumi.Input[str]):
        pulumi.set(self, "project", value)

    @property
    @pulumi.getter
    def membership(self) -> Optional[pulumi.Input[str]]:
        """
        (Output)
        The name of the managed Hub Membership resource associated to this
        cluster. Membership names are formatted as
        projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")

    @membership.setter
    def membership(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "membership", value)


@pulumi.input_type
class AttachedClusterLoggingConfigArgs:
    def __init__(__self__, *,
                 component_config: Optional[pulumi.Input['AttachedClusterLoggingConfigComponentConfigArgs']] = None):
        """
        :param pulumi.Input['AttachedClusterLoggingConfigComponentConfigArgs'] component_config: The configuration of the logging components
               Structure is documented below.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional[pulumi.Input['AttachedClusterLoggingConfigComponentConfigArgs']]:
        """
        The configuration of the logging components
        Structure is documented below.
        """
        return pulumi.get(self, "component_config")

    @component_config.setter
    def component_config(self, value: Optional[pulumi.Input['AttachedClusterLoggingConfigComponentConfigArgs']]):
        pulumi.set(self, "component_config", value)


@pulumi.input_type
class AttachedClusterLoggingConfigComponentConfigArgs:
    def __init__(__self__, *,
                 enable_components: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] enable_components: The components to be enabled.
               Each value may be one of: `SYSTEM_COMPONENTS`, `WORKLOADS`.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The components to be enabled.
        Each value may be one of: `SYSTEM_COMPONENTS`, `WORKLOADS`.
        """
        return pulumi.get(self, "enable_components")

    @enable_components.setter
    def enable_components(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "enable_components", value)


@pulumi.input_type
class AttachedClusterMonitoringConfigArgs:
    def __init__(__self__, *,
                 managed_prometheus_config: Optional[pulumi.Input['AttachedClusterMonitoringConfigManagedPrometheusConfigArgs']] = None):
        """
        :param pulumi.Input['AttachedClusterMonitoringConfigManagedPrometheusConfigArgs'] managed_prometheus_config: Enable Google Cloud Managed Service for Prometheus in the cluster.
               Structure is documented below.
        """
        if managed_prometheus_config is not None:
            pulumi.set(__self__, "managed_prometheus_config", managed_prometheus_config)

    @property
    @pulumi.getter(name="managedPrometheusConfig")
    def managed_prometheus_config(self) -> Optional[pulumi.Input['AttachedClusterMonitoringConfigManagedPrometheusConfigArgs']]:
        """
        Enable Google Cloud Managed Service for Prometheus in the cluster.
        Structure is documented below.
        """
        return pulumi.get(self, "managed_prometheus_config")

    @managed_prometheus_config.setter
    def managed_prometheus_config(self, value: Optional[pulumi.Input['AttachedClusterMonitoringConfigManagedPrometheusConfigArgs']]):
        pulumi.set(self, "managed_prometheus_config", value)


@pulumi.input_type
class AttachedClusterMonitoringConfigManagedPrometheusConfigArgs:
    def __init__(__self__, *,
                 enabled: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[bool] enabled: Enable Managed Collection.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[pulumi.Input[bool]]:
        """
        Enable Managed Collection.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class AttachedClusterOidcConfigArgs:
    def __init__(__self__, *,
                 issuer_url: pulumi.Input[str],
                 jwks: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] issuer_url: A JSON Web Token (JWT) issuer URI. `issuer` must start with `https://`
        :param pulumi.Input[str] jwks: OIDC verification keys in JWKS format (RFC 7517).
        """
        pulumi.set(__self__, "issuer_url", issuer_url)
        if jwks is not None:
            pulumi.set(__self__, "jwks", jwks)

    @property
    @pulumi.getter(name="issuerUrl")
    def issuer_url(self) -> pulumi.Input[str]:
        """
        A JSON Web Token (JWT) issuer URI. `issuer` must start with `https://`
        """
        return pulumi.get(self, "issuer_url")

    @issuer_url.setter
    def issuer_url(self, value: pulumi.Input[str]):
        pulumi.set(self, "issuer_url", value)

    @property
    @pulumi.getter
    def jwks(self) -> Optional[pulumi.Input[str]]:
        """
        OIDC verification keys in JWKS format (RFC 7517).
        """
        return pulumi.get(self, "jwks")

    @jwks.setter
    def jwks(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "jwks", value)


@pulumi.input_type
class AttachedClusterWorkloadIdentityConfigArgs:
    def __init__(__self__, *,
                 identity_provider: Optional[pulumi.Input[str]] = None,
                 issuer_uri: Optional[pulumi.Input[str]] = None,
                 workload_pool: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] identity_provider: The ID of the OIDC Identity Provider (IdP) associated to
               the Workload Identity Pool.
        :param pulumi.Input[str] issuer_uri: The OIDC issuer URL for this cluster.
        :param pulumi.Input[str] workload_pool: The Workload Identity Pool associated to the cluster.
        """
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[pulumi.Input[str]]:
        """
        The ID of the OIDC Identity Provider (IdP) associated to
        the Workload Identity Pool.
        """
        return pulumi.get(self, "identity_provider")

    @identity_provider.setter
    def identity_provider(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "identity_provider", value)

    @property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[pulumi.Input[str]]:
        """
        The OIDC issuer URL for this cluster.
        """
        return pulumi.get(self, "issuer_uri")

    @issuer_uri.setter
    def issuer_uri(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "issuer_uri", value)

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[pulumi.Input[str]]:
        """
        The Workload Identity Pool associated to the cluster.
        """
        return pulumi.get(self, "workload_pool")

    @workload_pool.setter
    def workload_pool(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "workload_pool", value)


@pulumi.input_type
class AwsClusterAuthorizationArgs:
    def __init__(__self__, *,
                 admin_users: pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminUserArgs']]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminUserArgs']]] admin_users: Users to perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        pulumi.set(__self__, "admin_users", admin_users)

    @property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminUserArgs']]]:
        """
        Users to perform operations as a cluster admin. A managed ClusterRoleBinding will be created to grant the `cluster-admin` ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")

    @admin_users.setter
    def admin_users(self, value: pulumi.Input[Sequence[pulumi.Input['AwsClusterAuthorizationAdminUserArgs']]]):
        pulumi.set(self, "admin_users", value)


@pulumi.input_type
class AwsClusterAuthorizationAdminUserArgs:
    def __init__(__self__, *,
                 username: pulumi.Input[str]):
        """
        :param pulumi.Input[str] username: The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def username(self) -> pulumi.Input[str]:
        """
        The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        return pulumi.get(self, "username")

    @username.setter
    def username(self, value: pulumi.Input[str]):
        pulumi.set(self, "username", value)


@pulumi.input_type
class AwsClusterControlPlaneArgs:
    def __init__(__self__, *,
                 aws_services_authentication: pulumi.Input['AwsClusterControlPlaneAwsServicesAuthenticationArgs'],
                 config_encryption: pulumi.Input['AwsClusterControlPlaneConfigEncryptionArgs'],
                 database_encryption: pulumi.Input['AwsClusterControlPlaneDatabaseEncryptionArgs'],
                 iam_instance_profile: pulumi.Input[str],
                 subnet_ids: pulumi.Input[Sequence[pulumi.Input[str]]],
                 version: pulumi.Input[str],
                 instance_placement: Optional[pulumi.Input['AwsClusterControlPlaneInstancePlacementArgs']] = None,
                 instance_type: Optional[pulumi.Input[str]] = None,
                 main_volume: Optional[pulumi.Input['AwsClusterControlPlaneMainVolumeArgs']] = None,
                 proxy_config: Optional[pulumi.Input['AwsClusterControlPlaneProxyConfigArgs']] = None,
                 root_volume: Optional[pulumi.Input['AwsClusterControlPlaneRootVolumeArgs']] = None,
                 security_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 ssh_config: Optional[pulumi.Input['AwsClusterControlPlaneSshConfigArgs']] = None,
                 tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input['AwsClusterControlPlaneAwsServicesAuthenticationArgs'] aws_services_authentication: Authentication configuration for management of AWS resources.
        :param pulumi.Input['AwsClusterControlPlaneConfigEncryptionArgs'] config_encryption: The ARN of the AWS KMS key used to encrypt cluster configuration.
        :param pulumi.Input['AwsClusterControlPlaneDatabaseEncryptionArgs'] database_encryption: The ARN of the AWS KMS key used to encrypt cluster secrets.
        :param pulumi.Input[str] iam_instance_profile: The name of the AWS IAM instance pofile to assign to each control plane replica.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] subnet_ids: The list of subnets where control plane replicas will run. A replica will be provisioned on each subnet and up to three values can be provided. Each subnet must be in a different AWS Availability Zone (AZ).
        :param pulumi.Input[str] version: The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling .
        :param pulumi.Input['AwsClusterControlPlaneInstancePlacementArgs'] instance_placement: (Beta only) Details of placement information for an instance.
        :param pulumi.Input[str] instance_type: Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        :param pulumi.Input['AwsClusterControlPlaneMainVolumeArgs'] main_volume: Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 8 GiB with the GP2 volume type.
        :param pulumi.Input['AwsClusterControlPlaneProxyConfigArgs'] proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param pulumi.Input['AwsClusterControlPlaneRootVolumeArgs'] root_volume: Optional. Configuration related to the root volume provisioned for each control plane replica. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] security_group_ids: Optional. The IDs of additional security groups to add to control plane replicas. The Anthos Multi-Cloud API will automatically create and manage security groups with the minimum rules needed for a functioning cluster.
        :param pulumi.Input['AwsClusterControlPlaneSshConfigArgs'] ssh_config: Optional. SSH configuration for how to access the underlying control plane machines.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] tags: Optional. A set of AWS resource tags to propagate to all underlying managed AWS resources. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        pulumi.set(__self__, "aws_services_authentication", aws_services_authentication)
        pulumi.set(__self__, "config_encryption", config_encryption)
        pulumi.set(__self__, "database_encryption", database_encryption)
        pulumi.set(__self__, "iam_instance_profile", iam_instance_profile)
        pulumi.set(__self__, "subnet_ids", subnet_ids)
        pulumi.set(__self__, "version", version)
        if instance_placement is not None:
            pulumi.set(__self__, "instance_placement", instance_placement)
        if instance_type is not None:
            pulumi.set(__self__, "instance_type", instance_type)
        if main_volume is not None:
            pulumi.set(__self__, "main_volume", main_volume)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if security_group_ids is not None:
            pulumi.set(__self__, "security_group_ids", security_group_ids)
        if ssh_config is not None:
            pulumi.set(__self__, "ssh_config", ssh_config)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @property
    @pulumi.getter(name="awsServicesAuthentication")
    def aws_services_authentication(self) -> pulumi.Input['AwsClusterControlPlaneAwsServicesAuthenticationArgs']:
        """
        Authentication configuration for management of AWS resources.
        """
        return pulumi.get(self, "aws_services_authentication")

    @aws_services_authentication.setter
    def aws_services_authentication(self, value: pulumi.Input['AwsClusterControlPlaneAwsServicesAuthenticationArgs']):
        pulumi.set(self, "aws_services_authentication", value)

    @property
    @pulumi.getter(name="configEncryption")
    def config_encryption(self) -> pulumi.Input['AwsClusterControlPlaneConfigEncryptionArgs']:
        """
        The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        return pulumi.get(self, "config_encryption")

    @config_encryption.setter
    def config_encryption(self, value: pulumi.Input['AwsClusterControlPlaneConfigEncryptionArgs']):
        pulumi.set(self, "config_encryption", value)

    @property
    @pulumi.getter(name="databaseEncryption")
    def database_encryption(self) -> pulumi.Input['AwsClusterControlPlaneDatabaseEncryptionArgs']:
        """
        The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        return pulumi.get(self, "database_encryption")

    @database_encryption.setter
    def database_encryption(self, value: pulumi.Input['AwsClusterControlPlaneDatabaseEncryptionArgs']):
        pulumi.set(self, "database_encryption", value)

    @property
    @pulumi.getter(name="iamInstanceProfile")
    def iam_instance_profile(self) -> pulumi.Input[str]:
        """
        The name of the AWS IAM instance pofile to assign to each control plane replica.
        """
        return pulumi.get(self, "iam_instance_profile")

    @iam_instance_profile.setter
    def iam_instance_profile(self, value: pulumi.Input[str]):
        pulumi.set(self, "iam_instance_profile", value)

    @property
    @pulumi.getter(name="subnetIds")
    def subnet_ids(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        The list of subnets where control plane replicas will run. A replica will be provisioned on each subnet and up to three values can be provided. Each subnet must be in a different AWS Availability Zone (AZ).
        """
        return pulumi.get(self, "subnet_ids")

    @subnet_ids.setter
    def subnet_ids(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "subnet_ids", value)

    @property
    @pulumi.getter
    def version(self) -> pulumi.Input[str]:
        """
        The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling .
        """
        return pulumi.get(self, "version")

    @version.setter
    def version(self, value: pulumi.Input[str]):
        pulumi.set(self, "version", value)

    @property
    @pulumi.getter(name="instancePlacement")
    def instance_placement(self) -> Optional[pulumi.Input['AwsClusterControlPlaneInstancePlacementArgs']]:
        """
        (Beta only) Details of placement information for an instance.
        """
        return pulumi.get(self, "instance_placement")

    @instance_placement.setter
    def instance_placement(self, value: Optional[pulumi.Input['AwsClusterControlPlaneInstancePlacementArgs']]):
        pulumi.set(self, "instance_placement", value)

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        """
        return pulumi.get(self, "instance_type")

    @instance_type.setter
    def instance_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "instance_type", value)

    @property
    @pulumi.getter(name="mainVolume")
    def main_volume(self) -> Optional[pulumi.Input['AwsClusterControlPlaneMainVolumeArgs']]:
        """
        Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 8 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "main_volume")

    @main_volume.setter
    def main_volume(self, value: Optional[pulumi.Input['AwsClusterControlPlaneMainVolumeArgs']]):
        pulumi.set(self, "main_volume", value)

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional[pulumi.Input['AwsClusterControlPlaneProxyConfigArgs']]:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @proxy_config.setter
    def proxy_config(self, value: Optional[pulumi.Input['AwsClusterControlPlaneProxyConfigArgs']]):
        pulumi.set(self, "proxy_config", value)

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional[pulumi.Input['AwsClusterControlPlaneRootVolumeArgs']]:
        """
        Optional. Configuration related to the root volume provisioned for each control plane replica. Volumes will be provisioned in the availability zone associated with the corresponding subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "root_volume")

    @root_volume.setter
    def root_volume(self, value: Optional[pulumi.Input['AwsClusterControlPlaneRootVolumeArgs']]):
        pulumi.set(self, "root_volume", value)

    @property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Optional. The IDs of additional security groups to add to control plane replicas. The Anthos Multi-Cloud API will automatically create and manage security groups with the minimum rules needed for a functioning cluster.
        """
        return pulumi.get(self, "security_group_ids")

    @security_group_ids.setter
    def security_group_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "security_group_ids", value)

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> Optional[pulumi.Input['AwsClusterControlPlaneSshConfigArgs']]:
        """
        Optional. SSH configuration for how to access the underlying control plane machines.
        """
        return pulumi.get(self, "ssh_config")

    @ssh_config.setter
    def ssh_config(self, value: Optional[pulumi.Input['AwsClusterControlPlaneSshConfigArgs']]):
        pulumi.set(self, "ssh_config", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        Optional. A set of AWS resource tags to propagate to all underlying managed AWS resources. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "tags", value)


@pulumi.input_type
class AwsClusterControlPlaneAwsServicesAuthenticationArgs:
    def __init__(__self__, *,
                 role_arn: pulumi.Input[str],
                 role_session_name: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] role_arn: The Amazon Resource Name (ARN) of the role that the Anthos Multi-Cloud API will assume when managing AWS resources on your account.
        :param pulumi.Input[str] role_session_name: Optional. An identifier for the assumed role session. When unspecified, it defaults to `multicloud-service-agent`.
        """
        pulumi.set(__self__, "role_arn", role_arn)
        if role_session_name is not None:
            pulumi.set(__self__, "role_session_name", role_session_name)

    @property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> pulumi.Input[str]:
        """
        The Amazon Resource Name (ARN) of the role that the Anthos Multi-Cloud API will assume when managing AWS resources on your account.
        """
        return pulumi.get(self, "role_arn")

    @role_arn.setter
    def role_arn(self, value: pulumi.Input[str]):
        pulumi.set(self, "role_arn", value)

    @property
    @pulumi.getter(name="roleSessionName")
    def role_session_name(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. An identifier for the assumed role session. When unspecified, it defaults to `multicloud-service-agent`.
        """
        return pulumi.get(self, "role_session_name")

    @role_session_name.setter
    def role_session_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "role_session_name", value)


@pulumi.input_type
class AwsClusterControlPlaneConfigEncryptionArgs:
    def __init__(__self__, *,
                 kms_key_arn: pulumi.Input[str]):
        """
        :param pulumi.Input[str] kms_key_arn: The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> pulumi.Input[str]:
        """
        The ARN of the AWS KMS key used to encrypt cluster configuration.
        """
        return pulumi.get(self, "kms_key_arn")

    @kms_key_arn.setter
    def kms_key_arn(self, value: pulumi.Input[str]):
        pulumi.set(self, "kms_key_arn", value)


@pulumi.input_type
class AwsClusterControlPlaneDatabaseEncryptionArgs:
    def __init__(__self__, *,
                 kms_key_arn: pulumi.Input[str]):
        """
        :param pulumi.Input[str] kms_key_arn: The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> pulumi.Input[str]:
        """
        The ARN of the AWS KMS key used to encrypt cluster secrets.
        """
        return pulumi.get(self, "kms_key_arn")

    @kms_key_arn.setter
    def kms_key_arn(self, value: pulumi.Input[str]):
        pulumi.set(self, "kms_key_arn", value)


@pulumi.input_type
class AwsClusterControlPlaneInstancePlacementArgs:
    def __init__(__self__, *,
                 tenancy: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] tenancy: The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        if tenancy is not None:
            pulumi.set(__self__, "tenancy", tenancy)

    @property
    @pulumi.getter
    def tenancy(self) -> Optional[pulumi.Input[str]]:
        """
        The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        return pulumi.get(self, "tenancy")

    @tenancy.setter
    def tenancy(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "tenancy", value)


@pulumi.input_type
class AwsClusterControlPlaneMainVolumeArgs:
    def __init__(__self__, *,
                 iops: Optional[pulumi.Input[int]] = None,
                 kms_key_arn: Optional[pulumi.Input[str]] = None,
                 size_gib: Optional[pulumi.Input[int]] = None,
                 throughput: Optional[pulumi.Input[int]] = None,
                 volume_type: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[int] iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param pulumi.Input[str] kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param pulumi.Input[int] size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param pulumi.Input[int] throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3.
        :param pulumi.Input[str] volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter
    def iops(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @iops.setter
    def iops(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "iops", value)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @kms_key_arn.setter
    def kms_key_arn(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "kms_key_arn", value)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @size_gib.setter
    def size_gib(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "size_gib", value)

    @property
    @pulumi.getter
    def throughput(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3.
        """
        return pulumi.get(self, "throughput")

    @throughput.setter
    def throughput(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "throughput", value)

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")

    @volume_type.setter
    def volume_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "volume_type", value)


@pulumi.input_type
class AwsClusterControlPlaneProxyConfigArgs:
    def __init__(__self__, *,
                 secret_arn: pulumi.Input[str],
                 secret_version: pulumi.Input[str]):
        """
        :param pulumi.Input[str] secret_arn: The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        :param pulumi.Input[str] secret_version: The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        pulumi.set(__self__, "secret_arn", secret_arn)
        pulumi.set(__self__, "secret_version", secret_version)

    @property
    @pulumi.getter(name="secretArn")
    def secret_arn(self) -> pulumi.Input[str]:
        """
        The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_arn")

    @secret_arn.setter
    def secret_arn(self, value: pulumi.Input[str]):
        pulumi.set(self, "secret_arn", value)

    @property
    @pulumi.getter(name="secretVersion")
    def secret_version(self) -> pulumi.Input[str]:
        """
        The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_version")

    @secret_version.setter
    def secret_version(self, value: pulumi.Input[str]):
        pulumi.set(self, "secret_version", value)


@pulumi.input_type
class AwsClusterControlPlaneRootVolumeArgs:
    def __init__(__self__, *,
                 iops: Optional[pulumi.Input[int]] = None,
                 kms_key_arn: Optional[pulumi.Input[str]] = None,
                 size_gib: Optional[pulumi.Input[int]] = None,
                 throughput: Optional[pulumi.Input[int]] = None,
                 volume_type: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[int] iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param pulumi.Input[str] kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param pulumi.Input[int] size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param pulumi.Input[int] throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3.
        :param pulumi.Input[str] volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter
    def iops(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @iops.setter
    def iops(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "iops", value)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @kms_key_arn.setter
    def kms_key_arn(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "kms_key_arn", value)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @size_gib.setter
    def size_gib(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "size_gib", value)

    @property
    @pulumi.getter
    def throughput(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3.
        """
        return pulumi.get(self, "throughput")

    @throughput.setter
    def throughput(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "throughput", value)

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")

    @volume_type.setter
    def volume_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "volume_type", value)


@pulumi.input_type
class AwsClusterControlPlaneSshConfigArgs:
    def __init__(__self__, *,
                 ec2_key_pair: pulumi.Input[str]):
        """
        :param pulumi.Input[str] ec2_key_pair: The name of the EC2 key pair used to login into cluster machines.
        """
        pulumi.set(__self__, "ec2_key_pair", ec2_key_pair)

    @property
    @pulumi.getter(name="ec2KeyPair")
    def ec2_key_pair(self) -> pulumi.Input[str]:
        """
        The name of the EC2 key pair used to login into cluster machines.
        """
        return pulumi.get(self, "ec2_key_pair")

    @ec2_key_pair.setter
    def ec2_key_pair(self, value: pulumi.Input[str]):
        pulumi.set(self, "ec2_key_pair", value)


@pulumi.input_type
class AwsClusterFleetArgs:
    def __init__(__self__, *,
                 membership: Optional[pulumi.Input[str]] = None,
                 project: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] membership: The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        :param pulumi.Input[str] project: The number of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @property
    @pulumi.getter
    def membership(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")

    @membership.setter
    def membership(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "membership", value)

    @property
    @pulumi.getter
    def project(self) -> Optional[pulumi.Input[str]]:
        """
        The number of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")

    @project.setter
    def project(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "project", value)


@pulumi.input_type
class AwsClusterLoggingConfigArgs:
    def __init__(__self__, *,
                 component_config: Optional[pulumi.Input['AwsClusterLoggingConfigComponentConfigArgs']] = None):
        """
        :param pulumi.Input['AwsClusterLoggingConfigComponentConfigArgs'] component_config: Configuration of the logging components.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional[pulumi.Input['AwsClusterLoggingConfigComponentConfigArgs']]:
        """
        Configuration of the logging components.
        """
        return pulumi.get(self, "component_config")

    @component_config.setter
    def component_config(self, value: Optional[pulumi.Input['AwsClusterLoggingConfigComponentConfigArgs']]):
        pulumi.set(self, "component_config", value)


@pulumi.input_type
class AwsClusterLoggingConfigComponentConfigArgs:
    def __init__(__self__, *,
                 enable_components: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] enable_components: Components of the logging configuration to be enabled.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Components of the logging configuration to be enabled.
        """
        return pulumi.get(self, "enable_components")

    @enable_components.setter
    def enable_components(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "enable_components", value)


@pulumi.input_type
class AwsClusterNetworkingArgs:
    def __init__(__self__, *,
                 pod_address_cidr_blocks: pulumi.Input[Sequence[pulumi.Input[str]]],
                 service_address_cidr_blocks: pulumi.Input[Sequence[pulumi.Input[str]]],
                 vpc_id: pulumi.Input[str],
                 per_node_pool_sg_rules_disabled: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] pod_address_cidr_blocks: All pods in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] service_address_cidr_blocks: All services in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param pulumi.Input[str] vpc_id: The VPC associated with the cluster. All component clusters (i.e. control plane and node pools) run on a single VPC. This field cannot be changed after creation.
               
               - - -
        :param pulumi.Input[bool] per_node_pool_sg_rules_disabled: Disable the per node pool subnet security group rules on the control plane security group. When set to true, you must also provide one or more security groups that ensure node pools are able to send requests to the control plane on TCP/443 and TCP/8132. Failure to do so may result in unavailable node pools.
        """
        pulumi.set(__self__, "pod_address_cidr_blocks", pod_address_cidr_blocks)
        pulumi.set(__self__, "service_address_cidr_blocks", service_address_cidr_blocks)
        pulumi.set(__self__, "vpc_id", vpc_id)
        if per_node_pool_sg_rules_disabled is not None:
            pulumi.set(__self__, "per_node_pool_sg_rules_disabled", per_node_pool_sg_rules_disabled)

    @property
    @pulumi.getter(name="podAddressCidrBlocks")
    def pod_address_cidr_blocks(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        All pods in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "pod_address_cidr_blocks")

    @pod_address_cidr_blocks.setter
    def pod_address_cidr_blocks(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "pod_address_cidr_blocks", value)

    @property
    @pulumi.getter(name="serviceAddressCidrBlocks")
    def service_address_cidr_blocks(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        All services in the cluster are assigned an RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "service_address_cidr_blocks")

    @service_address_cidr_blocks.setter
    def service_address_cidr_blocks(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "service_address_cidr_blocks", value)

    @property
    @pulumi.getter(name="vpcId")
    def vpc_id(self) -> pulumi.Input[str]:
        """
        The VPC associated with the cluster. All component clusters (i.e. control plane and node pools) run on a single VPC. This field cannot be changed after creation.

        - - -
        """
        return pulumi.get(self, "vpc_id")

    @vpc_id.setter
    def vpc_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "vpc_id", value)

    @property
    @pulumi.getter(name="perNodePoolSgRulesDisabled")
    def per_node_pool_sg_rules_disabled(self) -> Optional[pulumi.Input[bool]]:
        """
        Disable the per node pool subnet security group rules on the control plane security group. When set to true, you must also provide one or more security groups that ensure node pools are able to send requests to the control plane on TCP/443 and TCP/8132. Failure to do so may result in unavailable node pools.
        """
        return pulumi.get(self, "per_node_pool_sg_rules_disabled")

    @per_node_pool_sg_rules_disabled.setter
    def per_node_pool_sg_rules_disabled(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "per_node_pool_sg_rules_disabled", value)


@pulumi.input_type
class AwsClusterWorkloadIdentityConfigArgs:
    def __init__(__self__, *,
                 identity_provider: Optional[pulumi.Input[str]] = None,
                 issuer_uri: Optional[pulumi.Input[str]] = None,
                 workload_pool: Optional[pulumi.Input[str]] = None):
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "identity_provider")

    @identity_provider.setter
    def identity_provider(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "identity_provider", value)

    @property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "issuer_uri")

    @issuer_uri.setter
    def issuer_uri(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "issuer_uri", value)

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "workload_pool")

    @workload_pool.setter
    def workload_pool(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "workload_pool", value)


@pulumi.input_type
class AwsNodePoolAutoscalingArgs:
    def __init__(__self__, *,
                 max_node_count: pulumi.Input[int],
                 min_node_count: pulumi.Input[int]):
        """
        :param pulumi.Input[int] max_node_count: Maximum number of nodes in the NodePool. Must be >= min_node_count.
        :param pulumi.Input[int] min_node_count: Minimum number of nodes in the NodePool. Must be >= 1 and <= max_node_count.
        """
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> pulumi.Input[int]:
        """
        Maximum number of nodes in the NodePool. Must be >= min_node_count.
        """
        return pulumi.get(self, "max_node_count")

    @max_node_count.setter
    def max_node_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "max_node_count", value)

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> pulumi.Input[int]:
        """
        Minimum number of nodes in the NodePool. Must be >= 1 and <= max_node_count.
        """
        return pulumi.get(self, "min_node_count")

    @min_node_count.setter
    def min_node_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "min_node_count", value)


@pulumi.input_type
class AwsNodePoolConfigArgs:
    def __init__(__self__, *,
                 config_encryption: pulumi.Input['AwsNodePoolConfigConfigEncryptionArgs'],
                 iam_instance_profile: pulumi.Input[str],
                 autoscaling_metrics_collection: Optional[pulumi.Input['AwsNodePoolConfigAutoscalingMetricsCollectionArgs']] = None,
                 image_type: Optional[pulumi.Input[str]] = None,
                 instance_placement: Optional[pulumi.Input['AwsNodePoolConfigInstancePlacementArgs']] = None,
                 instance_type: Optional[pulumi.Input[str]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 proxy_config: Optional[pulumi.Input['AwsNodePoolConfigProxyConfigArgs']] = None,
                 root_volume: Optional[pulumi.Input['AwsNodePoolConfigRootVolumeArgs']] = None,
                 security_group_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 spot_config: Optional[pulumi.Input['AwsNodePoolConfigSpotConfigArgs']] = None,
                 ssh_config: Optional[pulumi.Input['AwsNodePoolConfigSshConfigArgs']] = None,
                 tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 taints: Optional[pulumi.Input[Sequence[pulumi.Input['AwsNodePoolConfigTaintArgs']]]] = None):
        """
        :param pulumi.Input['AwsNodePoolConfigConfigEncryptionArgs'] config_encryption: The ARN of the AWS KMS key used to encrypt node pool configuration.
        :param pulumi.Input[str] iam_instance_profile: The name of the AWS IAM role assigned to nodes in the pool.
        :param pulumi.Input['AwsNodePoolConfigAutoscalingMetricsCollectionArgs'] autoscaling_metrics_collection: Optional. Configuration related to CloudWatch metrics collection on the Auto Scaling group of the node pool. When unspecified, metrics collection is disabled.
        :param pulumi.Input[str] image_type: (Beta only) The OS image type to use on node pool instances.
        :param pulumi.Input['AwsNodePoolConfigInstancePlacementArgs'] instance_placement: (Beta only) Details of placement information for an instance.
        :param pulumi.Input[str] instance_type: Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] labels: Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        :param pulumi.Input['AwsNodePoolConfigProxyConfigArgs'] proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param pulumi.Input['AwsNodePoolConfigRootVolumeArgs'] root_volume: Optional. Template for the root volume provisioned for node pool nodes. Volumes will be provisioned in the availability zone assigned to the node pool subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] security_group_ids: Optional. The IDs of additional security groups to add to nodes in this pool. The manager will automatically create security groups with minimum rules needed for a functioning cluster.
        :param pulumi.Input['AwsNodePoolConfigSpotConfigArgs'] spot_config: (Beta only) Optional. When specified, the node pool will provision Spot instances from the set of spot_config.instance_types. This field is mutually exclusive with `instance_type`
        :param pulumi.Input['AwsNodePoolConfigSshConfigArgs'] ssh_config: Optional. The SSH configuration.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] tags: Optional. Key/value metadata to assign to each underlying AWS resource. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        :param pulumi.Input[Sequence[pulumi.Input['AwsNodePoolConfigTaintArgs']]] taints: Optional. The initial taints assigned to nodes of this node pool.
        """
        pulumi.set(__self__, "config_encryption", config_encryption)
        pulumi.set(__self__, "iam_instance_profile", iam_instance_profile)
        if autoscaling_metrics_collection is not None:
            pulumi.set(__self__, "autoscaling_metrics_collection", autoscaling_metrics_collection)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if instance_placement is not None:
            pulumi.set(__self__, "instance_placement", instance_placement)
        if instance_type is not None:
            pulumi.set(__self__, "instance_type", instance_type)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if security_group_ids is not None:
            pulumi.set(__self__, "security_group_ids", security_group_ids)
        if spot_config is not None:
            pulumi.set(__self__, "spot_config", spot_config)
        if ssh_config is not None:
            pulumi.set(__self__, "ssh_config", ssh_config)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)

    @property
    @pulumi.getter(name="configEncryption")
    def config_encryption(self) -> pulumi.Input['AwsNodePoolConfigConfigEncryptionArgs']:
        """
        The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        return pulumi.get(self, "config_encryption")

    @config_encryption.setter
    def config_encryption(self, value: pulumi.Input['AwsNodePoolConfigConfigEncryptionArgs']):
        pulumi.set(self, "config_encryption", value)

    @property
    @pulumi.getter(name="iamInstanceProfile")
    def iam_instance_profile(self) -> pulumi.Input[str]:
        """
        The name of the AWS IAM role assigned to nodes in the pool.
        """
        return pulumi.get(self, "iam_instance_profile")

    @iam_instance_profile.setter
    def iam_instance_profile(self, value: pulumi.Input[str]):
        pulumi.set(self, "iam_instance_profile", value)

    @property
    @pulumi.getter(name="autoscalingMetricsCollection")
    def autoscaling_metrics_collection(self) -> Optional[pulumi.Input['AwsNodePoolConfigAutoscalingMetricsCollectionArgs']]:
        """
        Optional. Configuration related to CloudWatch metrics collection on the Auto Scaling group of the node pool. When unspecified, metrics collection is disabled.
        """
        return pulumi.get(self, "autoscaling_metrics_collection")

    @autoscaling_metrics_collection.setter
    def autoscaling_metrics_collection(self, value: Optional[pulumi.Input['AwsNodePoolConfigAutoscalingMetricsCollectionArgs']]):
        pulumi.set(self, "autoscaling_metrics_collection", value)

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[pulumi.Input[str]]:
        """
        (Beta only) The OS image type to use on node pool instances.
        """
        return pulumi.get(self, "image_type")

    @image_type.setter
    def image_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "image_type", value)

    @property
    @pulumi.getter(name="instancePlacement")
    def instance_placement(self) -> Optional[pulumi.Input['AwsNodePoolConfigInstancePlacementArgs']]:
        """
        (Beta only) Details of placement information for an instance.
        """
        return pulumi.get(self, "instance_placement")

    @instance_placement.setter
    def instance_placement(self, value: Optional[pulumi.Input['AwsNodePoolConfigInstancePlacementArgs']]):
        pulumi.set(self, "instance_placement", value)

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The AWS instance type. When unspecified, it defaults to `m5.large`.
        """
        return pulumi.get(self, "instance_type")

    @instance_type.setter
    def instance_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "instance_type", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        Optional. The initial labels assigned to nodes of this node pool. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional[pulumi.Input['AwsNodePoolConfigProxyConfigArgs']]:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @proxy_config.setter
    def proxy_config(self, value: Optional[pulumi.Input['AwsNodePoolConfigProxyConfigArgs']]):
        pulumi.set(self, "proxy_config", value)

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional[pulumi.Input['AwsNodePoolConfigRootVolumeArgs']]:
        """
        Optional. Template for the root volume provisioned for node pool nodes. Volumes will be provisioned in the availability zone assigned to the node pool subnet. When unspecified, it defaults to 32 GiB with the GP2 volume type.
        """
        return pulumi.get(self, "root_volume")

    @root_volume.setter
    def root_volume(self, value: Optional[pulumi.Input['AwsNodePoolConfigRootVolumeArgs']]):
        pulumi.set(self, "root_volume", value)

    @property
    @pulumi.getter(name="securityGroupIds")
    def security_group_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Optional. The IDs of additional security groups to add to nodes in this pool. The manager will automatically create security groups with minimum rules needed for a functioning cluster.
        """
        return pulumi.get(self, "security_group_ids")

    @security_group_ids.setter
    def security_group_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "security_group_ids", value)

    @property
    @pulumi.getter(name="spotConfig")
    def spot_config(self) -> Optional[pulumi.Input['AwsNodePoolConfigSpotConfigArgs']]:
        """
        (Beta only) Optional. When specified, the node pool will provision Spot instances from the set of spot_config.instance_types. This field is mutually exclusive with `instance_type`
        """
        return pulumi.get(self, "spot_config")

    @spot_config.setter
    def spot_config(self, value: Optional[pulumi.Input['AwsNodePoolConfigSpotConfigArgs']]):
        pulumi.set(self, "spot_config", value)

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> Optional[pulumi.Input['AwsNodePoolConfigSshConfigArgs']]:
        """
        Optional. The SSH configuration.
        """
        return pulumi.get(self, "ssh_config")

    @ssh_config.setter
    def ssh_config(self, value: Optional[pulumi.Input['AwsNodePoolConfigSshConfigArgs']]):
        pulumi.set(self, "ssh_config", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        Optional. Key/value metadata to assign to each underlying AWS resource. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter
    def taints(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['AwsNodePoolConfigTaintArgs']]]]:
        """
        Optional. The initial taints assigned to nodes of this node pool.
        """
        return pulumi.get(self, "taints")

    @taints.setter
    def taints(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['AwsNodePoolConfigTaintArgs']]]]):
        pulumi.set(self, "taints", value)


@pulumi.input_type
class AwsNodePoolConfigAutoscalingMetricsCollectionArgs:
    def __init__(__self__, *,
                 granularity: pulumi.Input[str],
                 metrics: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[str] granularity: The frequency at which EC2 Auto Scaling sends aggregated data to AWS CloudWatch. The only valid value is "1Minute".
        :param pulumi.Input[Sequence[pulumi.Input[str]]] metrics: The metrics to enable. For a list of valid metrics, see https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html. If you specify granularity and don't specify any metrics, all metrics are enabled.
        """
        pulumi.set(__self__, "granularity", granularity)
        if metrics is not None:
            pulumi.set(__self__, "metrics", metrics)

    @property
    @pulumi.getter
    def granularity(self) -> pulumi.Input[str]:
        """
        The frequency at which EC2 Auto Scaling sends aggregated data to AWS CloudWatch. The only valid value is "1Minute".
        """
        return pulumi.get(self, "granularity")

    @granularity.setter
    def granularity(self, value: pulumi.Input[str]):
        pulumi.set(self, "granularity", value)

    @property
    @pulumi.getter
    def metrics(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The metrics to enable. For a list of valid metrics, see https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html. If you specify granularity and don't specify any metrics, all metrics are enabled.
        """
        return pulumi.get(self, "metrics")

    @metrics.setter
    def metrics(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "metrics", value)


@pulumi.input_type
class AwsNodePoolConfigConfigEncryptionArgs:
    def __init__(__self__, *,
                 kms_key_arn: pulumi.Input[str]):
        """
        :param pulumi.Input[str] kms_key_arn: The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        pulumi.set(__self__, "kms_key_arn", kms_key_arn)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> pulumi.Input[str]:
        """
        The ARN of the AWS KMS key used to encrypt node pool configuration.
        """
        return pulumi.get(self, "kms_key_arn")

    @kms_key_arn.setter
    def kms_key_arn(self, value: pulumi.Input[str]):
        pulumi.set(self, "kms_key_arn", value)


@pulumi.input_type
class AwsNodePoolConfigInstancePlacementArgs:
    def __init__(__self__, *,
                 tenancy: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] tenancy: The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        if tenancy is not None:
            pulumi.set(__self__, "tenancy", tenancy)

    @property
    @pulumi.getter
    def tenancy(self) -> Optional[pulumi.Input[str]]:
        """
        The tenancy for the instance. Possible values: TENANCY_UNSPECIFIED, DEFAULT, DEDICATED, HOST
        """
        return pulumi.get(self, "tenancy")

    @tenancy.setter
    def tenancy(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "tenancy", value)


@pulumi.input_type
class AwsNodePoolConfigProxyConfigArgs:
    def __init__(__self__, *,
                 secret_arn: pulumi.Input[str],
                 secret_version: pulumi.Input[str]):
        """
        :param pulumi.Input[str] secret_arn: The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        :param pulumi.Input[str] secret_version: The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        pulumi.set(__self__, "secret_arn", secret_arn)
        pulumi.set(__self__, "secret_version", secret_version)

    @property
    @pulumi.getter(name="secretArn")
    def secret_arn(self) -> pulumi.Input[str]:
        """
        The ARN of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_arn")

    @secret_arn.setter
    def secret_arn(self, value: pulumi.Input[str]):
        pulumi.set(self, "secret_arn", value)

    @property
    @pulumi.getter(name="secretVersion")
    def secret_version(self) -> pulumi.Input[str]:
        """
        The version string of the AWS Secret Manager secret that contains the HTTP(S) proxy configuration.
        """
        return pulumi.get(self, "secret_version")

    @secret_version.setter
    def secret_version(self, value: pulumi.Input[str]):
        pulumi.set(self, "secret_version", value)


@pulumi.input_type
class AwsNodePoolConfigRootVolumeArgs:
    def __init__(__self__, *,
                 iops: Optional[pulumi.Input[int]] = None,
                 kms_key_arn: Optional[pulumi.Input[str]] = None,
                 size_gib: Optional[pulumi.Input[int]] = None,
                 throughput: Optional[pulumi.Input[int]] = None,
                 volume_type: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[int] iops: Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        :param pulumi.Input[str] kms_key_arn: Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        :param pulumi.Input[int] size_gib: Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        :param pulumi.Input[int] throughput: Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3.
        :param pulumi.Input[str] volume_type: Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_arn is not None:
            pulumi.set(__self__, "kms_key_arn", kms_key_arn)
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter
    def iops(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The number of I/O operations per second (IOPS) to provision for GP3 volume.
        """
        return pulumi.get(self, "iops")

    @iops.setter
    def iops(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "iops", value)

    @property
    @pulumi.getter(name="kmsKeyArn")
    def kms_key_arn(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The Amazon Resource Name (ARN) of the Customer Managed Key (CMK) used to encrypt AWS EBS volumes. If not specified, the default Amazon managed key associated to the AWS region where this cluster runs will be used.
        """
        return pulumi.get(self, "kms_key_arn")

    @kms_key_arn.setter
    def kms_key_arn(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "kms_key_arn", value)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The size of the volume, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @size_gib.setter
    def size_gib(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "size_gib", value)

    @property
    @pulumi.getter
    def throughput(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The throughput to provision for the volume, in MiB/s. Only valid if the volume type is GP3.
        """
        return pulumi.get(self, "throughput")

    @throughput.setter
    def throughput(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "throughput", value)

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. Type of the EBS volume. When unspecified, it defaults to GP2 volume. Possible values: VOLUME_TYPE_UNSPECIFIED, GP2, GP3
        """
        return pulumi.get(self, "volume_type")

    @volume_type.setter
    def volume_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "volume_type", value)


@pulumi.input_type
class AwsNodePoolConfigSpotConfigArgs:
    def __init__(__self__, *,
                 instance_types: pulumi.Input[Sequence[pulumi.Input[str]]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] instance_types: List of AWS EC2 instance types for creating a spot node pool's nodes. The specified instance types must have the same number of CPUs and memory. You can use the Amazon EC2 Instance Selector tool (https://github.com/aws/amazon-ec2-instance-selector) to choose instance types with matching CPU and memory
        """
        pulumi.set(__self__, "instance_types", instance_types)

    @property
    @pulumi.getter(name="instanceTypes")
    def instance_types(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        List of AWS EC2 instance types for creating a spot node pool's nodes. The specified instance types must have the same number of CPUs and memory. You can use the Amazon EC2 Instance Selector tool (https://github.com/aws/amazon-ec2-instance-selector) to choose instance types with matching CPU and memory
        """
        return pulumi.get(self, "instance_types")

    @instance_types.setter
    def instance_types(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "instance_types", value)


@pulumi.input_type
class AwsNodePoolConfigSshConfigArgs:
    def __init__(__self__, *,
                 ec2_key_pair: pulumi.Input[str]):
        """
        :param pulumi.Input[str] ec2_key_pair: The name of the EC2 key pair used to login into cluster machines.
        """
        pulumi.set(__self__, "ec2_key_pair", ec2_key_pair)

    @property
    @pulumi.getter(name="ec2KeyPair")
    def ec2_key_pair(self) -> pulumi.Input[str]:
        """
        The name of the EC2 key pair used to login into cluster machines.
        """
        return pulumi.get(self, "ec2_key_pair")

    @ec2_key_pair.setter
    def ec2_key_pair(self, value: pulumi.Input[str]):
        pulumi.set(self, "ec2_key_pair", value)


@pulumi.input_type
class AwsNodePoolConfigTaintArgs:
    def __init__(__self__, *,
                 effect: pulumi.Input[str],
                 key: pulumi.Input[str],
                 value: pulumi.Input[str]):
        """
        :param pulumi.Input[str] effect: The taint effect. Possible values: EFFECT_UNSPECIFIED, NO_SCHEDULE, PREFER_NO_SCHEDULE, NO_EXECUTE
        :param pulumi.Input[str] key: Key for the taint.
        :param pulumi.Input[str] value: Value for the taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> pulumi.Input[str]:
        """
        The taint effect. Possible values: EFFECT_UNSPECIFIED, NO_SCHEDULE, PREFER_NO_SCHEDULE, NO_EXECUTE
        """
        return pulumi.get(self, "effect")

    @effect.setter
    def effect(self, value: pulumi.Input[str]):
        pulumi.set(self, "effect", value)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[str]:
        """
        Key for the taint.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[str]:
        """
        Value for the taint.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[str]):
        pulumi.set(self, "value", value)


@pulumi.input_type
class AwsNodePoolManagementArgs:
    def __init__(__self__, *,
                 auto_repair: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[bool] auto_repair: Optional. Whether or not the nodes will be automatically repaired.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[pulumi.Input[bool]]:
        """
        Optional. Whether or not the nodes will be automatically repaired.
        """
        return pulumi.get(self, "auto_repair")

    @auto_repair.setter
    def auto_repair(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "auto_repair", value)


@pulumi.input_type
class AwsNodePoolMaxPodsConstraintArgs:
    def __init__(__self__, *,
                 max_pods_per_node: pulumi.Input[int]):
        """
        :param pulumi.Input[int] max_pods_per_node: The maximum number of pods to schedule on a single node.
               
               - - -
        """
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> pulumi.Input[int]:
        """
        The maximum number of pods to schedule on a single node.

        - - -
        """
        return pulumi.get(self, "max_pods_per_node")

    @max_pods_per_node.setter
    def max_pods_per_node(self, value: pulumi.Input[int]):
        pulumi.set(self, "max_pods_per_node", value)


@pulumi.input_type
class AzureClusterAuthorizationArgs:
    def __init__(__self__, *,
                 admin_users: pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminUserArgs']]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminUserArgs']]] admin_users: Users that can perform operations as a cluster admin. A new ClusterRoleBinding will be created to grant the cluster-admin ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        pulumi.set(__self__, "admin_users", admin_users)

    @property
    @pulumi.getter(name="adminUsers")
    def admin_users(self) -> pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminUserArgs']]]:
        """
        Users that can perform operations as a cluster admin. A new ClusterRoleBinding will be created to grant the cluster-admin ClusterRole to the users. Up to ten admin users can be provided. For more info on RBAC, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
        """
        return pulumi.get(self, "admin_users")

    @admin_users.setter
    def admin_users(self, value: pulumi.Input[Sequence[pulumi.Input['AzureClusterAuthorizationAdminUserArgs']]]):
        pulumi.set(self, "admin_users", value)


@pulumi.input_type
class AzureClusterAuthorizationAdminUserArgs:
    def __init__(__self__, *,
                 username: pulumi.Input[str]):
        """
        :param pulumi.Input[str] username: The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def username(self) -> pulumi.Input[str]:
        """
        The name of the user, e.g. `my-gcp-id@gmail.com`.
        """
        return pulumi.get(self, "username")

    @username.setter
    def username(self, value: pulumi.Input[str]):
        pulumi.set(self, "username", value)


@pulumi.input_type
class AzureClusterAzureServicesAuthenticationArgs:
    def __init__(__self__, *,
                 application_id: pulumi.Input[str],
                 tenant_id: pulumi.Input[str]):
        """
        :param pulumi.Input[str] application_id: The Azure Active Directory Application ID for Authentication configuration.
        :param pulumi.Input[str] tenant_id: The Azure Active Directory Tenant ID for Authentication configuration.
        """
        pulumi.set(__self__, "application_id", application_id)
        pulumi.set(__self__, "tenant_id", tenant_id)

    @property
    @pulumi.getter(name="applicationId")
    def application_id(self) -> pulumi.Input[str]:
        """
        The Azure Active Directory Application ID for Authentication configuration.
        """
        return pulumi.get(self, "application_id")

    @application_id.setter
    def application_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "application_id", value)

    @property
    @pulumi.getter(name="tenantId")
    def tenant_id(self) -> pulumi.Input[str]:
        """
        The Azure Active Directory Tenant ID for Authentication configuration.
        """
        return pulumi.get(self, "tenant_id")

    @tenant_id.setter
    def tenant_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "tenant_id", value)


@pulumi.input_type
class AzureClusterControlPlaneArgs:
    def __init__(__self__, *,
                 ssh_config: pulumi.Input['AzureClusterControlPlaneSshConfigArgs'],
                 subnet_id: pulumi.Input[str],
                 version: pulumi.Input[str],
                 database_encryption: Optional[pulumi.Input['AzureClusterControlPlaneDatabaseEncryptionArgs']] = None,
                 main_volume: Optional[pulumi.Input['AzureClusterControlPlaneMainVolumeArgs']] = None,
                 proxy_config: Optional[pulumi.Input['AzureClusterControlPlaneProxyConfigArgs']] = None,
                 replica_placements: Optional[pulumi.Input[Sequence[pulumi.Input['AzureClusterControlPlaneReplicaPlacementArgs']]]] = None,
                 root_volume: Optional[pulumi.Input['AzureClusterControlPlaneRootVolumeArgs']] = None,
                 tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 vm_size: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['AzureClusterControlPlaneSshConfigArgs'] ssh_config: SSH configuration for how to access the underlying control plane machines.
        :param pulumi.Input[str] subnet_id: The ARM ID of the subnet where the control plane VMs are deployed. Example: `/subscriptions//resourceGroups//providers/Microsoft.Network/virtualNetworks//subnets/default`.
        :param pulumi.Input[str] version: The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling GetAzureServerConfig.
        :param pulumi.Input['AzureClusterControlPlaneDatabaseEncryptionArgs'] database_encryption: Optional. Configuration related to application-layer secrets encryption.
        :param pulumi.Input['AzureClusterControlPlaneMainVolumeArgs'] main_volume: Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. When unspecified, it defaults to a 8-GiB Azure Disk.
        :param pulumi.Input['AzureClusterControlPlaneProxyConfigArgs'] proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param pulumi.Input[Sequence[pulumi.Input['AzureClusterControlPlaneReplicaPlacementArgs']]] replica_placements: Configuration for where to place the control plane replicas. Up to three replica placement instances can be specified. If replica_placements is set, the replica placement instances will be applied to the three control plane replicas as evenly as possible.
        :param pulumi.Input['AzureClusterControlPlaneRootVolumeArgs'] root_volume: Optional. Configuration related to the root volume provisioned for each control plane replica. When unspecified, it defaults to 32-GiB Azure Disk.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] tags: Optional. A set of tags to apply to all underlying control plane Azure resources.
        :param pulumi.Input[str] vm_size: Optional. The Azure VM size name. Example: `Standard_DS2_v2`. For available VM sizes, see https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        pulumi.set(__self__, "ssh_config", ssh_config)
        pulumi.set(__self__, "subnet_id", subnet_id)
        pulumi.set(__self__, "version", version)
        if database_encryption is not None:
            pulumi.set(__self__, "database_encryption", database_encryption)
        if main_volume is not None:
            pulumi.set(__self__, "main_volume", main_volume)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if replica_placements is not None:
            pulumi.set(__self__, "replica_placements", replica_placements)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if vm_size is not None:
            pulumi.set(__self__, "vm_size", vm_size)

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> pulumi.Input['AzureClusterControlPlaneSshConfigArgs']:
        """
        SSH configuration for how to access the underlying control plane machines.
        """
        return pulumi.get(self, "ssh_config")

    @ssh_config.setter
    def ssh_config(self, value: pulumi.Input['AzureClusterControlPlaneSshConfigArgs']):
        pulumi.set(self, "ssh_config", value)

    @property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> pulumi.Input[str]:
        """
        The ARM ID of the subnet where the control plane VMs are deployed. Example: `/subscriptions//resourceGroups//providers/Microsoft.Network/virtualNetworks//subnets/default`.
        """
        return pulumi.get(self, "subnet_id")

    @subnet_id.setter
    def subnet_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "subnet_id", value)

    @property
    @pulumi.getter
    def version(self) -> pulumi.Input[str]:
        """
        The Kubernetes version to run on control plane replicas (e.g. `1.19.10-gke.1000`). You can list all supported versions on a given Google Cloud region by calling GetAzureServerConfig.
        """
        return pulumi.get(self, "version")

    @version.setter
    def version(self, value: pulumi.Input[str]):
        pulumi.set(self, "version", value)

    @property
    @pulumi.getter(name="databaseEncryption")
    def database_encryption(self) -> Optional[pulumi.Input['AzureClusterControlPlaneDatabaseEncryptionArgs']]:
        """
        Optional. Configuration related to application-layer secrets encryption.
        """
        return pulumi.get(self, "database_encryption")

    @database_encryption.setter
    def database_encryption(self, value: Optional[pulumi.Input['AzureClusterControlPlaneDatabaseEncryptionArgs']]):
        pulumi.set(self, "database_encryption", value)

    @property
    @pulumi.getter(name="mainVolume")
    def main_volume(self) -> Optional[pulumi.Input['AzureClusterControlPlaneMainVolumeArgs']]:
        """
        Optional. Configuration related to the main volume provisioned for each control plane replica. The main volume is in charge of storing all of the cluster's etcd state. When unspecified, it defaults to a 8-GiB Azure Disk.
        """
        return pulumi.get(self, "main_volume")

    @main_volume.setter
    def main_volume(self, value: Optional[pulumi.Input['AzureClusterControlPlaneMainVolumeArgs']]):
        pulumi.set(self, "main_volume", value)

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional[pulumi.Input['AzureClusterControlPlaneProxyConfigArgs']]:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @proxy_config.setter
    def proxy_config(self, value: Optional[pulumi.Input['AzureClusterControlPlaneProxyConfigArgs']]):
        pulumi.set(self, "proxy_config", value)

    @property
    @pulumi.getter(name="replicaPlacements")
    def replica_placements(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['AzureClusterControlPlaneReplicaPlacementArgs']]]]:
        """
        Configuration for where to place the control plane replicas. Up to three replica placement instances can be specified. If replica_placements is set, the replica placement instances will be applied to the three control plane replicas as evenly as possible.
        """
        return pulumi.get(self, "replica_placements")

    @replica_placements.setter
    def replica_placements(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['AzureClusterControlPlaneReplicaPlacementArgs']]]]):
        pulumi.set(self, "replica_placements", value)

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional[pulumi.Input['AzureClusterControlPlaneRootVolumeArgs']]:
        """
        Optional. Configuration related to the root volume provisioned for each control plane replica. When unspecified, it defaults to 32-GiB Azure Disk.
        """
        return pulumi.get(self, "root_volume")

    @root_volume.setter
    def root_volume(self, value: Optional[pulumi.Input['AzureClusterControlPlaneRootVolumeArgs']]):
        pulumi.set(self, "root_volume", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        Optional. A set of tags to apply to all underlying control plane Azure resources.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter(name="vmSize")
    def vm_size(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The Azure VM size name. Example: `Standard_DS2_v2`. For available VM sizes, see https://docs.microsoft.com/en-us/azure/virtual-machines/vm-naming-conventions. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        return pulumi.get(self, "vm_size")

    @vm_size.setter
    def vm_size(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "vm_size", value)


@pulumi.input_type
class AzureClusterControlPlaneDatabaseEncryptionArgs:
    def __init__(__self__, *,
                 key_id: pulumi.Input[str]):
        """
        :param pulumi.Input[str] key_id: The ARM ID of the Azure Key Vault key to encrypt / decrypt data. For example: `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>` Encryption will always take the latest version of the key and hence specific version is not supported.
        """
        pulumi.set(__self__, "key_id", key_id)

    @property
    @pulumi.getter(name="keyId")
    def key_id(self) -> pulumi.Input[str]:
        """
        The ARM ID of the Azure Key Vault key to encrypt / decrypt data. For example: `/subscriptions/<subscription-id>/resourceGroups/<resource-group-id>/providers/Microsoft.KeyVault/vaults/<key-vault-id>/keys/<key-name>` Encryption will always take the latest version of the key and hence specific version is not supported.
        """
        return pulumi.get(self, "key_id")

    @key_id.setter
    def key_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "key_id", value)


@pulumi.input_type
class AzureClusterControlPlaneMainVolumeArgs:
    def __init__(__self__, *,
                 size_gib: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input[int] size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @size_gib.setter
    def size_gib(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "size_gib", value)


@pulumi.input_type
class AzureClusterControlPlaneProxyConfigArgs:
    def __init__(__self__, *,
                 resource_group_id: pulumi.Input[str],
                 secret_id: pulumi.Input[str]):
        """
        :param pulumi.Input[str] resource_group_id: The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        :param pulumi.Input[str] secret_id: The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        pulumi.set(__self__, "resource_group_id", resource_group_id)
        pulumi.set(__self__, "secret_id", secret_id)

    @property
    @pulumi.getter(name="resourceGroupId")
    def resource_group_id(self) -> pulumi.Input[str]:
        """
        The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        """
        return pulumi.get(self, "resource_group_id")

    @resource_group_id.setter
    def resource_group_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "resource_group_id", value)

    @property
    @pulumi.getter(name="secretId")
    def secret_id(self) -> pulumi.Input[str]:
        """
        The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        return pulumi.get(self, "secret_id")

    @secret_id.setter
    def secret_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "secret_id", value)


@pulumi.input_type
class AzureClusterControlPlaneReplicaPlacementArgs:
    def __init__(__self__, *,
                 azure_availability_zone: pulumi.Input[str],
                 subnet_id: pulumi.Input[str]):
        """
        :param pulumi.Input[str] azure_availability_zone: For a given replica, the Azure availability zone where to provision the control plane VM and the ETCD disk.
        :param pulumi.Input[str] subnet_id: For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
        """
        pulumi.set(__self__, "azure_availability_zone", azure_availability_zone)
        pulumi.set(__self__, "subnet_id", subnet_id)

    @property
    @pulumi.getter(name="azureAvailabilityZone")
    def azure_availability_zone(self) -> pulumi.Input[str]:
        """
        For a given replica, the Azure availability zone where to provision the control plane VM and the ETCD disk.
        """
        return pulumi.get(self, "azure_availability_zone")

    @azure_availability_zone.setter
    def azure_availability_zone(self, value: pulumi.Input[str]):
        pulumi.set(self, "azure_availability_zone", value)

    @property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> pulumi.Input[str]:
        """
        For a given replica, the ARM ID of the subnet where the control plane VM is deployed. Make sure it's a subnet under the virtual network in the cluster configuration.
        """
        return pulumi.get(self, "subnet_id")

    @subnet_id.setter
    def subnet_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "subnet_id", value)


@pulumi.input_type
class AzureClusterControlPlaneRootVolumeArgs:
    def __init__(__self__, *,
                 size_gib: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input[int] size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @size_gib.setter
    def size_gib(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "size_gib", value)


@pulumi.input_type
class AzureClusterControlPlaneSshConfigArgs:
    def __init__(__self__, *,
                 authorized_key: pulumi.Input[str]):
        """
        :param pulumi.Input[str] authorized_key: The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        pulumi.set(__self__, "authorized_key", authorized_key)

    @property
    @pulumi.getter(name="authorizedKey")
    def authorized_key(self) -> pulumi.Input[str]:
        """
        The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        return pulumi.get(self, "authorized_key")

    @authorized_key.setter
    def authorized_key(self, value: pulumi.Input[str]):
        pulumi.set(self, "authorized_key", value)


@pulumi.input_type
class AzureClusterFleetArgs:
    def __init__(__self__, *,
                 membership: Optional[pulumi.Input[str]] = None,
                 project: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] membership: The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        :param pulumi.Input[str] project: The number of the Fleet host project where this cluster will be registered.
        """
        if membership is not None:
            pulumi.set(__self__, "membership", membership)
        if project is not None:
            pulumi.set(__self__, "project", project)

    @property
    @pulumi.getter
    def membership(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the managed Hub Membership resource associated to this cluster. Membership names are formatted as projects/<project-number>/locations/global/membership/<cluster-id>.
        """
        return pulumi.get(self, "membership")

    @membership.setter
    def membership(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "membership", value)

    @property
    @pulumi.getter
    def project(self) -> Optional[pulumi.Input[str]]:
        """
        The number of the Fleet host project where this cluster will be registered.
        """
        return pulumi.get(self, "project")

    @project.setter
    def project(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "project", value)


@pulumi.input_type
class AzureClusterLoggingConfigArgs:
    def __init__(__self__, *,
                 component_config: Optional[pulumi.Input['AzureClusterLoggingConfigComponentConfigArgs']] = None):
        """
        :param pulumi.Input['AzureClusterLoggingConfigComponentConfigArgs'] component_config: Configuration of the logging components.
        """
        if component_config is not None:
            pulumi.set(__self__, "component_config", component_config)

    @property
    @pulumi.getter(name="componentConfig")
    def component_config(self) -> Optional[pulumi.Input['AzureClusterLoggingConfigComponentConfigArgs']]:
        """
        Configuration of the logging components.
        """
        return pulumi.get(self, "component_config")

    @component_config.setter
    def component_config(self, value: Optional[pulumi.Input['AzureClusterLoggingConfigComponentConfigArgs']]):
        pulumi.set(self, "component_config", value)


@pulumi.input_type
class AzureClusterLoggingConfigComponentConfigArgs:
    def __init__(__self__, *,
                 enable_components: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] enable_components: Components of the logging configuration to be enabled.
        """
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Components of the logging configuration to be enabled.
        """
        return pulumi.get(self, "enable_components")

    @enable_components.setter
    def enable_components(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "enable_components", value)


@pulumi.input_type
class AzureClusterNetworkingArgs:
    def __init__(__self__, *,
                 pod_address_cidr_blocks: pulumi.Input[Sequence[pulumi.Input[str]]],
                 service_address_cidr_blocks: pulumi.Input[Sequence[pulumi.Input[str]]],
                 virtual_network_id: pulumi.Input[str]):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] pod_address_cidr_blocks: The IP address range of the pods in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All pods in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] service_address_cidr_blocks: The IP address range for services in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All services in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creating a cluster.
        :param pulumi.Input[str] virtual_network_id: The Azure Resource Manager (ARM) ID of the VNet associated with your cluster. All components in the cluster (i.e. control plane and node pools) run on a single VNet. Example: `/subscriptions/*/resourceGroups/*/providers/Microsoft.Network/virtualNetworks/*` This field cannot be changed after creation.
               
               - - -
        """
        pulumi.set(__self__, "pod_address_cidr_blocks", pod_address_cidr_blocks)
        pulumi.set(__self__, "service_address_cidr_blocks", service_address_cidr_blocks)
        pulumi.set(__self__, "virtual_network_id", virtual_network_id)

    @property
    @pulumi.getter(name="podAddressCidrBlocks")
    def pod_address_cidr_blocks(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        The IP address range of the pods in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All pods in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creation.
        """
        return pulumi.get(self, "pod_address_cidr_blocks")

    @pod_address_cidr_blocks.setter
    def pod_address_cidr_blocks(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "pod_address_cidr_blocks", value)

    @property
    @pulumi.getter(name="serviceAddressCidrBlocks")
    def service_address_cidr_blocks(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        The IP address range for services in this cluster, in CIDR notation (e.g. `10.96.0.0/14`). All services in the cluster get assigned a unique RFC1918 IPv4 address from these ranges. Only a single range is supported. This field cannot be changed after creating a cluster.
        """
        return pulumi.get(self, "service_address_cidr_blocks")

    @service_address_cidr_blocks.setter
    def service_address_cidr_blocks(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "service_address_cidr_blocks", value)

    @property
    @pulumi.getter(name="virtualNetworkId")
    def virtual_network_id(self) -> pulumi.Input[str]:
        """
        The Azure Resource Manager (ARM) ID of the VNet associated with your cluster. All components in the cluster (i.e. control plane and node pools) run on a single VNet. Example: `/subscriptions/*/resourceGroups/*/providers/Microsoft.Network/virtualNetworks/*` This field cannot be changed after creation.

        - - -
        """
        return pulumi.get(self, "virtual_network_id")

    @virtual_network_id.setter
    def virtual_network_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "virtual_network_id", value)


@pulumi.input_type
class AzureClusterWorkloadIdentityConfigArgs:
    def __init__(__self__, *,
                 identity_provider: Optional[pulumi.Input[str]] = None,
                 issuer_uri: Optional[pulumi.Input[str]] = None,
                 workload_pool: Optional[pulumi.Input[str]] = None):
        if identity_provider is not None:
            pulumi.set(__self__, "identity_provider", identity_provider)
        if issuer_uri is not None:
            pulumi.set(__self__, "issuer_uri", issuer_uri)
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="identityProvider")
    def identity_provider(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "identity_provider")

    @identity_provider.setter
    def identity_provider(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "identity_provider", value)

    @property
    @pulumi.getter(name="issuerUri")
    def issuer_uri(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "issuer_uri")

    @issuer_uri.setter
    def issuer_uri(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "issuer_uri", value)

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "workload_pool")

    @workload_pool.setter
    def workload_pool(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "workload_pool", value)


@pulumi.input_type
class AzureNodePoolAutoscalingArgs:
    def __init__(__self__, *,
                 max_node_count: pulumi.Input[int],
                 min_node_count: pulumi.Input[int]):
        """
        :param pulumi.Input[int] max_node_count: Maximum number of nodes in the node pool. Must be >= min_node_count.
        :param pulumi.Input[int] min_node_count: Minimum number of nodes in the node pool. Must be >= 1 and <= max_node_count.
        """
        pulumi.set(__self__, "max_node_count", max_node_count)
        pulumi.set(__self__, "min_node_count", min_node_count)

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> pulumi.Input[int]:
        """
        Maximum number of nodes in the node pool. Must be >= min_node_count.
        """
        return pulumi.get(self, "max_node_count")

    @max_node_count.setter
    def max_node_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "max_node_count", value)

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> pulumi.Input[int]:
        """
        Minimum number of nodes in the node pool. Must be >= 1 and <= max_node_count.
        """
        return pulumi.get(self, "min_node_count")

    @min_node_count.setter
    def min_node_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "min_node_count", value)


@pulumi.input_type
class AzureNodePoolConfigArgs:
    def __init__(__self__, *,
                 ssh_config: pulumi.Input['AzureNodePoolConfigSshConfigArgs'],
                 image_type: Optional[pulumi.Input[str]] = None,
                 proxy_config: Optional[pulumi.Input['AzureNodePoolConfigProxyConfigArgs']] = None,
                 root_volume: Optional[pulumi.Input['AzureNodePoolConfigRootVolumeArgs']] = None,
                 tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 vm_size: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['AzureNodePoolConfigSshConfigArgs'] ssh_config: SSH configuration for how to access the node pool machines.
        :param pulumi.Input[str] image_type: (Beta only) The OS image type to use on node pool instances.
        :param pulumi.Input['AzureNodePoolConfigProxyConfigArgs'] proxy_config: Proxy configuration for outbound HTTP(S) traffic.
        :param pulumi.Input['AzureNodePoolConfigRootVolumeArgs'] root_volume: Optional. Configuration related to the root volume provisioned for each node pool machine. When unspecified, it defaults to a 32-GiB Azure Disk.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] tags: Optional. A set of tags to apply to all underlying Azure resources for this node pool. This currently only includes Virtual Machine Scale Sets. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        :param pulumi.Input[str] vm_size: Optional. The Azure VM size name. Example: `Standard_DS2_v2`. See (/anthos/clusters/docs/azure/reference/supported-vms) for options. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        pulumi.set(__self__, "ssh_config", ssh_config)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if proxy_config is not None:
            pulumi.set(__self__, "proxy_config", proxy_config)
        if root_volume is not None:
            pulumi.set(__self__, "root_volume", root_volume)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if vm_size is not None:
            pulumi.set(__self__, "vm_size", vm_size)

    @property
    @pulumi.getter(name="sshConfig")
    def ssh_config(self) -> pulumi.Input['AzureNodePoolConfigSshConfigArgs']:
        """
        SSH configuration for how to access the node pool machines.
        """
        return pulumi.get(self, "ssh_config")

    @ssh_config.setter
    def ssh_config(self, value: pulumi.Input['AzureNodePoolConfigSshConfigArgs']):
        pulumi.set(self, "ssh_config", value)

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[pulumi.Input[str]]:
        """
        (Beta only) The OS image type to use on node pool instances.
        """
        return pulumi.get(self, "image_type")

    @image_type.setter
    def image_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "image_type", value)

    @property
    @pulumi.getter(name="proxyConfig")
    def proxy_config(self) -> Optional[pulumi.Input['AzureNodePoolConfigProxyConfigArgs']]:
        """
        Proxy configuration for outbound HTTP(S) traffic.
        """
        return pulumi.get(self, "proxy_config")

    @proxy_config.setter
    def proxy_config(self, value: Optional[pulumi.Input['AzureNodePoolConfigProxyConfigArgs']]):
        pulumi.set(self, "proxy_config", value)

    @property
    @pulumi.getter(name="rootVolume")
    def root_volume(self) -> Optional[pulumi.Input['AzureNodePoolConfigRootVolumeArgs']]:
        """
        Optional. Configuration related to the root volume provisioned for each node pool machine. When unspecified, it defaults to a 32-GiB Azure Disk.
        """
        return pulumi.get(self, "root_volume")

    @root_volume.setter
    def root_volume(self, value: Optional[pulumi.Input['AzureNodePoolConfigRootVolumeArgs']]):
        pulumi.set(self, "root_volume", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        Optional. A set of tags to apply to all underlying Azure resources for this node pool. This currently only includes Virtual Machine Scale Sets. Specify at most 50 pairs containing alphanumerics, spaces, and symbols (.+-=_:@/). Keys can be up to 127 Unicode characters. Values can be up to 255 Unicode characters.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter(name="vmSize")
    def vm_size(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The Azure VM size name. Example: `Standard_DS2_v2`. See (/anthos/clusters/docs/azure/reference/supported-vms) for options. When unspecified, it defaults to `Standard_DS2_v2`.
        """
        return pulumi.get(self, "vm_size")

    @vm_size.setter
    def vm_size(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "vm_size", value)


@pulumi.input_type
class AzureNodePoolConfigProxyConfigArgs:
    def __init__(__self__, *,
                 resource_group_id: pulumi.Input[str],
                 secret_id: pulumi.Input[str]):
        """
        :param pulumi.Input[str] resource_group_id: The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        :param pulumi.Input[str] secret_id: The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        pulumi.set(__self__, "resource_group_id", resource_group_id)
        pulumi.set(__self__, "secret_id", secret_id)

    @property
    @pulumi.getter(name="resourceGroupId")
    def resource_group_id(self) -> pulumi.Input[str]:
        """
        The ARM ID the of the resource group containing proxy keyvault. Resource group ids are formatted as `/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>`
        """
        return pulumi.get(self, "resource_group_id")

    @resource_group_id.setter
    def resource_group_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "resource_group_id", value)

    @property
    @pulumi.getter(name="secretId")
    def secret_id(self) -> pulumi.Input[str]:
        """
        The URL the of the proxy setting secret with its version. Secret ids are formatted as `https:<key-vault-name>.vault.azure.net/secrets/<secret-name>/<secret-version>`.
        """
        return pulumi.get(self, "secret_id")

    @secret_id.setter
    def secret_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "secret_id", value)


@pulumi.input_type
class AzureNodePoolConfigRootVolumeArgs:
    def __init__(__self__, *,
                 size_gib: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input[int] size_gib: Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        if size_gib is not None:
            pulumi.set(__self__, "size_gib", size_gib)

    @property
    @pulumi.getter(name="sizeGib")
    def size_gib(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The size of the disk, in GiBs. When unspecified, a default value is provided. See the specific reference in the parent resource.
        """
        return pulumi.get(self, "size_gib")

    @size_gib.setter
    def size_gib(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "size_gib", value)


@pulumi.input_type
class AzureNodePoolConfigSshConfigArgs:
    def __init__(__self__, *,
                 authorized_key: pulumi.Input[str]):
        """
        :param pulumi.Input[str] authorized_key: The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        pulumi.set(__self__, "authorized_key", authorized_key)

    @property
    @pulumi.getter(name="authorizedKey")
    def authorized_key(self) -> pulumi.Input[str]:
        """
        The SSH public key data for VMs managed by Anthos. This accepts the authorized_keys file format used in OpenSSH according to the sshd(8) manual page.
        """
        return pulumi.get(self, "authorized_key")

    @authorized_key.setter
    def authorized_key(self, value: pulumi.Input[str]):
        pulumi.set(self, "authorized_key", value)


@pulumi.input_type
class AzureNodePoolManagementArgs:
    def __init__(__self__, *,
                 auto_repair: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[bool] auto_repair: Optional. Whether or not the nodes will be automatically repaired.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[pulumi.Input[bool]]:
        """
        Optional. Whether or not the nodes will be automatically repaired.
        """
        return pulumi.get(self, "auto_repair")

    @auto_repair.setter
    def auto_repair(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "auto_repair", value)


@pulumi.input_type
class AzureNodePoolMaxPodsConstraintArgs:
    def __init__(__self__, *,
                 max_pods_per_node: pulumi.Input[int]):
        """
        :param pulumi.Input[int] max_pods_per_node: The maximum number of pods to schedule on a single node.
               
               - - -
        """
        pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> pulumi.Input[int]:
        """
        The maximum number of pods to schedule on a single node.

        - - -
        """
        return pulumi.get(self, "max_pods_per_node")

    @max_pods_per_node.setter
    def max_pods_per_node(self, value: pulumi.Input[int]):
        pulumi.set(self, "max_pods_per_node", value)


@pulumi.input_type
class ClusterAddonsConfigArgs:
    def __init__(__self__, *,
                 cloudrun_config: Optional[pulumi.Input['ClusterAddonsConfigCloudrunConfigArgs']] = None,
                 config_connector_config: Optional[pulumi.Input['ClusterAddonsConfigConfigConnectorConfigArgs']] = None,
                 dns_cache_config: Optional[pulumi.Input['ClusterAddonsConfigDnsCacheConfigArgs']] = None,
                 gce_persistent_disk_csi_driver_config: Optional[pulumi.Input['ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs']] = None,
                 gcp_filestore_csi_driver_config: Optional[pulumi.Input['ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs']] = None,
                 gcs_fuse_csi_driver_config: Optional[pulumi.Input['ClusterAddonsConfigGcsFuseCsiDriverConfigArgs']] = None,
                 gke_backup_agent_config: Optional[pulumi.Input['ClusterAddonsConfigGkeBackupAgentConfigArgs']] = None,
                 horizontal_pod_autoscaling: Optional[pulumi.Input['ClusterAddonsConfigHorizontalPodAutoscalingArgs']] = None,
                 http_load_balancing: Optional[pulumi.Input['ClusterAddonsConfigHttpLoadBalancingArgs']] = None,
                 istio_config: Optional[pulumi.Input['ClusterAddonsConfigIstioConfigArgs']] = None,
                 kalm_config: Optional[pulumi.Input['ClusterAddonsConfigKalmConfigArgs']] = None,
                 network_policy_config: Optional[pulumi.Input['ClusterAddonsConfigNetworkPolicyConfigArgs']] = None):
        """
        :param pulumi.Input['ClusterAddonsConfigCloudrunConfigArgs'] cloudrun_config: . Structure is documented below.
        :param pulumi.Input['ClusterAddonsConfigConfigConnectorConfigArgs'] config_connector_config: .
               The status of the ConfigConnector addon. It is disabled by default; Set `enabled = true` to enable.
               
               
               This example `addons_config` disables two addons:
               
               ```python
               import pulumi
               ```
               <a name="nested_binary_authorization"></a>The `binary_authorization` block supports:
        :param pulumi.Input['ClusterAddonsConfigDnsCacheConfigArgs'] dns_cache_config: .
               The status of the NodeLocal DNSCache addon. It is disabled by default.
               Set `enabled = true` to enable.
               
               **Enabling/Disabling NodeLocal DNSCache in an existing cluster is a disruptive operation.
               All cluster nodes running GKE 1.15 and higher are recreated.**
        :param pulumi.Input['ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs'] gce_persistent_disk_csi_driver_config: .
               Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set `enabled = true` to enable.
               
               **Note:** The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        :param pulumi.Input['ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs'] gcp_filestore_csi_driver_config: The status of the Filestore CSI driver addon,
               which allows the usage of filestore instance as volumes.
               It is disabled by default; set `enabled = true` to enable.
        :param pulumi.Input['ClusterAddonsConfigGcsFuseCsiDriverConfigArgs'] gcs_fuse_csi_driver_config: The status of the GCSFuse CSI driver addon,
               which allows the usage of a gcs bucket as volumes.
               It is disabled by default; set `enabled = true` to enable.
        :param pulumi.Input['ClusterAddonsConfigGkeBackupAgentConfigArgs'] gke_backup_agent_config: .
               The status of the Backup for GKE agent addon. It is disabled by default; Set `enabled = true` to enable.
        :param pulumi.Input['ClusterAddonsConfigHorizontalPodAutoscalingArgs'] horizontal_pod_autoscaling: The status of the Horizontal Pod Autoscaling
               addon, which increases or decreases the number of replica pods a replication controller
               has based on the resource usage of the existing pods.
               It is enabled by default;
               set `disabled = true` to disable.
        :param pulumi.Input['ClusterAddonsConfigHttpLoadBalancingArgs'] http_load_balancing: The status of the HTTP (L7) load balancing
               controller addon, which makes it easy to set up HTTP load balancers for services in a
               cluster. It is enabled by default; set `disabled = true` to disable.
        :param pulumi.Input['ClusterAddonsConfigIstioConfigArgs'] istio_config: .
               Structure is documented below.
        :param pulumi.Input['ClusterAddonsConfigKalmConfigArgs'] kalm_config: .
               Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set `enabled = true` to enable.
        :param pulumi.Input['ClusterAddonsConfigNetworkPolicyConfigArgs'] network_policy_config: Whether we should enable the network policy addon
               for the master.  This must be enabled in order to enable network policy for the nodes.
               To enable this, you must also define a `network_policy` block,
               otherwise nothing will happen.
               It can only be disabled if the nodes already do not have network policies enabled.
               Defaults to disabled; set `disabled = false` to enable.
        """
        if cloudrun_config is not None:
            pulumi.set(__self__, "cloudrun_config", cloudrun_config)
        if config_connector_config is not None:
            pulumi.set(__self__, "config_connector_config", config_connector_config)
        if dns_cache_config is not None:
            pulumi.set(__self__, "dns_cache_config", dns_cache_config)
        if gce_persistent_disk_csi_driver_config is not None:
            pulumi.set(__self__, "gce_persistent_disk_csi_driver_config", gce_persistent_disk_csi_driver_config)
        if gcp_filestore_csi_driver_config is not None:
            pulumi.set(__self__, "gcp_filestore_csi_driver_config", gcp_filestore_csi_driver_config)
        if gcs_fuse_csi_driver_config is not None:
            pulumi.set(__self__, "gcs_fuse_csi_driver_config", gcs_fuse_csi_driver_config)
        if gke_backup_agent_config is not None:
            pulumi.set(__self__, "gke_backup_agent_config", gke_backup_agent_config)
        if horizontal_pod_autoscaling is not None:
            pulumi.set(__self__, "horizontal_pod_autoscaling", horizontal_pod_autoscaling)
        if http_load_balancing is not None:
            pulumi.set(__self__, "http_load_balancing", http_load_balancing)
        if istio_config is not None:
            pulumi.set(__self__, "istio_config", istio_config)
        if kalm_config is not None:
            pulumi.set(__self__, "kalm_config", kalm_config)
        if network_policy_config is not None:
            pulumi.set(__self__, "network_policy_config", network_policy_config)

    @property
    @pulumi.getter(name="cloudrunConfig")
    def cloudrun_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigCloudrunConfigArgs']]:
        """
        . Structure is documented below.
        """
        return pulumi.get(self, "cloudrun_config")

    @cloudrun_config.setter
    def cloudrun_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigCloudrunConfigArgs']]):
        pulumi.set(self, "cloudrun_config", value)

    @property
    @pulumi.getter(name="configConnectorConfig")
    def config_connector_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigConfigConnectorConfigArgs']]:
        """
        .
        The status of the ConfigConnector addon. It is disabled by default; Set `enabled = true` to enable.


        This example `addons_config` disables two addons:

        ```python
        import pulumi
        ```
        <a name="nested_binary_authorization"></a>The `binary_authorization` block supports:
        """
        return pulumi.get(self, "config_connector_config")

    @config_connector_config.setter
    def config_connector_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigConfigConnectorConfigArgs']]):
        pulumi.set(self, "config_connector_config", value)

    @property
    @pulumi.getter(name="dnsCacheConfig")
    def dns_cache_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigDnsCacheConfigArgs']]:
        """
        .
        The status of the NodeLocal DNSCache addon. It is disabled by default.
        Set `enabled = true` to enable.

        **Enabling/Disabling NodeLocal DNSCache in an existing cluster is a disruptive operation.
        All cluster nodes running GKE 1.15 and higher are recreated.**
        """
        return pulumi.get(self, "dns_cache_config")

    @dns_cache_config.setter
    def dns_cache_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigDnsCacheConfigArgs']]):
        pulumi.set(self, "dns_cache_config", value)

    @property
    @pulumi.getter(name="gcePersistentDiskCsiDriverConfig")
    def gce_persistent_disk_csi_driver_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs']]:
        """
        .
        Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. Set `enabled = true` to enable.

        **Note:** The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: Linux clusters: GKE version 1.18.10-gke.2100 or later, or 1.19.3-gke.2100 or later.
        """
        return pulumi.get(self, "gce_persistent_disk_csi_driver_config")

    @gce_persistent_disk_csi_driver_config.setter
    def gce_persistent_disk_csi_driver_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs']]):
        pulumi.set(self, "gce_persistent_disk_csi_driver_config", value)

    @property
    @pulumi.getter(name="gcpFilestoreCsiDriverConfig")
    def gcp_filestore_csi_driver_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs']]:
        """
        The status of the Filestore CSI driver addon,
        which allows the usage of filestore instance as volumes.
        It is disabled by default; set `enabled = true` to enable.
        """
        return pulumi.get(self, "gcp_filestore_csi_driver_config")

    @gcp_filestore_csi_driver_config.setter
    def gcp_filestore_csi_driver_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs']]):
        pulumi.set(self, "gcp_filestore_csi_driver_config", value)

    @property
    @pulumi.getter(name="gcsFuseCsiDriverConfig")
    def gcs_fuse_csi_driver_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigGcsFuseCsiDriverConfigArgs']]:
        """
        The status of the GCSFuse CSI driver addon,
        which allows the usage of a gcs bucket as volumes.
        It is disabled by default; set `enabled = true` to enable.
        """
        return pulumi.get(self, "gcs_fuse_csi_driver_config")

    @gcs_fuse_csi_driver_config.setter
    def gcs_fuse_csi_driver_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigGcsFuseCsiDriverConfigArgs']]):
        pulumi.set(self, "gcs_fuse_csi_driver_config", value)

    @property
    @pulumi.getter(name="gkeBackupAgentConfig")
    def gke_backup_agent_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigGkeBackupAgentConfigArgs']]:
        """
        .
        The status of the Backup for GKE agent addon. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "gke_backup_agent_config")

    @gke_backup_agent_config.setter
    def gke_backup_agent_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigGkeBackupAgentConfigArgs']]):
        pulumi.set(self, "gke_backup_agent_config", value)

    @property
    @pulumi.getter(name="horizontalPodAutoscaling")
    def horizontal_pod_autoscaling(self) -> Optional[pulumi.Input['ClusterAddonsConfigHorizontalPodAutoscalingArgs']]:
        """
        The status of the Horizontal Pod Autoscaling
        addon, which increases or decreases the number of replica pods a replication controller
        has based on the resource usage of the existing pods.
        It is enabled by default;
        set `disabled = true` to disable.
        """
        return pulumi.get(self, "horizontal_pod_autoscaling")

    @horizontal_pod_autoscaling.setter
    def horizontal_pod_autoscaling(self, value: Optional[pulumi.Input['ClusterAddonsConfigHorizontalPodAutoscalingArgs']]):
        pulumi.set(self, "horizontal_pod_autoscaling", value)

    @property
    @pulumi.getter(name="httpLoadBalancing")
    def http_load_balancing(self) -> Optional[pulumi.Input['ClusterAddonsConfigHttpLoadBalancingArgs']]:
        """
        The status of the HTTP (L7) load balancing
        controller addon, which makes it easy to set up HTTP load balancers for services in a
        cluster. It is enabled by default; set `disabled = true` to disable.
        """
        return pulumi.get(self, "http_load_balancing")

    @http_load_balancing.setter
    def http_load_balancing(self, value: Optional[pulumi.Input['ClusterAddonsConfigHttpLoadBalancingArgs']]):
        pulumi.set(self, "http_load_balancing", value)

    @property
    @pulumi.getter(name="istioConfig")
    def istio_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigIstioConfigArgs']]:
        """
        .
        Structure is documented below.
        """
        return pulumi.get(self, "istio_config")

    @istio_config.setter
    def istio_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigIstioConfigArgs']]):
        pulumi.set(self, "istio_config", value)

    @property
    @pulumi.getter(name="kalmConfig")
    def kalm_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigKalmConfigArgs']]:
        """
        .
        Configuration for the KALM addon, which manages the lifecycle of k8s. It is disabled by default; Set `enabled = true` to enable.
        """
        return pulumi.get(self, "kalm_config")

    @kalm_config.setter
    def kalm_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigKalmConfigArgs']]):
        pulumi.set(self, "kalm_config", value)

    @property
    @pulumi.getter(name="networkPolicyConfig")
    def network_policy_config(self) -> Optional[pulumi.Input['ClusterAddonsConfigNetworkPolicyConfigArgs']]:
        """
        Whether we should enable the network policy addon
        for the master.  This must be enabled in order to enable network policy for the nodes.
        To enable this, you must also define a `network_policy` block,
        otherwise nothing will happen.
        It can only be disabled if the nodes already do not have network policies enabled.
        Defaults to disabled; set `disabled = false` to enable.
        """
        return pulumi.get(self, "network_policy_config")

    @network_policy_config.setter
    def network_policy_config(self, value: Optional[pulumi.Input['ClusterAddonsConfigNetworkPolicyConfigArgs']]):
        pulumi.set(self, "network_policy_config", value)


@pulumi.input_type
class ClusterAddonsConfigCloudrunConfigArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[bool],
                 load_balancer_type: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[bool] disabled: The status of the CloudRun addon. It is disabled by default. Set `disabled=false` to enable.
        :param pulumi.Input[str] load_balancer_type: The load balancer type of CloudRun ingress service. It is external load balancer by default.
               Set `load_balancer_type=LOAD_BALANCER_TYPE_INTERNAL` to configure it as internal load balancer.
        """
        pulumi.set(__self__, "disabled", disabled)
        if load_balancer_type is not None:
            pulumi.set(__self__, "load_balancer_type", load_balancer_type)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[bool]:
        """
        The status of the CloudRun addon. It is disabled by default. Set `disabled=false` to enable.
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "disabled", value)

    @property
    @pulumi.getter(name="loadBalancerType")
    def load_balancer_type(self) -> Optional[pulumi.Input[str]]:
        """
        The load balancer type of CloudRun ingress service. It is external load balancer by default.
        Set `load_balancer_type=LOAD_BALANCER_TYPE_INTERNAL` to configure it as internal load balancer.
        """
        return pulumi.get(self, "load_balancer_type")

    @load_balancer_type.setter
    def load_balancer_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "load_balancer_type", value)


@pulumi.input_type
class ClusterAddonsConfigConfigConnectorConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterAddonsConfigDnsCacheConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterAddonsConfigGcePersistentDiskCsiDriverConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterAddonsConfigGcpFilestoreCsiDriverConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterAddonsConfigGcsFuseCsiDriverConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterAddonsConfigGkeBackupAgentConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterAddonsConfigHorizontalPodAutoscalingArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[bool]:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "disabled", value)


@pulumi.input_type
class ClusterAddonsConfigHttpLoadBalancingArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[bool]:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "disabled", value)


@pulumi.input_type
class ClusterAddonsConfigIstioConfigArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[bool],
                 auth: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[bool] disabled: The status of the Istio addon, which makes it easy to set up Istio for services in a
               cluster. It is disabled by default. Set `disabled = false` to enable.
        :param pulumi.Input[str] auth: The authentication type between services in Istio. Available options include `AUTH_MUTUAL_TLS`.
        """
        pulumi.set(__self__, "disabled", disabled)
        if auth is not None:
            pulumi.set(__self__, "auth", auth)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[bool]:
        """
        The status of the Istio addon, which makes it easy to set up Istio for services in a
        cluster. It is disabled by default. Set `disabled = false` to enable.
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "disabled", value)

    @property
    @pulumi.getter
    def auth(self) -> Optional[pulumi.Input[str]]:
        """
        The authentication type between services in Istio. Available options include `AUTH_MUTUAL_TLS`.
        """
        return pulumi.get(self, "auth")

    @auth.setter
    def auth(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "auth", value)


@pulumi.input_type
class ClusterAddonsConfigKalmConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterAddonsConfigNetworkPolicyConfigArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[bool]:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "disabled", value)


@pulumi.input_type
class ClusterAuthenticatorGroupsConfigArgs:
    def __init__(__self__, *,
                 security_group: pulumi.Input[str]):
        """
        :param pulumi.Input[str] security_group: The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format `gke-security-groups@yourdomain.com`.
        """
        pulumi.set(__self__, "security_group", security_group)

    @property
    @pulumi.getter(name="securityGroup")
    def security_group(self) -> pulumi.Input[str]:
        """
        The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format `gke-security-groups@yourdomain.com`.
        """
        return pulumi.get(self, "security_group")

    @security_group.setter
    def security_group(self, value: pulumi.Input[str]):
        pulumi.set(self, "security_group", value)


@pulumi.input_type
class ClusterBinaryAuthorizationArgs:
    def __init__(__self__, *,
                 enabled: Optional[pulumi.Input[bool]] = None,
                 evaluation_mode: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[bool] enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        :param pulumi.Input[str] evaluation_mode: Mode of operation for Binary Authorization policy evaluation. Valid values are `DISABLED`
               and `PROJECT_SINGLETON_POLICY_ENFORCE`. `PROJECT_SINGLETON_POLICY_ENFORCE` is functionally equivalent to the
               deprecated `enable_binary_authorization` parameter being set to `true`.
        """
        if enabled is not None:
            warnings.warn("""Deprecated in favor of evaluation_mode.""", DeprecationWarning)
            pulumi.log.warn("""enabled is deprecated: Deprecated in favor of evaluation_mode.""")
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if evaluation_mode is not None:
            pulumi.set(__self__, "evaluation_mode", evaluation_mode)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[pulumi.Input[bool]]:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        warnings.warn("""Deprecated in favor of evaluation_mode.""", DeprecationWarning)
        pulumi.log.warn("""enabled is deprecated: Deprecated in favor of evaluation_mode.""")

        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter(name="evaluationMode")
    def evaluation_mode(self) -> Optional[pulumi.Input[str]]:
        """
        Mode of operation for Binary Authorization policy evaluation. Valid values are `DISABLED`
        and `PROJECT_SINGLETON_POLICY_ENFORCE`. `PROJECT_SINGLETON_POLICY_ENFORCE` is functionally equivalent to the
        deprecated `enable_binary_authorization` parameter being set to `true`.
        """
        return pulumi.get(self, "evaluation_mode")

    @evaluation_mode.setter
    def evaluation_mode(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "evaluation_mode", value)


@pulumi.input_type
class ClusterClusterAutoscalingArgs:
    def __init__(__self__, *,
                 auto_provisioning_defaults: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsArgs']] = None,
                 autoscaling_profile: Optional[pulumi.Input[str]] = None,
                 enabled: Optional[pulumi.Input[bool]] = None,
                 resource_limits: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingResourceLimitArgs']]]] = None):
        """
        :param pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsArgs'] auto_provisioning_defaults: Contains defaults for a node pool created by NAP. A subset of fields also apply to
               GKE Autopilot clusters.
               Structure is documented below.
        :param pulumi.Input[str] autoscaling_profile: ) Configuration
               options for the [Autoscaling profile](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler#autoscaling_profiles)
               feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability
               when deciding to remove nodes from a cluster. Can be `BALANCED` or `OPTIMIZE_UTILIZATION`. Defaults to `BALANCED`.
        :param pulumi.Input[bool] enabled: Whether node auto-provisioning is enabled. Must be supplied for GKE Standard clusters, `true` is implied
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingResourceLimitArgs']]] resource_limits: Global constraints for machine resources in the
               cluster. Configuring the `cpu` and `memory` types is required if node
               auto-provisioning is enabled. These limits will apply to node pool autoscaling
               in addition to node auto-provisioning. Structure is documented below.
        """
        if auto_provisioning_defaults is not None:
            pulumi.set(__self__, "auto_provisioning_defaults", auto_provisioning_defaults)
        if autoscaling_profile is not None:
            pulumi.set(__self__, "autoscaling_profile", autoscaling_profile)
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if resource_limits is not None:
            pulumi.set(__self__, "resource_limits", resource_limits)

    @property
    @pulumi.getter(name="autoProvisioningDefaults")
    def auto_provisioning_defaults(self) -> Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsArgs']]:
        """
        Contains defaults for a node pool created by NAP. A subset of fields also apply to
        GKE Autopilot clusters.
        Structure is documented below.
        """
        return pulumi.get(self, "auto_provisioning_defaults")

    @auto_provisioning_defaults.setter
    def auto_provisioning_defaults(self, value: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsArgs']]):
        pulumi.set(self, "auto_provisioning_defaults", value)

    @property
    @pulumi.getter(name="autoscalingProfile")
    def autoscaling_profile(self) -> Optional[pulumi.Input[str]]:
        """
        ) Configuration
        options for the [Autoscaling profile](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler#autoscaling_profiles)
        feature, which lets you choose whether the cluster autoscaler should optimize for resource utilization or resource availability
        when deciding to remove nodes from a cluster. Can be `BALANCED` or `OPTIMIZE_UTILIZATION`. Defaults to `BALANCED`.
        """
        return pulumi.get(self, "autoscaling_profile")

    @autoscaling_profile.setter
    def autoscaling_profile(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "autoscaling_profile", value)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether node auto-provisioning is enabled. Must be supplied for GKE Standard clusters, `true` is implied
        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter(name="resourceLimits")
    def resource_limits(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingResourceLimitArgs']]]]:
        """
        Global constraints for machine resources in the
        cluster. Configuring the `cpu` and `memory` types is required if node
        auto-provisioning is enabled. These limits will apply to node pool autoscaling
        in addition to node auto-provisioning. Structure is documented below.
        """
        return pulumi.get(self, "resource_limits")

    @resource_limits.setter
    def resource_limits(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingResourceLimitArgs']]]]):
        pulumi.set(self, "resource_limits", value)


@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsArgs:
    def __init__(__self__, *,
                 boot_disk_kms_key: Optional[pulumi.Input[str]] = None,
                 disk_size: Optional[pulumi.Input[int]] = None,
                 disk_type: Optional[pulumi.Input[str]] = None,
                 image_type: Optional[pulumi.Input[str]] = None,
                 management: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs']] = None,
                 min_cpu_platform: Optional[pulumi.Input[str]] = None,
                 oauth_scopes: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 service_account: Optional[pulumi.Input[str]] = None,
                 shielded_instance_config: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs']] = None,
                 upgrade_settings: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs']] = None):
        """
        :param pulumi.Input[str] boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
        :param pulumi.Input[int] disk_size: Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. Defaults to `100`
        :param pulumi.Input[str] disk_type: Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd' or 'pd-balanced'). Defaults to `pd-standard`
        :param pulumi.Input[str] image_type: The default image type used by NAP once a new node pool is being created. Please note that according to the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning#default-image-type) the value must be one of the [COS_CONTAINERD, COS, UBUNTU_CONTAINERD, UBUNTU]. __NOTE__ : COS AND UBUNTU are deprecated as of `GKE 1.24`
        :param pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs'] management: NodeManagement configuration for this NodePool. Structure is documented below.
        :param pulumi.Input[str] min_cpu_platform: Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the
               specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such
               as "Intel Haswell" or "Intel Sandy Bridge".
        :param pulumi.Input[Sequence[pulumi.Input[str]]] oauth_scopes: Scopes that are used by NAP and GKE Autopilot when creating node pools. Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               > `monitoring.write` is always enabled regardless of user input.  `monitoring` and `logging.write` may also be enabled depending on the values for `monitoring_service` and `logging_service`.
        :param pulumi.Input[str] service_account: The Google Cloud Platform Service Account to be used by the node VMs created by GKE Autopilot or NAP.
        :param pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs'] shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs'] upgrade_settings: Specifies the upgrade settings for NAP created node pools. Structure is documented below.
        """
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if disk_size is not None:
            pulumi.set(__self__, "disk_size", disk_size)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if management is not None:
            pulumi.set(__self__, "management", management)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if upgrade_settings is not None:
            pulumi.set(__self__, "upgrade_settings", upgrade_settings)

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[pulumi.Input[str]]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @boot_disk_kms_key.setter
    def boot_disk_kms_key(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "boot_disk_kms_key", value)

    @property
    @pulumi.getter(name="diskSize")
    def disk_size(self) -> Optional[pulumi.Input[int]]:
        """
        Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. Defaults to `100`
        """
        return pulumi.get(self, "disk_size")

    @disk_size.setter
    def disk_size(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "disk_size", value)

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[pulumi.Input[str]]:
        """
        Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd' or 'pd-balanced'). Defaults to `pd-standard`
        """
        return pulumi.get(self, "disk_type")

    @disk_type.setter
    def disk_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "disk_type", value)

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[pulumi.Input[str]]:
        """
        The default image type used by NAP once a new node pool is being created. Please note that according to the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning#default-image-type) the value must be one of the [COS_CONTAINERD, COS, UBUNTU_CONTAINERD, UBUNTU]. __NOTE__ : COS AND UBUNTU are deprecated as of `GKE 1.24`
        """
        return pulumi.get(self, "image_type")

    @image_type.setter
    def image_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "image_type", value)

    @property
    @pulumi.getter
    def management(self) -> Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs']]:
        """
        NodeManagement configuration for this NodePool. Structure is documented below.
        """
        return pulumi.get(self, "management")

    @management.setter
    def management(self, value: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs']]):
        pulumi.set(self, "management", value)

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[pulumi.Input[str]]:
        """
        Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the
        specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such
        as "Intel Haswell" or "Intel Sandy Bridge".
        """
        return pulumi.get(self, "min_cpu_platform")

    @min_cpu_platform.setter
    def min_cpu_platform(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "min_cpu_platform", value)

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Scopes that are used by NAP and GKE Autopilot when creating node pools. Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        > `monitoring.write` is always enabled regardless of user input.  `monitoring` and `logging.write` may also be enabled depending on the values for `monitoring_service` and `logging_service`.
        """
        return pulumi.get(self, "oauth_scopes")

    @oauth_scopes.setter
    def oauth_scopes(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "oauth_scopes", value)

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[pulumi.Input[str]]:
        """
        The Google Cloud Platform Service Account to be used by the node VMs created by GKE Autopilot or NAP.
        """
        return pulumi.get(self, "service_account")

    @service_account.setter
    def service_account(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "service_account", value)

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs']]:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @shielded_instance_config.setter
    def shielded_instance_config(self, value: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs']]):
        pulumi.set(self, "shielded_instance_config", value)

    @property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs']]:
        """
        Specifies the upgrade settings for NAP created node pools. Structure is documented below.
        """
        return pulumi.get(self, "upgrade_settings")

    @upgrade_settings.setter
    def upgrade_settings(self, value: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs']]):
        pulumi.set(self, "upgrade_settings", value)


@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsManagementArgs:
    def __init__(__self__, *,
                 auto_repair: Optional[pulumi.Input[bool]] = None,
                 auto_upgrade: Optional[pulumi.Input[bool]] = None,
                 upgrade_options: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs']]]] = None):
        """
        :param pulumi.Input[bool] auto_repair: Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
               
               This block also contains several computed attributes, documented below.
        :param pulumi.Input[bool] auto_upgrade: Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)
        if upgrade_options is not None:
            pulumi.set(__self__, "upgrade_options", upgrade_options)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[pulumi.Input[bool]]:
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.

        This block also contains several computed attributes, documented below.
        """
        return pulumi.get(self, "auto_repair")

    @auto_repair.setter
    def auto_repair(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "auto_repair", value)

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[pulumi.Input[bool]]:
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        return pulumi.get(self, "auto_upgrade")

    @auto_upgrade.setter
    def auto_upgrade(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "auto_upgrade", value)

    @property
    @pulumi.getter(name="upgradeOptions")
    def upgrade_options(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs']]]]:
        return pulumi.get(self, "upgrade_options")

    @upgrade_options.setter
    def upgrade_options(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs']]]]):
        pulumi.set(self, "upgrade_options", value)


@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsManagementUpgradeOptionArgs:
    def __init__(__self__, *,
                 auto_upgrade_start_time: Optional[pulumi.Input[str]] = None,
                 description: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] description: Description of the cluster.
        """
        if auto_upgrade_start_time is not None:
            pulumi.set(__self__, "auto_upgrade_start_time", auto_upgrade_start_time)
        if description is not None:
            pulumi.set(__self__, "description", description)

    @property
    @pulumi.getter(name="autoUpgradeStartTime")
    def auto_upgrade_start_time(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "auto_upgrade_start_time")

    @auto_upgrade_start_time.setter
    def auto_upgrade_start_time(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "auto_upgrade_start_time", value)

    @property
    @pulumi.getter
    def description(self) -> Optional[pulumi.Input[str]]:
        """
        Description of the cluster.
        """
        return pulumi.get(self, "description")

    @description.setter
    def description(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "description", value)


@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsShieldedInstanceConfigArgs:
    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[pulumi.Input[bool]] = None,
                 enable_secure_boot: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[bool] enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param pulumi.Input[bool] enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[pulumi.Input[bool]]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @enable_integrity_monitoring.setter
    def enable_integrity_monitoring(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_integrity_monitoring", value)

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[pulumi.Input[bool]]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")

    @enable_secure_boot.setter
    def enable_secure_boot(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_secure_boot", value)


@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsArgs:
    def __init__(__self__, *,
                 blue_green_settings: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs']] = None,
                 max_surge: Optional[pulumi.Input[int]] = None,
                 max_unavailable: Optional[pulumi.Input[int]] = None,
                 strategy: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs'] blue_green_settings: Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param pulumi.Input[int] max_surge: The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param pulumi.Input[int] max_unavailable: The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param pulumi.Input[str] strategy: Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs']]:
        """
        Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "blue_green_settings")

    @blue_green_settings.setter
    def blue_green_settings(self, value: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs']]):
        pulumi.set(self, "blue_green_settings", value)

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_surge")

    @max_surge.setter
    def max_surge(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_surge", value)

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_unavailable")

    @max_unavailable.setter
    def max_unavailable(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_unavailable", value)

    @property
    @pulumi.getter
    def strategy(self) -> Optional[pulumi.Input[str]]:
        """
        Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        return pulumi.get(self, "strategy")

    @strategy.setter
    def strategy(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "strategy", value)


@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsArgs:
    def __init__(__self__, *,
                 node_pool_soak_duration: Optional[pulumi.Input[str]] = None,
                 standard_rollout_policy: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']] = None):
        """
        :param pulumi.Input[str] node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        :param pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs'] standard_rollout_policy: Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)
        if standard_rollout_policy is not None:
            pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[pulumi.Input[str]]:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @node_pool_soak_duration.setter
    def node_pool_soak_duration(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "node_pool_soak_duration", value)

    @property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']]:
        """
        Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "standard_rollout_policy")

    @standard_rollout_policy.setter
    def standard_rollout_policy(self, value: Optional[pulumi.Input['ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']]):
        pulumi.set(self, "standard_rollout_policy", value)


@pulumi.input_type
class ClusterClusterAutoscalingAutoProvisioningDefaultsUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs:
    def __init__(__self__, *,
                 batch_node_count: Optional[pulumi.Input[int]] = None,
                 batch_percentage: Optional[pulumi.Input[float]] = None,
                 batch_soak_duration: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[int] batch_node_count: Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        :param pulumi.Input[float] batch_percentage: Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        :param pulumi.Input[str] batch_soak_duration: Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[pulumi.Input[int]]:
        """
        Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_node_count")

    @batch_node_count.setter
    def batch_node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "batch_node_count", value)

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[pulumi.Input[float]]:
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_percentage")

    @batch_percentage.setter
    def batch_percentage(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "batch_percentage", value)

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[pulumi.Input[str]]:
        """
        Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        return pulumi.get(self, "batch_soak_duration")

    @batch_soak_duration.setter
    def batch_soak_duration(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "batch_soak_duration", value)


@pulumi.input_type
class ClusterClusterAutoscalingResourceLimitArgs:
    def __init__(__self__, *,
                 resource_type: pulumi.Input[str],
                 maximum: Optional[pulumi.Input[int]] = None,
                 minimum: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input[str] resource_type: The type of the resource. For example, `cpu` and
               `memory`.  See the [guide to using Node Auto-Provisioning](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)
               for a list of types.
        :param pulumi.Input[int] maximum: Maximum amount of the resource in the cluster.
        :param pulumi.Input[int] minimum: Minimum amount of the resource in the cluster.
        """
        pulumi.set(__self__, "resource_type", resource_type)
        if maximum is not None:
            pulumi.set(__self__, "maximum", maximum)
        if minimum is not None:
            pulumi.set(__self__, "minimum", minimum)

    @property
    @pulumi.getter(name="resourceType")
    def resource_type(self) -> pulumi.Input[str]:
        """
        The type of the resource. For example, `cpu` and
        `memory`.  See the [guide to using Node Auto-Provisioning](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)
        for a list of types.
        """
        return pulumi.get(self, "resource_type")

    @resource_type.setter
    def resource_type(self, value: pulumi.Input[str]):
        pulumi.set(self, "resource_type", value)

    @property
    @pulumi.getter
    def maximum(self) -> Optional[pulumi.Input[int]]:
        """
        Maximum amount of the resource in the cluster.
        """
        return pulumi.get(self, "maximum")

    @maximum.setter
    def maximum(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "maximum", value)

    @property
    @pulumi.getter
    def minimum(self) -> Optional[pulumi.Input[int]]:
        """
        Minimum amount of the resource in the cluster.
        """
        return pulumi.get(self, "minimum")

    @minimum.setter
    def minimum(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "minimum", value)


@pulumi.input_type
class ClusterClusterTelemetryArgs:
    def __init__(__self__, *,
                 type: pulumi.Input[str]):
        """
        :param pulumi.Input[str] type: Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
               `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input[str]:
        """
        Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
        `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[str]):
        pulumi.set(self, "type", value)


@pulumi.input_type
class ClusterConfidentialNodesArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterCostManagementConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Whether to enable the [cost allocation](https://cloud.google.com/kubernetes-engine/docs/how-to/cost-allocations) feature.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Whether to enable the [cost allocation](https://cloud.google.com/kubernetes-engine/docs/how-to/cost-allocations) feature.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterDatabaseEncryptionArgs:
    def __init__(__self__, *,
                 state: pulumi.Input[str],
                 key_name: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] state: `ENCRYPTED` or `DECRYPTED`
        :param pulumi.Input[str] key_name: the key to use to encrypt/decrypt secrets.  See the [DatabaseEncryption definition](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.DatabaseEncryption) for more information.
               
               <a name="nested_enable_k8s_beta_apis"></a>The `enable_k8s_beta_apis` block supports:
        """
        pulumi.set(__self__, "state", state)
        if key_name is not None:
            pulumi.set(__self__, "key_name", key_name)

    @property
    @pulumi.getter
    def state(self) -> pulumi.Input[str]:
        """
        `ENCRYPTED` or `DECRYPTED`
        """
        return pulumi.get(self, "state")

    @state.setter
    def state(self, value: pulumi.Input[str]):
        pulumi.set(self, "state", value)

    @property
    @pulumi.getter(name="keyName")
    def key_name(self) -> Optional[pulumi.Input[str]]:
        """
        the key to use to encrypt/decrypt secrets.  See the [DatabaseEncryption definition](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.DatabaseEncryption) for more information.

        <a name="nested_enable_k8s_beta_apis"></a>The `enable_k8s_beta_apis` block supports:
        """
        return pulumi.get(self, "key_name")

    @key_name.setter
    def key_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "key_name", value)


@pulumi.input_type
class ClusterDefaultSnatStatusArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[bool]:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "disabled", value)


@pulumi.input_type
class ClusterDnsConfigArgs:
    def __init__(__self__, *,
                 cluster_dns: Optional[pulumi.Input[str]] = None,
                 cluster_dns_domain: Optional[pulumi.Input[str]] = None,
                 cluster_dns_scope: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] cluster_dns: Which in-cluster DNS provider should be used. `PROVIDER_UNSPECIFIED` (default) or `PLATFORM_DEFAULT` or `CLOUD_DNS`.
        :param pulumi.Input[str] cluster_dns_domain: The suffix used for all cluster service records.
        :param pulumi.Input[str] cluster_dns_scope: The scope of access to cluster DNS records. `DNS_SCOPE_UNSPECIFIED` (default) or `CLUSTER_SCOPE` or `VPC_SCOPE`.
        """
        if cluster_dns is not None:
            pulumi.set(__self__, "cluster_dns", cluster_dns)
        if cluster_dns_domain is not None:
            pulumi.set(__self__, "cluster_dns_domain", cluster_dns_domain)
        if cluster_dns_scope is not None:
            pulumi.set(__self__, "cluster_dns_scope", cluster_dns_scope)

    @property
    @pulumi.getter(name="clusterDns")
    def cluster_dns(self) -> Optional[pulumi.Input[str]]:
        """
        Which in-cluster DNS provider should be used. `PROVIDER_UNSPECIFIED` (default) or `PLATFORM_DEFAULT` or `CLOUD_DNS`.
        """
        return pulumi.get(self, "cluster_dns")

    @cluster_dns.setter
    def cluster_dns(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "cluster_dns", value)

    @property
    @pulumi.getter(name="clusterDnsDomain")
    def cluster_dns_domain(self) -> Optional[pulumi.Input[str]]:
        """
        The suffix used for all cluster service records.
        """
        return pulumi.get(self, "cluster_dns_domain")

    @cluster_dns_domain.setter
    def cluster_dns_domain(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "cluster_dns_domain", value)

    @property
    @pulumi.getter(name="clusterDnsScope")
    def cluster_dns_scope(self) -> Optional[pulumi.Input[str]]:
        """
        The scope of access to cluster DNS records. `DNS_SCOPE_UNSPECIFIED` (default) or `CLUSTER_SCOPE` or `VPC_SCOPE`.
        """
        return pulumi.get(self, "cluster_dns_scope")

    @cluster_dns_scope.setter
    def cluster_dns_scope(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "cluster_dns_scope", value)


@pulumi.input_type
class ClusterEnableK8sBetaApisArgs:
    def __init__(__self__, *,
                 enabled_apis: pulumi.Input[Sequence[pulumi.Input[str]]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] enabled_apis: Enabled Kubernetes Beta APIs. To list a Beta API resource, use the representation {group}/{version}/{resource}. The version must be a Beta version. Note that you cannot disable beta APIs that are already enabled on a cluster without recreating it. See the [Configure beta APIs](https://cloud.google.com/kubernetes-engine/docs/how-to/use-beta-apis#configure-beta-apis) for more information.
        """
        pulumi.set(__self__, "enabled_apis", enabled_apis)

    @property
    @pulumi.getter(name="enabledApis")
    def enabled_apis(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        Enabled Kubernetes Beta APIs. To list a Beta API resource, use the representation {group}/{version}/{resource}. The version must be a Beta version. Note that you cannot disable beta APIs that are already enabled on a cluster without recreating it. See the [Configure beta APIs](https://cloud.google.com/kubernetes-engine/docs/how-to/use-beta-apis#configure-beta-apis) for more information.
        """
        return pulumi.get(self, "enabled_apis")

    @enabled_apis.setter
    def enabled_apis(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "enabled_apis", value)


@pulumi.input_type
class ClusterGatewayApiConfigArgs:
    def __init__(__self__, *,
                 channel: pulumi.Input[str]):
        """
        :param pulumi.Input[str] channel: Which Gateway Api channel should be used. `CHANNEL_DISABLED`, `CHANNEL_EXPERIMENTAL` or `CHANNEL_STANDARD`.
        """
        pulumi.set(__self__, "channel", channel)

    @property
    @pulumi.getter
    def channel(self) -> pulumi.Input[str]:
        """
        Which Gateway Api channel should be used. `CHANNEL_DISABLED`, `CHANNEL_EXPERIMENTAL` or `CHANNEL_STANDARD`.
        """
        return pulumi.get(self, "channel")

    @channel.setter
    def channel(self, value: pulumi.Input[str]):
        pulumi.set(self, "channel", value)


@pulumi.input_type
class ClusterIdentityServiceConfigArgs:
    def __init__(__self__, *,
                 enabled: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[bool] enabled: Whether to enable the Identity Service component. It is disabled by default. Set `enabled=true` to enable.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether to enable the Identity Service component. It is disabled by default. Set `enabled=true` to enable.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterIpAllocationPolicyArgs:
    def __init__(__self__, *,
                 additional_pod_ranges_config: Optional[pulumi.Input['ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs']] = None,
                 cluster_ipv4_cidr_block: Optional[pulumi.Input[str]] = None,
                 cluster_secondary_range_name: Optional[pulumi.Input[str]] = None,
                 pod_cidr_overprovision_config: Optional[pulumi.Input['ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs']] = None,
                 services_ipv4_cidr_block: Optional[pulumi.Input[str]] = None,
                 services_secondary_range_name: Optional[pulumi.Input[str]] = None,
                 stack_type: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs'] additional_pod_ranges_config: The configuration for additional pod secondary ranges at
               the cluster level. Used for Autopilot clusters and Standard clusters with which control of the
               secondary Pod IP address assignment to node pools isn't needed. Structure is documented below.
        :param pulumi.Input[str] cluster_ipv4_cidr_block: The IP address range for the cluster pod IPs.
               Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
               to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
               from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
               pick a specific range to use.
        :param pulumi.Input[str] cluster_secondary_range_name: The name of the existing secondary
               range in the cluster's subnetwork to use for pod IP addresses. Alternatively,
               `cluster_ipv4_cidr_block` can be used to automatically create a GKE-managed one.
        :param pulumi.Input[str] services_ipv4_cidr_block: The IP address range of the services IPs in this cluster.
               Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
               to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
               from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
               pick a specific range to use.
        :param pulumi.Input[str] services_secondary_range_name: The name of the existing
               secondary range in the cluster's subnetwork to use for service `ClusterIP`s.
               Alternatively, `services_ipv4_cidr_block` can be used to automatically create a
               GKE-managed one.
        :param pulumi.Input[str] stack_type: The IP Stack Type of the cluster.
               Default value is `IPV4`.
               Possible values are `IPV4` and `IPV4_IPV6`.
        """
        if additional_pod_ranges_config is not None:
            pulumi.set(__self__, "additional_pod_ranges_config", additional_pod_ranges_config)
        if cluster_ipv4_cidr_block is not None:
            pulumi.set(__self__, "cluster_ipv4_cidr_block", cluster_ipv4_cidr_block)
        if cluster_secondary_range_name is not None:
            pulumi.set(__self__, "cluster_secondary_range_name", cluster_secondary_range_name)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if services_ipv4_cidr_block is not None:
            pulumi.set(__self__, "services_ipv4_cidr_block", services_ipv4_cidr_block)
        if services_secondary_range_name is not None:
            pulumi.set(__self__, "services_secondary_range_name", services_secondary_range_name)
        if stack_type is not None:
            pulumi.set(__self__, "stack_type", stack_type)

    @property
    @pulumi.getter(name="additionalPodRangesConfig")
    def additional_pod_ranges_config(self) -> Optional[pulumi.Input['ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs']]:
        """
        The configuration for additional pod secondary ranges at
        the cluster level. Used for Autopilot clusters and Standard clusters with which control of the
        secondary Pod IP address assignment to node pools isn't needed. Structure is documented below.
        """
        return pulumi.get(self, "additional_pod_ranges_config")

    @additional_pod_ranges_config.setter
    def additional_pod_ranges_config(self, value: Optional[pulumi.Input['ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs']]):
        pulumi.set(self, "additional_pod_ranges_config", value)

    @property
    @pulumi.getter(name="clusterIpv4CidrBlock")
    def cluster_ipv4_cidr_block(self) -> Optional[pulumi.Input[str]]:
        """
        The IP address range for the cluster pod IPs.
        Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
        to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
        from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
        pick a specific range to use.
        """
        return pulumi.get(self, "cluster_ipv4_cidr_block")

    @cluster_ipv4_cidr_block.setter
    def cluster_ipv4_cidr_block(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "cluster_ipv4_cidr_block", value)

    @property
    @pulumi.getter(name="clusterSecondaryRangeName")
    def cluster_secondary_range_name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the existing secondary
        range in the cluster's subnetwork to use for pod IP addresses. Alternatively,
        `cluster_ipv4_cidr_block` can be used to automatically create a GKE-managed one.
        """
        return pulumi.get(self, "cluster_secondary_range_name")

    @cluster_secondary_range_name.setter
    def cluster_secondary_range_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "cluster_secondary_range_name", value)

    @property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional[pulumi.Input['ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs']]:
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @pod_cidr_overprovision_config.setter
    def pod_cidr_overprovision_config(self, value: Optional[pulumi.Input['ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs']]):
        pulumi.set(self, "pod_cidr_overprovision_config", value)

    @property
    @pulumi.getter(name="servicesIpv4CidrBlock")
    def services_ipv4_cidr_block(self) -> Optional[pulumi.Input[str]]:
        """
        The IP address range of the services IPs in this cluster.
        Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14)
        to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14)
        from the RFC-1918 private networks (e.g. 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) to
        pick a specific range to use.
        """
        return pulumi.get(self, "services_ipv4_cidr_block")

    @services_ipv4_cidr_block.setter
    def services_ipv4_cidr_block(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "services_ipv4_cidr_block", value)

    @property
    @pulumi.getter(name="servicesSecondaryRangeName")
    def services_secondary_range_name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the existing
        secondary range in the cluster's subnetwork to use for service `ClusterIP`s.
        Alternatively, `services_ipv4_cidr_block` can be used to automatically create a
        GKE-managed one.
        """
        return pulumi.get(self, "services_secondary_range_name")

    @services_secondary_range_name.setter
    def services_secondary_range_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "services_secondary_range_name", value)

    @property
    @pulumi.getter(name="stackType")
    def stack_type(self) -> Optional[pulumi.Input[str]]:
        """
        The IP Stack Type of the cluster.
        Default value is `IPV4`.
        Possible values are `IPV4` and `IPV4_IPV6`.
        """
        return pulumi.get(self, "stack_type")

    @stack_type.setter
    def stack_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "stack_type", value)


@pulumi.input_type
class ClusterIpAllocationPolicyAdditionalPodRangesConfigArgs:
    def __init__(__self__, *,
                 pod_range_names: pulumi.Input[Sequence[pulumi.Input[str]]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] pod_range_names: The names of the Pod ranges to add to the cluster.
        """
        pulumi.set(__self__, "pod_range_names", pod_range_names)

    @property
    @pulumi.getter(name="podRangeNames")
    def pod_range_names(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        The names of the Pod ranges to add to the cluster.
        """
        return pulumi.get(self, "pod_range_names")

    @pod_range_names.setter
    def pod_range_names(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "pod_range_names", value)


@pulumi.input_type
class ClusterIpAllocationPolicyPodCidrOverprovisionConfigArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[bool]:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "disabled", value)


@pulumi.input_type
class ClusterLoggingConfigArgs:
    def __init__(__self__, *,
                 enable_components: pulumi.Input[Sequence[pulumi.Input[str]]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] enable_components: The GKE components exposing logs. Supported values include:
               `SYSTEM_COMPONENTS`, `APISERVER`, `CONTROLLER_MANAGER`, `SCHEDULER`, and `WORKLOADS`.
        """
        pulumi.set(__self__, "enable_components", enable_components)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        The GKE components exposing logs. Supported values include:
        `SYSTEM_COMPONENTS`, `APISERVER`, `CONTROLLER_MANAGER`, `SCHEDULER`, and `WORKLOADS`.
        """
        return pulumi.get(self, "enable_components")

    @enable_components.setter
    def enable_components(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "enable_components", value)


@pulumi.input_type
class ClusterMaintenancePolicyArgs:
    def __init__(__self__, *,
                 daily_maintenance_window: Optional[pulumi.Input['ClusterMaintenancePolicyDailyMaintenanceWindowArgs']] = None,
                 maintenance_exclusions: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionArgs']]]] = None,
                 recurring_window: Optional[pulumi.Input['ClusterMaintenancePolicyRecurringWindowArgs']] = None):
        """
        :param pulumi.Input['ClusterMaintenancePolicyDailyMaintenanceWindowArgs'] daily_maintenance_window: Time window specified for daily maintenance operations.
               Specify `start_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM,
               where HH : \\[00-23\\] and MM : \\[00-59\\] GMT. For example:
               
               Examples:
               ```python
               import pulumi
               ```
        :param pulumi.Input[Sequence[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionArgs']]] maintenance_exclusions: Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows. A cluster can have up to 20 maintenance exclusions at a time [Maintenance Window and Exclusions](https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions)
        :param pulumi.Input['ClusterMaintenancePolicyRecurringWindowArgs'] recurring_window: Time window for recurring maintenance operations.
               
               Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
               the initial date that the window starts, and the end time is used for calculating duration.  Specify `recurrence` in
               [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
               Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.
               
               Examples:
               ```python
               import pulumi
               ```
               
               ```python
               import pulumi
               ```
        """
        if daily_maintenance_window is not None:
            pulumi.set(__self__, "daily_maintenance_window", daily_maintenance_window)
        if maintenance_exclusions is not None:
            pulumi.set(__self__, "maintenance_exclusions", maintenance_exclusions)
        if recurring_window is not None:
            pulumi.set(__self__, "recurring_window", recurring_window)

    @property
    @pulumi.getter(name="dailyMaintenanceWindow")
    def daily_maintenance_window(self) -> Optional[pulumi.Input['ClusterMaintenancePolicyDailyMaintenanceWindowArgs']]:
        """
        Time window specified for daily maintenance operations.
        Specify `start_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM,
        where HH : \\[00-23\\] and MM : \\[00-59\\] GMT. For example:

        Examples:
        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "daily_maintenance_window")

    @daily_maintenance_window.setter
    def daily_maintenance_window(self, value: Optional[pulumi.Input['ClusterMaintenancePolicyDailyMaintenanceWindowArgs']]):
        pulumi.set(self, "daily_maintenance_window", value)

    @property
    @pulumi.getter(name="maintenanceExclusions")
    def maintenance_exclusions(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionArgs']]]]:
        """
        Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows. A cluster can have up to 20 maintenance exclusions at a time [Maintenance Window and Exclusions](https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions)
        """
        return pulumi.get(self, "maintenance_exclusions")

    @maintenance_exclusions.setter
    def maintenance_exclusions(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionArgs']]]]):
        pulumi.set(self, "maintenance_exclusions", value)

    @property
    @pulumi.getter(name="recurringWindow")
    def recurring_window(self) -> Optional[pulumi.Input['ClusterMaintenancePolicyRecurringWindowArgs']]:
        """
        Time window for recurring maintenance operations.

        Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
        the initial date that the window starts, and the end time is used for calculating duration.  Specify `recurrence` in
        [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
        Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.

        Examples:
        ```python
        import pulumi
        ```

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "recurring_window")

    @recurring_window.setter
    def recurring_window(self, value: Optional[pulumi.Input['ClusterMaintenancePolicyRecurringWindowArgs']]):
        pulumi.set(self, "recurring_window", value)


@pulumi.input_type
class ClusterMaintenancePolicyDailyMaintenanceWindowArgs:
    def __init__(__self__, *,
                 start_time: pulumi.Input[str],
                 duration: Optional[pulumi.Input[str]] = None):
        pulumi.set(__self__, "start_time", start_time)
        if duration is not None:
            pulumi.set(__self__, "duration", duration)

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> pulumi.Input[str]:
        return pulumi.get(self, "start_time")

    @start_time.setter
    def start_time(self, value: pulumi.Input[str]):
        pulumi.set(self, "start_time", value)

    @property
    @pulumi.getter
    def duration(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "duration")

    @duration.setter
    def duration(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "duration", value)


@pulumi.input_type
class ClusterMaintenancePolicyMaintenanceExclusionArgs:
    def __init__(__self__, *,
                 end_time: pulumi.Input[str],
                 exclusion_name: pulumi.Input[str],
                 start_time: pulumi.Input[str],
                 exclusion_options: Optional[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs']] = None):
        """
        :param pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs'] exclusion_options: MaintenanceExclusionOptions provides maintenance exclusion related options.
        """
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "exclusion_name", exclusion_name)
        pulumi.set(__self__, "start_time", start_time)
        if exclusion_options is not None:
            pulumi.set(__self__, "exclusion_options", exclusion_options)

    @property
    @pulumi.getter(name="endTime")
    def end_time(self) -> pulumi.Input[str]:
        return pulumi.get(self, "end_time")

    @end_time.setter
    def end_time(self, value: pulumi.Input[str]):
        pulumi.set(self, "end_time", value)

    @property
    @pulumi.getter(name="exclusionName")
    def exclusion_name(self) -> pulumi.Input[str]:
        return pulumi.get(self, "exclusion_name")

    @exclusion_name.setter
    def exclusion_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "exclusion_name", value)

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> pulumi.Input[str]:
        return pulumi.get(self, "start_time")

    @start_time.setter
    def start_time(self, value: pulumi.Input[str]):
        pulumi.set(self, "start_time", value)

    @property
    @pulumi.getter(name="exclusionOptions")
    def exclusion_options(self) -> Optional[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs']]:
        """
        MaintenanceExclusionOptions provides maintenance exclusion related options.
        """
        return pulumi.get(self, "exclusion_options")

    @exclusion_options.setter
    def exclusion_options(self, value: Optional[pulumi.Input['ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs']]):
        pulumi.set(self, "exclusion_options", value)


@pulumi.input_type
class ClusterMaintenancePolicyMaintenanceExclusionExclusionOptionsArgs:
    def __init__(__self__, *,
                 scope: pulumi.Input[str]):
        """
        :param pulumi.Input[str] scope: The scope of automatic upgrades to restrict in the exclusion window. One of: **NO_UPGRADES | NO_MINOR_UPGRADES | NO_MINOR_OR_NODE_UPGRADES**
               
               Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
               the initial date that the window starts, and the end time is used for calculating duration.Specify `recurrence` in
               [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
               Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.
               
               Examples:
               
               ```python
               import pulumi
               ```
        """
        pulumi.set(__self__, "scope", scope)

    @property
    @pulumi.getter
    def scope(self) -> pulumi.Input[str]:
        """
        The scope of automatic upgrades to restrict in the exclusion window. One of: **NO_UPGRADES | NO_MINOR_UPGRADES | NO_MINOR_OR_NODE_UPGRADES**

        Specify `start_time` and `end_time` in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) "Zulu" date format.  The start time's date is
        the initial date that the window starts, and the end time is used for calculating duration.Specify `recurrence` in
        [RFC5545](https://tools.ietf.org/html/rfc5545#section-3.8.5.3) RRULE format, to specify when this recurs.
        Note that GKE may accept other formats, but will return values in UTC, causing a permanent diff.

        Examples:

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "scope")

    @scope.setter
    def scope(self, value: pulumi.Input[str]):
        pulumi.set(self, "scope", value)


@pulumi.input_type
class ClusterMaintenancePolicyRecurringWindowArgs:
    def __init__(__self__, *,
                 end_time: pulumi.Input[str],
                 recurrence: pulumi.Input[str],
                 start_time: pulumi.Input[str]):
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "recurrence", recurrence)
        pulumi.set(__self__, "start_time", start_time)

    @property
    @pulumi.getter(name="endTime")
    def end_time(self) -> pulumi.Input[str]:
        return pulumi.get(self, "end_time")

    @end_time.setter
    def end_time(self, value: pulumi.Input[str]):
        pulumi.set(self, "end_time", value)

    @property
    @pulumi.getter
    def recurrence(self) -> pulumi.Input[str]:
        return pulumi.get(self, "recurrence")

    @recurrence.setter
    def recurrence(self, value: pulumi.Input[str]):
        pulumi.set(self, "recurrence", value)

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> pulumi.Input[str]:
        return pulumi.get(self, "start_time")

    @start_time.setter
    def start_time(self, value: pulumi.Input[str]):
        pulumi.set(self, "start_time", value)


@pulumi.input_type
class ClusterMasterAuthArgs:
    def __init__(__self__, *,
                 client_certificate_config: pulumi.Input['ClusterMasterAuthClientCertificateConfigArgs'],
                 client_certificate: Optional[pulumi.Input[str]] = None,
                 client_key: Optional[pulumi.Input[str]] = None,
                 cluster_ca_certificate: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['ClusterMasterAuthClientCertificateConfigArgs'] client_certificate_config: Whether client certificate authorization is enabled for this cluster.  For example:
               
               ```python
               import pulumi
               ```
               
               This block also contains several computed attributes, documented below.
        """
        pulumi.set(__self__, "client_certificate_config", client_certificate_config)
        if client_certificate is not None:
            pulumi.set(__self__, "client_certificate", client_certificate)
        if client_key is not None:
            pulumi.set(__self__, "client_key", client_key)
        if cluster_ca_certificate is not None:
            pulumi.set(__self__, "cluster_ca_certificate", cluster_ca_certificate)

    @property
    @pulumi.getter(name="clientCertificateConfig")
    def client_certificate_config(self) -> pulumi.Input['ClusterMasterAuthClientCertificateConfigArgs']:
        """
        Whether client certificate authorization is enabled for this cluster.  For example:

        ```python
        import pulumi
        ```

        This block also contains several computed attributes, documented below.
        """
        return pulumi.get(self, "client_certificate_config")

    @client_certificate_config.setter
    def client_certificate_config(self, value: pulumi.Input['ClusterMasterAuthClientCertificateConfigArgs']):
        pulumi.set(self, "client_certificate_config", value)

    @property
    @pulumi.getter(name="clientCertificate")
    def client_certificate(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "client_certificate")

    @client_certificate.setter
    def client_certificate(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "client_certificate", value)

    @property
    @pulumi.getter(name="clientKey")
    def client_key(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "client_key")

    @client_key.setter
    def client_key(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "client_key", value)

    @property
    @pulumi.getter(name="clusterCaCertificate")
    def cluster_ca_certificate(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "cluster_ca_certificate")

    @cluster_ca_certificate.setter
    def cluster_ca_certificate(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "cluster_ca_certificate", value)


@pulumi.input_type
class ClusterMasterAuthClientCertificateConfigArgs:
    def __init__(__self__, *,
                 issue_client_certificate: pulumi.Input[bool]):
        pulumi.set(__self__, "issue_client_certificate", issue_client_certificate)

    @property
    @pulumi.getter(name="issueClientCertificate")
    def issue_client_certificate(self) -> pulumi.Input[bool]:
        return pulumi.get(self, "issue_client_certificate")

    @issue_client_certificate.setter
    def issue_client_certificate(self, value: pulumi.Input[bool]):
        pulumi.set(self, "issue_client_certificate", value)


@pulumi.input_type
class ClusterMasterAuthorizedNetworksConfigArgs:
    def __init__(__self__, *,
                 cidr_blocks: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMasterAuthorizedNetworksConfigCidrBlockArgs']]]] = None,
                 gcp_public_cidrs_access_enabled: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input['ClusterMasterAuthorizedNetworksConfigCidrBlockArgs']]] cidr_blocks: External networks that can access the
               Kubernetes cluster master through HTTPS.
        :param pulumi.Input[bool] gcp_public_cidrs_access_enabled: Whether Kubernetes master is
               accessible via Google Compute Engine Public IPs.
        """
        if cidr_blocks is not None:
            pulumi.set(__self__, "cidr_blocks", cidr_blocks)
        if gcp_public_cidrs_access_enabled is not None:
            pulumi.set(__self__, "gcp_public_cidrs_access_enabled", gcp_public_cidrs_access_enabled)

    @property
    @pulumi.getter(name="cidrBlocks")
    def cidr_blocks(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMasterAuthorizedNetworksConfigCidrBlockArgs']]]]:
        """
        External networks that can access the
        Kubernetes cluster master through HTTPS.
        """
        return pulumi.get(self, "cidr_blocks")

    @cidr_blocks.setter
    def cidr_blocks(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMasterAuthorizedNetworksConfigCidrBlockArgs']]]]):
        pulumi.set(self, "cidr_blocks", value)

    @property
    @pulumi.getter(name="gcpPublicCidrsAccessEnabled")
    def gcp_public_cidrs_access_enabled(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether Kubernetes master is
        accessible via Google Compute Engine Public IPs.
        """
        return pulumi.get(self, "gcp_public_cidrs_access_enabled")

    @gcp_public_cidrs_access_enabled.setter
    def gcp_public_cidrs_access_enabled(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "gcp_public_cidrs_access_enabled", value)


@pulumi.input_type
class ClusterMasterAuthorizedNetworksConfigCidrBlockArgs:
    def __init__(__self__, *,
                 cidr_block: pulumi.Input[str],
                 display_name: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] cidr_block: External network that can access Kubernetes master through HTTPS.
               Must be specified in CIDR notation.
        :param pulumi.Input[str] display_name: Field for users to identify CIDR blocks.
        """
        pulumi.set(__self__, "cidr_block", cidr_block)
        if display_name is not None:
            pulumi.set(__self__, "display_name", display_name)

    @property
    @pulumi.getter(name="cidrBlock")
    def cidr_block(self) -> pulumi.Input[str]:
        """
        External network that can access Kubernetes master through HTTPS.
        Must be specified in CIDR notation.
        """
        return pulumi.get(self, "cidr_block")

    @cidr_block.setter
    def cidr_block(self, value: pulumi.Input[str]):
        pulumi.set(self, "cidr_block", value)

    @property
    @pulumi.getter(name="displayName")
    def display_name(self) -> Optional[pulumi.Input[str]]:
        """
        Field for users to identify CIDR blocks.
        """
        return pulumi.get(self, "display_name")

    @display_name.setter
    def display_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "display_name", value)


@pulumi.input_type
class ClusterMeshCertificatesArgs:
    def __init__(__self__, *,
                 enable_certificates: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enable_certificates: Controls the issuance of workload mTLS certificates. It is enabled by default. Workload Identity is required, see workload_config.
        """
        pulumi.set(__self__, "enable_certificates", enable_certificates)

    @property
    @pulumi.getter(name="enableCertificates")
    def enable_certificates(self) -> pulumi.Input[bool]:
        """
        Controls the issuance of workload mTLS certificates. It is enabled by default. Workload Identity is required, see workload_config.
        """
        return pulumi.get(self, "enable_certificates")

    @enable_certificates.setter
    def enable_certificates(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enable_certificates", value)


@pulumi.input_type
class ClusterMonitoringConfigArgs:
    def __init__(__self__, *,
                 advanced_datapath_observability_configs: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs']]]] = None,
                 enable_components: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 managed_prometheus: Optional[pulumi.Input['ClusterMonitoringConfigManagedPrometheusArgs']] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input['ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs']]] advanced_datapath_observability_configs: Configuration for Advanced Datapath Monitoring. Structure is documented below.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] enable_components: The GKE components exposing metrics. Supported values include: `SYSTEM_COMPONENTS`, `APISERVER`, `SCHEDULER`, `CONTROLLER_MANAGER`, `STORAGE`, `HPA`, `POD`, `DAEMONSET`, `DEPLOYMENT` and `STATEFULSET`. In beta provider, `WORKLOADS` is supported on top of those 10 values. (`WORKLOADS` is deprecated and removed in GKE 1.24.)
        :param pulumi.Input['ClusterMonitoringConfigManagedPrometheusArgs'] managed_prometheus: Configuration for Managed Service for Prometheus. Structure is documented below.
        """
        if advanced_datapath_observability_configs is not None:
            pulumi.set(__self__, "advanced_datapath_observability_configs", advanced_datapath_observability_configs)
        if enable_components is not None:
            pulumi.set(__self__, "enable_components", enable_components)
        if managed_prometheus is not None:
            pulumi.set(__self__, "managed_prometheus", managed_prometheus)

    @property
    @pulumi.getter(name="advancedDatapathObservabilityConfigs")
    def advanced_datapath_observability_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs']]]]:
        """
        Configuration for Advanced Datapath Monitoring. Structure is documented below.
        """
        return pulumi.get(self, "advanced_datapath_observability_configs")

    @advanced_datapath_observability_configs.setter
    def advanced_datapath_observability_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs']]]]):
        pulumi.set(self, "advanced_datapath_observability_configs", value)

    @property
    @pulumi.getter(name="enableComponents")
    def enable_components(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The GKE components exposing metrics. Supported values include: `SYSTEM_COMPONENTS`, `APISERVER`, `SCHEDULER`, `CONTROLLER_MANAGER`, `STORAGE`, `HPA`, `POD`, `DAEMONSET`, `DEPLOYMENT` and `STATEFULSET`. In beta provider, `WORKLOADS` is supported on top of those 10 values. (`WORKLOADS` is deprecated and removed in GKE 1.24.)
        """
        return pulumi.get(self, "enable_components")

    @enable_components.setter
    def enable_components(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "enable_components", value)

    @property
    @pulumi.getter(name="managedPrometheus")
    def managed_prometheus(self) -> Optional[pulumi.Input['ClusterMonitoringConfigManagedPrometheusArgs']]:
        """
        Configuration for Managed Service for Prometheus. Structure is documented below.
        """
        return pulumi.get(self, "managed_prometheus")

    @managed_prometheus.setter
    def managed_prometheus(self, value: Optional[pulumi.Input['ClusterMonitoringConfigManagedPrometheusArgs']]):
        pulumi.set(self, "managed_prometheus", value)


@pulumi.input_type
class ClusterMonitoringConfigAdvancedDatapathObservabilityConfigArgs:
    def __init__(__self__, *,
                 enable_metrics: pulumi.Input[bool],
                 relay_mode: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[bool] enable_metrics: Whether or not to enable advanced datapath metrics.
        :param pulumi.Input[str] relay_mode: Mode used to make Relay available.
        """
        pulumi.set(__self__, "enable_metrics", enable_metrics)
        if relay_mode is not None:
            pulumi.set(__self__, "relay_mode", relay_mode)

    @property
    @pulumi.getter(name="enableMetrics")
    def enable_metrics(self) -> pulumi.Input[bool]:
        """
        Whether or not to enable advanced datapath metrics.
        """
        return pulumi.get(self, "enable_metrics")

    @enable_metrics.setter
    def enable_metrics(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enable_metrics", value)

    @property
    @pulumi.getter(name="relayMode")
    def relay_mode(self) -> Optional[pulumi.Input[str]]:
        """
        Mode used to make Relay available.
        """
        return pulumi.get(self, "relay_mode")

    @relay_mode.setter
    def relay_mode(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "relay_mode", value)


@pulumi.input_type
class ClusterMonitoringConfigManagedPrometheusArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Whether or not the managed collection is enabled.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Whether or not the managed collection is enabled.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterNetworkPolicyArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool],
                 provider: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[bool] enabled: Whether network policy is enabled on the cluster.
        :param pulumi.Input[str] provider: The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.
        """
        pulumi.set(__self__, "enabled", enabled)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Whether network policy is enabled on the cluster.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter
    def provider(self) -> Optional[pulumi.Input[str]]:
        """
        The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.
        """
        return pulumi.get(self, "provider")

    @provider.setter
    def provider(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "provider", value)


@pulumi.input_type
class ClusterNodeConfigArgs:
    def __init__(__self__, *,
                 advanced_machine_features: Optional[pulumi.Input['ClusterNodeConfigAdvancedMachineFeaturesArgs']] = None,
                 boot_disk_kms_key: Optional[pulumi.Input[str]] = None,
                 confidential_nodes: Optional[pulumi.Input['ClusterNodeConfigConfidentialNodesArgs']] = None,
                 disk_size_gb: Optional[pulumi.Input[int]] = None,
                 disk_type: Optional[pulumi.Input[str]] = None,
                 ephemeral_storage_config: Optional[pulumi.Input['ClusterNodeConfigEphemeralStorageConfigArgs']] = None,
                 ephemeral_storage_local_ssd_config: Optional[pulumi.Input['ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs']] = None,
                 fast_socket: Optional[pulumi.Input['ClusterNodeConfigFastSocketArgs']] = None,
                 gcfs_config: Optional[pulumi.Input['ClusterNodeConfigGcfsConfigArgs']] = None,
                 guest_accelerators: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigGuestAcceleratorArgs']]]] = None,
                 gvnic: Optional[pulumi.Input['ClusterNodeConfigGvnicArgs']] = None,
                 host_maintenance_policy: Optional[pulumi.Input['ClusterNodeConfigHostMaintenancePolicyArgs']] = None,
                 image_type: Optional[pulumi.Input[str]] = None,
                 kubelet_config: Optional[pulumi.Input['ClusterNodeConfigKubeletConfigArgs']] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 linux_node_config: Optional[pulumi.Input['ClusterNodeConfigLinuxNodeConfigArgs']] = None,
                 local_nvme_ssd_block_config: Optional[pulumi.Input['ClusterNodeConfigLocalNvmeSsdBlockConfigArgs']] = None,
                 local_ssd_count: Optional[pulumi.Input[int]] = None,
                 logging_variant: Optional[pulumi.Input[str]] = None,
                 machine_type: Optional[pulumi.Input[str]] = None,
                 metadata: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 min_cpu_platform: Optional[pulumi.Input[str]] = None,
                 node_group: Optional[pulumi.Input[str]] = None,
                 oauth_scopes: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 preemptible: Optional[pulumi.Input[bool]] = None,
                 reservation_affinity: Optional[pulumi.Input['ClusterNodeConfigReservationAffinityArgs']] = None,
                 resource_labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 sandbox_config: Optional[pulumi.Input['ClusterNodeConfigSandboxConfigArgs']] = None,
                 service_account: Optional[pulumi.Input[str]] = None,
                 shielded_instance_config: Optional[pulumi.Input['ClusterNodeConfigShieldedInstanceConfigArgs']] = None,
                 sole_tenant_config: Optional[pulumi.Input['ClusterNodeConfigSoleTenantConfigArgs']] = None,
                 spot: Optional[pulumi.Input[bool]] = None,
                 tags: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 taints: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigTaintArgs']]]] = None,
                 workload_metadata_config: Optional[pulumi.Input['ClusterNodeConfigWorkloadMetadataConfigArgs']] = None):
        """
        :param pulumi.Input['ClusterNodeConfigAdvancedMachineFeaturesArgs'] advanced_machine_features: Specifies options for controlling
               advanced machine features. Structure is documented below.
        :param pulumi.Input[str] boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        :param pulumi.Input['ClusterNodeConfigConfidentialNodesArgs'] confidential_nodes: Configuration for [Confidential Nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/confidential-gke-nodes) feature. Structure is documented below documented below.
        :param pulumi.Input[int] disk_size_gb: Size of the disk attached to each node, specified
               in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        :param pulumi.Input[str] disk_type: Type of the disk attached to each node
               (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        :param pulumi.Input['ClusterNodeConfigEphemeralStorageConfigArgs'] ephemeral_storage_config: ) Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input['ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs'] ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input['ClusterNodeConfigFastSocketArgs'] fast_socket: Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
               Node Pool must enable gvnic.
               GKE version 1.25.2-gke.1700 or later.
               Structure is documented below.
        :param pulumi.Input['ClusterNodeConfigGcfsConfigArgs'] gcfs_config: Parameters for the Google Container Filesystem (GCFS).
               If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
               For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
               A `machine_type` that has more than 16 GiB of memory is also recommended.
               GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
               Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigGuestAcceleratorArgs']]] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
               Structure documented below.
        :param pulumi.Input['ClusterNodeConfigGvnicArgs'] gvnic: Google Virtual NIC (gVNIC) is a virtual network interface.
               Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
               gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
               GKE node version 1.15.11-gke.15 or later
               Structure is documented below.
               
               
               ```python
               import pulumi
               ```
        :param pulumi.Input[str] image_type: The image type to use for this node. Note that changing the image type
               will delete and recreate all nodes in the node pool.
        :param pulumi.Input['ClusterNodeConfigKubeletConfigArgs'] kubelet_config: Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] labels: The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
               reserved by Kubernetes Core components and cannot be specified.
        :param pulumi.Input['ClusterNodeConfigLinuxNodeConfigArgs'] linux_node_config: Linux node configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Note that validations happen all server side. All attributes are optional.
               Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input['ClusterNodeConfigLocalNvmeSsdBlockConfigArgs'] local_nvme_ssd_block_config: Parameters for the local NVMe SSDs. Structure is documented below.
        :param pulumi.Input[int] local_ssd_count: The amount of local SSD disks that will be
               attached to each cluster node. Defaults to 0.
        :param pulumi.Input[str] logging_variant: Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        :param pulumi.Input[str] machine_type: The name of a Google Compute Engine machine type.
               Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
               [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] metadata: The metadata key/value pairs assigned to instances in
               the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
               `true` by the API; if `metadata` is set but that default value is not
               included, the provider will attempt to unset the value. To avoid this, set the
               value in your config.
        :param pulumi.Input[str] min_cpu_platform: Minimum CPU platform to be used by this instance.
               The instance may be scheduled on the specified or newer CPU platform. Applicable
               values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
               [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
               for more information.
        :param pulumi.Input[str] node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] oauth_scopes: The set of Google API scopes to be made available
               on all of the node VMs under the "default" service account.
               Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        :param pulumi.Input[bool] preemptible: A boolean that represents whether or not the underlying node VMs
               are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
               for more information. Defaults to false.
        :param pulumi.Input['ClusterNodeConfigReservationAffinityArgs'] reservation_affinity: The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] resource_labels: The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
               for how these labels are applied to clusters, node pools and nodes.
        :param pulumi.Input[str] service_account: The service account to be used by the Node VMs.
               If not specified, the "default" service account is used.
        :param pulumi.Input['ClusterNodeConfigShieldedInstanceConfigArgs'] shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param pulumi.Input['ClusterNodeConfigSoleTenantConfigArgs'] sole_tenant_config: Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input[bool] spot: A boolean that represents whether the underlying node VMs are spot.
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
               for more information. Defaults to false.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] tags: The list of instance tags applied to all nodes. Tags are used to identify
               valid sources or targets for network firewalls.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigTaintArgs']]] taints: A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
               to apply to nodes. GKE's API can only set this field on cluster creation.
               However, GKE will add taints to your nodes if you enable certain features such
               as GPUs. If this field is set, any diffs on this field will cause the provider to
               recreate the underlying resource. Taint values can be updated safely in
               Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
               this field to manage taints. If you do, `lifecycle.ignore_changes` is
               recommended. Structure is documented below.
        :param pulumi.Input['ClusterNodeConfigWorkloadMetadataConfigArgs'] workload_metadata_config: Metadata configuration to expose to workloads on the node pool.
               Structure is documented below.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional[pulumi.Input['ClusterNodeConfigAdvancedMachineFeaturesArgs']]:
        """
        Specifies options for controlling
        advanced machine features. Structure is documented below.
        """
        return pulumi.get(self, "advanced_machine_features")

    @advanced_machine_features.setter
    def advanced_machine_features(self, value: Optional[pulumi.Input['ClusterNodeConfigAdvancedMachineFeaturesArgs']]):
        pulumi.set(self, "advanced_machine_features", value)

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[pulumi.Input[str]]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @boot_disk_kms_key.setter
    def boot_disk_kms_key(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "boot_disk_kms_key", value)

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional[pulumi.Input['ClusterNodeConfigConfidentialNodesArgs']]:
        """
        Configuration for [Confidential Nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/confidential-gke-nodes) feature. Structure is documented below documented below.
        """
        return pulumi.get(self, "confidential_nodes")

    @confidential_nodes.setter
    def confidential_nodes(self, value: Optional[pulumi.Input['ClusterNodeConfigConfidentialNodesArgs']]):
        pulumi.set(self, "confidential_nodes", value)

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[pulumi.Input[int]]:
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @disk_size_gb.setter
    def disk_size_gb(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "disk_size_gb", value)

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[pulumi.Input[str]]:
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        """
        return pulumi.get(self, "disk_type")

    @disk_type.setter
    def disk_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "disk_type", value)

    @property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional[pulumi.Input['ClusterNodeConfigEphemeralStorageConfigArgs']]:
        """
        ) Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @ephemeral_storage_config.setter
    def ephemeral_storage_config(self, value: Optional[pulumi.Input['ClusterNodeConfigEphemeralStorageConfigArgs']]):
        pulumi.set(self, "ephemeral_storage_config", value)

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional[pulumi.Input['ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs']]:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @ephemeral_storage_local_ssd_config.setter
    def ephemeral_storage_local_ssd_config(self, value: Optional[pulumi.Input['ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs']]):
        pulumi.set(self, "ephemeral_storage_local_ssd_config", value)

    @property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional[pulumi.Input['ClusterNodeConfigFastSocketArgs']]:
        """
        Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
        Node Pool must enable gvnic.
        GKE version 1.25.2-gke.1700 or later.
        Structure is documented below.
        """
        return pulumi.get(self, "fast_socket")

    @fast_socket.setter
    def fast_socket(self, value: Optional[pulumi.Input['ClusterNodeConfigFastSocketArgs']]):
        pulumi.set(self, "fast_socket", value)

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional[pulumi.Input['ClusterNodeConfigGcfsConfigArgs']]:
        """
        Parameters for the Google Container Filesystem (GCFS).
        If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
        For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
        A `machine_type` that has more than 16 GiB of memory is also recommended.
        GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
        Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "gcfs_config")

    @gcfs_config.setter
    def gcfs_config(self, value: Optional[pulumi.Input['ClusterNodeConfigGcfsConfigArgs']]):
        pulumi.set(self, "gcfs_config", value)

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigGuestAcceleratorArgs']]]]:
        """
        List of the type and count of accelerator cards attached to the instance.
        Structure documented below.
        """
        return pulumi.get(self, "guest_accelerators")

    @guest_accelerators.setter
    def guest_accelerators(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigGuestAcceleratorArgs']]]]):
        pulumi.set(self, "guest_accelerators", value)

    @property
    @pulumi.getter
    def gvnic(self) -> Optional[pulumi.Input['ClusterNodeConfigGvnicArgs']]:
        """
        Google Virtual NIC (gVNIC) is a virtual network interface.
        Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
        gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
        GKE node version 1.15.11-gke.15 or later
        Structure is documented below.


        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "gvnic")

    @gvnic.setter
    def gvnic(self, value: Optional[pulumi.Input['ClusterNodeConfigGvnicArgs']]):
        pulumi.set(self, "gvnic", value)

    @property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional[pulumi.Input['ClusterNodeConfigHostMaintenancePolicyArgs']]:
        return pulumi.get(self, "host_maintenance_policy")

    @host_maintenance_policy.setter
    def host_maintenance_policy(self, value: Optional[pulumi.Input['ClusterNodeConfigHostMaintenancePolicyArgs']]):
        pulumi.set(self, "host_maintenance_policy", value)

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[pulumi.Input[str]]:
        """
        The image type to use for this node. Note that changing the image type
        will delete and recreate all nodes in the node pool.
        """
        return pulumi.get(self, "image_type")

    @image_type.setter
    def image_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "image_type", value)

    @property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional[pulumi.Input['ClusterNodeConfigKubeletConfigArgs']]:
        """
        Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "kubelet_config")

    @kubelet_config.setter
    def kubelet_config(self, value: Optional[pulumi.Input['ClusterNodeConfigKubeletConfigArgs']]):
        pulumi.set(self, "kubelet_config", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
        reserved by Kubernetes Core components and cannot be specified.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional[pulumi.Input['ClusterNodeConfigLinuxNodeConfigArgs']]:
        """
        Linux node configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Note that validations happen all server side. All attributes are optional.
        Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "linux_node_config")

    @linux_node_config.setter
    def linux_node_config(self, value: Optional[pulumi.Input['ClusterNodeConfigLinuxNodeConfigArgs']]):
        pulumi.set(self, "linux_node_config", value)

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional[pulumi.Input['ClusterNodeConfigLocalNvmeSsdBlockConfigArgs']]:
        """
        Parameters for the local NVMe SSDs. Structure is documented below.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @local_nvme_ssd_block_config.setter
    def local_nvme_ssd_block_config(self, value: Optional[pulumi.Input['ClusterNodeConfigLocalNvmeSsdBlockConfigArgs']]):
        pulumi.set(self, "local_nvme_ssd_block_config", value)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[pulumi.Input[int]]:
        """
        The amount of local SSD disks that will be
        attached to each cluster node. Defaults to 0.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "local_ssd_count", value)

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[pulumi.Input[str]]:
        """
        Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")

    @logging_variant.setter
    def logging_variant(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "logging_variant", value)

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[pulumi.Input[str]]:
        """
        The name of a Google Compute Engine machine type.
        Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
        [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        """
        return pulumi.get(self, "machine_type")

    @machine_type.setter
    def machine_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "machine_type", value)

    @property
    @pulumi.getter
    def metadata(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        The metadata key/value pairs assigned to instances in
        the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
        `true` by the API; if `metadata` is set but that default value is not
        included, the provider will attempt to unset the value. To avoid this, set the
        value in your config.
        """
        return pulumi.get(self, "metadata")

    @metadata.setter
    def metadata(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "metadata", value)

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[pulumi.Input[str]]:
        """
        Minimum CPU platform to be used by this instance.
        The instance may be scheduled on the specified or newer CPU platform. Applicable
        values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
        [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
        for more information.
        """
        return pulumi.get(self, "min_cpu_platform")

    @min_cpu_platform.setter
    def min_cpu_platform(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "min_cpu_platform", value)

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[pulumi.Input[str]]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        """
        return pulumi.get(self, "node_group")

    @node_group.setter
    def node_group(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "node_group", value)

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The set of Google API scopes to be made available
        on all of the node VMs under the "default" service account.
        Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        """
        return pulumi.get(self, "oauth_scopes")

    @oauth_scopes.setter
    def oauth_scopes(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "oauth_scopes", value)

    @property
    @pulumi.getter
    def preemptible(self) -> Optional[pulumi.Input[bool]]:
        """
        A boolean that represents whether or not the underlying node VMs
        are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "preemptible")

    @preemptible.setter
    def preemptible(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "preemptible", value)

    @property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional[pulumi.Input['ClusterNodeConfigReservationAffinityArgs']]:
        """
        The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        """
        return pulumi.get(self, "reservation_affinity")

    @reservation_affinity.setter
    def reservation_affinity(self, value: Optional[pulumi.Input['ClusterNodeConfigReservationAffinityArgs']]):
        pulumi.set(self, "reservation_affinity", value)

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
        for how these labels are applied to clusters, node pools and nodes.
        """
        return pulumi.get(self, "resource_labels")

    @resource_labels.setter
    def resource_labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "resource_labels", value)

    @property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional[pulumi.Input['ClusterNodeConfigSandboxConfigArgs']]:
        return pulumi.get(self, "sandbox_config")

    @sandbox_config.setter
    def sandbox_config(self, value: Optional[pulumi.Input['ClusterNodeConfigSandboxConfigArgs']]):
        pulumi.set(self, "sandbox_config", value)

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[pulumi.Input[str]]:
        """
        The service account to be used by the Node VMs.
        If not specified, the "default" service account is used.
        """
        return pulumi.get(self, "service_account")

    @service_account.setter
    def service_account(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "service_account", value)

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional[pulumi.Input['ClusterNodeConfigShieldedInstanceConfigArgs']]:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @shielded_instance_config.setter
    def shielded_instance_config(self, value: Optional[pulumi.Input['ClusterNodeConfigShieldedInstanceConfigArgs']]):
        pulumi.set(self, "shielded_instance_config", value)

    @property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional[pulumi.Input['ClusterNodeConfigSoleTenantConfigArgs']]:
        """
        Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "sole_tenant_config")

    @sole_tenant_config.setter
    def sole_tenant_config(self, value: Optional[pulumi.Input['ClusterNodeConfigSoleTenantConfigArgs']]):
        pulumi.set(self, "sole_tenant_config", value)

    @property
    @pulumi.getter
    def spot(self) -> Optional[pulumi.Input[bool]]:
        """
        A boolean that represents whether the underlying node VMs are spot.
        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "spot")

    @spot.setter
    def spot(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "spot", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The list of instance tags applied to all nodes. Tags are used to identify
        valid sources or targets for network firewalls.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter
    def taints(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigTaintArgs']]]]:
        """
        A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
        to apply to nodes. GKE's API can only set this field on cluster creation.
        However, GKE will add taints to your nodes if you enable certain features such
        as GPUs. If this field is set, any diffs on this field will cause the provider to
        recreate the underlying resource. Taint values can be updated safely in
        Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
        this field to manage taints. If you do, `lifecycle.ignore_changes` is
        recommended. Structure is documented below.
        """
        return pulumi.get(self, "taints")

    @taints.setter
    def taints(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigTaintArgs']]]]):
        pulumi.set(self, "taints", value)

    @property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional[pulumi.Input['ClusterNodeConfigWorkloadMetadataConfigArgs']]:
        """
        Metadata configuration to expose to workloads on the node pool.
        Structure is documented below.
        """
        return pulumi.get(self, "workload_metadata_config")

    @workload_metadata_config.setter
    def workload_metadata_config(self, value: Optional[pulumi.Input['ClusterNodeConfigWorkloadMetadataConfigArgs']]):
        pulumi.set(self, "workload_metadata_config", value)


@pulumi.input_type
class ClusterNodeConfigAdvancedMachineFeaturesArgs:
    def __init__(__self__, *,
                 threads_per_core: pulumi.Input[int]):
        """
        :param pulumi.Input[int] threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> pulumi.Input[int]:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")

    @threads_per_core.setter
    def threads_per_core(self, value: pulumi.Input[int]):
        pulumi.set(self, "threads_per_core", value)


@pulumi.input_type
class ClusterNodeConfigConfidentialNodesArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterNodeConfigEphemeralStorageConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[int]):
        """
        :param pulumi.Input[int] local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[int]:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "local_ssd_count", value)


@pulumi.input_type
class ClusterNodeConfigEphemeralStorageLocalSsdConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[int]):
        """
        :param pulumi.Input[int] local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[int]:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "local_ssd_count", value)


@pulumi.input_type
class ClusterNodeConfigFastSocketArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Whether or not the NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Whether or not the NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterNodeConfigGcfsConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterNodeConfigGuestAcceleratorArgs:
    def __init__(__self__, *,
                 count: pulumi.Input[int],
                 type: pulumi.Input[str],
                 gpu_driver_installation_config: Optional[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']] = None,
                 gpu_partition_size: Optional[pulumi.Input[str]] = None,
                 gpu_sharing_config: Optional[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs']] = None):
        """
        :param pulumi.Input[int] count: The number of the guest accelerator cards exposed to this instance.
        :param pulumi.Input[str] type: The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        :param pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs'] gpu_driver_installation_config: Configuration for auto installation of GPU driver. Structure is documented below.
        :param pulumi.Input[str] gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        :param pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs'] gpu_sharing_config: Configuration for GPU sharing. Structure is documented below.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @property
    @pulumi.getter
    def count(self) -> pulumi.Input[int]:
        """
        The number of the guest accelerator cards exposed to this instance.
        """
        return pulumi.get(self, "count")

    @count.setter
    def count(self, value: pulumi.Input[int]):
        pulumi.set(self, "count", value)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input[str]:
        """
        The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[str]):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']]:
        """
        Configuration for auto installation of GPU driver. Structure is documented below.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @gpu_driver_installation_config.setter
    def gpu_driver_installation_config(self, value: Optional[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']]):
        pulumi.set(self, "gpu_driver_installation_config", value)

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[pulumi.Input[str]]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        """
        return pulumi.get(self, "gpu_partition_size")

    @gpu_partition_size.setter
    def gpu_partition_size(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "gpu_partition_size", value)

    @property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs']]:
        """
        Configuration for GPU sharing. Structure is documented below.
        """
        return pulumi.get(self, "gpu_sharing_config")

    @gpu_sharing_config.setter
    def gpu_sharing_config(self, value: Optional[pulumi.Input['ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs']]):
        pulumi.set(self, "gpu_sharing_config", value)


@pulumi.input_type
class ClusterNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs:
    def __init__(__self__, *,
                 gpu_driver_version: pulumi.Input[str]):
        """
        :param pulumi.Input[str] gpu_driver_version: Mode for how the GPU driver is installed.
               Accepted values are:
               * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to not install any GPU driver.
               * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
               * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
               * `"LATEST"`: "Latest" GPU driver in COS.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> pulumi.Input[str]:
        """
        Mode for how the GPU driver is installed.
        Accepted values are:
        * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to not install any GPU driver.
        * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
        * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
        * `"LATEST"`: "Latest" GPU driver in COS.
        """
        return pulumi.get(self, "gpu_driver_version")

    @gpu_driver_version.setter
    def gpu_driver_version(self, value: pulumi.Input[str]):
        pulumi.set(self, "gpu_driver_version", value)


@pulumi.input_type
class ClusterNodeConfigGuestAcceleratorGpuSharingConfigArgs:
    def __init__(__self__, *,
                 gpu_sharing_strategy: pulumi.Input[str],
                 max_shared_clients_per_gpu: pulumi.Input[int]):
        """
        :param pulumi.Input[str] gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node.
               Accepted values are:
               * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        :param pulumi.Input[int] max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> pulumi.Input[str]:
        """
        The type of GPU sharing strategy to enable on the GPU node.
        Accepted values are:
        * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @gpu_sharing_strategy.setter
    def gpu_sharing_strategy(self, value: pulumi.Input[str]):
        pulumi.set(self, "gpu_sharing_strategy", value)

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> pulumi.Input[int]:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")

    @max_shared_clients_per_gpu.setter
    def max_shared_clients_per_gpu(self, value: pulumi.Input[int]):
        pulumi.set(self, "max_shared_clients_per_gpu", value)


@pulumi.input_type
class ClusterNodeConfigGvnicArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterNodeConfigHostMaintenancePolicyArgs:
    def __init__(__self__, *,
                 maintenance_interval: pulumi.Input[str]):
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> pulumi.Input[str]:
        return pulumi.get(self, "maintenance_interval")

    @maintenance_interval.setter
    def maintenance_interval(self, value: pulumi.Input[str]):
        pulumi.set(self, "maintenance_interval", value)


@pulumi.input_type
class ClusterNodeConfigKubeletConfigArgs:
    def __init__(__self__, *,
                 cpu_manager_policy: pulumi.Input[str],
                 cpu_cfs_quota: Optional[pulumi.Input[bool]] = None,
                 cpu_cfs_quota_period: Optional[pulumi.Input[str]] = None,
                 pod_pids_limit: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input[str] cpu_manager_policy: The CPU management policy on the node. See
               [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
               One of `"none"` or `"static"`. Defaults to `none` when `kubelet_config` is unset.
        :param pulumi.Input[bool] cpu_cfs_quota: If true, enables CPU CFS quota enforcement for
               containers that specify CPU limits.
        :param pulumi.Input[str] cpu_cfs_quota_period: The CPU CFS quota period value. Specified
               as a sequence of decimal numbers, each with optional fraction and a unit suffix,
               such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
               "h". The value must be a positive duration.
               
               > Note: At the time of writing (2020/08/18) the GKE API rejects the `none`
               value and accepts an invalid `default` value instead. While this remains true,
               not specifying the `kubelet_config` block should be the equivalent of specifying
               `none`.
        :param pulumi.Input[int] pod_pids_limit: Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> pulumi.Input[str]:
        """
        The CPU management policy on the node. See
        [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
        One of `"none"` or `"static"`. Defaults to `none` when `kubelet_config` is unset.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @cpu_manager_policy.setter
    def cpu_manager_policy(self, value: pulumi.Input[str]):
        pulumi.set(self, "cpu_manager_policy", value)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[pulumi.Input[bool]]:
        """
        If true, enables CPU CFS quota enforcement for
        containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @cpu_cfs_quota.setter
    def cpu_cfs_quota(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "cpu_cfs_quota", value)

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[pulumi.Input[str]]:
        """
        The CPU CFS quota period value. Specified
        as a sequence of decimal numbers, each with optional fraction and a unit suffix,
        such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
        "h". The value must be a positive duration.

        > Note: At the time of writing (2020/08/18) the GKE API rejects the `none`
        value and accepts an invalid `default` value instead. While this remains true,
        not specifying the `kubelet_config` block should be the equivalent of specifying
        `none`.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @cpu_cfs_quota_period.setter
    def cpu_cfs_quota_period(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "cpu_cfs_quota_period", value)

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[pulumi.Input[int]]:
        """
        Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        return pulumi.get(self, "pod_pids_limit")

    @pod_pids_limit.setter
    def pod_pids_limit(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "pod_pids_limit", value)


@pulumi.input_type
class ClusterNodeConfigLinuxNodeConfigArgs:
    def __init__(__self__, *,
                 sysctls: pulumi.Input[Mapping[str, pulumi.Input[str]]]):
        """
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] sysctls: The Linux kernel parameters to be applied to the nodes
               and all pods running on the nodes. Specified as a map from the key, such as
               `net.core.wmem_max`, to a string value.
        """
        pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter
    def sysctls(self) -> pulumi.Input[Mapping[str, pulumi.Input[str]]]:
        """
        The Linux kernel parameters to be applied to the nodes
        and all pods running on the nodes. Specified as a map from the key, such as
        `net.core.wmem_max`, to a string value.
        """
        return pulumi.get(self, "sysctls")

    @sysctls.setter
    def sysctls(self, value: pulumi.Input[Mapping[str, pulumi.Input[str]]]):
        pulumi.set(self, "sysctls", value)


@pulumi.input_type
class ClusterNodeConfigLocalNvmeSsdBlockConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[int]):
        """
        :param pulumi.Input[int] local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
               > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[int]:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
        > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "local_ssd_count", value)


@pulumi.input_type
class ClusterNodeConfigReservationAffinityArgs:
    def __init__(__self__, *,
                 consume_reservation_type: pulumi.Input[str],
                 key: Optional[pulumi.Input[str]] = None,
                 values: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[str] consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param pulumi.Input[str] key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> pulumi.Input[str]:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @consume_reservation_type.setter
    def consume_reservation_type(self, value: pulumi.Input[str]):
        pulumi.set(self, "consume_reservation_type", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[pulumi.Input[str]]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "values", value)


@pulumi.input_type
class ClusterNodeConfigSandboxConfigArgs:
    def __init__(__self__, *,
                 sandbox_type: pulumi.Input[str]):
        """
        :param pulumi.Input[str] sandbox_type: Which sandbox to use for pods in the node pool.
               Accepted values are:
               
               * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> pulumi.Input[str]:
        """
        Which sandbox to use for pods in the node pool.
        Accepted values are:

        * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        return pulumi.get(self, "sandbox_type")

    @sandbox_type.setter
    def sandbox_type(self, value: pulumi.Input[str]):
        pulumi.set(self, "sandbox_type", value)


@pulumi.input_type
class ClusterNodeConfigShieldedInstanceConfigArgs:
    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[pulumi.Input[bool]] = None,
                 enable_secure_boot: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[bool] enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param pulumi.Input[bool] enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[pulumi.Input[bool]]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @enable_integrity_monitoring.setter
    def enable_integrity_monitoring(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_integrity_monitoring", value)

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[pulumi.Input[bool]]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")

    @enable_secure_boot.setter
    def enable_secure_boot(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_secure_boot", value)


@pulumi.input_type
class ClusterNodeConfigSoleTenantConfigArgs:
    def __init__(__self__, *,
                 node_affinities: pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSoleTenantConfigNodeAffinityArgs']]]):
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSoleTenantConfigNodeAffinityArgs']]]:
        return pulumi.get(self, "node_affinities")

    @node_affinities.setter
    def node_affinities(self, value: pulumi.Input[Sequence[pulumi.Input['ClusterNodeConfigSoleTenantConfigNodeAffinityArgs']]]):
        pulumi.set(self, "node_affinities", value)


@pulumi.input_type
class ClusterNodeConfigSoleTenantConfigNodeAffinityArgs:
    def __init__(__self__, *,
                 key: pulumi.Input[str],
                 operator: pulumi.Input[str],
                 values: pulumi.Input[Sequence[pulumi.Input[str]]]):
        """
        :param pulumi.Input[str] key: The default or custom node affinity label key name.
        :param pulumi.Input[str] operator: Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        :param pulumi.Input[Sequence[pulumi.Input[str]]] values: List of node affinity label values as strings.
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[str]:
        """
        The default or custom node affinity label key name.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def operator(self) -> pulumi.Input[str]:
        """
        Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        """
        return pulumi.get(self, "operator")

    @operator.setter
    def operator(self, value: pulumi.Input[str]):
        pulumi.set(self, "operator", value)

    @property
    @pulumi.getter
    def values(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        List of node affinity label values as strings.
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "values", value)


@pulumi.input_type
class ClusterNodeConfigTaintArgs:
    def __init__(__self__, *,
                 effect: pulumi.Input[str],
                 key: pulumi.Input[str],
                 value: pulumi.Input[str]):
        """
        :param pulumi.Input[str] effect: Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        :param pulumi.Input[str] key: Key for taint.
        :param pulumi.Input[str] value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> pulumi.Input[str]:
        """
        Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        """
        return pulumi.get(self, "effect")

    @effect.setter
    def effect(self, value: pulumi.Input[str]):
        pulumi.set(self, "effect", value)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[str]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[str]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[str]):
        pulumi.set(self, "value", value)


@pulumi.input_type
class ClusterNodeConfigWorkloadMetadataConfigArgs:
    def __init__(__self__, *,
                 mode: pulumi.Input[str]):
        """
        :param pulumi.Input[str] mode: How to expose the node metadata to the workload running on the node.
               Accepted values are:
               * UNSPECIFIED: Not Set
               * GCE_METADATA: Expose all Compute Engine metadata to pods.
               * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> pulumi.Input[str]:
        """
        How to expose the node metadata to the workload running on the node.
        Accepted values are:
        * UNSPECIFIED: Not Set
        * GCE_METADATA: Expose all Compute Engine metadata to pods.
        * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        return pulumi.get(self, "mode")

    @mode.setter
    def mode(self, value: pulumi.Input[str]):
        pulumi.set(self, "mode", value)


@pulumi.input_type
class ClusterNodePoolArgs:
    def __init__(__self__, *,
                 autoscaling: Optional[pulumi.Input['ClusterNodePoolAutoscalingArgs']] = None,
                 initial_node_count: Optional[pulumi.Input[int]] = None,
                 instance_group_urls: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 managed_instance_group_urls: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 management: Optional[pulumi.Input['ClusterNodePoolManagementArgs']] = None,
                 max_pods_per_node: Optional[pulumi.Input[int]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 name_prefix: Optional[pulumi.Input[str]] = None,
                 network_config: Optional[pulumi.Input['ClusterNodePoolNetworkConfigArgs']] = None,
                 node_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigArgs']] = None,
                 node_count: Optional[pulumi.Input[int]] = None,
                 node_locations: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 placement_policy: Optional[pulumi.Input['ClusterNodePoolPlacementPolicyArgs']] = None,
                 upgrade_settings: Optional[pulumi.Input['ClusterNodePoolUpgradeSettingsArgs']] = None,
                 version: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[int] initial_node_count: The number of nodes to create in this
               cluster's default node pool. In regional or multi-zonal clusters, this is the
               number of nodes per zone. Must be set if `node_pool` is not set. If you're using
               `container.NodePool` objects with no default node pool, you'll need to
               set this to a value of at least `1`, alongside setting
               `remove_default_node_pool` to `true`.
        :param pulumi.Input['ClusterNodePoolManagementArgs'] management: NodeManagement configuration for this NodePool. Structure is documented below.
        :param pulumi.Input[str] name: The name of the cluster, unique within the project and
               location.
               
               - - -
        :param pulumi.Input['ClusterNodePoolNetworkConfigArgs'] network_config: Configuration for
               [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
        :param pulumi.Input['ClusterNodePoolNodeConfigArgs'] node_config: Parameters used in creating the default node pool.
               Generally, this field should not be used at the same time as a
               `container.NodePool` or a `node_pool` block; this configuration
               manages the default node pool, which isn't recommended to be used.
               Structure is documented below.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] node_locations: The list of zones in which the cluster's nodes
               are located. Nodes must be in the region of their regional cluster or in the
               same region as their cluster's zone for zonal clusters. If this is specified for
               a zonal cluster, omit the cluster's zone.
               
               > A "multi-zonal" cluster is a zonal cluster with at least one additional zone
               defined; in a multi-zonal cluster, the cluster master is only present in a
               single zone while nodes are present in each of the primary zone and the node
               locations. In contrast, in a regional cluster, cluster master nodes are present
               in multiple zones in the region. For that reason, regional clusters should be
               preferred.
        :param pulumi.Input['ClusterNodePoolUpgradeSettingsArgs'] upgrade_settings: Specifies the upgrade settings for NAP created node pools. Structure is documented below.
        """
        if autoscaling is not None:
            pulumi.set(__self__, "autoscaling", autoscaling)
        if initial_node_count is not None:
            pulumi.set(__self__, "initial_node_count", initial_node_count)
        if instance_group_urls is not None:
            pulumi.set(__self__, "instance_group_urls", instance_group_urls)
        if managed_instance_group_urls is not None:
            pulumi.set(__self__, "managed_instance_group_urls", managed_instance_group_urls)
        if management is not None:
            pulumi.set(__self__, "management", management)
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if name_prefix is not None:
            pulumi.set(__self__, "name_prefix", name_prefix)
        if network_config is not None:
            pulumi.set(__self__, "network_config", network_config)
        if node_config is not None:
            pulumi.set(__self__, "node_config", node_config)
        if node_count is not None:
            pulumi.set(__self__, "node_count", node_count)
        if node_locations is not None:
            pulumi.set(__self__, "node_locations", node_locations)
        if placement_policy is not None:
            pulumi.set(__self__, "placement_policy", placement_policy)
        if upgrade_settings is not None:
            pulumi.set(__self__, "upgrade_settings", upgrade_settings)
        if version is not None:
            pulumi.set(__self__, "version", version)

    @property
    @pulumi.getter
    def autoscaling(self) -> Optional[pulumi.Input['ClusterNodePoolAutoscalingArgs']]:
        return pulumi.get(self, "autoscaling")

    @autoscaling.setter
    def autoscaling(self, value: Optional[pulumi.Input['ClusterNodePoolAutoscalingArgs']]):
        pulumi.set(self, "autoscaling", value)

    @property
    @pulumi.getter(name="initialNodeCount")
    def initial_node_count(self) -> Optional[pulumi.Input[int]]:
        """
        The number of nodes to create in this
        cluster's default node pool. In regional or multi-zonal clusters, this is the
        number of nodes per zone. Must be set if `node_pool` is not set. If you're using
        `container.NodePool` objects with no default node pool, you'll need to
        set this to a value of at least `1`, alongside setting
        `remove_default_node_pool` to `true`.
        """
        return pulumi.get(self, "initial_node_count")

    @initial_node_count.setter
    def initial_node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "initial_node_count", value)

    @property
    @pulumi.getter(name="instanceGroupUrls")
    def instance_group_urls(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        return pulumi.get(self, "instance_group_urls")

    @instance_group_urls.setter
    def instance_group_urls(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "instance_group_urls", value)

    @property
    @pulumi.getter(name="managedInstanceGroupUrls")
    def managed_instance_group_urls(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        return pulumi.get(self, "managed_instance_group_urls")

    @managed_instance_group_urls.setter
    def managed_instance_group_urls(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "managed_instance_group_urls", value)

    @property
    @pulumi.getter
    def management(self) -> Optional[pulumi.Input['ClusterNodePoolManagementArgs']]:
        """
        NodeManagement configuration for this NodePool. Structure is documented below.
        """
        return pulumi.get(self, "management")

    @management.setter
    def management(self, value: Optional[pulumi.Input['ClusterNodePoolManagementArgs']]):
        pulumi.set(self, "management", value)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[pulumi.Input[int]]:
        return pulumi.get(self, "max_pods_per_node")

    @max_pods_per_node.setter
    def max_pods_per_node(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_pods_per_node", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the cluster, unique within the project and
        location.

        - - -
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter(name="namePrefix")
    def name_prefix(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "name_prefix")

    @name_prefix.setter
    def name_prefix(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name_prefix", value)

    @property
    @pulumi.getter(name="networkConfig")
    def network_config(self) -> Optional[pulumi.Input['ClusterNodePoolNetworkConfigArgs']]:
        """
        Configuration for
        [Adding Pod IP address ranges](https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr)) to the node pool. Structure is documented below
        """
        return pulumi.get(self, "network_config")

    @network_config.setter
    def network_config(self, value: Optional[pulumi.Input['ClusterNodePoolNetworkConfigArgs']]):
        pulumi.set(self, "network_config", value)

    @property
    @pulumi.getter(name="nodeConfig")
    def node_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigArgs']]:
        """
        Parameters used in creating the default node pool.
        Generally, this field should not be used at the same time as a
        `container.NodePool` or a `node_pool` block; this configuration
        manages the default node pool, which isn't recommended to be used.
        Structure is documented below.
        """
        return pulumi.get(self, "node_config")

    @node_config.setter
    def node_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigArgs']]):
        pulumi.set(self, "node_config", value)

    @property
    @pulumi.getter(name="nodeCount")
    def node_count(self) -> Optional[pulumi.Input[int]]:
        return pulumi.get(self, "node_count")

    @node_count.setter
    def node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "node_count", value)

    @property
    @pulumi.getter(name="nodeLocations")
    def node_locations(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The list of zones in which the cluster's nodes
        are located. Nodes must be in the region of their regional cluster or in the
        same region as their cluster's zone for zonal clusters. If this is specified for
        a zonal cluster, omit the cluster's zone.

        > A "multi-zonal" cluster is a zonal cluster with at least one additional zone
        defined; in a multi-zonal cluster, the cluster master is only present in a
        single zone while nodes are present in each of the primary zone and the node
        locations. In contrast, in a regional cluster, cluster master nodes are present
        in multiple zones in the region. For that reason, regional clusters should be
        preferred.
        """
        return pulumi.get(self, "node_locations")

    @node_locations.setter
    def node_locations(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "node_locations", value)

    @property
    @pulumi.getter(name="placementPolicy")
    def placement_policy(self) -> Optional[pulumi.Input['ClusterNodePoolPlacementPolicyArgs']]:
        return pulumi.get(self, "placement_policy")

    @placement_policy.setter
    def placement_policy(self, value: Optional[pulumi.Input['ClusterNodePoolPlacementPolicyArgs']]):
        pulumi.set(self, "placement_policy", value)

    @property
    @pulumi.getter(name="upgradeSettings")
    def upgrade_settings(self) -> Optional[pulumi.Input['ClusterNodePoolUpgradeSettingsArgs']]:
        """
        Specifies the upgrade settings for NAP created node pools. Structure is documented below.
        """
        return pulumi.get(self, "upgrade_settings")

    @upgrade_settings.setter
    def upgrade_settings(self, value: Optional[pulumi.Input['ClusterNodePoolUpgradeSettingsArgs']]):
        pulumi.set(self, "upgrade_settings", value)

    @property
    @pulumi.getter
    def version(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "version")

    @version.setter
    def version(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "version", value)


@pulumi.input_type
class ClusterNodePoolAutoConfigArgs:
    def __init__(__self__, *,
                 network_tags: Optional[pulumi.Input['ClusterNodePoolAutoConfigNetworkTagsArgs']] = None):
        """
        :param pulumi.Input['ClusterNodePoolAutoConfigNetworkTagsArgs'] network_tags: The network tag config for the cluster's automatically provisioned node pools.
        """
        if network_tags is not None:
            pulumi.set(__self__, "network_tags", network_tags)

    @property
    @pulumi.getter(name="networkTags")
    def network_tags(self) -> Optional[pulumi.Input['ClusterNodePoolAutoConfigNetworkTagsArgs']]:
        """
        The network tag config for the cluster's automatically provisioned node pools.
        """
        return pulumi.get(self, "network_tags")

    @network_tags.setter
    def network_tags(self, value: Optional[pulumi.Input['ClusterNodePoolAutoConfigNetworkTagsArgs']]):
        pulumi.set(self, "network_tags", value)


@pulumi.input_type
class ClusterNodePoolAutoConfigNetworkTagsArgs:
    def __init__(__self__, *,
                 tags: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] tags: List of network tags applied to auto-provisioned node pools.
               
               ```python
               import pulumi
               ```
        """
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        List of network tags applied to auto-provisioned node pools.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "tags", value)


@pulumi.input_type
class ClusterNodePoolAutoscalingArgs:
    def __init__(__self__, *,
                 location_policy: Optional[pulumi.Input[str]] = None,
                 max_node_count: Optional[pulumi.Input[int]] = None,
                 min_node_count: Optional[pulumi.Input[int]] = None,
                 total_max_node_count: Optional[pulumi.Input[int]] = None,
                 total_min_node_count: Optional[pulumi.Input[int]] = None):
        if location_policy is not None:
            pulumi.set(__self__, "location_policy", location_policy)
        if max_node_count is not None:
            pulumi.set(__self__, "max_node_count", max_node_count)
        if min_node_count is not None:
            pulumi.set(__self__, "min_node_count", min_node_count)
        if total_max_node_count is not None:
            pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        if total_min_node_count is not None:
            pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "location_policy")

    @location_policy.setter
    def location_policy(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "location_policy", value)

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> Optional[pulumi.Input[int]]:
        return pulumi.get(self, "max_node_count")

    @max_node_count.setter
    def max_node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_node_count", value)

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> Optional[pulumi.Input[int]]:
        return pulumi.get(self, "min_node_count")

    @min_node_count.setter
    def min_node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "min_node_count", value)

    @property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> Optional[pulumi.Input[int]]:
        return pulumi.get(self, "total_max_node_count")

    @total_max_node_count.setter
    def total_max_node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "total_max_node_count", value)

    @property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> Optional[pulumi.Input[int]]:
        return pulumi.get(self, "total_min_node_count")

    @total_min_node_count.setter
    def total_min_node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "total_min_node_count", value)


@pulumi.input_type
class ClusterNodePoolDefaultsArgs:
    def __init__(__self__, *,
                 node_config_defaults: Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsArgs']] = None):
        """
        :param pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsArgs'] node_config_defaults: Subset of NodeConfig message that has defaults.
        """
        if node_config_defaults is not None:
            pulumi.set(__self__, "node_config_defaults", node_config_defaults)

    @property
    @pulumi.getter(name="nodeConfigDefaults")
    def node_config_defaults(self) -> Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsArgs']]:
        """
        Subset of NodeConfig message that has defaults.
        """
        return pulumi.get(self, "node_config_defaults")

    @node_config_defaults.setter
    def node_config_defaults(self, value: Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsArgs']]):
        pulumi.set(self, "node_config_defaults", value)


@pulumi.input_type
class ClusterNodePoolDefaultsNodeConfigDefaultsArgs:
    def __init__(__self__, *,
                 gcfs_config: Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs']] = None,
                 logging_variant: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs'] gcfs_config: ) The default Google Container Filesystem (GCFS) configuration at the cluster level. e.g. enable [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming) across all the node pools within the cluster. Structure is documented below.
        :param pulumi.Input[str] logging_variant: The type of logging agent that is deployed by default for newly created node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs']]:
        """
        ) The default Google Container Filesystem (GCFS) configuration at the cluster level. e.g. enable [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming) across all the node pools within the cluster. Structure is documented below.
        """
        return pulumi.get(self, "gcfs_config")

    @gcfs_config.setter
    def gcfs_config(self, value: Optional[pulumi.Input['ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs']]):
        pulumi.set(self, "gcfs_config", value)

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[pulumi.Input[str]]:
        """
        The type of logging agent that is deployed by default for newly created node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")

    @logging_variant.setter
    def logging_variant(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "logging_variant", value)


@pulumi.input_type
class ClusterNodePoolDefaultsNodeConfigDefaultsGcfsConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterNodePoolManagementArgs:
    def __init__(__self__, *,
                 auto_repair: Optional[pulumi.Input[bool]] = None,
                 auto_upgrade: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[bool] auto_repair: Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
               
               This block also contains several computed attributes, documented below.
        :param pulumi.Input[bool] auto_upgrade: Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[pulumi.Input[bool]]:
        """
        Specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.

        This block also contains several computed attributes, documented below.
        """
        return pulumi.get(self, "auto_repair")

    @auto_repair.setter
    def auto_repair(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "auto_repair", value)

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[pulumi.Input[bool]]:
        """
        Specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
        """
        return pulumi.get(self, "auto_upgrade")

    @auto_upgrade.setter
    def auto_upgrade(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "auto_upgrade", value)


@pulumi.input_type
class ClusterNodePoolNetworkConfigArgs:
    def __init__(__self__, *,
                 additional_node_network_configs: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]]] = None,
                 additional_pod_network_configs: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]]] = None,
                 create_pod_range: Optional[pulumi.Input[bool]] = None,
                 enable_private_nodes: Optional[pulumi.Input[bool]] = None,
                 pod_cidr_overprovision_config: Optional[pulumi.Input['ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs']] = None,
                 pod_ipv4_cidr_block: Optional[pulumi.Input[str]] = None,
                 pod_range: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[bool] create_pod_range: Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        :param pulumi.Input[bool] enable_private_nodes: Enables the private cluster feature,
               creating a private endpoint on the cluster. In a private cluster, nodes only
               have RFC 1918 private addresses and communicate with the master's private
               endpoint via private networking.
        :param pulumi.Input[str] pod_ipv4_cidr_block: The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        :param pulumi.Input[str] pod_range: The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        if additional_node_network_configs is not None:
            pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        if additional_pod_network_configs is not None:
            pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        if create_pod_range is not None:
            pulumi.set(__self__, "create_pod_range", create_pod_range)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if pod_ipv4_cidr_block is not None:
            pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        if pod_range is not None:
            pulumi.set(__self__, "pod_range", pod_range)

    @property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]]]:
        return pulumi.get(self, "additional_node_network_configs")

    @additional_node_network_configs.setter
    def additional_node_network_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]]]):
        pulumi.set(self, "additional_node_network_configs", value)

    @property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]]]:
        return pulumi.get(self, "additional_pod_network_configs")

    @additional_pod_network_configs.setter
    def additional_pod_network_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]]]):
        pulumi.set(self, "additional_pod_network_configs", value)

    @property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        """
        return pulumi.get(self, "create_pod_range")

    @create_pod_range.setter
    def create_pod_range(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "create_pod_range", value)

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[pulumi.Input[bool]]:
        """
        Enables the private cluster feature,
        creating a private endpoint on the cluster. In a private cluster, nodes only
        have RFC 1918 private addresses and communicate with the master's private
        endpoint via private networking.
        """
        return pulumi.get(self, "enable_private_nodes")

    @enable_private_nodes.setter
    def enable_private_nodes(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_private_nodes", value)

    @property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional[pulumi.Input['ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs']]:
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @pod_cidr_overprovision_config.setter
    def pod_cidr_overprovision_config(self, value: Optional[pulumi.Input['ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs']]):
        pulumi.set(self, "pod_cidr_overprovision_config", value)

    @property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> Optional[pulumi.Input[str]]:
        """
        The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @pod_ipv4_cidr_block.setter
    def pod_ipv4_cidr_block(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "pod_ipv4_cidr_block", value)

    @property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> Optional[pulumi.Input[str]]:
        """
        The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        return pulumi.get(self, "pod_range")

    @pod_range.setter
    def pod_range(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "pod_range", value)


@pulumi.input_type
class ClusterNodePoolNetworkConfigAdditionalNodeNetworkConfigArgs:
    def __init__(__self__, *,
                 network: Optional[pulumi.Input[str]] = None,
                 subnetwork: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] network: The name or self_link of the Google Compute Engine
               network to which the cluster is connected. For Shared VPC, set this to the self link of the
               shared network.
        :param pulumi.Input[str] subnetwork: The name or self_link of the Google Compute Engine
               subnetwork in which the cluster's instances are launched.
        """
        if network is not None:
            pulumi.set(__self__, "network", network)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter
    def network(self) -> Optional[pulumi.Input[str]]:
        """
        The name or self_link of the Google Compute Engine
        network to which the cluster is connected. For Shared VPC, set this to the self link of the
        shared network.
        """
        return pulumi.get(self, "network")

    @network.setter
    def network(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "network", value)

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[pulumi.Input[str]]:
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
        return pulumi.get(self, "subnetwork")

    @subnetwork.setter
    def subnetwork(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "subnetwork", value)


@pulumi.input_type
class ClusterNodePoolNetworkConfigAdditionalPodNetworkConfigArgs:
    def __init__(__self__, *,
                 max_pods_per_node: Optional[pulumi.Input[int]] = None,
                 secondary_pod_range: Optional[pulumi.Input[str]] = None,
                 subnetwork: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] subnetwork: The name or self_link of the Google Compute Engine
               subnetwork in which the cluster's instances are launched.
        """
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if secondary_pod_range is not None:
            pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[pulumi.Input[int]]:
        return pulumi.get(self, "max_pods_per_node")

    @max_pods_per_node.setter
    def max_pods_per_node(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_pods_per_node", value)

    @property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "secondary_pod_range")

    @secondary_pod_range.setter
    def secondary_pod_range(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "secondary_pod_range", value)

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[pulumi.Input[str]]:
        """
        The name or self_link of the Google Compute Engine
        subnetwork in which the cluster's instances are launched.
        """
        return pulumi.get(self, "subnetwork")

    @subnetwork.setter
    def subnetwork(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "subnetwork", value)


@pulumi.input_type
class ClusterNodePoolNetworkConfigPodCidrOverprovisionConfigArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] disabled: Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic
               
               <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[bool]:
        """
        Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when defaultSnatStatus is disabled.When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic

        <a name="nested_cluster_telemetry"></a>The `cluster_telemetry` block supports
        """
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "disabled", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigArgs:
    def __init__(__self__, *,
                 advanced_machine_features: Optional[pulumi.Input['ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs']] = None,
                 boot_disk_kms_key: Optional[pulumi.Input[str]] = None,
                 confidential_nodes: Optional[pulumi.Input['ClusterNodePoolNodeConfigConfidentialNodesArgs']] = None,
                 disk_size_gb: Optional[pulumi.Input[int]] = None,
                 disk_type: Optional[pulumi.Input[str]] = None,
                 ephemeral_storage_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageConfigArgs']] = None,
                 ephemeral_storage_local_ssd_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs']] = None,
                 fast_socket: Optional[pulumi.Input['ClusterNodePoolNodeConfigFastSocketArgs']] = None,
                 gcfs_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigGcfsConfigArgs']] = None,
                 guest_accelerators: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorArgs']]]] = None,
                 gvnic: Optional[pulumi.Input['ClusterNodePoolNodeConfigGvnicArgs']] = None,
                 host_maintenance_policy: Optional[pulumi.Input['ClusterNodePoolNodeConfigHostMaintenancePolicyArgs']] = None,
                 image_type: Optional[pulumi.Input[str]] = None,
                 kubelet_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigKubeletConfigArgs']] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 linux_node_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigArgs']] = None,
                 local_nvme_ssd_block_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs']] = None,
                 local_ssd_count: Optional[pulumi.Input[int]] = None,
                 logging_variant: Optional[pulumi.Input[str]] = None,
                 machine_type: Optional[pulumi.Input[str]] = None,
                 metadata: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 min_cpu_platform: Optional[pulumi.Input[str]] = None,
                 node_group: Optional[pulumi.Input[str]] = None,
                 oauth_scopes: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 preemptible: Optional[pulumi.Input[bool]] = None,
                 reservation_affinity: Optional[pulumi.Input['ClusterNodePoolNodeConfigReservationAffinityArgs']] = None,
                 resource_labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 sandbox_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigSandboxConfigArgs']] = None,
                 service_account: Optional[pulumi.Input[str]] = None,
                 shielded_instance_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigShieldedInstanceConfigArgs']] = None,
                 sole_tenant_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigArgs']] = None,
                 spot: Optional[pulumi.Input[bool]] = None,
                 tags: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 taints: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigTaintArgs']]]] = None,
                 workload_metadata_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs']] = None):
        """
        :param pulumi.Input['ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs'] advanced_machine_features: Specifies options for controlling
               advanced machine features. Structure is documented below.
        :param pulumi.Input[str] boot_disk_kms_key: The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        :param pulumi.Input['ClusterNodePoolNodeConfigConfidentialNodesArgs'] confidential_nodes: Configuration for [Confidential Nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/confidential-gke-nodes) feature. Structure is documented below documented below.
        :param pulumi.Input[int] disk_size_gb: Size of the disk attached to each node, specified
               in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        :param pulumi.Input[str] disk_type: Type of the disk attached to each node
               (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        :param pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageConfigArgs'] ephemeral_storage_config: ) Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs'] ephemeral_storage_local_ssd_config: Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input['ClusterNodePoolNodeConfigFastSocketArgs'] fast_socket: Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
               Node Pool must enable gvnic.
               GKE version 1.25.2-gke.1700 or later.
               Structure is documented below.
        :param pulumi.Input['ClusterNodePoolNodeConfigGcfsConfigArgs'] gcfs_config: Parameters for the Google Container Filesystem (GCFS).
               If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
               For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
               A `machine_type` that has more than 16 GiB of memory is also recommended.
               GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
               Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorArgs']]] guest_accelerators: List of the type and count of accelerator cards attached to the instance.
               Structure documented below.
        :param pulumi.Input['ClusterNodePoolNodeConfigGvnicArgs'] gvnic: Google Virtual NIC (gVNIC) is a virtual network interface.
               Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
               gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
               GKE node version 1.15.11-gke.15 or later
               Structure is documented below.
               
               
               ```python
               import pulumi
               ```
        :param pulumi.Input[str] image_type: The image type to use for this node. Note that changing the image type
               will delete and recreate all nodes in the node pool.
        :param pulumi.Input['ClusterNodePoolNodeConfigKubeletConfigArgs'] kubelet_config: Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] labels: The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
               reserved by Kubernetes Core components and cannot be specified.
        :param pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigArgs'] linux_node_config: Linux node configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
               Note that validations happen all server side. All attributes are optional.
               Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input['ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs'] local_nvme_ssd_block_config: Parameters for the local NVMe SSDs. Structure is documented below.
        :param pulumi.Input[int] local_ssd_count: The amount of local SSD disks that will be
               attached to each cluster node. Defaults to 0.
        :param pulumi.Input[str] logging_variant: Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        :param pulumi.Input[str] machine_type: The name of a Google Compute Engine machine type.
               Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
               [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] metadata: The metadata key/value pairs assigned to instances in
               the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
               `true` by the API; if `metadata` is set but that default value is not
               included, the provider will attempt to unset the value. To avoid this, set the
               value in your config.
        :param pulumi.Input[str] min_cpu_platform: Minimum CPU platform to be used by this instance.
               The instance may be scheduled on the specified or newer CPU platform. Applicable
               values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
               [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
               for more information.
        :param pulumi.Input[str] node_group: Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] oauth_scopes: The set of Google API scopes to be made available
               on all of the node VMs under the "default" service account.
               Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.
               
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        :param pulumi.Input[bool] preemptible: A boolean that represents whether or not the underlying node VMs
               are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
               for more information. Defaults to false.
        :param pulumi.Input['ClusterNodePoolNodeConfigReservationAffinityArgs'] reservation_affinity: The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] resource_labels: The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
               for how these labels are applied to clusters, node pools and nodes.
        :param pulumi.Input[str] service_account: The service account to be used by the Node VMs.
               If not specified, the "default" service account is used.
        :param pulumi.Input['ClusterNodePoolNodeConfigShieldedInstanceConfigArgs'] shielded_instance_config: Shielded Instance options. Structure is documented below.
        :param pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigArgs'] sole_tenant_config: Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input[bool] spot: A boolean that represents whether the underlying node VMs are spot.
               See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
               for more information. Defaults to false.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] tags: The list of instance tags applied to all nodes. Tags are used to identify
               valid sources or targets for network firewalls.
        :param pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigTaintArgs']]] taints: A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
               to apply to nodes. GKE's API can only set this field on cluster creation.
               However, GKE will add taints to your nodes if you enable certain features such
               as GPUs. If this field is set, any diffs on this field will cause the provider to
               recreate the underlying resource. Taint values can be updated safely in
               Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
               this field to manage taints. If you do, `lifecycle.ignore_changes` is
               recommended. Structure is documented below.
        :param pulumi.Input['ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs'] workload_metadata_config: Metadata configuration to expose to workloads on the node pool.
               Structure is documented below.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs']]:
        """
        Specifies options for controlling
        advanced machine features. Structure is documented below.
        """
        return pulumi.get(self, "advanced_machine_features")

    @advanced_machine_features.setter
    def advanced_machine_features(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs']]):
        pulumi.set(self, "advanced_machine_features", value)

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[pulumi.Input[str]]:
        """
        The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: <https://cloud.google.com/compute/docs/disks/customer-managed-encryption>
        """
        return pulumi.get(self, "boot_disk_kms_key")

    @boot_disk_kms_key.setter
    def boot_disk_kms_key(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "boot_disk_kms_key", value)

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigConfidentialNodesArgs']]:
        """
        Configuration for [Confidential Nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/confidential-gke-nodes) feature. Structure is documented below documented below.
        """
        return pulumi.get(self, "confidential_nodes")

    @confidential_nodes.setter
    def confidential_nodes(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigConfidentialNodesArgs']]):
        pulumi.set(self, "confidential_nodes", value)

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[pulumi.Input[int]]:
        """
        Size of the disk attached to each node, specified
        in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.
        """
        return pulumi.get(self, "disk_size_gb")

    @disk_size_gb.setter
    def disk_size_gb(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "disk_size_gb", value)

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[pulumi.Input[str]]:
        """
        Type of the disk attached to each node
        (e.g. 'pd-standard', 'pd-balanced' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'
        """
        return pulumi.get(self, "disk_type")

    @disk_type.setter
    def disk_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "disk_type", value)

    @property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageConfigArgs']]:
        """
        ) Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "ephemeral_storage_config")

    @ephemeral_storage_config.setter
    def ephemeral_storage_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageConfigArgs']]):
        pulumi.set(self, "ephemeral_storage_config", value)

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs']]:
        """
        Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk. Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @ephemeral_storage_local_ssd_config.setter
    def ephemeral_storage_local_ssd_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs']]):
        pulumi.set(self, "ephemeral_storage_local_ssd_config", value)

    @property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigFastSocketArgs']]:
        """
        Parameters for the NCCL Fast Socket feature. If unspecified, NCCL Fast Socket will not be enabled on the node pool.
        Node Pool must enable gvnic.
        GKE version 1.25.2-gke.1700 or later.
        Structure is documented below.
        """
        return pulumi.get(self, "fast_socket")

    @fast_socket.setter
    def fast_socket(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigFastSocketArgs']]):
        pulumi.set(self, "fast_socket", value)

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigGcfsConfigArgs']]:
        """
        Parameters for the Google Container Filesystem (GCFS).
        If unspecified, GCFS will not be enabled on the node pool. When enabling this feature you must specify `image_type = "COS_CONTAINERD"` and `node_version` from GKE versions 1.19 or later to use it.
        For GKE versions 1.19, 1.20, and 1.21, the recommended minimum `node_version` would be 1.19.15-gke.1300, 1.20.11-gke.1300, and 1.21.5-gke.1300 respectively.
        A `machine_type` that has more than 16 GiB of memory is also recommended.
        GCFS must be enabled in order to use [image streaming](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming).
        Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "gcfs_config")

    @gcfs_config.setter
    def gcfs_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigGcfsConfigArgs']]):
        pulumi.set(self, "gcfs_config", value)

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorArgs']]]]:
        """
        List of the type and count of accelerator cards attached to the instance.
        Structure documented below.
        """
        return pulumi.get(self, "guest_accelerators")

    @guest_accelerators.setter
    def guest_accelerators(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorArgs']]]]):
        pulumi.set(self, "guest_accelerators", value)

    @property
    @pulumi.getter
    def gvnic(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigGvnicArgs']]:
        """
        Google Virtual NIC (gVNIC) is a virtual network interface.
        Installing the gVNIC driver allows for more efficient traffic transmission across the Google network infrastructure.
        gVNIC is an alternative to the virtIO-based ethernet driver. GKE nodes must use a Container-Optimized OS node image.
        GKE node version 1.15.11-gke.15 or later
        Structure is documented below.


        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "gvnic")

    @gvnic.setter
    def gvnic(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigGvnicArgs']]):
        pulumi.set(self, "gvnic", value)

    @property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigHostMaintenancePolicyArgs']]:
        return pulumi.get(self, "host_maintenance_policy")

    @host_maintenance_policy.setter
    def host_maintenance_policy(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigHostMaintenancePolicyArgs']]):
        pulumi.set(self, "host_maintenance_policy", value)

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[pulumi.Input[str]]:
        """
        The image type to use for this node. Note that changing the image type
        will delete and recreate all nodes in the node pool.
        """
        return pulumi.get(self, "image_type")

    @image_type.setter
    def image_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "image_type", value)

    @property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigKubeletConfigArgs']]:
        """
        Kubelet configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "kubelet_config")

    @kubelet_config.setter
    def kubelet_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigKubeletConfigArgs']]):
        pulumi.set(self, "kubelet_config", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        The Kubernetes labels (key/value pairs) to be applied to each node. The kubernetes.io/ and k8s.io/ prefixes are
        reserved by Kubernetes Core components and cannot be specified.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigArgs']]:
        """
        Linux node configuration, currently supported attributes can be found [here](https://cloud.google.com/sdk/gcloud/reference/beta/container/node-pools/create#--system-config-from-file).
        Note that validations happen all server side. All attributes are optional.
        Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "linux_node_config")

    @linux_node_config.setter
    def linux_node_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigLinuxNodeConfigArgs']]):
        pulumi.set(self, "linux_node_config", value)

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs']]:
        """
        Parameters for the local NVMe SSDs. Structure is documented below.
        """
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @local_nvme_ssd_block_config.setter
    def local_nvme_ssd_block_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs']]):
        pulumi.set(self, "local_nvme_ssd_block_config", value)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[pulumi.Input[int]]:
        """
        The amount of local SSD disks that will be
        attached to each cluster node. Defaults to 0.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "local_ssd_count", value)

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[pulumi.Input[str]]:
        """
        Parameter for specifying the type of logging agent used in a node pool. This will override any cluster-wide default value. Valid values include DEFAULT and MAX_THROUGHPUT. See [Increasing logging agent throughput](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for more information.
        """
        return pulumi.get(self, "logging_variant")

    @logging_variant.setter
    def logging_variant(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "logging_variant", value)

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[pulumi.Input[str]]:
        """
        The name of a Google Compute Engine machine type.
        Defaults to `e2-medium`. To create a custom machine type, value should be set as specified
        [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).
        """
        return pulumi.get(self, "machine_type")

    @machine_type.setter
    def machine_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "machine_type", value)

    @property
    @pulumi.getter
    def metadata(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        The metadata key/value pairs assigned to instances in
        the cluster. From GKE `1.12` onwards, `disable-legacy-endpoints` is set to
        `true` by the API; if `metadata` is set but that default value is not
        included, the provider will attempt to unset the value. To avoid this, set the
        value in your config.
        """
        return pulumi.get(self, "metadata")

    @metadata.setter
    def metadata(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "metadata", value)

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[pulumi.Input[str]]:
        """
        Minimum CPU platform to be used by this instance.
        The instance may be scheduled on the specified or newer CPU platform. Applicable
        values are the friendly names of CPU platforms, such as `Intel Haswell`. See the
        [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
        for more information.
        """
        return pulumi.get(self, "min_cpu_platform")

    @min_cpu_platform.setter
    def min_cpu_platform(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "min_cpu_platform", value)

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[pulumi.Input[str]]:
        """
        Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
        """
        return pulumi.get(self, "node_group")

    @node_group.setter
    def node_group(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "node_group", value)

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The set of Google API scopes to be made available
        on all of the node VMs under the "default" service account.
        Use the "https://www.googleapis.com/auth/cloud-platform" scope to grant access to all APIs. It is recommended that you set `service_account` to a non-default service account and grant IAM roles to that service account for only the resources that it needs.

        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/access-scopes) for information on migrating off of legacy access scopes.
        """
        return pulumi.get(self, "oauth_scopes")

    @oauth_scopes.setter
    def oauth_scopes(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "oauth_scopes", value)

    @property
    @pulumi.getter
    def preemptible(self) -> Optional[pulumi.Input[bool]]:
        """
        A boolean that represents whether or not the underlying node VMs
        are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "preemptible")

    @preemptible.setter
    def preemptible(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "preemptible", value)

    @property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigReservationAffinityArgs']]:
        """
        The configuration of the desired reservation which instances could take capacity from. Structure is documented below.
        """
        return pulumi.get(self, "reservation_affinity")

    @reservation_affinity.setter
    def reservation_affinity(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigReservationAffinityArgs']]):
        pulumi.set(self, "reservation_affinity", value)

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        The GCP labels (key/value pairs) to be applied to each node. Refer [here](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels)
        for how these labels are applied to clusters, node pools and nodes.
        """
        return pulumi.get(self, "resource_labels")

    @resource_labels.setter
    def resource_labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "resource_labels", value)

    @property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigSandboxConfigArgs']]:
        return pulumi.get(self, "sandbox_config")

    @sandbox_config.setter
    def sandbox_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigSandboxConfigArgs']]):
        pulumi.set(self, "sandbox_config", value)

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[pulumi.Input[str]]:
        """
        The service account to be used by the Node VMs.
        If not specified, the "default" service account is used.
        """
        return pulumi.get(self, "service_account")

    @service_account.setter
    def service_account(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "service_account", value)

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigShieldedInstanceConfigArgs']]:
        """
        Shielded Instance options. Structure is documented below.
        """
        return pulumi.get(self, "shielded_instance_config")

    @shielded_instance_config.setter
    def shielded_instance_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigShieldedInstanceConfigArgs']]):
        pulumi.set(self, "shielded_instance_config", value)

    @property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigArgs']]:
        """
        Allows specifying multiple [node affinities](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes#node_affinity_and_anti-affinity) useful for running workloads on [sole tenant nodes](https://cloud.google.com/kubernetes-engine/docs/how-to/sole-tenancy). `node_affinity` structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "sole_tenant_config")

    @sole_tenant_config.setter
    def sole_tenant_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigArgs']]):
        pulumi.set(self, "sole_tenant_config", value)

    @property
    @pulumi.getter
    def spot(self) -> Optional[pulumi.Input[bool]]:
        """
        A boolean that represents whether the underlying node VMs are spot.
        See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms)
        for more information. Defaults to false.
        """
        return pulumi.get(self, "spot")

    @spot.setter
    def spot(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "spot", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The list of instance tags applied to all nodes. Tags are used to identify
        valid sources or targets for network firewalls.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter
    def taints(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigTaintArgs']]]]:
        """
        A list of [Kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
        to apply to nodes. GKE's API can only set this field on cluster creation.
        However, GKE will add taints to your nodes if you enable certain features such
        as GPUs. If this field is set, any diffs on this field will cause the provider to
        recreate the underlying resource. Taint values can be updated safely in
        Kubernetes (eg. through `kubectl`), and it's recommended that you do not use
        this field to manage taints. If you do, `lifecycle.ignore_changes` is
        recommended. Structure is documented below.
        """
        return pulumi.get(self, "taints")

    @taints.setter
    def taints(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigTaintArgs']]]]):
        pulumi.set(self, "taints", value)

    @property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs']]:
        """
        Metadata configuration to expose to workloads on the node pool.
        Structure is documented below.
        """
        return pulumi.get(self, "workload_metadata_config")

    @workload_metadata_config.setter
    def workload_metadata_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs']]):
        pulumi.set(self, "workload_metadata_config", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigAdvancedMachineFeaturesArgs:
    def __init__(__self__, *,
                 threads_per_core: pulumi.Input[int]):
        """
        :param pulumi.Input[int] threads_per_core: The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        pulumi.set(__self__, "threads_per_core", threads_per_core)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> pulumi.Input[int]:
        """
        The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
        """
        return pulumi.get(self, "threads_per_core")

    @threads_per_core.setter
    def threads_per_core(self, value: pulumi.Input[int]):
        pulumi.set(self, "threads_per_core", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigConfidentialNodesArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigEphemeralStorageConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[int]):
        """
        :param pulumi.Input[int] local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[int]:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "local_ssd_count", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[int]):
        """
        :param pulumi.Input[int] local_ssd_count: Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[int]:
        """
        Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD is 375 GB in size. If zero, it means to disable using local SSDs as ephemeral storage.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "local_ssd_count", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigFastSocketArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Whether or not the NCCL Fast Socket is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Whether or not the NCCL Fast Socket is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigGcfsConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Whether or not the Google Container Filesystem (GCFS) is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigGuestAcceleratorArgs:
    def __init__(__self__, *,
                 count: pulumi.Input[int],
                 type: pulumi.Input[str],
                 gpu_driver_installation_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']] = None,
                 gpu_partition_size: Optional[pulumi.Input[str]] = None,
                 gpu_sharing_config: Optional[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs']] = None):
        """
        :param pulumi.Input[int] count: The number of the guest accelerator cards exposed to this instance.
        :param pulumi.Input[str] type: The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        :param pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs'] gpu_driver_installation_config: Configuration for auto installation of GPU driver. Structure is documented below.
        :param pulumi.Input[str] gpu_partition_size: Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        :param pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs'] gpu_sharing_config: Configuration for GPU sharing. Structure is documented below.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @property
    @pulumi.getter
    def count(self) -> pulumi.Input[int]:
        """
        The number of the guest accelerator cards exposed to this instance.
        """
        return pulumi.get(self, "count")

    @count.setter
    def count(self, value: pulumi.Input[int]):
        pulumi.set(self, "count", value)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input[str]:
        """
        The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[str]):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']]:
        """
        Configuration for auto installation of GPU driver. Structure is documented below.
        """
        return pulumi.get(self, "gpu_driver_installation_config")

    @gpu_driver_installation_config.setter
    def gpu_driver_installation_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']]):
        pulumi.set(self, "gpu_driver_installation_config", value)

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[pulumi.Input[str]]:
        """
        Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig [user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
        """
        return pulumi.get(self, "gpu_partition_size")

    @gpu_partition_size.setter
    def gpu_partition_size(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "gpu_partition_size", value)

    @property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs']]:
        """
        Configuration for GPU sharing. Structure is documented below.
        """
        return pulumi.get(self, "gpu_sharing_config")

    @gpu_sharing_config.setter
    def gpu_sharing_config(self, value: Optional[pulumi.Input['ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs']]):
        pulumi.set(self, "gpu_sharing_config", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs:
    def __init__(__self__, *,
                 gpu_driver_version: pulumi.Input[str]):
        """
        :param pulumi.Input[str] gpu_driver_version: Mode for how the GPU driver is installed.
               Accepted values are:
               * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to not install any GPU driver.
               * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
               * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
               * `"LATEST"`: "Latest" GPU driver in COS.
        """
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> pulumi.Input[str]:
        """
        Mode for how the GPU driver is installed.
        Accepted values are:
        * `"GPU_DRIVER_VERSION_UNSPECIFIED"`: Default value is to not install any GPU driver.
        * `"INSTALLATION_DISABLED"`: Disable GPU driver auto installation and needs manual installation.
        * `"DEFAULT"`: "Default" GPU driver in COS and Ubuntu.
        * `"LATEST"`: "Latest" GPU driver in COS.
        """
        return pulumi.get(self, "gpu_driver_version")

    @gpu_driver_version.setter
    def gpu_driver_version(self, value: pulumi.Input[str]):
        pulumi.set(self, "gpu_driver_version", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs:
    def __init__(__self__, *,
                 gpu_sharing_strategy: pulumi.Input[str],
                 max_shared_clients_per_gpu: pulumi.Input[int]):
        """
        :param pulumi.Input[str] gpu_sharing_strategy: The type of GPU sharing strategy to enable on the GPU node.
               Accepted values are:
               * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        :param pulumi.Input[int] max_shared_clients_per_gpu: The maximum number of containers that can share a GPU.
        """
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> pulumi.Input[str]:
        """
        The type of GPU sharing strategy to enable on the GPU node.
        Accepted values are:
        * `"TIME_SHARING"`: Allow multiple containers to have [time-shared](https://cloud.google.com/kubernetes-engine/docs/concepts/timesharing-gpus) access to a single GPU device.
        """
        return pulumi.get(self, "gpu_sharing_strategy")

    @gpu_sharing_strategy.setter
    def gpu_sharing_strategy(self, value: pulumi.Input[str]):
        pulumi.set(self, "gpu_sharing_strategy", value)

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> pulumi.Input[int]:
        """
        The maximum number of containers that can share a GPU.
        """
        return pulumi.get(self, "max_shared_clients_per_gpu")

    @max_shared_clients_per_gpu.setter
    def max_shared_clients_per_gpu(self, value: pulumi.Input[int]):
        pulumi.set(self, "max_shared_clients_per_gpu", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigGvnicArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Whether or not the Google Virtual NIC (gVNIC) is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigHostMaintenancePolicyArgs:
    def __init__(__self__, *,
                 maintenance_interval: pulumi.Input[str]):
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> pulumi.Input[str]:
        return pulumi.get(self, "maintenance_interval")

    @maintenance_interval.setter
    def maintenance_interval(self, value: pulumi.Input[str]):
        pulumi.set(self, "maintenance_interval", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigKubeletConfigArgs:
    def __init__(__self__, *,
                 cpu_manager_policy: pulumi.Input[str],
                 cpu_cfs_quota: Optional[pulumi.Input[bool]] = None,
                 cpu_cfs_quota_period: Optional[pulumi.Input[str]] = None,
                 pod_pids_limit: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input[str] cpu_manager_policy: The CPU management policy on the node. See
               [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
               One of `"none"` or `"static"`. Defaults to `none` when `kubelet_config` is unset.
        :param pulumi.Input[bool] cpu_cfs_quota: If true, enables CPU CFS quota enforcement for
               containers that specify CPU limits.
        :param pulumi.Input[str] cpu_cfs_quota_period: The CPU CFS quota period value. Specified
               as a sequence of decimal numbers, each with optional fraction and a unit suffix,
               such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
               "h". The value must be a positive duration.
               
               > Note: At the time of writing (2020/08/18) the GKE API rejects the `none`
               value and accepts an invalid `default` value instead. While this remains true,
               not specifying the `kubelet_config` block should be the equivalent of specifying
               `none`.
        :param pulumi.Input[int] pod_pids_limit: Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> pulumi.Input[str]:
        """
        The CPU management policy on the node. See
        [K8S CPU Management Policies](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/).
        One of `"none"` or `"static"`. Defaults to `none` when `kubelet_config` is unset.
        """
        return pulumi.get(self, "cpu_manager_policy")

    @cpu_manager_policy.setter
    def cpu_manager_policy(self, value: pulumi.Input[str]):
        pulumi.set(self, "cpu_manager_policy", value)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[pulumi.Input[bool]]:
        """
        If true, enables CPU CFS quota enforcement for
        containers that specify CPU limits.
        """
        return pulumi.get(self, "cpu_cfs_quota")

    @cpu_cfs_quota.setter
    def cpu_cfs_quota(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "cpu_cfs_quota", value)

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[pulumi.Input[str]]:
        """
        The CPU CFS quota period value. Specified
        as a sequence of decimal numbers, each with optional fraction and a unit suffix,
        such as `"300ms"`. Valid time units are "ns", "us" (or "s"), "ms", "s", "m",
        "h". The value must be a positive duration.

        > Note: At the time of writing (2020/08/18) the GKE API rejects the `none`
        value and accepts an invalid `default` value instead. While this remains true,
        not specifying the `kubelet_config` block should be the equivalent of specifying
        `none`.
        """
        return pulumi.get(self, "cpu_cfs_quota_period")

    @cpu_cfs_quota_period.setter
    def cpu_cfs_quota_period(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "cpu_cfs_quota_period", value)

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[pulumi.Input[int]]:
        """
        Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
        """
        return pulumi.get(self, "pod_pids_limit")

    @pod_pids_limit.setter
    def pod_pids_limit(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "pod_pids_limit", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigLinuxNodeConfigArgs:
    def __init__(__self__, *,
                 sysctls: pulumi.Input[Mapping[str, pulumi.Input[str]]]):
        """
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] sysctls: The Linux kernel parameters to be applied to the nodes
               and all pods running on the nodes. Specified as a map from the key, such as
               `net.core.wmem_max`, to a string value.
        """
        pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter
    def sysctls(self) -> pulumi.Input[Mapping[str, pulumi.Input[str]]]:
        """
        The Linux kernel parameters to be applied to the nodes
        and all pods running on the nodes. Specified as a map from the key, such as
        `net.core.wmem_max`, to a string value.
        """
        return pulumi.get(self, "sysctls")

    @sysctls.setter
    def sysctls(self, value: pulumi.Input[Mapping[str, pulumi.Input[str]]]):
        pulumi.set(self, "sysctls", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigLocalNvmeSsdBlockConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[int]):
        """
        :param pulumi.Input[int] local_ssd_count: Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
               > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[int]:
        """
        Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size. If zero, it means no raw-block local NVMe SSD disks to be attached to the node.
        > Note: Local NVMe SSD storage available in GKE versions v1.25.3-gke.1800 and later.
        """
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "local_ssd_count", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigReservationAffinityArgs:
    def __init__(__self__, *,
                 consume_reservation_type: pulumi.Input[str],
                 key: Optional[pulumi.Input[str]] = None,
                 values: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[str] consume_reservation_type: The type of reservation consumption
               Accepted values are:
               
               * `"UNSPECIFIED"`: Default value. This should not be used.
               * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
               * `"ANY_RESERVATION"`: Consume any reservation available.
               * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        :param pulumi.Input[str] key: The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] values: The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> pulumi.Input[str]:
        """
        The type of reservation consumption
        Accepted values are:

        * `"UNSPECIFIED"`: Default value. This should not be used.
        * `"NO_RESERVATION"`: Do not consume from any reserved capacity.
        * `"ANY_RESERVATION"`: Consume any reservation available.
        * `"SPECIFIC_RESERVATION"`: Must consume from a specific reservation. Must specify key value fields for specifying the reservations.
        """
        return pulumi.get(self, "consume_reservation_type")

    @consume_reservation_type.setter
    def consume_reservation_type(self, value: pulumi.Input[str]):
        pulumi.set(self, "consume_reservation_type", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[pulumi.Input[str]]:
        """
        The label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The list of label values of reservation resources. For example: the name of the specific reservation when using a key of "compute.googleapis.com/reservation-name"
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "values", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigSandboxConfigArgs:
    def __init__(__self__, *,
                 sandbox_type: pulumi.Input[str]):
        """
        :param pulumi.Input[str] sandbox_type: Which sandbox to use for pods in the node pool.
               Accepted values are:
               
               * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> pulumi.Input[str]:
        """
        Which sandbox to use for pods in the node pool.
        Accepted values are:

        * `"gvisor"`: Pods run within a gVisor sandbox.
        """
        return pulumi.get(self, "sandbox_type")

    @sandbox_type.setter
    def sandbox_type(self, value: pulumi.Input[str]):
        pulumi.set(self, "sandbox_type", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigShieldedInstanceConfigArgs:
    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[pulumi.Input[bool]] = None,
                 enable_secure_boot: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[bool] enable_integrity_monitoring: Defines if the instance has integrity monitoring enabled.
               
               Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        :param pulumi.Input[bool] enable_secure_boot: Defines if the instance has Secure Boot enabled.
               
               Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[pulumi.Input[bool]]:
        """
        Defines if the instance has integrity monitoring enabled.

        Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.  Defaults to `true`.
        """
        return pulumi.get(self, "enable_integrity_monitoring")

    @enable_integrity_monitoring.setter
    def enable_integrity_monitoring(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_integrity_monitoring", value)

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[pulumi.Input[bool]]:
        """
        Defines if the instance has Secure Boot enabled.

        Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.  Defaults to `false`.
        """
        return pulumi.get(self, "enable_secure_boot")

    @enable_secure_boot.setter
    def enable_secure_boot(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_secure_boot", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigSoleTenantConfigArgs:
    def __init__(__self__, *,
                 node_affinities: pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]]):
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]]:
        return pulumi.get(self, "node_affinities")

    @node_affinities.setter
    def node_affinities(self, value: pulumi.Input[Sequence[pulumi.Input['ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]]):
        pulumi.set(self, "node_affinities", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigSoleTenantConfigNodeAffinityArgs:
    def __init__(__self__, *,
                 key: pulumi.Input[str],
                 operator: pulumi.Input[str],
                 values: pulumi.Input[Sequence[pulumi.Input[str]]]):
        """
        :param pulumi.Input[str] key: The default or custom node affinity label key name.
        :param pulumi.Input[str] operator: Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        :param pulumi.Input[Sequence[pulumi.Input[str]]] values: List of node affinity label values as strings.
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[str]:
        """
        The default or custom node affinity label key name.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def operator(self) -> pulumi.Input[str]:
        """
        Specifies affinity or anti-affinity. Accepted values are `"IN"` or `"NOT_IN"`
        """
        return pulumi.get(self, "operator")

    @operator.setter
    def operator(self, value: pulumi.Input[str]):
        pulumi.set(self, "operator", value)

    @property
    @pulumi.getter
    def values(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        List of node affinity label values as strings.
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "values", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigTaintArgs:
    def __init__(__self__, *,
                 effect: pulumi.Input[str],
                 key: pulumi.Input[str],
                 value: pulumi.Input[str]):
        """
        :param pulumi.Input[str] effect: Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        :param pulumi.Input[str] key: Key for taint.
        :param pulumi.Input[str] value: Value for taint.
        """
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> pulumi.Input[str]:
        """
        Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.
        """
        return pulumi.get(self, "effect")

    @effect.setter
    def effect(self, value: pulumi.Input[str]):
        pulumi.set(self, "effect", value)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[str]:
        """
        Key for taint.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[str]:
        """
        Value for taint.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[str]):
        pulumi.set(self, "value", value)


@pulumi.input_type
class ClusterNodePoolNodeConfigWorkloadMetadataConfigArgs:
    def __init__(__self__, *,
                 mode: pulumi.Input[str]):
        """
        :param pulumi.Input[str] mode: How to expose the node metadata to the workload running on the node.
               Accepted values are:
               * UNSPECIFIED: Not Set
               * GCE_METADATA: Expose all Compute Engine metadata to pods.
               * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> pulumi.Input[str]:
        """
        How to expose the node metadata to the workload running on the node.
        Accepted values are:
        * UNSPECIFIED: Not Set
        * GCE_METADATA: Expose all Compute Engine metadata to pods.
        * GKE_METADATA: Run the GKE Metadata Server on this node. The GKE Metadata Server exposes a metadata API to workloads that is compatible with the V1 Compute Metadata APIs exposed by the Compute Engine and App Engine Metadata Servers. This feature can only be enabled if [workload identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) is enabled at the cluster level.
        """
        return pulumi.get(self, "mode")

    @mode.setter
    def mode(self, value: pulumi.Input[str]):
        pulumi.set(self, "mode", value)


@pulumi.input_type
class ClusterNodePoolPlacementPolicyArgs:
    def __init__(__self__, *,
                 type: pulumi.Input[str],
                 policy_name: Optional[pulumi.Input[str]] = None,
                 tpu_topology: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] type: Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
               `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        pulumi.set(__self__, "type", type)
        if policy_name is not None:
            pulumi.set(__self__, "policy_name", policy_name)
        if tpu_topology is not None:
            pulumi.set(__self__, "tpu_topology", tpu_topology)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input[str]:
        """
        Telemetry integration for the cluster. Supported values (`ENABLED, DISABLED, SYSTEM_ONLY`);
        `SYSTEM_ONLY` (Only system components are monitored and logged) is only available in GKE versions 1.15 and later.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[str]):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "policy_name")

    @policy_name.setter
    def policy_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "policy_name", value)

    @property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "tpu_topology")

    @tpu_topology.setter
    def tpu_topology(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "tpu_topology", value)


@pulumi.input_type
class ClusterNodePoolUpgradeSettingsArgs:
    def __init__(__self__, *,
                 blue_green_settings: Optional[pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs']] = None,
                 max_surge: Optional[pulumi.Input[int]] = None,
                 max_unavailable: Optional[pulumi.Input[int]] = None,
                 strategy: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs'] blue_green_settings: Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param pulumi.Input[int] max_surge: The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param pulumi.Input[int] max_unavailable: The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        :param pulumi.Input[str] strategy: Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional[pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs']]:
        """
        Settings for blue-green upgrade strategy. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "blue_green_settings")

    @blue_green_settings.setter
    def blue_green_settings(self, value: Optional[pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs']]):
        pulumi.set(self, "blue_green_settings", value)

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_surge")

    @max_surge.setter
    def max_surge(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_surge", value)

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of nodes that can be simultaneously unavailable during the upgrade process. To be used when strategy is set to SURGE. Default is 0.
        """
        return pulumi.get(self, "max_unavailable")

    @max_unavailable.setter
    def max_unavailable(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_unavailable", value)

    @property
    @pulumi.getter
    def strategy(self) -> Optional[pulumi.Input[str]]:
        """
        Strategy used for node pool update. Strategy can only be one of BLUE_GREEN or SURGE. The default is value is SURGE.
        """
        return pulumi.get(self, "strategy")

    @strategy.setter
    def strategy(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "strategy", value)


@pulumi.input_type
class ClusterNodePoolUpgradeSettingsBlueGreenSettingsArgs:
    def __init__(__self__, *,
                 standard_rollout_policy: pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs'],
                 node_pool_soak_duration: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs'] standard_rollout_policy: Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        :param pulumi.Input[str] node_pool_soak_duration: Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)

    @property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']:
        """
        Standard policy for the blue-green upgrade. To be specified when strategy is set to BLUE_GREEN. Structure is documented below.
        """
        return pulumi.get(self, "standard_rollout_policy")

    @standard_rollout_policy.setter
    def standard_rollout_policy(self, value: pulumi.Input['ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']):
        pulumi.set(self, "standard_rollout_policy", value)

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[pulumi.Input[str]]:
        """
        Time needed after draining entire blue pool. After this period, blue pool will be cleaned up. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @node_pool_soak_duration.setter
    def node_pool_soak_duration(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "node_pool_soak_duration", value)


@pulumi.input_type
class ClusterNodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs:
    def __init__(__self__, *,
                 batch_node_count: Optional[pulumi.Input[int]] = None,
                 batch_percentage: Optional[pulumi.Input[float]] = None,
                 batch_soak_duration: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[int] batch_node_count: Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        :param pulumi.Input[float] batch_percentage: Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        :param pulumi.Input[str] batch_soak_duration: Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[pulumi.Input[int]]:
        """
        Number of blue nodes to drain in a batch. Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_node_count")

    @batch_node_count.setter
    def batch_node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "batch_node_count", value)

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[pulumi.Input[float]]:
        """
        Percentage of the bool pool nodes to drain in a batch. The range of this field should be (0.0, 1.0). Only one of the batch_percentage or batch_node_count can be specified.
        """
        return pulumi.get(self, "batch_percentage")

    @batch_percentage.setter
    def batch_percentage(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "batch_percentage", value)

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[pulumi.Input[str]]:
        """
        Soak time after each batch gets drained. A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".`.
        """
        return pulumi.get(self, "batch_soak_duration")

    @batch_soak_duration.setter
    def batch_soak_duration(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "batch_soak_duration", value)


@pulumi.input_type
class ClusterNotificationConfigArgs:
    def __init__(__self__, *,
                 pubsub: pulumi.Input['ClusterNotificationConfigPubsubArgs']):
        """
        :param pulumi.Input['ClusterNotificationConfigPubsubArgs'] pubsub: The pubsub config for the cluster's upgrade notifications.
        """
        pulumi.set(__self__, "pubsub", pubsub)

    @property
    @pulumi.getter
    def pubsub(self) -> pulumi.Input['ClusterNotificationConfigPubsubArgs']:
        """
        The pubsub config for the cluster's upgrade notifications.
        """
        return pulumi.get(self, "pubsub")

    @pubsub.setter
    def pubsub(self, value: pulumi.Input['ClusterNotificationConfigPubsubArgs']):
        pulumi.set(self, "pubsub", value)


@pulumi.input_type
class ClusterNotificationConfigPubsubArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool],
                 filter: Optional[pulumi.Input['ClusterNotificationConfigPubsubFilterArgs']] = None,
                 topic: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[bool] enabled: Whether or not the notification config is enabled
        :param pulumi.Input['ClusterNotificationConfigPubsubFilterArgs'] filter: Choose what type of notifications you want to receive. If no filters are applied, you'll receive all notification types. Structure is documented below.
               
               ```python
               import pulumi
               ```
        :param pulumi.Input[str] topic: The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: `projects/{project}/topics/{topic}`.
        """
        pulumi.set(__self__, "enabled", enabled)
        if filter is not None:
            pulumi.set(__self__, "filter", filter)
        if topic is not None:
            pulumi.set(__self__, "topic", topic)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Whether or not the notification config is enabled
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter
    def filter(self) -> Optional[pulumi.Input['ClusterNotificationConfigPubsubFilterArgs']]:
        """
        Choose what type of notifications you want to receive. If no filters are applied, you'll receive all notification types. Structure is documented below.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "filter")

    @filter.setter
    def filter(self, value: Optional[pulumi.Input['ClusterNotificationConfigPubsubFilterArgs']]):
        pulumi.set(self, "filter", value)

    @property
    @pulumi.getter
    def topic(self) -> Optional[pulumi.Input[str]]:
        """
        The pubsub topic to push upgrade notifications to. Must be in the same project as the cluster. Must be in the format: `projects/{project}/topics/{topic}`.
        """
        return pulumi.get(self, "topic")

    @topic.setter
    def topic(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "topic", value)


@pulumi.input_type
class ClusterNotificationConfigPubsubFilterArgs:
    def __init__(__self__, *,
                 event_types: pulumi.Input[Sequence[pulumi.Input[str]]]):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] event_types: Can be used to filter what notifications are sent. Accepted values are `UPGRADE_AVAILABLE_EVENT`, `UPGRADE_EVENT` and `SECURITY_BULLETIN_EVENT`. See [Filtering notifications](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-notifications#filtering) for more details.
        """
        pulumi.set(__self__, "event_types", event_types)

    @property
    @pulumi.getter(name="eventTypes")
    def event_types(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        Can be used to filter what notifications are sent. Accepted values are `UPGRADE_AVAILABLE_EVENT`, `UPGRADE_EVENT` and `SECURITY_BULLETIN_EVENT`. See [Filtering notifications](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-notifications#filtering) for more details.
        """
        return pulumi.get(self, "event_types")

    @event_types.setter
    def event_types(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "event_types", value)


@pulumi.input_type
class ClusterPodSecurityPolicyConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable the PodSecurityPolicy controller for this cluster.
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable the PodSecurityPolicy controller for this cluster.
        If enabled, pods must be valid under a PodSecurityPolicy to be created.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterPrivateClusterConfigArgs:
    def __init__(__self__, *,
                 enable_private_endpoint: Optional[pulumi.Input[bool]] = None,
                 enable_private_nodes: Optional[pulumi.Input[bool]] = None,
                 master_global_access_config: Optional[pulumi.Input['ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs']] = None,
                 master_ipv4_cidr_block: Optional[pulumi.Input[str]] = None,
                 peering_name: Optional[pulumi.Input[str]] = None,
                 private_endpoint: Optional[pulumi.Input[str]] = None,
                 private_endpoint_subnetwork: Optional[pulumi.Input[str]] = None,
                 public_endpoint: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[bool] enable_private_endpoint: When `true`, the cluster's private
               endpoint is used as the cluster endpoint and access through the public endpoint
               is disabled. When `false`, either endpoint can be used. This field only applies
               to private clusters, when `enable_private_nodes` is `true`.
        :param pulumi.Input[bool] enable_private_nodes: Enables the private cluster feature,
               creating a private endpoint on the cluster. In a private cluster, nodes only
               have RFC 1918 private addresses and communicate with the master's private
               endpoint via private networking.
        :param pulumi.Input['ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs'] master_global_access_config: Controls cluster master global
               access settings. If unset, the provider will no longer manage this field and will
               not modify the previously-set value. Structure is documented below.
        :param pulumi.Input[str] master_ipv4_cidr_block: The IP range in CIDR notation to use for
               the hosted master network. This range will be used for assigning private IP
               addresses to the cluster master(s) and the ILB VIP. This range must not overlap
               with any other ranges in use within the cluster's network, and it must be a /28
               subnet. See [Private Cluster Limitations](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#req_res_lim)
               for more details. This field only applies to private clusters, when
               `enable_private_nodes` is `true`.
        :param pulumi.Input[str] peering_name: The name of the peering between this cluster and the Google owned VPC.
        :param pulumi.Input[str] private_endpoint: The internal IP address of this cluster's master endpoint.
        :param pulumi.Input[str] private_endpoint_subnetwork: Subnetwork in cluster's network where master's endpoint will be provisioned.
        :param pulumi.Input[str] public_endpoint: The external IP address of this cluster's master endpoint.
               
               !> The Google provider is unable to validate certain configurations of
               `private_cluster_config` when `enable_private_nodes` is `false`. It's
               recommended that you omit the block entirely if the field is not set to `true`.
        """
        if enable_private_endpoint is not None:
            pulumi.set(__self__, "enable_private_endpoint", enable_private_endpoint)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if master_global_access_config is not None:
            pulumi.set(__self__, "master_global_access_config", master_global_access_config)
        if master_ipv4_cidr_block is not None:
            pulumi.set(__self__, "master_ipv4_cidr_block", master_ipv4_cidr_block)
        if peering_name is not None:
            pulumi.set(__self__, "peering_name", peering_name)
        if private_endpoint is not None:
            pulumi.set(__self__, "private_endpoint", private_endpoint)
        if private_endpoint_subnetwork is not None:
            pulumi.set(__self__, "private_endpoint_subnetwork", private_endpoint_subnetwork)
        if public_endpoint is not None:
            pulumi.set(__self__, "public_endpoint", public_endpoint)

    @property
    @pulumi.getter(name="enablePrivateEndpoint")
    def enable_private_endpoint(self) -> Optional[pulumi.Input[bool]]:
        """
        When `true`, the cluster's private
        endpoint is used as the cluster endpoint and access through the public endpoint
        is disabled. When `false`, either endpoint can be used. This field only applies
        to private clusters, when `enable_private_nodes` is `true`.
        """
        return pulumi.get(self, "enable_private_endpoint")

    @enable_private_endpoint.setter
    def enable_private_endpoint(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_private_endpoint", value)

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[pulumi.Input[bool]]:
        """
        Enables the private cluster feature,
        creating a private endpoint on the cluster. In a private cluster, nodes only
        have RFC 1918 private addresses and communicate with the master's private
        endpoint via private networking.
        """
        return pulumi.get(self, "enable_private_nodes")

    @enable_private_nodes.setter
    def enable_private_nodes(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_private_nodes", value)

    @property
    @pulumi.getter(name="masterGlobalAccessConfig")
    def master_global_access_config(self) -> Optional[pulumi.Input['ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs']]:
        """
        Controls cluster master global
        access settings. If unset, the provider will no longer manage this field and will
        not modify the previously-set value. Structure is documented below.
        """
        return pulumi.get(self, "master_global_access_config")

    @master_global_access_config.setter
    def master_global_access_config(self, value: Optional[pulumi.Input['ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs']]):
        pulumi.set(self, "master_global_access_config", value)

    @property
    @pulumi.getter(name="masterIpv4CidrBlock")
    def master_ipv4_cidr_block(self) -> Optional[pulumi.Input[str]]:
        """
        The IP range in CIDR notation to use for
        the hosted master network. This range will be used for assigning private IP
        addresses to the cluster master(s) and the ILB VIP. This range must not overlap
        with any other ranges in use within the cluster's network, and it must be a /28
        subnet. See [Private Cluster Limitations](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#req_res_lim)
        for more details. This field only applies to private clusters, when
        `enable_private_nodes` is `true`.
        """
        return pulumi.get(self, "master_ipv4_cidr_block")

    @master_ipv4_cidr_block.setter
    def master_ipv4_cidr_block(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "master_ipv4_cidr_block", value)

    @property
    @pulumi.getter(name="peeringName")
    def peering_name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the peering between this cluster and the Google owned VPC.
        """
        return pulumi.get(self, "peering_name")

    @peering_name.setter
    def peering_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "peering_name", value)

    @property
    @pulumi.getter(name="privateEndpoint")
    def private_endpoint(self) -> Optional[pulumi.Input[str]]:
        """
        The internal IP address of this cluster's master endpoint.
        """
        return pulumi.get(self, "private_endpoint")

    @private_endpoint.setter
    def private_endpoint(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "private_endpoint", value)

    @property
    @pulumi.getter(name="privateEndpointSubnetwork")
    def private_endpoint_subnetwork(self) -> Optional[pulumi.Input[str]]:
        """
        Subnetwork in cluster's network where master's endpoint will be provisioned.
        """
        return pulumi.get(self, "private_endpoint_subnetwork")

    @private_endpoint_subnetwork.setter
    def private_endpoint_subnetwork(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "private_endpoint_subnetwork", value)

    @property
    @pulumi.getter(name="publicEndpoint")
    def public_endpoint(self) -> Optional[pulumi.Input[str]]:
        """
        The external IP address of this cluster's master endpoint.

        !> The Google provider is unable to validate certain configurations of
        `private_cluster_config` when `enable_private_nodes` is `false`. It's
        recommended that you omit the block entirely if the field is not set to `true`.
        """
        return pulumi.get(self, "public_endpoint")

    @public_endpoint.setter
    def public_endpoint(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "public_endpoint", value)


@pulumi.input_type
class ClusterPrivateClusterConfigMasterGlobalAccessConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Whether the cluster master is accessible globally or
               not.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Whether the cluster master is accessible globally or
        not.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterProtectConfigArgs:
    def __init__(__self__, *,
                 workload_config: Optional[pulumi.Input['ClusterProtectConfigWorkloadConfigArgs']] = None,
                 workload_vulnerability_mode: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['ClusterProtectConfigWorkloadConfigArgs'] workload_config: ) WorkloadConfig defines which actions are enabled for a cluster's workload configurations. Structure is documented below
        :param pulumi.Input[str] workload_vulnerability_mode: ) Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        if workload_config is not None:
            pulumi.set(__self__, "workload_config", workload_config)
        if workload_vulnerability_mode is not None:
            pulumi.set(__self__, "workload_vulnerability_mode", workload_vulnerability_mode)

    @property
    @pulumi.getter(name="workloadConfig")
    def workload_config(self) -> Optional[pulumi.Input['ClusterProtectConfigWorkloadConfigArgs']]:
        """
        ) WorkloadConfig defines which actions are enabled for a cluster's workload configurations. Structure is documented below
        """
        return pulumi.get(self, "workload_config")

    @workload_config.setter
    def workload_config(self, value: Optional[pulumi.Input['ClusterProtectConfigWorkloadConfigArgs']]):
        pulumi.set(self, "workload_config", value)

    @property
    @pulumi.getter(name="workloadVulnerabilityMode")
    def workload_vulnerability_mode(self) -> Optional[pulumi.Input[str]]:
        """
        ) Sets which mode to use for Protect workload vulnerability scanning feature. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "workload_vulnerability_mode")

    @workload_vulnerability_mode.setter
    def workload_vulnerability_mode(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "workload_vulnerability_mode", value)


@pulumi.input_type
class ClusterProtectConfigWorkloadConfigArgs:
    def __init__(__self__, *,
                 audit_mode: pulumi.Input[str]):
        """
        :param pulumi.Input[str] audit_mode: ) Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        pulumi.set(__self__, "audit_mode", audit_mode)

    @property
    @pulumi.getter(name="auditMode")
    def audit_mode(self) -> pulumi.Input[str]:
        """
        ) Sets which mode of auditing should be used for the cluster's workloads. Accepted values are DISABLED, BASIC.
        """
        return pulumi.get(self, "audit_mode")

    @audit_mode.setter
    def audit_mode(self, value: pulumi.Input[str]):
        pulumi.set(self, "audit_mode", value)


@pulumi.input_type
class ClusterReleaseChannelArgs:
    def __init__(__self__, *,
                 channel: pulumi.Input[str]):
        """
        :param pulumi.Input[str] channel: The selected release channel.
               Accepted values are:
               * UNSPECIFIED: Not set.
               * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
               * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
               * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
        """
        pulumi.set(__self__, "channel", channel)

    @property
    @pulumi.getter
    def channel(self) -> pulumi.Input[str]:
        """
        The selected release channel.
        Accepted values are:
        * UNSPECIFIED: Not set.
        * RAPID: Weekly upgrade cadence; Early testers and developers who requires new features.
        * REGULAR: Multiple per month upgrade cadence; Production users who need features not yet offered in the Stable channel.
        * STABLE: Every few months upgrade cadence; Production users who need stability above all else, and for whom frequent upgrades are too risky.
        """
        return pulumi.get(self, "channel")

    @channel.setter
    def channel(self, value: pulumi.Input[str]):
        pulumi.set(self, "channel", value)


@pulumi.input_type
class ClusterResourceUsageExportConfigArgs:
    def __init__(__self__, *,
                 bigquery_destination: pulumi.Input['ClusterResourceUsageExportConfigBigqueryDestinationArgs'],
                 enable_network_egress_metering: Optional[pulumi.Input[bool]] = None,
                 enable_resource_consumption_metering: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input['ClusterResourceUsageExportConfigBigqueryDestinationArgs'] bigquery_destination: Parameters for using BigQuery as the destination of resource usage export.
               
               * `bigquery_destination.dataset_id` (Required) - The ID of a BigQuery Dataset. For Example:
               
               ```python
               import pulumi
               ```
        :param pulumi.Input[bool] enable_network_egress_metering: Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created
               in the cluster to meter network egress traffic.
        :param pulumi.Input[bool] enable_resource_consumption_metering: Whether to enable resource
               consumption metering on this cluster. When enabled, a table will be created in
               the resource export BigQuery dataset to store resource consumption data. The
               resulting table can be joined with the resource usage table or with BigQuery
               billing export. Defaults to `true`.
        """
        pulumi.set(__self__, "bigquery_destination", bigquery_destination)
        if enable_network_egress_metering is not None:
            pulumi.set(__self__, "enable_network_egress_metering", enable_network_egress_metering)
        if enable_resource_consumption_metering is not None:
            pulumi.set(__self__, "enable_resource_consumption_metering", enable_resource_consumption_metering)

    @property
    @pulumi.getter(name="bigqueryDestination")
    def bigquery_destination(self) -> pulumi.Input['ClusterResourceUsageExportConfigBigqueryDestinationArgs']:
        """
        Parameters for using BigQuery as the destination of resource usage export.

        * `bigquery_destination.dataset_id` (Required) - The ID of a BigQuery Dataset. For Example:

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "bigquery_destination")

    @bigquery_destination.setter
    def bigquery_destination(self, value: pulumi.Input['ClusterResourceUsageExportConfigBigqueryDestinationArgs']):
        pulumi.set(self, "bigquery_destination", value)

    @property
    @pulumi.getter(name="enableNetworkEgressMetering")
    def enable_network_egress_metering(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created
        in the cluster to meter network egress traffic.
        """
        return pulumi.get(self, "enable_network_egress_metering")

    @enable_network_egress_metering.setter
    def enable_network_egress_metering(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_network_egress_metering", value)

    @property
    @pulumi.getter(name="enableResourceConsumptionMetering")
    def enable_resource_consumption_metering(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether to enable resource
        consumption metering on this cluster. When enabled, a table will be created in
        the resource export BigQuery dataset to store resource consumption data. The
        resulting table can be joined with the resource usage table or with BigQuery
        billing export. Defaults to `true`.
        """
        return pulumi.get(self, "enable_resource_consumption_metering")

    @enable_resource_consumption_metering.setter
    def enable_resource_consumption_metering(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_resource_consumption_metering", value)


@pulumi.input_type
class ClusterResourceUsageExportConfigBigqueryDestinationArgs:
    def __init__(__self__, *,
                 dataset_id: pulumi.Input[str]):
        pulumi.set(__self__, "dataset_id", dataset_id)

    @property
    @pulumi.getter(name="datasetId")
    def dataset_id(self) -> pulumi.Input[str]:
        return pulumi.get(self, "dataset_id")

    @dataset_id.setter
    def dataset_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "dataset_id", value)


@pulumi.input_type
class ClusterSecurityPostureConfigArgs:
    def __init__(__self__, *,
                 mode: Optional[pulumi.Input[str]] = None,
                 vulnerability_mode: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] mode: Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include `DISABLED` and `BASIC`.
        :param pulumi.Input[str] vulnerability_mode: Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include `VULNERABILITY_DISABLED` and `VULNERABILITY_BASIC`.
        """
        if mode is not None:
            pulumi.set(__self__, "mode", mode)
        if vulnerability_mode is not None:
            pulumi.set(__self__, "vulnerability_mode", vulnerability_mode)

    @property
    @pulumi.getter
    def mode(self) -> Optional[pulumi.Input[str]]:
        """
        Sets the mode of the Kubernetes security posture API's off-cluster features. Available options include `DISABLED` and `BASIC`.
        """
        return pulumi.get(self, "mode")

    @mode.setter
    def mode(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "mode", value)

    @property
    @pulumi.getter(name="vulnerabilityMode")
    def vulnerability_mode(self) -> Optional[pulumi.Input[str]]:
        """
        Sets the mode of the Kubernetes security posture API's workload vulnerability scanning. Available options include `VULNERABILITY_DISABLED` and `VULNERABILITY_BASIC`.
        """
        return pulumi.get(self, "vulnerability_mode")

    @vulnerability_mode.setter
    def vulnerability_mode(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "vulnerability_mode", value)


@pulumi.input_type
class ClusterServiceExternalIpsConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Controls whether external ips specified by a service will be allowed. It is enabled by default.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Controls whether external ips specified by a service will be allowed. It is enabled by default.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterTpuConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool],
                 ipv4_cidr_block: Optional[pulumi.Input[str]] = None,
                 use_service_networking: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[bool] enabled: Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.
               
               
               
               for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.
               
               
               
               
               
               
               
               enforce encryption of data in-use.
               
               If enabled, pods must be valid under a PodSecurityPolicy to be created.
               
               not.
        """
        pulumi.set(__self__, "enabled", enabled)
        if ipv4_cidr_block is not None:
            pulumi.set(__self__, "ipv4_cidr_block", ipv4_cidr_block)
        if use_service_networking is not None:
            pulumi.set(__self__, "use_service_networking", use_service_networking)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Binary Authorization for this cluster. Deprecated in favor of `evaluation_mode`.



        for autopilot clusters. Resource limits for `cpu` and `memory` must be defined to enable node auto-provisioning for GKE Standard.







        enforce encryption of data in-use.

        If enabled, pods must be valid under a PodSecurityPolicy to be created.

        not.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)

    @property
    @pulumi.getter(name="ipv4CidrBlock")
    def ipv4_cidr_block(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "ipv4_cidr_block")

    @ipv4_cidr_block.setter
    def ipv4_cidr_block(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "ipv4_cidr_block", value)

    @property
    @pulumi.getter(name="useServiceNetworking")
    def use_service_networking(self) -> Optional[pulumi.Input[bool]]:
        return pulumi.get(self, "use_service_networking")

    @use_service_networking.setter
    def use_service_networking(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "use_service_networking", value)


@pulumi.input_type
class ClusterVerticalPodAutoscalingArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enables vertical pod autoscaling
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enables vertical pod autoscaling
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class ClusterWorkloadIdentityConfigArgs:
    def __init__(__self__, *,
                 workload_pool: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] workload_pool: The workload pool to attach all Kubernetes service accounts to.
               
               ```python
               import pulumi
               ```
        """
        if workload_pool is not None:
            pulumi.set(__self__, "workload_pool", workload_pool)

    @property
    @pulumi.getter(name="workloadPool")
    def workload_pool(self) -> Optional[pulumi.Input[str]]:
        """
        The workload pool to attach all Kubernetes service accounts to.

        ```python
        import pulumi
        ```
        """
        return pulumi.get(self, "workload_pool")

    @workload_pool.setter
    def workload_pool(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "workload_pool", value)


@pulumi.input_type
class NodePoolAutoscalingArgs:
    def __init__(__self__, *,
                 location_policy: Optional[pulumi.Input[str]] = None,
                 max_node_count: Optional[pulumi.Input[int]] = None,
                 min_node_count: Optional[pulumi.Input[int]] = None,
                 total_max_node_count: Optional[pulumi.Input[int]] = None,
                 total_min_node_count: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input[str] location_policy: Location policy specifies the algorithm used when
               scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
               * "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones.
               * "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations,
               and reduce preemption risk for Spot VMs.
        :param pulumi.Input[int] max_node_count: Maximum number of nodes per zone in the NodePool.
               Must be >= min_node_count. Cannot be used with total limits.
        :param pulumi.Input[int] min_node_count: Minimum number of nodes per zone in the NodePool.
               Must be >=0 and <= `max_node_count`. Cannot be used with total limits.
        :param pulumi.Input[int] total_max_node_count: Total maximum number of nodes in the NodePool.
               Must be >= total_min_node_count. Cannot be used with per zone limits.
               Total size limits are supported only in 1.24.1+ clusters.
        :param pulumi.Input[int] total_min_node_count: Total minimum number of nodes in the NodePool.
               Must be >=0 and <= `total_max_node_count`. Cannot be used with per zone limits.
               Total size limits are supported only in 1.24.1+ clusters.
        """
        if location_policy is not None:
            pulumi.set(__self__, "location_policy", location_policy)
        if max_node_count is not None:
            pulumi.set(__self__, "max_node_count", max_node_count)
        if min_node_count is not None:
            pulumi.set(__self__, "min_node_count", min_node_count)
        if total_max_node_count is not None:
            pulumi.set(__self__, "total_max_node_count", total_max_node_count)
        if total_min_node_count is not None:
            pulumi.set(__self__, "total_min_node_count", total_min_node_count)

    @property
    @pulumi.getter(name="locationPolicy")
    def location_policy(self) -> Optional[pulumi.Input[str]]:
        """
        Location policy specifies the algorithm used when
        scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
        * "BALANCED" - Is a best effort policy that aims to balance the sizes of available zones.
        * "ANY" - Instructs the cluster autoscaler to prioritize utilization of unused reservations,
        and reduce preemption risk for Spot VMs.
        """
        return pulumi.get(self, "location_policy")

    @location_policy.setter
    def location_policy(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "location_policy", value)

    @property
    @pulumi.getter(name="maxNodeCount")
    def max_node_count(self) -> Optional[pulumi.Input[int]]:
        """
        Maximum number of nodes per zone in the NodePool.
        Must be >= min_node_count. Cannot be used with total limits.
        """
        return pulumi.get(self, "max_node_count")

    @max_node_count.setter
    def max_node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_node_count", value)

    @property
    @pulumi.getter(name="minNodeCount")
    def min_node_count(self) -> Optional[pulumi.Input[int]]:
        """
        Minimum number of nodes per zone in the NodePool.
        Must be >=0 and <= `max_node_count`. Cannot be used with total limits.
        """
        return pulumi.get(self, "min_node_count")

    @min_node_count.setter
    def min_node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "min_node_count", value)

    @property
    @pulumi.getter(name="totalMaxNodeCount")
    def total_max_node_count(self) -> Optional[pulumi.Input[int]]:
        """
        Total maximum number of nodes in the NodePool.
        Must be >= total_min_node_count. Cannot be used with per zone limits.
        Total size limits are supported only in 1.24.1+ clusters.
        """
        return pulumi.get(self, "total_max_node_count")

    @total_max_node_count.setter
    def total_max_node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "total_max_node_count", value)

    @property
    @pulumi.getter(name="totalMinNodeCount")
    def total_min_node_count(self) -> Optional[pulumi.Input[int]]:
        """
        Total minimum number of nodes in the NodePool.
        Must be >=0 and <= `total_max_node_count`. Cannot be used with per zone limits.
        Total size limits are supported only in 1.24.1+ clusters.
        """
        return pulumi.get(self, "total_min_node_count")

    @total_min_node_count.setter
    def total_min_node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "total_min_node_count", value)


@pulumi.input_type
class NodePoolManagementArgs:
    def __init__(__self__, *,
                 auto_repair: Optional[pulumi.Input[bool]] = None,
                 auto_upgrade: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[bool] auto_repair: Whether the nodes will be automatically repaired.
        :param pulumi.Input[bool] auto_upgrade: Whether the nodes will be automatically upgraded.
        """
        if auto_repair is not None:
            pulumi.set(__self__, "auto_repair", auto_repair)
        if auto_upgrade is not None:
            pulumi.set(__self__, "auto_upgrade", auto_upgrade)

    @property
    @pulumi.getter(name="autoRepair")
    def auto_repair(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether the nodes will be automatically repaired.
        """
        return pulumi.get(self, "auto_repair")

    @auto_repair.setter
    def auto_repair(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "auto_repair", value)

    @property
    @pulumi.getter(name="autoUpgrade")
    def auto_upgrade(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether the nodes will be automatically upgraded.
        """
        return pulumi.get(self, "auto_upgrade")

    @auto_upgrade.setter
    def auto_upgrade(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "auto_upgrade", value)


@pulumi.input_type
class NodePoolNetworkConfigArgs:
    def __init__(__self__, *,
                 additional_node_network_configs: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]]] = None,
                 additional_pod_network_configs: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]]] = None,
                 create_pod_range: Optional[pulumi.Input[bool]] = None,
                 enable_private_nodes: Optional[pulumi.Input[bool]] = None,
                 pod_cidr_overprovision_config: Optional[pulumi.Input['NodePoolNetworkConfigPodCidrOverprovisionConfigArgs']] = None,
                 pod_ipv4_cidr_block: Optional[pulumi.Input[str]] = None,
                 pod_range: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]] additional_node_network_configs: We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface.
               Structure is documented below
        :param pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]] additional_pod_network_configs: We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node.
               Structure is documented below
        :param pulumi.Input[bool] create_pod_range: Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        :param pulumi.Input[bool] enable_private_nodes: Whether nodes have internal IP addresses only.
        :param pulumi.Input[str] pod_ipv4_cidr_block: The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        :param pulumi.Input[str] pod_range: The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        if additional_node_network_configs is not None:
            pulumi.set(__self__, "additional_node_network_configs", additional_node_network_configs)
        if additional_pod_network_configs is not None:
            pulumi.set(__self__, "additional_pod_network_configs", additional_pod_network_configs)
        if create_pod_range is not None:
            pulumi.set(__self__, "create_pod_range", create_pod_range)
        if enable_private_nodes is not None:
            pulumi.set(__self__, "enable_private_nodes", enable_private_nodes)
        if pod_cidr_overprovision_config is not None:
            pulumi.set(__self__, "pod_cidr_overprovision_config", pod_cidr_overprovision_config)
        if pod_ipv4_cidr_block is not None:
            pulumi.set(__self__, "pod_ipv4_cidr_block", pod_ipv4_cidr_block)
        if pod_range is not None:
            pulumi.set(__self__, "pod_range", pod_range)

    @property
    @pulumi.getter(name="additionalNodeNetworkConfigs")
    def additional_node_network_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]]]:
        """
        We specify the additional node networks for this node pool using this list. Each node network corresponds to an additional interface.
        Structure is documented below
        """
        return pulumi.get(self, "additional_node_network_configs")

    @additional_node_network_configs.setter
    def additional_node_network_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs']]]]):
        pulumi.set(self, "additional_node_network_configs", value)

    @property
    @pulumi.getter(name="additionalPodNetworkConfigs")
    def additional_pod_network_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]]]:
        """
        We specify the additional pod networks for this node pool using this list. Each pod network corresponds to an additional alias IP range for the node.
        Structure is documented below
        """
        return pulumi.get(self, "additional_pod_network_configs")

    @additional_pod_network_configs.setter
    def additional_pod_network_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNetworkConfigAdditionalPodNetworkConfigArgs']]]]):
        pulumi.set(self, "additional_pod_network_configs", value)

    @property
    @pulumi.getter(name="createPodRange")
    def create_pod_range(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified.
        """
        return pulumi.get(self, "create_pod_range")

    @create_pod_range.setter
    def create_pod_range(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "create_pod_range", value)

    @property
    @pulumi.getter(name="enablePrivateNodes")
    def enable_private_nodes(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether nodes have internal IP addresses only.
        """
        return pulumi.get(self, "enable_private_nodes")

    @enable_private_nodes.setter
    def enable_private_nodes(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_private_nodes", value)

    @property
    @pulumi.getter(name="podCidrOverprovisionConfig")
    def pod_cidr_overprovision_config(self) -> Optional[pulumi.Input['NodePoolNetworkConfigPodCidrOverprovisionConfigArgs']]:
        return pulumi.get(self, "pod_cidr_overprovision_config")

    @pod_cidr_overprovision_config.setter
    def pod_cidr_overprovision_config(self, value: Optional[pulumi.Input['NodePoolNetworkConfigPodCidrOverprovisionConfigArgs']]):
        pulumi.set(self, "pod_cidr_overprovision_config", value)

    @property
    @pulumi.getter(name="podIpv4CidrBlock")
    def pod_ipv4_cidr_block(self) -> Optional[pulumi.Input[str]]:
        """
        The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
        """
        return pulumi.get(self, "pod_ipv4_cidr_block")

    @pod_ipv4_cidr_block.setter
    def pod_ipv4_cidr_block(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "pod_ipv4_cidr_block", value)

    @property
    @pulumi.getter(name="podRange")
    def pod_range(self) -> Optional[pulumi.Input[str]]:
        """
        The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID.
        """
        return pulumi.get(self, "pod_range")

    @pod_range.setter
    def pod_range(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "pod_range", value)


@pulumi.input_type
class NodePoolNetworkConfigAdditionalNodeNetworkConfigArgs:
    def __init__(__self__, *,
                 network: Optional[pulumi.Input[str]] = None,
                 subnetwork: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] network: Name of the VPC where the additional interface belongs.
        :param pulumi.Input[str] subnetwork: Name of the subnetwork where the additional interface belongs.
        """
        if network is not None:
            pulumi.set(__self__, "network", network)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter
    def network(self) -> Optional[pulumi.Input[str]]:
        """
        Name of the VPC where the additional interface belongs.
        """
        return pulumi.get(self, "network")

    @network.setter
    def network(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "network", value)

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[pulumi.Input[str]]:
        """
        Name of the subnetwork where the additional interface belongs.
        """
        return pulumi.get(self, "subnetwork")

    @subnetwork.setter
    def subnetwork(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "subnetwork", value)


@pulumi.input_type
class NodePoolNetworkConfigAdditionalPodNetworkConfigArgs:
    def __init__(__self__, *,
                 max_pods_per_node: Optional[pulumi.Input[int]] = None,
                 secondary_pod_range: Optional[pulumi.Input[str]] = None,
                 subnetwork: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[int] max_pods_per_node: The maximum number of pods per node which use this pod network.
        :param pulumi.Input[str] secondary_pod_range: The name of the secondary range on the subnet which provides IP address for this pod range.
        :param pulumi.Input[str] subnetwork: Name of the subnetwork where the additional pod network belongs.
        """
        if max_pods_per_node is not None:
            pulumi.set(__self__, "max_pods_per_node", max_pods_per_node)
        if secondary_pod_range is not None:
            pulumi.set(__self__, "secondary_pod_range", secondary_pod_range)
        if subnetwork is not None:
            pulumi.set(__self__, "subnetwork", subnetwork)

    @property
    @pulumi.getter(name="maxPodsPerNode")
    def max_pods_per_node(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of pods per node which use this pod network.
        """
        return pulumi.get(self, "max_pods_per_node")

    @max_pods_per_node.setter
    def max_pods_per_node(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_pods_per_node", value)

    @property
    @pulumi.getter(name="secondaryPodRange")
    def secondary_pod_range(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the secondary range on the subnet which provides IP address for this pod range.
        """
        return pulumi.get(self, "secondary_pod_range")

    @secondary_pod_range.setter
    def secondary_pod_range(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "secondary_pod_range", value)

    @property
    @pulumi.getter
    def subnetwork(self) -> Optional[pulumi.Input[str]]:
        """
        Name of the subnetwork where the additional pod network belongs.
        """
        return pulumi.get(self, "subnetwork")

    @subnetwork.setter
    def subnetwork(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "subnetwork", value)


@pulumi.input_type
class NodePoolNetworkConfigPodCidrOverprovisionConfigArgs:
    def __init__(__self__, *,
                 disabled: pulumi.Input[bool]):
        pulumi.set(__self__, "disabled", disabled)

    @property
    @pulumi.getter
    def disabled(self) -> pulumi.Input[bool]:
        return pulumi.get(self, "disabled")

    @disabled.setter
    def disabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "disabled", value)


@pulumi.input_type
class NodePoolNodeConfigArgs:
    def __init__(__self__, *,
                 advanced_machine_features: Optional[pulumi.Input['NodePoolNodeConfigAdvancedMachineFeaturesArgs']] = None,
                 boot_disk_kms_key: Optional[pulumi.Input[str]] = None,
                 confidential_nodes: Optional[pulumi.Input['NodePoolNodeConfigConfidentialNodesArgs']] = None,
                 disk_size_gb: Optional[pulumi.Input[int]] = None,
                 disk_type: Optional[pulumi.Input[str]] = None,
                 ephemeral_storage_config: Optional[pulumi.Input['NodePoolNodeConfigEphemeralStorageConfigArgs']] = None,
                 ephemeral_storage_local_ssd_config: Optional[pulumi.Input['NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs']] = None,
                 fast_socket: Optional[pulumi.Input['NodePoolNodeConfigFastSocketArgs']] = None,
                 gcfs_config: Optional[pulumi.Input['NodePoolNodeConfigGcfsConfigArgs']] = None,
                 guest_accelerators: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigGuestAcceleratorArgs']]]] = None,
                 gvnic: Optional[pulumi.Input['NodePoolNodeConfigGvnicArgs']] = None,
                 host_maintenance_policy: Optional[pulumi.Input['NodePoolNodeConfigHostMaintenancePolicyArgs']] = None,
                 image_type: Optional[pulumi.Input[str]] = None,
                 kubelet_config: Optional[pulumi.Input['NodePoolNodeConfigKubeletConfigArgs']] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 linux_node_config: Optional[pulumi.Input['NodePoolNodeConfigLinuxNodeConfigArgs']] = None,
                 local_nvme_ssd_block_config: Optional[pulumi.Input['NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs']] = None,
                 local_ssd_count: Optional[pulumi.Input[int]] = None,
                 logging_variant: Optional[pulumi.Input[str]] = None,
                 machine_type: Optional[pulumi.Input[str]] = None,
                 metadata: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 min_cpu_platform: Optional[pulumi.Input[str]] = None,
                 node_group: Optional[pulumi.Input[str]] = None,
                 oauth_scopes: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 preemptible: Optional[pulumi.Input[bool]] = None,
                 reservation_affinity: Optional[pulumi.Input['NodePoolNodeConfigReservationAffinityArgs']] = None,
                 resource_labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 sandbox_config: Optional[pulumi.Input['NodePoolNodeConfigSandboxConfigArgs']] = None,
                 service_account: Optional[pulumi.Input[str]] = None,
                 shielded_instance_config: Optional[pulumi.Input['NodePoolNodeConfigShieldedInstanceConfigArgs']] = None,
                 sole_tenant_config: Optional[pulumi.Input['NodePoolNodeConfigSoleTenantConfigArgs']] = None,
                 spot: Optional[pulumi.Input[bool]] = None,
                 tags: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 taints: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigTaintArgs']]]] = None,
                 workload_metadata_config: Optional[pulumi.Input['NodePoolNodeConfigWorkloadMetadataConfigArgs']] = None):
        """
        :param pulumi.Input['NodePoolNodeConfigConfidentialNodesArgs'] confidential_nodes: Configuration for Confidential Nodes feature. Structure is documented below.
        """
        if advanced_machine_features is not None:
            pulumi.set(__self__, "advanced_machine_features", advanced_machine_features)
        if boot_disk_kms_key is not None:
            pulumi.set(__self__, "boot_disk_kms_key", boot_disk_kms_key)
        if confidential_nodes is not None:
            pulumi.set(__self__, "confidential_nodes", confidential_nodes)
        if disk_size_gb is not None:
            pulumi.set(__self__, "disk_size_gb", disk_size_gb)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)
        if ephemeral_storage_config is not None:
            pulumi.set(__self__, "ephemeral_storage_config", ephemeral_storage_config)
        if ephemeral_storage_local_ssd_config is not None:
            pulumi.set(__self__, "ephemeral_storage_local_ssd_config", ephemeral_storage_local_ssd_config)
        if fast_socket is not None:
            pulumi.set(__self__, "fast_socket", fast_socket)
        if gcfs_config is not None:
            pulumi.set(__self__, "gcfs_config", gcfs_config)
        if guest_accelerators is not None:
            pulumi.set(__self__, "guest_accelerators", guest_accelerators)
        if gvnic is not None:
            pulumi.set(__self__, "gvnic", gvnic)
        if host_maintenance_policy is not None:
            pulumi.set(__self__, "host_maintenance_policy", host_maintenance_policy)
        if image_type is not None:
            pulumi.set(__self__, "image_type", image_type)
        if kubelet_config is not None:
            pulumi.set(__self__, "kubelet_config", kubelet_config)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if linux_node_config is not None:
            pulumi.set(__self__, "linux_node_config", linux_node_config)
        if local_nvme_ssd_block_config is not None:
            pulumi.set(__self__, "local_nvme_ssd_block_config", local_nvme_ssd_block_config)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if logging_variant is not None:
            pulumi.set(__self__, "logging_variant", logging_variant)
        if machine_type is not None:
            pulumi.set(__self__, "machine_type", machine_type)
        if metadata is not None:
            pulumi.set(__self__, "metadata", metadata)
        if min_cpu_platform is not None:
            pulumi.set(__self__, "min_cpu_platform", min_cpu_platform)
        if node_group is not None:
            pulumi.set(__self__, "node_group", node_group)
        if oauth_scopes is not None:
            pulumi.set(__self__, "oauth_scopes", oauth_scopes)
        if preemptible is not None:
            pulumi.set(__self__, "preemptible", preemptible)
        if reservation_affinity is not None:
            pulumi.set(__self__, "reservation_affinity", reservation_affinity)
        if resource_labels is not None:
            pulumi.set(__self__, "resource_labels", resource_labels)
        if sandbox_config is not None:
            pulumi.set(__self__, "sandbox_config", sandbox_config)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if shielded_instance_config is not None:
            pulumi.set(__self__, "shielded_instance_config", shielded_instance_config)
        if sole_tenant_config is not None:
            pulumi.set(__self__, "sole_tenant_config", sole_tenant_config)
        if spot is not None:
            pulumi.set(__self__, "spot", spot)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if taints is not None:
            pulumi.set(__self__, "taints", taints)
        if workload_metadata_config is not None:
            pulumi.set(__self__, "workload_metadata_config", workload_metadata_config)

    @property
    @pulumi.getter(name="advancedMachineFeatures")
    def advanced_machine_features(self) -> Optional[pulumi.Input['NodePoolNodeConfigAdvancedMachineFeaturesArgs']]:
        return pulumi.get(self, "advanced_machine_features")

    @advanced_machine_features.setter
    def advanced_machine_features(self, value: Optional[pulumi.Input['NodePoolNodeConfigAdvancedMachineFeaturesArgs']]):
        pulumi.set(self, "advanced_machine_features", value)

    @property
    @pulumi.getter(name="bootDiskKmsKey")
    def boot_disk_kms_key(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "boot_disk_kms_key")

    @boot_disk_kms_key.setter
    def boot_disk_kms_key(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "boot_disk_kms_key", value)

    @property
    @pulumi.getter(name="confidentialNodes")
    def confidential_nodes(self) -> Optional[pulumi.Input['NodePoolNodeConfigConfidentialNodesArgs']]:
        """
        Configuration for Confidential Nodes feature. Structure is documented below.
        """
        return pulumi.get(self, "confidential_nodes")

    @confidential_nodes.setter
    def confidential_nodes(self, value: Optional[pulumi.Input['NodePoolNodeConfigConfidentialNodesArgs']]):
        pulumi.set(self, "confidential_nodes", value)

    @property
    @pulumi.getter(name="diskSizeGb")
    def disk_size_gb(self) -> Optional[pulumi.Input[int]]:
        return pulumi.get(self, "disk_size_gb")

    @disk_size_gb.setter
    def disk_size_gb(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "disk_size_gb", value)

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "disk_type")

    @disk_type.setter
    def disk_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "disk_type", value)

    @property
    @pulumi.getter(name="ephemeralStorageConfig")
    def ephemeral_storage_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigEphemeralStorageConfigArgs']]:
        return pulumi.get(self, "ephemeral_storage_config")

    @ephemeral_storage_config.setter
    def ephemeral_storage_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigEphemeralStorageConfigArgs']]):
        pulumi.set(self, "ephemeral_storage_config", value)

    @property
    @pulumi.getter(name="ephemeralStorageLocalSsdConfig")
    def ephemeral_storage_local_ssd_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs']]:
        return pulumi.get(self, "ephemeral_storage_local_ssd_config")

    @ephemeral_storage_local_ssd_config.setter
    def ephemeral_storage_local_ssd_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs']]):
        pulumi.set(self, "ephemeral_storage_local_ssd_config", value)

    @property
    @pulumi.getter(name="fastSocket")
    def fast_socket(self) -> Optional[pulumi.Input['NodePoolNodeConfigFastSocketArgs']]:
        return pulumi.get(self, "fast_socket")

    @fast_socket.setter
    def fast_socket(self, value: Optional[pulumi.Input['NodePoolNodeConfigFastSocketArgs']]):
        pulumi.set(self, "fast_socket", value)

    @property
    @pulumi.getter(name="gcfsConfig")
    def gcfs_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigGcfsConfigArgs']]:
        return pulumi.get(self, "gcfs_config")

    @gcfs_config.setter
    def gcfs_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigGcfsConfigArgs']]):
        pulumi.set(self, "gcfs_config", value)

    @property
    @pulumi.getter(name="guestAccelerators")
    def guest_accelerators(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigGuestAcceleratorArgs']]]]:
        return pulumi.get(self, "guest_accelerators")

    @guest_accelerators.setter
    def guest_accelerators(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigGuestAcceleratorArgs']]]]):
        pulumi.set(self, "guest_accelerators", value)

    @property
    @pulumi.getter
    def gvnic(self) -> Optional[pulumi.Input['NodePoolNodeConfigGvnicArgs']]:
        return pulumi.get(self, "gvnic")

    @gvnic.setter
    def gvnic(self, value: Optional[pulumi.Input['NodePoolNodeConfigGvnicArgs']]):
        pulumi.set(self, "gvnic", value)

    @property
    @pulumi.getter(name="hostMaintenancePolicy")
    def host_maintenance_policy(self) -> Optional[pulumi.Input['NodePoolNodeConfigHostMaintenancePolicyArgs']]:
        return pulumi.get(self, "host_maintenance_policy")

    @host_maintenance_policy.setter
    def host_maintenance_policy(self, value: Optional[pulumi.Input['NodePoolNodeConfigHostMaintenancePolicyArgs']]):
        pulumi.set(self, "host_maintenance_policy", value)

    @property
    @pulumi.getter(name="imageType")
    def image_type(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "image_type")

    @image_type.setter
    def image_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "image_type", value)

    @property
    @pulumi.getter(name="kubeletConfig")
    def kubelet_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigKubeletConfigArgs']]:
        return pulumi.get(self, "kubelet_config")

    @kubelet_config.setter
    def kubelet_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigKubeletConfigArgs']]):
        pulumi.set(self, "kubelet_config", value)

    @property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "labels", value)

    @property
    @pulumi.getter(name="linuxNodeConfig")
    def linux_node_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigLinuxNodeConfigArgs']]:
        return pulumi.get(self, "linux_node_config")

    @linux_node_config.setter
    def linux_node_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigLinuxNodeConfigArgs']]):
        pulumi.set(self, "linux_node_config", value)

    @property
    @pulumi.getter(name="localNvmeSsdBlockConfig")
    def local_nvme_ssd_block_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs']]:
        return pulumi.get(self, "local_nvme_ssd_block_config")

    @local_nvme_ssd_block_config.setter
    def local_nvme_ssd_block_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs']]):
        pulumi.set(self, "local_nvme_ssd_block_config", value)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[pulumi.Input[int]]:
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "local_ssd_count", value)

    @property
    @pulumi.getter(name="loggingVariant")
    def logging_variant(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "logging_variant")

    @logging_variant.setter
    def logging_variant(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "logging_variant", value)

    @property
    @pulumi.getter(name="machineType")
    def machine_type(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "machine_type")

    @machine_type.setter
    def machine_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "machine_type", value)

    @property
    @pulumi.getter
    def metadata(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        return pulumi.get(self, "metadata")

    @metadata.setter
    def metadata(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "metadata", value)

    @property
    @pulumi.getter(name="minCpuPlatform")
    def min_cpu_platform(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "min_cpu_platform")

    @min_cpu_platform.setter
    def min_cpu_platform(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "min_cpu_platform", value)

    @property
    @pulumi.getter(name="nodeGroup")
    def node_group(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "node_group")

    @node_group.setter
    def node_group(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "node_group", value)

    @property
    @pulumi.getter(name="oauthScopes")
    def oauth_scopes(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        return pulumi.get(self, "oauth_scopes")

    @oauth_scopes.setter
    def oauth_scopes(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "oauth_scopes", value)

    @property
    @pulumi.getter
    def preemptible(self) -> Optional[pulumi.Input[bool]]:
        return pulumi.get(self, "preemptible")

    @preemptible.setter
    def preemptible(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "preemptible", value)

    @property
    @pulumi.getter(name="reservationAffinity")
    def reservation_affinity(self) -> Optional[pulumi.Input['NodePoolNodeConfigReservationAffinityArgs']]:
        return pulumi.get(self, "reservation_affinity")

    @reservation_affinity.setter
    def reservation_affinity(self, value: Optional[pulumi.Input['NodePoolNodeConfigReservationAffinityArgs']]):
        pulumi.set(self, "reservation_affinity", value)

    @property
    @pulumi.getter(name="resourceLabels")
    def resource_labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        return pulumi.get(self, "resource_labels")

    @resource_labels.setter
    def resource_labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "resource_labels", value)

    @property
    @pulumi.getter(name="sandboxConfig")
    def sandbox_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigSandboxConfigArgs']]:
        return pulumi.get(self, "sandbox_config")

    @sandbox_config.setter
    def sandbox_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigSandboxConfigArgs']]):
        pulumi.set(self, "sandbox_config", value)

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "service_account")

    @service_account.setter
    def service_account(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "service_account", value)

    @property
    @pulumi.getter(name="shieldedInstanceConfig")
    def shielded_instance_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigShieldedInstanceConfigArgs']]:
        return pulumi.get(self, "shielded_instance_config")

    @shielded_instance_config.setter
    def shielded_instance_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigShieldedInstanceConfigArgs']]):
        pulumi.set(self, "shielded_instance_config", value)

    @property
    @pulumi.getter(name="soleTenantConfig")
    def sole_tenant_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigSoleTenantConfigArgs']]:
        return pulumi.get(self, "sole_tenant_config")

    @sole_tenant_config.setter
    def sole_tenant_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigSoleTenantConfigArgs']]):
        pulumi.set(self, "sole_tenant_config", value)

    @property
    @pulumi.getter
    def spot(self) -> Optional[pulumi.Input[bool]]:
        return pulumi.get(self, "spot")

    @spot.setter
    def spot(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "spot", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter
    def taints(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigTaintArgs']]]]:
        return pulumi.get(self, "taints")

    @taints.setter
    def taints(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigTaintArgs']]]]):
        pulumi.set(self, "taints", value)

    @property
    @pulumi.getter(name="workloadMetadataConfig")
    def workload_metadata_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigWorkloadMetadataConfigArgs']]:
        return pulumi.get(self, "workload_metadata_config")

    @workload_metadata_config.setter
    def workload_metadata_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigWorkloadMetadataConfigArgs']]):
        pulumi.set(self, "workload_metadata_config", value)


@pulumi.input_type
class NodePoolNodeConfigAdvancedMachineFeaturesArgs:
    def __init__(__self__, *,
                 threads_per_core: pulumi.Input[int]):
        pulumi.set(__self__, "threads_per_core", threads_per_core)

    @property
    @pulumi.getter(name="threadsPerCore")
    def threads_per_core(self) -> pulumi.Input[int]:
        return pulumi.get(self, "threads_per_core")

    @threads_per_core.setter
    def threads_per_core(self, value: pulumi.Input[int]):
        pulumi.set(self, "threads_per_core", value)


@pulumi.input_type
class NodePoolNodeConfigConfidentialNodesArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class NodePoolNodeConfigEphemeralStorageConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[int]):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[int]:
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "local_ssd_count", value)


@pulumi.input_type
class NodePoolNodeConfigEphemeralStorageLocalSsdConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[int]):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[int]:
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "local_ssd_count", value)


@pulumi.input_type
class NodePoolNodeConfigFastSocketArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class NodePoolNodeConfigGcfsConfigArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class NodePoolNodeConfigGuestAcceleratorArgs:
    def __init__(__self__, *,
                 count: pulumi.Input[int],
                 type: pulumi.Input[str],
                 gpu_driver_installation_config: Optional[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']] = None,
                 gpu_partition_size: Optional[pulumi.Input[str]] = None,
                 gpu_sharing_config: Optional[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs']] = None):
        """
        :param pulumi.Input[str] type: The type of the policy. Supports a single value: COMPACT.
               Specifying COMPACT placement policy type places node pool's nodes in a closer
               physical proximity in order to reduce network latency between nodes.
        """
        pulumi.set(__self__, "count", count)
        pulumi.set(__self__, "type", type)
        if gpu_driver_installation_config is not None:
            pulumi.set(__self__, "gpu_driver_installation_config", gpu_driver_installation_config)
        if gpu_partition_size is not None:
            pulumi.set(__self__, "gpu_partition_size", gpu_partition_size)
        if gpu_sharing_config is not None:
            pulumi.set(__self__, "gpu_sharing_config", gpu_sharing_config)

    @property
    @pulumi.getter
    def count(self) -> pulumi.Input[int]:
        return pulumi.get(self, "count")

    @count.setter
    def count(self, value: pulumi.Input[int]):
        pulumi.set(self, "count", value)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input[str]:
        """
        The type of the policy. Supports a single value: COMPACT.
        Specifying COMPACT placement policy type places node pool's nodes in a closer
        physical proximity in order to reduce network latency between nodes.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[str]):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter(name="gpuDriverInstallationConfig")
    def gpu_driver_installation_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']]:
        return pulumi.get(self, "gpu_driver_installation_config")

    @gpu_driver_installation_config.setter
    def gpu_driver_installation_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs']]):
        pulumi.set(self, "gpu_driver_installation_config", value)

    @property
    @pulumi.getter(name="gpuPartitionSize")
    def gpu_partition_size(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "gpu_partition_size")

    @gpu_partition_size.setter
    def gpu_partition_size(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "gpu_partition_size", value)

    @property
    @pulumi.getter(name="gpuSharingConfig")
    def gpu_sharing_config(self) -> Optional[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs']]:
        return pulumi.get(self, "gpu_sharing_config")

    @gpu_sharing_config.setter
    def gpu_sharing_config(self, value: Optional[pulumi.Input['NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs']]):
        pulumi.set(self, "gpu_sharing_config", value)


@pulumi.input_type
class NodePoolNodeConfigGuestAcceleratorGpuDriverInstallationConfigArgs:
    def __init__(__self__, *,
                 gpu_driver_version: pulumi.Input[str]):
        pulumi.set(__self__, "gpu_driver_version", gpu_driver_version)

    @property
    @pulumi.getter(name="gpuDriverVersion")
    def gpu_driver_version(self) -> pulumi.Input[str]:
        return pulumi.get(self, "gpu_driver_version")

    @gpu_driver_version.setter
    def gpu_driver_version(self, value: pulumi.Input[str]):
        pulumi.set(self, "gpu_driver_version", value)


@pulumi.input_type
class NodePoolNodeConfigGuestAcceleratorGpuSharingConfigArgs:
    def __init__(__self__, *,
                 gpu_sharing_strategy: pulumi.Input[str],
                 max_shared_clients_per_gpu: pulumi.Input[int]):
        pulumi.set(__self__, "gpu_sharing_strategy", gpu_sharing_strategy)
        pulumi.set(__self__, "max_shared_clients_per_gpu", max_shared_clients_per_gpu)

    @property
    @pulumi.getter(name="gpuSharingStrategy")
    def gpu_sharing_strategy(self) -> pulumi.Input[str]:
        return pulumi.get(self, "gpu_sharing_strategy")

    @gpu_sharing_strategy.setter
    def gpu_sharing_strategy(self, value: pulumi.Input[str]):
        pulumi.set(self, "gpu_sharing_strategy", value)

    @property
    @pulumi.getter(name="maxSharedClientsPerGpu")
    def max_shared_clients_per_gpu(self) -> pulumi.Input[int]:
        return pulumi.get(self, "max_shared_clients_per_gpu")

    @max_shared_clients_per_gpu.setter
    def max_shared_clients_per_gpu(self, value: pulumi.Input[int]):
        pulumi.set(self, "max_shared_clients_per_gpu", value)


@pulumi.input_type
class NodePoolNodeConfigGvnicArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[bool]):
        """
        :param pulumi.Input[bool] enabled: Enable Confidential GKE Nodes for this cluster, to
               enforce encryption of data in-use.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[bool]:
        """
        Enable Confidential GKE Nodes for this cluster, to
        enforce encryption of data in-use.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[bool]):
        pulumi.set(self, "enabled", value)


@pulumi.input_type
class NodePoolNodeConfigHostMaintenancePolicyArgs:
    def __init__(__self__, *,
                 maintenance_interval: pulumi.Input[str]):
        pulumi.set(__self__, "maintenance_interval", maintenance_interval)

    @property
    @pulumi.getter(name="maintenanceInterval")
    def maintenance_interval(self) -> pulumi.Input[str]:
        return pulumi.get(self, "maintenance_interval")

    @maintenance_interval.setter
    def maintenance_interval(self, value: pulumi.Input[str]):
        pulumi.set(self, "maintenance_interval", value)


@pulumi.input_type
class NodePoolNodeConfigKubeletConfigArgs:
    def __init__(__self__, *,
                 cpu_manager_policy: pulumi.Input[str],
                 cpu_cfs_quota: Optional[pulumi.Input[bool]] = None,
                 cpu_cfs_quota_period: Optional[pulumi.Input[str]] = None,
                 pod_pids_limit: Optional[pulumi.Input[int]] = None):
        pulumi.set(__self__, "cpu_manager_policy", cpu_manager_policy)
        if cpu_cfs_quota is not None:
            pulumi.set(__self__, "cpu_cfs_quota", cpu_cfs_quota)
        if cpu_cfs_quota_period is not None:
            pulumi.set(__self__, "cpu_cfs_quota_period", cpu_cfs_quota_period)
        if pod_pids_limit is not None:
            pulumi.set(__self__, "pod_pids_limit", pod_pids_limit)

    @property
    @pulumi.getter(name="cpuManagerPolicy")
    def cpu_manager_policy(self) -> pulumi.Input[str]:
        return pulumi.get(self, "cpu_manager_policy")

    @cpu_manager_policy.setter
    def cpu_manager_policy(self, value: pulumi.Input[str]):
        pulumi.set(self, "cpu_manager_policy", value)

    @property
    @pulumi.getter(name="cpuCfsQuota")
    def cpu_cfs_quota(self) -> Optional[pulumi.Input[bool]]:
        return pulumi.get(self, "cpu_cfs_quota")

    @cpu_cfs_quota.setter
    def cpu_cfs_quota(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "cpu_cfs_quota", value)

    @property
    @pulumi.getter(name="cpuCfsQuotaPeriod")
    def cpu_cfs_quota_period(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "cpu_cfs_quota_period")

    @cpu_cfs_quota_period.setter
    def cpu_cfs_quota_period(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "cpu_cfs_quota_period", value)

    @property
    @pulumi.getter(name="podPidsLimit")
    def pod_pids_limit(self) -> Optional[pulumi.Input[int]]:
        return pulumi.get(self, "pod_pids_limit")

    @pod_pids_limit.setter
    def pod_pids_limit(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "pod_pids_limit", value)


@pulumi.input_type
class NodePoolNodeConfigLinuxNodeConfigArgs:
    def __init__(__self__, *,
                 sysctls: pulumi.Input[Mapping[str, pulumi.Input[str]]]):
        pulumi.set(__self__, "sysctls", sysctls)

    @property
    @pulumi.getter
    def sysctls(self) -> pulumi.Input[Mapping[str, pulumi.Input[str]]]:
        return pulumi.get(self, "sysctls")

    @sysctls.setter
    def sysctls(self, value: pulumi.Input[Mapping[str, pulumi.Input[str]]]):
        pulumi.set(self, "sysctls", value)


@pulumi.input_type
class NodePoolNodeConfigLocalNvmeSsdBlockConfigArgs:
    def __init__(__self__, *,
                 local_ssd_count: pulumi.Input[int]):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> pulumi.Input[int]:
        return pulumi.get(self, "local_ssd_count")

    @local_ssd_count.setter
    def local_ssd_count(self, value: pulumi.Input[int]):
        pulumi.set(self, "local_ssd_count", value)


@pulumi.input_type
class NodePoolNodeConfigReservationAffinityArgs:
    def __init__(__self__, *,
                 consume_reservation_type: pulumi.Input[str],
                 key: Optional[pulumi.Input[str]] = None,
                 values: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        pulumi.set(__self__, "consume_reservation_type", consume_reservation_type)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="consumeReservationType")
    def consume_reservation_type(self) -> pulumi.Input[str]:
        return pulumi.get(self, "consume_reservation_type")

    @consume_reservation_type.setter
    def consume_reservation_type(self, value: pulumi.Input[str]):
        pulumi.set(self, "consume_reservation_type", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[pulumi.Input[str]]:
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "values", value)


@pulumi.input_type
class NodePoolNodeConfigSandboxConfigArgs:
    def __init__(__self__, *,
                 sandbox_type: pulumi.Input[str]):
        pulumi.set(__self__, "sandbox_type", sandbox_type)

    @property
    @pulumi.getter(name="sandboxType")
    def sandbox_type(self) -> pulumi.Input[str]:
        return pulumi.get(self, "sandbox_type")

    @sandbox_type.setter
    def sandbox_type(self, value: pulumi.Input[str]):
        pulumi.set(self, "sandbox_type", value)


@pulumi.input_type
class NodePoolNodeConfigShieldedInstanceConfigArgs:
    def __init__(__self__, *,
                 enable_integrity_monitoring: Optional[pulumi.Input[bool]] = None,
                 enable_secure_boot: Optional[pulumi.Input[bool]] = None):
        if enable_integrity_monitoring is not None:
            pulumi.set(__self__, "enable_integrity_monitoring", enable_integrity_monitoring)
        if enable_secure_boot is not None:
            pulumi.set(__self__, "enable_secure_boot", enable_secure_boot)

    @property
    @pulumi.getter(name="enableIntegrityMonitoring")
    def enable_integrity_monitoring(self) -> Optional[pulumi.Input[bool]]:
        return pulumi.get(self, "enable_integrity_monitoring")

    @enable_integrity_monitoring.setter
    def enable_integrity_monitoring(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_integrity_monitoring", value)

    @property
    @pulumi.getter(name="enableSecureBoot")
    def enable_secure_boot(self) -> Optional[pulumi.Input[bool]]:
        return pulumi.get(self, "enable_secure_boot")

    @enable_secure_boot.setter
    def enable_secure_boot(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_secure_boot", value)


@pulumi.input_type
class NodePoolNodeConfigSoleTenantConfigArgs:
    def __init__(__self__, *,
                 node_affinities: pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]]):
        pulumi.set(__self__, "node_affinities", node_affinities)

    @property
    @pulumi.getter(name="nodeAffinities")
    def node_affinities(self) -> pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]]:
        return pulumi.get(self, "node_affinities")

    @node_affinities.setter
    def node_affinities(self, value: pulumi.Input[Sequence[pulumi.Input['NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs']]]):
        pulumi.set(self, "node_affinities", value)


@pulumi.input_type
class NodePoolNodeConfigSoleTenantConfigNodeAffinityArgs:
    def __init__(__self__, *,
                 key: pulumi.Input[str],
                 operator: pulumi.Input[str],
                 values: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "operator", operator)
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[str]:
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def operator(self) -> pulumi.Input[str]:
        return pulumi.get(self, "operator")

    @operator.setter
    def operator(self, value: pulumi.Input[str]):
        pulumi.set(self, "operator", value)

    @property
    @pulumi.getter
    def values(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "values", value)


@pulumi.input_type
class NodePoolNodeConfigTaintArgs:
    def __init__(__self__, *,
                 effect: pulumi.Input[str],
                 key: pulumi.Input[str],
                 value: pulumi.Input[str]):
        pulumi.set(__self__, "effect", effect)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def effect(self) -> pulumi.Input[str]:
        return pulumi.get(self, "effect")

    @effect.setter
    def effect(self, value: pulumi.Input[str]):
        pulumi.set(self, "effect", value)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[str]:
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[str]:
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[str]):
        pulumi.set(self, "value", value)


@pulumi.input_type
class NodePoolNodeConfigWorkloadMetadataConfigArgs:
    def __init__(__self__, *,
                 mode: pulumi.Input[str]):
        pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter
    def mode(self) -> pulumi.Input[str]:
        return pulumi.get(self, "mode")

    @mode.setter
    def mode(self, value: pulumi.Input[str]):
        pulumi.set(self, "mode", value)


@pulumi.input_type
class NodePoolPlacementPolicyArgs:
    def __init__(__self__, *,
                 type: pulumi.Input[str],
                 policy_name: Optional[pulumi.Input[str]] = None,
                 tpu_topology: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] type: The type of the policy. Supports a single value: COMPACT.
               Specifying COMPACT placement policy type places node pool's nodes in a closer
               physical proximity in order to reduce network latency between nodes.
        :param pulumi.Input[str] policy_name: If set, refers to the name of a custom resource policy supplied by the user.
               The resource policy must be in the same project and region as the node pool.
               If not found, InvalidArgument error is returned.
        :param pulumi.Input[str] tpu_topology: The [TPU placement topology](https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies) for pod slice node pool.
        """
        pulumi.set(__self__, "type", type)
        if policy_name is not None:
            pulumi.set(__self__, "policy_name", policy_name)
        if tpu_topology is not None:
            pulumi.set(__self__, "tpu_topology", tpu_topology)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input[str]:
        """
        The type of the policy. Supports a single value: COMPACT.
        Specifying COMPACT placement policy type places node pool's nodes in a closer
        physical proximity in order to reduce network latency between nodes.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[str]):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter(name="policyName")
    def policy_name(self) -> Optional[pulumi.Input[str]]:
        """
        If set, refers to the name of a custom resource policy supplied by the user.
        The resource policy must be in the same project and region as the node pool.
        If not found, InvalidArgument error is returned.
        """
        return pulumi.get(self, "policy_name")

    @policy_name.setter
    def policy_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "policy_name", value)

    @property
    @pulumi.getter(name="tpuTopology")
    def tpu_topology(self) -> Optional[pulumi.Input[str]]:
        """
        The [TPU placement topology](https://cloud.google.com/tpu/docs/types-topologies#tpu_topologies) for pod slice node pool.
        """
        return pulumi.get(self, "tpu_topology")

    @tpu_topology.setter
    def tpu_topology(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "tpu_topology", value)


@pulumi.input_type
class NodePoolUpgradeSettingsArgs:
    def __init__(__self__, *,
                 blue_green_settings: Optional[pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsArgs']] = None,
                 max_surge: Optional[pulumi.Input[int]] = None,
                 max_unavailable: Optional[pulumi.Input[int]] = None,
                 strategy: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsArgs'] blue_green_settings: The settings to adjust [blue green upgrades](https://cloud.google.com/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy).
               Structure is documented below
        :param pulumi.Input[int] max_surge: The number of additional nodes that can be added to the node pool during
               an upgrade. Increasing `max_surge` raises the number of nodes that can be upgraded simultaneously.
               Can be set to 0 or greater.
        :param pulumi.Input[int] max_unavailable: The number of nodes that can be simultaneously unavailable during
               an upgrade. Increasing `max_unavailable` raises the number of nodes that can be upgraded in
               parallel. Can be set to 0 or greater.
               
               `max_surge` and `max_unavailable` must not be negative and at least one of them must be greater than zero.
        :param pulumi.Input[str] strategy: The upgrade stragey to be used for upgrading the nodes.
        """
        if blue_green_settings is not None:
            pulumi.set(__self__, "blue_green_settings", blue_green_settings)
        if max_surge is not None:
            pulumi.set(__self__, "max_surge", max_surge)
        if max_unavailable is not None:
            pulumi.set(__self__, "max_unavailable", max_unavailable)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @property
    @pulumi.getter(name="blueGreenSettings")
    def blue_green_settings(self) -> Optional[pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsArgs']]:
        """
        The settings to adjust [blue green upgrades](https://cloud.google.com/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy).
        Structure is documented below
        """
        return pulumi.get(self, "blue_green_settings")

    @blue_green_settings.setter
    def blue_green_settings(self, value: Optional[pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsArgs']]):
        pulumi.set(self, "blue_green_settings", value)

    @property
    @pulumi.getter(name="maxSurge")
    def max_surge(self) -> Optional[pulumi.Input[int]]:
        """
        The number of additional nodes that can be added to the node pool during
        an upgrade. Increasing `max_surge` raises the number of nodes that can be upgraded simultaneously.
        Can be set to 0 or greater.
        """
        return pulumi.get(self, "max_surge")

    @max_surge.setter
    def max_surge(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_surge", value)

    @property
    @pulumi.getter(name="maxUnavailable")
    def max_unavailable(self) -> Optional[pulumi.Input[int]]:
        """
        The number of nodes that can be simultaneously unavailable during
        an upgrade. Increasing `max_unavailable` raises the number of nodes that can be upgraded in
        parallel. Can be set to 0 or greater.

        `max_surge` and `max_unavailable` must not be negative and at least one of them must be greater than zero.
        """
        return pulumi.get(self, "max_unavailable")

    @max_unavailable.setter
    def max_unavailable(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_unavailable", value)

    @property
    @pulumi.getter
    def strategy(self) -> Optional[pulumi.Input[str]]:
        """
        The upgrade stragey to be used for upgrading the nodes.
        """
        return pulumi.get(self, "strategy")

    @strategy.setter
    def strategy(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "strategy", value)


@pulumi.input_type
class NodePoolUpgradeSettingsBlueGreenSettingsArgs:
    def __init__(__self__, *,
                 standard_rollout_policy: pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs'],
                 node_pool_soak_duration: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs'] standard_rollout_policy: Specifies the standard policy settings for blue-green upgrades.
        :param pulumi.Input[str] node_pool_soak_duration: Time needed after draining the entire blue pool.
               After this period, the blue pool will be cleaned up.
        """
        pulumi.set(__self__, "standard_rollout_policy", standard_rollout_policy)
        if node_pool_soak_duration is not None:
            pulumi.set(__self__, "node_pool_soak_duration", node_pool_soak_duration)

    @property
    @pulumi.getter(name="standardRolloutPolicy")
    def standard_rollout_policy(self) -> pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']:
        """
        Specifies the standard policy settings for blue-green upgrades.
        """
        return pulumi.get(self, "standard_rollout_policy")

    @standard_rollout_policy.setter
    def standard_rollout_policy(self, value: pulumi.Input['NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs']):
        pulumi.set(self, "standard_rollout_policy", value)

    @property
    @pulumi.getter(name="nodePoolSoakDuration")
    def node_pool_soak_duration(self) -> Optional[pulumi.Input[str]]:
        """
        Time needed after draining the entire blue pool.
        After this period, the blue pool will be cleaned up.
        """
        return pulumi.get(self, "node_pool_soak_duration")

    @node_pool_soak_duration.setter
    def node_pool_soak_duration(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "node_pool_soak_duration", value)


@pulumi.input_type
class NodePoolUpgradeSettingsBlueGreenSettingsStandardRolloutPolicyArgs:
    def __init__(__self__, *,
                 batch_node_count: Optional[pulumi.Input[int]] = None,
                 batch_percentage: Optional[pulumi.Input[float]] = None,
                 batch_soak_duration: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[int] batch_node_count: Number of blue nodes to drain in a batch.
        :param pulumi.Input[float] batch_percentage: Percentage of the blue pool nodes to drain in a batch.
        :param pulumi.Input[str] batch_soak_duration: Soak time after each batch gets drained.
        """
        if batch_node_count is not None:
            pulumi.set(__self__, "batch_node_count", batch_node_count)
        if batch_percentage is not None:
            pulumi.set(__self__, "batch_percentage", batch_percentage)
        if batch_soak_duration is not None:
            pulumi.set(__self__, "batch_soak_duration", batch_soak_duration)

    @property
    @pulumi.getter(name="batchNodeCount")
    def batch_node_count(self) -> Optional[pulumi.Input[int]]:
        """
        Number of blue nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_node_count")

    @batch_node_count.setter
    def batch_node_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "batch_node_count", value)

    @property
    @pulumi.getter(name="batchPercentage")
    def batch_percentage(self) -> Optional[pulumi.Input[float]]:
        """
        Percentage of the blue pool nodes to drain in a batch.
        """
        return pulumi.get(self, "batch_percentage")

    @batch_percentage.setter
    def batch_percentage(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "batch_percentage", value)

    @property
    @pulumi.getter(name="batchSoakDuration")
    def batch_soak_duration(self) -> Optional[pulumi.Input[str]]:
        """
        Soak time after each batch gets drained.
        """
        return pulumi.get(self, "batch_soak_duration")

    @batch_soak_duration.setter
    def batch_soak_duration(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "batch_soak_duration", value)


