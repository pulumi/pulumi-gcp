// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package bigquery

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi/sdk/v2/go/pulumi"
)

type AppProfileSingleClusterRouting struct {
	// If true, CheckAndMutateRow and ReadModifyWriteRow requests are allowed by this app profile.
	// It is unsafe to send these requests to the same table/row/column in multiple clusters.
	AllowTransactionalWrites *bool `pulumi:"allowTransactionalWrites"`
	// The cluster to which read/write requests should be routed.
	ClusterId string `pulumi:"clusterId"`
}

// AppProfileSingleClusterRoutingInput is an input type that accepts AppProfileSingleClusterRoutingArgs and AppProfileSingleClusterRoutingOutput values.
// You can construct a concrete instance of `AppProfileSingleClusterRoutingInput` via:
//
// 		 AppProfileSingleClusterRoutingArgs{...}
//
type AppProfileSingleClusterRoutingInput interface {
	pulumi.Input

	ToAppProfileSingleClusterRoutingOutput() AppProfileSingleClusterRoutingOutput
	ToAppProfileSingleClusterRoutingOutputWithContext(context.Context) AppProfileSingleClusterRoutingOutput
}

type AppProfileSingleClusterRoutingArgs struct {
	// If true, CheckAndMutateRow and ReadModifyWriteRow requests are allowed by this app profile.
	// It is unsafe to send these requests to the same table/row/column in multiple clusters.
	AllowTransactionalWrites pulumi.BoolPtrInput `pulumi:"allowTransactionalWrites"`
	// The cluster to which read/write requests should be routed.
	ClusterId pulumi.StringInput `pulumi:"clusterId"`
}

func (AppProfileSingleClusterRoutingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AppProfileSingleClusterRouting)(nil)).Elem()
}

func (i AppProfileSingleClusterRoutingArgs) ToAppProfileSingleClusterRoutingOutput() AppProfileSingleClusterRoutingOutput {
	return i.ToAppProfileSingleClusterRoutingOutputWithContext(context.Background())
}

func (i AppProfileSingleClusterRoutingArgs) ToAppProfileSingleClusterRoutingOutputWithContext(ctx context.Context) AppProfileSingleClusterRoutingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AppProfileSingleClusterRoutingOutput)
}

func (i AppProfileSingleClusterRoutingArgs) ToAppProfileSingleClusterRoutingPtrOutput() AppProfileSingleClusterRoutingPtrOutput {
	return i.ToAppProfileSingleClusterRoutingPtrOutputWithContext(context.Background())
}

func (i AppProfileSingleClusterRoutingArgs) ToAppProfileSingleClusterRoutingPtrOutputWithContext(ctx context.Context) AppProfileSingleClusterRoutingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AppProfileSingleClusterRoutingOutput).ToAppProfileSingleClusterRoutingPtrOutputWithContext(ctx)
}

// AppProfileSingleClusterRoutingPtrInput is an input type that accepts AppProfileSingleClusterRoutingArgs, AppProfileSingleClusterRoutingPtr and AppProfileSingleClusterRoutingPtrOutput values.
// You can construct a concrete instance of `AppProfileSingleClusterRoutingPtrInput` via:
//
// 		 AppProfileSingleClusterRoutingArgs{...}
//
//  or:
//
// 		 nil
//
type AppProfileSingleClusterRoutingPtrInput interface {
	pulumi.Input

	ToAppProfileSingleClusterRoutingPtrOutput() AppProfileSingleClusterRoutingPtrOutput
	ToAppProfileSingleClusterRoutingPtrOutputWithContext(context.Context) AppProfileSingleClusterRoutingPtrOutput
}

type appProfileSingleClusterRoutingPtrType AppProfileSingleClusterRoutingArgs

func AppProfileSingleClusterRoutingPtr(v *AppProfileSingleClusterRoutingArgs) AppProfileSingleClusterRoutingPtrInput {
	return (*appProfileSingleClusterRoutingPtrType)(v)
}

func (*appProfileSingleClusterRoutingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AppProfileSingleClusterRouting)(nil)).Elem()
}

func (i *appProfileSingleClusterRoutingPtrType) ToAppProfileSingleClusterRoutingPtrOutput() AppProfileSingleClusterRoutingPtrOutput {
	return i.ToAppProfileSingleClusterRoutingPtrOutputWithContext(context.Background())
}

func (i *appProfileSingleClusterRoutingPtrType) ToAppProfileSingleClusterRoutingPtrOutputWithContext(ctx context.Context) AppProfileSingleClusterRoutingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AppProfileSingleClusterRoutingPtrOutput)
}

type AppProfileSingleClusterRoutingOutput struct{ *pulumi.OutputState }

func (AppProfileSingleClusterRoutingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AppProfileSingleClusterRouting)(nil)).Elem()
}

func (o AppProfileSingleClusterRoutingOutput) ToAppProfileSingleClusterRoutingOutput() AppProfileSingleClusterRoutingOutput {
	return o
}

func (o AppProfileSingleClusterRoutingOutput) ToAppProfileSingleClusterRoutingOutputWithContext(ctx context.Context) AppProfileSingleClusterRoutingOutput {
	return o
}

func (o AppProfileSingleClusterRoutingOutput) ToAppProfileSingleClusterRoutingPtrOutput() AppProfileSingleClusterRoutingPtrOutput {
	return o.ToAppProfileSingleClusterRoutingPtrOutputWithContext(context.Background())
}

func (o AppProfileSingleClusterRoutingOutput) ToAppProfileSingleClusterRoutingPtrOutputWithContext(ctx context.Context) AppProfileSingleClusterRoutingPtrOutput {
	return o.ApplyT(func(v AppProfileSingleClusterRouting) *AppProfileSingleClusterRouting {
		return &v
	}).(AppProfileSingleClusterRoutingPtrOutput)
}

// If true, CheckAndMutateRow and ReadModifyWriteRow requests are allowed by this app profile.
// It is unsafe to send these requests to the same table/row/column in multiple clusters.
func (o AppProfileSingleClusterRoutingOutput) AllowTransactionalWrites() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AppProfileSingleClusterRouting) *bool { return v.AllowTransactionalWrites }).(pulumi.BoolPtrOutput)
}

// The cluster to which read/write requests should be routed.
func (o AppProfileSingleClusterRoutingOutput) ClusterId() pulumi.StringOutput {
	return o.ApplyT(func(v AppProfileSingleClusterRouting) string { return v.ClusterId }).(pulumi.StringOutput)
}

type AppProfileSingleClusterRoutingPtrOutput struct{ *pulumi.OutputState }

func (AppProfileSingleClusterRoutingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AppProfileSingleClusterRouting)(nil)).Elem()
}

func (o AppProfileSingleClusterRoutingPtrOutput) ToAppProfileSingleClusterRoutingPtrOutput() AppProfileSingleClusterRoutingPtrOutput {
	return o
}

func (o AppProfileSingleClusterRoutingPtrOutput) ToAppProfileSingleClusterRoutingPtrOutputWithContext(ctx context.Context) AppProfileSingleClusterRoutingPtrOutput {
	return o
}

func (o AppProfileSingleClusterRoutingPtrOutput) Elem() AppProfileSingleClusterRoutingOutput {
	return o.ApplyT(func(v *AppProfileSingleClusterRouting) AppProfileSingleClusterRouting { return *v }).(AppProfileSingleClusterRoutingOutput)
}

// If true, CheckAndMutateRow and ReadModifyWriteRow requests are allowed by this app profile.
// It is unsafe to send these requests to the same table/row/column in multiple clusters.
func (o AppProfileSingleClusterRoutingPtrOutput) AllowTransactionalWrites() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AppProfileSingleClusterRouting) *bool {
		if v == nil {
			return nil
		}
		return v.AllowTransactionalWrites
	}).(pulumi.BoolPtrOutput)
}

// The cluster to which read/write requests should be routed.
func (o AppProfileSingleClusterRoutingPtrOutput) ClusterId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AppProfileSingleClusterRouting) *string {
		if v == nil {
			return nil
		}
		return &v.ClusterId
	}).(pulumi.StringPtrOutput)
}

type ConnectionCloudSql struct {
	// Cloud SQL properties.
	// Structure is documented below.
	Credential ConnectionCloudSqlCredential `pulumi:"credential"`
	// Database name.
	Database string `pulumi:"database"`
	// Cloud SQL instance ID in the form project:location:instance.
	InstanceId string `pulumi:"instanceId"`
	// Type of the Cloud SQL database.
	// Possible values are `DATABASE_TYPE_UNSPECIFIED`, `POSTGRES`, and `MYSQL`.
	Type string `pulumi:"type"`
}

// ConnectionCloudSqlInput is an input type that accepts ConnectionCloudSqlArgs and ConnectionCloudSqlOutput values.
// You can construct a concrete instance of `ConnectionCloudSqlInput` via:
//
// 		 ConnectionCloudSqlArgs{...}
//
type ConnectionCloudSqlInput interface {
	pulumi.Input

	ToConnectionCloudSqlOutput() ConnectionCloudSqlOutput
	ToConnectionCloudSqlOutputWithContext(context.Context) ConnectionCloudSqlOutput
}

type ConnectionCloudSqlArgs struct {
	// Cloud SQL properties.
	// Structure is documented below.
	Credential ConnectionCloudSqlCredentialInput `pulumi:"credential"`
	// Database name.
	Database pulumi.StringInput `pulumi:"database"`
	// Cloud SQL instance ID in the form project:location:instance.
	InstanceId pulumi.StringInput `pulumi:"instanceId"`
	// Type of the Cloud SQL database.
	// Possible values are `DATABASE_TYPE_UNSPECIFIED`, `POSTGRES`, and `MYSQL`.
	Type pulumi.StringInput `pulumi:"type"`
}

func (ConnectionCloudSqlArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ConnectionCloudSql)(nil)).Elem()
}

func (i ConnectionCloudSqlArgs) ToConnectionCloudSqlOutput() ConnectionCloudSqlOutput {
	return i.ToConnectionCloudSqlOutputWithContext(context.Background())
}

func (i ConnectionCloudSqlArgs) ToConnectionCloudSqlOutputWithContext(ctx context.Context) ConnectionCloudSqlOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ConnectionCloudSqlOutput)
}

func (i ConnectionCloudSqlArgs) ToConnectionCloudSqlPtrOutput() ConnectionCloudSqlPtrOutput {
	return i.ToConnectionCloudSqlPtrOutputWithContext(context.Background())
}

func (i ConnectionCloudSqlArgs) ToConnectionCloudSqlPtrOutputWithContext(ctx context.Context) ConnectionCloudSqlPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ConnectionCloudSqlOutput).ToConnectionCloudSqlPtrOutputWithContext(ctx)
}

// ConnectionCloudSqlPtrInput is an input type that accepts ConnectionCloudSqlArgs, ConnectionCloudSqlPtr and ConnectionCloudSqlPtrOutput values.
// You can construct a concrete instance of `ConnectionCloudSqlPtrInput` via:
//
// 		 ConnectionCloudSqlArgs{...}
//
//  or:
//
// 		 nil
//
type ConnectionCloudSqlPtrInput interface {
	pulumi.Input

	ToConnectionCloudSqlPtrOutput() ConnectionCloudSqlPtrOutput
	ToConnectionCloudSqlPtrOutputWithContext(context.Context) ConnectionCloudSqlPtrOutput
}

type connectionCloudSqlPtrType ConnectionCloudSqlArgs

func ConnectionCloudSqlPtr(v *ConnectionCloudSqlArgs) ConnectionCloudSqlPtrInput {
	return (*connectionCloudSqlPtrType)(v)
}

func (*connectionCloudSqlPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ConnectionCloudSql)(nil)).Elem()
}

func (i *connectionCloudSqlPtrType) ToConnectionCloudSqlPtrOutput() ConnectionCloudSqlPtrOutput {
	return i.ToConnectionCloudSqlPtrOutputWithContext(context.Background())
}

func (i *connectionCloudSqlPtrType) ToConnectionCloudSqlPtrOutputWithContext(ctx context.Context) ConnectionCloudSqlPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ConnectionCloudSqlPtrOutput)
}

type ConnectionCloudSqlOutput struct{ *pulumi.OutputState }

func (ConnectionCloudSqlOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ConnectionCloudSql)(nil)).Elem()
}

func (o ConnectionCloudSqlOutput) ToConnectionCloudSqlOutput() ConnectionCloudSqlOutput {
	return o
}

func (o ConnectionCloudSqlOutput) ToConnectionCloudSqlOutputWithContext(ctx context.Context) ConnectionCloudSqlOutput {
	return o
}

func (o ConnectionCloudSqlOutput) ToConnectionCloudSqlPtrOutput() ConnectionCloudSqlPtrOutput {
	return o.ToConnectionCloudSqlPtrOutputWithContext(context.Background())
}

func (o ConnectionCloudSqlOutput) ToConnectionCloudSqlPtrOutputWithContext(ctx context.Context) ConnectionCloudSqlPtrOutput {
	return o.ApplyT(func(v ConnectionCloudSql) *ConnectionCloudSql {
		return &v
	}).(ConnectionCloudSqlPtrOutput)
}

// Cloud SQL properties.
// Structure is documented below.
func (o ConnectionCloudSqlOutput) Credential() ConnectionCloudSqlCredentialOutput {
	return o.ApplyT(func(v ConnectionCloudSql) ConnectionCloudSqlCredential { return v.Credential }).(ConnectionCloudSqlCredentialOutput)
}

// Database name.
func (o ConnectionCloudSqlOutput) Database() pulumi.StringOutput {
	return o.ApplyT(func(v ConnectionCloudSql) string { return v.Database }).(pulumi.StringOutput)
}

// Cloud SQL instance ID in the form project:location:instance.
func (o ConnectionCloudSqlOutput) InstanceId() pulumi.StringOutput {
	return o.ApplyT(func(v ConnectionCloudSql) string { return v.InstanceId }).(pulumi.StringOutput)
}

// Type of the Cloud SQL database.
// Possible values are `DATABASE_TYPE_UNSPECIFIED`, `POSTGRES`, and `MYSQL`.
func (o ConnectionCloudSqlOutput) Type() pulumi.StringOutput {
	return o.ApplyT(func(v ConnectionCloudSql) string { return v.Type }).(pulumi.StringOutput)
}

type ConnectionCloudSqlPtrOutput struct{ *pulumi.OutputState }

func (ConnectionCloudSqlPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ConnectionCloudSql)(nil)).Elem()
}

func (o ConnectionCloudSqlPtrOutput) ToConnectionCloudSqlPtrOutput() ConnectionCloudSqlPtrOutput {
	return o
}

func (o ConnectionCloudSqlPtrOutput) ToConnectionCloudSqlPtrOutputWithContext(ctx context.Context) ConnectionCloudSqlPtrOutput {
	return o
}

func (o ConnectionCloudSqlPtrOutput) Elem() ConnectionCloudSqlOutput {
	return o.ApplyT(func(v *ConnectionCloudSql) ConnectionCloudSql { return *v }).(ConnectionCloudSqlOutput)
}

// Cloud SQL properties.
// Structure is documented below.
func (o ConnectionCloudSqlPtrOutput) Credential() ConnectionCloudSqlCredentialPtrOutput {
	return o.ApplyT(func(v *ConnectionCloudSql) *ConnectionCloudSqlCredential {
		if v == nil {
			return nil
		}
		return &v.Credential
	}).(ConnectionCloudSqlCredentialPtrOutput)
}

// Database name.
func (o ConnectionCloudSqlPtrOutput) Database() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ConnectionCloudSql) *string {
		if v == nil {
			return nil
		}
		return &v.Database
	}).(pulumi.StringPtrOutput)
}

// Cloud SQL instance ID in the form project:location:instance.
func (o ConnectionCloudSqlPtrOutput) InstanceId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ConnectionCloudSql) *string {
		if v == nil {
			return nil
		}
		return &v.InstanceId
	}).(pulumi.StringPtrOutput)
}

// Type of the Cloud SQL database.
// Possible values are `DATABASE_TYPE_UNSPECIFIED`, `POSTGRES`, and `MYSQL`.
func (o ConnectionCloudSqlPtrOutput) Type() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ConnectionCloudSql) *string {
		if v == nil {
			return nil
		}
		return &v.Type
	}).(pulumi.StringPtrOutput)
}

type ConnectionCloudSqlCredential struct {
	// Password for database.
	// **Note**: This property is sensitive and will not be displayed in the plan.
	Password string `pulumi:"password"`
	// Username for database.
	Username string `pulumi:"username"`
}

// ConnectionCloudSqlCredentialInput is an input type that accepts ConnectionCloudSqlCredentialArgs and ConnectionCloudSqlCredentialOutput values.
// You can construct a concrete instance of `ConnectionCloudSqlCredentialInput` via:
//
// 		 ConnectionCloudSqlCredentialArgs{...}
//
type ConnectionCloudSqlCredentialInput interface {
	pulumi.Input

	ToConnectionCloudSqlCredentialOutput() ConnectionCloudSqlCredentialOutput
	ToConnectionCloudSqlCredentialOutputWithContext(context.Context) ConnectionCloudSqlCredentialOutput
}

type ConnectionCloudSqlCredentialArgs struct {
	// Password for database.
	// **Note**: This property is sensitive and will not be displayed in the plan.
	Password pulumi.StringInput `pulumi:"password"`
	// Username for database.
	Username pulumi.StringInput `pulumi:"username"`
}

func (ConnectionCloudSqlCredentialArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ConnectionCloudSqlCredential)(nil)).Elem()
}

func (i ConnectionCloudSqlCredentialArgs) ToConnectionCloudSqlCredentialOutput() ConnectionCloudSqlCredentialOutput {
	return i.ToConnectionCloudSqlCredentialOutputWithContext(context.Background())
}

func (i ConnectionCloudSqlCredentialArgs) ToConnectionCloudSqlCredentialOutputWithContext(ctx context.Context) ConnectionCloudSqlCredentialOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ConnectionCloudSqlCredentialOutput)
}

func (i ConnectionCloudSqlCredentialArgs) ToConnectionCloudSqlCredentialPtrOutput() ConnectionCloudSqlCredentialPtrOutput {
	return i.ToConnectionCloudSqlCredentialPtrOutputWithContext(context.Background())
}

func (i ConnectionCloudSqlCredentialArgs) ToConnectionCloudSqlCredentialPtrOutputWithContext(ctx context.Context) ConnectionCloudSqlCredentialPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ConnectionCloudSqlCredentialOutput).ToConnectionCloudSqlCredentialPtrOutputWithContext(ctx)
}

// ConnectionCloudSqlCredentialPtrInput is an input type that accepts ConnectionCloudSqlCredentialArgs, ConnectionCloudSqlCredentialPtr and ConnectionCloudSqlCredentialPtrOutput values.
// You can construct a concrete instance of `ConnectionCloudSqlCredentialPtrInput` via:
//
// 		 ConnectionCloudSqlCredentialArgs{...}
//
//  or:
//
// 		 nil
//
type ConnectionCloudSqlCredentialPtrInput interface {
	pulumi.Input

	ToConnectionCloudSqlCredentialPtrOutput() ConnectionCloudSqlCredentialPtrOutput
	ToConnectionCloudSqlCredentialPtrOutputWithContext(context.Context) ConnectionCloudSqlCredentialPtrOutput
}

type connectionCloudSqlCredentialPtrType ConnectionCloudSqlCredentialArgs

func ConnectionCloudSqlCredentialPtr(v *ConnectionCloudSqlCredentialArgs) ConnectionCloudSqlCredentialPtrInput {
	return (*connectionCloudSqlCredentialPtrType)(v)
}

func (*connectionCloudSqlCredentialPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ConnectionCloudSqlCredential)(nil)).Elem()
}

func (i *connectionCloudSqlCredentialPtrType) ToConnectionCloudSqlCredentialPtrOutput() ConnectionCloudSqlCredentialPtrOutput {
	return i.ToConnectionCloudSqlCredentialPtrOutputWithContext(context.Background())
}

func (i *connectionCloudSqlCredentialPtrType) ToConnectionCloudSqlCredentialPtrOutputWithContext(ctx context.Context) ConnectionCloudSqlCredentialPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ConnectionCloudSqlCredentialPtrOutput)
}

type ConnectionCloudSqlCredentialOutput struct{ *pulumi.OutputState }

func (ConnectionCloudSqlCredentialOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ConnectionCloudSqlCredential)(nil)).Elem()
}

func (o ConnectionCloudSqlCredentialOutput) ToConnectionCloudSqlCredentialOutput() ConnectionCloudSqlCredentialOutput {
	return o
}

func (o ConnectionCloudSqlCredentialOutput) ToConnectionCloudSqlCredentialOutputWithContext(ctx context.Context) ConnectionCloudSqlCredentialOutput {
	return o
}

func (o ConnectionCloudSqlCredentialOutput) ToConnectionCloudSqlCredentialPtrOutput() ConnectionCloudSqlCredentialPtrOutput {
	return o.ToConnectionCloudSqlCredentialPtrOutputWithContext(context.Background())
}

func (o ConnectionCloudSqlCredentialOutput) ToConnectionCloudSqlCredentialPtrOutputWithContext(ctx context.Context) ConnectionCloudSqlCredentialPtrOutput {
	return o.ApplyT(func(v ConnectionCloudSqlCredential) *ConnectionCloudSqlCredential {
		return &v
	}).(ConnectionCloudSqlCredentialPtrOutput)
}

// Password for database.
// **Note**: This property is sensitive and will not be displayed in the plan.
func (o ConnectionCloudSqlCredentialOutput) Password() pulumi.StringOutput {
	return o.ApplyT(func(v ConnectionCloudSqlCredential) string { return v.Password }).(pulumi.StringOutput)
}

// Username for database.
func (o ConnectionCloudSqlCredentialOutput) Username() pulumi.StringOutput {
	return o.ApplyT(func(v ConnectionCloudSqlCredential) string { return v.Username }).(pulumi.StringOutput)
}

type ConnectionCloudSqlCredentialPtrOutput struct{ *pulumi.OutputState }

func (ConnectionCloudSqlCredentialPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ConnectionCloudSqlCredential)(nil)).Elem()
}

func (o ConnectionCloudSqlCredentialPtrOutput) ToConnectionCloudSqlCredentialPtrOutput() ConnectionCloudSqlCredentialPtrOutput {
	return o
}

func (o ConnectionCloudSqlCredentialPtrOutput) ToConnectionCloudSqlCredentialPtrOutputWithContext(ctx context.Context) ConnectionCloudSqlCredentialPtrOutput {
	return o
}

func (o ConnectionCloudSqlCredentialPtrOutput) Elem() ConnectionCloudSqlCredentialOutput {
	return o.ApplyT(func(v *ConnectionCloudSqlCredential) ConnectionCloudSqlCredential { return *v }).(ConnectionCloudSqlCredentialOutput)
}

// Password for database.
// **Note**: This property is sensitive and will not be displayed in the plan.
func (o ConnectionCloudSqlCredentialPtrOutput) Password() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ConnectionCloudSqlCredential) *string {
		if v == nil {
			return nil
		}
		return &v.Password
	}).(pulumi.StringPtrOutput)
}

// Username for database.
func (o ConnectionCloudSqlCredentialPtrOutput) Username() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ConnectionCloudSqlCredential) *string {
		if v == nil {
			return nil
		}
		return &v.Username
	}).(pulumi.StringPtrOutput)
}

type DatasetAccessType struct {
	// A domain to grant access to. Any users signed in with the
	// domain specified will be granted the specified access
	Domain *string `pulumi:"domain"`
	// An email address of a Google Group to grant access to.
	GroupByEmail *string `pulumi:"groupByEmail"`
	// Describes the rights granted to the user specified by the other
	// member of the access object. Primitive, Predefined and custom
	// roles are supported. Predefined roles that have equivalent
	// primitive roles are swapped by the API to their Primitive
	// counterparts. See
	// [official docs](https://cloud.google.com/bigquery/docs/access-control).
	Role *string `pulumi:"role"`
	// A special group to grant access to. Possible values include:
	SpecialGroup *string `pulumi:"specialGroup"`
	// An email address of a user to grant access to. For example:
	// fred@example.com
	UserByEmail *string `pulumi:"userByEmail"`
	// A view from a different dataset to grant access to. Queries
	// executed against that view will have read access to tables in
	// this dataset. The role field is not required when this field is
	// set. If that view is updated by any user, access to the view
	// needs to be granted again via an update operation.
	// Structure is documented below.
	View *DatasetAccessView `pulumi:"view"`
}

// DatasetAccessTypeInput is an input type that accepts DatasetAccessTypeArgs and DatasetAccessTypeOutput values.
// You can construct a concrete instance of `DatasetAccessTypeInput` via:
//
// 		 DatasetAccessTypeArgs{...}
//
type DatasetAccessTypeInput interface {
	pulumi.Input

	ToDatasetAccessTypeOutput() DatasetAccessTypeOutput
	ToDatasetAccessTypeOutputWithContext(context.Context) DatasetAccessTypeOutput
}

type DatasetAccessTypeArgs struct {
	// A domain to grant access to. Any users signed in with the
	// domain specified will be granted the specified access
	Domain pulumi.StringPtrInput `pulumi:"domain"`
	// An email address of a Google Group to grant access to.
	GroupByEmail pulumi.StringPtrInput `pulumi:"groupByEmail"`
	// Describes the rights granted to the user specified by the other
	// member of the access object. Primitive, Predefined and custom
	// roles are supported. Predefined roles that have equivalent
	// primitive roles are swapped by the API to their Primitive
	// counterparts. See
	// [official docs](https://cloud.google.com/bigquery/docs/access-control).
	Role pulumi.StringPtrInput `pulumi:"role"`
	// A special group to grant access to. Possible values include:
	SpecialGroup pulumi.StringPtrInput `pulumi:"specialGroup"`
	// An email address of a user to grant access to. For example:
	// fred@example.com
	UserByEmail pulumi.StringPtrInput `pulumi:"userByEmail"`
	// A view from a different dataset to grant access to. Queries
	// executed against that view will have read access to tables in
	// this dataset. The role field is not required when this field is
	// set. If that view is updated by any user, access to the view
	// needs to be granted again via an update operation.
	// Structure is documented below.
	View DatasetAccessViewPtrInput `pulumi:"view"`
}

func (DatasetAccessTypeArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*DatasetAccessType)(nil)).Elem()
}

func (i DatasetAccessTypeArgs) ToDatasetAccessTypeOutput() DatasetAccessTypeOutput {
	return i.ToDatasetAccessTypeOutputWithContext(context.Background())
}

func (i DatasetAccessTypeArgs) ToDatasetAccessTypeOutputWithContext(ctx context.Context) DatasetAccessTypeOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetAccessTypeOutput)
}

// DatasetAccessTypeArrayInput is an input type that accepts DatasetAccessTypeArray and DatasetAccessTypeArrayOutput values.
// You can construct a concrete instance of `DatasetAccessTypeArrayInput` via:
//
// 		 DatasetAccessTypeArray{ DatasetAccessTypeArgs{...} }
//
type DatasetAccessTypeArrayInput interface {
	pulumi.Input

	ToDatasetAccessTypeArrayOutput() DatasetAccessTypeArrayOutput
	ToDatasetAccessTypeArrayOutputWithContext(context.Context) DatasetAccessTypeArrayOutput
}

type DatasetAccessTypeArray []DatasetAccessTypeInput

func (DatasetAccessTypeArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]DatasetAccessType)(nil)).Elem()
}

func (i DatasetAccessTypeArray) ToDatasetAccessTypeArrayOutput() DatasetAccessTypeArrayOutput {
	return i.ToDatasetAccessTypeArrayOutputWithContext(context.Background())
}

func (i DatasetAccessTypeArray) ToDatasetAccessTypeArrayOutputWithContext(ctx context.Context) DatasetAccessTypeArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetAccessTypeArrayOutput)
}

type DatasetAccessTypeOutput struct{ *pulumi.OutputState }

func (DatasetAccessTypeOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*DatasetAccessType)(nil)).Elem()
}

func (o DatasetAccessTypeOutput) ToDatasetAccessTypeOutput() DatasetAccessTypeOutput {
	return o
}

func (o DatasetAccessTypeOutput) ToDatasetAccessTypeOutputWithContext(ctx context.Context) DatasetAccessTypeOutput {
	return o
}

// A domain to grant access to. Any users signed in with the
// domain specified will be granted the specified access
func (o DatasetAccessTypeOutput) Domain() pulumi.StringPtrOutput {
	return o.ApplyT(func(v DatasetAccessType) *string { return v.Domain }).(pulumi.StringPtrOutput)
}

// An email address of a Google Group to grant access to.
func (o DatasetAccessTypeOutput) GroupByEmail() pulumi.StringPtrOutput {
	return o.ApplyT(func(v DatasetAccessType) *string { return v.GroupByEmail }).(pulumi.StringPtrOutput)
}

// Describes the rights granted to the user specified by the other
// member of the access object. Primitive, Predefined and custom
// roles are supported. Predefined roles that have equivalent
// primitive roles are swapped by the API to their Primitive
// counterparts. See
// [official docs](https://cloud.google.com/bigquery/docs/access-control).
func (o DatasetAccessTypeOutput) Role() pulumi.StringPtrOutput {
	return o.ApplyT(func(v DatasetAccessType) *string { return v.Role }).(pulumi.StringPtrOutput)
}

// A special group to grant access to. Possible values include:
func (o DatasetAccessTypeOutput) SpecialGroup() pulumi.StringPtrOutput {
	return o.ApplyT(func(v DatasetAccessType) *string { return v.SpecialGroup }).(pulumi.StringPtrOutput)
}

// An email address of a user to grant access to. For example:
// fred@example.com
func (o DatasetAccessTypeOutput) UserByEmail() pulumi.StringPtrOutput {
	return o.ApplyT(func(v DatasetAccessType) *string { return v.UserByEmail }).(pulumi.StringPtrOutput)
}

// A view from a different dataset to grant access to. Queries
// executed against that view will have read access to tables in
// this dataset. The role field is not required when this field is
// set. If that view is updated by any user, access to the view
// needs to be granted again via an update operation.
// Structure is documented below.
func (o DatasetAccessTypeOutput) View() DatasetAccessViewPtrOutput {
	return o.ApplyT(func(v DatasetAccessType) *DatasetAccessView { return v.View }).(DatasetAccessViewPtrOutput)
}

type DatasetAccessTypeArrayOutput struct{ *pulumi.OutputState }

func (DatasetAccessTypeArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]DatasetAccessType)(nil)).Elem()
}

func (o DatasetAccessTypeArrayOutput) ToDatasetAccessTypeArrayOutput() DatasetAccessTypeArrayOutput {
	return o
}

func (o DatasetAccessTypeArrayOutput) ToDatasetAccessTypeArrayOutputWithContext(ctx context.Context) DatasetAccessTypeArrayOutput {
	return o
}

func (o DatasetAccessTypeArrayOutput) Index(i pulumi.IntInput) DatasetAccessTypeOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) DatasetAccessType {
		return vs[0].([]DatasetAccessType)[vs[1].(int)]
	}).(DatasetAccessTypeOutput)
}

type DatasetAccessView struct {
	// The ID of the dataset containing this table.
	DatasetId string `pulumi:"datasetId"`
	// The ID of the project containing this table.
	ProjectId string `pulumi:"projectId"`
	// The ID of the table. The ID must contain only letters (a-z,
	// A-Z), numbers (0-9), or underscores (_). The maximum length
	// is 1,024 characters.
	TableId string `pulumi:"tableId"`
}

// DatasetAccessViewInput is an input type that accepts DatasetAccessViewArgs and DatasetAccessViewOutput values.
// You can construct a concrete instance of `DatasetAccessViewInput` via:
//
// 		 DatasetAccessViewArgs{...}
//
type DatasetAccessViewInput interface {
	pulumi.Input

	ToDatasetAccessViewOutput() DatasetAccessViewOutput
	ToDatasetAccessViewOutputWithContext(context.Context) DatasetAccessViewOutput
}

type DatasetAccessViewArgs struct {
	// The ID of the dataset containing this table.
	DatasetId pulumi.StringInput `pulumi:"datasetId"`
	// The ID of the project containing this table.
	ProjectId pulumi.StringInput `pulumi:"projectId"`
	// The ID of the table. The ID must contain only letters (a-z,
	// A-Z), numbers (0-9), or underscores (_). The maximum length
	// is 1,024 characters.
	TableId pulumi.StringInput `pulumi:"tableId"`
}

func (DatasetAccessViewArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*DatasetAccessView)(nil)).Elem()
}

func (i DatasetAccessViewArgs) ToDatasetAccessViewOutput() DatasetAccessViewOutput {
	return i.ToDatasetAccessViewOutputWithContext(context.Background())
}

func (i DatasetAccessViewArgs) ToDatasetAccessViewOutputWithContext(ctx context.Context) DatasetAccessViewOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetAccessViewOutput)
}

func (i DatasetAccessViewArgs) ToDatasetAccessViewPtrOutput() DatasetAccessViewPtrOutput {
	return i.ToDatasetAccessViewPtrOutputWithContext(context.Background())
}

func (i DatasetAccessViewArgs) ToDatasetAccessViewPtrOutputWithContext(ctx context.Context) DatasetAccessViewPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetAccessViewOutput).ToDatasetAccessViewPtrOutputWithContext(ctx)
}

// DatasetAccessViewPtrInput is an input type that accepts DatasetAccessViewArgs, DatasetAccessViewPtr and DatasetAccessViewPtrOutput values.
// You can construct a concrete instance of `DatasetAccessViewPtrInput` via:
//
// 		 DatasetAccessViewArgs{...}
//
//  or:
//
// 		 nil
//
type DatasetAccessViewPtrInput interface {
	pulumi.Input

	ToDatasetAccessViewPtrOutput() DatasetAccessViewPtrOutput
	ToDatasetAccessViewPtrOutputWithContext(context.Context) DatasetAccessViewPtrOutput
}

type datasetAccessViewPtrType DatasetAccessViewArgs

func DatasetAccessViewPtr(v *DatasetAccessViewArgs) DatasetAccessViewPtrInput {
	return (*datasetAccessViewPtrType)(v)
}

func (*datasetAccessViewPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**DatasetAccessView)(nil)).Elem()
}

func (i *datasetAccessViewPtrType) ToDatasetAccessViewPtrOutput() DatasetAccessViewPtrOutput {
	return i.ToDatasetAccessViewPtrOutputWithContext(context.Background())
}

func (i *datasetAccessViewPtrType) ToDatasetAccessViewPtrOutputWithContext(ctx context.Context) DatasetAccessViewPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetAccessViewPtrOutput)
}

type DatasetAccessViewOutput struct{ *pulumi.OutputState }

func (DatasetAccessViewOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*DatasetAccessView)(nil)).Elem()
}

func (o DatasetAccessViewOutput) ToDatasetAccessViewOutput() DatasetAccessViewOutput {
	return o
}

func (o DatasetAccessViewOutput) ToDatasetAccessViewOutputWithContext(ctx context.Context) DatasetAccessViewOutput {
	return o
}

func (o DatasetAccessViewOutput) ToDatasetAccessViewPtrOutput() DatasetAccessViewPtrOutput {
	return o.ToDatasetAccessViewPtrOutputWithContext(context.Background())
}

func (o DatasetAccessViewOutput) ToDatasetAccessViewPtrOutputWithContext(ctx context.Context) DatasetAccessViewPtrOutput {
	return o.ApplyT(func(v DatasetAccessView) *DatasetAccessView {
		return &v
	}).(DatasetAccessViewPtrOutput)
}

// The ID of the dataset containing this table.
func (o DatasetAccessViewOutput) DatasetId() pulumi.StringOutput {
	return o.ApplyT(func(v DatasetAccessView) string { return v.DatasetId }).(pulumi.StringOutput)
}

// The ID of the project containing this table.
func (o DatasetAccessViewOutput) ProjectId() pulumi.StringOutput {
	return o.ApplyT(func(v DatasetAccessView) string { return v.ProjectId }).(pulumi.StringOutput)
}

// The ID of the table. The ID must contain only letters (a-z,
// A-Z), numbers (0-9), or underscores (_). The maximum length
// is 1,024 characters.
func (o DatasetAccessViewOutput) TableId() pulumi.StringOutput {
	return o.ApplyT(func(v DatasetAccessView) string { return v.TableId }).(pulumi.StringOutput)
}

type DatasetAccessViewPtrOutput struct{ *pulumi.OutputState }

func (DatasetAccessViewPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**DatasetAccessView)(nil)).Elem()
}

func (o DatasetAccessViewPtrOutput) ToDatasetAccessViewPtrOutput() DatasetAccessViewPtrOutput {
	return o
}

func (o DatasetAccessViewPtrOutput) ToDatasetAccessViewPtrOutputWithContext(ctx context.Context) DatasetAccessViewPtrOutput {
	return o
}

func (o DatasetAccessViewPtrOutput) Elem() DatasetAccessViewOutput {
	return o.ApplyT(func(v *DatasetAccessView) DatasetAccessView { return *v }).(DatasetAccessViewOutput)
}

// The ID of the dataset containing this table.
func (o DatasetAccessViewPtrOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DatasetAccessView) *string {
		if v == nil {
			return nil
		}
		return &v.DatasetId
	}).(pulumi.StringPtrOutput)
}

// The ID of the project containing this table.
func (o DatasetAccessViewPtrOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DatasetAccessView) *string {
		if v == nil {
			return nil
		}
		return &v.ProjectId
	}).(pulumi.StringPtrOutput)
}

// The ID of the table. The ID must contain only letters (a-z,
// A-Z), numbers (0-9), or underscores (_). The maximum length
// is 1,024 characters.
func (o DatasetAccessViewPtrOutput) TableId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DatasetAccessView) *string {
		if v == nil {
			return nil
		}
		return &v.TableId
	}).(pulumi.StringPtrOutput)
}

type DatasetDefaultEncryptionConfiguration struct {
	// Describes the Cloud KMS encryption key that will be used to protect destination
	// BigQuery table. The BigQuery Service Account associated with your project requires
	// access to this encryption key.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// DatasetDefaultEncryptionConfigurationInput is an input type that accepts DatasetDefaultEncryptionConfigurationArgs and DatasetDefaultEncryptionConfigurationOutput values.
// You can construct a concrete instance of `DatasetDefaultEncryptionConfigurationInput` via:
//
// 		 DatasetDefaultEncryptionConfigurationArgs{...}
//
type DatasetDefaultEncryptionConfigurationInput interface {
	pulumi.Input

	ToDatasetDefaultEncryptionConfigurationOutput() DatasetDefaultEncryptionConfigurationOutput
	ToDatasetDefaultEncryptionConfigurationOutputWithContext(context.Context) DatasetDefaultEncryptionConfigurationOutput
}

type DatasetDefaultEncryptionConfigurationArgs struct {
	// Describes the Cloud KMS encryption key that will be used to protect destination
	// BigQuery table. The BigQuery Service Account associated with your project requires
	// access to this encryption key.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (DatasetDefaultEncryptionConfigurationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*DatasetDefaultEncryptionConfiguration)(nil)).Elem()
}

func (i DatasetDefaultEncryptionConfigurationArgs) ToDatasetDefaultEncryptionConfigurationOutput() DatasetDefaultEncryptionConfigurationOutput {
	return i.ToDatasetDefaultEncryptionConfigurationOutputWithContext(context.Background())
}

func (i DatasetDefaultEncryptionConfigurationArgs) ToDatasetDefaultEncryptionConfigurationOutputWithContext(ctx context.Context) DatasetDefaultEncryptionConfigurationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetDefaultEncryptionConfigurationOutput)
}

func (i DatasetDefaultEncryptionConfigurationArgs) ToDatasetDefaultEncryptionConfigurationPtrOutput() DatasetDefaultEncryptionConfigurationPtrOutput {
	return i.ToDatasetDefaultEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (i DatasetDefaultEncryptionConfigurationArgs) ToDatasetDefaultEncryptionConfigurationPtrOutputWithContext(ctx context.Context) DatasetDefaultEncryptionConfigurationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetDefaultEncryptionConfigurationOutput).ToDatasetDefaultEncryptionConfigurationPtrOutputWithContext(ctx)
}

// DatasetDefaultEncryptionConfigurationPtrInput is an input type that accepts DatasetDefaultEncryptionConfigurationArgs, DatasetDefaultEncryptionConfigurationPtr and DatasetDefaultEncryptionConfigurationPtrOutput values.
// You can construct a concrete instance of `DatasetDefaultEncryptionConfigurationPtrInput` via:
//
// 		 DatasetDefaultEncryptionConfigurationArgs{...}
//
//  or:
//
// 		 nil
//
type DatasetDefaultEncryptionConfigurationPtrInput interface {
	pulumi.Input

	ToDatasetDefaultEncryptionConfigurationPtrOutput() DatasetDefaultEncryptionConfigurationPtrOutput
	ToDatasetDefaultEncryptionConfigurationPtrOutputWithContext(context.Context) DatasetDefaultEncryptionConfigurationPtrOutput
}

type datasetDefaultEncryptionConfigurationPtrType DatasetDefaultEncryptionConfigurationArgs

func DatasetDefaultEncryptionConfigurationPtr(v *DatasetDefaultEncryptionConfigurationArgs) DatasetDefaultEncryptionConfigurationPtrInput {
	return (*datasetDefaultEncryptionConfigurationPtrType)(v)
}

func (*datasetDefaultEncryptionConfigurationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**DatasetDefaultEncryptionConfiguration)(nil)).Elem()
}

func (i *datasetDefaultEncryptionConfigurationPtrType) ToDatasetDefaultEncryptionConfigurationPtrOutput() DatasetDefaultEncryptionConfigurationPtrOutput {
	return i.ToDatasetDefaultEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (i *datasetDefaultEncryptionConfigurationPtrType) ToDatasetDefaultEncryptionConfigurationPtrOutputWithContext(ctx context.Context) DatasetDefaultEncryptionConfigurationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetDefaultEncryptionConfigurationPtrOutput)
}

type DatasetDefaultEncryptionConfigurationOutput struct{ *pulumi.OutputState }

func (DatasetDefaultEncryptionConfigurationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*DatasetDefaultEncryptionConfiguration)(nil)).Elem()
}

func (o DatasetDefaultEncryptionConfigurationOutput) ToDatasetDefaultEncryptionConfigurationOutput() DatasetDefaultEncryptionConfigurationOutput {
	return o
}

func (o DatasetDefaultEncryptionConfigurationOutput) ToDatasetDefaultEncryptionConfigurationOutputWithContext(ctx context.Context) DatasetDefaultEncryptionConfigurationOutput {
	return o
}

func (o DatasetDefaultEncryptionConfigurationOutput) ToDatasetDefaultEncryptionConfigurationPtrOutput() DatasetDefaultEncryptionConfigurationPtrOutput {
	return o.ToDatasetDefaultEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (o DatasetDefaultEncryptionConfigurationOutput) ToDatasetDefaultEncryptionConfigurationPtrOutputWithContext(ctx context.Context) DatasetDefaultEncryptionConfigurationPtrOutput {
	return o.ApplyT(func(v DatasetDefaultEncryptionConfiguration) *DatasetDefaultEncryptionConfiguration {
		return &v
	}).(DatasetDefaultEncryptionConfigurationPtrOutput)
}

// Describes the Cloud KMS encryption key that will be used to protect destination
// BigQuery table. The BigQuery Service Account associated with your project requires
// access to this encryption key.
func (o DatasetDefaultEncryptionConfigurationOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v DatasetDefaultEncryptionConfiguration) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type DatasetDefaultEncryptionConfigurationPtrOutput struct{ *pulumi.OutputState }

func (DatasetDefaultEncryptionConfigurationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**DatasetDefaultEncryptionConfiguration)(nil)).Elem()
}

func (o DatasetDefaultEncryptionConfigurationPtrOutput) ToDatasetDefaultEncryptionConfigurationPtrOutput() DatasetDefaultEncryptionConfigurationPtrOutput {
	return o
}

func (o DatasetDefaultEncryptionConfigurationPtrOutput) ToDatasetDefaultEncryptionConfigurationPtrOutputWithContext(ctx context.Context) DatasetDefaultEncryptionConfigurationPtrOutput {
	return o
}

func (o DatasetDefaultEncryptionConfigurationPtrOutput) Elem() DatasetDefaultEncryptionConfigurationOutput {
	return o.ApplyT(func(v *DatasetDefaultEncryptionConfiguration) DatasetDefaultEncryptionConfiguration { return *v }).(DatasetDefaultEncryptionConfigurationOutput)
}

// Describes the Cloud KMS encryption key that will be used to protect destination
// BigQuery table. The BigQuery Service Account associated with your project requires
// access to this encryption key.
func (o DatasetDefaultEncryptionConfigurationPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DatasetDefaultEncryptionConfiguration) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type DatasetIamBindingCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// DatasetIamBindingConditionInput is an input type that accepts DatasetIamBindingConditionArgs and DatasetIamBindingConditionOutput values.
// You can construct a concrete instance of `DatasetIamBindingConditionInput` via:
//
// 		 DatasetIamBindingConditionArgs{...}
//
type DatasetIamBindingConditionInput interface {
	pulumi.Input

	ToDatasetIamBindingConditionOutput() DatasetIamBindingConditionOutput
	ToDatasetIamBindingConditionOutputWithContext(context.Context) DatasetIamBindingConditionOutput
}

type DatasetIamBindingConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (DatasetIamBindingConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*DatasetIamBindingCondition)(nil)).Elem()
}

func (i DatasetIamBindingConditionArgs) ToDatasetIamBindingConditionOutput() DatasetIamBindingConditionOutput {
	return i.ToDatasetIamBindingConditionOutputWithContext(context.Background())
}

func (i DatasetIamBindingConditionArgs) ToDatasetIamBindingConditionOutputWithContext(ctx context.Context) DatasetIamBindingConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetIamBindingConditionOutput)
}

func (i DatasetIamBindingConditionArgs) ToDatasetIamBindingConditionPtrOutput() DatasetIamBindingConditionPtrOutput {
	return i.ToDatasetIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i DatasetIamBindingConditionArgs) ToDatasetIamBindingConditionPtrOutputWithContext(ctx context.Context) DatasetIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetIamBindingConditionOutput).ToDatasetIamBindingConditionPtrOutputWithContext(ctx)
}

// DatasetIamBindingConditionPtrInput is an input type that accepts DatasetIamBindingConditionArgs, DatasetIamBindingConditionPtr and DatasetIamBindingConditionPtrOutput values.
// You can construct a concrete instance of `DatasetIamBindingConditionPtrInput` via:
//
// 		 DatasetIamBindingConditionArgs{...}
//
//  or:
//
// 		 nil
//
type DatasetIamBindingConditionPtrInput interface {
	pulumi.Input

	ToDatasetIamBindingConditionPtrOutput() DatasetIamBindingConditionPtrOutput
	ToDatasetIamBindingConditionPtrOutputWithContext(context.Context) DatasetIamBindingConditionPtrOutput
}

type datasetIamBindingConditionPtrType DatasetIamBindingConditionArgs

func DatasetIamBindingConditionPtr(v *DatasetIamBindingConditionArgs) DatasetIamBindingConditionPtrInput {
	return (*datasetIamBindingConditionPtrType)(v)
}

func (*datasetIamBindingConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**DatasetIamBindingCondition)(nil)).Elem()
}

func (i *datasetIamBindingConditionPtrType) ToDatasetIamBindingConditionPtrOutput() DatasetIamBindingConditionPtrOutput {
	return i.ToDatasetIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i *datasetIamBindingConditionPtrType) ToDatasetIamBindingConditionPtrOutputWithContext(ctx context.Context) DatasetIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetIamBindingConditionPtrOutput)
}

type DatasetIamBindingConditionOutput struct{ *pulumi.OutputState }

func (DatasetIamBindingConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*DatasetIamBindingCondition)(nil)).Elem()
}

func (o DatasetIamBindingConditionOutput) ToDatasetIamBindingConditionOutput() DatasetIamBindingConditionOutput {
	return o
}

func (o DatasetIamBindingConditionOutput) ToDatasetIamBindingConditionOutputWithContext(ctx context.Context) DatasetIamBindingConditionOutput {
	return o
}

func (o DatasetIamBindingConditionOutput) ToDatasetIamBindingConditionPtrOutput() DatasetIamBindingConditionPtrOutput {
	return o.ToDatasetIamBindingConditionPtrOutputWithContext(context.Background())
}

func (o DatasetIamBindingConditionOutput) ToDatasetIamBindingConditionPtrOutputWithContext(ctx context.Context) DatasetIamBindingConditionPtrOutput {
	return o.ApplyT(func(v DatasetIamBindingCondition) *DatasetIamBindingCondition {
		return &v
	}).(DatasetIamBindingConditionPtrOutput)
}
func (o DatasetIamBindingConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v DatasetIamBindingCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o DatasetIamBindingConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v DatasetIamBindingCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o DatasetIamBindingConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v DatasetIamBindingCondition) string { return v.Title }).(pulumi.StringOutput)
}

type DatasetIamBindingConditionPtrOutput struct{ *pulumi.OutputState }

func (DatasetIamBindingConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**DatasetIamBindingCondition)(nil)).Elem()
}

func (o DatasetIamBindingConditionPtrOutput) ToDatasetIamBindingConditionPtrOutput() DatasetIamBindingConditionPtrOutput {
	return o
}

func (o DatasetIamBindingConditionPtrOutput) ToDatasetIamBindingConditionPtrOutputWithContext(ctx context.Context) DatasetIamBindingConditionPtrOutput {
	return o
}

func (o DatasetIamBindingConditionPtrOutput) Elem() DatasetIamBindingConditionOutput {
	return o.ApplyT(func(v *DatasetIamBindingCondition) DatasetIamBindingCondition { return *v }).(DatasetIamBindingConditionOutput)
}

func (o DatasetIamBindingConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DatasetIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o DatasetIamBindingConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DatasetIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o DatasetIamBindingConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DatasetIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type DatasetIamMemberCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// DatasetIamMemberConditionInput is an input type that accepts DatasetIamMemberConditionArgs and DatasetIamMemberConditionOutput values.
// You can construct a concrete instance of `DatasetIamMemberConditionInput` via:
//
// 		 DatasetIamMemberConditionArgs{...}
//
type DatasetIamMemberConditionInput interface {
	pulumi.Input

	ToDatasetIamMemberConditionOutput() DatasetIamMemberConditionOutput
	ToDatasetIamMemberConditionOutputWithContext(context.Context) DatasetIamMemberConditionOutput
}

type DatasetIamMemberConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (DatasetIamMemberConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*DatasetIamMemberCondition)(nil)).Elem()
}

func (i DatasetIamMemberConditionArgs) ToDatasetIamMemberConditionOutput() DatasetIamMemberConditionOutput {
	return i.ToDatasetIamMemberConditionOutputWithContext(context.Background())
}

func (i DatasetIamMemberConditionArgs) ToDatasetIamMemberConditionOutputWithContext(ctx context.Context) DatasetIamMemberConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetIamMemberConditionOutput)
}

func (i DatasetIamMemberConditionArgs) ToDatasetIamMemberConditionPtrOutput() DatasetIamMemberConditionPtrOutput {
	return i.ToDatasetIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i DatasetIamMemberConditionArgs) ToDatasetIamMemberConditionPtrOutputWithContext(ctx context.Context) DatasetIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetIamMemberConditionOutput).ToDatasetIamMemberConditionPtrOutputWithContext(ctx)
}

// DatasetIamMemberConditionPtrInput is an input type that accepts DatasetIamMemberConditionArgs, DatasetIamMemberConditionPtr and DatasetIamMemberConditionPtrOutput values.
// You can construct a concrete instance of `DatasetIamMemberConditionPtrInput` via:
//
// 		 DatasetIamMemberConditionArgs{...}
//
//  or:
//
// 		 nil
//
type DatasetIamMemberConditionPtrInput interface {
	pulumi.Input

	ToDatasetIamMemberConditionPtrOutput() DatasetIamMemberConditionPtrOutput
	ToDatasetIamMemberConditionPtrOutputWithContext(context.Context) DatasetIamMemberConditionPtrOutput
}

type datasetIamMemberConditionPtrType DatasetIamMemberConditionArgs

func DatasetIamMemberConditionPtr(v *DatasetIamMemberConditionArgs) DatasetIamMemberConditionPtrInput {
	return (*datasetIamMemberConditionPtrType)(v)
}

func (*datasetIamMemberConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**DatasetIamMemberCondition)(nil)).Elem()
}

func (i *datasetIamMemberConditionPtrType) ToDatasetIamMemberConditionPtrOutput() DatasetIamMemberConditionPtrOutput {
	return i.ToDatasetIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i *datasetIamMemberConditionPtrType) ToDatasetIamMemberConditionPtrOutputWithContext(ctx context.Context) DatasetIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatasetIamMemberConditionPtrOutput)
}

type DatasetIamMemberConditionOutput struct{ *pulumi.OutputState }

func (DatasetIamMemberConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*DatasetIamMemberCondition)(nil)).Elem()
}

func (o DatasetIamMemberConditionOutput) ToDatasetIamMemberConditionOutput() DatasetIamMemberConditionOutput {
	return o
}

func (o DatasetIamMemberConditionOutput) ToDatasetIamMemberConditionOutputWithContext(ctx context.Context) DatasetIamMemberConditionOutput {
	return o
}

func (o DatasetIamMemberConditionOutput) ToDatasetIamMemberConditionPtrOutput() DatasetIamMemberConditionPtrOutput {
	return o.ToDatasetIamMemberConditionPtrOutputWithContext(context.Background())
}

func (o DatasetIamMemberConditionOutput) ToDatasetIamMemberConditionPtrOutputWithContext(ctx context.Context) DatasetIamMemberConditionPtrOutput {
	return o.ApplyT(func(v DatasetIamMemberCondition) *DatasetIamMemberCondition {
		return &v
	}).(DatasetIamMemberConditionPtrOutput)
}
func (o DatasetIamMemberConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v DatasetIamMemberCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o DatasetIamMemberConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v DatasetIamMemberCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o DatasetIamMemberConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v DatasetIamMemberCondition) string { return v.Title }).(pulumi.StringOutput)
}

type DatasetIamMemberConditionPtrOutput struct{ *pulumi.OutputState }

func (DatasetIamMemberConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**DatasetIamMemberCondition)(nil)).Elem()
}

func (o DatasetIamMemberConditionPtrOutput) ToDatasetIamMemberConditionPtrOutput() DatasetIamMemberConditionPtrOutput {
	return o
}

func (o DatasetIamMemberConditionPtrOutput) ToDatasetIamMemberConditionPtrOutputWithContext(ctx context.Context) DatasetIamMemberConditionPtrOutput {
	return o
}

func (o DatasetIamMemberConditionPtrOutput) Elem() DatasetIamMemberConditionOutput {
	return o.ApplyT(func(v *DatasetIamMemberCondition) DatasetIamMemberCondition { return *v }).(DatasetIamMemberConditionOutput)
}

func (o DatasetIamMemberConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DatasetIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o DatasetIamMemberConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DatasetIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o DatasetIamMemberConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DatasetIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type JobCopy struct {
	// Specifies whether the job is allowed to create new tables. The following values are supported:
	// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
	// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
	// Creation, truncation and append actions occur as one atomic update upon job completion
	// Default value is `CREATE_IF_NEEDED`.
	// Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
	CreateDisposition *string `pulumi:"createDisposition"`
	// Custom encryption configuration (e.g., Cloud KMS keys)
	// Structure is documented below.
	DestinationEncryptionConfiguration *JobCopyDestinationEncryptionConfiguration `pulumi:"destinationEncryptionConfiguration"`
	// The destination table.
	// Structure is documented below.
	DestinationTable *JobCopyDestinationTable `pulumi:"destinationTable"`
	// Source tables to copy.
	// Structure is documented below.
	SourceTables []JobCopySourceTable `pulumi:"sourceTables"`
	// Specifies the action that occurs if the destination table already exists. The following values are supported:
	// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
	// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
	// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
	// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
	// Creation, truncation and append actions occur as one atomic update upon job completion.
	// Default value is `WRITE_EMPTY`.
	// Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
	WriteDisposition *string `pulumi:"writeDisposition"`
}

// JobCopyInput is an input type that accepts JobCopyArgs and JobCopyOutput values.
// You can construct a concrete instance of `JobCopyInput` via:
//
// 		 JobCopyArgs{...}
//
type JobCopyInput interface {
	pulumi.Input

	ToJobCopyOutput() JobCopyOutput
	ToJobCopyOutputWithContext(context.Context) JobCopyOutput
}

type JobCopyArgs struct {
	// Specifies whether the job is allowed to create new tables. The following values are supported:
	// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
	// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
	// Creation, truncation and append actions occur as one atomic update upon job completion
	// Default value is `CREATE_IF_NEEDED`.
	// Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
	CreateDisposition pulumi.StringPtrInput `pulumi:"createDisposition"`
	// Custom encryption configuration (e.g., Cloud KMS keys)
	// Structure is documented below.
	DestinationEncryptionConfiguration JobCopyDestinationEncryptionConfigurationPtrInput `pulumi:"destinationEncryptionConfiguration"`
	// The destination table.
	// Structure is documented below.
	DestinationTable JobCopyDestinationTablePtrInput `pulumi:"destinationTable"`
	// Source tables to copy.
	// Structure is documented below.
	SourceTables JobCopySourceTableArrayInput `pulumi:"sourceTables"`
	// Specifies the action that occurs if the destination table already exists. The following values are supported:
	// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
	// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
	// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
	// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
	// Creation, truncation and append actions occur as one atomic update upon job completion.
	// Default value is `WRITE_EMPTY`.
	// Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
	WriteDisposition pulumi.StringPtrInput `pulumi:"writeDisposition"`
}

func (JobCopyArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobCopy)(nil)).Elem()
}

func (i JobCopyArgs) ToJobCopyOutput() JobCopyOutput {
	return i.ToJobCopyOutputWithContext(context.Background())
}

func (i JobCopyArgs) ToJobCopyOutputWithContext(ctx context.Context) JobCopyOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobCopyOutput)
}

func (i JobCopyArgs) ToJobCopyPtrOutput() JobCopyPtrOutput {
	return i.ToJobCopyPtrOutputWithContext(context.Background())
}

func (i JobCopyArgs) ToJobCopyPtrOutputWithContext(ctx context.Context) JobCopyPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobCopyOutput).ToJobCopyPtrOutputWithContext(ctx)
}

// JobCopyPtrInput is an input type that accepts JobCopyArgs, JobCopyPtr and JobCopyPtrOutput values.
// You can construct a concrete instance of `JobCopyPtrInput` via:
//
// 		 JobCopyArgs{...}
//
//  or:
//
// 		 nil
//
type JobCopyPtrInput interface {
	pulumi.Input

	ToJobCopyPtrOutput() JobCopyPtrOutput
	ToJobCopyPtrOutputWithContext(context.Context) JobCopyPtrOutput
}

type jobCopyPtrType JobCopyArgs

func JobCopyPtr(v *JobCopyArgs) JobCopyPtrInput {
	return (*jobCopyPtrType)(v)
}

func (*jobCopyPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobCopy)(nil)).Elem()
}

func (i *jobCopyPtrType) ToJobCopyPtrOutput() JobCopyPtrOutput {
	return i.ToJobCopyPtrOutputWithContext(context.Background())
}

func (i *jobCopyPtrType) ToJobCopyPtrOutputWithContext(ctx context.Context) JobCopyPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobCopyPtrOutput)
}

type JobCopyOutput struct{ *pulumi.OutputState }

func (JobCopyOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobCopy)(nil)).Elem()
}

func (o JobCopyOutput) ToJobCopyOutput() JobCopyOutput {
	return o
}

func (o JobCopyOutput) ToJobCopyOutputWithContext(ctx context.Context) JobCopyOutput {
	return o
}

func (o JobCopyOutput) ToJobCopyPtrOutput() JobCopyPtrOutput {
	return o.ToJobCopyPtrOutputWithContext(context.Background())
}

func (o JobCopyOutput) ToJobCopyPtrOutputWithContext(ctx context.Context) JobCopyPtrOutput {
	return o.ApplyT(func(v JobCopy) *JobCopy {
		return &v
	}).(JobCopyPtrOutput)
}

// Specifies whether the job is allowed to create new tables. The following values are supported:
// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
// Creation, truncation and append actions occur as one atomic update upon job completion
// Default value is `CREATE_IF_NEEDED`.
// Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
func (o JobCopyOutput) CreateDisposition() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobCopy) *string { return v.CreateDisposition }).(pulumi.StringPtrOutput)
}

// Custom encryption configuration (e.g., Cloud KMS keys)
// Structure is documented below.
func (o JobCopyOutput) DestinationEncryptionConfiguration() JobCopyDestinationEncryptionConfigurationPtrOutput {
	return o.ApplyT(func(v JobCopy) *JobCopyDestinationEncryptionConfiguration {
		return v.DestinationEncryptionConfiguration
	}).(JobCopyDestinationEncryptionConfigurationPtrOutput)
}

// The destination table.
// Structure is documented below.
func (o JobCopyOutput) DestinationTable() JobCopyDestinationTablePtrOutput {
	return o.ApplyT(func(v JobCopy) *JobCopyDestinationTable { return v.DestinationTable }).(JobCopyDestinationTablePtrOutput)
}

// Source tables to copy.
// Structure is documented below.
func (o JobCopyOutput) SourceTables() JobCopySourceTableArrayOutput {
	return o.ApplyT(func(v JobCopy) []JobCopySourceTable { return v.SourceTables }).(JobCopySourceTableArrayOutput)
}

// Specifies the action that occurs if the destination table already exists. The following values are supported:
// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
// Creation, truncation and append actions occur as one atomic update upon job completion.
// Default value is `WRITE_EMPTY`.
// Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
func (o JobCopyOutput) WriteDisposition() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobCopy) *string { return v.WriteDisposition }).(pulumi.StringPtrOutput)
}

type JobCopyPtrOutput struct{ *pulumi.OutputState }

func (JobCopyPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobCopy)(nil)).Elem()
}

func (o JobCopyPtrOutput) ToJobCopyPtrOutput() JobCopyPtrOutput {
	return o
}

func (o JobCopyPtrOutput) ToJobCopyPtrOutputWithContext(ctx context.Context) JobCopyPtrOutput {
	return o
}

func (o JobCopyPtrOutput) Elem() JobCopyOutput {
	return o.ApplyT(func(v *JobCopy) JobCopy { return *v }).(JobCopyOutput)
}

// Specifies whether the job is allowed to create new tables. The following values are supported:
// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
// Creation, truncation and append actions occur as one atomic update upon job completion
// Default value is `CREATE_IF_NEEDED`.
// Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
func (o JobCopyPtrOutput) CreateDisposition() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobCopy) *string {
		if v == nil {
			return nil
		}
		return v.CreateDisposition
	}).(pulumi.StringPtrOutput)
}

// Custom encryption configuration (e.g., Cloud KMS keys)
// Structure is documented below.
func (o JobCopyPtrOutput) DestinationEncryptionConfiguration() JobCopyDestinationEncryptionConfigurationPtrOutput {
	return o.ApplyT(func(v *JobCopy) *JobCopyDestinationEncryptionConfiguration {
		if v == nil {
			return nil
		}
		return v.DestinationEncryptionConfiguration
	}).(JobCopyDestinationEncryptionConfigurationPtrOutput)
}

// The destination table.
// Structure is documented below.
func (o JobCopyPtrOutput) DestinationTable() JobCopyDestinationTablePtrOutput {
	return o.ApplyT(func(v *JobCopy) *JobCopyDestinationTable {
		if v == nil {
			return nil
		}
		return v.DestinationTable
	}).(JobCopyDestinationTablePtrOutput)
}

// Source tables to copy.
// Structure is documented below.
func (o JobCopyPtrOutput) SourceTables() JobCopySourceTableArrayOutput {
	return o.ApplyT(func(v *JobCopy) []JobCopySourceTable {
		if v == nil {
			return nil
		}
		return v.SourceTables
	}).(JobCopySourceTableArrayOutput)
}

// Specifies the action that occurs if the destination table already exists. The following values are supported:
// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
// Creation, truncation and append actions occur as one atomic update upon job completion.
// Default value is `WRITE_EMPTY`.
// Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
func (o JobCopyPtrOutput) WriteDisposition() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobCopy) *string {
		if v == nil {
			return nil
		}
		return v.WriteDisposition
	}).(pulumi.StringPtrOutput)
}

type JobCopyDestinationEncryptionConfiguration struct {
	// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
	// The BigQuery Service Account associated with your project requires access to this encryption key.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// JobCopyDestinationEncryptionConfigurationInput is an input type that accepts JobCopyDestinationEncryptionConfigurationArgs and JobCopyDestinationEncryptionConfigurationOutput values.
// You can construct a concrete instance of `JobCopyDestinationEncryptionConfigurationInput` via:
//
// 		 JobCopyDestinationEncryptionConfigurationArgs{...}
//
type JobCopyDestinationEncryptionConfigurationInput interface {
	pulumi.Input

	ToJobCopyDestinationEncryptionConfigurationOutput() JobCopyDestinationEncryptionConfigurationOutput
	ToJobCopyDestinationEncryptionConfigurationOutputWithContext(context.Context) JobCopyDestinationEncryptionConfigurationOutput
}

type JobCopyDestinationEncryptionConfigurationArgs struct {
	// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
	// The BigQuery Service Account associated with your project requires access to this encryption key.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (JobCopyDestinationEncryptionConfigurationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobCopyDestinationEncryptionConfiguration)(nil)).Elem()
}

func (i JobCopyDestinationEncryptionConfigurationArgs) ToJobCopyDestinationEncryptionConfigurationOutput() JobCopyDestinationEncryptionConfigurationOutput {
	return i.ToJobCopyDestinationEncryptionConfigurationOutputWithContext(context.Background())
}

func (i JobCopyDestinationEncryptionConfigurationArgs) ToJobCopyDestinationEncryptionConfigurationOutputWithContext(ctx context.Context) JobCopyDestinationEncryptionConfigurationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobCopyDestinationEncryptionConfigurationOutput)
}

func (i JobCopyDestinationEncryptionConfigurationArgs) ToJobCopyDestinationEncryptionConfigurationPtrOutput() JobCopyDestinationEncryptionConfigurationPtrOutput {
	return i.ToJobCopyDestinationEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (i JobCopyDestinationEncryptionConfigurationArgs) ToJobCopyDestinationEncryptionConfigurationPtrOutputWithContext(ctx context.Context) JobCopyDestinationEncryptionConfigurationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobCopyDestinationEncryptionConfigurationOutput).ToJobCopyDestinationEncryptionConfigurationPtrOutputWithContext(ctx)
}

// JobCopyDestinationEncryptionConfigurationPtrInput is an input type that accepts JobCopyDestinationEncryptionConfigurationArgs, JobCopyDestinationEncryptionConfigurationPtr and JobCopyDestinationEncryptionConfigurationPtrOutput values.
// You can construct a concrete instance of `JobCopyDestinationEncryptionConfigurationPtrInput` via:
//
// 		 JobCopyDestinationEncryptionConfigurationArgs{...}
//
//  or:
//
// 		 nil
//
type JobCopyDestinationEncryptionConfigurationPtrInput interface {
	pulumi.Input

	ToJobCopyDestinationEncryptionConfigurationPtrOutput() JobCopyDestinationEncryptionConfigurationPtrOutput
	ToJobCopyDestinationEncryptionConfigurationPtrOutputWithContext(context.Context) JobCopyDestinationEncryptionConfigurationPtrOutput
}

type jobCopyDestinationEncryptionConfigurationPtrType JobCopyDestinationEncryptionConfigurationArgs

func JobCopyDestinationEncryptionConfigurationPtr(v *JobCopyDestinationEncryptionConfigurationArgs) JobCopyDestinationEncryptionConfigurationPtrInput {
	return (*jobCopyDestinationEncryptionConfigurationPtrType)(v)
}

func (*jobCopyDestinationEncryptionConfigurationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobCopyDestinationEncryptionConfiguration)(nil)).Elem()
}

func (i *jobCopyDestinationEncryptionConfigurationPtrType) ToJobCopyDestinationEncryptionConfigurationPtrOutput() JobCopyDestinationEncryptionConfigurationPtrOutput {
	return i.ToJobCopyDestinationEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (i *jobCopyDestinationEncryptionConfigurationPtrType) ToJobCopyDestinationEncryptionConfigurationPtrOutputWithContext(ctx context.Context) JobCopyDestinationEncryptionConfigurationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobCopyDestinationEncryptionConfigurationPtrOutput)
}

type JobCopyDestinationEncryptionConfigurationOutput struct{ *pulumi.OutputState }

func (JobCopyDestinationEncryptionConfigurationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobCopyDestinationEncryptionConfiguration)(nil)).Elem()
}

func (o JobCopyDestinationEncryptionConfigurationOutput) ToJobCopyDestinationEncryptionConfigurationOutput() JobCopyDestinationEncryptionConfigurationOutput {
	return o
}

func (o JobCopyDestinationEncryptionConfigurationOutput) ToJobCopyDestinationEncryptionConfigurationOutputWithContext(ctx context.Context) JobCopyDestinationEncryptionConfigurationOutput {
	return o
}

func (o JobCopyDestinationEncryptionConfigurationOutput) ToJobCopyDestinationEncryptionConfigurationPtrOutput() JobCopyDestinationEncryptionConfigurationPtrOutput {
	return o.ToJobCopyDestinationEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (o JobCopyDestinationEncryptionConfigurationOutput) ToJobCopyDestinationEncryptionConfigurationPtrOutputWithContext(ctx context.Context) JobCopyDestinationEncryptionConfigurationPtrOutput {
	return o.ApplyT(func(v JobCopyDestinationEncryptionConfiguration) *JobCopyDestinationEncryptionConfiguration {
		return &v
	}).(JobCopyDestinationEncryptionConfigurationPtrOutput)
}

// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
// The BigQuery Service Account associated with your project requires access to this encryption key.
func (o JobCopyDestinationEncryptionConfigurationOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v JobCopyDestinationEncryptionConfiguration) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type JobCopyDestinationEncryptionConfigurationPtrOutput struct{ *pulumi.OutputState }

func (JobCopyDestinationEncryptionConfigurationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobCopyDestinationEncryptionConfiguration)(nil)).Elem()
}

func (o JobCopyDestinationEncryptionConfigurationPtrOutput) ToJobCopyDestinationEncryptionConfigurationPtrOutput() JobCopyDestinationEncryptionConfigurationPtrOutput {
	return o
}

func (o JobCopyDestinationEncryptionConfigurationPtrOutput) ToJobCopyDestinationEncryptionConfigurationPtrOutputWithContext(ctx context.Context) JobCopyDestinationEncryptionConfigurationPtrOutput {
	return o
}

func (o JobCopyDestinationEncryptionConfigurationPtrOutput) Elem() JobCopyDestinationEncryptionConfigurationOutput {
	return o.ApplyT(func(v *JobCopyDestinationEncryptionConfiguration) JobCopyDestinationEncryptionConfiguration {
		return *v
	}).(JobCopyDestinationEncryptionConfigurationOutput)
}

// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
// The BigQuery Service Account associated with your project requires access to this encryption key.
func (o JobCopyDestinationEncryptionConfigurationPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobCopyDestinationEncryptionConfiguration) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type JobCopyDestinationTable struct {
	// The ID of the dataset containing this model.
	DatasetId *string `pulumi:"datasetId"`
	// The ID of the project containing this model.
	ProjectId *string `pulumi:"projectId"`
	// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
	// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
	TableId string `pulumi:"tableId"`
}

// JobCopyDestinationTableInput is an input type that accepts JobCopyDestinationTableArgs and JobCopyDestinationTableOutput values.
// You can construct a concrete instance of `JobCopyDestinationTableInput` via:
//
// 		 JobCopyDestinationTableArgs{...}
//
type JobCopyDestinationTableInput interface {
	pulumi.Input

	ToJobCopyDestinationTableOutput() JobCopyDestinationTableOutput
	ToJobCopyDestinationTableOutputWithContext(context.Context) JobCopyDestinationTableOutput
}

type JobCopyDestinationTableArgs struct {
	// The ID of the dataset containing this model.
	DatasetId pulumi.StringPtrInput `pulumi:"datasetId"`
	// The ID of the project containing this model.
	ProjectId pulumi.StringPtrInput `pulumi:"projectId"`
	// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
	// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
	TableId pulumi.StringInput `pulumi:"tableId"`
}

func (JobCopyDestinationTableArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobCopyDestinationTable)(nil)).Elem()
}

func (i JobCopyDestinationTableArgs) ToJobCopyDestinationTableOutput() JobCopyDestinationTableOutput {
	return i.ToJobCopyDestinationTableOutputWithContext(context.Background())
}

func (i JobCopyDestinationTableArgs) ToJobCopyDestinationTableOutputWithContext(ctx context.Context) JobCopyDestinationTableOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobCopyDestinationTableOutput)
}

func (i JobCopyDestinationTableArgs) ToJobCopyDestinationTablePtrOutput() JobCopyDestinationTablePtrOutput {
	return i.ToJobCopyDestinationTablePtrOutputWithContext(context.Background())
}

func (i JobCopyDestinationTableArgs) ToJobCopyDestinationTablePtrOutputWithContext(ctx context.Context) JobCopyDestinationTablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobCopyDestinationTableOutput).ToJobCopyDestinationTablePtrOutputWithContext(ctx)
}

// JobCopyDestinationTablePtrInput is an input type that accepts JobCopyDestinationTableArgs, JobCopyDestinationTablePtr and JobCopyDestinationTablePtrOutput values.
// You can construct a concrete instance of `JobCopyDestinationTablePtrInput` via:
//
// 		 JobCopyDestinationTableArgs{...}
//
//  or:
//
// 		 nil
//
type JobCopyDestinationTablePtrInput interface {
	pulumi.Input

	ToJobCopyDestinationTablePtrOutput() JobCopyDestinationTablePtrOutput
	ToJobCopyDestinationTablePtrOutputWithContext(context.Context) JobCopyDestinationTablePtrOutput
}

type jobCopyDestinationTablePtrType JobCopyDestinationTableArgs

func JobCopyDestinationTablePtr(v *JobCopyDestinationTableArgs) JobCopyDestinationTablePtrInput {
	return (*jobCopyDestinationTablePtrType)(v)
}

func (*jobCopyDestinationTablePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobCopyDestinationTable)(nil)).Elem()
}

func (i *jobCopyDestinationTablePtrType) ToJobCopyDestinationTablePtrOutput() JobCopyDestinationTablePtrOutput {
	return i.ToJobCopyDestinationTablePtrOutputWithContext(context.Background())
}

func (i *jobCopyDestinationTablePtrType) ToJobCopyDestinationTablePtrOutputWithContext(ctx context.Context) JobCopyDestinationTablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobCopyDestinationTablePtrOutput)
}

type JobCopyDestinationTableOutput struct{ *pulumi.OutputState }

func (JobCopyDestinationTableOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobCopyDestinationTable)(nil)).Elem()
}

func (o JobCopyDestinationTableOutput) ToJobCopyDestinationTableOutput() JobCopyDestinationTableOutput {
	return o
}

func (o JobCopyDestinationTableOutput) ToJobCopyDestinationTableOutputWithContext(ctx context.Context) JobCopyDestinationTableOutput {
	return o
}

func (o JobCopyDestinationTableOutput) ToJobCopyDestinationTablePtrOutput() JobCopyDestinationTablePtrOutput {
	return o.ToJobCopyDestinationTablePtrOutputWithContext(context.Background())
}

func (o JobCopyDestinationTableOutput) ToJobCopyDestinationTablePtrOutputWithContext(ctx context.Context) JobCopyDestinationTablePtrOutput {
	return o.ApplyT(func(v JobCopyDestinationTable) *JobCopyDestinationTable {
		return &v
	}).(JobCopyDestinationTablePtrOutput)
}

// The ID of the dataset containing this model.
func (o JobCopyDestinationTableOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobCopyDestinationTable) *string { return v.DatasetId }).(pulumi.StringPtrOutput)
}

// The ID of the project containing this model.
func (o JobCopyDestinationTableOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobCopyDestinationTable) *string { return v.ProjectId }).(pulumi.StringPtrOutput)
}

// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
func (o JobCopyDestinationTableOutput) TableId() pulumi.StringOutput {
	return o.ApplyT(func(v JobCopyDestinationTable) string { return v.TableId }).(pulumi.StringOutput)
}

type JobCopyDestinationTablePtrOutput struct{ *pulumi.OutputState }

func (JobCopyDestinationTablePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobCopyDestinationTable)(nil)).Elem()
}

func (o JobCopyDestinationTablePtrOutput) ToJobCopyDestinationTablePtrOutput() JobCopyDestinationTablePtrOutput {
	return o
}

func (o JobCopyDestinationTablePtrOutput) ToJobCopyDestinationTablePtrOutputWithContext(ctx context.Context) JobCopyDestinationTablePtrOutput {
	return o
}

func (o JobCopyDestinationTablePtrOutput) Elem() JobCopyDestinationTableOutput {
	return o.ApplyT(func(v *JobCopyDestinationTable) JobCopyDestinationTable { return *v }).(JobCopyDestinationTableOutput)
}

// The ID of the dataset containing this model.
func (o JobCopyDestinationTablePtrOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobCopyDestinationTable) *string {
		if v == nil {
			return nil
		}
		return v.DatasetId
	}).(pulumi.StringPtrOutput)
}

// The ID of the project containing this model.
func (o JobCopyDestinationTablePtrOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobCopyDestinationTable) *string {
		if v == nil {
			return nil
		}
		return v.ProjectId
	}).(pulumi.StringPtrOutput)
}

// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
func (o JobCopyDestinationTablePtrOutput) TableId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobCopyDestinationTable) *string {
		if v == nil {
			return nil
		}
		return &v.TableId
	}).(pulumi.StringPtrOutput)
}

type JobCopySourceTable struct {
	// The ID of the dataset containing this model.
	DatasetId *string `pulumi:"datasetId"`
	// The ID of the project containing this model.
	ProjectId *string `pulumi:"projectId"`
	// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
	// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
	TableId string `pulumi:"tableId"`
}

// JobCopySourceTableInput is an input type that accepts JobCopySourceTableArgs and JobCopySourceTableOutput values.
// You can construct a concrete instance of `JobCopySourceTableInput` via:
//
// 		 JobCopySourceTableArgs{...}
//
type JobCopySourceTableInput interface {
	pulumi.Input

	ToJobCopySourceTableOutput() JobCopySourceTableOutput
	ToJobCopySourceTableOutputWithContext(context.Context) JobCopySourceTableOutput
}

type JobCopySourceTableArgs struct {
	// The ID of the dataset containing this model.
	DatasetId pulumi.StringPtrInput `pulumi:"datasetId"`
	// The ID of the project containing this model.
	ProjectId pulumi.StringPtrInput `pulumi:"projectId"`
	// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
	// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
	TableId pulumi.StringInput `pulumi:"tableId"`
}

func (JobCopySourceTableArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobCopySourceTable)(nil)).Elem()
}

func (i JobCopySourceTableArgs) ToJobCopySourceTableOutput() JobCopySourceTableOutput {
	return i.ToJobCopySourceTableOutputWithContext(context.Background())
}

func (i JobCopySourceTableArgs) ToJobCopySourceTableOutputWithContext(ctx context.Context) JobCopySourceTableOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobCopySourceTableOutput)
}

// JobCopySourceTableArrayInput is an input type that accepts JobCopySourceTableArray and JobCopySourceTableArrayOutput values.
// You can construct a concrete instance of `JobCopySourceTableArrayInput` via:
//
// 		 JobCopySourceTableArray{ JobCopySourceTableArgs{...} }
//
type JobCopySourceTableArrayInput interface {
	pulumi.Input

	ToJobCopySourceTableArrayOutput() JobCopySourceTableArrayOutput
	ToJobCopySourceTableArrayOutputWithContext(context.Context) JobCopySourceTableArrayOutput
}

type JobCopySourceTableArray []JobCopySourceTableInput

func (JobCopySourceTableArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]JobCopySourceTable)(nil)).Elem()
}

func (i JobCopySourceTableArray) ToJobCopySourceTableArrayOutput() JobCopySourceTableArrayOutput {
	return i.ToJobCopySourceTableArrayOutputWithContext(context.Background())
}

func (i JobCopySourceTableArray) ToJobCopySourceTableArrayOutputWithContext(ctx context.Context) JobCopySourceTableArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobCopySourceTableArrayOutput)
}

type JobCopySourceTableOutput struct{ *pulumi.OutputState }

func (JobCopySourceTableOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobCopySourceTable)(nil)).Elem()
}

func (o JobCopySourceTableOutput) ToJobCopySourceTableOutput() JobCopySourceTableOutput {
	return o
}

func (o JobCopySourceTableOutput) ToJobCopySourceTableOutputWithContext(ctx context.Context) JobCopySourceTableOutput {
	return o
}

// The ID of the dataset containing this model.
func (o JobCopySourceTableOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobCopySourceTable) *string { return v.DatasetId }).(pulumi.StringPtrOutput)
}

// The ID of the project containing this model.
func (o JobCopySourceTableOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobCopySourceTable) *string { return v.ProjectId }).(pulumi.StringPtrOutput)
}

// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
func (o JobCopySourceTableOutput) TableId() pulumi.StringOutput {
	return o.ApplyT(func(v JobCopySourceTable) string { return v.TableId }).(pulumi.StringOutput)
}

type JobCopySourceTableArrayOutput struct{ *pulumi.OutputState }

func (JobCopySourceTableArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]JobCopySourceTable)(nil)).Elem()
}

func (o JobCopySourceTableArrayOutput) ToJobCopySourceTableArrayOutput() JobCopySourceTableArrayOutput {
	return o
}

func (o JobCopySourceTableArrayOutput) ToJobCopySourceTableArrayOutputWithContext(ctx context.Context) JobCopySourceTableArrayOutput {
	return o
}

func (o JobCopySourceTableArrayOutput) Index(i pulumi.IntInput) JobCopySourceTableOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) JobCopySourceTable {
		return vs[0].([]JobCopySourceTable)[vs[1].(int)]
	}).(JobCopySourceTableOutput)
}

type JobExtract struct {
	// The compression type to use for exported files. Possible values include GZIP, DEFLATE, SNAPPY, and NONE.
	// The default value is NONE. DEFLATE and SNAPPY are only supported for Avro.
	Compression *string `pulumi:"compression"`
	// The exported file format. Possible values include CSV, NEWLINE_DELIMITED_JSON and AVRO for tables and SAVED_MODEL for models.
	// The default value for tables is CSV. Tables with nested or repeated fields cannot be exported as CSV.
	// The default value for models is SAVED_MODEL.
	DestinationFormat *string `pulumi:"destinationFormat"`
	// A list of fully-qualified Google Cloud Storage URIs where the extracted table should be written.
	DestinationUris []string `pulumi:"destinationUris"`
	// When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
	// Default is ','
	FieldDelimiter *string `pulumi:"fieldDelimiter"`
	// Whether to print out a header row in the results. Default is true.
	PrintHeader *bool `pulumi:"printHeader"`
	// A reference to the model being exported.
	// Structure is documented below.
	SourceModel *JobExtractSourceModel `pulumi:"sourceModel"`
	// A reference to the table being exported.
	// Structure is documented below.
	SourceTable *JobExtractSourceTable `pulumi:"sourceTable"`
	// Whether to use logical types when extracting to AVRO format.
	UseAvroLogicalTypes *bool `pulumi:"useAvroLogicalTypes"`
}

// JobExtractInput is an input type that accepts JobExtractArgs and JobExtractOutput values.
// You can construct a concrete instance of `JobExtractInput` via:
//
// 		 JobExtractArgs{...}
//
type JobExtractInput interface {
	pulumi.Input

	ToJobExtractOutput() JobExtractOutput
	ToJobExtractOutputWithContext(context.Context) JobExtractOutput
}

type JobExtractArgs struct {
	// The compression type to use for exported files. Possible values include GZIP, DEFLATE, SNAPPY, and NONE.
	// The default value is NONE. DEFLATE and SNAPPY are only supported for Avro.
	Compression pulumi.StringPtrInput `pulumi:"compression"`
	// The exported file format. Possible values include CSV, NEWLINE_DELIMITED_JSON and AVRO for tables and SAVED_MODEL for models.
	// The default value for tables is CSV. Tables with nested or repeated fields cannot be exported as CSV.
	// The default value for models is SAVED_MODEL.
	DestinationFormat pulumi.StringPtrInput `pulumi:"destinationFormat"`
	// A list of fully-qualified Google Cloud Storage URIs where the extracted table should be written.
	DestinationUris pulumi.StringArrayInput `pulumi:"destinationUris"`
	// When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
	// Default is ','
	FieldDelimiter pulumi.StringPtrInput `pulumi:"fieldDelimiter"`
	// Whether to print out a header row in the results. Default is true.
	PrintHeader pulumi.BoolPtrInput `pulumi:"printHeader"`
	// A reference to the model being exported.
	// Structure is documented below.
	SourceModel JobExtractSourceModelPtrInput `pulumi:"sourceModel"`
	// A reference to the table being exported.
	// Structure is documented below.
	SourceTable JobExtractSourceTablePtrInput `pulumi:"sourceTable"`
	// Whether to use logical types when extracting to AVRO format.
	UseAvroLogicalTypes pulumi.BoolPtrInput `pulumi:"useAvroLogicalTypes"`
}

func (JobExtractArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobExtract)(nil)).Elem()
}

func (i JobExtractArgs) ToJobExtractOutput() JobExtractOutput {
	return i.ToJobExtractOutputWithContext(context.Background())
}

func (i JobExtractArgs) ToJobExtractOutputWithContext(ctx context.Context) JobExtractOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobExtractOutput)
}

func (i JobExtractArgs) ToJobExtractPtrOutput() JobExtractPtrOutput {
	return i.ToJobExtractPtrOutputWithContext(context.Background())
}

func (i JobExtractArgs) ToJobExtractPtrOutputWithContext(ctx context.Context) JobExtractPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobExtractOutput).ToJobExtractPtrOutputWithContext(ctx)
}

// JobExtractPtrInput is an input type that accepts JobExtractArgs, JobExtractPtr and JobExtractPtrOutput values.
// You can construct a concrete instance of `JobExtractPtrInput` via:
//
// 		 JobExtractArgs{...}
//
//  or:
//
// 		 nil
//
type JobExtractPtrInput interface {
	pulumi.Input

	ToJobExtractPtrOutput() JobExtractPtrOutput
	ToJobExtractPtrOutputWithContext(context.Context) JobExtractPtrOutput
}

type jobExtractPtrType JobExtractArgs

func JobExtractPtr(v *JobExtractArgs) JobExtractPtrInput {
	return (*jobExtractPtrType)(v)
}

func (*jobExtractPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobExtract)(nil)).Elem()
}

func (i *jobExtractPtrType) ToJobExtractPtrOutput() JobExtractPtrOutput {
	return i.ToJobExtractPtrOutputWithContext(context.Background())
}

func (i *jobExtractPtrType) ToJobExtractPtrOutputWithContext(ctx context.Context) JobExtractPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobExtractPtrOutput)
}

type JobExtractOutput struct{ *pulumi.OutputState }

func (JobExtractOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobExtract)(nil)).Elem()
}

func (o JobExtractOutput) ToJobExtractOutput() JobExtractOutput {
	return o
}

func (o JobExtractOutput) ToJobExtractOutputWithContext(ctx context.Context) JobExtractOutput {
	return o
}

func (o JobExtractOutput) ToJobExtractPtrOutput() JobExtractPtrOutput {
	return o.ToJobExtractPtrOutputWithContext(context.Background())
}

func (o JobExtractOutput) ToJobExtractPtrOutputWithContext(ctx context.Context) JobExtractPtrOutput {
	return o.ApplyT(func(v JobExtract) *JobExtract {
		return &v
	}).(JobExtractPtrOutput)
}

// The compression type to use for exported files. Possible values include GZIP, DEFLATE, SNAPPY, and NONE.
// The default value is NONE. DEFLATE and SNAPPY are only supported for Avro.
func (o JobExtractOutput) Compression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobExtract) *string { return v.Compression }).(pulumi.StringPtrOutput)
}

// The exported file format. Possible values include CSV, NEWLINE_DELIMITED_JSON and AVRO for tables and SAVED_MODEL for models.
// The default value for tables is CSV. Tables with nested or repeated fields cannot be exported as CSV.
// The default value for models is SAVED_MODEL.
func (o JobExtractOutput) DestinationFormat() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobExtract) *string { return v.DestinationFormat }).(pulumi.StringPtrOutput)
}

// A list of fully-qualified Google Cloud Storage URIs where the extracted table should be written.
func (o JobExtractOutput) DestinationUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobExtract) []string { return v.DestinationUris }).(pulumi.StringArrayOutput)
}

// When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
// Default is ','
func (o JobExtractOutput) FieldDelimiter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobExtract) *string { return v.FieldDelimiter }).(pulumi.StringPtrOutput)
}

// Whether to print out a header row in the results. Default is true.
func (o JobExtractOutput) PrintHeader() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v JobExtract) *bool { return v.PrintHeader }).(pulumi.BoolPtrOutput)
}

// A reference to the model being exported.
// Structure is documented below.
func (o JobExtractOutput) SourceModel() JobExtractSourceModelPtrOutput {
	return o.ApplyT(func(v JobExtract) *JobExtractSourceModel { return v.SourceModel }).(JobExtractSourceModelPtrOutput)
}

// A reference to the table being exported.
// Structure is documented below.
func (o JobExtractOutput) SourceTable() JobExtractSourceTablePtrOutput {
	return o.ApplyT(func(v JobExtract) *JobExtractSourceTable { return v.SourceTable }).(JobExtractSourceTablePtrOutput)
}

// Whether to use logical types when extracting to AVRO format.
func (o JobExtractOutput) UseAvroLogicalTypes() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v JobExtract) *bool { return v.UseAvroLogicalTypes }).(pulumi.BoolPtrOutput)
}

type JobExtractPtrOutput struct{ *pulumi.OutputState }

func (JobExtractPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobExtract)(nil)).Elem()
}

func (o JobExtractPtrOutput) ToJobExtractPtrOutput() JobExtractPtrOutput {
	return o
}

func (o JobExtractPtrOutput) ToJobExtractPtrOutputWithContext(ctx context.Context) JobExtractPtrOutput {
	return o
}

func (o JobExtractPtrOutput) Elem() JobExtractOutput {
	return o.ApplyT(func(v *JobExtract) JobExtract { return *v }).(JobExtractOutput)
}

// The compression type to use for exported files. Possible values include GZIP, DEFLATE, SNAPPY, and NONE.
// The default value is NONE. DEFLATE and SNAPPY are only supported for Avro.
func (o JobExtractPtrOutput) Compression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobExtract) *string {
		if v == nil {
			return nil
		}
		return v.Compression
	}).(pulumi.StringPtrOutput)
}

// The exported file format. Possible values include CSV, NEWLINE_DELIMITED_JSON and AVRO for tables and SAVED_MODEL for models.
// The default value for tables is CSV. Tables with nested or repeated fields cannot be exported as CSV.
// The default value for models is SAVED_MODEL.
func (o JobExtractPtrOutput) DestinationFormat() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobExtract) *string {
		if v == nil {
			return nil
		}
		return v.DestinationFormat
	}).(pulumi.StringPtrOutput)
}

// A list of fully-qualified Google Cloud Storage URIs where the extracted table should be written.
func (o JobExtractPtrOutput) DestinationUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobExtract) []string {
		if v == nil {
			return nil
		}
		return v.DestinationUris
	}).(pulumi.StringArrayOutput)
}

// When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
// Default is ','
func (o JobExtractPtrOutput) FieldDelimiter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobExtract) *string {
		if v == nil {
			return nil
		}
		return v.FieldDelimiter
	}).(pulumi.StringPtrOutput)
}

// Whether to print out a header row in the results. Default is true.
func (o JobExtractPtrOutput) PrintHeader() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *JobExtract) *bool {
		if v == nil {
			return nil
		}
		return v.PrintHeader
	}).(pulumi.BoolPtrOutput)
}

// A reference to the model being exported.
// Structure is documented below.
func (o JobExtractPtrOutput) SourceModel() JobExtractSourceModelPtrOutput {
	return o.ApplyT(func(v *JobExtract) *JobExtractSourceModel {
		if v == nil {
			return nil
		}
		return v.SourceModel
	}).(JobExtractSourceModelPtrOutput)
}

// A reference to the table being exported.
// Structure is documented below.
func (o JobExtractPtrOutput) SourceTable() JobExtractSourceTablePtrOutput {
	return o.ApplyT(func(v *JobExtract) *JobExtractSourceTable {
		if v == nil {
			return nil
		}
		return v.SourceTable
	}).(JobExtractSourceTablePtrOutput)
}

// Whether to use logical types when extracting to AVRO format.
func (o JobExtractPtrOutput) UseAvroLogicalTypes() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *JobExtract) *bool {
		if v == nil {
			return nil
		}
		return v.UseAvroLogicalTypes
	}).(pulumi.BoolPtrOutput)
}

type JobExtractSourceModel struct {
	// The ID of the dataset containing this model.
	DatasetId string `pulumi:"datasetId"`
	// The ID of the model.
	ModelId string `pulumi:"modelId"`
	// The ID of the project containing this model.
	ProjectId string `pulumi:"projectId"`
}

// JobExtractSourceModelInput is an input type that accepts JobExtractSourceModelArgs and JobExtractSourceModelOutput values.
// You can construct a concrete instance of `JobExtractSourceModelInput` via:
//
// 		 JobExtractSourceModelArgs{...}
//
type JobExtractSourceModelInput interface {
	pulumi.Input

	ToJobExtractSourceModelOutput() JobExtractSourceModelOutput
	ToJobExtractSourceModelOutputWithContext(context.Context) JobExtractSourceModelOutput
}

type JobExtractSourceModelArgs struct {
	// The ID of the dataset containing this model.
	DatasetId pulumi.StringInput `pulumi:"datasetId"`
	// The ID of the model.
	ModelId pulumi.StringInput `pulumi:"modelId"`
	// The ID of the project containing this model.
	ProjectId pulumi.StringInput `pulumi:"projectId"`
}

func (JobExtractSourceModelArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobExtractSourceModel)(nil)).Elem()
}

func (i JobExtractSourceModelArgs) ToJobExtractSourceModelOutput() JobExtractSourceModelOutput {
	return i.ToJobExtractSourceModelOutputWithContext(context.Background())
}

func (i JobExtractSourceModelArgs) ToJobExtractSourceModelOutputWithContext(ctx context.Context) JobExtractSourceModelOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobExtractSourceModelOutput)
}

func (i JobExtractSourceModelArgs) ToJobExtractSourceModelPtrOutput() JobExtractSourceModelPtrOutput {
	return i.ToJobExtractSourceModelPtrOutputWithContext(context.Background())
}

func (i JobExtractSourceModelArgs) ToJobExtractSourceModelPtrOutputWithContext(ctx context.Context) JobExtractSourceModelPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobExtractSourceModelOutput).ToJobExtractSourceModelPtrOutputWithContext(ctx)
}

// JobExtractSourceModelPtrInput is an input type that accepts JobExtractSourceModelArgs, JobExtractSourceModelPtr and JobExtractSourceModelPtrOutput values.
// You can construct a concrete instance of `JobExtractSourceModelPtrInput` via:
//
// 		 JobExtractSourceModelArgs{...}
//
//  or:
//
// 		 nil
//
type JobExtractSourceModelPtrInput interface {
	pulumi.Input

	ToJobExtractSourceModelPtrOutput() JobExtractSourceModelPtrOutput
	ToJobExtractSourceModelPtrOutputWithContext(context.Context) JobExtractSourceModelPtrOutput
}

type jobExtractSourceModelPtrType JobExtractSourceModelArgs

func JobExtractSourceModelPtr(v *JobExtractSourceModelArgs) JobExtractSourceModelPtrInput {
	return (*jobExtractSourceModelPtrType)(v)
}

func (*jobExtractSourceModelPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobExtractSourceModel)(nil)).Elem()
}

func (i *jobExtractSourceModelPtrType) ToJobExtractSourceModelPtrOutput() JobExtractSourceModelPtrOutput {
	return i.ToJobExtractSourceModelPtrOutputWithContext(context.Background())
}

func (i *jobExtractSourceModelPtrType) ToJobExtractSourceModelPtrOutputWithContext(ctx context.Context) JobExtractSourceModelPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobExtractSourceModelPtrOutput)
}

type JobExtractSourceModelOutput struct{ *pulumi.OutputState }

func (JobExtractSourceModelOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobExtractSourceModel)(nil)).Elem()
}

func (o JobExtractSourceModelOutput) ToJobExtractSourceModelOutput() JobExtractSourceModelOutput {
	return o
}

func (o JobExtractSourceModelOutput) ToJobExtractSourceModelOutputWithContext(ctx context.Context) JobExtractSourceModelOutput {
	return o
}

func (o JobExtractSourceModelOutput) ToJobExtractSourceModelPtrOutput() JobExtractSourceModelPtrOutput {
	return o.ToJobExtractSourceModelPtrOutputWithContext(context.Background())
}

func (o JobExtractSourceModelOutput) ToJobExtractSourceModelPtrOutputWithContext(ctx context.Context) JobExtractSourceModelPtrOutput {
	return o.ApplyT(func(v JobExtractSourceModel) *JobExtractSourceModel {
		return &v
	}).(JobExtractSourceModelPtrOutput)
}

// The ID of the dataset containing this model.
func (o JobExtractSourceModelOutput) DatasetId() pulumi.StringOutput {
	return o.ApplyT(func(v JobExtractSourceModel) string { return v.DatasetId }).(pulumi.StringOutput)
}

// The ID of the model.
func (o JobExtractSourceModelOutput) ModelId() pulumi.StringOutput {
	return o.ApplyT(func(v JobExtractSourceModel) string { return v.ModelId }).(pulumi.StringOutput)
}

// The ID of the project containing this model.
func (o JobExtractSourceModelOutput) ProjectId() pulumi.StringOutput {
	return o.ApplyT(func(v JobExtractSourceModel) string { return v.ProjectId }).(pulumi.StringOutput)
}

type JobExtractSourceModelPtrOutput struct{ *pulumi.OutputState }

func (JobExtractSourceModelPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobExtractSourceModel)(nil)).Elem()
}

func (o JobExtractSourceModelPtrOutput) ToJobExtractSourceModelPtrOutput() JobExtractSourceModelPtrOutput {
	return o
}

func (o JobExtractSourceModelPtrOutput) ToJobExtractSourceModelPtrOutputWithContext(ctx context.Context) JobExtractSourceModelPtrOutput {
	return o
}

func (o JobExtractSourceModelPtrOutput) Elem() JobExtractSourceModelOutput {
	return o.ApplyT(func(v *JobExtractSourceModel) JobExtractSourceModel { return *v }).(JobExtractSourceModelOutput)
}

// The ID of the dataset containing this model.
func (o JobExtractSourceModelPtrOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobExtractSourceModel) *string {
		if v == nil {
			return nil
		}
		return &v.DatasetId
	}).(pulumi.StringPtrOutput)
}

// The ID of the model.
func (o JobExtractSourceModelPtrOutput) ModelId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobExtractSourceModel) *string {
		if v == nil {
			return nil
		}
		return &v.ModelId
	}).(pulumi.StringPtrOutput)
}

// The ID of the project containing this model.
func (o JobExtractSourceModelPtrOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobExtractSourceModel) *string {
		if v == nil {
			return nil
		}
		return &v.ProjectId
	}).(pulumi.StringPtrOutput)
}

type JobExtractSourceTable struct {
	// The ID of the dataset containing this model.
	DatasetId *string `pulumi:"datasetId"`
	// The ID of the project containing this model.
	ProjectId *string `pulumi:"projectId"`
	// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
	// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
	TableId string `pulumi:"tableId"`
}

// JobExtractSourceTableInput is an input type that accepts JobExtractSourceTableArgs and JobExtractSourceTableOutput values.
// You can construct a concrete instance of `JobExtractSourceTableInput` via:
//
// 		 JobExtractSourceTableArgs{...}
//
type JobExtractSourceTableInput interface {
	pulumi.Input

	ToJobExtractSourceTableOutput() JobExtractSourceTableOutput
	ToJobExtractSourceTableOutputWithContext(context.Context) JobExtractSourceTableOutput
}

type JobExtractSourceTableArgs struct {
	// The ID of the dataset containing this model.
	DatasetId pulumi.StringPtrInput `pulumi:"datasetId"`
	// The ID of the project containing this model.
	ProjectId pulumi.StringPtrInput `pulumi:"projectId"`
	// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
	// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
	TableId pulumi.StringInput `pulumi:"tableId"`
}

func (JobExtractSourceTableArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobExtractSourceTable)(nil)).Elem()
}

func (i JobExtractSourceTableArgs) ToJobExtractSourceTableOutput() JobExtractSourceTableOutput {
	return i.ToJobExtractSourceTableOutputWithContext(context.Background())
}

func (i JobExtractSourceTableArgs) ToJobExtractSourceTableOutputWithContext(ctx context.Context) JobExtractSourceTableOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobExtractSourceTableOutput)
}

func (i JobExtractSourceTableArgs) ToJobExtractSourceTablePtrOutput() JobExtractSourceTablePtrOutput {
	return i.ToJobExtractSourceTablePtrOutputWithContext(context.Background())
}

func (i JobExtractSourceTableArgs) ToJobExtractSourceTablePtrOutputWithContext(ctx context.Context) JobExtractSourceTablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobExtractSourceTableOutput).ToJobExtractSourceTablePtrOutputWithContext(ctx)
}

// JobExtractSourceTablePtrInput is an input type that accepts JobExtractSourceTableArgs, JobExtractSourceTablePtr and JobExtractSourceTablePtrOutput values.
// You can construct a concrete instance of `JobExtractSourceTablePtrInput` via:
//
// 		 JobExtractSourceTableArgs{...}
//
//  or:
//
// 		 nil
//
type JobExtractSourceTablePtrInput interface {
	pulumi.Input

	ToJobExtractSourceTablePtrOutput() JobExtractSourceTablePtrOutput
	ToJobExtractSourceTablePtrOutputWithContext(context.Context) JobExtractSourceTablePtrOutput
}

type jobExtractSourceTablePtrType JobExtractSourceTableArgs

func JobExtractSourceTablePtr(v *JobExtractSourceTableArgs) JobExtractSourceTablePtrInput {
	return (*jobExtractSourceTablePtrType)(v)
}

func (*jobExtractSourceTablePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobExtractSourceTable)(nil)).Elem()
}

func (i *jobExtractSourceTablePtrType) ToJobExtractSourceTablePtrOutput() JobExtractSourceTablePtrOutput {
	return i.ToJobExtractSourceTablePtrOutputWithContext(context.Background())
}

func (i *jobExtractSourceTablePtrType) ToJobExtractSourceTablePtrOutputWithContext(ctx context.Context) JobExtractSourceTablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobExtractSourceTablePtrOutput)
}

type JobExtractSourceTableOutput struct{ *pulumi.OutputState }

func (JobExtractSourceTableOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobExtractSourceTable)(nil)).Elem()
}

func (o JobExtractSourceTableOutput) ToJobExtractSourceTableOutput() JobExtractSourceTableOutput {
	return o
}

func (o JobExtractSourceTableOutput) ToJobExtractSourceTableOutputWithContext(ctx context.Context) JobExtractSourceTableOutput {
	return o
}

func (o JobExtractSourceTableOutput) ToJobExtractSourceTablePtrOutput() JobExtractSourceTablePtrOutput {
	return o.ToJobExtractSourceTablePtrOutputWithContext(context.Background())
}

func (o JobExtractSourceTableOutput) ToJobExtractSourceTablePtrOutputWithContext(ctx context.Context) JobExtractSourceTablePtrOutput {
	return o.ApplyT(func(v JobExtractSourceTable) *JobExtractSourceTable {
		return &v
	}).(JobExtractSourceTablePtrOutput)
}

// The ID of the dataset containing this model.
func (o JobExtractSourceTableOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobExtractSourceTable) *string { return v.DatasetId }).(pulumi.StringPtrOutput)
}

// The ID of the project containing this model.
func (o JobExtractSourceTableOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobExtractSourceTable) *string { return v.ProjectId }).(pulumi.StringPtrOutput)
}

// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
func (o JobExtractSourceTableOutput) TableId() pulumi.StringOutput {
	return o.ApplyT(func(v JobExtractSourceTable) string { return v.TableId }).(pulumi.StringOutput)
}

type JobExtractSourceTablePtrOutput struct{ *pulumi.OutputState }

func (JobExtractSourceTablePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobExtractSourceTable)(nil)).Elem()
}

func (o JobExtractSourceTablePtrOutput) ToJobExtractSourceTablePtrOutput() JobExtractSourceTablePtrOutput {
	return o
}

func (o JobExtractSourceTablePtrOutput) ToJobExtractSourceTablePtrOutputWithContext(ctx context.Context) JobExtractSourceTablePtrOutput {
	return o
}

func (o JobExtractSourceTablePtrOutput) Elem() JobExtractSourceTableOutput {
	return o.ApplyT(func(v *JobExtractSourceTable) JobExtractSourceTable { return *v }).(JobExtractSourceTableOutput)
}

// The ID of the dataset containing this model.
func (o JobExtractSourceTablePtrOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobExtractSourceTable) *string {
		if v == nil {
			return nil
		}
		return v.DatasetId
	}).(pulumi.StringPtrOutput)
}

// The ID of the project containing this model.
func (o JobExtractSourceTablePtrOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobExtractSourceTable) *string {
		if v == nil {
			return nil
		}
		return v.ProjectId
	}).(pulumi.StringPtrOutput)
}

// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
func (o JobExtractSourceTablePtrOutput) TableId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobExtractSourceTable) *string {
		if v == nil {
			return nil
		}
		return &v.TableId
	}).(pulumi.StringPtrOutput)
}

type JobLoad struct {
	// Accept rows that are missing trailing optional columns. The missing values are treated as nulls.
	// If false, records with missing trailing columns are treated as bad records, and if there are too many bad records,
	// an invalid error is returned in the job result. The default value is false. Only applicable to CSV, ignored for other formats.
	AllowJaggedRows *bool `pulumi:"allowJaggedRows"`
	// Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file.
	// The default value is false.
	AllowQuotedNewlines *bool `pulumi:"allowQuotedNewlines"`
	// Indicates if we should automatically infer the options and schema for CSV and JSON sources.
	Autodetect *bool `pulumi:"autodetect"`
	// Specifies whether the job is allowed to create new tables. The following values are supported:
	// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
	// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
	// Creation, truncation and append actions occur as one atomic update upon job completion
	// Default value is `CREATE_IF_NEEDED`.
	// Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
	CreateDisposition *string `pulumi:"createDisposition"`
	// Custom encryption configuration (e.g., Cloud KMS keys)
	// Structure is documented below.
	DestinationEncryptionConfiguration *JobLoadDestinationEncryptionConfiguration `pulumi:"destinationEncryptionConfiguration"`
	// The destination table.
	// Structure is documented below.
	DestinationTable JobLoadDestinationTable `pulumi:"destinationTable"`
	// The character encoding of the data. The supported values are UTF-8 or ISO-8859-1.
	// The default value is UTF-8. BigQuery decodes the data after the raw, binary data
	// has been split using the values of the quote and fieldDelimiter properties.
	Encoding *string `pulumi:"encoding"`
	// When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
	// Default is ','
	FieldDelimiter *string `pulumi:"fieldDelimiter"`
	// Indicates if BigQuery should allow extra values that are not represented in the table schema.
	// If true, the extra values are ignored. If false, records with extra columns are treated as bad records,
	// and if there are too many bad records, an invalid error is returned in the job result.
	// The default value is false. The sourceFormat property determines what BigQuery treats as an extra value:
	// CSV: Trailing columns
	// JSON: Named values that don't match any column names
	IgnoreUnknownValues *bool `pulumi:"ignoreUnknownValues"`
	// The maximum number of bad records that BigQuery can ignore when running the job. If the number of bad records exceeds this value,
	// an invalid error is returned in the job result. The default value is 0, which requires that all records are valid.
	MaxBadRecords *int `pulumi:"maxBadRecords"`
	// Specifies a string that represents a null value in a CSV file. The default value is the empty string. If you set this
	// property to a custom value, BigQuery throws an error if an
	// empty string is present for all data types except for STRING and BYTE. For STRING and BYTE columns, BigQuery interprets the empty string as
	// an empty value.
	NullMarker *string `pulumi:"nullMarker"`
	// If sourceFormat is set to "DATASTORE_BACKUP", indicates which entity properties to load into BigQuery from a Cloud Datastore backup.
	// Property names are case sensitive and must be top-level properties. If no properties are specified, BigQuery loads all properties.
	// If any named property isn't found in the Cloud Datastore backup, an invalid error is returned in the job result.
	ProjectionFields []string `pulumi:"projectionFields"`
	// The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding,
	// and then uses the first byte of the encoded string to split the data in its raw, binary state.
	// The default value is a double-quote ('"'). If your data does not contain quoted sections, set the property value to an empty string.
	// If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true.
	Quote *string `pulumi:"quote"`
	// Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
	// supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
	// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
	// For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
	// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
	// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
	SchemaUpdateOptions []string `pulumi:"schemaUpdateOptions"`
	// The number of rows at the top of a CSV file that BigQuery will skip when loading the data.
	// The default value is 0. This property is useful if you have header rows in the file that should be skipped.
	// When autodetect is on, the behavior is the following:
	// skipLeadingRows unspecified - Autodetect tries to detect headers in the first row. If they are not detected,
	// the row is read as data. Otherwise data is read starting from the second row.
	// skipLeadingRows is 0 - Instructs autodetect that there are no headers and data should be read starting from the first row.
	// skipLeadingRows = N > 0 - Autodetect skips N-1 rows and tries to detect headers in row N. If headers are not detected,
	// row N is just skipped. Otherwise row N is used to extract column names for the detected schema.
	SkipLeadingRows *int `pulumi:"skipLeadingRows"`
	// The format of the data files. For CSV files, specify "CSV". For datastore backups, specify "DATASTORE_BACKUP".
	// For newline-delimited JSON, specify "NEWLINE_DELIMITED_JSON". For Avro, specify "AVRO". For parquet, specify "PARQUET".
	// For orc, specify "ORC". The default value is CSV.
	SourceFormat *string `pulumi:"sourceFormat"`
	// The fully-qualified URIs that point to your data in Google Cloud.
	// For Google Cloud Storage URIs: Each URI can contain one '*' wildcard character
	// and it must come after the 'bucket' name. Size limits related to load jobs apply
	// to external data sources. For Google Cloud Bigtable URIs: Exactly one URI can be
	// specified and it has be a fully specified and valid HTTPS URL for a Google Cloud Bigtable table.
	// For Google Cloud Datastore backups: Exactly one URI can be specified. Also, the '*' wildcard character is not allowed.
	SourceUris []string `pulumi:"sourceUris"`
	// Time-based partitioning specification for the destination table.
	// Structure is documented below.
	TimePartitioning *JobLoadTimePartitioning `pulumi:"timePartitioning"`
	// Specifies the action that occurs if the destination table already exists. The following values are supported:
	// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
	// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
	// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
	// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
	// Creation, truncation and append actions occur as one atomic update upon job completion.
	// Default value is `WRITE_EMPTY`.
	// Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
	WriteDisposition *string `pulumi:"writeDisposition"`
}

// JobLoadInput is an input type that accepts JobLoadArgs and JobLoadOutput values.
// You can construct a concrete instance of `JobLoadInput` via:
//
// 		 JobLoadArgs{...}
//
type JobLoadInput interface {
	pulumi.Input

	ToJobLoadOutput() JobLoadOutput
	ToJobLoadOutputWithContext(context.Context) JobLoadOutput
}

type JobLoadArgs struct {
	// Accept rows that are missing trailing optional columns. The missing values are treated as nulls.
	// If false, records with missing trailing columns are treated as bad records, and if there are too many bad records,
	// an invalid error is returned in the job result. The default value is false. Only applicable to CSV, ignored for other formats.
	AllowJaggedRows pulumi.BoolPtrInput `pulumi:"allowJaggedRows"`
	// Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file.
	// The default value is false.
	AllowQuotedNewlines pulumi.BoolPtrInput `pulumi:"allowQuotedNewlines"`
	// Indicates if we should automatically infer the options and schema for CSV and JSON sources.
	Autodetect pulumi.BoolPtrInput `pulumi:"autodetect"`
	// Specifies whether the job is allowed to create new tables. The following values are supported:
	// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
	// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
	// Creation, truncation and append actions occur as one atomic update upon job completion
	// Default value is `CREATE_IF_NEEDED`.
	// Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
	CreateDisposition pulumi.StringPtrInput `pulumi:"createDisposition"`
	// Custom encryption configuration (e.g., Cloud KMS keys)
	// Structure is documented below.
	DestinationEncryptionConfiguration JobLoadDestinationEncryptionConfigurationPtrInput `pulumi:"destinationEncryptionConfiguration"`
	// The destination table.
	// Structure is documented below.
	DestinationTable JobLoadDestinationTableInput `pulumi:"destinationTable"`
	// The character encoding of the data. The supported values are UTF-8 or ISO-8859-1.
	// The default value is UTF-8. BigQuery decodes the data after the raw, binary data
	// has been split using the values of the quote and fieldDelimiter properties.
	Encoding pulumi.StringPtrInput `pulumi:"encoding"`
	// When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
	// Default is ','
	FieldDelimiter pulumi.StringPtrInput `pulumi:"fieldDelimiter"`
	// Indicates if BigQuery should allow extra values that are not represented in the table schema.
	// If true, the extra values are ignored. If false, records with extra columns are treated as bad records,
	// and if there are too many bad records, an invalid error is returned in the job result.
	// The default value is false. The sourceFormat property determines what BigQuery treats as an extra value:
	// CSV: Trailing columns
	// JSON: Named values that don't match any column names
	IgnoreUnknownValues pulumi.BoolPtrInput `pulumi:"ignoreUnknownValues"`
	// The maximum number of bad records that BigQuery can ignore when running the job. If the number of bad records exceeds this value,
	// an invalid error is returned in the job result. The default value is 0, which requires that all records are valid.
	MaxBadRecords pulumi.IntPtrInput `pulumi:"maxBadRecords"`
	// Specifies a string that represents a null value in a CSV file. The default value is the empty string. If you set this
	// property to a custom value, BigQuery throws an error if an
	// empty string is present for all data types except for STRING and BYTE. For STRING and BYTE columns, BigQuery interprets the empty string as
	// an empty value.
	NullMarker pulumi.StringPtrInput `pulumi:"nullMarker"`
	// If sourceFormat is set to "DATASTORE_BACKUP", indicates which entity properties to load into BigQuery from a Cloud Datastore backup.
	// Property names are case sensitive and must be top-level properties. If no properties are specified, BigQuery loads all properties.
	// If any named property isn't found in the Cloud Datastore backup, an invalid error is returned in the job result.
	ProjectionFields pulumi.StringArrayInput `pulumi:"projectionFields"`
	// The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding,
	// and then uses the first byte of the encoded string to split the data in its raw, binary state.
	// The default value is a double-quote ('"'). If your data does not contain quoted sections, set the property value to an empty string.
	// If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true.
	Quote pulumi.StringPtrInput `pulumi:"quote"`
	// Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
	// supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
	// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
	// For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
	// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
	// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
	SchemaUpdateOptions pulumi.StringArrayInput `pulumi:"schemaUpdateOptions"`
	// The number of rows at the top of a CSV file that BigQuery will skip when loading the data.
	// The default value is 0. This property is useful if you have header rows in the file that should be skipped.
	// When autodetect is on, the behavior is the following:
	// skipLeadingRows unspecified - Autodetect tries to detect headers in the first row. If they are not detected,
	// the row is read as data. Otherwise data is read starting from the second row.
	// skipLeadingRows is 0 - Instructs autodetect that there are no headers and data should be read starting from the first row.
	// skipLeadingRows = N > 0 - Autodetect skips N-1 rows and tries to detect headers in row N. If headers are not detected,
	// row N is just skipped. Otherwise row N is used to extract column names for the detected schema.
	SkipLeadingRows pulumi.IntPtrInput `pulumi:"skipLeadingRows"`
	// The format of the data files. For CSV files, specify "CSV". For datastore backups, specify "DATASTORE_BACKUP".
	// For newline-delimited JSON, specify "NEWLINE_DELIMITED_JSON". For Avro, specify "AVRO". For parquet, specify "PARQUET".
	// For orc, specify "ORC". The default value is CSV.
	SourceFormat pulumi.StringPtrInput `pulumi:"sourceFormat"`
	// The fully-qualified URIs that point to your data in Google Cloud.
	// For Google Cloud Storage URIs: Each URI can contain one '*' wildcard character
	// and it must come after the 'bucket' name. Size limits related to load jobs apply
	// to external data sources. For Google Cloud Bigtable URIs: Exactly one URI can be
	// specified and it has be a fully specified and valid HTTPS URL for a Google Cloud Bigtable table.
	// For Google Cloud Datastore backups: Exactly one URI can be specified. Also, the '*' wildcard character is not allowed.
	SourceUris pulumi.StringArrayInput `pulumi:"sourceUris"`
	// Time-based partitioning specification for the destination table.
	// Structure is documented below.
	TimePartitioning JobLoadTimePartitioningPtrInput `pulumi:"timePartitioning"`
	// Specifies the action that occurs if the destination table already exists. The following values are supported:
	// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
	// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
	// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
	// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
	// Creation, truncation and append actions occur as one atomic update upon job completion.
	// Default value is `WRITE_EMPTY`.
	// Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
	WriteDisposition pulumi.StringPtrInput `pulumi:"writeDisposition"`
}

func (JobLoadArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobLoad)(nil)).Elem()
}

func (i JobLoadArgs) ToJobLoadOutput() JobLoadOutput {
	return i.ToJobLoadOutputWithContext(context.Background())
}

func (i JobLoadArgs) ToJobLoadOutputWithContext(ctx context.Context) JobLoadOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobLoadOutput)
}

func (i JobLoadArgs) ToJobLoadPtrOutput() JobLoadPtrOutput {
	return i.ToJobLoadPtrOutputWithContext(context.Background())
}

func (i JobLoadArgs) ToJobLoadPtrOutputWithContext(ctx context.Context) JobLoadPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobLoadOutput).ToJobLoadPtrOutputWithContext(ctx)
}

// JobLoadPtrInput is an input type that accepts JobLoadArgs, JobLoadPtr and JobLoadPtrOutput values.
// You can construct a concrete instance of `JobLoadPtrInput` via:
//
// 		 JobLoadArgs{...}
//
//  or:
//
// 		 nil
//
type JobLoadPtrInput interface {
	pulumi.Input

	ToJobLoadPtrOutput() JobLoadPtrOutput
	ToJobLoadPtrOutputWithContext(context.Context) JobLoadPtrOutput
}

type jobLoadPtrType JobLoadArgs

func JobLoadPtr(v *JobLoadArgs) JobLoadPtrInput {
	return (*jobLoadPtrType)(v)
}

func (*jobLoadPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobLoad)(nil)).Elem()
}

func (i *jobLoadPtrType) ToJobLoadPtrOutput() JobLoadPtrOutput {
	return i.ToJobLoadPtrOutputWithContext(context.Background())
}

func (i *jobLoadPtrType) ToJobLoadPtrOutputWithContext(ctx context.Context) JobLoadPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobLoadPtrOutput)
}

type JobLoadOutput struct{ *pulumi.OutputState }

func (JobLoadOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobLoad)(nil)).Elem()
}

func (o JobLoadOutput) ToJobLoadOutput() JobLoadOutput {
	return o
}

func (o JobLoadOutput) ToJobLoadOutputWithContext(ctx context.Context) JobLoadOutput {
	return o
}

func (o JobLoadOutput) ToJobLoadPtrOutput() JobLoadPtrOutput {
	return o.ToJobLoadPtrOutputWithContext(context.Background())
}

func (o JobLoadOutput) ToJobLoadPtrOutputWithContext(ctx context.Context) JobLoadPtrOutput {
	return o.ApplyT(func(v JobLoad) *JobLoad {
		return &v
	}).(JobLoadPtrOutput)
}

// Accept rows that are missing trailing optional columns. The missing values are treated as nulls.
// If false, records with missing trailing columns are treated as bad records, and if there are too many bad records,
// an invalid error is returned in the job result. The default value is false. Only applicable to CSV, ignored for other formats.
func (o JobLoadOutput) AllowJaggedRows() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v JobLoad) *bool { return v.AllowJaggedRows }).(pulumi.BoolPtrOutput)
}

// Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file.
// The default value is false.
func (o JobLoadOutput) AllowQuotedNewlines() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v JobLoad) *bool { return v.AllowQuotedNewlines }).(pulumi.BoolPtrOutput)
}

// Indicates if we should automatically infer the options and schema for CSV and JSON sources.
func (o JobLoadOutput) Autodetect() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v JobLoad) *bool { return v.Autodetect }).(pulumi.BoolPtrOutput)
}

// Specifies whether the job is allowed to create new tables. The following values are supported:
// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
// Creation, truncation and append actions occur as one atomic update upon job completion
// Default value is `CREATE_IF_NEEDED`.
// Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
func (o JobLoadOutput) CreateDisposition() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobLoad) *string { return v.CreateDisposition }).(pulumi.StringPtrOutput)
}

// Custom encryption configuration (e.g., Cloud KMS keys)
// Structure is documented below.
func (o JobLoadOutput) DestinationEncryptionConfiguration() JobLoadDestinationEncryptionConfigurationPtrOutput {
	return o.ApplyT(func(v JobLoad) *JobLoadDestinationEncryptionConfiguration {
		return v.DestinationEncryptionConfiguration
	}).(JobLoadDestinationEncryptionConfigurationPtrOutput)
}

// The destination table.
// Structure is documented below.
func (o JobLoadOutput) DestinationTable() JobLoadDestinationTableOutput {
	return o.ApplyT(func(v JobLoad) JobLoadDestinationTable { return v.DestinationTable }).(JobLoadDestinationTableOutput)
}

// The character encoding of the data. The supported values are UTF-8 or ISO-8859-1.
// The default value is UTF-8. BigQuery decodes the data after the raw, binary data
// has been split using the values of the quote and fieldDelimiter properties.
func (o JobLoadOutput) Encoding() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobLoad) *string { return v.Encoding }).(pulumi.StringPtrOutput)
}

// When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
// Default is ','
func (o JobLoadOutput) FieldDelimiter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobLoad) *string { return v.FieldDelimiter }).(pulumi.StringPtrOutput)
}

// Indicates if BigQuery should allow extra values that are not represented in the table schema.
// If true, the extra values are ignored. If false, records with extra columns are treated as bad records,
// and if there are too many bad records, an invalid error is returned in the job result.
// The default value is false. The sourceFormat property determines what BigQuery treats as an extra value:
// CSV: Trailing columns
// JSON: Named values that don't match any column names
func (o JobLoadOutput) IgnoreUnknownValues() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v JobLoad) *bool { return v.IgnoreUnknownValues }).(pulumi.BoolPtrOutput)
}

// The maximum number of bad records that BigQuery can ignore when running the job. If the number of bad records exceeds this value,
// an invalid error is returned in the job result. The default value is 0, which requires that all records are valid.
func (o JobLoadOutput) MaxBadRecords() pulumi.IntPtrOutput {
	return o.ApplyT(func(v JobLoad) *int { return v.MaxBadRecords }).(pulumi.IntPtrOutput)
}

// Specifies a string that represents a null value in a CSV file. The default value is the empty string. If you set this
// property to a custom value, BigQuery throws an error if an
// empty string is present for all data types except for STRING and BYTE. For STRING and BYTE columns, BigQuery interprets the empty string as
// an empty value.
func (o JobLoadOutput) NullMarker() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobLoad) *string { return v.NullMarker }).(pulumi.StringPtrOutput)
}

// If sourceFormat is set to "DATASTORE_BACKUP", indicates which entity properties to load into BigQuery from a Cloud Datastore backup.
// Property names are case sensitive and must be top-level properties. If no properties are specified, BigQuery loads all properties.
// If any named property isn't found in the Cloud Datastore backup, an invalid error is returned in the job result.
func (o JobLoadOutput) ProjectionFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobLoad) []string { return v.ProjectionFields }).(pulumi.StringArrayOutput)
}

// The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding,
// and then uses the first byte of the encoded string to split the data in its raw, binary state.
// The default value is a double-quote ('"'). If your data does not contain quoted sections, set the property value to an empty string.
// If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true.
func (o JobLoadOutput) Quote() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobLoad) *string { return v.Quote }).(pulumi.StringPtrOutput)
}

// Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
// supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
// For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
func (o JobLoadOutput) SchemaUpdateOptions() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobLoad) []string { return v.SchemaUpdateOptions }).(pulumi.StringArrayOutput)
}

// The number of rows at the top of a CSV file that BigQuery will skip when loading the data.
// The default value is 0. This property is useful if you have header rows in the file that should be skipped.
// When autodetect is on, the behavior is the following:
// skipLeadingRows unspecified - Autodetect tries to detect headers in the first row. If they are not detected,
// the row is read as data. Otherwise data is read starting from the second row.
// skipLeadingRows is 0 - Instructs autodetect that there are no headers and data should be read starting from the first row.
// skipLeadingRows = N > 0 - Autodetect skips N-1 rows and tries to detect headers in row N. If headers are not detected,
// row N is just skipped. Otherwise row N is used to extract column names for the detected schema.
func (o JobLoadOutput) SkipLeadingRows() pulumi.IntPtrOutput {
	return o.ApplyT(func(v JobLoad) *int { return v.SkipLeadingRows }).(pulumi.IntPtrOutput)
}

// The format of the data files. For CSV files, specify "CSV". For datastore backups, specify "DATASTORE_BACKUP".
// For newline-delimited JSON, specify "NEWLINE_DELIMITED_JSON". For Avro, specify "AVRO". For parquet, specify "PARQUET".
// For orc, specify "ORC". The default value is CSV.
func (o JobLoadOutput) SourceFormat() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobLoad) *string { return v.SourceFormat }).(pulumi.StringPtrOutput)
}

// The fully-qualified URIs that point to your data in Google Cloud.
// For Google Cloud Storage URIs: Each URI can contain one '*' wildcard character
// and it must come after the 'bucket' name. Size limits related to load jobs apply
// to external data sources. For Google Cloud Bigtable URIs: Exactly one URI can be
// specified and it has be a fully specified and valid HTTPS URL for a Google Cloud Bigtable table.
// For Google Cloud Datastore backups: Exactly one URI can be specified. Also, the '*' wildcard character is not allowed.
func (o JobLoadOutput) SourceUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobLoad) []string { return v.SourceUris }).(pulumi.StringArrayOutput)
}

// Time-based partitioning specification for the destination table.
// Structure is documented below.
func (o JobLoadOutput) TimePartitioning() JobLoadTimePartitioningPtrOutput {
	return o.ApplyT(func(v JobLoad) *JobLoadTimePartitioning { return v.TimePartitioning }).(JobLoadTimePartitioningPtrOutput)
}

// Specifies the action that occurs if the destination table already exists. The following values are supported:
// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
// Creation, truncation and append actions occur as one atomic update upon job completion.
// Default value is `WRITE_EMPTY`.
// Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
func (o JobLoadOutput) WriteDisposition() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobLoad) *string { return v.WriteDisposition }).(pulumi.StringPtrOutput)
}

type JobLoadPtrOutput struct{ *pulumi.OutputState }

func (JobLoadPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobLoad)(nil)).Elem()
}

func (o JobLoadPtrOutput) ToJobLoadPtrOutput() JobLoadPtrOutput {
	return o
}

func (o JobLoadPtrOutput) ToJobLoadPtrOutputWithContext(ctx context.Context) JobLoadPtrOutput {
	return o
}

func (o JobLoadPtrOutput) Elem() JobLoadOutput {
	return o.ApplyT(func(v *JobLoad) JobLoad { return *v }).(JobLoadOutput)
}

// Accept rows that are missing trailing optional columns. The missing values are treated as nulls.
// If false, records with missing trailing columns are treated as bad records, and if there are too many bad records,
// an invalid error is returned in the job result. The default value is false. Only applicable to CSV, ignored for other formats.
func (o JobLoadPtrOutput) AllowJaggedRows() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *JobLoad) *bool {
		if v == nil {
			return nil
		}
		return v.AllowJaggedRows
	}).(pulumi.BoolPtrOutput)
}

// Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file.
// The default value is false.
func (o JobLoadPtrOutput) AllowQuotedNewlines() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *JobLoad) *bool {
		if v == nil {
			return nil
		}
		return v.AllowQuotedNewlines
	}).(pulumi.BoolPtrOutput)
}

// Indicates if we should automatically infer the options and schema for CSV and JSON sources.
func (o JobLoadPtrOutput) Autodetect() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *JobLoad) *bool {
		if v == nil {
			return nil
		}
		return v.Autodetect
	}).(pulumi.BoolPtrOutput)
}

// Specifies whether the job is allowed to create new tables. The following values are supported:
// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
// Creation, truncation and append actions occur as one atomic update upon job completion
// Default value is `CREATE_IF_NEEDED`.
// Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
func (o JobLoadPtrOutput) CreateDisposition() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoad) *string {
		if v == nil {
			return nil
		}
		return v.CreateDisposition
	}).(pulumi.StringPtrOutput)
}

// Custom encryption configuration (e.g., Cloud KMS keys)
// Structure is documented below.
func (o JobLoadPtrOutput) DestinationEncryptionConfiguration() JobLoadDestinationEncryptionConfigurationPtrOutput {
	return o.ApplyT(func(v *JobLoad) *JobLoadDestinationEncryptionConfiguration {
		if v == nil {
			return nil
		}
		return v.DestinationEncryptionConfiguration
	}).(JobLoadDestinationEncryptionConfigurationPtrOutput)
}

// The destination table.
// Structure is documented below.
func (o JobLoadPtrOutput) DestinationTable() JobLoadDestinationTablePtrOutput {
	return o.ApplyT(func(v *JobLoad) *JobLoadDestinationTable {
		if v == nil {
			return nil
		}
		return &v.DestinationTable
	}).(JobLoadDestinationTablePtrOutput)
}

// The character encoding of the data. The supported values are UTF-8 or ISO-8859-1.
// The default value is UTF-8. BigQuery decodes the data after the raw, binary data
// has been split using the values of the quote and fieldDelimiter properties.
func (o JobLoadPtrOutput) Encoding() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoad) *string {
		if v == nil {
			return nil
		}
		return v.Encoding
	}).(pulumi.StringPtrOutput)
}

// When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
// Default is ','
func (o JobLoadPtrOutput) FieldDelimiter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoad) *string {
		if v == nil {
			return nil
		}
		return v.FieldDelimiter
	}).(pulumi.StringPtrOutput)
}

// Indicates if BigQuery should allow extra values that are not represented in the table schema.
// If true, the extra values are ignored. If false, records with extra columns are treated as bad records,
// and if there are too many bad records, an invalid error is returned in the job result.
// The default value is false. The sourceFormat property determines what BigQuery treats as an extra value:
// CSV: Trailing columns
// JSON: Named values that don't match any column names
func (o JobLoadPtrOutput) IgnoreUnknownValues() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *JobLoad) *bool {
		if v == nil {
			return nil
		}
		return v.IgnoreUnknownValues
	}).(pulumi.BoolPtrOutput)
}

// The maximum number of bad records that BigQuery can ignore when running the job. If the number of bad records exceeds this value,
// an invalid error is returned in the job result. The default value is 0, which requires that all records are valid.
func (o JobLoadPtrOutput) MaxBadRecords() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *JobLoad) *int {
		if v == nil {
			return nil
		}
		return v.MaxBadRecords
	}).(pulumi.IntPtrOutput)
}

// Specifies a string that represents a null value in a CSV file. The default value is the empty string. If you set this
// property to a custom value, BigQuery throws an error if an
// empty string is present for all data types except for STRING and BYTE. For STRING and BYTE columns, BigQuery interprets the empty string as
// an empty value.
func (o JobLoadPtrOutput) NullMarker() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoad) *string {
		if v == nil {
			return nil
		}
		return v.NullMarker
	}).(pulumi.StringPtrOutput)
}

// If sourceFormat is set to "DATASTORE_BACKUP", indicates which entity properties to load into BigQuery from a Cloud Datastore backup.
// Property names are case sensitive and must be top-level properties. If no properties are specified, BigQuery loads all properties.
// If any named property isn't found in the Cloud Datastore backup, an invalid error is returned in the job result.
func (o JobLoadPtrOutput) ProjectionFields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobLoad) []string {
		if v == nil {
			return nil
		}
		return v.ProjectionFields
	}).(pulumi.StringArrayOutput)
}

// The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding,
// and then uses the first byte of the encoded string to split the data in its raw, binary state.
// The default value is a double-quote ('"'). If your data does not contain quoted sections, set the property value to an empty string.
// If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true.
func (o JobLoadPtrOutput) Quote() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoad) *string {
		if v == nil {
			return nil
		}
		return v.Quote
	}).(pulumi.StringPtrOutput)
}

// Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
// supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
// For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
func (o JobLoadPtrOutput) SchemaUpdateOptions() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobLoad) []string {
		if v == nil {
			return nil
		}
		return v.SchemaUpdateOptions
	}).(pulumi.StringArrayOutput)
}

// The number of rows at the top of a CSV file that BigQuery will skip when loading the data.
// The default value is 0. This property is useful if you have header rows in the file that should be skipped.
// When autodetect is on, the behavior is the following:
// skipLeadingRows unspecified - Autodetect tries to detect headers in the first row. If they are not detected,
// the row is read as data. Otherwise data is read starting from the second row.
// skipLeadingRows is 0 - Instructs autodetect that there are no headers and data should be read starting from the first row.
// skipLeadingRows = N > 0 - Autodetect skips N-1 rows and tries to detect headers in row N. If headers are not detected,
// row N is just skipped. Otherwise row N is used to extract column names for the detected schema.
func (o JobLoadPtrOutput) SkipLeadingRows() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *JobLoad) *int {
		if v == nil {
			return nil
		}
		return v.SkipLeadingRows
	}).(pulumi.IntPtrOutput)
}

// The format of the data files. For CSV files, specify "CSV". For datastore backups, specify "DATASTORE_BACKUP".
// For newline-delimited JSON, specify "NEWLINE_DELIMITED_JSON". For Avro, specify "AVRO". For parquet, specify "PARQUET".
// For orc, specify "ORC". The default value is CSV.
func (o JobLoadPtrOutput) SourceFormat() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoad) *string {
		if v == nil {
			return nil
		}
		return v.SourceFormat
	}).(pulumi.StringPtrOutput)
}

// The fully-qualified URIs that point to your data in Google Cloud.
// For Google Cloud Storage URIs: Each URI can contain one '*' wildcard character
// and it must come after the 'bucket' name. Size limits related to load jobs apply
// to external data sources. For Google Cloud Bigtable URIs: Exactly one URI can be
// specified and it has be a fully specified and valid HTTPS URL for a Google Cloud Bigtable table.
// For Google Cloud Datastore backups: Exactly one URI can be specified. Also, the '*' wildcard character is not allowed.
func (o JobLoadPtrOutput) SourceUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobLoad) []string {
		if v == nil {
			return nil
		}
		return v.SourceUris
	}).(pulumi.StringArrayOutput)
}

// Time-based partitioning specification for the destination table.
// Structure is documented below.
func (o JobLoadPtrOutput) TimePartitioning() JobLoadTimePartitioningPtrOutput {
	return o.ApplyT(func(v *JobLoad) *JobLoadTimePartitioning {
		if v == nil {
			return nil
		}
		return v.TimePartitioning
	}).(JobLoadTimePartitioningPtrOutput)
}

// Specifies the action that occurs if the destination table already exists. The following values are supported:
// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
// Creation, truncation and append actions occur as one atomic update upon job completion.
// Default value is `WRITE_EMPTY`.
// Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
func (o JobLoadPtrOutput) WriteDisposition() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoad) *string {
		if v == nil {
			return nil
		}
		return v.WriteDisposition
	}).(pulumi.StringPtrOutput)
}

type JobLoadDestinationEncryptionConfiguration struct {
	// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
	// The BigQuery Service Account associated with your project requires access to this encryption key.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// JobLoadDestinationEncryptionConfigurationInput is an input type that accepts JobLoadDestinationEncryptionConfigurationArgs and JobLoadDestinationEncryptionConfigurationOutput values.
// You can construct a concrete instance of `JobLoadDestinationEncryptionConfigurationInput` via:
//
// 		 JobLoadDestinationEncryptionConfigurationArgs{...}
//
type JobLoadDestinationEncryptionConfigurationInput interface {
	pulumi.Input

	ToJobLoadDestinationEncryptionConfigurationOutput() JobLoadDestinationEncryptionConfigurationOutput
	ToJobLoadDestinationEncryptionConfigurationOutputWithContext(context.Context) JobLoadDestinationEncryptionConfigurationOutput
}

type JobLoadDestinationEncryptionConfigurationArgs struct {
	// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
	// The BigQuery Service Account associated with your project requires access to this encryption key.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (JobLoadDestinationEncryptionConfigurationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobLoadDestinationEncryptionConfiguration)(nil)).Elem()
}

func (i JobLoadDestinationEncryptionConfigurationArgs) ToJobLoadDestinationEncryptionConfigurationOutput() JobLoadDestinationEncryptionConfigurationOutput {
	return i.ToJobLoadDestinationEncryptionConfigurationOutputWithContext(context.Background())
}

func (i JobLoadDestinationEncryptionConfigurationArgs) ToJobLoadDestinationEncryptionConfigurationOutputWithContext(ctx context.Context) JobLoadDestinationEncryptionConfigurationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobLoadDestinationEncryptionConfigurationOutput)
}

func (i JobLoadDestinationEncryptionConfigurationArgs) ToJobLoadDestinationEncryptionConfigurationPtrOutput() JobLoadDestinationEncryptionConfigurationPtrOutput {
	return i.ToJobLoadDestinationEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (i JobLoadDestinationEncryptionConfigurationArgs) ToJobLoadDestinationEncryptionConfigurationPtrOutputWithContext(ctx context.Context) JobLoadDestinationEncryptionConfigurationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobLoadDestinationEncryptionConfigurationOutput).ToJobLoadDestinationEncryptionConfigurationPtrOutputWithContext(ctx)
}

// JobLoadDestinationEncryptionConfigurationPtrInput is an input type that accepts JobLoadDestinationEncryptionConfigurationArgs, JobLoadDestinationEncryptionConfigurationPtr and JobLoadDestinationEncryptionConfigurationPtrOutput values.
// You can construct a concrete instance of `JobLoadDestinationEncryptionConfigurationPtrInput` via:
//
// 		 JobLoadDestinationEncryptionConfigurationArgs{...}
//
//  or:
//
// 		 nil
//
type JobLoadDestinationEncryptionConfigurationPtrInput interface {
	pulumi.Input

	ToJobLoadDestinationEncryptionConfigurationPtrOutput() JobLoadDestinationEncryptionConfigurationPtrOutput
	ToJobLoadDestinationEncryptionConfigurationPtrOutputWithContext(context.Context) JobLoadDestinationEncryptionConfigurationPtrOutput
}

type jobLoadDestinationEncryptionConfigurationPtrType JobLoadDestinationEncryptionConfigurationArgs

func JobLoadDestinationEncryptionConfigurationPtr(v *JobLoadDestinationEncryptionConfigurationArgs) JobLoadDestinationEncryptionConfigurationPtrInput {
	return (*jobLoadDestinationEncryptionConfigurationPtrType)(v)
}

func (*jobLoadDestinationEncryptionConfigurationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobLoadDestinationEncryptionConfiguration)(nil)).Elem()
}

func (i *jobLoadDestinationEncryptionConfigurationPtrType) ToJobLoadDestinationEncryptionConfigurationPtrOutput() JobLoadDestinationEncryptionConfigurationPtrOutput {
	return i.ToJobLoadDestinationEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (i *jobLoadDestinationEncryptionConfigurationPtrType) ToJobLoadDestinationEncryptionConfigurationPtrOutputWithContext(ctx context.Context) JobLoadDestinationEncryptionConfigurationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobLoadDestinationEncryptionConfigurationPtrOutput)
}

type JobLoadDestinationEncryptionConfigurationOutput struct{ *pulumi.OutputState }

func (JobLoadDestinationEncryptionConfigurationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobLoadDestinationEncryptionConfiguration)(nil)).Elem()
}

func (o JobLoadDestinationEncryptionConfigurationOutput) ToJobLoadDestinationEncryptionConfigurationOutput() JobLoadDestinationEncryptionConfigurationOutput {
	return o
}

func (o JobLoadDestinationEncryptionConfigurationOutput) ToJobLoadDestinationEncryptionConfigurationOutputWithContext(ctx context.Context) JobLoadDestinationEncryptionConfigurationOutput {
	return o
}

func (o JobLoadDestinationEncryptionConfigurationOutput) ToJobLoadDestinationEncryptionConfigurationPtrOutput() JobLoadDestinationEncryptionConfigurationPtrOutput {
	return o.ToJobLoadDestinationEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (o JobLoadDestinationEncryptionConfigurationOutput) ToJobLoadDestinationEncryptionConfigurationPtrOutputWithContext(ctx context.Context) JobLoadDestinationEncryptionConfigurationPtrOutput {
	return o.ApplyT(func(v JobLoadDestinationEncryptionConfiguration) *JobLoadDestinationEncryptionConfiguration {
		return &v
	}).(JobLoadDestinationEncryptionConfigurationPtrOutput)
}

// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
// The BigQuery Service Account associated with your project requires access to this encryption key.
func (o JobLoadDestinationEncryptionConfigurationOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v JobLoadDestinationEncryptionConfiguration) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type JobLoadDestinationEncryptionConfigurationPtrOutput struct{ *pulumi.OutputState }

func (JobLoadDestinationEncryptionConfigurationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobLoadDestinationEncryptionConfiguration)(nil)).Elem()
}

func (o JobLoadDestinationEncryptionConfigurationPtrOutput) ToJobLoadDestinationEncryptionConfigurationPtrOutput() JobLoadDestinationEncryptionConfigurationPtrOutput {
	return o
}

func (o JobLoadDestinationEncryptionConfigurationPtrOutput) ToJobLoadDestinationEncryptionConfigurationPtrOutputWithContext(ctx context.Context) JobLoadDestinationEncryptionConfigurationPtrOutput {
	return o
}

func (o JobLoadDestinationEncryptionConfigurationPtrOutput) Elem() JobLoadDestinationEncryptionConfigurationOutput {
	return o.ApplyT(func(v *JobLoadDestinationEncryptionConfiguration) JobLoadDestinationEncryptionConfiguration {
		return *v
	}).(JobLoadDestinationEncryptionConfigurationOutput)
}

// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
// The BigQuery Service Account associated with your project requires access to this encryption key.
func (o JobLoadDestinationEncryptionConfigurationPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoadDestinationEncryptionConfiguration) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type JobLoadDestinationTable struct {
	// The ID of the dataset containing this model.
	DatasetId *string `pulumi:"datasetId"`
	// The ID of the project containing this model.
	ProjectId *string `pulumi:"projectId"`
	// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
	// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
	TableId string `pulumi:"tableId"`
}

// JobLoadDestinationTableInput is an input type that accepts JobLoadDestinationTableArgs and JobLoadDestinationTableOutput values.
// You can construct a concrete instance of `JobLoadDestinationTableInput` via:
//
// 		 JobLoadDestinationTableArgs{...}
//
type JobLoadDestinationTableInput interface {
	pulumi.Input

	ToJobLoadDestinationTableOutput() JobLoadDestinationTableOutput
	ToJobLoadDestinationTableOutputWithContext(context.Context) JobLoadDestinationTableOutput
}

type JobLoadDestinationTableArgs struct {
	// The ID of the dataset containing this model.
	DatasetId pulumi.StringPtrInput `pulumi:"datasetId"`
	// The ID of the project containing this model.
	ProjectId pulumi.StringPtrInput `pulumi:"projectId"`
	// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
	// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
	TableId pulumi.StringInput `pulumi:"tableId"`
}

func (JobLoadDestinationTableArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobLoadDestinationTable)(nil)).Elem()
}

func (i JobLoadDestinationTableArgs) ToJobLoadDestinationTableOutput() JobLoadDestinationTableOutput {
	return i.ToJobLoadDestinationTableOutputWithContext(context.Background())
}

func (i JobLoadDestinationTableArgs) ToJobLoadDestinationTableOutputWithContext(ctx context.Context) JobLoadDestinationTableOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobLoadDestinationTableOutput)
}

func (i JobLoadDestinationTableArgs) ToJobLoadDestinationTablePtrOutput() JobLoadDestinationTablePtrOutput {
	return i.ToJobLoadDestinationTablePtrOutputWithContext(context.Background())
}

func (i JobLoadDestinationTableArgs) ToJobLoadDestinationTablePtrOutputWithContext(ctx context.Context) JobLoadDestinationTablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobLoadDestinationTableOutput).ToJobLoadDestinationTablePtrOutputWithContext(ctx)
}

// JobLoadDestinationTablePtrInput is an input type that accepts JobLoadDestinationTableArgs, JobLoadDestinationTablePtr and JobLoadDestinationTablePtrOutput values.
// You can construct a concrete instance of `JobLoadDestinationTablePtrInput` via:
//
// 		 JobLoadDestinationTableArgs{...}
//
//  or:
//
// 		 nil
//
type JobLoadDestinationTablePtrInput interface {
	pulumi.Input

	ToJobLoadDestinationTablePtrOutput() JobLoadDestinationTablePtrOutput
	ToJobLoadDestinationTablePtrOutputWithContext(context.Context) JobLoadDestinationTablePtrOutput
}

type jobLoadDestinationTablePtrType JobLoadDestinationTableArgs

func JobLoadDestinationTablePtr(v *JobLoadDestinationTableArgs) JobLoadDestinationTablePtrInput {
	return (*jobLoadDestinationTablePtrType)(v)
}

func (*jobLoadDestinationTablePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobLoadDestinationTable)(nil)).Elem()
}

func (i *jobLoadDestinationTablePtrType) ToJobLoadDestinationTablePtrOutput() JobLoadDestinationTablePtrOutput {
	return i.ToJobLoadDestinationTablePtrOutputWithContext(context.Background())
}

func (i *jobLoadDestinationTablePtrType) ToJobLoadDestinationTablePtrOutputWithContext(ctx context.Context) JobLoadDestinationTablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobLoadDestinationTablePtrOutput)
}

type JobLoadDestinationTableOutput struct{ *pulumi.OutputState }

func (JobLoadDestinationTableOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobLoadDestinationTable)(nil)).Elem()
}

func (o JobLoadDestinationTableOutput) ToJobLoadDestinationTableOutput() JobLoadDestinationTableOutput {
	return o
}

func (o JobLoadDestinationTableOutput) ToJobLoadDestinationTableOutputWithContext(ctx context.Context) JobLoadDestinationTableOutput {
	return o
}

func (o JobLoadDestinationTableOutput) ToJobLoadDestinationTablePtrOutput() JobLoadDestinationTablePtrOutput {
	return o.ToJobLoadDestinationTablePtrOutputWithContext(context.Background())
}

func (o JobLoadDestinationTableOutput) ToJobLoadDestinationTablePtrOutputWithContext(ctx context.Context) JobLoadDestinationTablePtrOutput {
	return o.ApplyT(func(v JobLoadDestinationTable) *JobLoadDestinationTable {
		return &v
	}).(JobLoadDestinationTablePtrOutput)
}

// The ID of the dataset containing this model.
func (o JobLoadDestinationTableOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobLoadDestinationTable) *string { return v.DatasetId }).(pulumi.StringPtrOutput)
}

// The ID of the project containing this model.
func (o JobLoadDestinationTableOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobLoadDestinationTable) *string { return v.ProjectId }).(pulumi.StringPtrOutput)
}

// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
func (o JobLoadDestinationTableOutput) TableId() pulumi.StringOutput {
	return o.ApplyT(func(v JobLoadDestinationTable) string { return v.TableId }).(pulumi.StringOutput)
}

type JobLoadDestinationTablePtrOutput struct{ *pulumi.OutputState }

func (JobLoadDestinationTablePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobLoadDestinationTable)(nil)).Elem()
}

func (o JobLoadDestinationTablePtrOutput) ToJobLoadDestinationTablePtrOutput() JobLoadDestinationTablePtrOutput {
	return o
}

func (o JobLoadDestinationTablePtrOutput) ToJobLoadDestinationTablePtrOutputWithContext(ctx context.Context) JobLoadDestinationTablePtrOutput {
	return o
}

func (o JobLoadDestinationTablePtrOutput) Elem() JobLoadDestinationTableOutput {
	return o.ApplyT(func(v *JobLoadDestinationTable) JobLoadDestinationTable { return *v }).(JobLoadDestinationTableOutput)
}

// The ID of the dataset containing this model.
func (o JobLoadDestinationTablePtrOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoadDestinationTable) *string {
		if v == nil {
			return nil
		}
		return v.DatasetId
	}).(pulumi.StringPtrOutput)
}

// The ID of the project containing this model.
func (o JobLoadDestinationTablePtrOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoadDestinationTable) *string {
		if v == nil {
			return nil
		}
		return v.ProjectId
	}).(pulumi.StringPtrOutput)
}

// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
func (o JobLoadDestinationTablePtrOutput) TableId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoadDestinationTable) *string {
		if v == nil {
			return nil
		}
		return &v.TableId
	}).(pulumi.StringPtrOutput)
}

type JobLoadTimePartitioning struct {
	// Number of milliseconds for which to keep the storage for a partition. A wrapper is used here because 0 is an invalid value.
	ExpirationMs *string `pulumi:"expirationMs"`
	// If not set, the table is partitioned by pseudo column '_PARTITIONTIME'; if set, the table is partitioned by this field.
	// The field must be a top-level TIMESTAMP or DATE field. Its mode must be NULLABLE or REQUIRED.
	// A wrapper is used here because an empty string is an invalid value.
	Field *string `pulumi:"field"`
	// The only type supported is DAY, which will generate one partition per day. Providing an empty string used to cause an error,
	// but in OnePlatform the field will be treated as unset.
	Type string `pulumi:"type"`
}

// JobLoadTimePartitioningInput is an input type that accepts JobLoadTimePartitioningArgs and JobLoadTimePartitioningOutput values.
// You can construct a concrete instance of `JobLoadTimePartitioningInput` via:
//
// 		 JobLoadTimePartitioningArgs{...}
//
type JobLoadTimePartitioningInput interface {
	pulumi.Input

	ToJobLoadTimePartitioningOutput() JobLoadTimePartitioningOutput
	ToJobLoadTimePartitioningOutputWithContext(context.Context) JobLoadTimePartitioningOutput
}

type JobLoadTimePartitioningArgs struct {
	// Number of milliseconds for which to keep the storage for a partition. A wrapper is used here because 0 is an invalid value.
	ExpirationMs pulumi.StringPtrInput `pulumi:"expirationMs"`
	// If not set, the table is partitioned by pseudo column '_PARTITIONTIME'; if set, the table is partitioned by this field.
	// The field must be a top-level TIMESTAMP or DATE field. Its mode must be NULLABLE or REQUIRED.
	// A wrapper is used here because an empty string is an invalid value.
	Field pulumi.StringPtrInput `pulumi:"field"`
	// The only type supported is DAY, which will generate one partition per day. Providing an empty string used to cause an error,
	// but in OnePlatform the field will be treated as unset.
	Type pulumi.StringInput `pulumi:"type"`
}

func (JobLoadTimePartitioningArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobLoadTimePartitioning)(nil)).Elem()
}

func (i JobLoadTimePartitioningArgs) ToJobLoadTimePartitioningOutput() JobLoadTimePartitioningOutput {
	return i.ToJobLoadTimePartitioningOutputWithContext(context.Background())
}

func (i JobLoadTimePartitioningArgs) ToJobLoadTimePartitioningOutputWithContext(ctx context.Context) JobLoadTimePartitioningOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobLoadTimePartitioningOutput)
}

func (i JobLoadTimePartitioningArgs) ToJobLoadTimePartitioningPtrOutput() JobLoadTimePartitioningPtrOutput {
	return i.ToJobLoadTimePartitioningPtrOutputWithContext(context.Background())
}

func (i JobLoadTimePartitioningArgs) ToJobLoadTimePartitioningPtrOutputWithContext(ctx context.Context) JobLoadTimePartitioningPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobLoadTimePartitioningOutput).ToJobLoadTimePartitioningPtrOutputWithContext(ctx)
}

// JobLoadTimePartitioningPtrInput is an input type that accepts JobLoadTimePartitioningArgs, JobLoadTimePartitioningPtr and JobLoadTimePartitioningPtrOutput values.
// You can construct a concrete instance of `JobLoadTimePartitioningPtrInput` via:
//
// 		 JobLoadTimePartitioningArgs{...}
//
//  or:
//
// 		 nil
//
type JobLoadTimePartitioningPtrInput interface {
	pulumi.Input

	ToJobLoadTimePartitioningPtrOutput() JobLoadTimePartitioningPtrOutput
	ToJobLoadTimePartitioningPtrOutputWithContext(context.Context) JobLoadTimePartitioningPtrOutput
}

type jobLoadTimePartitioningPtrType JobLoadTimePartitioningArgs

func JobLoadTimePartitioningPtr(v *JobLoadTimePartitioningArgs) JobLoadTimePartitioningPtrInput {
	return (*jobLoadTimePartitioningPtrType)(v)
}

func (*jobLoadTimePartitioningPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobLoadTimePartitioning)(nil)).Elem()
}

func (i *jobLoadTimePartitioningPtrType) ToJobLoadTimePartitioningPtrOutput() JobLoadTimePartitioningPtrOutput {
	return i.ToJobLoadTimePartitioningPtrOutputWithContext(context.Background())
}

func (i *jobLoadTimePartitioningPtrType) ToJobLoadTimePartitioningPtrOutputWithContext(ctx context.Context) JobLoadTimePartitioningPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobLoadTimePartitioningPtrOutput)
}

type JobLoadTimePartitioningOutput struct{ *pulumi.OutputState }

func (JobLoadTimePartitioningOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobLoadTimePartitioning)(nil)).Elem()
}

func (o JobLoadTimePartitioningOutput) ToJobLoadTimePartitioningOutput() JobLoadTimePartitioningOutput {
	return o
}

func (o JobLoadTimePartitioningOutput) ToJobLoadTimePartitioningOutputWithContext(ctx context.Context) JobLoadTimePartitioningOutput {
	return o
}

func (o JobLoadTimePartitioningOutput) ToJobLoadTimePartitioningPtrOutput() JobLoadTimePartitioningPtrOutput {
	return o.ToJobLoadTimePartitioningPtrOutputWithContext(context.Background())
}

func (o JobLoadTimePartitioningOutput) ToJobLoadTimePartitioningPtrOutputWithContext(ctx context.Context) JobLoadTimePartitioningPtrOutput {
	return o.ApplyT(func(v JobLoadTimePartitioning) *JobLoadTimePartitioning {
		return &v
	}).(JobLoadTimePartitioningPtrOutput)
}

// Number of milliseconds for which to keep the storage for a partition. A wrapper is used here because 0 is an invalid value.
func (o JobLoadTimePartitioningOutput) ExpirationMs() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobLoadTimePartitioning) *string { return v.ExpirationMs }).(pulumi.StringPtrOutput)
}

// If not set, the table is partitioned by pseudo column '_PARTITIONTIME'; if set, the table is partitioned by this field.
// The field must be a top-level TIMESTAMP or DATE field. Its mode must be NULLABLE or REQUIRED.
// A wrapper is used here because an empty string is an invalid value.
func (o JobLoadTimePartitioningOutput) Field() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobLoadTimePartitioning) *string { return v.Field }).(pulumi.StringPtrOutput)
}

// The only type supported is DAY, which will generate one partition per day. Providing an empty string used to cause an error,
// but in OnePlatform the field will be treated as unset.
func (o JobLoadTimePartitioningOutput) Type() pulumi.StringOutput {
	return o.ApplyT(func(v JobLoadTimePartitioning) string { return v.Type }).(pulumi.StringOutput)
}

type JobLoadTimePartitioningPtrOutput struct{ *pulumi.OutputState }

func (JobLoadTimePartitioningPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobLoadTimePartitioning)(nil)).Elem()
}

func (o JobLoadTimePartitioningPtrOutput) ToJobLoadTimePartitioningPtrOutput() JobLoadTimePartitioningPtrOutput {
	return o
}

func (o JobLoadTimePartitioningPtrOutput) ToJobLoadTimePartitioningPtrOutputWithContext(ctx context.Context) JobLoadTimePartitioningPtrOutput {
	return o
}

func (o JobLoadTimePartitioningPtrOutput) Elem() JobLoadTimePartitioningOutput {
	return o.ApplyT(func(v *JobLoadTimePartitioning) JobLoadTimePartitioning { return *v }).(JobLoadTimePartitioningOutput)
}

// Number of milliseconds for which to keep the storage for a partition. A wrapper is used here because 0 is an invalid value.
func (o JobLoadTimePartitioningPtrOutput) ExpirationMs() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoadTimePartitioning) *string {
		if v == nil {
			return nil
		}
		return v.ExpirationMs
	}).(pulumi.StringPtrOutput)
}

// If not set, the table is partitioned by pseudo column '_PARTITIONTIME'; if set, the table is partitioned by this field.
// The field must be a top-level TIMESTAMP or DATE field. Its mode must be NULLABLE or REQUIRED.
// A wrapper is used here because an empty string is an invalid value.
func (o JobLoadTimePartitioningPtrOutput) Field() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoadTimePartitioning) *string {
		if v == nil {
			return nil
		}
		return v.Field
	}).(pulumi.StringPtrOutput)
}

// The only type supported is DAY, which will generate one partition per day. Providing an empty string used to cause an error,
// but in OnePlatform the field will be treated as unset.
func (o JobLoadTimePartitioningPtrOutput) Type() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobLoadTimePartitioning) *string {
		if v == nil {
			return nil
		}
		return &v.Type
	}).(pulumi.StringPtrOutput)
}

type JobQuery struct {
	// If true and query uses legacy SQL dialect, allows the query to produce arbitrarily large result tables at a slight cost in performance.
	// Requires destinationTable to be set. For standard SQL queries, this flag is ignored and large results are always allowed.
	// However, you must still set destinationTable when result size exceeds the allowed maximum response size.
	AllowLargeResults *bool `pulumi:"allowLargeResults"`
	// Specifies whether the job is allowed to create new tables. The following values are supported:
	// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
	// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
	// Creation, truncation and append actions occur as one atomic update upon job completion
	// Default value is `CREATE_IF_NEEDED`.
	// Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
	CreateDisposition *string `pulumi:"createDisposition"`
	// Specifies the default dataset to use for unqualified table names in the query. Note that this does not alter behavior of unqualified dataset names.
	// Structure is documented below.
	DefaultDataset *JobQueryDefaultDataset `pulumi:"defaultDataset"`
	// Custom encryption configuration (e.g., Cloud KMS keys)
	// Structure is documented below.
	DestinationEncryptionConfiguration *JobQueryDestinationEncryptionConfiguration `pulumi:"destinationEncryptionConfiguration"`
	// The destination table.
	// Structure is documented below.
	DestinationTable *JobQueryDestinationTable `pulumi:"destinationTable"`
	// If true and query uses legacy SQL dialect, flattens all nested and repeated fields in the query results.
	// allowLargeResults must be true if this is set to false. For standard SQL queries, this flag is ignored and results are never flattened.
	FlattenResults *bool `pulumi:"flattenResults"`
	// Limits the billing tier for this job. Queries that have resource usage beyond this tier will fail (without incurring a charge).
	// If unspecified, this will be set to your project default.
	MaximumBillingTier *int `pulumi:"maximumBillingTier"`
	// Limits the bytes billed for this job. Queries that will have bytes billed beyond this limit will fail (without incurring a charge).
	// If unspecified, this will be set to your project default.
	MaximumBytesBilled *string `pulumi:"maximumBytesBilled"`
	// Standard SQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query.
	ParameterMode *string `pulumi:"parameterMode"`
	// Specifies a priority for the query.
	// Default value is `INTERACTIVE`.
	// Possible values are `INTERACTIVE` and `BATCH`.
	Priority *string `pulumi:"priority"`
	// Configures a query job.
	// Structure is documented below.
	Query string `pulumi:"query"`
	// Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
	// supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
	// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
	// For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
	// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
	// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
	SchemaUpdateOptions []string `pulumi:"schemaUpdateOptions"`
	// Options controlling the execution of scripts.
	// Structure is documented below.
	ScriptOptions *JobQueryScriptOptions `pulumi:"scriptOptions"`
	// Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true.
	// If set to false, the query will use BigQuery's standard SQL.
	UseLegacySql *bool `pulumi:"useLegacySql"`
	// Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever
	// tables in the query are modified. Moreover, the query cache is only available when a query does not have a destination table specified.
	// The default value is true.
	UseQueryCache *bool `pulumi:"useQueryCache"`
	// Describes user-defined function resources used in the query.
	// Structure is documented below.
	UserDefinedFunctionResources []JobQueryUserDefinedFunctionResource `pulumi:"userDefinedFunctionResources"`
	// Specifies the action that occurs if the destination table already exists. The following values are supported:
	// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
	// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
	// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
	// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
	// Creation, truncation and append actions occur as one atomic update upon job completion.
	// Default value is `WRITE_EMPTY`.
	// Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
	WriteDisposition *string `pulumi:"writeDisposition"`
}

// JobQueryInput is an input type that accepts JobQueryArgs and JobQueryOutput values.
// You can construct a concrete instance of `JobQueryInput` via:
//
// 		 JobQueryArgs{...}
//
type JobQueryInput interface {
	pulumi.Input

	ToJobQueryOutput() JobQueryOutput
	ToJobQueryOutputWithContext(context.Context) JobQueryOutput
}

type JobQueryArgs struct {
	// If true and query uses legacy SQL dialect, allows the query to produce arbitrarily large result tables at a slight cost in performance.
	// Requires destinationTable to be set. For standard SQL queries, this flag is ignored and large results are always allowed.
	// However, you must still set destinationTable when result size exceeds the allowed maximum response size.
	AllowLargeResults pulumi.BoolPtrInput `pulumi:"allowLargeResults"`
	// Specifies whether the job is allowed to create new tables. The following values are supported:
	// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
	// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
	// Creation, truncation and append actions occur as one atomic update upon job completion
	// Default value is `CREATE_IF_NEEDED`.
	// Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
	CreateDisposition pulumi.StringPtrInput `pulumi:"createDisposition"`
	// Specifies the default dataset to use for unqualified table names in the query. Note that this does not alter behavior of unqualified dataset names.
	// Structure is documented below.
	DefaultDataset JobQueryDefaultDatasetPtrInput `pulumi:"defaultDataset"`
	// Custom encryption configuration (e.g., Cloud KMS keys)
	// Structure is documented below.
	DestinationEncryptionConfiguration JobQueryDestinationEncryptionConfigurationPtrInput `pulumi:"destinationEncryptionConfiguration"`
	// The destination table.
	// Structure is documented below.
	DestinationTable JobQueryDestinationTablePtrInput `pulumi:"destinationTable"`
	// If true and query uses legacy SQL dialect, flattens all nested and repeated fields in the query results.
	// allowLargeResults must be true if this is set to false. For standard SQL queries, this flag is ignored and results are never flattened.
	FlattenResults pulumi.BoolPtrInput `pulumi:"flattenResults"`
	// Limits the billing tier for this job. Queries that have resource usage beyond this tier will fail (without incurring a charge).
	// If unspecified, this will be set to your project default.
	MaximumBillingTier pulumi.IntPtrInput `pulumi:"maximumBillingTier"`
	// Limits the bytes billed for this job. Queries that will have bytes billed beyond this limit will fail (without incurring a charge).
	// If unspecified, this will be set to your project default.
	MaximumBytesBilled pulumi.StringPtrInput `pulumi:"maximumBytesBilled"`
	// Standard SQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query.
	ParameterMode pulumi.StringPtrInput `pulumi:"parameterMode"`
	// Specifies a priority for the query.
	// Default value is `INTERACTIVE`.
	// Possible values are `INTERACTIVE` and `BATCH`.
	Priority pulumi.StringPtrInput `pulumi:"priority"`
	// Configures a query job.
	// Structure is documented below.
	Query pulumi.StringInput `pulumi:"query"`
	// Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
	// supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
	// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
	// For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
	// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
	// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
	SchemaUpdateOptions pulumi.StringArrayInput `pulumi:"schemaUpdateOptions"`
	// Options controlling the execution of scripts.
	// Structure is documented below.
	ScriptOptions JobQueryScriptOptionsPtrInput `pulumi:"scriptOptions"`
	// Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true.
	// If set to false, the query will use BigQuery's standard SQL.
	UseLegacySql pulumi.BoolPtrInput `pulumi:"useLegacySql"`
	// Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever
	// tables in the query are modified. Moreover, the query cache is only available when a query does not have a destination table specified.
	// The default value is true.
	UseQueryCache pulumi.BoolPtrInput `pulumi:"useQueryCache"`
	// Describes user-defined function resources used in the query.
	// Structure is documented below.
	UserDefinedFunctionResources JobQueryUserDefinedFunctionResourceArrayInput `pulumi:"userDefinedFunctionResources"`
	// Specifies the action that occurs if the destination table already exists. The following values are supported:
	// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
	// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
	// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
	// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
	// Creation, truncation and append actions occur as one atomic update upon job completion.
	// Default value is `WRITE_EMPTY`.
	// Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
	WriteDisposition pulumi.StringPtrInput `pulumi:"writeDisposition"`
}

func (JobQueryArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobQuery)(nil)).Elem()
}

func (i JobQueryArgs) ToJobQueryOutput() JobQueryOutput {
	return i.ToJobQueryOutputWithContext(context.Background())
}

func (i JobQueryArgs) ToJobQueryOutputWithContext(ctx context.Context) JobQueryOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryOutput)
}

func (i JobQueryArgs) ToJobQueryPtrOutput() JobQueryPtrOutput {
	return i.ToJobQueryPtrOutputWithContext(context.Background())
}

func (i JobQueryArgs) ToJobQueryPtrOutputWithContext(ctx context.Context) JobQueryPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryOutput).ToJobQueryPtrOutputWithContext(ctx)
}

// JobQueryPtrInput is an input type that accepts JobQueryArgs, JobQueryPtr and JobQueryPtrOutput values.
// You can construct a concrete instance of `JobQueryPtrInput` via:
//
// 		 JobQueryArgs{...}
//
//  or:
//
// 		 nil
//
type JobQueryPtrInput interface {
	pulumi.Input

	ToJobQueryPtrOutput() JobQueryPtrOutput
	ToJobQueryPtrOutputWithContext(context.Context) JobQueryPtrOutput
}

type jobQueryPtrType JobQueryArgs

func JobQueryPtr(v *JobQueryArgs) JobQueryPtrInput {
	return (*jobQueryPtrType)(v)
}

func (*jobQueryPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobQuery)(nil)).Elem()
}

func (i *jobQueryPtrType) ToJobQueryPtrOutput() JobQueryPtrOutput {
	return i.ToJobQueryPtrOutputWithContext(context.Background())
}

func (i *jobQueryPtrType) ToJobQueryPtrOutputWithContext(ctx context.Context) JobQueryPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryPtrOutput)
}

type JobQueryOutput struct{ *pulumi.OutputState }

func (JobQueryOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobQuery)(nil)).Elem()
}

func (o JobQueryOutput) ToJobQueryOutput() JobQueryOutput {
	return o
}

func (o JobQueryOutput) ToJobQueryOutputWithContext(ctx context.Context) JobQueryOutput {
	return o
}

func (o JobQueryOutput) ToJobQueryPtrOutput() JobQueryPtrOutput {
	return o.ToJobQueryPtrOutputWithContext(context.Background())
}

func (o JobQueryOutput) ToJobQueryPtrOutputWithContext(ctx context.Context) JobQueryPtrOutput {
	return o.ApplyT(func(v JobQuery) *JobQuery {
		return &v
	}).(JobQueryPtrOutput)
}

// If true and query uses legacy SQL dialect, allows the query to produce arbitrarily large result tables at a slight cost in performance.
// Requires destinationTable to be set. For standard SQL queries, this flag is ignored and large results are always allowed.
// However, you must still set destinationTable when result size exceeds the allowed maximum response size.
func (o JobQueryOutput) AllowLargeResults() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v JobQuery) *bool { return v.AllowLargeResults }).(pulumi.BoolPtrOutput)
}

// Specifies whether the job is allowed to create new tables. The following values are supported:
// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
// Creation, truncation and append actions occur as one atomic update upon job completion
// Default value is `CREATE_IF_NEEDED`.
// Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
func (o JobQueryOutput) CreateDisposition() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQuery) *string { return v.CreateDisposition }).(pulumi.StringPtrOutput)
}

// Specifies the default dataset to use for unqualified table names in the query. Note that this does not alter behavior of unqualified dataset names.
// Structure is documented below.
func (o JobQueryOutput) DefaultDataset() JobQueryDefaultDatasetPtrOutput {
	return o.ApplyT(func(v JobQuery) *JobQueryDefaultDataset { return v.DefaultDataset }).(JobQueryDefaultDatasetPtrOutput)
}

// Custom encryption configuration (e.g., Cloud KMS keys)
// Structure is documented below.
func (o JobQueryOutput) DestinationEncryptionConfiguration() JobQueryDestinationEncryptionConfigurationPtrOutput {
	return o.ApplyT(func(v JobQuery) *JobQueryDestinationEncryptionConfiguration {
		return v.DestinationEncryptionConfiguration
	}).(JobQueryDestinationEncryptionConfigurationPtrOutput)
}

// The destination table.
// Structure is documented below.
func (o JobQueryOutput) DestinationTable() JobQueryDestinationTablePtrOutput {
	return o.ApplyT(func(v JobQuery) *JobQueryDestinationTable { return v.DestinationTable }).(JobQueryDestinationTablePtrOutput)
}

// If true and query uses legacy SQL dialect, flattens all nested and repeated fields in the query results.
// allowLargeResults must be true if this is set to false. For standard SQL queries, this flag is ignored and results are never flattened.
func (o JobQueryOutput) FlattenResults() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v JobQuery) *bool { return v.FlattenResults }).(pulumi.BoolPtrOutput)
}

// Limits the billing tier for this job. Queries that have resource usage beyond this tier will fail (without incurring a charge).
// If unspecified, this will be set to your project default.
func (o JobQueryOutput) MaximumBillingTier() pulumi.IntPtrOutput {
	return o.ApplyT(func(v JobQuery) *int { return v.MaximumBillingTier }).(pulumi.IntPtrOutput)
}

// Limits the bytes billed for this job. Queries that will have bytes billed beyond this limit will fail (without incurring a charge).
// If unspecified, this will be set to your project default.
func (o JobQueryOutput) MaximumBytesBilled() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQuery) *string { return v.MaximumBytesBilled }).(pulumi.StringPtrOutput)
}

// Standard SQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query.
func (o JobQueryOutput) ParameterMode() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQuery) *string { return v.ParameterMode }).(pulumi.StringPtrOutput)
}

// Specifies a priority for the query.
// Default value is `INTERACTIVE`.
// Possible values are `INTERACTIVE` and `BATCH`.
func (o JobQueryOutput) Priority() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQuery) *string { return v.Priority }).(pulumi.StringPtrOutput)
}

// Configures a query job.
// Structure is documented below.
func (o JobQueryOutput) Query() pulumi.StringOutput {
	return o.ApplyT(func(v JobQuery) string { return v.Query }).(pulumi.StringOutput)
}

// Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
// supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
// For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
func (o JobQueryOutput) SchemaUpdateOptions() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobQuery) []string { return v.SchemaUpdateOptions }).(pulumi.StringArrayOutput)
}

// Options controlling the execution of scripts.
// Structure is documented below.
func (o JobQueryOutput) ScriptOptions() JobQueryScriptOptionsPtrOutput {
	return o.ApplyT(func(v JobQuery) *JobQueryScriptOptions { return v.ScriptOptions }).(JobQueryScriptOptionsPtrOutput)
}

// Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true.
// If set to false, the query will use BigQuery's standard SQL.
func (o JobQueryOutput) UseLegacySql() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v JobQuery) *bool { return v.UseLegacySql }).(pulumi.BoolPtrOutput)
}

// Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever
// tables in the query are modified. Moreover, the query cache is only available when a query does not have a destination table specified.
// The default value is true.
func (o JobQueryOutput) UseQueryCache() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v JobQuery) *bool { return v.UseQueryCache }).(pulumi.BoolPtrOutput)
}

// Describes user-defined function resources used in the query.
// Structure is documented below.
func (o JobQueryOutput) UserDefinedFunctionResources() JobQueryUserDefinedFunctionResourceArrayOutput {
	return o.ApplyT(func(v JobQuery) []JobQueryUserDefinedFunctionResource { return v.UserDefinedFunctionResources }).(JobQueryUserDefinedFunctionResourceArrayOutput)
}

// Specifies the action that occurs if the destination table already exists. The following values are supported:
// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
// Creation, truncation and append actions occur as one atomic update upon job completion.
// Default value is `WRITE_EMPTY`.
// Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
func (o JobQueryOutput) WriteDisposition() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQuery) *string { return v.WriteDisposition }).(pulumi.StringPtrOutput)
}

type JobQueryPtrOutput struct{ *pulumi.OutputState }

func (JobQueryPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobQuery)(nil)).Elem()
}

func (o JobQueryPtrOutput) ToJobQueryPtrOutput() JobQueryPtrOutput {
	return o
}

func (o JobQueryPtrOutput) ToJobQueryPtrOutputWithContext(ctx context.Context) JobQueryPtrOutput {
	return o
}

func (o JobQueryPtrOutput) Elem() JobQueryOutput {
	return o.ApplyT(func(v *JobQuery) JobQuery { return *v }).(JobQueryOutput)
}

// If true and query uses legacy SQL dialect, allows the query to produce arbitrarily large result tables at a slight cost in performance.
// Requires destinationTable to be set. For standard SQL queries, this flag is ignored and large results are always allowed.
// However, you must still set destinationTable when result size exceeds the allowed maximum response size.
func (o JobQueryPtrOutput) AllowLargeResults() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *JobQuery) *bool {
		if v == nil {
			return nil
		}
		return v.AllowLargeResults
	}).(pulumi.BoolPtrOutput)
}

// Specifies whether the job is allowed to create new tables. The following values are supported:
// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
// Creation, truncation and append actions occur as one atomic update upon job completion
// Default value is `CREATE_IF_NEEDED`.
// Possible values are `CREATE_IF_NEEDED` and `CREATE_NEVER`.
func (o JobQueryPtrOutput) CreateDisposition() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQuery) *string {
		if v == nil {
			return nil
		}
		return v.CreateDisposition
	}).(pulumi.StringPtrOutput)
}

// Specifies the default dataset to use for unqualified table names in the query. Note that this does not alter behavior of unqualified dataset names.
// Structure is documented below.
func (o JobQueryPtrOutput) DefaultDataset() JobQueryDefaultDatasetPtrOutput {
	return o.ApplyT(func(v *JobQuery) *JobQueryDefaultDataset {
		if v == nil {
			return nil
		}
		return v.DefaultDataset
	}).(JobQueryDefaultDatasetPtrOutput)
}

// Custom encryption configuration (e.g., Cloud KMS keys)
// Structure is documented below.
func (o JobQueryPtrOutput) DestinationEncryptionConfiguration() JobQueryDestinationEncryptionConfigurationPtrOutput {
	return o.ApplyT(func(v *JobQuery) *JobQueryDestinationEncryptionConfiguration {
		if v == nil {
			return nil
		}
		return v.DestinationEncryptionConfiguration
	}).(JobQueryDestinationEncryptionConfigurationPtrOutput)
}

// The destination table.
// Structure is documented below.
func (o JobQueryPtrOutput) DestinationTable() JobQueryDestinationTablePtrOutput {
	return o.ApplyT(func(v *JobQuery) *JobQueryDestinationTable {
		if v == nil {
			return nil
		}
		return v.DestinationTable
	}).(JobQueryDestinationTablePtrOutput)
}

// If true and query uses legacy SQL dialect, flattens all nested and repeated fields in the query results.
// allowLargeResults must be true if this is set to false. For standard SQL queries, this flag is ignored and results are never flattened.
func (o JobQueryPtrOutput) FlattenResults() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *JobQuery) *bool {
		if v == nil {
			return nil
		}
		return v.FlattenResults
	}).(pulumi.BoolPtrOutput)
}

// Limits the billing tier for this job. Queries that have resource usage beyond this tier will fail (without incurring a charge).
// If unspecified, this will be set to your project default.
func (o JobQueryPtrOutput) MaximumBillingTier() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *JobQuery) *int {
		if v == nil {
			return nil
		}
		return v.MaximumBillingTier
	}).(pulumi.IntPtrOutput)
}

// Limits the bytes billed for this job. Queries that will have bytes billed beyond this limit will fail (without incurring a charge).
// If unspecified, this will be set to your project default.
func (o JobQueryPtrOutput) MaximumBytesBilled() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQuery) *string {
		if v == nil {
			return nil
		}
		return v.MaximumBytesBilled
	}).(pulumi.StringPtrOutput)
}

// Standard SQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query.
func (o JobQueryPtrOutput) ParameterMode() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQuery) *string {
		if v == nil {
			return nil
		}
		return v.ParameterMode
	}).(pulumi.StringPtrOutput)
}

// Specifies a priority for the query.
// Default value is `INTERACTIVE`.
// Possible values are `INTERACTIVE` and `BATCH`.
func (o JobQueryPtrOutput) Priority() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQuery) *string {
		if v == nil {
			return nil
		}
		return v.Priority
	}).(pulumi.StringPtrOutput)
}

// Configures a query job.
// Structure is documented below.
func (o JobQueryPtrOutput) Query() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQuery) *string {
		if v == nil {
			return nil
		}
		return &v.Query
	}).(pulumi.StringPtrOutput)
}

// Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
// supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
// For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
func (o JobQueryPtrOutput) SchemaUpdateOptions() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobQuery) []string {
		if v == nil {
			return nil
		}
		return v.SchemaUpdateOptions
	}).(pulumi.StringArrayOutput)
}

// Options controlling the execution of scripts.
// Structure is documented below.
func (o JobQueryPtrOutput) ScriptOptions() JobQueryScriptOptionsPtrOutput {
	return o.ApplyT(func(v *JobQuery) *JobQueryScriptOptions {
		if v == nil {
			return nil
		}
		return v.ScriptOptions
	}).(JobQueryScriptOptionsPtrOutput)
}

// Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true.
// If set to false, the query will use BigQuery's standard SQL.
func (o JobQueryPtrOutput) UseLegacySql() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *JobQuery) *bool {
		if v == nil {
			return nil
		}
		return v.UseLegacySql
	}).(pulumi.BoolPtrOutput)
}

// Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever
// tables in the query are modified. Moreover, the query cache is only available when a query does not have a destination table specified.
// The default value is true.
func (o JobQueryPtrOutput) UseQueryCache() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *JobQuery) *bool {
		if v == nil {
			return nil
		}
		return v.UseQueryCache
	}).(pulumi.BoolPtrOutput)
}

// Describes user-defined function resources used in the query.
// Structure is documented below.
func (o JobQueryPtrOutput) UserDefinedFunctionResources() JobQueryUserDefinedFunctionResourceArrayOutput {
	return o.ApplyT(func(v *JobQuery) []JobQueryUserDefinedFunctionResource {
		if v == nil {
			return nil
		}
		return v.UserDefinedFunctionResources
	}).(JobQueryUserDefinedFunctionResourceArrayOutput)
}

// Specifies the action that occurs if the destination table already exists. The following values are supported:
// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
// Creation, truncation and append actions occur as one atomic update upon job completion.
// Default value is `WRITE_EMPTY`.
// Possible values are `WRITE_TRUNCATE`, `WRITE_APPEND`, and `WRITE_EMPTY`.
func (o JobQueryPtrOutput) WriteDisposition() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQuery) *string {
		if v == nil {
			return nil
		}
		return v.WriteDisposition
	}).(pulumi.StringPtrOutput)
}

type JobQueryDefaultDataset struct {
	// The ID of the dataset containing this model.
	DatasetId string `pulumi:"datasetId"`
	// The ID of the project containing this model.
	ProjectId *string `pulumi:"projectId"`
}

// JobQueryDefaultDatasetInput is an input type that accepts JobQueryDefaultDatasetArgs and JobQueryDefaultDatasetOutput values.
// You can construct a concrete instance of `JobQueryDefaultDatasetInput` via:
//
// 		 JobQueryDefaultDatasetArgs{...}
//
type JobQueryDefaultDatasetInput interface {
	pulumi.Input

	ToJobQueryDefaultDatasetOutput() JobQueryDefaultDatasetOutput
	ToJobQueryDefaultDatasetOutputWithContext(context.Context) JobQueryDefaultDatasetOutput
}

type JobQueryDefaultDatasetArgs struct {
	// The ID of the dataset containing this model.
	DatasetId pulumi.StringInput `pulumi:"datasetId"`
	// The ID of the project containing this model.
	ProjectId pulumi.StringPtrInput `pulumi:"projectId"`
}

func (JobQueryDefaultDatasetArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobQueryDefaultDataset)(nil)).Elem()
}

func (i JobQueryDefaultDatasetArgs) ToJobQueryDefaultDatasetOutput() JobQueryDefaultDatasetOutput {
	return i.ToJobQueryDefaultDatasetOutputWithContext(context.Background())
}

func (i JobQueryDefaultDatasetArgs) ToJobQueryDefaultDatasetOutputWithContext(ctx context.Context) JobQueryDefaultDatasetOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryDefaultDatasetOutput)
}

func (i JobQueryDefaultDatasetArgs) ToJobQueryDefaultDatasetPtrOutput() JobQueryDefaultDatasetPtrOutput {
	return i.ToJobQueryDefaultDatasetPtrOutputWithContext(context.Background())
}

func (i JobQueryDefaultDatasetArgs) ToJobQueryDefaultDatasetPtrOutputWithContext(ctx context.Context) JobQueryDefaultDatasetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryDefaultDatasetOutput).ToJobQueryDefaultDatasetPtrOutputWithContext(ctx)
}

// JobQueryDefaultDatasetPtrInput is an input type that accepts JobQueryDefaultDatasetArgs, JobQueryDefaultDatasetPtr and JobQueryDefaultDatasetPtrOutput values.
// You can construct a concrete instance of `JobQueryDefaultDatasetPtrInput` via:
//
// 		 JobQueryDefaultDatasetArgs{...}
//
//  or:
//
// 		 nil
//
type JobQueryDefaultDatasetPtrInput interface {
	pulumi.Input

	ToJobQueryDefaultDatasetPtrOutput() JobQueryDefaultDatasetPtrOutput
	ToJobQueryDefaultDatasetPtrOutputWithContext(context.Context) JobQueryDefaultDatasetPtrOutput
}

type jobQueryDefaultDatasetPtrType JobQueryDefaultDatasetArgs

func JobQueryDefaultDatasetPtr(v *JobQueryDefaultDatasetArgs) JobQueryDefaultDatasetPtrInput {
	return (*jobQueryDefaultDatasetPtrType)(v)
}

func (*jobQueryDefaultDatasetPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobQueryDefaultDataset)(nil)).Elem()
}

func (i *jobQueryDefaultDatasetPtrType) ToJobQueryDefaultDatasetPtrOutput() JobQueryDefaultDatasetPtrOutput {
	return i.ToJobQueryDefaultDatasetPtrOutputWithContext(context.Background())
}

func (i *jobQueryDefaultDatasetPtrType) ToJobQueryDefaultDatasetPtrOutputWithContext(ctx context.Context) JobQueryDefaultDatasetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryDefaultDatasetPtrOutput)
}

type JobQueryDefaultDatasetOutput struct{ *pulumi.OutputState }

func (JobQueryDefaultDatasetOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobQueryDefaultDataset)(nil)).Elem()
}

func (o JobQueryDefaultDatasetOutput) ToJobQueryDefaultDatasetOutput() JobQueryDefaultDatasetOutput {
	return o
}

func (o JobQueryDefaultDatasetOutput) ToJobQueryDefaultDatasetOutputWithContext(ctx context.Context) JobQueryDefaultDatasetOutput {
	return o
}

func (o JobQueryDefaultDatasetOutput) ToJobQueryDefaultDatasetPtrOutput() JobQueryDefaultDatasetPtrOutput {
	return o.ToJobQueryDefaultDatasetPtrOutputWithContext(context.Background())
}

func (o JobQueryDefaultDatasetOutput) ToJobQueryDefaultDatasetPtrOutputWithContext(ctx context.Context) JobQueryDefaultDatasetPtrOutput {
	return o.ApplyT(func(v JobQueryDefaultDataset) *JobQueryDefaultDataset {
		return &v
	}).(JobQueryDefaultDatasetPtrOutput)
}

// The ID of the dataset containing this model.
func (o JobQueryDefaultDatasetOutput) DatasetId() pulumi.StringOutput {
	return o.ApplyT(func(v JobQueryDefaultDataset) string { return v.DatasetId }).(pulumi.StringOutput)
}

// The ID of the project containing this model.
func (o JobQueryDefaultDatasetOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQueryDefaultDataset) *string { return v.ProjectId }).(pulumi.StringPtrOutput)
}

type JobQueryDefaultDatasetPtrOutput struct{ *pulumi.OutputState }

func (JobQueryDefaultDatasetPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobQueryDefaultDataset)(nil)).Elem()
}

func (o JobQueryDefaultDatasetPtrOutput) ToJobQueryDefaultDatasetPtrOutput() JobQueryDefaultDatasetPtrOutput {
	return o
}

func (o JobQueryDefaultDatasetPtrOutput) ToJobQueryDefaultDatasetPtrOutputWithContext(ctx context.Context) JobQueryDefaultDatasetPtrOutput {
	return o
}

func (o JobQueryDefaultDatasetPtrOutput) Elem() JobQueryDefaultDatasetOutput {
	return o.ApplyT(func(v *JobQueryDefaultDataset) JobQueryDefaultDataset { return *v }).(JobQueryDefaultDatasetOutput)
}

// The ID of the dataset containing this model.
func (o JobQueryDefaultDatasetPtrOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQueryDefaultDataset) *string {
		if v == nil {
			return nil
		}
		return &v.DatasetId
	}).(pulumi.StringPtrOutput)
}

// The ID of the project containing this model.
func (o JobQueryDefaultDatasetPtrOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQueryDefaultDataset) *string {
		if v == nil {
			return nil
		}
		return v.ProjectId
	}).(pulumi.StringPtrOutput)
}

type JobQueryDestinationEncryptionConfiguration struct {
	// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
	// The BigQuery Service Account associated with your project requires access to this encryption key.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// JobQueryDestinationEncryptionConfigurationInput is an input type that accepts JobQueryDestinationEncryptionConfigurationArgs and JobQueryDestinationEncryptionConfigurationOutput values.
// You can construct a concrete instance of `JobQueryDestinationEncryptionConfigurationInput` via:
//
// 		 JobQueryDestinationEncryptionConfigurationArgs{...}
//
type JobQueryDestinationEncryptionConfigurationInput interface {
	pulumi.Input

	ToJobQueryDestinationEncryptionConfigurationOutput() JobQueryDestinationEncryptionConfigurationOutput
	ToJobQueryDestinationEncryptionConfigurationOutputWithContext(context.Context) JobQueryDestinationEncryptionConfigurationOutput
}

type JobQueryDestinationEncryptionConfigurationArgs struct {
	// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
	// The BigQuery Service Account associated with your project requires access to this encryption key.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (JobQueryDestinationEncryptionConfigurationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobQueryDestinationEncryptionConfiguration)(nil)).Elem()
}

func (i JobQueryDestinationEncryptionConfigurationArgs) ToJobQueryDestinationEncryptionConfigurationOutput() JobQueryDestinationEncryptionConfigurationOutput {
	return i.ToJobQueryDestinationEncryptionConfigurationOutputWithContext(context.Background())
}

func (i JobQueryDestinationEncryptionConfigurationArgs) ToJobQueryDestinationEncryptionConfigurationOutputWithContext(ctx context.Context) JobQueryDestinationEncryptionConfigurationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryDestinationEncryptionConfigurationOutput)
}

func (i JobQueryDestinationEncryptionConfigurationArgs) ToJobQueryDestinationEncryptionConfigurationPtrOutput() JobQueryDestinationEncryptionConfigurationPtrOutput {
	return i.ToJobQueryDestinationEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (i JobQueryDestinationEncryptionConfigurationArgs) ToJobQueryDestinationEncryptionConfigurationPtrOutputWithContext(ctx context.Context) JobQueryDestinationEncryptionConfigurationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryDestinationEncryptionConfigurationOutput).ToJobQueryDestinationEncryptionConfigurationPtrOutputWithContext(ctx)
}

// JobQueryDestinationEncryptionConfigurationPtrInput is an input type that accepts JobQueryDestinationEncryptionConfigurationArgs, JobQueryDestinationEncryptionConfigurationPtr and JobQueryDestinationEncryptionConfigurationPtrOutput values.
// You can construct a concrete instance of `JobQueryDestinationEncryptionConfigurationPtrInput` via:
//
// 		 JobQueryDestinationEncryptionConfigurationArgs{...}
//
//  or:
//
// 		 nil
//
type JobQueryDestinationEncryptionConfigurationPtrInput interface {
	pulumi.Input

	ToJobQueryDestinationEncryptionConfigurationPtrOutput() JobQueryDestinationEncryptionConfigurationPtrOutput
	ToJobQueryDestinationEncryptionConfigurationPtrOutputWithContext(context.Context) JobQueryDestinationEncryptionConfigurationPtrOutput
}

type jobQueryDestinationEncryptionConfigurationPtrType JobQueryDestinationEncryptionConfigurationArgs

func JobQueryDestinationEncryptionConfigurationPtr(v *JobQueryDestinationEncryptionConfigurationArgs) JobQueryDestinationEncryptionConfigurationPtrInput {
	return (*jobQueryDestinationEncryptionConfigurationPtrType)(v)
}

func (*jobQueryDestinationEncryptionConfigurationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobQueryDestinationEncryptionConfiguration)(nil)).Elem()
}

func (i *jobQueryDestinationEncryptionConfigurationPtrType) ToJobQueryDestinationEncryptionConfigurationPtrOutput() JobQueryDestinationEncryptionConfigurationPtrOutput {
	return i.ToJobQueryDestinationEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (i *jobQueryDestinationEncryptionConfigurationPtrType) ToJobQueryDestinationEncryptionConfigurationPtrOutputWithContext(ctx context.Context) JobQueryDestinationEncryptionConfigurationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryDestinationEncryptionConfigurationPtrOutput)
}

type JobQueryDestinationEncryptionConfigurationOutput struct{ *pulumi.OutputState }

func (JobQueryDestinationEncryptionConfigurationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobQueryDestinationEncryptionConfiguration)(nil)).Elem()
}

func (o JobQueryDestinationEncryptionConfigurationOutput) ToJobQueryDestinationEncryptionConfigurationOutput() JobQueryDestinationEncryptionConfigurationOutput {
	return o
}

func (o JobQueryDestinationEncryptionConfigurationOutput) ToJobQueryDestinationEncryptionConfigurationOutputWithContext(ctx context.Context) JobQueryDestinationEncryptionConfigurationOutput {
	return o
}

func (o JobQueryDestinationEncryptionConfigurationOutput) ToJobQueryDestinationEncryptionConfigurationPtrOutput() JobQueryDestinationEncryptionConfigurationPtrOutput {
	return o.ToJobQueryDestinationEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (o JobQueryDestinationEncryptionConfigurationOutput) ToJobQueryDestinationEncryptionConfigurationPtrOutputWithContext(ctx context.Context) JobQueryDestinationEncryptionConfigurationPtrOutput {
	return o.ApplyT(func(v JobQueryDestinationEncryptionConfiguration) *JobQueryDestinationEncryptionConfiguration {
		return &v
	}).(JobQueryDestinationEncryptionConfigurationPtrOutput)
}

// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
// The BigQuery Service Account associated with your project requires access to this encryption key.
func (o JobQueryDestinationEncryptionConfigurationOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v JobQueryDestinationEncryptionConfiguration) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type JobQueryDestinationEncryptionConfigurationPtrOutput struct{ *pulumi.OutputState }

func (JobQueryDestinationEncryptionConfigurationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobQueryDestinationEncryptionConfiguration)(nil)).Elem()
}

func (o JobQueryDestinationEncryptionConfigurationPtrOutput) ToJobQueryDestinationEncryptionConfigurationPtrOutput() JobQueryDestinationEncryptionConfigurationPtrOutput {
	return o
}

func (o JobQueryDestinationEncryptionConfigurationPtrOutput) ToJobQueryDestinationEncryptionConfigurationPtrOutputWithContext(ctx context.Context) JobQueryDestinationEncryptionConfigurationPtrOutput {
	return o
}

func (o JobQueryDestinationEncryptionConfigurationPtrOutput) Elem() JobQueryDestinationEncryptionConfigurationOutput {
	return o.ApplyT(func(v *JobQueryDestinationEncryptionConfiguration) JobQueryDestinationEncryptionConfiguration {
		return *v
	}).(JobQueryDestinationEncryptionConfigurationOutput)
}

// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
// The BigQuery Service Account associated with your project requires access to this encryption key.
func (o JobQueryDestinationEncryptionConfigurationPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQueryDestinationEncryptionConfiguration) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type JobQueryDestinationTable struct {
	// The ID of the dataset containing this model.
	DatasetId *string `pulumi:"datasetId"`
	// The ID of the project containing this model.
	ProjectId *string `pulumi:"projectId"`
	// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
	// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
	TableId string `pulumi:"tableId"`
}

// JobQueryDestinationTableInput is an input type that accepts JobQueryDestinationTableArgs and JobQueryDestinationTableOutput values.
// You can construct a concrete instance of `JobQueryDestinationTableInput` via:
//
// 		 JobQueryDestinationTableArgs{...}
//
type JobQueryDestinationTableInput interface {
	pulumi.Input

	ToJobQueryDestinationTableOutput() JobQueryDestinationTableOutput
	ToJobQueryDestinationTableOutputWithContext(context.Context) JobQueryDestinationTableOutput
}

type JobQueryDestinationTableArgs struct {
	// The ID of the dataset containing this model.
	DatasetId pulumi.StringPtrInput `pulumi:"datasetId"`
	// The ID of the project containing this model.
	ProjectId pulumi.StringPtrInput `pulumi:"projectId"`
	// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
	// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
	TableId pulumi.StringInput `pulumi:"tableId"`
}

func (JobQueryDestinationTableArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobQueryDestinationTable)(nil)).Elem()
}

func (i JobQueryDestinationTableArgs) ToJobQueryDestinationTableOutput() JobQueryDestinationTableOutput {
	return i.ToJobQueryDestinationTableOutputWithContext(context.Background())
}

func (i JobQueryDestinationTableArgs) ToJobQueryDestinationTableOutputWithContext(ctx context.Context) JobQueryDestinationTableOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryDestinationTableOutput)
}

func (i JobQueryDestinationTableArgs) ToJobQueryDestinationTablePtrOutput() JobQueryDestinationTablePtrOutput {
	return i.ToJobQueryDestinationTablePtrOutputWithContext(context.Background())
}

func (i JobQueryDestinationTableArgs) ToJobQueryDestinationTablePtrOutputWithContext(ctx context.Context) JobQueryDestinationTablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryDestinationTableOutput).ToJobQueryDestinationTablePtrOutputWithContext(ctx)
}

// JobQueryDestinationTablePtrInput is an input type that accepts JobQueryDestinationTableArgs, JobQueryDestinationTablePtr and JobQueryDestinationTablePtrOutput values.
// You can construct a concrete instance of `JobQueryDestinationTablePtrInput` via:
//
// 		 JobQueryDestinationTableArgs{...}
//
//  or:
//
// 		 nil
//
type JobQueryDestinationTablePtrInput interface {
	pulumi.Input

	ToJobQueryDestinationTablePtrOutput() JobQueryDestinationTablePtrOutput
	ToJobQueryDestinationTablePtrOutputWithContext(context.Context) JobQueryDestinationTablePtrOutput
}

type jobQueryDestinationTablePtrType JobQueryDestinationTableArgs

func JobQueryDestinationTablePtr(v *JobQueryDestinationTableArgs) JobQueryDestinationTablePtrInput {
	return (*jobQueryDestinationTablePtrType)(v)
}

func (*jobQueryDestinationTablePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobQueryDestinationTable)(nil)).Elem()
}

func (i *jobQueryDestinationTablePtrType) ToJobQueryDestinationTablePtrOutput() JobQueryDestinationTablePtrOutput {
	return i.ToJobQueryDestinationTablePtrOutputWithContext(context.Background())
}

func (i *jobQueryDestinationTablePtrType) ToJobQueryDestinationTablePtrOutputWithContext(ctx context.Context) JobQueryDestinationTablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryDestinationTablePtrOutput)
}

type JobQueryDestinationTableOutput struct{ *pulumi.OutputState }

func (JobQueryDestinationTableOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobQueryDestinationTable)(nil)).Elem()
}

func (o JobQueryDestinationTableOutput) ToJobQueryDestinationTableOutput() JobQueryDestinationTableOutput {
	return o
}

func (o JobQueryDestinationTableOutput) ToJobQueryDestinationTableOutputWithContext(ctx context.Context) JobQueryDestinationTableOutput {
	return o
}

func (o JobQueryDestinationTableOutput) ToJobQueryDestinationTablePtrOutput() JobQueryDestinationTablePtrOutput {
	return o.ToJobQueryDestinationTablePtrOutputWithContext(context.Background())
}

func (o JobQueryDestinationTableOutput) ToJobQueryDestinationTablePtrOutputWithContext(ctx context.Context) JobQueryDestinationTablePtrOutput {
	return o.ApplyT(func(v JobQueryDestinationTable) *JobQueryDestinationTable {
		return &v
	}).(JobQueryDestinationTablePtrOutput)
}

// The ID of the dataset containing this model.
func (o JobQueryDestinationTableOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQueryDestinationTable) *string { return v.DatasetId }).(pulumi.StringPtrOutput)
}

// The ID of the project containing this model.
func (o JobQueryDestinationTableOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQueryDestinationTable) *string { return v.ProjectId }).(pulumi.StringPtrOutput)
}

// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
func (o JobQueryDestinationTableOutput) TableId() pulumi.StringOutput {
	return o.ApplyT(func(v JobQueryDestinationTable) string { return v.TableId }).(pulumi.StringOutput)
}

type JobQueryDestinationTablePtrOutput struct{ *pulumi.OutputState }

func (JobQueryDestinationTablePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobQueryDestinationTable)(nil)).Elem()
}

func (o JobQueryDestinationTablePtrOutput) ToJobQueryDestinationTablePtrOutput() JobQueryDestinationTablePtrOutput {
	return o
}

func (o JobQueryDestinationTablePtrOutput) ToJobQueryDestinationTablePtrOutputWithContext(ctx context.Context) JobQueryDestinationTablePtrOutput {
	return o
}

func (o JobQueryDestinationTablePtrOutput) Elem() JobQueryDestinationTableOutput {
	return o.ApplyT(func(v *JobQueryDestinationTable) JobQueryDestinationTable { return *v }).(JobQueryDestinationTableOutput)
}

// The ID of the dataset containing this model.
func (o JobQueryDestinationTablePtrOutput) DatasetId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQueryDestinationTable) *string {
		if v == nil {
			return nil
		}
		return v.DatasetId
	}).(pulumi.StringPtrOutput)
}

// The ID of the project containing this model.
func (o JobQueryDestinationTablePtrOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQueryDestinationTable) *string {
		if v == nil {
			return nil
		}
		return v.ProjectId
	}).(pulumi.StringPtrOutput)
}

// The table. Can be specified `{{table_id}}` if `projectId` and `datasetId` are also set,
// or of the form `projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}` if not.
func (o JobQueryDestinationTablePtrOutput) TableId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQueryDestinationTable) *string {
		if v == nil {
			return nil
		}
		return &v.TableId
	}).(pulumi.StringPtrOutput)
}

type JobQueryScriptOptions struct {
	// Determines which statement in the script represents the "key result",
	// used to populate the schema and query results of the script job.
	// Possible values are `LAST` and `FIRST_SELECT`.
	KeyResultStatement *string `pulumi:"keyResultStatement"`
	// Limit on the number of bytes billed per statement. Exceeding this budget results in an error.
	StatementByteBudget *string `pulumi:"statementByteBudget"`
	// Timeout period for each statement in a script.
	StatementTimeoutMs *string `pulumi:"statementTimeoutMs"`
}

// JobQueryScriptOptionsInput is an input type that accepts JobQueryScriptOptionsArgs and JobQueryScriptOptionsOutput values.
// You can construct a concrete instance of `JobQueryScriptOptionsInput` via:
//
// 		 JobQueryScriptOptionsArgs{...}
//
type JobQueryScriptOptionsInput interface {
	pulumi.Input

	ToJobQueryScriptOptionsOutput() JobQueryScriptOptionsOutput
	ToJobQueryScriptOptionsOutputWithContext(context.Context) JobQueryScriptOptionsOutput
}

type JobQueryScriptOptionsArgs struct {
	// Determines which statement in the script represents the "key result",
	// used to populate the schema and query results of the script job.
	// Possible values are `LAST` and `FIRST_SELECT`.
	KeyResultStatement pulumi.StringPtrInput `pulumi:"keyResultStatement"`
	// Limit on the number of bytes billed per statement. Exceeding this budget results in an error.
	StatementByteBudget pulumi.StringPtrInput `pulumi:"statementByteBudget"`
	// Timeout period for each statement in a script.
	StatementTimeoutMs pulumi.StringPtrInput `pulumi:"statementTimeoutMs"`
}

func (JobQueryScriptOptionsArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobQueryScriptOptions)(nil)).Elem()
}

func (i JobQueryScriptOptionsArgs) ToJobQueryScriptOptionsOutput() JobQueryScriptOptionsOutput {
	return i.ToJobQueryScriptOptionsOutputWithContext(context.Background())
}

func (i JobQueryScriptOptionsArgs) ToJobQueryScriptOptionsOutputWithContext(ctx context.Context) JobQueryScriptOptionsOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryScriptOptionsOutput)
}

func (i JobQueryScriptOptionsArgs) ToJobQueryScriptOptionsPtrOutput() JobQueryScriptOptionsPtrOutput {
	return i.ToJobQueryScriptOptionsPtrOutputWithContext(context.Background())
}

func (i JobQueryScriptOptionsArgs) ToJobQueryScriptOptionsPtrOutputWithContext(ctx context.Context) JobQueryScriptOptionsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryScriptOptionsOutput).ToJobQueryScriptOptionsPtrOutputWithContext(ctx)
}

// JobQueryScriptOptionsPtrInput is an input type that accepts JobQueryScriptOptionsArgs, JobQueryScriptOptionsPtr and JobQueryScriptOptionsPtrOutput values.
// You can construct a concrete instance of `JobQueryScriptOptionsPtrInput` via:
//
// 		 JobQueryScriptOptionsArgs{...}
//
//  or:
//
// 		 nil
//
type JobQueryScriptOptionsPtrInput interface {
	pulumi.Input

	ToJobQueryScriptOptionsPtrOutput() JobQueryScriptOptionsPtrOutput
	ToJobQueryScriptOptionsPtrOutputWithContext(context.Context) JobQueryScriptOptionsPtrOutput
}

type jobQueryScriptOptionsPtrType JobQueryScriptOptionsArgs

func JobQueryScriptOptionsPtr(v *JobQueryScriptOptionsArgs) JobQueryScriptOptionsPtrInput {
	return (*jobQueryScriptOptionsPtrType)(v)
}

func (*jobQueryScriptOptionsPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobQueryScriptOptions)(nil)).Elem()
}

func (i *jobQueryScriptOptionsPtrType) ToJobQueryScriptOptionsPtrOutput() JobQueryScriptOptionsPtrOutput {
	return i.ToJobQueryScriptOptionsPtrOutputWithContext(context.Background())
}

func (i *jobQueryScriptOptionsPtrType) ToJobQueryScriptOptionsPtrOutputWithContext(ctx context.Context) JobQueryScriptOptionsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryScriptOptionsPtrOutput)
}

type JobQueryScriptOptionsOutput struct{ *pulumi.OutputState }

func (JobQueryScriptOptionsOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobQueryScriptOptions)(nil)).Elem()
}

func (o JobQueryScriptOptionsOutput) ToJobQueryScriptOptionsOutput() JobQueryScriptOptionsOutput {
	return o
}

func (o JobQueryScriptOptionsOutput) ToJobQueryScriptOptionsOutputWithContext(ctx context.Context) JobQueryScriptOptionsOutput {
	return o
}

func (o JobQueryScriptOptionsOutput) ToJobQueryScriptOptionsPtrOutput() JobQueryScriptOptionsPtrOutput {
	return o.ToJobQueryScriptOptionsPtrOutputWithContext(context.Background())
}

func (o JobQueryScriptOptionsOutput) ToJobQueryScriptOptionsPtrOutputWithContext(ctx context.Context) JobQueryScriptOptionsPtrOutput {
	return o.ApplyT(func(v JobQueryScriptOptions) *JobQueryScriptOptions {
		return &v
	}).(JobQueryScriptOptionsPtrOutput)
}

// Determines which statement in the script represents the "key result",
// used to populate the schema and query results of the script job.
// Possible values are `LAST` and `FIRST_SELECT`.
func (o JobQueryScriptOptionsOutput) KeyResultStatement() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQueryScriptOptions) *string { return v.KeyResultStatement }).(pulumi.StringPtrOutput)
}

// Limit on the number of bytes billed per statement. Exceeding this budget results in an error.
func (o JobQueryScriptOptionsOutput) StatementByteBudget() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQueryScriptOptions) *string { return v.StatementByteBudget }).(pulumi.StringPtrOutput)
}

// Timeout period for each statement in a script.
func (o JobQueryScriptOptionsOutput) StatementTimeoutMs() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQueryScriptOptions) *string { return v.StatementTimeoutMs }).(pulumi.StringPtrOutput)
}

type JobQueryScriptOptionsPtrOutput struct{ *pulumi.OutputState }

func (JobQueryScriptOptionsPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobQueryScriptOptions)(nil)).Elem()
}

func (o JobQueryScriptOptionsPtrOutput) ToJobQueryScriptOptionsPtrOutput() JobQueryScriptOptionsPtrOutput {
	return o
}

func (o JobQueryScriptOptionsPtrOutput) ToJobQueryScriptOptionsPtrOutputWithContext(ctx context.Context) JobQueryScriptOptionsPtrOutput {
	return o
}

func (o JobQueryScriptOptionsPtrOutput) Elem() JobQueryScriptOptionsOutput {
	return o.ApplyT(func(v *JobQueryScriptOptions) JobQueryScriptOptions { return *v }).(JobQueryScriptOptionsOutput)
}

// Determines which statement in the script represents the "key result",
// used to populate the schema and query results of the script job.
// Possible values are `LAST` and `FIRST_SELECT`.
func (o JobQueryScriptOptionsPtrOutput) KeyResultStatement() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQueryScriptOptions) *string {
		if v == nil {
			return nil
		}
		return v.KeyResultStatement
	}).(pulumi.StringPtrOutput)
}

// Limit on the number of bytes billed per statement. Exceeding this budget results in an error.
func (o JobQueryScriptOptionsPtrOutput) StatementByteBudget() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQueryScriptOptions) *string {
		if v == nil {
			return nil
		}
		return v.StatementByteBudget
	}).(pulumi.StringPtrOutput)
}

// Timeout period for each statement in a script.
func (o JobQueryScriptOptionsPtrOutput) StatementTimeoutMs() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobQueryScriptOptions) *string {
		if v == nil {
			return nil
		}
		return v.StatementTimeoutMs
	}).(pulumi.StringPtrOutput)
}

type JobQueryUserDefinedFunctionResource struct {
	// An inline resource that contains code for a user-defined function (UDF).
	// Providing a inline code resource is equivalent to providing a URI for a file containing the same code.
	InlineCode *string `pulumi:"inlineCode"`
	// A code resource to load from a Google Cloud Storage URI (gs://bucket/path).
	ResourceUri *string `pulumi:"resourceUri"`
}

// JobQueryUserDefinedFunctionResourceInput is an input type that accepts JobQueryUserDefinedFunctionResourceArgs and JobQueryUserDefinedFunctionResourceOutput values.
// You can construct a concrete instance of `JobQueryUserDefinedFunctionResourceInput` via:
//
// 		 JobQueryUserDefinedFunctionResourceArgs{...}
//
type JobQueryUserDefinedFunctionResourceInput interface {
	pulumi.Input

	ToJobQueryUserDefinedFunctionResourceOutput() JobQueryUserDefinedFunctionResourceOutput
	ToJobQueryUserDefinedFunctionResourceOutputWithContext(context.Context) JobQueryUserDefinedFunctionResourceOutput
}

type JobQueryUserDefinedFunctionResourceArgs struct {
	// An inline resource that contains code for a user-defined function (UDF).
	// Providing a inline code resource is equivalent to providing a URI for a file containing the same code.
	InlineCode pulumi.StringPtrInput `pulumi:"inlineCode"`
	// A code resource to load from a Google Cloud Storage URI (gs://bucket/path).
	ResourceUri pulumi.StringPtrInput `pulumi:"resourceUri"`
}

func (JobQueryUserDefinedFunctionResourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobQueryUserDefinedFunctionResource)(nil)).Elem()
}

func (i JobQueryUserDefinedFunctionResourceArgs) ToJobQueryUserDefinedFunctionResourceOutput() JobQueryUserDefinedFunctionResourceOutput {
	return i.ToJobQueryUserDefinedFunctionResourceOutputWithContext(context.Background())
}

func (i JobQueryUserDefinedFunctionResourceArgs) ToJobQueryUserDefinedFunctionResourceOutputWithContext(ctx context.Context) JobQueryUserDefinedFunctionResourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryUserDefinedFunctionResourceOutput)
}

// JobQueryUserDefinedFunctionResourceArrayInput is an input type that accepts JobQueryUserDefinedFunctionResourceArray and JobQueryUserDefinedFunctionResourceArrayOutput values.
// You can construct a concrete instance of `JobQueryUserDefinedFunctionResourceArrayInput` via:
//
// 		 JobQueryUserDefinedFunctionResourceArray{ JobQueryUserDefinedFunctionResourceArgs{...} }
//
type JobQueryUserDefinedFunctionResourceArrayInput interface {
	pulumi.Input

	ToJobQueryUserDefinedFunctionResourceArrayOutput() JobQueryUserDefinedFunctionResourceArrayOutput
	ToJobQueryUserDefinedFunctionResourceArrayOutputWithContext(context.Context) JobQueryUserDefinedFunctionResourceArrayOutput
}

type JobQueryUserDefinedFunctionResourceArray []JobQueryUserDefinedFunctionResourceInput

func (JobQueryUserDefinedFunctionResourceArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]JobQueryUserDefinedFunctionResource)(nil)).Elem()
}

func (i JobQueryUserDefinedFunctionResourceArray) ToJobQueryUserDefinedFunctionResourceArrayOutput() JobQueryUserDefinedFunctionResourceArrayOutput {
	return i.ToJobQueryUserDefinedFunctionResourceArrayOutputWithContext(context.Background())
}

func (i JobQueryUserDefinedFunctionResourceArray) ToJobQueryUserDefinedFunctionResourceArrayOutputWithContext(ctx context.Context) JobQueryUserDefinedFunctionResourceArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobQueryUserDefinedFunctionResourceArrayOutput)
}

type JobQueryUserDefinedFunctionResourceOutput struct{ *pulumi.OutputState }

func (JobQueryUserDefinedFunctionResourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobQueryUserDefinedFunctionResource)(nil)).Elem()
}

func (o JobQueryUserDefinedFunctionResourceOutput) ToJobQueryUserDefinedFunctionResourceOutput() JobQueryUserDefinedFunctionResourceOutput {
	return o
}

func (o JobQueryUserDefinedFunctionResourceOutput) ToJobQueryUserDefinedFunctionResourceOutputWithContext(ctx context.Context) JobQueryUserDefinedFunctionResourceOutput {
	return o
}

// An inline resource that contains code for a user-defined function (UDF).
// Providing a inline code resource is equivalent to providing a URI for a file containing the same code.
func (o JobQueryUserDefinedFunctionResourceOutput) InlineCode() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQueryUserDefinedFunctionResource) *string { return v.InlineCode }).(pulumi.StringPtrOutput)
}

// A code resource to load from a Google Cloud Storage URI (gs://bucket/path).
func (o JobQueryUserDefinedFunctionResourceOutput) ResourceUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobQueryUserDefinedFunctionResource) *string { return v.ResourceUri }).(pulumi.StringPtrOutput)
}

type JobQueryUserDefinedFunctionResourceArrayOutput struct{ *pulumi.OutputState }

func (JobQueryUserDefinedFunctionResourceArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]JobQueryUserDefinedFunctionResource)(nil)).Elem()
}

func (o JobQueryUserDefinedFunctionResourceArrayOutput) ToJobQueryUserDefinedFunctionResourceArrayOutput() JobQueryUserDefinedFunctionResourceArrayOutput {
	return o
}

func (o JobQueryUserDefinedFunctionResourceArrayOutput) ToJobQueryUserDefinedFunctionResourceArrayOutputWithContext(ctx context.Context) JobQueryUserDefinedFunctionResourceArrayOutput {
	return o
}

func (o JobQueryUserDefinedFunctionResourceArrayOutput) Index(i pulumi.IntInput) JobQueryUserDefinedFunctionResourceOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) JobQueryUserDefinedFunctionResource {
		return vs[0].([]JobQueryUserDefinedFunctionResource)[vs[1].(int)]
	}).(JobQueryUserDefinedFunctionResourceOutput)
}

type TableEncryptionConfiguration struct {
	// The self link or full name of a key which should be used to
	// encrypt this table.  Note that the default bigquery service account will need to have
	// encrypt/decrypt permissions on this key - you may want to see the
	// `bigquery.getDefaultServiceAccount` datasource and the
	// `kms.CryptoKeyIAMBinding` resource.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// TableEncryptionConfigurationInput is an input type that accepts TableEncryptionConfigurationArgs and TableEncryptionConfigurationOutput values.
// You can construct a concrete instance of `TableEncryptionConfigurationInput` via:
//
// 		 TableEncryptionConfigurationArgs{...}
//
type TableEncryptionConfigurationInput interface {
	pulumi.Input

	ToTableEncryptionConfigurationOutput() TableEncryptionConfigurationOutput
	ToTableEncryptionConfigurationOutputWithContext(context.Context) TableEncryptionConfigurationOutput
}

type TableEncryptionConfigurationArgs struct {
	// The self link or full name of a key which should be used to
	// encrypt this table.  Note that the default bigquery service account will need to have
	// encrypt/decrypt permissions on this key - you may want to see the
	// `bigquery.getDefaultServiceAccount` datasource and the
	// `kms.CryptoKeyIAMBinding` resource.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (TableEncryptionConfigurationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*TableEncryptionConfiguration)(nil)).Elem()
}

func (i TableEncryptionConfigurationArgs) ToTableEncryptionConfigurationOutput() TableEncryptionConfigurationOutput {
	return i.ToTableEncryptionConfigurationOutputWithContext(context.Background())
}

func (i TableEncryptionConfigurationArgs) ToTableEncryptionConfigurationOutputWithContext(ctx context.Context) TableEncryptionConfigurationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableEncryptionConfigurationOutput)
}

func (i TableEncryptionConfigurationArgs) ToTableEncryptionConfigurationPtrOutput() TableEncryptionConfigurationPtrOutput {
	return i.ToTableEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (i TableEncryptionConfigurationArgs) ToTableEncryptionConfigurationPtrOutputWithContext(ctx context.Context) TableEncryptionConfigurationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableEncryptionConfigurationOutput).ToTableEncryptionConfigurationPtrOutputWithContext(ctx)
}

// TableEncryptionConfigurationPtrInput is an input type that accepts TableEncryptionConfigurationArgs, TableEncryptionConfigurationPtr and TableEncryptionConfigurationPtrOutput values.
// You can construct a concrete instance of `TableEncryptionConfigurationPtrInput` via:
//
// 		 TableEncryptionConfigurationArgs{...}
//
//  or:
//
// 		 nil
//
type TableEncryptionConfigurationPtrInput interface {
	pulumi.Input

	ToTableEncryptionConfigurationPtrOutput() TableEncryptionConfigurationPtrOutput
	ToTableEncryptionConfigurationPtrOutputWithContext(context.Context) TableEncryptionConfigurationPtrOutput
}

type tableEncryptionConfigurationPtrType TableEncryptionConfigurationArgs

func TableEncryptionConfigurationPtr(v *TableEncryptionConfigurationArgs) TableEncryptionConfigurationPtrInput {
	return (*tableEncryptionConfigurationPtrType)(v)
}

func (*tableEncryptionConfigurationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**TableEncryptionConfiguration)(nil)).Elem()
}

func (i *tableEncryptionConfigurationPtrType) ToTableEncryptionConfigurationPtrOutput() TableEncryptionConfigurationPtrOutput {
	return i.ToTableEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (i *tableEncryptionConfigurationPtrType) ToTableEncryptionConfigurationPtrOutputWithContext(ctx context.Context) TableEncryptionConfigurationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableEncryptionConfigurationPtrOutput)
}

type TableEncryptionConfigurationOutput struct{ *pulumi.OutputState }

func (TableEncryptionConfigurationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*TableEncryptionConfiguration)(nil)).Elem()
}

func (o TableEncryptionConfigurationOutput) ToTableEncryptionConfigurationOutput() TableEncryptionConfigurationOutput {
	return o
}

func (o TableEncryptionConfigurationOutput) ToTableEncryptionConfigurationOutputWithContext(ctx context.Context) TableEncryptionConfigurationOutput {
	return o
}

func (o TableEncryptionConfigurationOutput) ToTableEncryptionConfigurationPtrOutput() TableEncryptionConfigurationPtrOutput {
	return o.ToTableEncryptionConfigurationPtrOutputWithContext(context.Background())
}

func (o TableEncryptionConfigurationOutput) ToTableEncryptionConfigurationPtrOutputWithContext(ctx context.Context) TableEncryptionConfigurationPtrOutput {
	return o.ApplyT(func(v TableEncryptionConfiguration) *TableEncryptionConfiguration {
		return &v
	}).(TableEncryptionConfigurationPtrOutput)
}

// The self link or full name of a key which should be used to
// encrypt this table.  Note that the default bigquery service account will need to have
// encrypt/decrypt permissions on this key - you may want to see the
// `bigquery.getDefaultServiceAccount` datasource and the
// `kms.CryptoKeyIAMBinding` resource.
func (o TableEncryptionConfigurationOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v TableEncryptionConfiguration) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type TableEncryptionConfigurationPtrOutput struct{ *pulumi.OutputState }

func (TableEncryptionConfigurationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**TableEncryptionConfiguration)(nil)).Elem()
}

func (o TableEncryptionConfigurationPtrOutput) ToTableEncryptionConfigurationPtrOutput() TableEncryptionConfigurationPtrOutput {
	return o
}

func (o TableEncryptionConfigurationPtrOutput) ToTableEncryptionConfigurationPtrOutputWithContext(ctx context.Context) TableEncryptionConfigurationPtrOutput {
	return o
}

func (o TableEncryptionConfigurationPtrOutput) Elem() TableEncryptionConfigurationOutput {
	return o.ApplyT(func(v *TableEncryptionConfiguration) TableEncryptionConfiguration { return *v }).(TableEncryptionConfigurationOutput)
}

// The self link or full name of a key which should be used to
// encrypt this table.  Note that the default bigquery service account will need to have
// encrypt/decrypt permissions on this key - you may want to see the
// `bigquery.getDefaultServiceAccount` datasource and the
// `kms.CryptoKeyIAMBinding` resource.
func (o TableEncryptionConfigurationPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableEncryptionConfiguration) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type TableExternalDataConfiguration struct {
	// - Let BigQuery try to autodetect the schema
	// and format of the table.
	Autodetect bool `pulumi:"autodetect"`
	// The compression type of the data source.
	// Valid values are "NONE" or "GZIP".
	Compression *string `pulumi:"compression"`
	// Additional properties to set if
	// `sourceFormat` is set to "CSV". Structure is documented below.
	CsvOptions *TableExternalDataConfigurationCsvOptions `pulumi:"csvOptions"`
	// Additional options if
	// `sourceFormat` is set to "GOOGLE_SHEETS". Structure is
	// documented below.
	GoogleSheetsOptions *TableExternalDataConfigurationGoogleSheetsOptions `pulumi:"googleSheetsOptions"`
	// When set, configures hive partitioning
	// support. Not all storage formats support hive partitioning -- requesting hive
	// partitioning on an unsupported format will lead to an error, as will providing
	// an invalid specification.
	HivePartitioningOptions *TableExternalDataConfigurationHivePartitioningOptions `pulumi:"hivePartitioningOptions"`
	// Indicates if BigQuery should
	// allow extra values that are not represented in the table schema.
	// If true, the extra values are ignored. If false, records with
	// extra columns are treated as bad records, and if there are too
	// many bad records, an invalid error is returned in the job result.
	// The default value is false.
	IgnoreUnknownValues *bool `pulumi:"ignoreUnknownValues"`
	// The maximum number of bad records that
	// BigQuery can ignore when reading data.
	MaxBadRecords *int `pulumi:"maxBadRecords"`
	// A JSON schema for the external table. Schema is required
	// for CSV and JSON formats if autodetect is not on. Schema is disallowed
	// for Google Cloud Bigtable, Cloud Datastore backups, Avro, ORC and Parquet formats.
	// ~>**NOTE:** Because this field expects a JSON string, any changes to the
	// string will create a diff, even if the JSON itself hasn't changed.
	// Furthermore drift for this field cannot not be detected because BigQuery
	// only uses this schema to compute the effective schema for the table, therefore
	// any changes on the configured value will force the table to be recreated.
	// This schema is effectively only applied when creating a table from an external
	// datasource, after creation the computed schema will be stored in
	// `google_bigquery_table.schema`
	Schema *string `pulumi:"schema"`
	// The data format. Supported values are:
	// "CSV", "GOOGLE_SHEETS", "NEWLINE_DELIMITED_JSON", "AVRO", "PARQUET",
	// and "DATSTORE_BACKUP". To use "GOOGLE_SHEETS"
	// the `scopes` must include
	// "https://www.googleapis.com/auth/drive.readonly".
	SourceFormat string `pulumi:"sourceFormat"`
	// A list of the fully-qualified URIs that point to
	// your data in Google Cloud.
	SourceUris []string `pulumi:"sourceUris"`
}

// TableExternalDataConfigurationInput is an input type that accepts TableExternalDataConfigurationArgs and TableExternalDataConfigurationOutput values.
// You can construct a concrete instance of `TableExternalDataConfigurationInput` via:
//
// 		 TableExternalDataConfigurationArgs{...}
//
type TableExternalDataConfigurationInput interface {
	pulumi.Input

	ToTableExternalDataConfigurationOutput() TableExternalDataConfigurationOutput
	ToTableExternalDataConfigurationOutputWithContext(context.Context) TableExternalDataConfigurationOutput
}

type TableExternalDataConfigurationArgs struct {
	// - Let BigQuery try to autodetect the schema
	// and format of the table.
	Autodetect pulumi.BoolInput `pulumi:"autodetect"`
	// The compression type of the data source.
	// Valid values are "NONE" or "GZIP".
	Compression pulumi.StringPtrInput `pulumi:"compression"`
	// Additional properties to set if
	// `sourceFormat` is set to "CSV". Structure is documented below.
	CsvOptions TableExternalDataConfigurationCsvOptionsPtrInput `pulumi:"csvOptions"`
	// Additional options if
	// `sourceFormat` is set to "GOOGLE_SHEETS". Structure is
	// documented below.
	GoogleSheetsOptions TableExternalDataConfigurationGoogleSheetsOptionsPtrInput `pulumi:"googleSheetsOptions"`
	// When set, configures hive partitioning
	// support. Not all storage formats support hive partitioning -- requesting hive
	// partitioning on an unsupported format will lead to an error, as will providing
	// an invalid specification.
	HivePartitioningOptions TableExternalDataConfigurationHivePartitioningOptionsPtrInput `pulumi:"hivePartitioningOptions"`
	// Indicates if BigQuery should
	// allow extra values that are not represented in the table schema.
	// If true, the extra values are ignored. If false, records with
	// extra columns are treated as bad records, and if there are too
	// many bad records, an invalid error is returned in the job result.
	// The default value is false.
	IgnoreUnknownValues pulumi.BoolPtrInput `pulumi:"ignoreUnknownValues"`
	// The maximum number of bad records that
	// BigQuery can ignore when reading data.
	MaxBadRecords pulumi.IntPtrInput `pulumi:"maxBadRecords"`
	// A JSON schema for the external table. Schema is required
	// for CSV and JSON formats if autodetect is not on. Schema is disallowed
	// for Google Cloud Bigtable, Cloud Datastore backups, Avro, ORC and Parquet formats.
	// ~>**NOTE:** Because this field expects a JSON string, any changes to the
	// string will create a diff, even if the JSON itself hasn't changed.
	// Furthermore drift for this field cannot not be detected because BigQuery
	// only uses this schema to compute the effective schema for the table, therefore
	// any changes on the configured value will force the table to be recreated.
	// This schema is effectively only applied when creating a table from an external
	// datasource, after creation the computed schema will be stored in
	// `google_bigquery_table.schema`
	Schema pulumi.StringPtrInput `pulumi:"schema"`
	// The data format. Supported values are:
	// "CSV", "GOOGLE_SHEETS", "NEWLINE_DELIMITED_JSON", "AVRO", "PARQUET",
	// and "DATSTORE_BACKUP". To use "GOOGLE_SHEETS"
	// the `scopes` must include
	// "https://www.googleapis.com/auth/drive.readonly".
	SourceFormat pulumi.StringInput `pulumi:"sourceFormat"`
	// A list of the fully-qualified URIs that point to
	// your data in Google Cloud.
	SourceUris pulumi.StringArrayInput `pulumi:"sourceUris"`
}

func (TableExternalDataConfigurationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*TableExternalDataConfiguration)(nil)).Elem()
}

func (i TableExternalDataConfigurationArgs) ToTableExternalDataConfigurationOutput() TableExternalDataConfigurationOutput {
	return i.ToTableExternalDataConfigurationOutputWithContext(context.Background())
}

func (i TableExternalDataConfigurationArgs) ToTableExternalDataConfigurationOutputWithContext(ctx context.Context) TableExternalDataConfigurationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableExternalDataConfigurationOutput)
}

func (i TableExternalDataConfigurationArgs) ToTableExternalDataConfigurationPtrOutput() TableExternalDataConfigurationPtrOutput {
	return i.ToTableExternalDataConfigurationPtrOutputWithContext(context.Background())
}

func (i TableExternalDataConfigurationArgs) ToTableExternalDataConfigurationPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableExternalDataConfigurationOutput).ToTableExternalDataConfigurationPtrOutputWithContext(ctx)
}

// TableExternalDataConfigurationPtrInput is an input type that accepts TableExternalDataConfigurationArgs, TableExternalDataConfigurationPtr and TableExternalDataConfigurationPtrOutput values.
// You can construct a concrete instance of `TableExternalDataConfigurationPtrInput` via:
//
// 		 TableExternalDataConfigurationArgs{...}
//
//  or:
//
// 		 nil
//
type TableExternalDataConfigurationPtrInput interface {
	pulumi.Input

	ToTableExternalDataConfigurationPtrOutput() TableExternalDataConfigurationPtrOutput
	ToTableExternalDataConfigurationPtrOutputWithContext(context.Context) TableExternalDataConfigurationPtrOutput
}

type tableExternalDataConfigurationPtrType TableExternalDataConfigurationArgs

func TableExternalDataConfigurationPtr(v *TableExternalDataConfigurationArgs) TableExternalDataConfigurationPtrInput {
	return (*tableExternalDataConfigurationPtrType)(v)
}

func (*tableExternalDataConfigurationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**TableExternalDataConfiguration)(nil)).Elem()
}

func (i *tableExternalDataConfigurationPtrType) ToTableExternalDataConfigurationPtrOutput() TableExternalDataConfigurationPtrOutput {
	return i.ToTableExternalDataConfigurationPtrOutputWithContext(context.Background())
}

func (i *tableExternalDataConfigurationPtrType) ToTableExternalDataConfigurationPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableExternalDataConfigurationPtrOutput)
}

type TableExternalDataConfigurationOutput struct{ *pulumi.OutputState }

func (TableExternalDataConfigurationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*TableExternalDataConfiguration)(nil)).Elem()
}

func (o TableExternalDataConfigurationOutput) ToTableExternalDataConfigurationOutput() TableExternalDataConfigurationOutput {
	return o
}

func (o TableExternalDataConfigurationOutput) ToTableExternalDataConfigurationOutputWithContext(ctx context.Context) TableExternalDataConfigurationOutput {
	return o
}

func (o TableExternalDataConfigurationOutput) ToTableExternalDataConfigurationPtrOutput() TableExternalDataConfigurationPtrOutput {
	return o.ToTableExternalDataConfigurationPtrOutputWithContext(context.Background())
}

func (o TableExternalDataConfigurationOutput) ToTableExternalDataConfigurationPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfiguration) *TableExternalDataConfiguration {
		return &v
	}).(TableExternalDataConfigurationPtrOutput)
}

// - Let BigQuery try to autodetect the schema
// and format of the table.
func (o TableExternalDataConfigurationOutput) Autodetect() pulumi.BoolOutput {
	return o.ApplyT(func(v TableExternalDataConfiguration) bool { return v.Autodetect }).(pulumi.BoolOutput)
}

// The compression type of the data source.
// Valid values are "NONE" or "GZIP".
func (o TableExternalDataConfigurationOutput) Compression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfiguration) *string { return v.Compression }).(pulumi.StringPtrOutput)
}

// Additional properties to set if
// `sourceFormat` is set to "CSV". Structure is documented below.
func (o TableExternalDataConfigurationOutput) CsvOptions() TableExternalDataConfigurationCsvOptionsPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfiguration) *TableExternalDataConfigurationCsvOptions { return v.CsvOptions }).(TableExternalDataConfigurationCsvOptionsPtrOutput)
}

// Additional options if
// `sourceFormat` is set to "GOOGLE_SHEETS". Structure is
// documented below.
func (o TableExternalDataConfigurationOutput) GoogleSheetsOptions() TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfiguration) *TableExternalDataConfigurationGoogleSheetsOptions {
		return v.GoogleSheetsOptions
	}).(TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput)
}

// When set, configures hive partitioning
// support. Not all storage formats support hive partitioning -- requesting hive
// partitioning on an unsupported format will lead to an error, as will providing
// an invalid specification.
func (o TableExternalDataConfigurationOutput) HivePartitioningOptions() TableExternalDataConfigurationHivePartitioningOptionsPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfiguration) *TableExternalDataConfigurationHivePartitioningOptions {
		return v.HivePartitioningOptions
	}).(TableExternalDataConfigurationHivePartitioningOptionsPtrOutput)
}

// Indicates if BigQuery should
// allow extra values that are not represented in the table schema.
// If true, the extra values are ignored. If false, records with
// extra columns are treated as bad records, and if there are too
// many bad records, an invalid error is returned in the job result.
// The default value is false.
func (o TableExternalDataConfigurationOutput) IgnoreUnknownValues() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfiguration) *bool { return v.IgnoreUnknownValues }).(pulumi.BoolPtrOutput)
}

// The maximum number of bad records that
// BigQuery can ignore when reading data.
func (o TableExternalDataConfigurationOutput) MaxBadRecords() pulumi.IntPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfiguration) *int { return v.MaxBadRecords }).(pulumi.IntPtrOutput)
}

// A JSON schema for the external table. Schema is required
// for CSV and JSON formats if autodetect is not on. Schema is disallowed
// for Google Cloud Bigtable, Cloud Datastore backups, Avro, ORC and Parquet formats.
// ~>**NOTE:** Because this field expects a JSON string, any changes to the
// string will create a diff, even if the JSON itself hasn't changed.
// Furthermore drift for this field cannot not be detected because BigQuery
// only uses this schema to compute the effective schema for the table, therefore
// any changes on the configured value will force the table to be recreated.
// This schema is effectively only applied when creating a table from an external
// datasource, after creation the computed schema will be stored in
// `google_bigquery_table.schema`
func (o TableExternalDataConfigurationOutput) Schema() pulumi.StringPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfiguration) *string { return v.Schema }).(pulumi.StringPtrOutput)
}

// The data format. Supported values are:
// "CSV", "GOOGLE_SHEETS", "NEWLINE_DELIMITED_JSON", "AVRO", "PARQUET",
// and "DATSTORE_BACKUP". To use "GOOGLE_SHEETS"
// the `scopes` must include
// "https://www.googleapis.com/auth/drive.readonly".
func (o TableExternalDataConfigurationOutput) SourceFormat() pulumi.StringOutput {
	return o.ApplyT(func(v TableExternalDataConfiguration) string { return v.SourceFormat }).(pulumi.StringOutput)
}

// A list of the fully-qualified URIs that point to
// your data in Google Cloud.
func (o TableExternalDataConfigurationOutput) SourceUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v TableExternalDataConfiguration) []string { return v.SourceUris }).(pulumi.StringArrayOutput)
}

type TableExternalDataConfigurationPtrOutput struct{ *pulumi.OutputState }

func (TableExternalDataConfigurationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**TableExternalDataConfiguration)(nil)).Elem()
}

func (o TableExternalDataConfigurationPtrOutput) ToTableExternalDataConfigurationPtrOutput() TableExternalDataConfigurationPtrOutput {
	return o
}

func (o TableExternalDataConfigurationPtrOutput) ToTableExternalDataConfigurationPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationPtrOutput {
	return o
}

func (o TableExternalDataConfigurationPtrOutput) Elem() TableExternalDataConfigurationOutput {
	return o.ApplyT(func(v *TableExternalDataConfiguration) TableExternalDataConfiguration { return *v }).(TableExternalDataConfigurationOutput)
}

// - Let BigQuery try to autodetect the schema
// and format of the table.
func (o TableExternalDataConfigurationPtrOutput) Autodetect() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfiguration) *bool {
		if v == nil {
			return nil
		}
		return &v.Autodetect
	}).(pulumi.BoolPtrOutput)
}

// The compression type of the data source.
// Valid values are "NONE" or "GZIP".
func (o TableExternalDataConfigurationPtrOutput) Compression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfiguration) *string {
		if v == nil {
			return nil
		}
		return v.Compression
	}).(pulumi.StringPtrOutput)
}

// Additional properties to set if
// `sourceFormat` is set to "CSV". Structure is documented below.
func (o TableExternalDataConfigurationPtrOutput) CsvOptions() TableExternalDataConfigurationCsvOptionsPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfiguration) *TableExternalDataConfigurationCsvOptions {
		if v == nil {
			return nil
		}
		return v.CsvOptions
	}).(TableExternalDataConfigurationCsvOptionsPtrOutput)
}

// Additional options if
// `sourceFormat` is set to "GOOGLE_SHEETS". Structure is
// documented below.
func (o TableExternalDataConfigurationPtrOutput) GoogleSheetsOptions() TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfiguration) *TableExternalDataConfigurationGoogleSheetsOptions {
		if v == nil {
			return nil
		}
		return v.GoogleSheetsOptions
	}).(TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput)
}

// When set, configures hive partitioning
// support. Not all storage formats support hive partitioning -- requesting hive
// partitioning on an unsupported format will lead to an error, as will providing
// an invalid specification.
func (o TableExternalDataConfigurationPtrOutput) HivePartitioningOptions() TableExternalDataConfigurationHivePartitioningOptionsPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfiguration) *TableExternalDataConfigurationHivePartitioningOptions {
		if v == nil {
			return nil
		}
		return v.HivePartitioningOptions
	}).(TableExternalDataConfigurationHivePartitioningOptionsPtrOutput)
}

// Indicates if BigQuery should
// allow extra values that are not represented in the table schema.
// If true, the extra values are ignored. If false, records with
// extra columns are treated as bad records, and if there are too
// many bad records, an invalid error is returned in the job result.
// The default value is false.
func (o TableExternalDataConfigurationPtrOutput) IgnoreUnknownValues() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfiguration) *bool {
		if v == nil {
			return nil
		}
		return v.IgnoreUnknownValues
	}).(pulumi.BoolPtrOutput)
}

// The maximum number of bad records that
// BigQuery can ignore when reading data.
func (o TableExternalDataConfigurationPtrOutput) MaxBadRecords() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfiguration) *int {
		if v == nil {
			return nil
		}
		return v.MaxBadRecords
	}).(pulumi.IntPtrOutput)
}

// A JSON schema for the external table. Schema is required
// for CSV and JSON formats if autodetect is not on. Schema is disallowed
// for Google Cloud Bigtable, Cloud Datastore backups, Avro, ORC and Parquet formats.
// ~>**NOTE:** Because this field expects a JSON string, any changes to the
// string will create a diff, even if the JSON itself hasn't changed.
// Furthermore drift for this field cannot not be detected because BigQuery
// only uses this schema to compute the effective schema for the table, therefore
// any changes on the configured value will force the table to be recreated.
// This schema is effectively only applied when creating a table from an external
// datasource, after creation the computed schema will be stored in
// `google_bigquery_table.schema`
func (o TableExternalDataConfigurationPtrOutput) Schema() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfiguration) *string {
		if v == nil {
			return nil
		}
		return v.Schema
	}).(pulumi.StringPtrOutput)
}

// The data format. Supported values are:
// "CSV", "GOOGLE_SHEETS", "NEWLINE_DELIMITED_JSON", "AVRO", "PARQUET",
// and "DATSTORE_BACKUP". To use "GOOGLE_SHEETS"
// the `scopes` must include
// "https://www.googleapis.com/auth/drive.readonly".
func (o TableExternalDataConfigurationPtrOutput) SourceFormat() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfiguration) *string {
		if v == nil {
			return nil
		}
		return &v.SourceFormat
	}).(pulumi.StringPtrOutput)
}

// A list of the fully-qualified URIs that point to
// your data in Google Cloud.
func (o TableExternalDataConfigurationPtrOutput) SourceUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *TableExternalDataConfiguration) []string {
		if v == nil {
			return nil
		}
		return v.SourceUris
	}).(pulumi.StringArrayOutput)
}

type TableExternalDataConfigurationCsvOptions struct {
	// Indicates if BigQuery should accept rows
	// that are missing trailing optional columns.
	AllowJaggedRows *bool `pulumi:"allowJaggedRows"`
	// Indicates if BigQuery should allow
	// quoted data sections that contain newline characters in a CSV file.
	// The default value is false.
	AllowQuotedNewlines *bool `pulumi:"allowQuotedNewlines"`
	// The character encoding of the data. The supported
	// values are UTF-8 or ISO-8859-1.
	Encoding *string `pulumi:"encoding"`
	// The separator for fields in a CSV file.
	FieldDelimiter *string `pulumi:"fieldDelimiter"`
	// The value that is used to quote data sections in a
	// CSV file. If your data does not contain quoted sections, set the
	// property value to an empty string. If your data contains quoted newline
	// characters, you must also set the `allowQuotedNewlines` property to true.
	// The API-side default is `"`, specified in the provider escaped as `\"`. Due to
	// limitations with default values, this value is required to be
	// explicitly set.
	Quote string `pulumi:"quote"`
	// The number of rows at the top of the sheet
	// that BigQuery will skip when reading the data. At least one of `range` or
	// `skipLeadingRows` must be set.
	SkipLeadingRows *int `pulumi:"skipLeadingRows"`
}

// TableExternalDataConfigurationCsvOptionsInput is an input type that accepts TableExternalDataConfigurationCsvOptionsArgs and TableExternalDataConfigurationCsvOptionsOutput values.
// You can construct a concrete instance of `TableExternalDataConfigurationCsvOptionsInput` via:
//
// 		 TableExternalDataConfigurationCsvOptionsArgs{...}
//
type TableExternalDataConfigurationCsvOptionsInput interface {
	pulumi.Input

	ToTableExternalDataConfigurationCsvOptionsOutput() TableExternalDataConfigurationCsvOptionsOutput
	ToTableExternalDataConfigurationCsvOptionsOutputWithContext(context.Context) TableExternalDataConfigurationCsvOptionsOutput
}

type TableExternalDataConfigurationCsvOptionsArgs struct {
	// Indicates if BigQuery should accept rows
	// that are missing trailing optional columns.
	AllowJaggedRows pulumi.BoolPtrInput `pulumi:"allowJaggedRows"`
	// Indicates if BigQuery should allow
	// quoted data sections that contain newline characters in a CSV file.
	// The default value is false.
	AllowQuotedNewlines pulumi.BoolPtrInput `pulumi:"allowQuotedNewlines"`
	// The character encoding of the data. The supported
	// values are UTF-8 or ISO-8859-1.
	Encoding pulumi.StringPtrInput `pulumi:"encoding"`
	// The separator for fields in a CSV file.
	FieldDelimiter pulumi.StringPtrInput `pulumi:"fieldDelimiter"`
	// The value that is used to quote data sections in a
	// CSV file. If your data does not contain quoted sections, set the
	// property value to an empty string. If your data contains quoted newline
	// characters, you must also set the `allowQuotedNewlines` property to true.
	// The API-side default is `"`, specified in the provider escaped as `\"`. Due to
	// limitations with default values, this value is required to be
	// explicitly set.
	Quote pulumi.StringInput `pulumi:"quote"`
	// The number of rows at the top of the sheet
	// that BigQuery will skip when reading the data. At least one of `range` or
	// `skipLeadingRows` must be set.
	SkipLeadingRows pulumi.IntPtrInput `pulumi:"skipLeadingRows"`
}

func (TableExternalDataConfigurationCsvOptionsArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*TableExternalDataConfigurationCsvOptions)(nil)).Elem()
}

func (i TableExternalDataConfigurationCsvOptionsArgs) ToTableExternalDataConfigurationCsvOptionsOutput() TableExternalDataConfigurationCsvOptionsOutput {
	return i.ToTableExternalDataConfigurationCsvOptionsOutputWithContext(context.Background())
}

func (i TableExternalDataConfigurationCsvOptionsArgs) ToTableExternalDataConfigurationCsvOptionsOutputWithContext(ctx context.Context) TableExternalDataConfigurationCsvOptionsOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableExternalDataConfigurationCsvOptionsOutput)
}

func (i TableExternalDataConfigurationCsvOptionsArgs) ToTableExternalDataConfigurationCsvOptionsPtrOutput() TableExternalDataConfigurationCsvOptionsPtrOutput {
	return i.ToTableExternalDataConfigurationCsvOptionsPtrOutputWithContext(context.Background())
}

func (i TableExternalDataConfigurationCsvOptionsArgs) ToTableExternalDataConfigurationCsvOptionsPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationCsvOptionsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableExternalDataConfigurationCsvOptionsOutput).ToTableExternalDataConfigurationCsvOptionsPtrOutputWithContext(ctx)
}

// TableExternalDataConfigurationCsvOptionsPtrInput is an input type that accepts TableExternalDataConfigurationCsvOptionsArgs, TableExternalDataConfigurationCsvOptionsPtr and TableExternalDataConfigurationCsvOptionsPtrOutput values.
// You can construct a concrete instance of `TableExternalDataConfigurationCsvOptionsPtrInput` via:
//
// 		 TableExternalDataConfigurationCsvOptionsArgs{...}
//
//  or:
//
// 		 nil
//
type TableExternalDataConfigurationCsvOptionsPtrInput interface {
	pulumi.Input

	ToTableExternalDataConfigurationCsvOptionsPtrOutput() TableExternalDataConfigurationCsvOptionsPtrOutput
	ToTableExternalDataConfigurationCsvOptionsPtrOutputWithContext(context.Context) TableExternalDataConfigurationCsvOptionsPtrOutput
}

type tableExternalDataConfigurationCsvOptionsPtrType TableExternalDataConfigurationCsvOptionsArgs

func TableExternalDataConfigurationCsvOptionsPtr(v *TableExternalDataConfigurationCsvOptionsArgs) TableExternalDataConfigurationCsvOptionsPtrInput {
	return (*tableExternalDataConfigurationCsvOptionsPtrType)(v)
}

func (*tableExternalDataConfigurationCsvOptionsPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**TableExternalDataConfigurationCsvOptions)(nil)).Elem()
}

func (i *tableExternalDataConfigurationCsvOptionsPtrType) ToTableExternalDataConfigurationCsvOptionsPtrOutput() TableExternalDataConfigurationCsvOptionsPtrOutput {
	return i.ToTableExternalDataConfigurationCsvOptionsPtrOutputWithContext(context.Background())
}

func (i *tableExternalDataConfigurationCsvOptionsPtrType) ToTableExternalDataConfigurationCsvOptionsPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationCsvOptionsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableExternalDataConfigurationCsvOptionsPtrOutput)
}

type TableExternalDataConfigurationCsvOptionsOutput struct{ *pulumi.OutputState }

func (TableExternalDataConfigurationCsvOptionsOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*TableExternalDataConfigurationCsvOptions)(nil)).Elem()
}

func (o TableExternalDataConfigurationCsvOptionsOutput) ToTableExternalDataConfigurationCsvOptionsOutput() TableExternalDataConfigurationCsvOptionsOutput {
	return o
}

func (o TableExternalDataConfigurationCsvOptionsOutput) ToTableExternalDataConfigurationCsvOptionsOutputWithContext(ctx context.Context) TableExternalDataConfigurationCsvOptionsOutput {
	return o
}

func (o TableExternalDataConfigurationCsvOptionsOutput) ToTableExternalDataConfigurationCsvOptionsPtrOutput() TableExternalDataConfigurationCsvOptionsPtrOutput {
	return o.ToTableExternalDataConfigurationCsvOptionsPtrOutputWithContext(context.Background())
}

func (o TableExternalDataConfigurationCsvOptionsOutput) ToTableExternalDataConfigurationCsvOptionsPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationCsvOptionsPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationCsvOptions) *TableExternalDataConfigurationCsvOptions {
		return &v
	}).(TableExternalDataConfigurationCsvOptionsPtrOutput)
}

// Indicates if BigQuery should accept rows
// that are missing trailing optional columns.
func (o TableExternalDataConfigurationCsvOptionsOutput) AllowJaggedRows() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationCsvOptions) *bool { return v.AllowJaggedRows }).(pulumi.BoolPtrOutput)
}

// Indicates if BigQuery should allow
// quoted data sections that contain newline characters in a CSV file.
// The default value is false.
func (o TableExternalDataConfigurationCsvOptionsOutput) AllowQuotedNewlines() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationCsvOptions) *bool { return v.AllowQuotedNewlines }).(pulumi.BoolPtrOutput)
}

// The character encoding of the data. The supported
// values are UTF-8 or ISO-8859-1.
func (o TableExternalDataConfigurationCsvOptionsOutput) Encoding() pulumi.StringPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationCsvOptions) *string { return v.Encoding }).(pulumi.StringPtrOutput)
}

// The separator for fields in a CSV file.
func (o TableExternalDataConfigurationCsvOptionsOutput) FieldDelimiter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationCsvOptions) *string { return v.FieldDelimiter }).(pulumi.StringPtrOutput)
}

// The value that is used to quote data sections in a
// CSV file. If your data does not contain quoted sections, set the
// property value to an empty string. If your data contains quoted newline
// characters, you must also set the `allowQuotedNewlines` property to true.
// The API-side default is `"`, specified in the provider escaped as `\"`. Due to
// limitations with default values, this value is required to be
// explicitly set.
func (o TableExternalDataConfigurationCsvOptionsOutput) Quote() pulumi.StringOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationCsvOptions) string { return v.Quote }).(pulumi.StringOutput)
}

// The number of rows at the top of the sheet
// that BigQuery will skip when reading the data. At least one of `range` or
// `skipLeadingRows` must be set.
func (o TableExternalDataConfigurationCsvOptionsOutput) SkipLeadingRows() pulumi.IntPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationCsvOptions) *int { return v.SkipLeadingRows }).(pulumi.IntPtrOutput)
}

type TableExternalDataConfigurationCsvOptionsPtrOutput struct{ *pulumi.OutputState }

func (TableExternalDataConfigurationCsvOptionsPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**TableExternalDataConfigurationCsvOptions)(nil)).Elem()
}

func (o TableExternalDataConfigurationCsvOptionsPtrOutput) ToTableExternalDataConfigurationCsvOptionsPtrOutput() TableExternalDataConfigurationCsvOptionsPtrOutput {
	return o
}

func (o TableExternalDataConfigurationCsvOptionsPtrOutput) ToTableExternalDataConfigurationCsvOptionsPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationCsvOptionsPtrOutput {
	return o
}

func (o TableExternalDataConfigurationCsvOptionsPtrOutput) Elem() TableExternalDataConfigurationCsvOptionsOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationCsvOptions) TableExternalDataConfigurationCsvOptions { return *v }).(TableExternalDataConfigurationCsvOptionsOutput)
}

// Indicates if BigQuery should accept rows
// that are missing trailing optional columns.
func (o TableExternalDataConfigurationCsvOptionsPtrOutput) AllowJaggedRows() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationCsvOptions) *bool {
		if v == nil {
			return nil
		}
		return v.AllowJaggedRows
	}).(pulumi.BoolPtrOutput)
}

// Indicates if BigQuery should allow
// quoted data sections that contain newline characters in a CSV file.
// The default value is false.
func (o TableExternalDataConfigurationCsvOptionsPtrOutput) AllowQuotedNewlines() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationCsvOptions) *bool {
		if v == nil {
			return nil
		}
		return v.AllowQuotedNewlines
	}).(pulumi.BoolPtrOutput)
}

// The character encoding of the data. The supported
// values are UTF-8 or ISO-8859-1.
func (o TableExternalDataConfigurationCsvOptionsPtrOutput) Encoding() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationCsvOptions) *string {
		if v == nil {
			return nil
		}
		return v.Encoding
	}).(pulumi.StringPtrOutput)
}

// The separator for fields in a CSV file.
func (o TableExternalDataConfigurationCsvOptionsPtrOutput) FieldDelimiter() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationCsvOptions) *string {
		if v == nil {
			return nil
		}
		return v.FieldDelimiter
	}).(pulumi.StringPtrOutput)
}

// The value that is used to quote data sections in a
// CSV file. If your data does not contain quoted sections, set the
// property value to an empty string. If your data contains quoted newline
// characters, you must also set the `allowQuotedNewlines` property to true.
// The API-side default is `"`, specified in the provider escaped as `\"`. Due to
// limitations with default values, this value is required to be
// explicitly set.
func (o TableExternalDataConfigurationCsvOptionsPtrOutput) Quote() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationCsvOptions) *string {
		if v == nil {
			return nil
		}
		return &v.Quote
	}).(pulumi.StringPtrOutput)
}

// The number of rows at the top of the sheet
// that BigQuery will skip when reading the data. At least one of `range` or
// `skipLeadingRows` must be set.
func (o TableExternalDataConfigurationCsvOptionsPtrOutput) SkipLeadingRows() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationCsvOptions) *int {
		if v == nil {
			return nil
		}
		return v.SkipLeadingRows
	}).(pulumi.IntPtrOutput)
}

type TableExternalDataConfigurationGoogleSheetsOptions struct {
	// Information required to partition based on ranges.
	// Structure is documented below.
	Range *string `pulumi:"range"`
	// The number of rows at the top of the sheet
	// that BigQuery will skip when reading the data. At least one of `range` or
	// `skipLeadingRows` must be set.
	SkipLeadingRows *int `pulumi:"skipLeadingRows"`
}

// TableExternalDataConfigurationGoogleSheetsOptionsInput is an input type that accepts TableExternalDataConfigurationGoogleSheetsOptionsArgs and TableExternalDataConfigurationGoogleSheetsOptionsOutput values.
// You can construct a concrete instance of `TableExternalDataConfigurationGoogleSheetsOptionsInput` via:
//
// 		 TableExternalDataConfigurationGoogleSheetsOptionsArgs{...}
//
type TableExternalDataConfigurationGoogleSheetsOptionsInput interface {
	pulumi.Input

	ToTableExternalDataConfigurationGoogleSheetsOptionsOutput() TableExternalDataConfigurationGoogleSheetsOptionsOutput
	ToTableExternalDataConfigurationGoogleSheetsOptionsOutputWithContext(context.Context) TableExternalDataConfigurationGoogleSheetsOptionsOutput
}

type TableExternalDataConfigurationGoogleSheetsOptionsArgs struct {
	// Information required to partition based on ranges.
	// Structure is documented below.
	Range pulumi.StringPtrInput `pulumi:"range"`
	// The number of rows at the top of the sheet
	// that BigQuery will skip when reading the data. At least one of `range` or
	// `skipLeadingRows` must be set.
	SkipLeadingRows pulumi.IntPtrInput `pulumi:"skipLeadingRows"`
}

func (TableExternalDataConfigurationGoogleSheetsOptionsArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*TableExternalDataConfigurationGoogleSheetsOptions)(nil)).Elem()
}

func (i TableExternalDataConfigurationGoogleSheetsOptionsArgs) ToTableExternalDataConfigurationGoogleSheetsOptionsOutput() TableExternalDataConfigurationGoogleSheetsOptionsOutput {
	return i.ToTableExternalDataConfigurationGoogleSheetsOptionsOutputWithContext(context.Background())
}

func (i TableExternalDataConfigurationGoogleSheetsOptionsArgs) ToTableExternalDataConfigurationGoogleSheetsOptionsOutputWithContext(ctx context.Context) TableExternalDataConfigurationGoogleSheetsOptionsOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableExternalDataConfigurationGoogleSheetsOptionsOutput)
}

func (i TableExternalDataConfigurationGoogleSheetsOptionsArgs) ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutput() TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput {
	return i.ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutputWithContext(context.Background())
}

func (i TableExternalDataConfigurationGoogleSheetsOptionsArgs) ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableExternalDataConfigurationGoogleSheetsOptionsOutput).ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutputWithContext(ctx)
}

// TableExternalDataConfigurationGoogleSheetsOptionsPtrInput is an input type that accepts TableExternalDataConfigurationGoogleSheetsOptionsArgs, TableExternalDataConfigurationGoogleSheetsOptionsPtr and TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput values.
// You can construct a concrete instance of `TableExternalDataConfigurationGoogleSheetsOptionsPtrInput` via:
//
// 		 TableExternalDataConfigurationGoogleSheetsOptionsArgs{...}
//
//  or:
//
// 		 nil
//
type TableExternalDataConfigurationGoogleSheetsOptionsPtrInput interface {
	pulumi.Input

	ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutput() TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput
	ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutputWithContext(context.Context) TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput
}

type tableExternalDataConfigurationGoogleSheetsOptionsPtrType TableExternalDataConfigurationGoogleSheetsOptionsArgs

func TableExternalDataConfigurationGoogleSheetsOptionsPtr(v *TableExternalDataConfigurationGoogleSheetsOptionsArgs) TableExternalDataConfigurationGoogleSheetsOptionsPtrInput {
	return (*tableExternalDataConfigurationGoogleSheetsOptionsPtrType)(v)
}

func (*tableExternalDataConfigurationGoogleSheetsOptionsPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**TableExternalDataConfigurationGoogleSheetsOptions)(nil)).Elem()
}

func (i *tableExternalDataConfigurationGoogleSheetsOptionsPtrType) ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutput() TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput {
	return i.ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutputWithContext(context.Background())
}

func (i *tableExternalDataConfigurationGoogleSheetsOptionsPtrType) ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput)
}

type TableExternalDataConfigurationGoogleSheetsOptionsOutput struct{ *pulumi.OutputState }

func (TableExternalDataConfigurationGoogleSheetsOptionsOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*TableExternalDataConfigurationGoogleSheetsOptions)(nil)).Elem()
}

func (o TableExternalDataConfigurationGoogleSheetsOptionsOutput) ToTableExternalDataConfigurationGoogleSheetsOptionsOutput() TableExternalDataConfigurationGoogleSheetsOptionsOutput {
	return o
}

func (o TableExternalDataConfigurationGoogleSheetsOptionsOutput) ToTableExternalDataConfigurationGoogleSheetsOptionsOutputWithContext(ctx context.Context) TableExternalDataConfigurationGoogleSheetsOptionsOutput {
	return o
}

func (o TableExternalDataConfigurationGoogleSheetsOptionsOutput) ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutput() TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput {
	return o.ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutputWithContext(context.Background())
}

func (o TableExternalDataConfigurationGoogleSheetsOptionsOutput) ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationGoogleSheetsOptions) *TableExternalDataConfigurationGoogleSheetsOptions {
		return &v
	}).(TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput)
}

// Information required to partition based on ranges.
// Structure is documented below.
func (o TableExternalDataConfigurationGoogleSheetsOptionsOutput) Range() pulumi.StringPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationGoogleSheetsOptions) *string { return v.Range }).(pulumi.StringPtrOutput)
}

// The number of rows at the top of the sheet
// that BigQuery will skip when reading the data. At least one of `range` or
// `skipLeadingRows` must be set.
func (o TableExternalDataConfigurationGoogleSheetsOptionsOutput) SkipLeadingRows() pulumi.IntPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationGoogleSheetsOptions) *int { return v.SkipLeadingRows }).(pulumi.IntPtrOutput)
}

type TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput struct{ *pulumi.OutputState }

func (TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**TableExternalDataConfigurationGoogleSheetsOptions)(nil)).Elem()
}

func (o TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput) ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutput() TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput {
	return o
}

func (o TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput) ToTableExternalDataConfigurationGoogleSheetsOptionsPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput {
	return o
}

func (o TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput) Elem() TableExternalDataConfigurationGoogleSheetsOptionsOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationGoogleSheetsOptions) TableExternalDataConfigurationGoogleSheetsOptions {
		return *v
	}).(TableExternalDataConfigurationGoogleSheetsOptionsOutput)
}

// Information required to partition based on ranges.
// Structure is documented below.
func (o TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput) Range() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationGoogleSheetsOptions) *string {
		if v == nil {
			return nil
		}
		return v.Range
	}).(pulumi.StringPtrOutput)
}

// The number of rows at the top of the sheet
// that BigQuery will skip when reading the data. At least one of `range` or
// `skipLeadingRows` must be set.
func (o TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput) SkipLeadingRows() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationGoogleSheetsOptions) *int {
		if v == nil {
			return nil
		}
		return v.SkipLeadingRows
	}).(pulumi.IntPtrOutput)
}

type TableExternalDataConfigurationHivePartitioningOptions struct {
	// When set, what mode of hive partitioning to use when
	// reading data. The following modes are supported.
	// * AUTO: automatically infer partition key name(s) and type(s).
	// * STRINGS: automatically infer partition key name(s). All types are
	// Not all storage formats support hive partitioning. Requesting hive
	// partitioning on an unsupported format will lead to an error.
	// Currently supported formats are: JSON, CSV, ORC, Avro and Parquet.
	// * CUSTOM: when set to `CUSTOM`, you must encode the partition key schema within the `sourceUriPrefix` by setting `sourceUriPrefix` to `gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}`.
	Mode *string `pulumi:"mode"`
	// When hive partition detection is requested,
	// a common for all source uris must be required. The prefix must end immediately
	// before the partition key encoding begins. For example, consider files following
	// this data layout. `gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro`
	// `gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro` When hive
	// partitioning is requested with either AUTO or STRINGS detection, the common prefix
	// can be either of `gs://bucket/path_to_table` or `gs://bucket/path_to_table/`.
	// Note that when `mode` is set to `CUSTOM`, you must encode the partition key schema within the `sourceUriPrefix` by setting `sourceUriPrefix` to `gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}`.
	SourceUriPrefix *string `pulumi:"sourceUriPrefix"`
}

// TableExternalDataConfigurationHivePartitioningOptionsInput is an input type that accepts TableExternalDataConfigurationHivePartitioningOptionsArgs and TableExternalDataConfigurationHivePartitioningOptionsOutput values.
// You can construct a concrete instance of `TableExternalDataConfigurationHivePartitioningOptionsInput` via:
//
// 		 TableExternalDataConfigurationHivePartitioningOptionsArgs{...}
//
type TableExternalDataConfigurationHivePartitioningOptionsInput interface {
	pulumi.Input

	ToTableExternalDataConfigurationHivePartitioningOptionsOutput() TableExternalDataConfigurationHivePartitioningOptionsOutput
	ToTableExternalDataConfigurationHivePartitioningOptionsOutputWithContext(context.Context) TableExternalDataConfigurationHivePartitioningOptionsOutput
}

type TableExternalDataConfigurationHivePartitioningOptionsArgs struct {
	// When set, what mode of hive partitioning to use when
	// reading data. The following modes are supported.
	// * AUTO: automatically infer partition key name(s) and type(s).
	// * STRINGS: automatically infer partition key name(s). All types are
	// Not all storage formats support hive partitioning. Requesting hive
	// partitioning on an unsupported format will lead to an error.
	// Currently supported formats are: JSON, CSV, ORC, Avro and Parquet.
	// * CUSTOM: when set to `CUSTOM`, you must encode the partition key schema within the `sourceUriPrefix` by setting `sourceUriPrefix` to `gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}`.
	Mode pulumi.StringPtrInput `pulumi:"mode"`
	// When hive partition detection is requested,
	// a common for all source uris must be required. The prefix must end immediately
	// before the partition key encoding begins. For example, consider files following
	// this data layout. `gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro`
	// `gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro` When hive
	// partitioning is requested with either AUTO or STRINGS detection, the common prefix
	// can be either of `gs://bucket/path_to_table` or `gs://bucket/path_to_table/`.
	// Note that when `mode` is set to `CUSTOM`, you must encode the partition key schema within the `sourceUriPrefix` by setting `sourceUriPrefix` to `gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}`.
	SourceUriPrefix pulumi.StringPtrInput `pulumi:"sourceUriPrefix"`
}

func (TableExternalDataConfigurationHivePartitioningOptionsArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*TableExternalDataConfigurationHivePartitioningOptions)(nil)).Elem()
}

func (i TableExternalDataConfigurationHivePartitioningOptionsArgs) ToTableExternalDataConfigurationHivePartitioningOptionsOutput() TableExternalDataConfigurationHivePartitioningOptionsOutput {
	return i.ToTableExternalDataConfigurationHivePartitioningOptionsOutputWithContext(context.Background())
}

func (i TableExternalDataConfigurationHivePartitioningOptionsArgs) ToTableExternalDataConfigurationHivePartitioningOptionsOutputWithContext(ctx context.Context) TableExternalDataConfigurationHivePartitioningOptionsOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableExternalDataConfigurationHivePartitioningOptionsOutput)
}

func (i TableExternalDataConfigurationHivePartitioningOptionsArgs) ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutput() TableExternalDataConfigurationHivePartitioningOptionsPtrOutput {
	return i.ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutputWithContext(context.Background())
}

func (i TableExternalDataConfigurationHivePartitioningOptionsArgs) ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationHivePartitioningOptionsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableExternalDataConfigurationHivePartitioningOptionsOutput).ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutputWithContext(ctx)
}

// TableExternalDataConfigurationHivePartitioningOptionsPtrInput is an input type that accepts TableExternalDataConfigurationHivePartitioningOptionsArgs, TableExternalDataConfigurationHivePartitioningOptionsPtr and TableExternalDataConfigurationHivePartitioningOptionsPtrOutput values.
// You can construct a concrete instance of `TableExternalDataConfigurationHivePartitioningOptionsPtrInput` via:
//
// 		 TableExternalDataConfigurationHivePartitioningOptionsArgs{...}
//
//  or:
//
// 		 nil
//
type TableExternalDataConfigurationHivePartitioningOptionsPtrInput interface {
	pulumi.Input

	ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutput() TableExternalDataConfigurationHivePartitioningOptionsPtrOutput
	ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutputWithContext(context.Context) TableExternalDataConfigurationHivePartitioningOptionsPtrOutput
}

type tableExternalDataConfigurationHivePartitioningOptionsPtrType TableExternalDataConfigurationHivePartitioningOptionsArgs

func TableExternalDataConfigurationHivePartitioningOptionsPtr(v *TableExternalDataConfigurationHivePartitioningOptionsArgs) TableExternalDataConfigurationHivePartitioningOptionsPtrInput {
	return (*tableExternalDataConfigurationHivePartitioningOptionsPtrType)(v)
}

func (*tableExternalDataConfigurationHivePartitioningOptionsPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**TableExternalDataConfigurationHivePartitioningOptions)(nil)).Elem()
}

func (i *tableExternalDataConfigurationHivePartitioningOptionsPtrType) ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutput() TableExternalDataConfigurationHivePartitioningOptionsPtrOutput {
	return i.ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutputWithContext(context.Background())
}

func (i *tableExternalDataConfigurationHivePartitioningOptionsPtrType) ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationHivePartitioningOptionsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableExternalDataConfigurationHivePartitioningOptionsPtrOutput)
}

type TableExternalDataConfigurationHivePartitioningOptionsOutput struct{ *pulumi.OutputState }

func (TableExternalDataConfigurationHivePartitioningOptionsOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*TableExternalDataConfigurationHivePartitioningOptions)(nil)).Elem()
}

func (o TableExternalDataConfigurationHivePartitioningOptionsOutput) ToTableExternalDataConfigurationHivePartitioningOptionsOutput() TableExternalDataConfigurationHivePartitioningOptionsOutput {
	return o
}

func (o TableExternalDataConfigurationHivePartitioningOptionsOutput) ToTableExternalDataConfigurationHivePartitioningOptionsOutputWithContext(ctx context.Context) TableExternalDataConfigurationHivePartitioningOptionsOutput {
	return o
}

func (o TableExternalDataConfigurationHivePartitioningOptionsOutput) ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutput() TableExternalDataConfigurationHivePartitioningOptionsPtrOutput {
	return o.ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutputWithContext(context.Background())
}

func (o TableExternalDataConfigurationHivePartitioningOptionsOutput) ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationHivePartitioningOptionsPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationHivePartitioningOptions) *TableExternalDataConfigurationHivePartitioningOptions {
		return &v
	}).(TableExternalDataConfigurationHivePartitioningOptionsPtrOutput)
}

// When set, what mode of hive partitioning to use when
// reading data. The following modes are supported.
// * AUTO: automatically infer partition key name(s) and type(s).
// * STRINGS: automatically infer partition key name(s). All types are
// Not all storage formats support hive partitioning. Requesting hive
// partitioning on an unsupported format will lead to an error.
// Currently supported formats are: JSON, CSV, ORC, Avro and Parquet.
// * CUSTOM: when set to `CUSTOM`, you must encode the partition key schema within the `sourceUriPrefix` by setting `sourceUriPrefix` to `gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}`.
func (o TableExternalDataConfigurationHivePartitioningOptionsOutput) Mode() pulumi.StringPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationHivePartitioningOptions) *string { return v.Mode }).(pulumi.StringPtrOutput)
}

// When hive partition detection is requested,
// a common for all source uris must be required. The prefix must end immediately
// before the partition key encoding begins. For example, consider files following
// this data layout. `gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro`
// `gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro` When hive
// partitioning is requested with either AUTO or STRINGS detection, the common prefix
// can be either of `gs://bucket/path_to_table` or `gs://bucket/path_to_table/`.
// Note that when `mode` is set to `CUSTOM`, you must encode the partition key schema within the `sourceUriPrefix` by setting `sourceUriPrefix` to `gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}`.
func (o TableExternalDataConfigurationHivePartitioningOptionsOutput) SourceUriPrefix() pulumi.StringPtrOutput {
	return o.ApplyT(func(v TableExternalDataConfigurationHivePartitioningOptions) *string { return v.SourceUriPrefix }).(pulumi.StringPtrOutput)
}

type TableExternalDataConfigurationHivePartitioningOptionsPtrOutput struct{ *pulumi.OutputState }

func (TableExternalDataConfigurationHivePartitioningOptionsPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**TableExternalDataConfigurationHivePartitioningOptions)(nil)).Elem()
}

func (o TableExternalDataConfigurationHivePartitioningOptionsPtrOutput) ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutput() TableExternalDataConfigurationHivePartitioningOptionsPtrOutput {
	return o
}

func (o TableExternalDataConfigurationHivePartitioningOptionsPtrOutput) ToTableExternalDataConfigurationHivePartitioningOptionsPtrOutputWithContext(ctx context.Context) TableExternalDataConfigurationHivePartitioningOptionsPtrOutput {
	return o
}

func (o TableExternalDataConfigurationHivePartitioningOptionsPtrOutput) Elem() TableExternalDataConfigurationHivePartitioningOptionsOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationHivePartitioningOptions) TableExternalDataConfigurationHivePartitioningOptions {
		return *v
	}).(TableExternalDataConfigurationHivePartitioningOptionsOutput)
}

// When set, what mode of hive partitioning to use when
// reading data. The following modes are supported.
// * AUTO: automatically infer partition key name(s) and type(s).
// * STRINGS: automatically infer partition key name(s). All types are
// Not all storage formats support hive partitioning. Requesting hive
// partitioning on an unsupported format will lead to an error.
// Currently supported formats are: JSON, CSV, ORC, Avro and Parquet.
// * CUSTOM: when set to `CUSTOM`, you must encode the partition key schema within the `sourceUriPrefix` by setting `sourceUriPrefix` to `gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}`.
func (o TableExternalDataConfigurationHivePartitioningOptionsPtrOutput) Mode() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationHivePartitioningOptions) *string {
		if v == nil {
			return nil
		}
		return v.Mode
	}).(pulumi.StringPtrOutput)
}

// When hive partition detection is requested,
// a common for all source uris must be required. The prefix must end immediately
// before the partition key encoding begins. For example, consider files following
// this data layout. `gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro`
// `gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro` When hive
// partitioning is requested with either AUTO or STRINGS detection, the common prefix
// can be either of `gs://bucket/path_to_table` or `gs://bucket/path_to_table/`.
// Note that when `mode` is set to `CUSTOM`, you must encode the partition key schema within the `sourceUriPrefix` by setting `sourceUriPrefix` to `gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}`.
func (o TableExternalDataConfigurationHivePartitioningOptionsPtrOutput) SourceUriPrefix() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableExternalDataConfigurationHivePartitioningOptions) *string {
		if v == nil {
			return nil
		}
		return v.SourceUriPrefix
	}).(pulumi.StringPtrOutput)
}

type TableRangePartitioning struct {
	// The field used to determine how to create a range-based
	// partition.
	Field string `pulumi:"field"`
	// Information required to partition based on ranges.
	// Structure is documented below.
	Range TableRangePartitioningRange `pulumi:"range"`
}

// TableRangePartitioningInput is an input type that accepts TableRangePartitioningArgs and TableRangePartitioningOutput values.
// You can construct a concrete instance of `TableRangePartitioningInput` via:
//
// 		 TableRangePartitioningArgs{...}
//
type TableRangePartitioningInput interface {
	pulumi.Input

	ToTableRangePartitioningOutput() TableRangePartitioningOutput
	ToTableRangePartitioningOutputWithContext(context.Context) TableRangePartitioningOutput
}

type TableRangePartitioningArgs struct {
	// The field used to determine how to create a range-based
	// partition.
	Field pulumi.StringInput `pulumi:"field"`
	// Information required to partition based on ranges.
	// Structure is documented below.
	Range TableRangePartitioningRangeInput `pulumi:"range"`
}

func (TableRangePartitioningArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*TableRangePartitioning)(nil)).Elem()
}

func (i TableRangePartitioningArgs) ToTableRangePartitioningOutput() TableRangePartitioningOutput {
	return i.ToTableRangePartitioningOutputWithContext(context.Background())
}

func (i TableRangePartitioningArgs) ToTableRangePartitioningOutputWithContext(ctx context.Context) TableRangePartitioningOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableRangePartitioningOutput)
}

func (i TableRangePartitioningArgs) ToTableRangePartitioningPtrOutput() TableRangePartitioningPtrOutput {
	return i.ToTableRangePartitioningPtrOutputWithContext(context.Background())
}

func (i TableRangePartitioningArgs) ToTableRangePartitioningPtrOutputWithContext(ctx context.Context) TableRangePartitioningPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableRangePartitioningOutput).ToTableRangePartitioningPtrOutputWithContext(ctx)
}

// TableRangePartitioningPtrInput is an input type that accepts TableRangePartitioningArgs, TableRangePartitioningPtr and TableRangePartitioningPtrOutput values.
// You can construct a concrete instance of `TableRangePartitioningPtrInput` via:
//
// 		 TableRangePartitioningArgs{...}
//
//  or:
//
// 		 nil
//
type TableRangePartitioningPtrInput interface {
	pulumi.Input

	ToTableRangePartitioningPtrOutput() TableRangePartitioningPtrOutput
	ToTableRangePartitioningPtrOutputWithContext(context.Context) TableRangePartitioningPtrOutput
}

type tableRangePartitioningPtrType TableRangePartitioningArgs

func TableRangePartitioningPtr(v *TableRangePartitioningArgs) TableRangePartitioningPtrInput {
	return (*tableRangePartitioningPtrType)(v)
}

func (*tableRangePartitioningPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**TableRangePartitioning)(nil)).Elem()
}

func (i *tableRangePartitioningPtrType) ToTableRangePartitioningPtrOutput() TableRangePartitioningPtrOutput {
	return i.ToTableRangePartitioningPtrOutputWithContext(context.Background())
}

func (i *tableRangePartitioningPtrType) ToTableRangePartitioningPtrOutputWithContext(ctx context.Context) TableRangePartitioningPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableRangePartitioningPtrOutput)
}

type TableRangePartitioningOutput struct{ *pulumi.OutputState }

func (TableRangePartitioningOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*TableRangePartitioning)(nil)).Elem()
}

func (o TableRangePartitioningOutput) ToTableRangePartitioningOutput() TableRangePartitioningOutput {
	return o
}

func (o TableRangePartitioningOutput) ToTableRangePartitioningOutputWithContext(ctx context.Context) TableRangePartitioningOutput {
	return o
}

func (o TableRangePartitioningOutput) ToTableRangePartitioningPtrOutput() TableRangePartitioningPtrOutput {
	return o.ToTableRangePartitioningPtrOutputWithContext(context.Background())
}

func (o TableRangePartitioningOutput) ToTableRangePartitioningPtrOutputWithContext(ctx context.Context) TableRangePartitioningPtrOutput {
	return o.ApplyT(func(v TableRangePartitioning) *TableRangePartitioning {
		return &v
	}).(TableRangePartitioningPtrOutput)
}

// The field used to determine how to create a range-based
// partition.
func (o TableRangePartitioningOutput) Field() pulumi.StringOutput {
	return o.ApplyT(func(v TableRangePartitioning) string { return v.Field }).(pulumi.StringOutput)
}

// Information required to partition based on ranges.
// Structure is documented below.
func (o TableRangePartitioningOutput) Range() TableRangePartitioningRangeOutput {
	return o.ApplyT(func(v TableRangePartitioning) TableRangePartitioningRange { return v.Range }).(TableRangePartitioningRangeOutput)
}

type TableRangePartitioningPtrOutput struct{ *pulumi.OutputState }

func (TableRangePartitioningPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**TableRangePartitioning)(nil)).Elem()
}

func (o TableRangePartitioningPtrOutput) ToTableRangePartitioningPtrOutput() TableRangePartitioningPtrOutput {
	return o
}

func (o TableRangePartitioningPtrOutput) ToTableRangePartitioningPtrOutputWithContext(ctx context.Context) TableRangePartitioningPtrOutput {
	return o
}

func (o TableRangePartitioningPtrOutput) Elem() TableRangePartitioningOutput {
	return o.ApplyT(func(v *TableRangePartitioning) TableRangePartitioning { return *v }).(TableRangePartitioningOutput)
}

// The field used to determine how to create a range-based
// partition.
func (o TableRangePartitioningPtrOutput) Field() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableRangePartitioning) *string {
		if v == nil {
			return nil
		}
		return &v.Field
	}).(pulumi.StringPtrOutput)
}

// Information required to partition based on ranges.
// Structure is documented below.
func (o TableRangePartitioningPtrOutput) Range() TableRangePartitioningRangePtrOutput {
	return o.ApplyT(func(v *TableRangePartitioning) *TableRangePartitioningRange {
		if v == nil {
			return nil
		}
		return &v.Range
	}).(TableRangePartitioningRangePtrOutput)
}

type TableRangePartitioningRange struct {
	// End of the range partitioning, exclusive.
	End int `pulumi:"end"`
	// The width of each range within the partition.
	Interval int `pulumi:"interval"`
	// Start of the range partitioning, inclusive.
	Start int `pulumi:"start"`
}

// TableRangePartitioningRangeInput is an input type that accepts TableRangePartitioningRangeArgs and TableRangePartitioningRangeOutput values.
// You can construct a concrete instance of `TableRangePartitioningRangeInput` via:
//
// 		 TableRangePartitioningRangeArgs{...}
//
type TableRangePartitioningRangeInput interface {
	pulumi.Input

	ToTableRangePartitioningRangeOutput() TableRangePartitioningRangeOutput
	ToTableRangePartitioningRangeOutputWithContext(context.Context) TableRangePartitioningRangeOutput
}

type TableRangePartitioningRangeArgs struct {
	// End of the range partitioning, exclusive.
	End pulumi.IntInput `pulumi:"end"`
	// The width of each range within the partition.
	Interval pulumi.IntInput `pulumi:"interval"`
	// Start of the range partitioning, inclusive.
	Start pulumi.IntInput `pulumi:"start"`
}

func (TableRangePartitioningRangeArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*TableRangePartitioningRange)(nil)).Elem()
}

func (i TableRangePartitioningRangeArgs) ToTableRangePartitioningRangeOutput() TableRangePartitioningRangeOutput {
	return i.ToTableRangePartitioningRangeOutputWithContext(context.Background())
}

func (i TableRangePartitioningRangeArgs) ToTableRangePartitioningRangeOutputWithContext(ctx context.Context) TableRangePartitioningRangeOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableRangePartitioningRangeOutput)
}

func (i TableRangePartitioningRangeArgs) ToTableRangePartitioningRangePtrOutput() TableRangePartitioningRangePtrOutput {
	return i.ToTableRangePartitioningRangePtrOutputWithContext(context.Background())
}

func (i TableRangePartitioningRangeArgs) ToTableRangePartitioningRangePtrOutputWithContext(ctx context.Context) TableRangePartitioningRangePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableRangePartitioningRangeOutput).ToTableRangePartitioningRangePtrOutputWithContext(ctx)
}

// TableRangePartitioningRangePtrInput is an input type that accepts TableRangePartitioningRangeArgs, TableRangePartitioningRangePtr and TableRangePartitioningRangePtrOutput values.
// You can construct a concrete instance of `TableRangePartitioningRangePtrInput` via:
//
// 		 TableRangePartitioningRangeArgs{...}
//
//  or:
//
// 		 nil
//
type TableRangePartitioningRangePtrInput interface {
	pulumi.Input

	ToTableRangePartitioningRangePtrOutput() TableRangePartitioningRangePtrOutput
	ToTableRangePartitioningRangePtrOutputWithContext(context.Context) TableRangePartitioningRangePtrOutput
}

type tableRangePartitioningRangePtrType TableRangePartitioningRangeArgs

func TableRangePartitioningRangePtr(v *TableRangePartitioningRangeArgs) TableRangePartitioningRangePtrInput {
	return (*tableRangePartitioningRangePtrType)(v)
}

func (*tableRangePartitioningRangePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**TableRangePartitioningRange)(nil)).Elem()
}

func (i *tableRangePartitioningRangePtrType) ToTableRangePartitioningRangePtrOutput() TableRangePartitioningRangePtrOutput {
	return i.ToTableRangePartitioningRangePtrOutputWithContext(context.Background())
}

func (i *tableRangePartitioningRangePtrType) ToTableRangePartitioningRangePtrOutputWithContext(ctx context.Context) TableRangePartitioningRangePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableRangePartitioningRangePtrOutput)
}

type TableRangePartitioningRangeOutput struct{ *pulumi.OutputState }

func (TableRangePartitioningRangeOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*TableRangePartitioningRange)(nil)).Elem()
}

func (o TableRangePartitioningRangeOutput) ToTableRangePartitioningRangeOutput() TableRangePartitioningRangeOutput {
	return o
}

func (o TableRangePartitioningRangeOutput) ToTableRangePartitioningRangeOutputWithContext(ctx context.Context) TableRangePartitioningRangeOutput {
	return o
}

func (o TableRangePartitioningRangeOutput) ToTableRangePartitioningRangePtrOutput() TableRangePartitioningRangePtrOutput {
	return o.ToTableRangePartitioningRangePtrOutputWithContext(context.Background())
}

func (o TableRangePartitioningRangeOutput) ToTableRangePartitioningRangePtrOutputWithContext(ctx context.Context) TableRangePartitioningRangePtrOutput {
	return o.ApplyT(func(v TableRangePartitioningRange) *TableRangePartitioningRange {
		return &v
	}).(TableRangePartitioningRangePtrOutput)
}

// End of the range partitioning, exclusive.
func (o TableRangePartitioningRangeOutput) End() pulumi.IntOutput {
	return o.ApplyT(func(v TableRangePartitioningRange) int { return v.End }).(pulumi.IntOutput)
}

// The width of each range within the partition.
func (o TableRangePartitioningRangeOutput) Interval() pulumi.IntOutput {
	return o.ApplyT(func(v TableRangePartitioningRange) int { return v.Interval }).(pulumi.IntOutput)
}

// Start of the range partitioning, inclusive.
func (o TableRangePartitioningRangeOutput) Start() pulumi.IntOutput {
	return o.ApplyT(func(v TableRangePartitioningRange) int { return v.Start }).(pulumi.IntOutput)
}

type TableRangePartitioningRangePtrOutput struct{ *pulumi.OutputState }

func (TableRangePartitioningRangePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**TableRangePartitioningRange)(nil)).Elem()
}

func (o TableRangePartitioningRangePtrOutput) ToTableRangePartitioningRangePtrOutput() TableRangePartitioningRangePtrOutput {
	return o
}

func (o TableRangePartitioningRangePtrOutput) ToTableRangePartitioningRangePtrOutputWithContext(ctx context.Context) TableRangePartitioningRangePtrOutput {
	return o
}

func (o TableRangePartitioningRangePtrOutput) Elem() TableRangePartitioningRangeOutput {
	return o.ApplyT(func(v *TableRangePartitioningRange) TableRangePartitioningRange { return *v }).(TableRangePartitioningRangeOutput)
}

// End of the range partitioning, exclusive.
func (o TableRangePartitioningRangePtrOutput) End() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *TableRangePartitioningRange) *int {
		if v == nil {
			return nil
		}
		return &v.End
	}).(pulumi.IntPtrOutput)
}

// The width of each range within the partition.
func (o TableRangePartitioningRangePtrOutput) Interval() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *TableRangePartitioningRange) *int {
		if v == nil {
			return nil
		}
		return &v.Interval
	}).(pulumi.IntPtrOutput)
}

// Start of the range partitioning, inclusive.
func (o TableRangePartitioningRangePtrOutput) Start() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *TableRangePartitioningRange) *int {
		if v == nil {
			return nil
		}
		return &v.Start
	}).(pulumi.IntPtrOutput)
}

type TableTimePartitioning struct {
	// Number of milliseconds for which to keep the
	// storage for a partition.
	ExpirationMs *int `pulumi:"expirationMs"`
	// The field used to determine how to create a range-based
	// partition.
	Field *string `pulumi:"field"`
	// If set to true, queries over this table
	// require a partition filter that can be used for partition elimination to be
	// specified.
	RequirePartitionFilter *bool `pulumi:"requirePartitionFilter"`
	// The only type supported is DAY, which will generate
	// one partition per day based on data loading time.
	Type string `pulumi:"type"`
}

// TableTimePartitioningInput is an input type that accepts TableTimePartitioningArgs and TableTimePartitioningOutput values.
// You can construct a concrete instance of `TableTimePartitioningInput` via:
//
// 		 TableTimePartitioningArgs{...}
//
type TableTimePartitioningInput interface {
	pulumi.Input

	ToTableTimePartitioningOutput() TableTimePartitioningOutput
	ToTableTimePartitioningOutputWithContext(context.Context) TableTimePartitioningOutput
}

type TableTimePartitioningArgs struct {
	// Number of milliseconds for which to keep the
	// storage for a partition.
	ExpirationMs pulumi.IntPtrInput `pulumi:"expirationMs"`
	// The field used to determine how to create a range-based
	// partition.
	Field pulumi.StringPtrInput `pulumi:"field"`
	// If set to true, queries over this table
	// require a partition filter that can be used for partition elimination to be
	// specified.
	RequirePartitionFilter pulumi.BoolPtrInput `pulumi:"requirePartitionFilter"`
	// The only type supported is DAY, which will generate
	// one partition per day based on data loading time.
	Type pulumi.StringInput `pulumi:"type"`
}

func (TableTimePartitioningArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*TableTimePartitioning)(nil)).Elem()
}

func (i TableTimePartitioningArgs) ToTableTimePartitioningOutput() TableTimePartitioningOutput {
	return i.ToTableTimePartitioningOutputWithContext(context.Background())
}

func (i TableTimePartitioningArgs) ToTableTimePartitioningOutputWithContext(ctx context.Context) TableTimePartitioningOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableTimePartitioningOutput)
}

func (i TableTimePartitioningArgs) ToTableTimePartitioningPtrOutput() TableTimePartitioningPtrOutput {
	return i.ToTableTimePartitioningPtrOutputWithContext(context.Background())
}

func (i TableTimePartitioningArgs) ToTableTimePartitioningPtrOutputWithContext(ctx context.Context) TableTimePartitioningPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableTimePartitioningOutput).ToTableTimePartitioningPtrOutputWithContext(ctx)
}

// TableTimePartitioningPtrInput is an input type that accepts TableTimePartitioningArgs, TableTimePartitioningPtr and TableTimePartitioningPtrOutput values.
// You can construct a concrete instance of `TableTimePartitioningPtrInput` via:
//
// 		 TableTimePartitioningArgs{...}
//
//  or:
//
// 		 nil
//
type TableTimePartitioningPtrInput interface {
	pulumi.Input

	ToTableTimePartitioningPtrOutput() TableTimePartitioningPtrOutput
	ToTableTimePartitioningPtrOutputWithContext(context.Context) TableTimePartitioningPtrOutput
}

type tableTimePartitioningPtrType TableTimePartitioningArgs

func TableTimePartitioningPtr(v *TableTimePartitioningArgs) TableTimePartitioningPtrInput {
	return (*tableTimePartitioningPtrType)(v)
}

func (*tableTimePartitioningPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**TableTimePartitioning)(nil)).Elem()
}

func (i *tableTimePartitioningPtrType) ToTableTimePartitioningPtrOutput() TableTimePartitioningPtrOutput {
	return i.ToTableTimePartitioningPtrOutputWithContext(context.Background())
}

func (i *tableTimePartitioningPtrType) ToTableTimePartitioningPtrOutputWithContext(ctx context.Context) TableTimePartitioningPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableTimePartitioningPtrOutput)
}

type TableTimePartitioningOutput struct{ *pulumi.OutputState }

func (TableTimePartitioningOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*TableTimePartitioning)(nil)).Elem()
}

func (o TableTimePartitioningOutput) ToTableTimePartitioningOutput() TableTimePartitioningOutput {
	return o
}

func (o TableTimePartitioningOutput) ToTableTimePartitioningOutputWithContext(ctx context.Context) TableTimePartitioningOutput {
	return o
}

func (o TableTimePartitioningOutput) ToTableTimePartitioningPtrOutput() TableTimePartitioningPtrOutput {
	return o.ToTableTimePartitioningPtrOutputWithContext(context.Background())
}

func (o TableTimePartitioningOutput) ToTableTimePartitioningPtrOutputWithContext(ctx context.Context) TableTimePartitioningPtrOutput {
	return o.ApplyT(func(v TableTimePartitioning) *TableTimePartitioning {
		return &v
	}).(TableTimePartitioningPtrOutput)
}

// Number of milliseconds for which to keep the
// storage for a partition.
func (o TableTimePartitioningOutput) ExpirationMs() pulumi.IntPtrOutput {
	return o.ApplyT(func(v TableTimePartitioning) *int { return v.ExpirationMs }).(pulumi.IntPtrOutput)
}

// The field used to determine how to create a range-based
// partition.
func (o TableTimePartitioningOutput) Field() pulumi.StringPtrOutput {
	return o.ApplyT(func(v TableTimePartitioning) *string { return v.Field }).(pulumi.StringPtrOutput)
}

// If set to true, queries over this table
// require a partition filter that can be used for partition elimination to be
// specified.
func (o TableTimePartitioningOutput) RequirePartitionFilter() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v TableTimePartitioning) *bool { return v.RequirePartitionFilter }).(pulumi.BoolPtrOutput)
}

// The only type supported is DAY, which will generate
// one partition per day based on data loading time.
func (o TableTimePartitioningOutput) Type() pulumi.StringOutput {
	return o.ApplyT(func(v TableTimePartitioning) string { return v.Type }).(pulumi.StringOutput)
}

type TableTimePartitioningPtrOutput struct{ *pulumi.OutputState }

func (TableTimePartitioningPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**TableTimePartitioning)(nil)).Elem()
}

func (o TableTimePartitioningPtrOutput) ToTableTimePartitioningPtrOutput() TableTimePartitioningPtrOutput {
	return o
}

func (o TableTimePartitioningPtrOutput) ToTableTimePartitioningPtrOutputWithContext(ctx context.Context) TableTimePartitioningPtrOutput {
	return o
}

func (o TableTimePartitioningPtrOutput) Elem() TableTimePartitioningOutput {
	return o.ApplyT(func(v *TableTimePartitioning) TableTimePartitioning { return *v }).(TableTimePartitioningOutput)
}

// Number of milliseconds for which to keep the
// storage for a partition.
func (o TableTimePartitioningPtrOutput) ExpirationMs() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *TableTimePartitioning) *int {
		if v == nil {
			return nil
		}
		return v.ExpirationMs
	}).(pulumi.IntPtrOutput)
}

// The field used to determine how to create a range-based
// partition.
func (o TableTimePartitioningPtrOutput) Field() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableTimePartitioning) *string {
		if v == nil {
			return nil
		}
		return v.Field
	}).(pulumi.StringPtrOutput)
}

// If set to true, queries over this table
// require a partition filter that can be used for partition elimination to be
// specified.
func (o TableTimePartitioningPtrOutput) RequirePartitionFilter() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *TableTimePartitioning) *bool {
		if v == nil {
			return nil
		}
		return v.RequirePartitionFilter
	}).(pulumi.BoolPtrOutput)
}

// The only type supported is DAY, which will generate
// one partition per day based on data loading time.
func (o TableTimePartitioningPtrOutput) Type() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableTimePartitioning) *string {
		if v == nil {
			return nil
		}
		return &v.Type
	}).(pulumi.StringPtrOutput)
}

type TableView struct {
	// A query that BigQuery executes when the view is referenced.
	Query string `pulumi:"query"`
	// Specifies whether to use BigQuery's legacy SQL for this view.
	// The default value is true. If set to false, the view will use BigQuery's standard SQL.
	UseLegacySql *bool `pulumi:"useLegacySql"`
}

// TableViewInput is an input type that accepts TableViewArgs and TableViewOutput values.
// You can construct a concrete instance of `TableViewInput` via:
//
// 		 TableViewArgs{...}
//
type TableViewInput interface {
	pulumi.Input

	ToTableViewOutput() TableViewOutput
	ToTableViewOutputWithContext(context.Context) TableViewOutput
}

type TableViewArgs struct {
	// A query that BigQuery executes when the view is referenced.
	Query pulumi.StringInput `pulumi:"query"`
	// Specifies whether to use BigQuery's legacy SQL for this view.
	// The default value is true. If set to false, the view will use BigQuery's standard SQL.
	UseLegacySql pulumi.BoolPtrInput `pulumi:"useLegacySql"`
}

func (TableViewArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*TableView)(nil)).Elem()
}

func (i TableViewArgs) ToTableViewOutput() TableViewOutput {
	return i.ToTableViewOutputWithContext(context.Background())
}

func (i TableViewArgs) ToTableViewOutputWithContext(ctx context.Context) TableViewOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableViewOutput)
}

func (i TableViewArgs) ToTableViewPtrOutput() TableViewPtrOutput {
	return i.ToTableViewPtrOutputWithContext(context.Background())
}

func (i TableViewArgs) ToTableViewPtrOutputWithContext(ctx context.Context) TableViewPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableViewOutput).ToTableViewPtrOutputWithContext(ctx)
}

// TableViewPtrInput is an input type that accepts TableViewArgs, TableViewPtr and TableViewPtrOutput values.
// You can construct a concrete instance of `TableViewPtrInput` via:
//
// 		 TableViewArgs{...}
//
//  or:
//
// 		 nil
//
type TableViewPtrInput interface {
	pulumi.Input

	ToTableViewPtrOutput() TableViewPtrOutput
	ToTableViewPtrOutputWithContext(context.Context) TableViewPtrOutput
}

type tableViewPtrType TableViewArgs

func TableViewPtr(v *TableViewArgs) TableViewPtrInput {
	return (*tableViewPtrType)(v)
}

func (*tableViewPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**TableView)(nil)).Elem()
}

func (i *tableViewPtrType) ToTableViewPtrOutput() TableViewPtrOutput {
	return i.ToTableViewPtrOutputWithContext(context.Background())
}

func (i *tableViewPtrType) ToTableViewPtrOutputWithContext(ctx context.Context) TableViewPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TableViewPtrOutput)
}

type TableViewOutput struct{ *pulumi.OutputState }

func (TableViewOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*TableView)(nil)).Elem()
}

func (o TableViewOutput) ToTableViewOutput() TableViewOutput {
	return o
}

func (o TableViewOutput) ToTableViewOutputWithContext(ctx context.Context) TableViewOutput {
	return o
}

func (o TableViewOutput) ToTableViewPtrOutput() TableViewPtrOutput {
	return o.ToTableViewPtrOutputWithContext(context.Background())
}

func (o TableViewOutput) ToTableViewPtrOutputWithContext(ctx context.Context) TableViewPtrOutput {
	return o.ApplyT(func(v TableView) *TableView {
		return &v
	}).(TableViewPtrOutput)
}

// A query that BigQuery executes when the view is referenced.
func (o TableViewOutput) Query() pulumi.StringOutput {
	return o.ApplyT(func(v TableView) string { return v.Query }).(pulumi.StringOutput)
}

// Specifies whether to use BigQuery's legacy SQL for this view.
// The default value is true. If set to false, the view will use BigQuery's standard SQL.
func (o TableViewOutput) UseLegacySql() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v TableView) *bool { return v.UseLegacySql }).(pulumi.BoolPtrOutput)
}

type TableViewPtrOutput struct{ *pulumi.OutputState }

func (TableViewPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**TableView)(nil)).Elem()
}

func (o TableViewPtrOutput) ToTableViewPtrOutput() TableViewPtrOutput {
	return o
}

func (o TableViewPtrOutput) ToTableViewPtrOutputWithContext(ctx context.Context) TableViewPtrOutput {
	return o
}

func (o TableViewPtrOutput) Elem() TableViewOutput {
	return o.ApplyT(func(v *TableView) TableView { return *v }).(TableViewOutput)
}

// A query that BigQuery executes when the view is referenced.
func (o TableViewPtrOutput) Query() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *TableView) *string {
		if v == nil {
			return nil
		}
		return &v.Query
	}).(pulumi.StringPtrOutput)
}

// Specifies whether to use BigQuery's legacy SQL for this view.
// The default value is true. If set to false, the view will use BigQuery's standard SQL.
func (o TableViewPtrOutput) UseLegacySql() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *TableView) *bool {
		if v == nil {
			return nil
		}
		return v.UseLegacySql
	}).(pulumi.BoolPtrOutput)
}

func init() {
	pulumi.RegisterOutputType(AppProfileSingleClusterRoutingOutput{})
	pulumi.RegisterOutputType(AppProfileSingleClusterRoutingPtrOutput{})
	pulumi.RegisterOutputType(ConnectionCloudSqlOutput{})
	pulumi.RegisterOutputType(ConnectionCloudSqlPtrOutput{})
	pulumi.RegisterOutputType(ConnectionCloudSqlCredentialOutput{})
	pulumi.RegisterOutputType(ConnectionCloudSqlCredentialPtrOutput{})
	pulumi.RegisterOutputType(DatasetAccessTypeOutput{})
	pulumi.RegisterOutputType(DatasetAccessTypeArrayOutput{})
	pulumi.RegisterOutputType(DatasetAccessViewOutput{})
	pulumi.RegisterOutputType(DatasetAccessViewPtrOutput{})
	pulumi.RegisterOutputType(DatasetDefaultEncryptionConfigurationOutput{})
	pulumi.RegisterOutputType(DatasetDefaultEncryptionConfigurationPtrOutput{})
	pulumi.RegisterOutputType(DatasetIamBindingConditionOutput{})
	pulumi.RegisterOutputType(DatasetIamBindingConditionPtrOutput{})
	pulumi.RegisterOutputType(DatasetIamMemberConditionOutput{})
	pulumi.RegisterOutputType(DatasetIamMemberConditionPtrOutput{})
	pulumi.RegisterOutputType(JobCopyOutput{})
	pulumi.RegisterOutputType(JobCopyPtrOutput{})
	pulumi.RegisterOutputType(JobCopyDestinationEncryptionConfigurationOutput{})
	pulumi.RegisterOutputType(JobCopyDestinationEncryptionConfigurationPtrOutput{})
	pulumi.RegisterOutputType(JobCopyDestinationTableOutput{})
	pulumi.RegisterOutputType(JobCopyDestinationTablePtrOutput{})
	pulumi.RegisterOutputType(JobCopySourceTableOutput{})
	pulumi.RegisterOutputType(JobCopySourceTableArrayOutput{})
	pulumi.RegisterOutputType(JobExtractOutput{})
	pulumi.RegisterOutputType(JobExtractPtrOutput{})
	pulumi.RegisterOutputType(JobExtractSourceModelOutput{})
	pulumi.RegisterOutputType(JobExtractSourceModelPtrOutput{})
	pulumi.RegisterOutputType(JobExtractSourceTableOutput{})
	pulumi.RegisterOutputType(JobExtractSourceTablePtrOutput{})
	pulumi.RegisterOutputType(JobLoadOutput{})
	pulumi.RegisterOutputType(JobLoadPtrOutput{})
	pulumi.RegisterOutputType(JobLoadDestinationEncryptionConfigurationOutput{})
	pulumi.RegisterOutputType(JobLoadDestinationEncryptionConfigurationPtrOutput{})
	pulumi.RegisterOutputType(JobLoadDestinationTableOutput{})
	pulumi.RegisterOutputType(JobLoadDestinationTablePtrOutput{})
	pulumi.RegisterOutputType(JobLoadTimePartitioningOutput{})
	pulumi.RegisterOutputType(JobLoadTimePartitioningPtrOutput{})
	pulumi.RegisterOutputType(JobQueryOutput{})
	pulumi.RegisterOutputType(JobQueryPtrOutput{})
	pulumi.RegisterOutputType(JobQueryDefaultDatasetOutput{})
	pulumi.RegisterOutputType(JobQueryDefaultDatasetPtrOutput{})
	pulumi.RegisterOutputType(JobQueryDestinationEncryptionConfigurationOutput{})
	pulumi.RegisterOutputType(JobQueryDestinationEncryptionConfigurationPtrOutput{})
	pulumi.RegisterOutputType(JobQueryDestinationTableOutput{})
	pulumi.RegisterOutputType(JobQueryDestinationTablePtrOutput{})
	pulumi.RegisterOutputType(JobQueryScriptOptionsOutput{})
	pulumi.RegisterOutputType(JobQueryScriptOptionsPtrOutput{})
	pulumi.RegisterOutputType(JobQueryUserDefinedFunctionResourceOutput{})
	pulumi.RegisterOutputType(JobQueryUserDefinedFunctionResourceArrayOutput{})
	pulumi.RegisterOutputType(TableEncryptionConfigurationOutput{})
	pulumi.RegisterOutputType(TableEncryptionConfigurationPtrOutput{})
	pulumi.RegisterOutputType(TableExternalDataConfigurationOutput{})
	pulumi.RegisterOutputType(TableExternalDataConfigurationPtrOutput{})
	pulumi.RegisterOutputType(TableExternalDataConfigurationCsvOptionsOutput{})
	pulumi.RegisterOutputType(TableExternalDataConfigurationCsvOptionsPtrOutput{})
	pulumi.RegisterOutputType(TableExternalDataConfigurationGoogleSheetsOptionsOutput{})
	pulumi.RegisterOutputType(TableExternalDataConfigurationGoogleSheetsOptionsPtrOutput{})
	pulumi.RegisterOutputType(TableExternalDataConfigurationHivePartitioningOptionsOutput{})
	pulumi.RegisterOutputType(TableExternalDataConfigurationHivePartitioningOptionsPtrOutput{})
	pulumi.RegisterOutputType(TableRangePartitioningOutput{})
	pulumi.RegisterOutputType(TableRangePartitioningPtrOutput{})
	pulumi.RegisterOutputType(TableRangePartitioningRangeOutput{})
	pulumi.RegisterOutputType(TableRangePartitioningRangePtrOutput{})
	pulumi.RegisterOutputType(TableTimePartitioningOutput{})
	pulumi.RegisterOutputType(TableTimePartitioningPtrOutput{})
	pulumi.RegisterOutputType(TableViewOutput{})
	pulumi.RegisterOutputType(TableViewPtrOutput{})
}
