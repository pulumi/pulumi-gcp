// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package dataproc

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi/sdk/v2/go/pulumi"
)

type AutoscalingPolicyBasicAlgorithm struct {
	// Duration between scaling events. A scaling period starts after the
	// update operation from the previous event has completed.
	// Bounds: [2m, 1d]. Default: 2m.
	CooldownPeriod *string `pulumi:"cooldownPeriod"`
	// YARN autoscaling configuration.  Structure is documented below.
	YarnConfig AutoscalingPolicyBasicAlgorithmYarnConfig `pulumi:"yarnConfig"`
}

// AutoscalingPolicyBasicAlgorithmInput is an input type that accepts AutoscalingPolicyBasicAlgorithmArgs and AutoscalingPolicyBasicAlgorithmOutput values.
// You can construct a concrete instance of `AutoscalingPolicyBasicAlgorithmInput` via:
//
// 		 AutoscalingPolicyBasicAlgorithmArgs{...}
//
type AutoscalingPolicyBasicAlgorithmInput interface {
	pulumi.Input

	ToAutoscalingPolicyBasicAlgorithmOutput() AutoscalingPolicyBasicAlgorithmOutput
	ToAutoscalingPolicyBasicAlgorithmOutputWithContext(context.Context) AutoscalingPolicyBasicAlgorithmOutput
}

type AutoscalingPolicyBasicAlgorithmArgs struct {
	// Duration between scaling events. A scaling period starts after the
	// update operation from the previous event has completed.
	// Bounds: [2m, 1d]. Default: 2m.
	CooldownPeriod pulumi.StringPtrInput `pulumi:"cooldownPeriod"`
	// YARN autoscaling configuration.  Structure is documented below.
	YarnConfig AutoscalingPolicyBasicAlgorithmYarnConfigInput `pulumi:"yarnConfig"`
}

func (AutoscalingPolicyBasicAlgorithmArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AutoscalingPolicyBasicAlgorithm)(nil)).Elem()
}

func (i AutoscalingPolicyBasicAlgorithmArgs) ToAutoscalingPolicyBasicAlgorithmOutput() AutoscalingPolicyBasicAlgorithmOutput {
	return i.ToAutoscalingPolicyBasicAlgorithmOutputWithContext(context.Background())
}

func (i AutoscalingPolicyBasicAlgorithmArgs) ToAutoscalingPolicyBasicAlgorithmOutputWithContext(ctx context.Context) AutoscalingPolicyBasicAlgorithmOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingPolicyBasicAlgorithmOutput)
}

func (i AutoscalingPolicyBasicAlgorithmArgs) ToAutoscalingPolicyBasicAlgorithmPtrOutput() AutoscalingPolicyBasicAlgorithmPtrOutput {
	return i.ToAutoscalingPolicyBasicAlgorithmPtrOutputWithContext(context.Background())
}

func (i AutoscalingPolicyBasicAlgorithmArgs) ToAutoscalingPolicyBasicAlgorithmPtrOutputWithContext(ctx context.Context) AutoscalingPolicyBasicAlgorithmPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingPolicyBasicAlgorithmOutput).ToAutoscalingPolicyBasicAlgorithmPtrOutputWithContext(ctx)
}

// AutoscalingPolicyBasicAlgorithmPtrInput is an input type that accepts AutoscalingPolicyBasicAlgorithmArgs, AutoscalingPolicyBasicAlgorithmPtr and AutoscalingPolicyBasicAlgorithmPtrOutput values.
// You can construct a concrete instance of `AutoscalingPolicyBasicAlgorithmPtrInput` via:
//
// 		 AutoscalingPolicyBasicAlgorithmArgs{...}
//
//  or:
//
// 		 nil
//
type AutoscalingPolicyBasicAlgorithmPtrInput interface {
	pulumi.Input

	ToAutoscalingPolicyBasicAlgorithmPtrOutput() AutoscalingPolicyBasicAlgorithmPtrOutput
	ToAutoscalingPolicyBasicAlgorithmPtrOutputWithContext(context.Context) AutoscalingPolicyBasicAlgorithmPtrOutput
}

type autoscalingPolicyBasicAlgorithmPtrType AutoscalingPolicyBasicAlgorithmArgs

func AutoscalingPolicyBasicAlgorithmPtr(v *AutoscalingPolicyBasicAlgorithmArgs) AutoscalingPolicyBasicAlgorithmPtrInput {
	return (*autoscalingPolicyBasicAlgorithmPtrType)(v)
}

func (*autoscalingPolicyBasicAlgorithmPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AutoscalingPolicyBasicAlgorithm)(nil)).Elem()
}

func (i *autoscalingPolicyBasicAlgorithmPtrType) ToAutoscalingPolicyBasicAlgorithmPtrOutput() AutoscalingPolicyBasicAlgorithmPtrOutput {
	return i.ToAutoscalingPolicyBasicAlgorithmPtrOutputWithContext(context.Background())
}

func (i *autoscalingPolicyBasicAlgorithmPtrType) ToAutoscalingPolicyBasicAlgorithmPtrOutputWithContext(ctx context.Context) AutoscalingPolicyBasicAlgorithmPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingPolicyBasicAlgorithmPtrOutput)
}

type AutoscalingPolicyBasicAlgorithmOutput struct{ *pulumi.OutputState }

func (AutoscalingPolicyBasicAlgorithmOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AutoscalingPolicyBasicAlgorithm)(nil)).Elem()
}

func (o AutoscalingPolicyBasicAlgorithmOutput) ToAutoscalingPolicyBasicAlgorithmOutput() AutoscalingPolicyBasicAlgorithmOutput {
	return o
}

func (o AutoscalingPolicyBasicAlgorithmOutput) ToAutoscalingPolicyBasicAlgorithmOutputWithContext(ctx context.Context) AutoscalingPolicyBasicAlgorithmOutput {
	return o
}

func (o AutoscalingPolicyBasicAlgorithmOutput) ToAutoscalingPolicyBasicAlgorithmPtrOutput() AutoscalingPolicyBasicAlgorithmPtrOutput {
	return o.ToAutoscalingPolicyBasicAlgorithmPtrOutputWithContext(context.Background())
}

func (o AutoscalingPolicyBasicAlgorithmOutput) ToAutoscalingPolicyBasicAlgorithmPtrOutputWithContext(ctx context.Context) AutoscalingPolicyBasicAlgorithmPtrOutput {
	return o.ApplyT(func(v AutoscalingPolicyBasicAlgorithm) *AutoscalingPolicyBasicAlgorithm {
		return &v
	}).(AutoscalingPolicyBasicAlgorithmPtrOutput)
}

// Duration between scaling events. A scaling period starts after the
// update operation from the previous event has completed.
// Bounds: [2m, 1d]. Default: 2m.
func (o AutoscalingPolicyBasicAlgorithmOutput) CooldownPeriod() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AutoscalingPolicyBasicAlgorithm) *string { return v.CooldownPeriod }).(pulumi.StringPtrOutput)
}

// YARN autoscaling configuration.  Structure is documented below.
func (o AutoscalingPolicyBasicAlgorithmOutput) YarnConfig() AutoscalingPolicyBasicAlgorithmYarnConfigOutput {
	return o.ApplyT(func(v AutoscalingPolicyBasicAlgorithm) AutoscalingPolicyBasicAlgorithmYarnConfig {
		return v.YarnConfig
	}).(AutoscalingPolicyBasicAlgorithmYarnConfigOutput)
}

type AutoscalingPolicyBasicAlgorithmPtrOutput struct{ *pulumi.OutputState }

func (AutoscalingPolicyBasicAlgorithmPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AutoscalingPolicyBasicAlgorithm)(nil)).Elem()
}

func (o AutoscalingPolicyBasicAlgorithmPtrOutput) ToAutoscalingPolicyBasicAlgorithmPtrOutput() AutoscalingPolicyBasicAlgorithmPtrOutput {
	return o
}

func (o AutoscalingPolicyBasicAlgorithmPtrOutput) ToAutoscalingPolicyBasicAlgorithmPtrOutputWithContext(ctx context.Context) AutoscalingPolicyBasicAlgorithmPtrOutput {
	return o
}

func (o AutoscalingPolicyBasicAlgorithmPtrOutput) Elem() AutoscalingPolicyBasicAlgorithmOutput {
	return o.ApplyT(func(v *AutoscalingPolicyBasicAlgorithm) AutoscalingPolicyBasicAlgorithm { return *v }).(AutoscalingPolicyBasicAlgorithmOutput)
}

// Duration between scaling events. A scaling period starts after the
// update operation from the previous event has completed.
// Bounds: [2m, 1d]. Default: 2m.
func (o AutoscalingPolicyBasicAlgorithmPtrOutput) CooldownPeriod() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicyBasicAlgorithm) *string {
		if v == nil {
			return nil
		}
		return v.CooldownPeriod
	}).(pulumi.StringPtrOutput)
}

// YARN autoscaling configuration.  Structure is documented below.
func (o AutoscalingPolicyBasicAlgorithmPtrOutput) YarnConfig() AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicyBasicAlgorithm) *AutoscalingPolicyBasicAlgorithmYarnConfig {
		if v == nil {
			return nil
		}
		return &v.YarnConfig
	}).(AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput)
}

type AutoscalingPolicyBasicAlgorithmYarnConfig struct {
	// Timeout for YARN graceful decommissioning of Node Managers. Specifies the
	// duration to wait for jobs to complete before forcefully removing workers
	// (and potentially interrupting jobs). Only applicable to downscaling operations.
	// Bounds: [0s, 1d].
	GracefulDecommissionTimeout string `pulumi:"gracefulDecommissionTimeout"`
	// Fraction of average pending memory in the last cooldown period for which to
	// remove workers. A scale-down factor of 1 will result in scaling down so that there
	// is no available memory remaining after the update (more aggressive scaling).
	// A scale-down factor of 0 disables removing workers, which can be beneficial for
	// autoscaling a single job.
	// Bounds: [0.0, 1.0].
	ScaleDownFactor float64 `pulumi:"scaleDownFactor"`
	// Minimum scale-down threshold as a fraction of total cluster size before scaling occurs.
	// For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must
	// recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0
	// means the autoscaler will scale down on any recommended change.
	// Bounds: [0.0, 1.0]. Default: 0.0.
	ScaleDownMinWorkerFraction *float64 `pulumi:"scaleDownMinWorkerFraction"`
	// Fraction of average pending memory in the last cooldown period for which to
	// add workers. A scale-up factor of 1.0 will result in scaling up so that there
	// is no pending memory remaining after the update (more aggressive scaling).
	// A scale-up factor closer to 0 will result in a smaller magnitude of scaling up
	// (less aggressive scaling).
	// Bounds: [0.0, 1.0].
	ScaleUpFactor float64 `pulumi:"scaleUpFactor"`
	// Minimum scale-up threshold as a fraction of total cluster size before scaling
	// occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler
	// must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of
	// 0 means the autoscaler will scale up on any recommended change.
	// Bounds: [0.0, 1.0]. Default: 0.0.
	ScaleUpMinWorkerFraction *float64 `pulumi:"scaleUpMinWorkerFraction"`
}

// AutoscalingPolicyBasicAlgorithmYarnConfigInput is an input type that accepts AutoscalingPolicyBasicAlgorithmYarnConfigArgs and AutoscalingPolicyBasicAlgorithmYarnConfigOutput values.
// You can construct a concrete instance of `AutoscalingPolicyBasicAlgorithmYarnConfigInput` via:
//
// 		 AutoscalingPolicyBasicAlgorithmYarnConfigArgs{...}
//
type AutoscalingPolicyBasicAlgorithmYarnConfigInput interface {
	pulumi.Input

	ToAutoscalingPolicyBasicAlgorithmYarnConfigOutput() AutoscalingPolicyBasicAlgorithmYarnConfigOutput
	ToAutoscalingPolicyBasicAlgorithmYarnConfigOutputWithContext(context.Context) AutoscalingPolicyBasicAlgorithmYarnConfigOutput
}

type AutoscalingPolicyBasicAlgorithmYarnConfigArgs struct {
	// Timeout for YARN graceful decommissioning of Node Managers. Specifies the
	// duration to wait for jobs to complete before forcefully removing workers
	// (and potentially interrupting jobs). Only applicable to downscaling operations.
	// Bounds: [0s, 1d].
	GracefulDecommissionTimeout pulumi.StringInput `pulumi:"gracefulDecommissionTimeout"`
	// Fraction of average pending memory in the last cooldown period for which to
	// remove workers. A scale-down factor of 1 will result in scaling down so that there
	// is no available memory remaining after the update (more aggressive scaling).
	// A scale-down factor of 0 disables removing workers, which can be beneficial for
	// autoscaling a single job.
	// Bounds: [0.0, 1.0].
	ScaleDownFactor pulumi.Float64Input `pulumi:"scaleDownFactor"`
	// Minimum scale-down threshold as a fraction of total cluster size before scaling occurs.
	// For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must
	// recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0
	// means the autoscaler will scale down on any recommended change.
	// Bounds: [0.0, 1.0]. Default: 0.0.
	ScaleDownMinWorkerFraction pulumi.Float64PtrInput `pulumi:"scaleDownMinWorkerFraction"`
	// Fraction of average pending memory in the last cooldown period for which to
	// add workers. A scale-up factor of 1.0 will result in scaling up so that there
	// is no pending memory remaining after the update (more aggressive scaling).
	// A scale-up factor closer to 0 will result in a smaller magnitude of scaling up
	// (less aggressive scaling).
	// Bounds: [0.0, 1.0].
	ScaleUpFactor pulumi.Float64Input `pulumi:"scaleUpFactor"`
	// Minimum scale-up threshold as a fraction of total cluster size before scaling
	// occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler
	// must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of
	// 0 means the autoscaler will scale up on any recommended change.
	// Bounds: [0.0, 1.0]. Default: 0.0.
	ScaleUpMinWorkerFraction pulumi.Float64PtrInput `pulumi:"scaleUpMinWorkerFraction"`
}

func (AutoscalingPolicyBasicAlgorithmYarnConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AutoscalingPolicyBasicAlgorithmYarnConfig)(nil)).Elem()
}

func (i AutoscalingPolicyBasicAlgorithmYarnConfigArgs) ToAutoscalingPolicyBasicAlgorithmYarnConfigOutput() AutoscalingPolicyBasicAlgorithmYarnConfigOutput {
	return i.ToAutoscalingPolicyBasicAlgorithmYarnConfigOutputWithContext(context.Background())
}

func (i AutoscalingPolicyBasicAlgorithmYarnConfigArgs) ToAutoscalingPolicyBasicAlgorithmYarnConfigOutputWithContext(ctx context.Context) AutoscalingPolicyBasicAlgorithmYarnConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingPolicyBasicAlgorithmYarnConfigOutput)
}

func (i AutoscalingPolicyBasicAlgorithmYarnConfigArgs) ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput() AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput {
	return i.ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutputWithContext(context.Background())
}

func (i AutoscalingPolicyBasicAlgorithmYarnConfigArgs) ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutputWithContext(ctx context.Context) AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingPolicyBasicAlgorithmYarnConfigOutput).ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutputWithContext(ctx)
}

// AutoscalingPolicyBasicAlgorithmYarnConfigPtrInput is an input type that accepts AutoscalingPolicyBasicAlgorithmYarnConfigArgs, AutoscalingPolicyBasicAlgorithmYarnConfigPtr and AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput values.
// You can construct a concrete instance of `AutoscalingPolicyBasicAlgorithmYarnConfigPtrInput` via:
//
// 		 AutoscalingPolicyBasicAlgorithmYarnConfigArgs{...}
//
//  or:
//
// 		 nil
//
type AutoscalingPolicyBasicAlgorithmYarnConfigPtrInput interface {
	pulumi.Input

	ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput() AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput
	ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutputWithContext(context.Context) AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput
}

type autoscalingPolicyBasicAlgorithmYarnConfigPtrType AutoscalingPolicyBasicAlgorithmYarnConfigArgs

func AutoscalingPolicyBasicAlgorithmYarnConfigPtr(v *AutoscalingPolicyBasicAlgorithmYarnConfigArgs) AutoscalingPolicyBasicAlgorithmYarnConfigPtrInput {
	return (*autoscalingPolicyBasicAlgorithmYarnConfigPtrType)(v)
}

func (*autoscalingPolicyBasicAlgorithmYarnConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AutoscalingPolicyBasicAlgorithmYarnConfig)(nil)).Elem()
}

func (i *autoscalingPolicyBasicAlgorithmYarnConfigPtrType) ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput() AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput {
	return i.ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutputWithContext(context.Background())
}

func (i *autoscalingPolicyBasicAlgorithmYarnConfigPtrType) ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutputWithContext(ctx context.Context) AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput)
}

type AutoscalingPolicyBasicAlgorithmYarnConfigOutput struct{ *pulumi.OutputState }

func (AutoscalingPolicyBasicAlgorithmYarnConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AutoscalingPolicyBasicAlgorithmYarnConfig)(nil)).Elem()
}

func (o AutoscalingPolicyBasicAlgorithmYarnConfigOutput) ToAutoscalingPolicyBasicAlgorithmYarnConfigOutput() AutoscalingPolicyBasicAlgorithmYarnConfigOutput {
	return o
}

func (o AutoscalingPolicyBasicAlgorithmYarnConfigOutput) ToAutoscalingPolicyBasicAlgorithmYarnConfigOutputWithContext(ctx context.Context) AutoscalingPolicyBasicAlgorithmYarnConfigOutput {
	return o
}

func (o AutoscalingPolicyBasicAlgorithmYarnConfigOutput) ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput() AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput {
	return o.ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutputWithContext(context.Background())
}

func (o AutoscalingPolicyBasicAlgorithmYarnConfigOutput) ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutputWithContext(ctx context.Context) AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput {
	return o.ApplyT(func(v AutoscalingPolicyBasicAlgorithmYarnConfig) *AutoscalingPolicyBasicAlgorithmYarnConfig {
		return &v
	}).(AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput)
}

// Timeout for YARN graceful decommissioning of Node Managers. Specifies the
// duration to wait for jobs to complete before forcefully removing workers
// (and potentially interrupting jobs). Only applicable to downscaling operations.
// Bounds: [0s, 1d].
func (o AutoscalingPolicyBasicAlgorithmYarnConfigOutput) GracefulDecommissionTimeout() pulumi.StringOutput {
	return o.ApplyT(func(v AutoscalingPolicyBasicAlgorithmYarnConfig) string { return v.GracefulDecommissionTimeout }).(pulumi.StringOutput)
}

// Fraction of average pending memory in the last cooldown period for which to
// remove workers. A scale-down factor of 1 will result in scaling down so that there
// is no available memory remaining after the update (more aggressive scaling).
// A scale-down factor of 0 disables removing workers, which can be beneficial for
// autoscaling a single job.
// Bounds: [0.0, 1.0].
func (o AutoscalingPolicyBasicAlgorithmYarnConfigOutput) ScaleDownFactor() pulumi.Float64Output {
	return o.ApplyT(func(v AutoscalingPolicyBasicAlgorithmYarnConfig) float64 { return v.ScaleDownFactor }).(pulumi.Float64Output)
}

// Minimum scale-down threshold as a fraction of total cluster size before scaling occurs.
// For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must
// recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0
// means the autoscaler will scale down on any recommended change.
// Bounds: [0.0, 1.0]. Default: 0.0.
func (o AutoscalingPolicyBasicAlgorithmYarnConfigOutput) ScaleDownMinWorkerFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v AutoscalingPolicyBasicAlgorithmYarnConfig) *float64 { return v.ScaleDownMinWorkerFraction }).(pulumi.Float64PtrOutput)
}

// Fraction of average pending memory in the last cooldown period for which to
// add workers. A scale-up factor of 1.0 will result in scaling up so that there
// is no pending memory remaining after the update (more aggressive scaling).
// A scale-up factor closer to 0 will result in a smaller magnitude of scaling up
// (less aggressive scaling).
// Bounds: [0.0, 1.0].
func (o AutoscalingPolicyBasicAlgorithmYarnConfigOutput) ScaleUpFactor() pulumi.Float64Output {
	return o.ApplyT(func(v AutoscalingPolicyBasicAlgorithmYarnConfig) float64 { return v.ScaleUpFactor }).(pulumi.Float64Output)
}

// Minimum scale-up threshold as a fraction of total cluster size before scaling
// occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler
// must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of
// 0 means the autoscaler will scale up on any recommended change.
// Bounds: [0.0, 1.0]. Default: 0.0.
func (o AutoscalingPolicyBasicAlgorithmYarnConfigOutput) ScaleUpMinWorkerFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v AutoscalingPolicyBasicAlgorithmYarnConfig) *float64 { return v.ScaleUpMinWorkerFraction }).(pulumi.Float64PtrOutput)
}

type AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput struct{ *pulumi.OutputState }

func (AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AutoscalingPolicyBasicAlgorithmYarnConfig)(nil)).Elem()
}

func (o AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput) ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput() AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput {
	return o
}

func (o AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput) ToAutoscalingPolicyBasicAlgorithmYarnConfigPtrOutputWithContext(ctx context.Context) AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput {
	return o
}

func (o AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput) Elem() AutoscalingPolicyBasicAlgorithmYarnConfigOutput {
	return o.ApplyT(func(v *AutoscalingPolicyBasicAlgorithmYarnConfig) AutoscalingPolicyBasicAlgorithmYarnConfig {
		return *v
	}).(AutoscalingPolicyBasicAlgorithmYarnConfigOutput)
}

// Timeout for YARN graceful decommissioning of Node Managers. Specifies the
// duration to wait for jobs to complete before forcefully removing workers
// (and potentially interrupting jobs). Only applicable to downscaling operations.
// Bounds: [0s, 1d].
func (o AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput) GracefulDecommissionTimeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicyBasicAlgorithmYarnConfig) *string {
		if v == nil {
			return nil
		}
		return &v.GracefulDecommissionTimeout
	}).(pulumi.StringPtrOutput)
}

// Fraction of average pending memory in the last cooldown period for which to
// remove workers. A scale-down factor of 1 will result in scaling down so that there
// is no available memory remaining after the update (more aggressive scaling).
// A scale-down factor of 0 disables removing workers, which can be beneficial for
// autoscaling a single job.
// Bounds: [0.0, 1.0].
func (o AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput) ScaleDownFactor() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicyBasicAlgorithmYarnConfig) *float64 {
		if v == nil {
			return nil
		}
		return &v.ScaleDownFactor
	}).(pulumi.Float64PtrOutput)
}

// Minimum scale-down threshold as a fraction of total cluster size before scaling occurs.
// For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must
// recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0
// means the autoscaler will scale down on any recommended change.
// Bounds: [0.0, 1.0]. Default: 0.0.
func (o AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput) ScaleDownMinWorkerFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicyBasicAlgorithmYarnConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.ScaleDownMinWorkerFraction
	}).(pulumi.Float64PtrOutput)
}

// Fraction of average pending memory in the last cooldown period for which to
// add workers. A scale-up factor of 1.0 will result in scaling up so that there
// is no pending memory remaining after the update (more aggressive scaling).
// A scale-up factor closer to 0 will result in a smaller magnitude of scaling up
// (less aggressive scaling).
// Bounds: [0.0, 1.0].
func (o AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput) ScaleUpFactor() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicyBasicAlgorithmYarnConfig) *float64 {
		if v == nil {
			return nil
		}
		return &v.ScaleUpFactor
	}).(pulumi.Float64PtrOutput)
}

// Minimum scale-up threshold as a fraction of total cluster size before scaling
// occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler
// must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of
// 0 means the autoscaler will scale up on any recommended change.
// Bounds: [0.0, 1.0]. Default: 0.0.
func (o AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput) ScaleUpMinWorkerFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicyBasicAlgorithmYarnConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.ScaleUpMinWorkerFraction
	}).(pulumi.Float64PtrOutput)
}

type AutoscalingPolicySecondaryWorkerConfig struct {
	// Maximum number of instances for this group. Note that by default, clusters will not use
	// secondary workers. Required for secondary workers if the minimum secondary instances is set.
	// Bounds: [minInstances, ). Defaults to 0.
	MaxInstances *int `pulumi:"maxInstances"`
	// Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
	MinInstances *int `pulumi:"minInstances"`
	// Weight for the instance group, which is used to determine the fraction of total workers
	// in the cluster from this instance group. For example, if primary workers have weight 2,
	// and secondary workers have weight 1, the cluster will have approximately 2 primary workers
	// for each secondary worker.
	// The cluster may not reach the specified balance if constrained by min/max bounds or other
	// autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
	// primary workers will be added. The cluster can also be out of balance when created.
	// If weight is not set on any instance group, the cluster will default to equal weight for
	// all groups: the cluster will attempt to maintain an equal number of workers in each group
	// within the configured size bounds for each group. If weight is set for one group only,
	// the cluster will default to zero weight on the unset group. For example if weight is set
	// only on primary workers, the cluster will use primary workers only and no secondary workers.
	Weight *int `pulumi:"weight"`
}

// AutoscalingPolicySecondaryWorkerConfigInput is an input type that accepts AutoscalingPolicySecondaryWorkerConfigArgs and AutoscalingPolicySecondaryWorkerConfigOutput values.
// You can construct a concrete instance of `AutoscalingPolicySecondaryWorkerConfigInput` via:
//
// 		 AutoscalingPolicySecondaryWorkerConfigArgs{...}
//
type AutoscalingPolicySecondaryWorkerConfigInput interface {
	pulumi.Input

	ToAutoscalingPolicySecondaryWorkerConfigOutput() AutoscalingPolicySecondaryWorkerConfigOutput
	ToAutoscalingPolicySecondaryWorkerConfigOutputWithContext(context.Context) AutoscalingPolicySecondaryWorkerConfigOutput
}

type AutoscalingPolicySecondaryWorkerConfigArgs struct {
	// Maximum number of instances for this group. Note that by default, clusters will not use
	// secondary workers. Required for secondary workers if the minimum secondary instances is set.
	// Bounds: [minInstances, ). Defaults to 0.
	MaxInstances pulumi.IntPtrInput `pulumi:"maxInstances"`
	// Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
	MinInstances pulumi.IntPtrInput `pulumi:"minInstances"`
	// Weight for the instance group, which is used to determine the fraction of total workers
	// in the cluster from this instance group. For example, if primary workers have weight 2,
	// and secondary workers have weight 1, the cluster will have approximately 2 primary workers
	// for each secondary worker.
	// The cluster may not reach the specified balance if constrained by min/max bounds or other
	// autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
	// primary workers will be added. The cluster can also be out of balance when created.
	// If weight is not set on any instance group, the cluster will default to equal weight for
	// all groups: the cluster will attempt to maintain an equal number of workers in each group
	// within the configured size bounds for each group. If weight is set for one group only,
	// the cluster will default to zero weight on the unset group. For example if weight is set
	// only on primary workers, the cluster will use primary workers only and no secondary workers.
	Weight pulumi.IntPtrInput `pulumi:"weight"`
}

func (AutoscalingPolicySecondaryWorkerConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AutoscalingPolicySecondaryWorkerConfig)(nil)).Elem()
}

func (i AutoscalingPolicySecondaryWorkerConfigArgs) ToAutoscalingPolicySecondaryWorkerConfigOutput() AutoscalingPolicySecondaryWorkerConfigOutput {
	return i.ToAutoscalingPolicySecondaryWorkerConfigOutputWithContext(context.Background())
}

func (i AutoscalingPolicySecondaryWorkerConfigArgs) ToAutoscalingPolicySecondaryWorkerConfigOutputWithContext(ctx context.Context) AutoscalingPolicySecondaryWorkerConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingPolicySecondaryWorkerConfigOutput)
}

func (i AutoscalingPolicySecondaryWorkerConfigArgs) ToAutoscalingPolicySecondaryWorkerConfigPtrOutput() AutoscalingPolicySecondaryWorkerConfigPtrOutput {
	return i.ToAutoscalingPolicySecondaryWorkerConfigPtrOutputWithContext(context.Background())
}

func (i AutoscalingPolicySecondaryWorkerConfigArgs) ToAutoscalingPolicySecondaryWorkerConfigPtrOutputWithContext(ctx context.Context) AutoscalingPolicySecondaryWorkerConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingPolicySecondaryWorkerConfigOutput).ToAutoscalingPolicySecondaryWorkerConfigPtrOutputWithContext(ctx)
}

// AutoscalingPolicySecondaryWorkerConfigPtrInput is an input type that accepts AutoscalingPolicySecondaryWorkerConfigArgs, AutoscalingPolicySecondaryWorkerConfigPtr and AutoscalingPolicySecondaryWorkerConfigPtrOutput values.
// You can construct a concrete instance of `AutoscalingPolicySecondaryWorkerConfigPtrInput` via:
//
// 		 AutoscalingPolicySecondaryWorkerConfigArgs{...}
//
//  or:
//
// 		 nil
//
type AutoscalingPolicySecondaryWorkerConfigPtrInput interface {
	pulumi.Input

	ToAutoscalingPolicySecondaryWorkerConfigPtrOutput() AutoscalingPolicySecondaryWorkerConfigPtrOutput
	ToAutoscalingPolicySecondaryWorkerConfigPtrOutputWithContext(context.Context) AutoscalingPolicySecondaryWorkerConfigPtrOutput
}

type autoscalingPolicySecondaryWorkerConfigPtrType AutoscalingPolicySecondaryWorkerConfigArgs

func AutoscalingPolicySecondaryWorkerConfigPtr(v *AutoscalingPolicySecondaryWorkerConfigArgs) AutoscalingPolicySecondaryWorkerConfigPtrInput {
	return (*autoscalingPolicySecondaryWorkerConfigPtrType)(v)
}

func (*autoscalingPolicySecondaryWorkerConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AutoscalingPolicySecondaryWorkerConfig)(nil)).Elem()
}

func (i *autoscalingPolicySecondaryWorkerConfigPtrType) ToAutoscalingPolicySecondaryWorkerConfigPtrOutput() AutoscalingPolicySecondaryWorkerConfigPtrOutput {
	return i.ToAutoscalingPolicySecondaryWorkerConfigPtrOutputWithContext(context.Background())
}

func (i *autoscalingPolicySecondaryWorkerConfigPtrType) ToAutoscalingPolicySecondaryWorkerConfigPtrOutputWithContext(ctx context.Context) AutoscalingPolicySecondaryWorkerConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingPolicySecondaryWorkerConfigPtrOutput)
}

type AutoscalingPolicySecondaryWorkerConfigOutput struct{ *pulumi.OutputState }

func (AutoscalingPolicySecondaryWorkerConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AutoscalingPolicySecondaryWorkerConfig)(nil)).Elem()
}

func (o AutoscalingPolicySecondaryWorkerConfigOutput) ToAutoscalingPolicySecondaryWorkerConfigOutput() AutoscalingPolicySecondaryWorkerConfigOutput {
	return o
}

func (o AutoscalingPolicySecondaryWorkerConfigOutput) ToAutoscalingPolicySecondaryWorkerConfigOutputWithContext(ctx context.Context) AutoscalingPolicySecondaryWorkerConfigOutput {
	return o
}

func (o AutoscalingPolicySecondaryWorkerConfigOutput) ToAutoscalingPolicySecondaryWorkerConfigPtrOutput() AutoscalingPolicySecondaryWorkerConfigPtrOutput {
	return o.ToAutoscalingPolicySecondaryWorkerConfigPtrOutputWithContext(context.Background())
}

func (o AutoscalingPolicySecondaryWorkerConfigOutput) ToAutoscalingPolicySecondaryWorkerConfigPtrOutputWithContext(ctx context.Context) AutoscalingPolicySecondaryWorkerConfigPtrOutput {
	return o.ApplyT(func(v AutoscalingPolicySecondaryWorkerConfig) *AutoscalingPolicySecondaryWorkerConfig {
		return &v
	}).(AutoscalingPolicySecondaryWorkerConfigPtrOutput)
}

// Maximum number of instances for this group. Note that by default, clusters will not use
// secondary workers. Required for secondary workers if the minimum secondary instances is set.
// Bounds: [minInstances, ). Defaults to 0.
func (o AutoscalingPolicySecondaryWorkerConfigOutput) MaxInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AutoscalingPolicySecondaryWorkerConfig) *int { return v.MaxInstances }).(pulumi.IntPtrOutput)
}

// Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
func (o AutoscalingPolicySecondaryWorkerConfigOutput) MinInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AutoscalingPolicySecondaryWorkerConfig) *int { return v.MinInstances }).(pulumi.IntPtrOutput)
}

// Weight for the instance group, which is used to determine the fraction of total workers
// in the cluster from this instance group. For example, if primary workers have weight 2,
// and secondary workers have weight 1, the cluster will have approximately 2 primary workers
// for each secondary worker.
// The cluster may not reach the specified balance if constrained by min/max bounds or other
// autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
// primary workers will be added. The cluster can also be out of balance when created.
// If weight is not set on any instance group, the cluster will default to equal weight for
// all groups: the cluster will attempt to maintain an equal number of workers in each group
// within the configured size bounds for each group. If weight is set for one group only,
// the cluster will default to zero weight on the unset group. For example if weight is set
// only on primary workers, the cluster will use primary workers only and no secondary workers.
func (o AutoscalingPolicySecondaryWorkerConfigOutput) Weight() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AutoscalingPolicySecondaryWorkerConfig) *int { return v.Weight }).(pulumi.IntPtrOutput)
}

type AutoscalingPolicySecondaryWorkerConfigPtrOutput struct{ *pulumi.OutputState }

func (AutoscalingPolicySecondaryWorkerConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AutoscalingPolicySecondaryWorkerConfig)(nil)).Elem()
}

func (o AutoscalingPolicySecondaryWorkerConfigPtrOutput) ToAutoscalingPolicySecondaryWorkerConfigPtrOutput() AutoscalingPolicySecondaryWorkerConfigPtrOutput {
	return o
}

func (o AutoscalingPolicySecondaryWorkerConfigPtrOutput) ToAutoscalingPolicySecondaryWorkerConfigPtrOutputWithContext(ctx context.Context) AutoscalingPolicySecondaryWorkerConfigPtrOutput {
	return o
}

func (o AutoscalingPolicySecondaryWorkerConfigPtrOutput) Elem() AutoscalingPolicySecondaryWorkerConfigOutput {
	return o.ApplyT(func(v *AutoscalingPolicySecondaryWorkerConfig) AutoscalingPolicySecondaryWorkerConfig { return *v }).(AutoscalingPolicySecondaryWorkerConfigOutput)
}

// Maximum number of instances for this group. Note that by default, clusters will not use
// secondary workers. Required for secondary workers if the minimum secondary instances is set.
// Bounds: [minInstances, ). Defaults to 0.
func (o AutoscalingPolicySecondaryWorkerConfigPtrOutput) MaxInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicySecondaryWorkerConfig) *int {
		if v == nil {
			return nil
		}
		return v.MaxInstances
	}).(pulumi.IntPtrOutput)
}

// Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
func (o AutoscalingPolicySecondaryWorkerConfigPtrOutput) MinInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicySecondaryWorkerConfig) *int {
		if v == nil {
			return nil
		}
		return v.MinInstances
	}).(pulumi.IntPtrOutput)
}

// Weight for the instance group, which is used to determine the fraction of total workers
// in the cluster from this instance group. For example, if primary workers have weight 2,
// and secondary workers have weight 1, the cluster will have approximately 2 primary workers
// for each secondary worker.
// The cluster may not reach the specified balance if constrained by min/max bounds or other
// autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
// primary workers will be added. The cluster can also be out of balance when created.
// If weight is not set on any instance group, the cluster will default to equal weight for
// all groups: the cluster will attempt to maintain an equal number of workers in each group
// within the configured size bounds for each group. If weight is set for one group only,
// the cluster will default to zero weight on the unset group. For example if weight is set
// only on primary workers, the cluster will use primary workers only and no secondary workers.
func (o AutoscalingPolicySecondaryWorkerConfigPtrOutput) Weight() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicySecondaryWorkerConfig) *int {
		if v == nil {
			return nil
		}
		return v.Weight
	}).(pulumi.IntPtrOutput)
}

type AutoscalingPolicyWorkerConfig struct {
	// Maximum number of instances for this group. Note that by default, clusters will not use
	// secondary workers. Required for secondary workers if the minimum secondary instances is set.
	// Bounds: [minInstances, ). Defaults to 0.
	MaxInstances int `pulumi:"maxInstances"`
	// Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
	MinInstances *int `pulumi:"minInstances"`
	// Weight for the instance group, which is used to determine the fraction of total workers
	// in the cluster from this instance group. For example, if primary workers have weight 2,
	// and secondary workers have weight 1, the cluster will have approximately 2 primary workers
	// for each secondary worker.
	// The cluster may not reach the specified balance if constrained by min/max bounds or other
	// autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
	// primary workers will be added. The cluster can also be out of balance when created.
	// If weight is not set on any instance group, the cluster will default to equal weight for
	// all groups: the cluster will attempt to maintain an equal number of workers in each group
	// within the configured size bounds for each group. If weight is set for one group only,
	// the cluster will default to zero weight on the unset group. For example if weight is set
	// only on primary workers, the cluster will use primary workers only and no secondary workers.
	Weight *int `pulumi:"weight"`
}

// AutoscalingPolicyWorkerConfigInput is an input type that accepts AutoscalingPolicyWorkerConfigArgs and AutoscalingPolicyWorkerConfigOutput values.
// You can construct a concrete instance of `AutoscalingPolicyWorkerConfigInput` via:
//
// 		 AutoscalingPolicyWorkerConfigArgs{...}
//
type AutoscalingPolicyWorkerConfigInput interface {
	pulumi.Input

	ToAutoscalingPolicyWorkerConfigOutput() AutoscalingPolicyWorkerConfigOutput
	ToAutoscalingPolicyWorkerConfigOutputWithContext(context.Context) AutoscalingPolicyWorkerConfigOutput
}

type AutoscalingPolicyWorkerConfigArgs struct {
	// Maximum number of instances for this group. Note that by default, clusters will not use
	// secondary workers. Required for secondary workers if the minimum secondary instances is set.
	// Bounds: [minInstances, ). Defaults to 0.
	MaxInstances pulumi.IntInput `pulumi:"maxInstances"`
	// Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
	MinInstances pulumi.IntPtrInput `pulumi:"minInstances"`
	// Weight for the instance group, which is used to determine the fraction of total workers
	// in the cluster from this instance group. For example, if primary workers have weight 2,
	// and secondary workers have weight 1, the cluster will have approximately 2 primary workers
	// for each secondary worker.
	// The cluster may not reach the specified balance if constrained by min/max bounds or other
	// autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
	// primary workers will be added. The cluster can also be out of balance when created.
	// If weight is not set on any instance group, the cluster will default to equal weight for
	// all groups: the cluster will attempt to maintain an equal number of workers in each group
	// within the configured size bounds for each group. If weight is set for one group only,
	// the cluster will default to zero weight on the unset group. For example if weight is set
	// only on primary workers, the cluster will use primary workers only and no secondary workers.
	Weight pulumi.IntPtrInput `pulumi:"weight"`
}

func (AutoscalingPolicyWorkerConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AutoscalingPolicyWorkerConfig)(nil)).Elem()
}

func (i AutoscalingPolicyWorkerConfigArgs) ToAutoscalingPolicyWorkerConfigOutput() AutoscalingPolicyWorkerConfigOutput {
	return i.ToAutoscalingPolicyWorkerConfigOutputWithContext(context.Background())
}

func (i AutoscalingPolicyWorkerConfigArgs) ToAutoscalingPolicyWorkerConfigOutputWithContext(ctx context.Context) AutoscalingPolicyWorkerConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingPolicyWorkerConfigOutput)
}

func (i AutoscalingPolicyWorkerConfigArgs) ToAutoscalingPolicyWorkerConfigPtrOutput() AutoscalingPolicyWorkerConfigPtrOutput {
	return i.ToAutoscalingPolicyWorkerConfigPtrOutputWithContext(context.Background())
}

func (i AutoscalingPolicyWorkerConfigArgs) ToAutoscalingPolicyWorkerConfigPtrOutputWithContext(ctx context.Context) AutoscalingPolicyWorkerConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingPolicyWorkerConfigOutput).ToAutoscalingPolicyWorkerConfigPtrOutputWithContext(ctx)
}

// AutoscalingPolicyWorkerConfigPtrInput is an input type that accepts AutoscalingPolicyWorkerConfigArgs, AutoscalingPolicyWorkerConfigPtr and AutoscalingPolicyWorkerConfigPtrOutput values.
// You can construct a concrete instance of `AutoscalingPolicyWorkerConfigPtrInput` via:
//
// 		 AutoscalingPolicyWorkerConfigArgs{...}
//
//  or:
//
// 		 nil
//
type AutoscalingPolicyWorkerConfigPtrInput interface {
	pulumi.Input

	ToAutoscalingPolicyWorkerConfigPtrOutput() AutoscalingPolicyWorkerConfigPtrOutput
	ToAutoscalingPolicyWorkerConfigPtrOutputWithContext(context.Context) AutoscalingPolicyWorkerConfigPtrOutput
}

type autoscalingPolicyWorkerConfigPtrType AutoscalingPolicyWorkerConfigArgs

func AutoscalingPolicyWorkerConfigPtr(v *AutoscalingPolicyWorkerConfigArgs) AutoscalingPolicyWorkerConfigPtrInput {
	return (*autoscalingPolicyWorkerConfigPtrType)(v)
}

func (*autoscalingPolicyWorkerConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AutoscalingPolicyWorkerConfig)(nil)).Elem()
}

func (i *autoscalingPolicyWorkerConfigPtrType) ToAutoscalingPolicyWorkerConfigPtrOutput() AutoscalingPolicyWorkerConfigPtrOutput {
	return i.ToAutoscalingPolicyWorkerConfigPtrOutputWithContext(context.Background())
}

func (i *autoscalingPolicyWorkerConfigPtrType) ToAutoscalingPolicyWorkerConfigPtrOutputWithContext(ctx context.Context) AutoscalingPolicyWorkerConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingPolicyWorkerConfigPtrOutput)
}

type AutoscalingPolicyWorkerConfigOutput struct{ *pulumi.OutputState }

func (AutoscalingPolicyWorkerConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AutoscalingPolicyWorkerConfig)(nil)).Elem()
}

func (o AutoscalingPolicyWorkerConfigOutput) ToAutoscalingPolicyWorkerConfigOutput() AutoscalingPolicyWorkerConfigOutput {
	return o
}

func (o AutoscalingPolicyWorkerConfigOutput) ToAutoscalingPolicyWorkerConfigOutputWithContext(ctx context.Context) AutoscalingPolicyWorkerConfigOutput {
	return o
}

func (o AutoscalingPolicyWorkerConfigOutput) ToAutoscalingPolicyWorkerConfigPtrOutput() AutoscalingPolicyWorkerConfigPtrOutput {
	return o.ToAutoscalingPolicyWorkerConfigPtrOutputWithContext(context.Background())
}

func (o AutoscalingPolicyWorkerConfigOutput) ToAutoscalingPolicyWorkerConfigPtrOutputWithContext(ctx context.Context) AutoscalingPolicyWorkerConfigPtrOutput {
	return o.ApplyT(func(v AutoscalingPolicyWorkerConfig) *AutoscalingPolicyWorkerConfig {
		return &v
	}).(AutoscalingPolicyWorkerConfigPtrOutput)
}

// Maximum number of instances for this group. Note that by default, clusters will not use
// secondary workers. Required for secondary workers if the minimum secondary instances is set.
// Bounds: [minInstances, ). Defaults to 0.
func (o AutoscalingPolicyWorkerConfigOutput) MaxInstances() pulumi.IntOutput {
	return o.ApplyT(func(v AutoscalingPolicyWorkerConfig) int { return v.MaxInstances }).(pulumi.IntOutput)
}

// Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
func (o AutoscalingPolicyWorkerConfigOutput) MinInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AutoscalingPolicyWorkerConfig) *int { return v.MinInstances }).(pulumi.IntPtrOutput)
}

// Weight for the instance group, which is used to determine the fraction of total workers
// in the cluster from this instance group. For example, if primary workers have weight 2,
// and secondary workers have weight 1, the cluster will have approximately 2 primary workers
// for each secondary worker.
// The cluster may not reach the specified balance if constrained by min/max bounds or other
// autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
// primary workers will be added. The cluster can also be out of balance when created.
// If weight is not set on any instance group, the cluster will default to equal weight for
// all groups: the cluster will attempt to maintain an equal number of workers in each group
// within the configured size bounds for each group. If weight is set for one group only,
// the cluster will default to zero weight on the unset group. For example if weight is set
// only on primary workers, the cluster will use primary workers only and no secondary workers.
func (o AutoscalingPolicyWorkerConfigOutput) Weight() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AutoscalingPolicyWorkerConfig) *int { return v.Weight }).(pulumi.IntPtrOutput)
}

type AutoscalingPolicyWorkerConfigPtrOutput struct{ *pulumi.OutputState }

func (AutoscalingPolicyWorkerConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AutoscalingPolicyWorkerConfig)(nil)).Elem()
}

func (o AutoscalingPolicyWorkerConfigPtrOutput) ToAutoscalingPolicyWorkerConfigPtrOutput() AutoscalingPolicyWorkerConfigPtrOutput {
	return o
}

func (o AutoscalingPolicyWorkerConfigPtrOutput) ToAutoscalingPolicyWorkerConfigPtrOutputWithContext(ctx context.Context) AutoscalingPolicyWorkerConfigPtrOutput {
	return o
}

func (o AutoscalingPolicyWorkerConfigPtrOutput) Elem() AutoscalingPolicyWorkerConfigOutput {
	return o.ApplyT(func(v *AutoscalingPolicyWorkerConfig) AutoscalingPolicyWorkerConfig { return *v }).(AutoscalingPolicyWorkerConfigOutput)
}

// Maximum number of instances for this group. Note that by default, clusters will not use
// secondary workers. Required for secondary workers if the minimum secondary instances is set.
// Bounds: [minInstances, ). Defaults to 0.
func (o AutoscalingPolicyWorkerConfigPtrOutput) MaxInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicyWorkerConfig) *int {
		if v == nil {
			return nil
		}
		return &v.MaxInstances
	}).(pulumi.IntPtrOutput)
}

// Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
func (o AutoscalingPolicyWorkerConfigPtrOutput) MinInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicyWorkerConfig) *int {
		if v == nil {
			return nil
		}
		return v.MinInstances
	}).(pulumi.IntPtrOutput)
}

// Weight for the instance group, which is used to determine the fraction of total workers
// in the cluster from this instance group. For example, if primary workers have weight 2,
// and secondary workers have weight 1, the cluster will have approximately 2 primary workers
// for each secondary worker.
// The cluster may not reach the specified balance if constrained by min/max bounds or other
// autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
// primary workers will be added. The cluster can also be out of balance when created.
// If weight is not set on any instance group, the cluster will default to equal weight for
// all groups: the cluster will attempt to maintain an equal number of workers in each group
// within the configured size bounds for each group. If weight is set for one group only,
// the cluster will default to zero weight on the unset group. For example if weight is set
// only on primary workers, the cluster will use primary workers only and no secondary workers.
func (o AutoscalingPolicyWorkerConfigPtrOutput) Weight() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AutoscalingPolicyWorkerConfig) *int {
		if v == nil {
			return nil
		}
		return v.Weight
	}).(pulumi.IntPtrOutput)
}

type ClusterClusterConfig struct {
	// The autoscaling policy config associated with the cluster.
	// Structure defined below.
	AutoscalingConfig *ClusterClusterConfigAutoscalingConfig `pulumi:"autoscalingConfig"`
	Bucket            *string                                `pulumi:"bucket"`
	// The Customer managed encryption keys settings for the cluster.
	// Structure defined below.
	EncryptionConfig *ClusterClusterConfigEncryptionConfig `pulumi:"encryptionConfig"`
	// Common config settings for resources of Google Compute Engine cluster
	// instances, applicable to all instances in the cluster. Structure defined below.
	GceClusterConfig *ClusterClusterConfigGceClusterConfig `pulumi:"gceClusterConfig"`
	// Commands to execute on each node after config is completed.
	// You can specify multiple versions of these. Structure defined below.
	InitializationActions []ClusterClusterConfigInitializationAction `pulumi:"initializationActions"`
	// The settings for auto deletion cluster schedule.
	// Structure defined below.
	LifecycleConfig *ClusterClusterConfigLifecycleConfig `pulumi:"lifecycleConfig"`
	// The Google Compute Engine config settings for the master instances
	// in a cluster.. Structure defined below.
	MasterConfig *ClusterClusterConfigMasterConfig `pulumi:"masterConfig"`
	// The Google Compute Engine config settings for the additional (aka
	// preemptible) instances in a cluster. Structure defined below.
	PreemptibleWorkerConfig *ClusterClusterConfigPreemptibleWorkerConfig `pulumi:"preemptibleWorkerConfig"`
	// Security related configuration. Structure defined below.
	SecurityConfig *ClusterClusterConfigSecurityConfig `pulumi:"securityConfig"`
	// The config settings for software inside the cluster.
	// Structure defined below.
	SoftwareConfig *ClusterClusterConfigSoftwareConfig `pulumi:"softwareConfig"`
	// The Cloud Storage staging bucket used to stage files,
	// such as Hadoop jars, between client machines and the cluster.
	// Note: If you don't explicitly specify a `stagingBucket`
	// then GCP will auto create / assign one for you. However, you are not guaranteed
	// an auto generated bucket which is solely dedicated to your cluster; it may be shared
	// with other clusters in the same region/zone also choosing to use the auto generation
	// option.
	StagingBucket *string `pulumi:"stagingBucket"`
	// The Google Compute Engine config settings for the worker instances
	// in a cluster.. Structure defined below.
	WorkerConfig *ClusterClusterConfigWorkerConfig `pulumi:"workerConfig"`
}

// ClusterClusterConfigInput is an input type that accepts ClusterClusterConfigArgs and ClusterClusterConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigInput` via:
//
// 		 ClusterClusterConfigArgs{...}
//
type ClusterClusterConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigOutput() ClusterClusterConfigOutput
	ToClusterClusterConfigOutputWithContext(context.Context) ClusterClusterConfigOutput
}

type ClusterClusterConfigArgs struct {
	// The autoscaling policy config associated with the cluster.
	// Structure defined below.
	AutoscalingConfig ClusterClusterConfigAutoscalingConfigPtrInput `pulumi:"autoscalingConfig"`
	Bucket            pulumi.StringPtrInput                         `pulumi:"bucket"`
	// The Customer managed encryption keys settings for the cluster.
	// Structure defined below.
	EncryptionConfig ClusterClusterConfigEncryptionConfigPtrInput `pulumi:"encryptionConfig"`
	// Common config settings for resources of Google Compute Engine cluster
	// instances, applicable to all instances in the cluster. Structure defined below.
	GceClusterConfig ClusterClusterConfigGceClusterConfigPtrInput `pulumi:"gceClusterConfig"`
	// Commands to execute on each node after config is completed.
	// You can specify multiple versions of these. Structure defined below.
	InitializationActions ClusterClusterConfigInitializationActionArrayInput `pulumi:"initializationActions"`
	// The settings for auto deletion cluster schedule.
	// Structure defined below.
	LifecycleConfig ClusterClusterConfigLifecycleConfigPtrInput `pulumi:"lifecycleConfig"`
	// The Google Compute Engine config settings for the master instances
	// in a cluster.. Structure defined below.
	MasterConfig ClusterClusterConfigMasterConfigPtrInput `pulumi:"masterConfig"`
	// The Google Compute Engine config settings for the additional (aka
	// preemptible) instances in a cluster. Structure defined below.
	PreemptibleWorkerConfig ClusterClusterConfigPreemptibleWorkerConfigPtrInput `pulumi:"preemptibleWorkerConfig"`
	// Security related configuration. Structure defined below.
	SecurityConfig ClusterClusterConfigSecurityConfigPtrInput `pulumi:"securityConfig"`
	// The config settings for software inside the cluster.
	// Structure defined below.
	SoftwareConfig ClusterClusterConfigSoftwareConfigPtrInput `pulumi:"softwareConfig"`
	// The Cloud Storage staging bucket used to stage files,
	// such as Hadoop jars, between client machines and the cluster.
	// Note: If you don't explicitly specify a `stagingBucket`
	// then GCP will auto create / assign one for you. However, you are not guaranteed
	// an auto generated bucket which is solely dedicated to your cluster; it may be shared
	// with other clusters in the same region/zone also choosing to use the auto generation
	// option.
	StagingBucket pulumi.StringPtrInput `pulumi:"stagingBucket"`
	// The Google Compute Engine config settings for the worker instances
	// in a cluster.. Structure defined below.
	WorkerConfig ClusterClusterConfigWorkerConfigPtrInput `pulumi:"workerConfig"`
}

func (ClusterClusterConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfig)(nil)).Elem()
}

func (i ClusterClusterConfigArgs) ToClusterClusterConfigOutput() ClusterClusterConfigOutput {
	return i.ToClusterClusterConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigArgs) ToClusterClusterConfigOutputWithContext(ctx context.Context) ClusterClusterConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigOutput)
}

func (i ClusterClusterConfigArgs) ToClusterClusterConfigPtrOutput() ClusterClusterConfigPtrOutput {
	return i.ToClusterClusterConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigArgs) ToClusterClusterConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigOutput).ToClusterClusterConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigPtrInput is an input type that accepts ClusterClusterConfigArgs, ClusterClusterConfigPtr and ClusterClusterConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigPtrInput` via:
//
// 		 ClusterClusterConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigPtrOutput() ClusterClusterConfigPtrOutput
	ToClusterClusterConfigPtrOutputWithContext(context.Context) ClusterClusterConfigPtrOutput
}

type clusterClusterConfigPtrType ClusterClusterConfigArgs

func ClusterClusterConfigPtr(v *ClusterClusterConfigArgs) ClusterClusterConfigPtrInput {
	return (*clusterClusterConfigPtrType)(v)
}

func (*clusterClusterConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfig)(nil)).Elem()
}

func (i *clusterClusterConfigPtrType) ToClusterClusterConfigPtrOutput() ClusterClusterConfigPtrOutput {
	return i.ToClusterClusterConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigPtrType) ToClusterClusterConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigPtrOutput)
}

type ClusterClusterConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfig)(nil)).Elem()
}

func (o ClusterClusterConfigOutput) ToClusterClusterConfigOutput() ClusterClusterConfigOutput {
	return o
}

func (o ClusterClusterConfigOutput) ToClusterClusterConfigOutputWithContext(ctx context.Context) ClusterClusterConfigOutput {
	return o
}

func (o ClusterClusterConfigOutput) ToClusterClusterConfigPtrOutput() ClusterClusterConfigPtrOutput {
	return o.ToClusterClusterConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigOutput) ToClusterClusterConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfig) *ClusterClusterConfig {
		return &v
	}).(ClusterClusterConfigPtrOutput)
}

// The autoscaling policy config associated with the cluster.
// Structure defined below.
func (o ClusterClusterConfigOutput) AutoscalingConfig() ClusterClusterConfigAutoscalingConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfig) *ClusterClusterConfigAutoscalingConfig { return v.AutoscalingConfig }).(ClusterClusterConfigAutoscalingConfigPtrOutput)
}

func (o ClusterClusterConfigOutput) Bucket() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfig) *string { return v.Bucket }).(pulumi.StringPtrOutput)
}

// The Customer managed encryption keys settings for the cluster.
// Structure defined below.
func (o ClusterClusterConfigOutput) EncryptionConfig() ClusterClusterConfigEncryptionConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfig) *ClusterClusterConfigEncryptionConfig { return v.EncryptionConfig }).(ClusterClusterConfigEncryptionConfigPtrOutput)
}

// Common config settings for resources of Google Compute Engine cluster
// instances, applicable to all instances in the cluster. Structure defined below.
func (o ClusterClusterConfigOutput) GceClusterConfig() ClusterClusterConfigGceClusterConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfig) *ClusterClusterConfigGceClusterConfig { return v.GceClusterConfig }).(ClusterClusterConfigGceClusterConfigPtrOutput)
}

// Commands to execute on each node after config is completed.
// You can specify multiple versions of these. Structure defined below.
func (o ClusterClusterConfigOutput) InitializationActions() ClusterClusterConfigInitializationActionArrayOutput {
	return o.ApplyT(func(v ClusterClusterConfig) []ClusterClusterConfigInitializationAction {
		return v.InitializationActions
	}).(ClusterClusterConfigInitializationActionArrayOutput)
}

// The settings for auto deletion cluster schedule.
// Structure defined below.
func (o ClusterClusterConfigOutput) LifecycleConfig() ClusterClusterConfigLifecycleConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfig) *ClusterClusterConfigLifecycleConfig { return v.LifecycleConfig }).(ClusterClusterConfigLifecycleConfigPtrOutput)
}

// The Google Compute Engine config settings for the master instances
// in a cluster.. Structure defined below.
func (o ClusterClusterConfigOutput) MasterConfig() ClusterClusterConfigMasterConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfig) *ClusterClusterConfigMasterConfig { return v.MasterConfig }).(ClusterClusterConfigMasterConfigPtrOutput)
}

// The Google Compute Engine config settings for the additional (aka
// preemptible) instances in a cluster. Structure defined below.
func (o ClusterClusterConfigOutput) PreemptibleWorkerConfig() ClusterClusterConfigPreemptibleWorkerConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfig) *ClusterClusterConfigPreemptibleWorkerConfig {
		return v.PreemptibleWorkerConfig
	}).(ClusterClusterConfigPreemptibleWorkerConfigPtrOutput)
}

// Security related configuration. Structure defined below.
func (o ClusterClusterConfigOutput) SecurityConfig() ClusterClusterConfigSecurityConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfig) *ClusterClusterConfigSecurityConfig { return v.SecurityConfig }).(ClusterClusterConfigSecurityConfigPtrOutput)
}

// The config settings for software inside the cluster.
// Structure defined below.
func (o ClusterClusterConfigOutput) SoftwareConfig() ClusterClusterConfigSoftwareConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfig) *ClusterClusterConfigSoftwareConfig { return v.SoftwareConfig }).(ClusterClusterConfigSoftwareConfigPtrOutput)
}

// The Cloud Storage staging bucket used to stage files,
// such as Hadoop jars, between client machines and the cluster.
// Note: If you don't explicitly specify a `stagingBucket`
// then GCP will auto create / assign one for you. However, you are not guaranteed
// an auto generated bucket which is solely dedicated to your cluster; it may be shared
// with other clusters in the same region/zone also choosing to use the auto generation
// option.
func (o ClusterClusterConfigOutput) StagingBucket() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfig) *string { return v.StagingBucket }).(pulumi.StringPtrOutput)
}

// The Google Compute Engine config settings for the worker instances
// in a cluster.. Structure defined below.
func (o ClusterClusterConfigOutput) WorkerConfig() ClusterClusterConfigWorkerConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfig) *ClusterClusterConfigWorkerConfig { return v.WorkerConfig }).(ClusterClusterConfigWorkerConfigPtrOutput)
}

type ClusterClusterConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfig)(nil)).Elem()
}

func (o ClusterClusterConfigPtrOutput) ToClusterClusterConfigPtrOutput() ClusterClusterConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigPtrOutput) ToClusterClusterConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigPtrOutput) Elem() ClusterClusterConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) ClusterClusterConfig { return *v }).(ClusterClusterConfigOutput)
}

// The autoscaling policy config associated with the cluster.
// Structure defined below.
func (o ClusterClusterConfigPtrOutput) AutoscalingConfig() ClusterClusterConfigAutoscalingConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) *ClusterClusterConfigAutoscalingConfig {
		if v == nil {
			return nil
		}
		return v.AutoscalingConfig
	}).(ClusterClusterConfigAutoscalingConfigPtrOutput)
}

func (o ClusterClusterConfigPtrOutput) Bucket() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.Bucket
	}).(pulumi.StringPtrOutput)
}

// The Customer managed encryption keys settings for the cluster.
// Structure defined below.
func (o ClusterClusterConfigPtrOutput) EncryptionConfig() ClusterClusterConfigEncryptionConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) *ClusterClusterConfigEncryptionConfig {
		if v == nil {
			return nil
		}
		return v.EncryptionConfig
	}).(ClusterClusterConfigEncryptionConfigPtrOutput)
}

// Common config settings for resources of Google Compute Engine cluster
// instances, applicable to all instances in the cluster. Structure defined below.
func (o ClusterClusterConfigPtrOutput) GceClusterConfig() ClusterClusterConfigGceClusterConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) *ClusterClusterConfigGceClusterConfig {
		if v == nil {
			return nil
		}
		return v.GceClusterConfig
	}).(ClusterClusterConfigGceClusterConfigPtrOutput)
}

// Commands to execute on each node after config is completed.
// You can specify multiple versions of these. Structure defined below.
func (o ClusterClusterConfigPtrOutput) InitializationActions() ClusterClusterConfigInitializationActionArrayOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) []ClusterClusterConfigInitializationAction {
		if v == nil {
			return nil
		}
		return v.InitializationActions
	}).(ClusterClusterConfigInitializationActionArrayOutput)
}

// The settings for auto deletion cluster schedule.
// Structure defined below.
func (o ClusterClusterConfigPtrOutput) LifecycleConfig() ClusterClusterConfigLifecycleConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) *ClusterClusterConfigLifecycleConfig {
		if v == nil {
			return nil
		}
		return v.LifecycleConfig
	}).(ClusterClusterConfigLifecycleConfigPtrOutput)
}

// The Google Compute Engine config settings for the master instances
// in a cluster.. Structure defined below.
func (o ClusterClusterConfigPtrOutput) MasterConfig() ClusterClusterConfigMasterConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) *ClusterClusterConfigMasterConfig {
		if v == nil {
			return nil
		}
		return v.MasterConfig
	}).(ClusterClusterConfigMasterConfigPtrOutput)
}

// The Google Compute Engine config settings for the additional (aka
// preemptible) instances in a cluster. Structure defined below.
func (o ClusterClusterConfigPtrOutput) PreemptibleWorkerConfig() ClusterClusterConfigPreemptibleWorkerConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) *ClusterClusterConfigPreemptibleWorkerConfig {
		if v == nil {
			return nil
		}
		return v.PreemptibleWorkerConfig
	}).(ClusterClusterConfigPreemptibleWorkerConfigPtrOutput)
}

// Security related configuration. Structure defined below.
func (o ClusterClusterConfigPtrOutput) SecurityConfig() ClusterClusterConfigSecurityConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) *ClusterClusterConfigSecurityConfig {
		if v == nil {
			return nil
		}
		return v.SecurityConfig
	}).(ClusterClusterConfigSecurityConfigPtrOutput)
}

// The config settings for software inside the cluster.
// Structure defined below.
func (o ClusterClusterConfigPtrOutput) SoftwareConfig() ClusterClusterConfigSoftwareConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) *ClusterClusterConfigSoftwareConfig {
		if v == nil {
			return nil
		}
		return v.SoftwareConfig
	}).(ClusterClusterConfigSoftwareConfigPtrOutput)
}

// The Cloud Storage staging bucket used to stage files,
// such as Hadoop jars, between client machines and the cluster.
// Note: If you don't explicitly specify a `stagingBucket`
// then GCP will auto create / assign one for you. However, you are not guaranteed
// an auto generated bucket which is solely dedicated to your cluster; it may be shared
// with other clusters in the same region/zone also choosing to use the auto generation
// option.
func (o ClusterClusterConfigPtrOutput) StagingBucket() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.StagingBucket
	}).(pulumi.StringPtrOutput)
}

// The Google Compute Engine config settings for the worker instances
// in a cluster.. Structure defined below.
func (o ClusterClusterConfigPtrOutput) WorkerConfig() ClusterClusterConfigWorkerConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfig) *ClusterClusterConfigWorkerConfig {
		if v == nil {
			return nil
		}
		return v.WorkerConfig
	}).(ClusterClusterConfigWorkerConfigPtrOutput)
}

type ClusterClusterConfigAutoscalingConfig struct {
	// The autoscaling policy used by the cluster.
	PolicyUri string `pulumi:"policyUri"`
}

// ClusterClusterConfigAutoscalingConfigInput is an input type that accepts ClusterClusterConfigAutoscalingConfigArgs and ClusterClusterConfigAutoscalingConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigAutoscalingConfigInput` via:
//
// 		 ClusterClusterConfigAutoscalingConfigArgs{...}
//
type ClusterClusterConfigAutoscalingConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigAutoscalingConfigOutput() ClusterClusterConfigAutoscalingConfigOutput
	ToClusterClusterConfigAutoscalingConfigOutputWithContext(context.Context) ClusterClusterConfigAutoscalingConfigOutput
}

type ClusterClusterConfigAutoscalingConfigArgs struct {
	// The autoscaling policy used by the cluster.
	PolicyUri pulumi.StringInput `pulumi:"policyUri"`
}

func (ClusterClusterConfigAutoscalingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigAutoscalingConfig)(nil)).Elem()
}

func (i ClusterClusterConfigAutoscalingConfigArgs) ToClusterClusterConfigAutoscalingConfigOutput() ClusterClusterConfigAutoscalingConfigOutput {
	return i.ToClusterClusterConfigAutoscalingConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigAutoscalingConfigArgs) ToClusterClusterConfigAutoscalingConfigOutputWithContext(ctx context.Context) ClusterClusterConfigAutoscalingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigAutoscalingConfigOutput)
}

func (i ClusterClusterConfigAutoscalingConfigArgs) ToClusterClusterConfigAutoscalingConfigPtrOutput() ClusterClusterConfigAutoscalingConfigPtrOutput {
	return i.ToClusterClusterConfigAutoscalingConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigAutoscalingConfigArgs) ToClusterClusterConfigAutoscalingConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigAutoscalingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigAutoscalingConfigOutput).ToClusterClusterConfigAutoscalingConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigAutoscalingConfigPtrInput is an input type that accepts ClusterClusterConfigAutoscalingConfigArgs, ClusterClusterConfigAutoscalingConfigPtr and ClusterClusterConfigAutoscalingConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigAutoscalingConfigPtrInput` via:
//
// 		 ClusterClusterConfigAutoscalingConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigAutoscalingConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigAutoscalingConfigPtrOutput() ClusterClusterConfigAutoscalingConfigPtrOutput
	ToClusterClusterConfigAutoscalingConfigPtrOutputWithContext(context.Context) ClusterClusterConfigAutoscalingConfigPtrOutput
}

type clusterClusterConfigAutoscalingConfigPtrType ClusterClusterConfigAutoscalingConfigArgs

func ClusterClusterConfigAutoscalingConfigPtr(v *ClusterClusterConfigAutoscalingConfigArgs) ClusterClusterConfigAutoscalingConfigPtrInput {
	return (*clusterClusterConfigAutoscalingConfigPtrType)(v)
}

func (*clusterClusterConfigAutoscalingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigAutoscalingConfig)(nil)).Elem()
}

func (i *clusterClusterConfigAutoscalingConfigPtrType) ToClusterClusterConfigAutoscalingConfigPtrOutput() ClusterClusterConfigAutoscalingConfigPtrOutput {
	return i.ToClusterClusterConfigAutoscalingConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigAutoscalingConfigPtrType) ToClusterClusterConfigAutoscalingConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigAutoscalingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigAutoscalingConfigPtrOutput)
}

type ClusterClusterConfigAutoscalingConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigAutoscalingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigAutoscalingConfig)(nil)).Elem()
}

func (o ClusterClusterConfigAutoscalingConfigOutput) ToClusterClusterConfigAutoscalingConfigOutput() ClusterClusterConfigAutoscalingConfigOutput {
	return o
}

func (o ClusterClusterConfigAutoscalingConfigOutput) ToClusterClusterConfigAutoscalingConfigOutputWithContext(ctx context.Context) ClusterClusterConfigAutoscalingConfigOutput {
	return o
}

func (o ClusterClusterConfigAutoscalingConfigOutput) ToClusterClusterConfigAutoscalingConfigPtrOutput() ClusterClusterConfigAutoscalingConfigPtrOutput {
	return o.ToClusterClusterConfigAutoscalingConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigAutoscalingConfigOutput) ToClusterClusterConfigAutoscalingConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigAutoscalingConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigAutoscalingConfig) *ClusterClusterConfigAutoscalingConfig {
		return &v
	}).(ClusterClusterConfigAutoscalingConfigPtrOutput)
}

// The autoscaling policy used by the cluster.
func (o ClusterClusterConfigAutoscalingConfigOutput) PolicyUri() pulumi.StringOutput {
	return o.ApplyT(func(v ClusterClusterConfigAutoscalingConfig) string { return v.PolicyUri }).(pulumi.StringOutput)
}

type ClusterClusterConfigAutoscalingConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigAutoscalingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigAutoscalingConfig)(nil)).Elem()
}

func (o ClusterClusterConfigAutoscalingConfigPtrOutput) ToClusterClusterConfigAutoscalingConfigPtrOutput() ClusterClusterConfigAutoscalingConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigAutoscalingConfigPtrOutput) ToClusterClusterConfigAutoscalingConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigAutoscalingConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigAutoscalingConfigPtrOutput) Elem() ClusterClusterConfigAutoscalingConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigAutoscalingConfig) ClusterClusterConfigAutoscalingConfig { return *v }).(ClusterClusterConfigAutoscalingConfigOutput)
}

// The autoscaling policy used by the cluster.
func (o ClusterClusterConfigAutoscalingConfigPtrOutput) PolicyUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigAutoscalingConfig) *string {
		if v == nil {
			return nil
		}
		return &v.PolicyUri
	}).(pulumi.StringPtrOutput)
}

type ClusterClusterConfigEncryptionConfig struct {
	// The Cloud KMS key name to use for PD disk encryption for
	// all instances in the cluster.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// ClusterClusterConfigEncryptionConfigInput is an input type that accepts ClusterClusterConfigEncryptionConfigArgs and ClusterClusterConfigEncryptionConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigEncryptionConfigInput` via:
//
// 		 ClusterClusterConfigEncryptionConfigArgs{...}
//
type ClusterClusterConfigEncryptionConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigEncryptionConfigOutput() ClusterClusterConfigEncryptionConfigOutput
	ToClusterClusterConfigEncryptionConfigOutputWithContext(context.Context) ClusterClusterConfigEncryptionConfigOutput
}

type ClusterClusterConfigEncryptionConfigArgs struct {
	// The Cloud KMS key name to use for PD disk encryption for
	// all instances in the cluster.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (ClusterClusterConfigEncryptionConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigEncryptionConfig)(nil)).Elem()
}

func (i ClusterClusterConfigEncryptionConfigArgs) ToClusterClusterConfigEncryptionConfigOutput() ClusterClusterConfigEncryptionConfigOutput {
	return i.ToClusterClusterConfigEncryptionConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigEncryptionConfigArgs) ToClusterClusterConfigEncryptionConfigOutputWithContext(ctx context.Context) ClusterClusterConfigEncryptionConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigEncryptionConfigOutput)
}

func (i ClusterClusterConfigEncryptionConfigArgs) ToClusterClusterConfigEncryptionConfigPtrOutput() ClusterClusterConfigEncryptionConfigPtrOutput {
	return i.ToClusterClusterConfigEncryptionConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigEncryptionConfigArgs) ToClusterClusterConfigEncryptionConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigEncryptionConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigEncryptionConfigOutput).ToClusterClusterConfigEncryptionConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigEncryptionConfigPtrInput is an input type that accepts ClusterClusterConfigEncryptionConfigArgs, ClusterClusterConfigEncryptionConfigPtr and ClusterClusterConfigEncryptionConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigEncryptionConfigPtrInput` via:
//
// 		 ClusterClusterConfigEncryptionConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigEncryptionConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigEncryptionConfigPtrOutput() ClusterClusterConfigEncryptionConfigPtrOutput
	ToClusterClusterConfigEncryptionConfigPtrOutputWithContext(context.Context) ClusterClusterConfigEncryptionConfigPtrOutput
}

type clusterClusterConfigEncryptionConfigPtrType ClusterClusterConfigEncryptionConfigArgs

func ClusterClusterConfigEncryptionConfigPtr(v *ClusterClusterConfigEncryptionConfigArgs) ClusterClusterConfigEncryptionConfigPtrInput {
	return (*clusterClusterConfigEncryptionConfigPtrType)(v)
}

func (*clusterClusterConfigEncryptionConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigEncryptionConfig)(nil)).Elem()
}

func (i *clusterClusterConfigEncryptionConfigPtrType) ToClusterClusterConfigEncryptionConfigPtrOutput() ClusterClusterConfigEncryptionConfigPtrOutput {
	return i.ToClusterClusterConfigEncryptionConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigEncryptionConfigPtrType) ToClusterClusterConfigEncryptionConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigEncryptionConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigEncryptionConfigPtrOutput)
}

type ClusterClusterConfigEncryptionConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigEncryptionConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigEncryptionConfig)(nil)).Elem()
}

func (o ClusterClusterConfigEncryptionConfigOutput) ToClusterClusterConfigEncryptionConfigOutput() ClusterClusterConfigEncryptionConfigOutput {
	return o
}

func (o ClusterClusterConfigEncryptionConfigOutput) ToClusterClusterConfigEncryptionConfigOutputWithContext(ctx context.Context) ClusterClusterConfigEncryptionConfigOutput {
	return o
}

func (o ClusterClusterConfigEncryptionConfigOutput) ToClusterClusterConfigEncryptionConfigPtrOutput() ClusterClusterConfigEncryptionConfigPtrOutput {
	return o.ToClusterClusterConfigEncryptionConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigEncryptionConfigOutput) ToClusterClusterConfigEncryptionConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigEncryptionConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigEncryptionConfig) *ClusterClusterConfigEncryptionConfig {
		return &v
	}).(ClusterClusterConfigEncryptionConfigPtrOutput)
}

// The Cloud KMS key name to use for PD disk encryption for
// all instances in the cluster.
func (o ClusterClusterConfigEncryptionConfigOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v ClusterClusterConfigEncryptionConfig) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type ClusterClusterConfigEncryptionConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigEncryptionConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigEncryptionConfig)(nil)).Elem()
}

func (o ClusterClusterConfigEncryptionConfigPtrOutput) ToClusterClusterConfigEncryptionConfigPtrOutput() ClusterClusterConfigEncryptionConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigEncryptionConfigPtrOutput) ToClusterClusterConfigEncryptionConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigEncryptionConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigEncryptionConfigPtrOutput) Elem() ClusterClusterConfigEncryptionConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigEncryptionConfig) ClusterClusterConfigEncryptionConfig { return *v }).(ClusterClusterConfigEncryptionConfigOutput)
}

// The Cloud KMS key name to use for PD disk encryption for
// all instances in the cluster.
func (o ClusterClusterConfigEncryptionConfigPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigEncryptionConfig) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type ClusterClusterConfigGceClusterConfig struct {
	// By default, clusters are not restricted to internal IP addresses,
	// and will have ephemeral external IP addresses assigned to each instance. If set to true, all
	// instances in the cluster will only have internal IP addresses. Note: Private Google Access
	// (also known as `privateIpGoogleAccess`) must be enabled on the subnetwork that the cluster
	// will be launched in.
	InternalIpOnly *bool `pulumi:"internalIpOnly"`
	// A map of the Compute Engine metadata entries to add to all instances
	// (see [Project and instance metadata](https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
	Metadata map[string]string `pulumi:"metadata"`
	// The name or selfLink of the Google Compute Engine
	// network to the cluster will be part of. Conflicts with `subnetwork`.
	// If neither is specified, this defaults to the "default" network.
	Network *string `pulumi:"network"`
	// The service account to be used by the Node VMs.
	// If not specified, the "default" service account is used.
	ServiceAccount *string `pulumi:"serviceAccount"`
	// The set of Google API scopes
	// to be made available on all of the node VMs under the `serviceAccount`
	// specified. These can be	either FQDNs, or scope aliases. The following scopes
	// must be set if any other scopes are set. They're necessary to ensure the
	// correct functioning ofthe cluster, and are set automatically by the API:
	ServiceAccountScopes []string `pulumi:"serviceAccountScopes"`
	// The name or selfLink of the Google Compute Engine
	// subnetwork the cluster will be part of. Conflicts with `network`.
	Subnetwork *string `pulumi:"subnetwork"`
	// The list of instance tags applied to instances in the cluster.
	// Tags are used to identify valid sources or targets for network firewalls.
	Tags []string `pulumi:"tags"`
	// The GCP zone where your data is stored and used (i.e. where
	// the master and the worker nodes will be created in). If `region` is set to 'global' (default)
	// then `zone` is mandatory, otherwise GCP is able to make use of [Auto Zone Placement](https://cloud.google.com/dataproc/docs/concepts/auto-zone)
	// to determine this automatically for you.
	// Note: This setting additionally determines and restricts
	// which computing resources are available for use with other configs such as
	// `cluster_config.master_config.machine_type` and `cluster_config.worker_config.machine_type`.
	Zone *string `pulumi:"zone"`
}

// ClusterClusterConfigGceClusterConfigInput is an input type that accepts ClusterClusterConfigGceClusterConfigArgs and ClusterClusterConfigGceClusterConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigGceClusterConfigInput` via:
//
// 		 ClusterClusterConfigGceClusterConfigArgs{...}
//
type ClusterClusterConfigGceClusterConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigGceClusterConfigOutput() ClusterClusterConfigGceClusterConfigOutput
	ToClusterClusterConfigGceClusterConfigOutputWithContext(context.Context) ClusterClusterConfigGceClusterConfigOutput
}

type ClusterClusterConfigGceClusterConfigArgs struct {
	// By default, clusters are not restricted to internal IP addresses,
	// and will have ephemeral external IP addresses assigned to each instance. If set to true, all
	// instances in the cluster will only have internal IP addresses. Note: Private Google Access
	// (also known as `privateIpGoogleAccess`) must be enabled on the subnetwork that the cluster
	// will be launched in.
	InternalIpOnly pulumi.BoolPtrInput `pulumi:"internalIpOnly"`
	// A map of the Compute Engine metadata entries to add to all instances
	// (see [Project and instance metadata](https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
	Metadata pulumi.StringMapInput `pulumi:"metadata"`
	// The name or selfLink of the Google Compute Engine
	// network to the cluster will be part of. Conflicts with `subnetwork`.
	// If neither is specified, this defaults to the "default" network.
	Network pulumi.StringPtrInput `pulumi:"network"`
	// The service account to be used by the Node VMs.
	// If not specified, the "default" service account is used.
	ServiceAccount pulumi.StringPtrInput `pulumi:"serviceAccount"`
	// The set of Google API scopes
	// to be made available on all of the node VMs under the `serviceAccount`
	// specified. These can be	either FQDNs, or scope aliases. The following scopes
	// must be set if any other scopes are set. They're necessary to ensure the
	// correct functioning ofthe cluster, and are set automatically by the API:
	ServiceAccountScopes pulumi.StringArrayInput `pulumi:"serviceAccountScopes"`
	// The name or selfLink of the Google Compute Engine
	// subnetwork the cluster will be part of. Conflicts with `network`.
	Subnetwork pulumi.StringPtrInput `pulumi:"subnetwork"`
	// The list of instance tags applied to instances in the cluster.
	// Tags are used to identify valid sources or targets for network firewalls.
	Tags pulumi.StringArrayInput `pulumi:"tags"`
	// The GCP zone where your data is stored and used (i.e. where
	// the master and the worker nodes will be created in). If `region` is set to 'global' (default)
	// then `zone` is mandatory, otherwise GCP is able to make use of [Auto Zone Placement](https://cloud.google.com/dataproc/docs/concepts/auto-zone)
	// to determine this automatically for you.
	// Note: This setting additionally determines and restricts
	// which computing resources are available for use with other configs such as
	// `cluster_config.master_config.machine_type` and `cluster_config.worker_config.machine_type`.
	Zone pulumi.StringPtrInput `pulumi:"zone"`
}

func (ClusterClusterConfigGceClusterConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigGceClusterConfig)(nil)).Elem()
}

func (i ClusterClusterConfigGceClusterConfigArgs) ToClusterClusterConfigGceClusterConfigOutput() ClusterClusterConfigGceClusterConfigOutput {
	return i.ToClusterClusterConfigGceClusterConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigGceClusterConfigArgs) ToClusterClusterConfigGceClusterConfigOutputWithContext(ctx context.Context) ClusterClusterConfigGceClusterConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigGceClusterConfigOutput)
}

func (i ClusterClusterConfigGceClusterConfigArgs) ToClusterClusterConfigGceClusterConfigPtrOutput() ClusterClusterConfigGceClusterConfigPtrOutput {
	return i.ToClusterClusterConfigGceClusterConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigGceClusterConfigArgs) ToClusterClusterConfigGceClusterConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigGceClusterConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigGceClusterConfigOutput).ToClusterClusterConfigGceClusterConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigGceClusterConfigPtrInput is an input type that accepts ClusterClusterConfigGceClusterConfigArgs, ClusterClusterConfigGceClusterConfigPtr and ClusterClusterConfigGceClusterConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigGceClusterConfigPtrInput` via:
//
// 		 ClusterClusterConfigGceClusterConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigGceClusterConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigGceClusterConfigPtrOutput() ClusterClusterConfigGceClusterConfigPtrOutput
	ToClusterClusterConfigGceClusterConfigPtrOutputWithContext(context.Context) ClusterClusterConfigGceClusterConfigPtrOutput
}

type clusterClusterConfigGceClusterConfigPtrType ClusterClusterConfigGceClusterConfigArgs

func ClusterClusterConfigGceClusterConfigPtr(v *ClusterClusterConfigGceClusterConfigArgs) ClusterClusterConfigGceClusterConfigPtrInput {
	return (*clusterClusterConfigGceClusterConfigPtrType)(v)
}

func (*clusterClusterConfigGceClusterConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigGceClusterConfig)(nil)).Elem()
}

func (i *clusterClusterConfigGceClusterConfigPtrType) ToClusterClusterConfigGceClusterConfigPtrOutput() ClusterClusterConfigGceClusterConfigPtrOutput {
	return i.ToClusterClusterConfigGceClusterConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigGceClusterConfigPtrType) ToClusterClusterConfigGceClusterConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigGceClusterConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigGceClusterConfigPtrOutput)
}

type ClusterClusterConfigGceClusterConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigGceClusterConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigGceClusterConfig)(nil)).Elem()
}

func (o ClusterClusterConfigGceClusterConfigOutput) ToClusterClusterConfigGceClusterConfigOutput() ClusterClusterConfigGceClusterConfigOutput {
	return o
}

func (o ClusterClusterConfigGceClusterConfigOutput) ToClusterClusterConfigGceClusterConfigOutputWithContext(ctx context.Context) ClusterClusterConfigGceClusterConfigOutput {
	return o
}

func (o ClusterClusterConfigGceClusterConfigOutput) ToClusterClusterConfigGceClusterConfigPtrOutput() ClusterClusterConfigGceClusterConfigPtrOutput {
	return o.ToClusterClusterConfigGceClusterConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigGceClusterConfigOutput) ToClusterClusterConfigGceClusterConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigGceClusterConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigGceClusterConfig) *ClusterClusterConfigGceClusterConfig {
		return &v
	}).(ClusterClusterConfigGceClusterConfigPtrOutput)
}

// By default, clusters are not restricted to internal IP addresses,
// and will have ephemeral external IP addresses assigned to each instance. If set to true, all
// instances in the cluster will only have internal IP addresses. Note: Private Google Access
// (also known as `privateIpGoogleAccess`) must be enabled on the subnetwork that the cluster
// will be launched in.
func (o ClusterClusterConfigGceClusterConfigOutput) InternalIpOnly() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigGceClusterConfig) *bool { return v.InternalIpOnly }).(pulumi.BoolPtrOutput)
}

// A map of the Compute Engine metadata entries to add to all instances
// (see [Project and instance metadata](https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
func (o ClusterClusterConfigGceClusterConfigOutput) Metadata() pulumi.StringMapOutput {
	return o.ApplyT(func(v ClusterClusterConfigGceClusterConfig) map[string]string { return v.Metadata }).(pulumi.StringMapOutput)
}

// The name or selfLink of the Google Compute Engine
// network to the cluster will be part of. Conflicts with `subnetwork`.
// If neither is specified, this defaults to the "default" network.
func (o ClusterClusterConfigGceClusterConfigOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigGceClusterConfig) *string { return v.Network }).(pulumi.StringPtrOutput)
}

// The service account to be used by the Node VMs.
// If not specified, the "default" service account is used.
func (o ClusterClusterConfigGceClusterConfigOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigGceClusterConfig) *string { return v.ServiceAccount }).(pulumi.StringPtrOutput)
}

// The set of Google API scopes
// to be made available on all of the node VMs under the `serviceAccount`
// specified. These can be	either FQDNs, or scope aliases. The following scopes
// must be set if any other scopes are set. They're necessary to ensure the
// correct functioning ofthe cluster, and are set automatically by the API:
func (o ClusterClusterConfigGceClusterConfigOutput) ServiceAccountScopes() pulumi.StringArrayOutput {
	return o.ApplyT(func(v ClusterClusterConfigGceClusterConfig) []string { return v.ServiceAccountScopes }).(pulumi.StringArrayOutput)
}

// The name or selfLink of the Google Compute Engine
// subnetwork the cluster will be part of. Conflicts with `network`.
func (o ClusterClusterConfigGceClusterConfigOutput) Subnetwork() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigGceClusterConfig) *string { return v.Subnetwork }).(pulumi.StringPtrOutput)
}

// The list of instance tags applied to instances in the cluster.
// Tags are used to identify valid sources or targets for network firewalls.
func (o ClusterClusterConfigGceClusterConfigOutput) Tags() pulumi.StringArrayOutput {
	return o.ApplyT(func(v ClusterClusterConfigGceClusterConfig) []string { return v.Tags }).(pulumi.StringArrayOutput)
}

// The GCP zone where your data is stored and used (i.e. where
// the master and the worker nodes will be created in). If `region` is set to 'global' (default)
// then `zone` is mandatory, otherwise GCP is able to make use of [Auto Zone Placement](https://cloud.google.com/dataproc/docs/concepts/auto-zone)
// to determine this automatically for you.
// Note: This setting additionally determines and restricts
// which computing resources are available for use with other configs such as
// `cluster_config.master_config.machine_type` and `cluster_config.worker_config.machine_type`.
func (o ClusterClusterConfigGceClusterConfigOutput) Zone() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigGceClusterConfig) *string { return v.Zone }).(pulumi.StringPtrOutput)
}

type ClusterClusterConfigGceClusterConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigGceClusterConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigGceClusterConfig)(nil)).Elem()
}

func (o ClusterClusterConfigGceClusterConfigPtrOutput) ToClusterClusterConfigGceClusterConfigPtrOutput() ClusterClusterConfigGceClusterConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigGceClusterConfigPtrOutput) ToClusterClusterConfigGceClusterConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigGceClusterConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigGceClusterConfigPtrOutput) Elem() ClusterClusterConfigGceClusterConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigGceClusterConfig) ClusterClusterConfigGceClusterConfig { return *v }).(ClusterClusterConfigGceClusterConfigOutput)
}

// By default, clusters are not restricted to internal IP addresses,
// and will have ephemeral external IP addresses assigned to each instance. If set to true, all
// instances in the cluster will only have internal IP addresses. Note: Private Google Access
// (also known as `privateIpGoogleAccess`) must be enabled on the subnetwork that the cluster
// will be launched in.
func (o ClusterClusterConfigGceClusterConfigPtrOutput) InternalIpOnly() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigGceClusterConfig) *bool {
		if v == nil {
			return nil
		}
		return v.InternalIpOnly
	}).(pulumi.BoolPtrOutput)
}

// A map of the Compute Engine metadata entries to add to all instances
// (see [Project and instance metadata](https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
func (o ClusterClusterConfigGceClusterConfigPtrOutput) Metadata() pulumi.StringMapOutput {
	return o.ApplyT(func(v *ClusterClusterConfigGceClusterConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.Metadata
	}).(pulumi.StringMapOutput)
}

// The name or selfLink of the Google Compute Engine
// network to the cluster will be part of. Conflicts with `subnetwork`.
// If neither is specified, this defaults to the "default" network.
func (o ClusterClusterConfigGceClusterConfigPtrOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigGceClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.Network
	}).(pulumi.StringPtrOutput)
}

// The service account to be used by the Node VMs.
// If not specified, the "default" service account is used.
func (o ClusterClusterConfigGceClusterConfigPtrOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigGceClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.ServiceAccount
	}).(pulumi.StringPtrOutput)
}

// The set of Google API scopes
// to be made available on all of the node VMs under the `serviceAccount`
// specified. These can be	either FQDNs, or scope aliases. The following scopes
// must be set if any other scopes are set. They're necessary to ensure the
// correct functioning ofthe cluster, and are set automatically by the API:
func (o ClusterClusterConfigGceClusterConfigPtrOutput) ServiceAccountScopes() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *ClusterClusterConfigGceClusterConfig) []string {
		if v == nil {
			return nil
		}
		return v.ServiceAccountScopes
	}).(pulumi.StringArrayOutput)
}

// The name or selfLink of the Google Compute Engine
// subnetwork the cluster will be part of. Conflicts with `network`.
func (o ClusterClusterConfigGceClusterConfigPtrOutput) Subnetwork() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigGceClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.Subnetwork
	}).(pulumi.StringPtrOutput)
}

// The list of instance tags applied to instances in the cluster.
// Tags are used to identify valid sources or targets for network firewalls.
func (o ClusterClusterConfigGceClusterConfigPtrOutput) Tags() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *ClusterClusterConfigGceClusterConfig) []string {
		if v == nil {
			return nil
		}
		return v.Tags
	}).(pulumi.StringArrayOutput)
}

// The GCP zone where your data is stored and used (i.e. where
// the master and the worker nodes will be created in). If `region` is set to 'global' (default)
// then `zone` is mandatory, otherwise GCP is able to make use of [Auto Zone Placement](https://cloud.google.com/dataproc/docs/concepts/auto-zone)
// to determine this automatically for you.
// Note: This setting additionally determines and restricts
// which computing resources are available for use with other configs such as
// `cluster_config.master_config.machine_type` and `cluster_config.worker_config.machine_type`.
func (o ClusterClusterConfigGceClusterConfigPtrOutput) Zone() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigGceClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.Zone
	}).(pulumi.StringPtrOutput)
}

type ClusterClusterConfigInitializationAction struct {
	// The script to be executed during initialization of the cluster.
	// The script must be a GCS file with a gs:// prefix.
	Script string `pulumi:"script"`
	// The maximum duration (in seconds) which `script` is
	// allowed to take to execute its action. GCP will default to a predetermined
	// computed value if not set (currently 300).
	TimeoutSec *int `pulumi:"timeoutSec"`
}

// ClusterClusterConfigInitializationActionInput is an input type that accepts ClusterClusterConfigInitializationActionArgs and ClusterClusterConfigInitializationActionOutput values.
// You can construct a concrete instance of `ClusterClusterConfigInitializationActionInput` via:
//
// 		 ClusterClusterConfigInitializationActionArgs{...}
//
type ClusterClusterConfigInitializationActionInput interface {
	pulumi.Input

	ToClusterClusterConfigInitializationActionOutput() ClusterClusterConfigInitializationActionOutput
	ToClusterClusterConfigInitializationActionOutputWithContext(context.Context) ClusterClusterConfigInitializationActionOutput
}

type ClusterClusterConfigInitializationActionArgs struct {
	// The script to be executed during initialization of the cluster.
	// The script must be a GCS file with a gs:// prefix.
	Script pulumi.StringInput `pulumi:"script"`
	// The maximum duration (in seconds) which `script` is
	// allowed to take to execute its action. GCP will default to a predetermined
	// computed value if not set (currently 300).
	TimeoutSec pulumi.IntPtrInput `pulumi:"timeoutSec"`
}

func (ClusterClusterConfigInitializationActionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigInitializationAction)(nil)).Elem()
}

func (i ClusterClusterConfigInitializationActionArgs) ToClusterClusterConfigInitializationActionOutput() ClusterClusterConfigInitializationActionOutput {
	return i.ToClusterClusterConfigInitializationActionOutputWithContext(context.Background())
}

func (i ClusterClusterConfigInitializationActionArgs) ToClusterClusterConfigInitializationActionOutputWithContext(ctx context.Context) ClusterClusterConfigInitializationActionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigInitializationActionOutput)
}

// ClusterClusterConfigInitializationActionArrayInput is an input type that accepts ClusterClusterConfigInitializationActionArray and ClusterClusterConfigInitializationActionArrayOutput values.
// You can construct a concrete instance of `ClusterClusterConfigInitializationActionArrayInput` via:
//
// 		 ClusterClusterConfigInitializationActionArray{ ClusterClusterConfigInitializationActionArgs{...} }
//
type ClusterClusterConfigInitializationActionArrayInput interface {
	pulumi.Input

	ToClusterClusterConfigInitializationActionArrayOutput() ClusterClusterConfigInitializationActionArrayOutput
	ToClusterClusterConfigInitializationActionArrayOutputWithContext(context.Context) ClusterClusterConfigInitializationActionArrayOutput
}

type ClusterClusterConfigInitializationActionArray []ClusterClusterConfigInitializationActionInput

func (ClusterClusterConfigInitializationActionArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]ClusterClusterConfigInitializationAction)(nil)).Elem()
}

func (i ClusterClusterConfigInitializationActionArray) ToClusterClusterConfigInitializationActionArrayOutput() ClusterClusterConfigInitializationActionArrayOutput {
	return i.ToClusterClusterConfigInitializationActionArrayOutputWithContext(context.Background())
}

func (i ClusterClusterConfigInitializationActionArray) ToClusterClusterConfigInitializationActionArrayOutputWithContext(ctx context.Context) ClusterClusterConfigInitializationActionArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigInitializationActionArrayOutput)
}

type ClusterClusterConfigInitializationActionOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigInitializationActionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigInitializationAction)(nil)).Elem()
}

func (o ClusterClusterConfigInitializationActionOutput) ToClusterClusterConfigInitializationActionOutput() ClusterClusterConfigInitializationActionOutput {
	return o
}

func (o ClusterClusterConfigInitializationActionOutput) ToClusterClusterConfigInitializationActionOutputWithContext(ctx context.Context) ClusterClusterConfigInitializationActionOutput {
	return o
}

// The script to be executed during initialization of the cluster.
// The script must be a GCS file with a gs:// prefix.
func (o ClusterClusterConfigInitializationActionOutput) Script() pulumi.StringOutput {
	return o.ApplyT(func(v ClusterClusterConfigInitializationAction) string { return v.Script }).(pulumi.StringOutput)
}

// The maximum duration (in seconds) which `script` is
// allowed to take to execute its action. GCP will default to a predetermined
// computed value if not set (currently 300).
func (o ClusterClusterConfigInitializationActionOutput) TimeoutSec() pulumi.IntPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigInitializationAction) *int { return v.TimeoutSec }).(pulumi.IntPtrOutput)
}

type ClusterClusterConfigInitializationActionArrayOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigInitializationActionArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]ClusterClusterConfigInitializationAction)(nil)).Elem()
}

func (o ClusterClusterConfigInitializationActionArrayOutput) ToClusterClusterConfigInitializationActionArrayOutput() ClusterClusterConfigInitializationActionArrayOutput {
	return o
}

func (o ClusterClusterConfigInitializationActionArrayOutput) ToClusterClusterConfigInitializationActionArrayOutputWithContext(ctx context.Context) ClusterClusterConfigInitializationActionArrayOutput {
	return o
}

func (o ClusterClusterConfigInitializationActionArrayOutput) Index(i pulumi.IntInput) ClusterClusterConfigInitializationActionOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) ClusterClusterConfigInitializationAction {
		return vs[0].([]ClusterClusterConfigInitializationAction)[vs[1].(int)]
	}).(ClusterClusterConfigInitializationActionOutput)
}

type ClusterClusterConfigLifecycleConfig struct {
	// The time when cluster will be auto-deleted.
	// A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
	// Example: "2014-10-02T15:01:23.045123456Z".
	AutoDeleteTime *string `pulumi:"autoDeleteTime"`
	// The duration to keep the cluster alive while idling
	// (no jobs running). After this TTL, the cluster will be deleted. Valid range: [10m, 14d].
	IdleDeleteTtl *string `pulumi:"idleDeleteTtl"`
	IdleStartTime *string `pulumi:"idleStartTime"`
}

// ClusterClusterConfigLifecycleConfigInput is an input type that accepts ClusterClusterConfigLifecycleConfigArgs and ClusterClusterConfigLifecycleConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigLifecycleConfigInput` via:
//
// 		 ClusterClusterConfigLifecycleConfigArgs{...}
//
type ClusterClusterConfigLifecycleConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigLifecycleConfigOutput() ClusterClusterConfigLifecycleConfigOutput
	ToClusterClusterConfigLifecycleConfigOutputWithContext(context.Context) ClusterClusterConfigLifecycleConfigOutput
}

type ClusterClusterConfigLifecycleConfigArgs struct {
	// The time when cluster will be auto-deleted.
	// A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
	// Example: "2014-10-02T15:01:23.045123456Z".
	AutoDeleteTime pulumi.StringPtrInput `pulumi:"autoDeleteTime"`
	// The duration to keep the cluster alive while idling
	// (no jobs running). After this TTL, the cluster will be deleted. Valid range: [10m, 14d].
	IdleDeleteTtl pulumi.StringPtrInput `pulumi:"idleDeleteTtl"`
	IdleStartTime pulumi.StringPtrInput `pulumi:"idleStartTime"`
}

func (ClusterClusterConfigLifecycleConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigLifecycleConfig)(nil)).Elem()
}

func (i ClusterClusterConfigLifecycleConfigArgs) ToClusterClusterConfigLifecycleConfigOutput() ClusterClusterConfigLifecycleConfigOutput {
	return i.ToClusterClusterConfigLifecycleConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigLifecycleConfigArgs) ToClusterClusterConfigLifecycleConfigOutputWithContext(ctx context.Context) ClusterClusterConfigLifecycleConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigLifecycleConfigOutput)
}

func (i ClusterClusterConfigLifecycleConfigArgs) ToClusterClusterConfigLifecycleConfigPtrOutput() ClusterClusterConfigLifecycleConfigPtrOutput {
	return i.ToClusterClusterConfigLifecycleConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigLifecycleConfigArgs) ToClusterClusterConfigLifecycleConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigLifecycleConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigLifecycleConfigOutput).ToClusterClusterConfigLifecycleConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigLifecycleConfigPtrInput is an input type that accepts ClusterClusterConfigLifecycleConfigArgs, ClusterClusterConfigLifecycleConfigPtr and ClusterClusterConfigLifecycleConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigLifecycleConfigPtrInput` via:
//
// 		 ClusterClusterConfigLifecycleConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigLifecycleConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigLifecycleConfigPtrOutput() ClusterClusterConfigLifecycleConfigPtrOutput
	ToClusterClusterConfigLifecycleConfigPtrOutputWithContext(context.Context) ClusterClusterConfigLifecycleConfigPtrOutput
}

type clusterClusterConfigLifecycleConfigPtrType ClusterClusterConfigLifecycleConfigArgs

func ClusterClusterConfigLifecycleConfigPtr(v *ClusterClusterConfigLifecycleConfigArgs) ClusterClusterConfigLifecycleConfigPtrInput {
	return (*clusterClusterConfigLifecycleConfigPtrType)(v)
}

func (*clusterClusterConfigLifecycleConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigLifecycleConfig)(nil)).Elem()
}

func (i *clusterClusterConfigLifecycleConfigPtrType) ToClusterClusterConfigLifecycleConfigPtrOutput() ClusterClusterConfigLifecycleConfigPtrOutput {
	return i.ToClusterClusterConfigLifecycleConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigLifecycleConfigPtrType) ToClusterClusterConfigLifecycleConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigLifecycleConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigLifecycleConfigPtrOutput)
}

type ClusterClusterConfigLifecycleConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigLifecycleConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigLifecycleConfig)(nil)).Elem()
}

func (o ClusterClusterConfigLifecycleConfigOutput) ToClusterClusterConfigLifecycleConfigOutput() ClusterClusterConfigLifecycleConfigOutput {
	return o
}

func (o ClusterClusterConfigLifecycleConfigOutput) ToClusterClusterConfigLifecycleConfigOutputWithContext(ctx context.Context) ClusterClusterConfigLifecycleConfigOutput {
	return o
}

func (o ClusterClusterConfigLifecycleConfigOutput) ToClusterClusterConfigLifecycleConfigPtrOutput() ClusterClusterConfigLifecycleConfigPtrOutput {
	return o.ToClusterClusterConfigLifecycleConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigLifecycleConfigOutput) ToClusterClusterConfigLifecycleConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigLifecycleConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigLifecycleConfig) *ClusterClusterConfigLifecycleConfig {
		return &v
	}).(ClusterClusterConfigLifecycleConfigPtrOutput)
}

// The time when cluster will be auto-deleted.
// A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
// Example: "2014-10-02T15:01:23.045123456Z".
func (o ClusterClusterConfigLifecycleConfigOutput) AutoDeleteTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigLifecycleConfig) *string { return v.AutoDeleteTime }).(pulumi.StringPtrOutput)
}

// The duration to keep the cluster alive while idling
// (no jobs running). After this TTL, the cluster will be deleted. Valid range: [10m, 14d].
func (o ClusterClusterConfigLifecycleConfigOutput) IdleDeleteTtl() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigLifecycleConfig) *string { return v.IdleDeleteTtl }).(pulumi.StringPtrOutput)
}

func (o ClusterClusterConfigLifecycleConfigOutput) IdleStartTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigLifecycleConfig) *string { return v.IdleStartTime }).(pulumi.StringPtrOutput)
}

type ClusterClusterConfigLifecycleConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigLifecycleConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigLifecycleConfig)(nil)).Elem()
}

func (o ClusterClusterConfigLifecycleConfigPtrOutput) ToClusterClusterConfigLifecycleConfigPtrOutput() ClusterClusterConfigLifecycleConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigLifecycleConfigPtrOutput) ToClusterClusterConfigLifecycleConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigLifecycleConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigLifecycleConfigPtrOutput) Elem() ClusterClusterConfigLifecycleConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigLifecycleConfig) ClusterClusterConfigLifecycleConfig { return *v }).(ClusterClusterConfigLifecycleConfigOutput)
}

// The time when cluster will be auto-deleted.
// A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
// Example: "2014-10-02T15:01:23.045123456Z".
func (o ClusterClusterConfigLifecycleConfigPtrOutput) AutoDeleteTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigLifecycleConfig) *string {
		if v == nil {
			return nil
		}
		return v.AutoDeleteTime
	}).(pulumi.StringPtrOutput)
}

// The duration to keep the cluster alive while idling
// (no jobs running). After this TTL, the cluster will be deleted. Valid range: [10m, 14d].
func (o ClusterClusterConfigLifecycleConfigPtrOutput) IdleDeleteTtl() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigLifecycleConfig) *string {
		if v == nil {
			return nil
		}
		return v.IdleDeleteTtl
	}).(pulumi.StringPtrOutput)
}

func (o ClusterClusterConfigLifecycleConfigPtrOutput) IdleStartTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigLifecycleConfig) *string {
		if v == nil {
			return nil
		}
		return v.IdleStartTime
	}).(pulumi.StringPtrOutput)
}

type ClusterClusterConfigMasterConfig struct {
	// The Compute Engine accelerator configuration for these instances. Can be specified multiple times.
	Accelerators []ClusterClusterConfigMasterConfigAccelerator `pulumi:"accelerators"`
	// Disk Config
	DiskConfig *ClusterClusterConfigMasterConfigDiskConfig `pulumi:"diskConfig"`
	// The URI for the image to use for this worker.  See [the guide](https://cloud.google.com/dataproc/docs/guides/dataproc-images)
	// for more information.
	ImageUri      *string  `pulumi:"imageUri"`
	InstanceNames []string `pulumi:"instanceNames"`
	// The name of a Google Compute Engine machine type
	// to create for the worker nodes. If not specified, GCP will default to a predetermined
	// computed value (currently `n1-standard-4`).
	MachineType *string `pulumi:"machineType"`
	// The name of a minimum generation of CPU family
	// for the master. If not specified, GCP will default to a predetermined computed value
	// for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
	// for details about which CPU families are available (and defaulted) for each zone.
	MinCpuPlatform *string `pulumi:"minCpuPlatform"`
	// Specifies the number of preemptible nodes to create.
	// Defaults to 0.
	NumInstances *int `pulumi:"numInstances"`
}

// ClusterClusterConfigMasterConfigInput is an input type that accepts ClusterClusterConfigMasterConfigArgs and ClusterClusterConfigMasterConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigMasterConfigInput` via:
//
// 		 ClusterClusterConfigMasterConfigArgs{...}
//
type ClusterClusterConfigMasterConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigMasterConfigOutput() ClusterClusterConfigMasterConfigOutput
	ToClusterClusterConfigMasterConfigOutputWithContext(context.Context) ClusterClusterConfigMasterConfigOutput
}

type ClusterClusterConfigMasterConfigArgs struct {
	// The Compute Engine accelerator configuration for these instances. Can be specified multiple times.
	Accelerators ClusterClusterConfigMasterConfigAcceleratorArrayInput `pulumi:"accelerators"`
	// Disk Config
	DiskConfig ClusterClusterConfigMasterConfigDiskConfigPtrInput `pulumi:"diskConfig"`
	// The URI for the image to use for this worker.  See [the guide](https://cloud.google.com/dataproc/docs/guides/dataproc-images)
	// for more information.
	ImageUri      pulumi.StringPtrInput   `pulumi:"imageUri"`
	InstanceNames pulumi.StringArrayInput `pulumi:"instanceNames"`
	// The name of a Google Compute Engine machine type
	// to create for the worker nodes. If not specified, GCP will default to a predetermined
	// computed value (currently `n1-standard-4`).
	MachineType pulumi.StringPtrInput `pulumi:"machineType"`
	// The name of a minimum generation of CPU family
	// for the master. If not specified, GCP will default to a predetermined computed value
	// for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
	// for details about which CPU families are available (and defaulted) for each zone.
	MinCpuPlatform pulumi.StringPtrInput `pulumi:"minCpuPlatform"`
	// Specifies the number of preemptible nodes to create.
	// Defaults to 0.
	NumInstances pulumi.IntPtrInput `pulumi:"numInstances"`
}

func (ClusterClusterConfigMasterConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigMasterConfig)(nil)).Elem()
}

func (i ClusterClusterConfigMasterConfigArgs) ToClusterClusterConfigMasterConfigOutput() ClusterClusterConfigMasterConfigOutput {
	return i.ToClusterClusterConfigMasterConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigMasterConfigArgs) ToClusterClusterConfigMasterConfigOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigMasterConfigOutput)
}

func (i ClusterClusterConfigMasterConfigArgs) ToClusterClusterConfigMasterConfigPtrOutput() ClusterClusterConfigMasterConfigPtrOutput {
	return i.ToClusterClusterConfigMasterConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigMasterConfigArgs) ToClusterClusterConfigMasterConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigMasterConfigOutput).ToClusterClusterConfigMasterConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigMasterConfigPtrInput is an input type that accepts ClusterClusterConfigMasterConfigArgs, ClusterClusterConfigMasterConfigPtr and ClusterClusterConfigMasterConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigMasterConfigPtrInput` via:
//
// 		 ClusterClusterConfigMasterConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigMasterConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigMasterConfigPtrOutput() ClusterClusterConfigMasterConfigPtrOutput
	ToClusterClusterConfigMasterConfigPtrOutputWithContext(context.Context) ClusterClusterConfigMasterConfigPtrOutput
}

type clusterClusterConfigMasterConfigPtrType ClusterClusterConfigMasterConfigArgs

func ClusterClusterConfigMasterConfigPtr(v *ClusterClusterConfigMasterConfigArgs) ClusterClusterConfigMasterConfigPtrInput {
	return (*clusterClusterConfigMasterConfigPtrType)(v)
}

func (*clusterClusterConfigMasterConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigMasterConfig)(nil)).Elem()
}

func (i *clusterClusterConfigMasterConfigPtrType) ToClusterClusterConfigMasterConfigPtrOutput() ClusterClusterConfigMasterConfigPtrOutput {
	return i.ToClusterClusterConfigMasterConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigMasterConfigPtrType) ToClusterClusterConfigMasterConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigMasterConfigPtrOutput)
}

type ClusterClusterConfigMasterConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigMasterConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigMasterConfig)(nil)).Elem()
}

func (o ClusterClusterConfigMasterConfigOutput) ToClusterClusterConfigMasterConfigOutput() ClusterClusterConfigMasterConfigOutput {
	return o
}

func (o ClusterClusterConfigMasterConfigOutput) ToClusterClusterConfigMasterConfigOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigOutput {
	return o
}

func (o ClusterClusterConfigMasterConfigOutput) ToClusterClusterConfigMasterConfigPtrOutput() ClusterClusterConfigMasterConfigPtrOutput {
	return o.ToClusterClusterConfigMasterConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigMasterConfigOutput) ToClusterClusterConfigMasterConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfig) *ClusterClusterConfigMasterConfig {
		return &v
	}).(ClusterClusterConfigMasterConfigPtrOutput)
}

// The Compute Engine accelerator configuration for these instances. Can be specified multiple times.
func (o ClusterClusterConfigMasterConfigOutput) Accelerators() ClusterClusterConfigMasterConfigAcceleratorArrayOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfig) []ClusterClusterConfigMasterConfigAccelerator {
		return v.Accelerators
	}).(ClusterClusterConfigMasterConfigAcceleratorArrayOutput)
}

// Disk Config
func (o ClusterClusterConfigMasterConfigOutput) DiskConfig() ClusterClusterConfigMasterConfigDiskConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfig) *ClusterClusterConfigMasterConfigDiskConfig {
		return v.DiskConfig
	}).(ClusterClusterConfigMasterConfigDiskConfigPtrOutput)
}

// The URI for the image to use for this worker.  See [the guide](https://cloud.google.com/dataproc/docs/guides/dataproc-images)
// for more information.
func (o ClusterClusterConfigMasterConfigOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfig) *string { return v.ImageUri }).(pulumi.StringPtrOutput)
}

func (o ClusterClusterConfigMasterConfigOutput) InstanceNames() pulumi.StringArrayOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfig) []string { return v.InstanceNames }).(pulumi.StringArrayOutput)
}

// The name of a Google Compute Engine machine type
// to create for the worker nodes. If not specified, GCP will default to a predetermined
// computed value (currently `n1-standard-4`).
func (o ClusterClusterConfigMasterConfigOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfig) *string { return v.MachineType }).(pulumi.StringPtrOutput)
}

// The name of a minimum generation of CPU family
// for the master. If not specified, GCP will default to a predetermined computed value
// for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
// for details about which CPU families are available (and defaulted) for each zone.
func (o ClusterClusterConfigMasterConfigOutput) MinCpuPlatform() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfig) *string { return v.MinCpuPlatform }).(pulumi.StringPtrOutput)
}

// Specifies the number of preemptible nodes to create.
// Defaults to 0.
func (o ClusterClusterConfigMasterConfigOutput) NumInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfig) *int { return v.NumInstances }).(pulumi.IntPtrOutput)
}

type ClusterClusterConfigMasterConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigMasterConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigMasterConfig)(nil)).Elem()
}

func (o ClusterClusterConfigMasterConfigPtrOutput) ToClusterClusterConfigMasterConfigPtrOutput() ClusterClusterConfigMasterConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigMasterConfigPtrOutput) ToClusterClusterConfigMasterConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigMasterConfigPtrOutput) Elem() ClusterClusterConfigMasterConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigMasterConfig) ClusterClusterConfigMasterConfig { return *v }).(ClusterClusterConfigMasterConfigOutput)
}

// The Compute Engine accelerator configuration for these instances. Can be specified multiple times.
func (o ClusterClusterConfigMasterConfigPtrOutput) Accelerators() ClusterClusterConfigMasterConfigAcceleratorArrayOutput {
	return o.ApplyT(func(v *ClusterClusterConfigMasterConfig) []ClusterClusterConfigMasterConfigAccelerator {
		if v == nil {
			return nil
		}
		return v.Accelerators
	}).(ClusterClusterConfigMasterConfigAcceleratorArrayOutput)
}

// Disk Config
func (o ClusterClusterConfigMasterConfigPtrOutput) DiskConfig() ClusterClusterConfigMasterConfigDiskConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigMasterConfig) *ClusterClusterConfigMasterConfigDiskConfig {
		if v == nil {
			return nil
		}
		return v.DiskConfig
	}).(ClusterClusterConfigMasterConfigDiskConfigPtrOutput)
}

// The URI for the image to use for this worker.  See [the guide](https://cloud.google.com/dataproc/docs/guides/dataproc-images)
// for more information.
func (o ClusterClusterConfigMasterConfigPtrOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigMasterConfig) *string {
		if v == nil {
			return nil
		}
		return v.ImageUri
	}).(pulumi.StringPtrOutput)
}

func (o ClusterClusterConfigMasterConfigPtrOutput) InstanceNames() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *ClusterClusterConfigMasterConfig) []string {
		if v == nil {
			return nil
		}
		return v.InstanceNames
	}).(pulumi.StringArrayOutput)
}

// The name of a Google Compute Engine machine type
// to create for the worker nodes. If not specified, GCP will default to a predetermined
// computed value (currently `n1-standard-4`).
func (o ClusterClusterConfigMasterConfigPtrOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigMasterConfig) *string {
		if v == nil {
			return nil
		}
		return v.MachineType
	}).(pulumi.StringPtrOutput)
}

// The name of a minimum generation of CPU family
// for the master. If not specified, GCP will default to a predetermined computed value
// for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
// for details about which CPU families are available (and defaulted) for each zone.
func (o ClusterClusterConfigMasterConfigPtrOutput) MinCpuPlatform() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigMasterConfig) *string {
		if v == nil {
			return nil
		}
		return v.MinCpuPlatform
	}).(pulumi.StringPtrOutput)
}

// Specifies the number of preemptible nodes to create.
// Defaults to 0.
func (o ClusterClusterConfigMasterConfigPtrOutput) NumInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigMasterConfig) *int {
		if v == nil {
			return nil
		}
		return v.NumInstances
	}).(pulumi.IntPtrOutput)
}

type ClusterClusterConfigMasterConfigAccelerator struct {
	// The number of the accelerator cards of this type exposed to this instance. Often restricted to one of `1`, `2`, `4`, or `8`.
	AcceleratorCount int `pulumi:"acceleratorCount"`
	// The short name of the accelerator type to expose to this instance. For example, `nvidia-tesla-k80`.
	AcceleratorType string `pulumi:"acceleratorType"`
}

// ClusterClusterConfigMasterConfigAcceleratorInput is an input type that accepts ClusterClusterConfigMasterConfigAcceleratorArgs and ClusterClusterConfigMasterConfigAcceleratorOutput values.
// You can construct a concrete instance of `ClusterClusterConfigMasterConfigAcceleratorInput` via:
//
// 		 ClusterClusterConfigMasterConfigAcceleratorArgs{...}
//
type ClusterClusterConfigMasterConfigAcceleratorInput interface {
	pulumi.Input

	ToClusterClusterConfigMasterConfigAcceleratorOutput() ClusterClusterConfigMasterConfigAcceleratorOutput
	ToClusterClusterConfigMasterConfigAcceleratorOutputWithContext(context.Context) ClusterClusterConfigMasterConfigAcceleratorOutput
}

type ClusterClusterConfigMasterConfigAcceleratorArgs struct {
	// The number of the accelerator cards of this type exposed to this instance. Often restricted to one of `1`, `2`, `4`, or `8`.
	AcceleratorCount pulumi.IntInput `pulumi:"acceleratorCount"`
	// The short name of the accelerator type to expose to this instance. For example, `nvidia-tesla-k80`.
	AcceleratorType pulumi.StringInput `pulumi:"acceleratorType"`
}

func (ClusterClusterConfigMasterConfigAcceleratorArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigMasterConfigAccelerator)(nil)).Elem()
}

func (i ClusterClusterConfigMasterConfigAcceleratorArgs) ToClusterClusterConfigMasterConfigAcceleratorOutput() ClusterClusterConfigMasterConfigAcceleratorOutput {
	return i.ToClusterClusterConfigMasterConfigAcceleratorOutputWithContext(context.Background())
}

func (i ClusterClusterConfigMasterConfigAcceleratorArgs) ToClusterClusterConfigMasterConfigAcceleratorOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigAcceleratorOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigMasterConfigAcceleratorOutput)
}

// ClusterClusterConfigMasterConfigAcceleratorArrayInput is an input type that accepts ClusterClusterConfigMasterConfigAcceleratorArray and ClusterClusterConfigMasterConfigAcceleratorArrayOutput values.
// You can construct a concrete instance of `ClusterClusterConfigMasterConfigAcceleratorArrayInput` via:
//
// 		 ClusterClusterConfigMasterConfigAcceleratorArray{ ClusterClusterConfigMasterConfigAcceleratorArgs{...} }
//
type ClusterClusterConfigMasterConfigAcceleratorArrayInput interface {
	pulumi.Input

	ToClusterClusterConfigMasterConfigAcceleratorArrayOutput() ClusterClusterConfigMasterConfigAcceleratorArrayOutput
	ToClusterClusterConfigMasterConfigAcceleratorArrayOutputWithContext(context.Context) ClusterClusterConfigMasterConfigAcceleratorArrayOutput
}

type ClusterClusterConfigMasterConfigAcceleratorArray []ClusterClusterConfigMasterConfigAcceleratorInput

func (ClusterClusterConfigMasterConfigAcceleratorArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]ClusterClusterConfigMasterConfigAccelerator)(nil)).Elem()
}

func (i ClusterClusterConfigMasterConfigAcceleratorArray) ToClusterClusterConfigMasterConfigAcceleratorArrayOutput() ClusterClusterConfigMasterConfigAcceleratorArrayOutput {
	return i.ToClusterClusterConfigMasterConfigAcceleratorArrayOutputWithContext(context.Background())
}

func (i ClusterClusterConfigMasterConfigAcceleratorArray) ToClusterClusterConfigMasterConfigAcceleratorArrayOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigAcceleratorArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigMasterConfigAcceleratorArrayOutput)
}

type ClusterClusterConfigMasterConfigAcceleratorOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigMasterConfigAcceleratorOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigMasterConfigAccelerator)(nil)).Elem()
}

func (o ClusterClusterConfigMasterConfigAcceleratorOutput) ToClusterClusterConfigMasterConfigAcceleratorOutput() ClusterClusterConfigMasterConfigAcceleratorOutput {
	return o
}

func (o ClusterClusterConfigMasterConfigAcceleratorOutput) ToClusterClusterConfigMasterConfigAcceleratorOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigAcceleratorOutput {
	return o
}

// The number of the accelerator cards of this type exposed to this instance. Often restricted to one of `1`, `2`, `4`, or `8`.
func (o ClusterClusterConfigMasterConfigAcceleratorOutput) AcceleratorCount() pulumi.IntOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfigAccelerator) int { return v.AcceleratorCount }).(pulumi.IntOutput)
}

// The short name of the accelerator type to expose to this instance. For example, `nvidia-tesla-k80`.
func (o ClusterClusterConfigMasterConfigAcceleratorOutput) AcceleratorType() pulumi.StringOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfigAccelerator) string { return v.AcceleratorType }).(pulumi.StringOutput)
}

type ClusterClusterConfigMasterConfigAcceleratorArrayOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigMasterConfigAcceleratorArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]ClusterClusterConfigMasterConfigAccelerator)(nil)).Elem()
}

func (o ClusterClusterConfigMasterConfigAcceleratorArrayOutput) ToClusterClusterConfigMasterConfigAcceleratorArrayOutput() ClusterClusterConfigMasterConfigAcceleratorArrayOutput {
	return o
}

func (o ClusterClusterConfigMasterConfigAcceleratorArrayOutput) ToClusterClusterConfigMasterConfigAcceleratorArrayOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigAcceleratorArrayOutput {
	return o
}

func (o ClusterClusterConfigMasterConfigAcceleratorArrayOutput) Index(i pulumi.IntInput) ClusterClusterConfigMasterConfigAcceleratorOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) ClusterClusterConfigMasterConfigAccelerator {
		return vs[0].([]ClusterClusterConfigMasterConfigAccelerator)[vs[1].(int)]
	}).(ClusterClusterConfigMasterConfigAcceleratorOutput)
}

type ClusterClusterConfigMasterConfigDiskConfig struct {
	// Size of the primary disk attached to each preemptible worker node, specified
	// in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
	// computed value if not set (currently 500GB). Note: If SSDs are not
	// attached, it also contains the HDFS data blocks and Hadoop working directories.
	BootDiskSizeGb *int `pulumi:"bootDiskSizeGb"`
	// The disk type of the primary disk attached to each preemptible worker node.
	// One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
	BootDiskType *string `pulumi:"bootDiskType"`
	// The amount of local SSD disks that will be
	// attached to each preemptible worker node. Defaults to 0.
	NumLocalSsds *int `pulumi:"numLocalSsds"`
}

// ClusterClusterConfigMasterConfigDiskConfigInput is an input type that accepts ClusterClusterConfigMasterConfigDiskConfigArgs and ClusterClusterConfigMasterConfigDiskConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigMasterConfigDiskConfigInput` via:
//
// 		 ClusterClusterConfigMasterConfigDiskConfigArgs{...}
//
type ClusterClusterConfigMasterConfigDiskConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigMasterConfigDiskConfigOutput() ClusterClusterConfigMasterConfigDiskConfigOutput
	ToClusterClusterConfigMasterConfigDiskConfigOutputWithContext(context.Context) ClusterClusterConfigMasterConfigDiskConfigOutput
}

type ClusterClusterConfigMasterConfigDiskConfigArgs struct {
	// Size of the primary disk attached to each preemptible worker node, specified
	// in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
	// computed value if not set (currently 500GB). Note: If SSDs are not
	// attached, it also contains the HDFS data blocks and Hadoop working directories.
	BootDiskSizeGb pulumi.IntPtrInput `pulumi:"bootDiskSizeGb"`
	// The disk type of the primary disk attached to each preemptible worker node.
	// One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
	BootDiskType pulumi.StringPtrInput `pulumi:"bootDiskType"`
	// The amount of local SSD disks that will be
	// attached to each preemptible worker node. Defaults to 0.
	NumLocalSsds pulumi.IntPtrInput `pulumi:"numLocalSsds"`
}

func (ClusterClusterConfigMasterConfigDiskConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigMasterConfigDiskConfig)(nil)).Elem()
}

func (i ClusterClusterConfigMasterConfigDiskConfigArgs) ToClusterClusterConfigMasterConfigDiskConfigOutput() ClusterClusterConfigMasterConfigDiskConfigOutput {
	return i.ToClusterClusterConfigMasterConfigDiskConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigMasterConfigDiskConfigArgs) ToClusterClusterConfigMasterConfigDiskConfigOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigDiskConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigMasterConfigDiskConfigOutput)
}

func (i ClusterClusterConfigMasterConfigDiskConfigArgs) ToClusterClusterConfigMasterConfigDiskConfigPtrOutput() ClusterClusterConfigMasterConfigDiskConfigPtrOutput {
	return i.ToClusterClusterConfigMasterConfigDiskConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigMasterConfigDiskConfigArgs) ToClusterClusterConfigMasterConfigDiskConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigDiskConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigMasterConfigDiskConfigOutput).ToClusterClusterConfigMasterConfigDiskConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigMasterConfigDiskConfigPtrInput is an input type that accepts ClusterClusterConfigMasterConfigDiskConfigArgs, ClusterClusterConfigMasterConfigDiskConfigPtr and ClusterClusterConfigMasterConfigDiskConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigMasterConfigDiskConfigPtrInput` via:
//
// 		 ClusterClusterConfigMasterConfigDiskConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigMasterConfigDiskConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigMasterConfigDiskConfigPtrOutput() ClusterClusterConfigMasterConfigDiskConfigPtrOutput
	ToClusterClusterConfigMasterConfigDiskConfigPtrOutputWithContext(context.Context) ClusterClusterConfigMasterConfigDiskConfigPtrOutput
}

type clusterClusterConfigMasterConfigDiskConfigPtrType ClusterClusterConfigMasterConfigDiskConfigArgs

func ClusterClusterConfigMasterConfigDiskConfigPtr(v *ClusterClusterConfigMasterConfigDiskConfigArgs) ClusterClusterConfigMasterConfigDiskConfigPtrInput {
	return (*clusterClusterConfigMasterConfigDiskConfigPtrType)(v)
}

func (*clusterClusterConfigMasterConfigDiskConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigMasterConfigDiskConfig)(nil)).Elem()
}

func (i *clusterClusterConfigMasterConfigDiskConfigPtrType) ToClusterClusterConfigMasterConfigDiskConfigPtrOutput() ClusterClusterConfigMasterConfigDiskConfigPtrOutput {
	return i.ToClusterClusterConfigMasterConfigDiskConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigMasterConfigDiskConfigPtrType) ToClusterClusterConfigMasterConfigDiskConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigDiskConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigMasterConfigDiskConfigPtrOutput)
}

type ClusterClusterConfigMasterConfigDiskConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigMasterConfigDiskConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigMasterConfigDiskConfig)(nil)).Elem()
}

func (o ClusterClusterConfigMasterConfigDiskConfigOutput) ToClusterClusterConfigMasterConfigDiskConfigOutput() ClusterClusterConfigMasterConfigDiskConfigOutput {
	return o
}

func (o ClusterClusterConfigMasterConfigDiskConfigOutput) ToClusterClusterConfigMasterConfigDiskConfigOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigDiskConfigOutput {
	return o
}

func (o ClusterClusterConfigMasterConfigDiskConfigOutput) ToClusterClusterConfigMasterConfigDiskConfigPtrOutput() ClusterClusterConfigMasterConfigDiskConfigPtrOutput {
	return o.ToClusterClusterConfigMasterConfigDiskConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigMasterConfigDiskConfigOutput) ToClusterClusterConfigMasterConfigDiskConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigDiskConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfigDiskConfig) *ClusterClusterConfigMasterConfigDiskConfig {
		return &v
	}).(ClusterClusterConfigMasterConfigDiskConfigPtrOutput)
}

// Size of the primary disk attached to each preemptible worker node, specified
// in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
// computed value if not set (currently 500GB). Note: If SSDs are not
// attached, it also contains the HDFS data blocks and Hadoop working directories.
func (o ClusterClusterConfigMasterConfigDiskConfigOutput) BootDiskSizeGb() pulumi.IntPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfigDiskConfig) *int { return v.BootDiskSizeGb }).(pulumi.IntPtrOutput)
}

// The disk type of the primary disk attached to each preemptible worker node.
// One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
func (o ClusterClusterConfigMasterConfigDiskConfigOutput) BootDiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfigDiskConfig) *string { return v.BootDiskType }).(pulumi.StringPtrOutput)
}

// The amount of local SSD disks that will be
// attached to each preemptible worker node. Defaults to 0.
func (o ClusterClusterConfigMasterConfigDiskConfigOutput) NumLocalSsds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigMasterConfigDiskConfig) *int { return v.NumLocalSsds }).(pulumi.IntPtrOutput)
}

type ClusterClusterConfigMasterConfigDiskConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigMasterConfigDiskConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigMasterConfigDiskConfig)(nil)).Elem()
}

func (o ClusterClusterConfigMasterConfigDiskConfigPtrOutput) ToClusterClusterConfigMasterConfigDiskConfigPtrOutput() ClusterClusterConfigMasterConfigDiskConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigMasterConfigDiskConfigPtrOutput) ToClusterClusterConfigMasterConfigDiskConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigMasterConfigDiskConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigMasterConfigDiskConfigPtrOutput) Elem() ClusterClusterConfigMasterConfigDiskConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigMasterConfigDiskConfig) ClusterClusterConfigMasterConfigDiskConfig {
		return *v
	}).(ClusterClusterConfigMasterConfigDiskConfigOutput)
}

// Size of the primary disk attached to each preemptible worker node, specified
// in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
// computed value if not set (currently 500GB). Note: If SSDs are not
// attached, it also contains the HDFS data blocks and Hadoop working directories.
func (o ClusterClusterConfigMasterConfigDiskConfigPtrOutput) BootDiskSizeGb() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigMasterConfigDiskConfig) *int {
		if v == nil {
			return nil
		}
		return v.BootDiskSizeGb
	}).(pulumi.IntPtrOutput)
}

// The disk type of the primary disk attached to each preemptible worker node.
// One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
func (o ClusterClusterConfigMasterConfigDiskConfigPtrOutput) BootDiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigMasterConfigDiskConfig) *string {
		if v == nil {
			return nil
		}
		return v.BootDiskType
	}).(pulumi.StringPtrOutput)
}

// The amount of local SSD disks that will be
// attached to each preemptible worker node. Defaults to 0.
func (o ClusterClusterConfigMasterConfigDiskConfigPtrOutput) NumLocalSsds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigMasterConfigDiskConfig) *int {
		if v == nil {
			return nil
		}
		return v.NumLocalSsds
	}).(pulumi.IntPtrOutput)
}

type ClusterClusterConfigPreemptibleWorkerConfig struct {
	// Disk Config
	DiskConfig    *ClusterClusterConfigPreemptibleWorkerConfigDiskConfig `pulumi:"diskConfig"`
	InstanceNames []string                                               `pulumi:"instanceNames"`
	// Specifies the number of preemptible nodes to create.
	// Defaults to 0.
	NumInstances *int `pulumi:"numInstances"`
}

// ClusterClusterConfigPreemptibleWorkerConfigInput is an input type that accepts ClusterClusterConfigPreemptibleWorkerConfigArgs and ClusterClusterConfigPreemptibleWorkerConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigPreemptibleWorkerConfigInput` via:
//
// 		 ClusterClusterConfigPreemptibleWorkerConfigArgs{...}
//
type ClusterClusterConfigPreemptibleWorkerConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigPreemptibleWorkerConfigOutput() ClusterClusterConfigPreemptibleWorkerConfigOutput
	ToClusterClusterConfigPreemptibleWorkerConfigOutputWithContext(context.Context) ClusterClusterConfigPreemptibleWorkerConfigOutput
}

type ClusterClusterConfigPreemptibleWorkerConfigArgs struct {
	// Disk Config
	DiskConfig    ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrInput `pulumi:"diskConfig"`
	InstanceNames pulumi.StringArrayInput                                       `pulumi:"instanceNames"`
	// Specifies the number of preemptible nodes to create.
	// Defaults to 0.
	NumInstances pulumi.IntPtrInput `pulumi:"numInstances"`
}

func (ClusterClusterConfigPreemptibleWorkerConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigPreemptibleWorkerConfig)(nil)).Elem()
}

func (i ClusterClusterConfigPreemptibleWorkerConfigArgs) ToClusterClusterConfigPreemptibleWorkerConfigOutput() ClusterClusterConfigPreemptibleWorkerConfigOutput {
	return i.ToClusterClusterConfigPreemptibleWorkerConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigPreemptibleWorkerConfigArgs) ToClusterClusterConfigPreemptibleWorkerConfigOutputWithContext(ctx context.Context) ClusterClusterConfigPreemptibleWorkerConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigPreemptibleWorkerConfigOutput)
}

func (i ClusterClusterConfigPreemptibleWorkerConfigArgs) ToClusterClusterConfigPreemptibleWorkerConfigPtrOutput() ClusterClusterConfigPreemptibleWorkerConfigPtrOutput {
	return i.ToClusterClusterConfigPreemptibleWorkerConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigPreemptibleWorkerConfigArgs) ToClusterClusterConfigPreemptibleWorkerConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigPreemptibleWorkerConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigPreemptibleWorkerConfigOutput).ToClusterClusterConfigPreemptibleWorkerConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigPreemptibleWorkerConfigPtrInput is an input type that accepts ClusterClusterConfigPreemptibleWorkerConfigArgs, ClusterClusterConfigPreemptibleWorkerConfigPtr and ClusterClusterConfigPreemptibleWorkerConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigPreemptibleWorkerConfigPtrInput` via:
//
// 		 ClusterClusterConfigPreemptibleWorkerConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigPreemptibleWorkerConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigPreemptibleWorkerConfigPtrOutput() ClusterClusterConfigPreemptibleWorkerConfigPtrOutput
	ToClusterClusterConfigPreemptibleWorkerConfigPtrOutputWithContext(context.Context) ClusterClusterConfigPreemptibleWorkerConfigPtrOutput
}

type clusterClusterConfigPreemptibleWorkerConfigPtrType ClusterClusterConfigPreemptibleWorkerConfigArgs

func ClusterClusterConfigPreemptibleWorkerConfigPtr(v *ClusterClusterConfigPreemptibleWorkerConfigArgs) ClusterClusterConfigPreemptibleWorkerConfigPtrInput {
	return (*clusterClusterConfigPreemptibleWorkerConfigPtrType)(v)
}

func (*clusterClusterConfigPreemptibleWorkerConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigPreemptibleWorkerConfig)(nil)).Elem()
}

func (i *clusterClusterConfigPreemptibleWorkerConfigPtrType) ToClusterClusterConfigPreemptibleWorkerConfigPtrOutput() ClusterClusterConfigPreemptibleWorkerConfigPtrOutput {
	return i.ToClusterClusterConfigPreemptibleWorkerConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigPreemptibleWorkerConfigPtrType) ToClusterClusterConfigPreemptibleWorkerConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigPreemptibleWorkerConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigPreemptibleWorkerConfigPtrOutput)
}

type ClusterClusterConfigPreemptibleWorkerConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigPreemptibleWorkerConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigPreemptibleWorkerConfig)(nil)).Elem()
}

func (o ClusterClusterConfigPreemptibleWorkerConfigOutput) ToClusterClusterConfigPreemptibleWorkerConfigOutput() ClusterClusterConfigPreemptibleWorkerConfigOutput {
	return o
}

func (o ClusterClusterConfigPreemptibleWorkerConfigOutput) ToClusterClusterConfigPreemptibleWorkerConfigOutputWithContext(ctx context.Context) ClusterClusterConfigPreemptibleWorkerConfigOutput {
	return o
}

func (o ClusterClusterConfigPreemptibleWorkerConfigOutput) ToClusterClusterConfigPreemptibleWorkerConfigPtrOutput() ClusterClusterConfigPreemptibleWorkerConfigPtrOutput {
	return o.ToClusterClusterConfigPreemptibleWorkerConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigPreemptibleWorkerConfigOutput) ToClusterClusterConfigPreemptibleWorkerConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigPreemptibleWorkerConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigPreemptibleWorkerConfig) *ClusterClusterConfigPreemptibleWorkerConfig {
		return &v
	}).(ClusterClusterConfigPreemptibleWorkerConfigPtrOutput)
}

// Disk Config
func (o ClusterClusterConfigPreemptibleWorkerConfigOutput) DiskConfig() ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigPreemptibleWorkerConfig) *ClusterClusterConfigPreemptibleWorkerConfigDiskConfig {
		return v.DiskConfig
	}).(ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput)
}

func (o ClusterClusterConfigPreemptibleWorkerConfigOutput) InstanceNames() pulumi.StringArrayOutput {
	return o.ApplyT(func(v ClusterClusterConfigPreemptibleWorkerConfig) []string { return v.InstanceNames }).(pulumi.StringArrayOutput)
}

// Specifies the number of preemptible nodes to create.
// Defaults to 0.
func (o ClusterClusterConfigPreemptibleWorkerConfigOutput) NumInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigPreemptibleWorkerConfig) *int { return v.NumInstances }).(pulumi.IntPtrOutput)
}

type ClusterClusterConfigPreemptibleWorkerConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigPreemptibleWorkerConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigPreemptibleWorkerConfig)(nil)).Elem()
}

func (o ClusterClusterConfigPreemptibleWorkerConfigPtrOutput) ToClusterClusterConfigPreemptibleWorkerConfigPtrOutput() ClusterClusterConfigPreemptibleWorkerConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigPreemptibleWorkerConfigPtrOutput) ToClusterClusterConfigPreemptibleWorkerConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigPreemptibleWorkerConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigPreemptibleWorkerConfigPtrOutput) Elem() ClusterClusterConfigPreemptibleWorkerConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigPreemptibleWorkerConfig) ClusterClusterConfigPreemptibleWorkerConfig {
		return *v
	}).(ClusterClusterConfigPreemptibleWorkerConfigOutput)
}

// Disk Config
func (o ClusterClusterConfigPreemptibleWorkerConfigPtrOutput) DiskConfig() ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigPreemptibleWorkerConfig) *ClusterClusterConfigPreemptibleWorkerConfigDiskConfig {
		if v == nil {
			return nil
		}
		return v.DiskConfig
	}).(ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput)
}

func (o ClusterClusterConfigPreemptibleWorkerConfigPtrOutput) InstanceNames() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *ClusterClusterConfigPreemptibleWorkerConfig) []string {
		if v == nil {
			return nil
		}
		return v.InstanceNames
	}).(pulumi.StringArrayOutput)
}

// Specifies the number of preemptible nodes to create.
// Defaults to 0.
func (o ClusterClusterConfigPreemptibleWorkerConfigPtrOutput) NumInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigPreemptibleWorkerConfig) *int {
		if v == nil {
			return nil
		}
		return v.NumInstances
	}).(pulumi.IntPtrOutput)
}

type ClusterClusterConfigPreemptibleWorkerConfigDiskConfig struct {
	// Size of the primary disk attached to each preemptible worker node, specified
	// in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
	// computed value if not set (currently 500GB). Note: If SSDs are not
	// attached, it also contains the HDFS data blocks and Hadoop working directories.
	BootDiskSizeGb *int `pulumi:"bootDiskSizeGb"`
	// The disk type of the primary disk attached to each preemptible worker node.
	// One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
	BootDiskType *string `pulumi:"bootDiskType"`
	// The amount of local SSD disks that will be
	// attached to each preemptible worker node. Defaults to 0.
	NumLocalSsds *int `pulumi:"numLocalSsds"`
}

// ClusterClusterConfigPreemptibleWorkerConfigDiskConfigInput is an input type that accepts ClusterClusterConfigPreemptibleWorkerConfigDiskConfigArgs and ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigPreemptibleWorkerConfigDiskConfigInput` via:
//
// 		 ClusterClusterConfigPreemptibleWorkerConfigDiskConfigArgs{...}
//
type ClusterClusterConfigPreemptibleWorkerConfigDiskConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput() ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput
	ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutputWithContext(context.Context) ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput
}

type ClusterClusterConfigPreemptibleWorkerConfigDiskConfigArgs struct {
	// Size of the primary disk attached to each preemptible worker node, specified
	// in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
	// computed value if not set (currently 500GB). Note: If SSDs are not
	// attached, it also contains the HDFS data blocks and Hadoop working directories.
	BootDiskSizeGb pulumi.IntPtrInput `pulumi:"bootDiskSizeGb"`
	// The disk type of the primary disk attached to each preemptible worker node.
	// One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
	BootDiskType pulumi.StringPtrInput `pulumi:"bootDiskType"`
	// The amount of local SSD disks that will be
	// attached to each preemptible worker node. Defaults to 0.
	NumLocalSsds pulumi.IntPtrInput `pulumi:"numLocalSsds"`
}

func (ClusterClusterConfigPreemptibleWorkerConfigDiskConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigPreemptibleWorkerConfigDiskConfig)(nil)).Elem()
}

func (i ClusterClusterConfigPreemptibleWorkerConfigDiskConfigArgs) ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput() ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput {
	return i.ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigPreemptibleWorkerConfigDiskConfigArgs) ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutputWithContext(ctx context.Context) ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput)
}

func (i ClusterClusterConfigPreemptibleWorkerConfigDiskConfigArgs) ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput() ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput {
	return i.ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigPreemptibleWorkerConfigDiskConfigArgs) ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput).ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrInput is an input type that accepts ClusterClusterConfigPreemptibleWorkerConfigDiskConfigArgs, ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtr and ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrInput` via:
//
// 		 ClusterClusterConfigPreemptibleWorkerConfigDiskConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput() ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput
	ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutputWithContext(context.Context) ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput
}

type clusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrType ClusterClusterConfigPreemptibleWorkerConfigDiskConfigArgs

func ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtr(v *ClusterClusterConfigPreemptibleWorkerConfigDiskConfigArgs) ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrInput {
	return (*clusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrType)(v)
}

func (*clusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigPreemptibleWorkerConfigDiskConfig)(nil)).Elem()
}

func (i *clusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrType) ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput() ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput {
	return i.ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrType) ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput)
}

type ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigPreemptibleWorkerConfigDiskConfig)(nil)).Elem()
}

func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput) ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput() ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput {
	return o
}

func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput) ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutputWithContext(ctx context.Context) ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput {
	return o
}

func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput) ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput() ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput {
	return o.ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput) ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigPreemptibleWorkerConfigDiskConfig) *ClusterClusterConfigPreemptibleWorkerConfigDiskConfig {
		return &v
	}).(ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput)
}

// Size of the primary disk attached to each preemptible worker node, specified
// in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
// computed value if not set (currently 500GB). Note: If SSDs are not
// attached, it also contains the HDFS data blocks and Hadoop working directories.
func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput) BootDiskSizeGb() pulumi.IntPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigPreemptibleWorkerConfigDiskConfig) *int { return v.BootDiskSizeGb }).(pulumi.IntPtrOutput)
}

// The disk type of the primary disk attached to each preemptible worker node.
// One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput) BootDiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigPreemptibleWorkerConfigDiskConfig) *string { return v.BootDiskType }).(pulumi.StringPtrOutput)
}

// The amount of local SSD disks that will be
// attached to each preemptible worker node. Defaults to 0.
func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput) NumLocalSsds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigPreemptibleWorkerConfigDiskConfig) *int { return v.NumLocalSsds }).(pulumi.IntPtrOutput)
}

type ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigPreemptibleWorkerConfigDiskConfig)(nil)).Elem()
}

func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput) ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput() ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput) ToClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput) Elem() ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigPreemptibleWorkerConfigDiskConfig) ClusterClusterConfigPreemptibleWorkerConfigDiskConfig {
		return *v
	}).(ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput)
}

// Size of the primary disk attached to each preemptible worker node, specified
// in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
// computed value if not set (currently 500GB). Note: If SSDs are not
// attached, it also contains the HDFS data blocks and Hadoop working directories.
func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput) BootDiskSizeGb() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigPreemptibleWorkerConfigDiskConfig) *int {
		if v == nil {
			return nil
		}
		return v.BootDiskSizeGb
	}).(pulumi.IntPtrOutput)
}

// The disk type of the primary disk attached to each preemptible worker node.
// One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput) BootDiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigPreemptibleWorkerConfigDiskConfig) *string {
		if v == nil {
			return nil
		}
		return v.BootDiskType
	}).(pulumi.StringPtrOutput)
}

// The amount of local SSD disks that will be
// attached to each preemptible worker node. Defaults to 0.
func (o ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput) NumLocalSsds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigPreemptibleWorkerConfigDiskConfig) *int {
		if v == nil {
			return nil
		}
		return v.NumLocalSsds
	}).(pulumi.IntPtrOutput)
}

type ClusterClusterConfigSecurityConfig struct {
	// Kerberos Configuration
	KerberosConfig ClusterClusterConfigSecurityConfigKerberosConfig `pulumi:"kerberosConfig"`
}

// ClusterClusterConfigSecurityConfigInput is an input type that accepts ClusterClusterConfigSecurityConfigArgs and ClusterClusterConfigSecurityConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigSecurityConfigInput` via:
//
// 		 ClusterClusterConfigSecurityConfigArgs{...}
//
type ClusterClusterConfigSecurityConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigSecurityConfigOutput() ClusterClusterConfigSecurityConfigOutput
	ToClusterClusterConfigSecurityConfigOutputWithContext(context.Context) ClusterClusterConfigSecurityConfigOutput
}

type ClusterClusterConfigSecurityConfigArgs struct {
	// Kerberos Configuration
	KerberosConfig ClusterClusterConfigSecurityConfigKerberosConfigInput `pulumi:"kerberosConfig"`
}

func (ClusterClusterConfigSecurityConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigSecurityConfig)(nil)).Elem()
}

func (i ClusterClusterConfigSecurityConfigArgs) ToClusterClusterConfigSecurityConfigOutput() ClusterClusterConfigSecurityConfigOutput {
	return i.ToClusterClusterConfigSecurityConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigSecurityConfigArgs) ToClusterClusterConfigSecurityConfigOutputWithContext(ctx context.Context) ClusterClusterConfigSecurityConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigSecurityConfigOutput)
}

func (i ClusterClusterConfigSecurityConfigArgs) ToClusterClusterConfigSecurityConfigPtrOutput() ClusterClusterConfigSecurityConfigPtrOutput {
	return i.ToClusterClusterConfigSecurityConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigSecurityConfigArgs) ToClusterClusterConfigSecurityConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigSecurityConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigSecurityConfigOutput).ToClusterClusterConfigSecurityConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigSecurityConfigPtrInput is an input type that accepts ClusterClusterConfigSecurityConfigArgs, ClusterClusterConfigSecurityConfigPtr and ClusterClusterConfigSecurityConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigSecurityConfigPtrInput` via:
//
// 		 ClusterClusterConfigSecurityConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigSecurityConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigSecurityConfigPtrOutput() ClusterClusterConfigSecurityConfigPtrOutput
	ToClusterClusterConfigSecurityConfigPtrOutputWithContext(context.Context) ClusterClusterConfigSecurityConfigPtrOutput
}

type clusterClusterConfigSecurityConfigPtrType ClusterClusterConfigSecurityConfigArgs

func ClusterClusterConfigSecurityConfigPtr(v *ClusterClusterConfigSecurityConfigArgs) ClusterClusterConfigSecurityConfigPtrInput {
	return (*clusterClusterConfigSecurityConfigPtrType)(v)
}

func (*clusterClusterConfigSecurityConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigSecurityConfig)(nil)).Elem()
}

func (i *clusterClusterConfigSecurityConfigPtrType) ToClusterClusterConfigSecurityConfigPtrOutput() ClusterClusterConfigSecurityConfigPtrOutput {
	return i.ToClusterClusterConfigSecurityConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigSecurityConfigPtrType) ToClusterClusterConfigSecurityConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigSecurityConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigSecurityConfigPtrOutput)
}

type ClusterClusterConfigSecurityConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigSecurityConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigSecurityConfig)(nil)).Elem()
}

func (o ClusterClusterConfigSecurityConfigOutput) ToClusterClusterConfigSecurityConfigOutput() ClusterClusterConfigSecurityConfigOutput {
	return o
}

func (o ClusterClusterConfigSecurityConfigOutput) ToClusterClusterConfigSecurityConfigOutputWithContext(ctx context.Context) ClusterClusterConfigSecurityConfigOutput {
	return o
}

func (o ClusterClusterConfigSecurityConfigOutput) ToClusterClusterConfigSecurityConfigPtrOutput() ClusterClusterConfigSecurityConfigPtrOutput {
	return o.ToClusterClusterConfigSecurityConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigSecurityConfigOutput) ToClusterClusterConfigSecurityConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigSecurityConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfig) *ClusterClusterConfigSecurityConfig {
		return &v
	}).(ClusterClusterConfigSecurityConfigPtrOutput)
}

// Kerberos Configuration
func (o ClusterClusterConfigSecurityConfigOutput) KerberosConfig() ClusterClusterConfigSecurityConfigKerberosConfigOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfig) ClusterClusterConfigSecurityConfigKerberosConfig {
		return v.KerberosConfig
	}).(ClusterClusterConfigSecurityConfigKerberosConfigOutput)
}

type ClusterClusterConfigSecurityConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigSecurityConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigSecurityConfig)(nil)).Elem()
}

func (o ClusterClusterConfigSecurityConfigPtrOutput) ToClusterClusterConfigSecurityConfigPtrOutput() ClusterClusterConfigSecurityConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigSecurityConfigPtrOutput) ToClusterClusterConfigSecurityConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigSecurityConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigSecurityConfigPtrOutput) Elem() ClusterClusterConfigSecurityConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfig) ClusterClusterConfigSecurityConfig { return *v }).(ClusterClusterConfigSecurityConfigOutput)
}

// Kerberos Configuration
func (o ClusterClusterConfigSecurityConfigPtrOutput) KerberosConfig() ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfig) *ClusterClusterConfigSecurityConfigKerberosConfig {
		if v == nil {
			return nil
		}
		return &v.KerberosConfig
	}).(ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput)
}

type ClusterClusterConfigSecurityConfigKerberosConfig struct {
	// The admin server (IP or hostname) for the
	// remote trusted realm in a cross realm trust relationship.
	CrossRealmTrustAdminServer *string `pulumi:"crossRealmTrustAdminServer"`
	// The KDC (IP or hostname) for the
	// remote trusted realm in a cross realm trust relationship.
	CrossRealmTrustKdc *string `pulumi:"crossRealmTrustKdc"`
	// The remote realm the Dataproc on-cluster KDC will
	// trust, should the user enable cross realm trust.
	CrossRealmTrustRealm *string `pulumi:"crossRealmTrustRealm"`
	// The Cloud Storage URI of a KMS
	// encrypted file containing the shared password between the on-cluster Kerberos realm
	// and the remote trusted realm, in a cross realm trust relationship.
	CrossRealmTrustSharedPasswordUri *string `pulumi:"crossRealmTrustSharedPasswordUri"`
	// Flag to indicate whether to Kerberize the cluster.
	EnableKerberos *bool `pulumi:"enableKerberos"`
	// The Cloud Storage URI of a KMS encrypted file containing
	// the master key of the KDC database.
	KdcDbKeyUri *string `pulumi:"kdcDbKeyUri"`
	// The Cloud Storage URI of a KMS encrypted file containing
	// the password to the user provided key. For the self-signed certificate, this password
	// is generated by Dataproc.
	KeyPasswordUri *string `pulumi:"keyPasswordUri"`
	// The Cloud Storage URI of a KMS encrypted file containing
	// the password to the user provided keystore. For the self-signed certificated, the password
	// is generated by Dataproc.
	KeystorePasswordUri *string `pulumi:"keystorePasswordUri"`
	// The Cloud Storage URI of the keystore file used for SSL encryption.
	// If not provided, Dataproc will provide a self-signed certificate.
	KeystoreUri *string `pulumi:"keystoreUri"`
	// The URI of the KMS key used to encrypt various sensitive files.
	KmsKeyUri string `pulumi:"kmsKeyUri"`
	// The name of the on-cluster Kerberos realm. If not specified, the
	// uppercased domain of hostnames will be the realm.
	Realm *string `pulumi:"realm"`
	// The Cloud Storage URI of a KMS encrypted file
	// containing the root principal password.
	RootPrincipalPasswordUri string `pulumi:"rootPrincipalPasswordUri"`
	// The lifetime of the ticket granting ticket, in hours.
	TgtLifetimeHours *int `pulumi:"tgtLifetimeHours"`
	// The Cloud Storage URI of a KMS encrypted file
	// containing the password to the user provided truststore. For the self-signed
	// certificate, this password is generated by Dataproc.
	TruststorePasswordUri *string `pulumi:"truststorePasswordUri"`
	// The Cloud Storage URI of the truststore file used for
	// SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
	TruststoreUri *string `pulumi:"truststoreUri"`
}

// ClusterClusterConfigSecurityConfigKerberosConfigInput is an input type that accepts ClusterClusterConfigSecurityConfigKerberosConfigArgs and ClusterClusterConfigSecurityConfigKerberosConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigSecurityConfigKerberosConfigInput` via:
//
// 		 ClusterClusterConfigSecurityConfigKerberosConfigArgs{...}
//
type ClusterClusterConfigSecurityConfigKerberosConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigSecurityConfigKerberosConfigOutput() ClusterClusterConfigSecurityConfigKerberosConfigOutput
	ToClusterClusterConfigSecurityConfigKerberosConfigOutputWithContext(context.Context) ClusterClusterConfigSecurityConfigKerberosConfigOutput
}

type ClusterClusterConfigSecurityConfigKerberosConfigArgs struct {
	// The admin server (IP or hostname) for the
	// remote trusted realm in a cross realm trust relationship.
	CrossRealmTrustAdminServer pulumi.StringPtrInput `pulumi:"crossRealmTrustAdminServer"`
	// The KDC (IP or hostname) for the
	// remote trusted realm in a cross realm trust relationship.
	CrossRealmTrustKdc pulumi.StringPtrInput `pulumi:"crossRealmTrustKdc"`
	// The remote realm the Dataproc on-cluster KDC will
	// trust, should the user enable cross realm trust.
	CrossRealmTrustRealm pulumi.StringPtrInput `pulumi:"crossRealmTrustRealm"`
	// The Cloud Storage URI of a KMS
	// encrypted file containing the shared password between the on-cluster Kerberos realm
	// and the remote trusted realm, in a cross realm trust relationship.
	CrossRealmTrustSharedPasswordUri pulumi.StringPtrInput `pulumi:"crossRealmTrustSharedPasswordUri"`
	// Flag to indicate whether to Kerberize the cluster.
	EnableKerberos pulumi.BoolPtrInput `pulumi:"enableKerberos"`
	// The Cloud Storage URI of a KMS encrypted file containing
	// the master key of the KDC database.
	KdcDbKeyUri pulumi.StringPtrInput `pulumi:"kdcDbKeyUri"`
	// The Cloud Storage URI of a KMS encrypted file containing
	// the password to the user provided key. For the self-signed certificate, this password
	// is generated by Dataproc.
	KeyPasswordUri pulumi.StringPtrInput `pulumi:"keyPasswordUri"`
	// The Cloud Storage URI of a KMS encrypted file containing
	// the password to the user provided keystore. For the self-signed certificated, the password
	// is generated by Dataproc.
	KeystorePasswordUri pulumi.StringPtrInput `pulumi:"keystorePasswordUri"`
	// The Cloud Storage URI of the keystore file used for SSL encryption.
	// If not provided, Dataproc will provide a self-signed certificate.
	KeystoreUri pulumi.StringPtrInput `pulumi:"keystoreUri"`
	// The URI of the KMS key used to encrypt various sensitive files.
	KmsKeyUri pulumi.StringInput `pulumi:"kmsKeyUri"`
	// The name of the on-cluster Kerberos realm. If not specified, the
	// uppercased domain of hostnames will be the realm.
	Realm pulumi.StringPtrInput `pulumi:"realm"`
	// The Cloud Storage URI of a KMS encrypted file
	// containing the root principal password.
	RootPrincipalPasswordUri pulumi.StringInput `pulumi:"rootPrincipalPasswordUri"`
	// The lifetime of the ticket granting ticket, in hours.
	TgtLifetimeHours pulumi.IntPtrInput `pulumi:"tgtLifetimeHours"`
	// The Cloud Storage URI of a KMS encrypted file
	// containing the password to the user provided truststore. For the self-signed
	// certificate, this password is generated by Dataproc.
	TruststorePasswordUri pulumi.StringPtrInput `pulumi:"truststorePasswordUri"`
	// The Cloud Storage URI of the truststore file used for
	// SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
	TruststoreUri pulumi.StringPtrInput `pulumi:"truststoreUri"`
}

func (ClusterClusterConfigSecurityConfigKerberosConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigSecurityConfigKerberosConfig)(nil)).Elem()
}

func (i ClusterClusterConfigSecurityConfigKerberosConfigArgs) ToClusterClusterConfigSecurityConfigKerberosConfigOutput() ClusterClusterConfigSecurityConfigKerberosConfigOutput {
	return i.ToClusterClusterConfigSecurityConfigKerberosConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigSecurityConfigKerberosConfigArgs) ToClusterClusterConfigSecurityConfigKerberosConfigOutputWithContext(ctx context.Context) ClusterClusterConfigSecurityConfigKerberosConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigSecurityConfigKerberosConfigOutput)
}

func (i ClusterClusterConfigSecurityConfigKerberosConfigArgs) ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutput() ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput {
	return i.ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigSecurityConfigKerberosConfigArgs) ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigSecurityConfigKerberosConfigOutput).ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigSecurityConfigKerberosConfigPtrInput is an input type that accepts ClusterClusterConfigSecurityConfigKerberosConfigArgs, ClusterClusterConfigSecurityConfigKerberosConfigPtr and ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigSecurityConfigKerberosConfigPtrInput` via:
//
// 		 ClusterClusterConfigSecurityConfigKerberosConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigSecurityConfigKerberosConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutput() ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput
	ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutputWithContext(context.Context) ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput
}

type clusterClusterConfigSecurityConfigKerberosConfigPtrType ClusterClusterConfigSecurityConfigKerberosConfigArgs

func ClusterClusterConfigSecurityConfigKerberosConfigPtr(v *ClusterClusterConfigSecurityConfigKerberosConfigArgs) ClusterClusterConfigSecurityConfigKerberosConfigPtrInput {
	return (*clusterClusterConfigSecurityConfigKerberosConfigPtrType)(v)
}

func (*clusterClusterConfigSecurityConfigKerberosConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigSecurityConfigKerberosConfig)(nil)).Elem()
}

func (i *clusterClusterConfigSecurityConfigKerberosConfigPtrType) ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutput() ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput {
	return i.ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigSecurityConfigKerberosConfigPtrType) ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput)
}

type ClusterClusterConfigSecurityConfigKerberosConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigSecurityConfigKerberosConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigSecurityConfigKerberosConfig)(nil)).Elem()
}

func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) ToClusterClusterConfigSecurityConfigKerberosConfigOutput() ClusterClusterConfigSecurityConfigKerberosConfigOutput {
	return o
}

func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) ToClusterClusterConfigSecurityConfigKerberosConfigOutputWithContext(ctx context.Context) ClusterClusterConfigSecurityConfigKerberosConfigOutput {
	return o
}

func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutput() ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput {
	return o.ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *ClusterClusterConfigSecurityConfigKerberosConfig {
		return &v
	}).(ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput)
}

// The admin server (IP or hostname) for the
// remote trusted realm in a cross realm trust relationship.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) CrossRealmTrustAdminServer() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *string { return v.CrossRealmTrustAdminServer }).(pulumi.StringPtrOutput)
}

// The KDC (IP or hostname) for the
// remote trusted realm in a cross realm trust relationship.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) CrossRealmTrustKdc() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *string { return v.CrossRealmTrustKdc }).(pulumi.StringPtrOutput)
}

// The remote realm the Dataproc on-cluster KDC will
// trust, should the user enable cross realm trust.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) CrossRealmTrustRealm() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *string { return v.CrossRealmTrustRealm }).(pulumi.StringPtrOutput)
}

// The Cloud Storage URI of a KMS
// encrypted file containing the shared password between the on-cluster Kerberos realm
// and the remote trusted realm, in a cross realm trust relationship.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) CrossRealmTrustSharedPasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		return v.CrossRealmTrustSharedPasswordUri
	}).(pulumi.StringPtrOutput)
}

// Flag to indicate whether to Kerberize the cluster.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) EnableKerberos() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *bool { return v.EnableKerberos }).(pulumi.BoolPtrOutput)
}

// The Cloud Storage URI of a KMS encrypted file containing
// the master key of the KDC database.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) KdcDbKeyUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *string { return v.KdcDbKeyUri }).(pulumi.StringPtrOutput)
}

// The Cloud Storage URI of a KMS encrypted file containing
// the password to the user provided key. For the self-signed certificate, this password
// is generated by Dataproc.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) KeyPasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *string { return v.KeyPasswordUri }).(pulumi.StringPtrOutput)
}

// The Cloud Storage URI of a KMS encrypted file containing
// the password to the user provided keystore. For the self-signed certificated, the password
// is generated by Dataproc.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) KeystorePasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *string { return v.KeystorePasswordUri }).(pulumi.StringPtrOutput)
}

// The Cloud Storage URI of the keystore file used for SSL encryption.
// If not provided, Dataproc will provide a self-signed certificate.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) KeystoreUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *string { return v.KeystoreUri }).(pulumi.StringPtrOutput)
}

// The URI of the KMS key used to encrypt various sensitive files.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) KmsKeyUri() pulumi.StringOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) string { return v.KmsKeyUri }).(pulumi.StringOutput)
}

// The name of the on-cluster Kerberos realm. If not specified, the
// uppercased domain of hostnames will be the realm.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) Realm() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *string { return v.Realm }).(pulumi.StringPtrOutput)
}

// The Cloud Storage URI of a KMS encrypted file
// containing the root principal password.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) RootPrincipalPasswordUri() pulumi.StringOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) string { return v.RootPrincipalPasswordUri }).(pulumi.StringOutput)
}

// The lifetime of the ticket granting ticket, in hours.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) TgtLifetimeHours() pulumi.IntPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *int { return v.TgtLifetimeHours }).(pulumi.IntPtrOutput)
}

// The Cloud Storage URI of a KMS encrypted file
// containing the password to the user provided truststore. For the self-signed
// certificate, this password is generated by Dataproc.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) TruststorePasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *string { return v.TruststorePasswordUri }).(pulumi.StringPtrOutput)
}

// The Cloud Storage URI of the truststore file used for
// SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
func (o ClusterClusterConfigSecurityConfigKerberosConfigOutput) TruststoreUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSecurityConfigKerberosConfig) *string { return v.TruststoreUri }).(pulumi.StringPtrOutput)
}

type ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigSecurityConfigKerberosConfig)(nil)).Elem()
}

func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutput() ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) ToClusterClusterConfigSecurityConfigKerberosConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) Elem() ClusterClusterConfigSecurityConfigKerberosConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) ClusterClusterConfigSecurityConfigKerberosConfig {
		return *v
	}).(ClusterClusterConfigSecurityConfigKerberosConfigOutput)
}

// The admin server (IP or hostname) for the
// remote trusted realm in a cross realm trust relationship.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) CrossRealmTrustAdminServer() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.CrossRealmTrustAdminServer
	}).(pulumi.StringPtrOutput)
}

// The KDC (IP or hostname) for the
// remote trusted realm in a cross realm trust relationship.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) CrossRealmTrustKdc() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.CrossRealmTrustKdc
	}).(pulumi.StringPtrOutput)
}

// The remote realm the Dataproc on-cluster KDC will
// trust, should the user enable cross realm trust.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) CrossRealmTrustRealm() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.CrossRealmTrustRealm
	}).(pulumi.StringPtrOutput)
}

// The Cloud Storage URI of a KMS
// encrypted file containing the shared password between the on-cluster Kerberos realm
// and the remote trusted realm, in a cross realm trust relationship.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) CrossRealmTrustSharedPasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.CrossRealmTrustSharedPasswordUri
	}).(pulumi.StringPtrOutput)
}

// Flag to indicate whether to Kerberize the cluster.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) EnableKerberos() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EnableKerberos
	}).(pulumi.BoolPtrOutput)
}

// The Cloud Storage URI of a KMS encrypted file containing
// the master key of the KDC database.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) KdcDbKeyUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.KdcDbKeyUri
	}).(pulumi.StringPtrOutput)
}

// The Cloud Storage URI of a KMS encrypted file containing
// the password to the user provided key. For the self-signed certificate, this password
// is generated by Dataproc.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) KeyPasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.KeyPasswordUri
	}).(pulumi.StringPtrOutput)
}

// The Cloud Storage URI of a KMS encrypted file containing
// the password to the user provided keystore. For the self-signed certificated, the password
// is generated by Dataproc.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) KeystorePasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.KeystorePasswordUri
	}).(pulumi.StringPtrOutput)
}

// The Cloud Storage URI of the keystore file used for SSL encryption.
// If not provided, Dataproc will provide a self-signed certificate.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) KeystoreUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.KeystoreUri
	}).(pulumi.StringPtrOutput)
}

// The URI of the KMS key used to encrypt various sensitive files.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) KmsKeyUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyUri
	}).(pulumi.StringPtrOutput)
}

// The name of the on-cluster Kerberos realm. If not specified, the
// uppercased domain of hostnames will be the realm.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) Realm() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.Realm
	}).(pulumi.StringPtrOutput)
}

// The Cloud Storage URI of a KMS encrypted file
// containing the root principal password.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) RootPrincipalPasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return &v.RootPrincipalPasswordUri
	}).(pulumi.StringPtrOutput)
}

// The lifetime of the ticket granting ticket, in hours.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) TgtLifetimeHours() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *int {
		if v == nil {
			return nil
		}
		return v.TgtLifetimeHours
	}).(pulumi.IntPtrOutput)
}

// The Cloud Storage URI of a KMS encrypted file
// containing the password to the user provided truststore. For the self-signed
// certificate, this password is generated by Dataproc.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) TruststorePasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.TruststorePasswordUri
	}).(pulumi.StringPtrOutput)
}

// The Cloud Storage URI of the truststore file used for
// SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
func (o ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput) TruststoreUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSecurityConfigKerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.TruststoreUri
	}).(pulumi.StringPtrOutput)
}

type ClusterClusterConfigSoftwareConfig struct {
	// The Cloud Dataproc image version to use
	// for the cluster - this controls the sets of software versions
	// installed onto the nodes when you create clusters. If not specified, defaults to the
	// latest version. For a list of valid versions see
	// [Cloud Dataproc versions](https://cloud.google.com/dataproc/docs/concepts/dataproc-versions)
	ImageVersion *string `pulumi:"imageVersion"`
	// The set of optional components to activate on the cluster.
	// Accepted values are:
	// * ANACONDA
	// * DRUID
	// * HIVE_WEBHCAT
	// * JUPYTER
	// * KERBEROS
	// * PRESTO
	// * ZEPPELIN
	// * ZOOKEEPER
	OptionalComponents []string `pulumi:"optionalComponents"`
	// A list of override and additional properties (key/value pairs)
	// used to modify various aspects of the common configuration files used when creating
	// a cluster. For a list of valid properties please see
	// [Cluster properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties)
	OverrideProperties map[string]string      `pulumi:"overrideProperties"`
	Properties         map[string]interface{} `pulumi:"properties"`
}

// ClusterClusterConfigSoftwareConfigInput is an input type that accepts ClusterClusterConfigSoftwareConfigArgs and ClusterClusterConfigSoftwareConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigSoftwareConfigInput` via:
//
// 		 ClusterClusterConfigSoftwareConfigArgs{...}
//
type ClusterClusterConfigSoftwareConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigSoftwareConfigOutput() ClusterClusterConfigSoftwareConfigOutput
	ToClusterClusterConfigSoftwareConfigOutputWithContext(context.Context) ClusterClusterConfigSoftwareConfigOutput
}

type ClusterClusterConfigSoftwareConfigArgs struct {
	// The Cloud Dataproc image version to use
	// for the cluster - this controls the sets of software versions
	// installed onto the nodes when you create clusters. If not specified, defaults to the
	// latest version. For a list of valid versions see
	// [Cloud Dataproc versions](https://cloud.google.com/dataproc/docs/concepts/dataproc-versions)
	ImageVersion pulumi.StringPtrInput `pulumi:"imageVersion"`
	// The set of optional components to activate on the cluster.
	// Accepted values are:
	// * ANACONDA
	// * DRUID
	// * HIVE_WEBHCAT
	// * JUPYTER
	// * KERBEROS
	// * PRESTO
	// * ZEPPELIN
	// * ZOOKEEPER
	OptionalComponents pulumi.StringArrayInput `pulumi:"optionalComponents"`
	// A list of override and additional properties (key/value pairs)
	// used to modify various aspects of the common configuration files used when creating
	// a cluster. For a list of valid properties please see
	// [Cluster properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties)
	OverrideProperties pulumi.StringMapInput `pulumi:"overrideProperties"`
	Properties         pulumi.MapInput       `pulumi:"properties"`
}

func (ClusterClusterConfigSoftwareConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigSoftwareConfig)(nil)).Elem()
}

func (i ClusterClusterConfigSoftwareConfigArgs) ToClusterClusterConfigSoftwareConfigOutput() ClusterClusterConfigSoftwareConfigOutput {
	return i.ToClusterClusterConfigSoftwareConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigSoftwareConfigArgs) ToClusterClusterConfigSoftwareConfigOutputWithContext(ctx context.Context) ClusterClusterConfigSoftwareConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigSoftwareConfigOutput)
}

func (i ClusterClusterConfigSoftwareConfigArgs) ToClusterClusterConfigSoftwareConfigPtrOutput() ClusterClusterConfigSoftwareConfigPtrOutput {
	return i.ToClusterClusterConfigSoftwareConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigSoftwareConfigArgs) ToClusterClusterConfigSoftwareConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigSoftwareConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigSoftwareConfigOutput).ToClusterClusterConfigSoftwareConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigSoftwareConfigPtrInput is an input type that accepts ClusterClusterConfigSoftwareConfigArgs, ClusterClusterConfigSoftwareConfigPtr and ClusterClusterConfigSoftwareConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigSoftwareConfigPtrInput` via:
//
// 		 ClusterClusterConfigSoftwareConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigSoftwareConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigSoftwareConfigPtrOutput() ClusterClusterConfigSoftwareConfigPtrOutput
	ToClusterClusterConfigSoftwareConfigPtrOutputWithContext(context.Context) ClusterClusterConfigSoftwareConfigPtrOutput
}

type clusterClusterConfigSoftwareConfigPtrType ClusterClusterConfigSoftwareConfigArgs

func ClusterClusterConfigSoftwareConfigPtr(v *ClusterClusterConfigSoftwareConfigArgs) ClusterClusterConfigSoftwareConfigPtrInput {
	return (*clusterClusterConfigSoftwareConfigPtrType)(v)
}

func (*clusterClusterConfigSoftwareConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigSoftwareConfig)(nil)).Elem()
}

func (i *clusterClusterConfigSoftwareConfigPtrType) ToClusterClusterConfigSoftwareConfigPtrOutput() ClusterClusterConfigSoftwareConfigPtrOutput {
	return i.ToClusterClusterConfigSoftwareConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigSoftwareConfigPtrType) ToClusterClusterConfigSoftwareConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigSoftwareConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigSoftwareConfigPtrOutput)
}

type ClusterClusterConfigSoftwareConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigSoftwareConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigSoftwareConfig)(nil)).Elem()
}

func (o ClusterClusterConfigSoftwareConfigOutput) ToClusterClusterConfigSoftwareConfigOutput() ClusterClusterConfigSoftwareConfigOutput {
	return o
}

func (o ClusterClusterConfigSoftwareConfigOutput) ToClusterClusterConfigSoftwareConfigOutputWithContext(ctx context.Context) ClusterClusterConfigSoftwareConfigOutput {
	return o
}

func (o ClusterClusterConfigSoftwareConfigOutput) ToClusterClusterConfigSoftwareConfigPtrOutput() ClusterClusterConfigSoftwareConfigPtrOutput {
	return o.ToClusterClusterConfigSoftwareConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigSoftwareConfigOutput) ToClusterClusterConfigSoftwareConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigSoftwareConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSoftwareConfig) *ClusterClusterConfigSoftwareConfig {
		return &v
	}).(ClusterClusterConfigSoftwareConfigPtrOutput)
}

// The Cloud Dataproc image version to use
// for the cluster - this controls the sets of software versions
// installed onto the nodes when you create clusters. If not specified, defaults to the
// latest version. For a list of valid versions see
// [Cloud Dataproc versions](https://cloud.google.com/dataproc/docs/concepts/dataproc-versions)
func (o ClusterClusterConfigSoftwareConfigOutput) ImageVersion() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigSoftwareConfig) *string { return v.ImageVersion }).(pulumi.StringPtrOutput)
}

// The set of optional components to activate on the cluster.
// Accepted values are:
// * ANACONDA
// * DRUID
// * HIVE_WEBHCAT
// * JUPYTER
// * KERBEROS
// * PRESTO
// * ZEPPELIN
// * ZOOKEEPER
func (o ClusterClusterConfigSoftwareConfigOutput) OptionalComponents() pulumi.StringArrayOutput {
	return o.ApplyT(func(v ClusterClusterConfigSoftwareConfig) []string { return v.OptionalComponents }).(pulumi.StringArrayOutput)
}

// A list of override and additional properties (key/value pairs)
// used to modify various aspects of the common configuration files used when creating
// a cluster. For a list of valid properties please see
// [Cluster properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties)
func (o ClusterClusterConfigSoftwareConfigOutput) OverrideProperties() pulumi.StringMapOutput {
	return o.ApplyT(func(v ClusterClusterConfigSoftwareConfig) map[string]string { return v.OverrideProperties }).(pulumi.StringMapOutput)
}

func (o ClusterClusterConfigSoftwareConfigOutput) Properties() pulumi.MapOutput {
	return o.ApplyT(func(v ClusterClusterConfigSoftwareConfig) map[string]interface{} { return v.Properties }).(pulumi.MapOutput)
}

type ClusterClusterConfigSoftwareConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigSoftwareConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigSoftwareConfig)(nil)).Elem()
}

func (o ClusterClusterConfigSoftwareConfigPtrOutput) ToClusterClusterConfigSoftwareConfigPtrOutput() ClusterClusterConfigSoftwareConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigSoftwareConfigPtrOutput) ToClusterClusterConfigSoftwareConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigSoftwareConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigSoftwareConfigPtrOutput) Elem() ClusterClusterConfigSoftwareConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSoftwareConfig) ClusterClusterConfigSoftwareConfig { return *v }).(ClusterClusterConfigSoftwareConfigOutput)
}

// The Cloud Dataproc image version to use
// for the cluster - this controls the sets of software versions
// installed onto the nodes when you create clusters. If not specified, defaults to the
// latest version. For a list of valid versions see
// [Cloud Dataproc versions](https://cloud.google.com/dataproc/docs/concepts/dataproc-versions)
func (o ClusterClusterConfigSoftwareConfigPtrOutput) ImageVersion() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSoftwareConfig) *string {
		if v == nil {
			return nil
		}
		return v.ImageVersion
	}).(pulumi.StringPtrOutput)
}

// The set of optional components to activate on the cluster.
// Accepted values are:
// * ANACONDA
// * DRUID
// * HIVE_WEBHCAT
// * JUPYTER
// * KERBEROS
// * PRESTO
// * ZEPPELIN
// * ZOOKEEPER
func (o ClusterClusterConfigSoftwareConfigPtrOutput) OptionalComponents() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSoftwareConfig) []string {
		if v == nil {
			return nil
		}
		return v.OptionalComponents
	}).(pulumi.StringArrayOutput)
}

// A list of override and additional properties (key/value pairs)
// used to modify various aspects of the common configuration files used when creating
// a cluster. For a list of valid properties please see
// [Cluster properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties)
func (o ClusterClusterConfigSoftwareConfigPtrOutput) OverrideProperties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSoftwareConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.OverrideProperties
	}).(pulumi.StringMapOutput)
}

func (o ClusterClusterConfigSoftwareConfigPtrOutput) Properties() pulumi.MapOutput {
	return o.ApplyT(func(v *ClusterClusterConfigSoftwareConfig) map[string]interface{} {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.MapOutput)
}

type ClusterClusterConfigWorkerConfig struct {
	// The Compute Engine accelerator configuration for these instances. Can be specified multiple times.
	Accelerators []ClusterClusterConfigWorkerConfigAccelerator `pulumi:"accelerators"`
	// Disk Config
	DiskConfig *ClusterClusterConfigWorkerConfigDiskConfig `pulumi:"diskConfig"`
	// The URI for the image to use for this worker.  See [the guide](https://cloud.google.com/dataproc/docs/guides/dataproc-images)
	// for more information.
	ImageUri      *string  `pulumi:"imageUri"`
	InstanceNames []string `pulumi:"instanceNames"`
	// The name of a Google Compute Engine machine type
	// to create for the worker nodes. If not specified, GCP will default to a predetermined
	// computed value (currently `n1-standard-4`).
	MachineType *string `pulumi:"machineType"`
	// The name of a minimum generation of CPU family
	// for the master. If not specified, GCP will default to a predetermined computed value
	// for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
	// for details about which CPU families are available (and defaulted) for each zone.
	MinCpuPlatform *string `pulumi:"minCpuPlatform"`
	// Specifies the number of preemptible nodes to create.
	// Defaults to 0.
	NumInstances *int `pulumi:"numInstances"`
}

// ClusterClusterConfigWorkerConfigInput is an input type that accepts ClusterClusterConfigWorkerConfigArgs and ClusterClusterConfigWorkerConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigWorkerConfigInput` via:
//
// 		 ClusterClusterConfigWorkerConfigArgs{...}
//
type ClusterClusterConfigWorkerConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigWorkerConfigOutput() ClusterClusterConfigWorkerConfigOutput
	ToClusterClusterConfigWorkerConfigOutputWithContext(context.Context) ClusterClusterConfigWorkerConfigOutput
}

type ClusterClusterConfigWorkerConfigArgs struct {
	// The Compute Engine accelerator configuration for these instances. Can be specified multiple times.
	Accelerators ClusterClusterConfigWorkerConfigAcceleratorArrayInput `pulumi:"accelerators"`
	// Disk Config
	DiskConfig ClusterClusterConfigWorkerConfigDiskConfigPtrInput `pulumi:"diskConfig"`
	// The URI for the image to use for this worker.  See [the guide](https://cloud.google.com/dataproc/docs/guides/dataproc-images)
	// for more information.
	ImageUri      pulumi.StringPtrInput   `pulumi:"imageUri"`
	InstanceNames pulumi.StringArrayInput `pulumi:"instanceNames"`
	// The name of a Google Compute Engine machine type
	// to create for the worker nodes. If not specified, GCP will default to a predetermined
	// computed value (currently `n1-standard-4`).
	MachineType pulumi.StringPtrInput `pulumi:"machineType"`
	// The name of a minimum generation of CPU family
	// for the master. If not specified, GCP will default to a predetermined computed value
	// for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
	// for details about which CPU families are available (and defaulted) for each zone.
	MinCpuPlatform pulumi.StringPtrInput `pulumi:"minCpuPlatform"`
	// Specifies the number of preemptible nodes to create.
	// Defaults to 0.
	NumInstances pulumi.IntPtrInput `pulumi:"numInstances"`
}

func (ClusterClusterConfigWorkerConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigWorkerConfig)(nil)).Elem()
}

func (i ClusterClusterConfigWorkerConfigArgs) ToClusterClusterConfigWorkerConfigOutput() ClusterClusterConfigWorkerConfigOutput {
	return i.ToClusterClusterConfigWorkerConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigWorkerConfigArgs) ToClusterClusterConfigWorkerConfigOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigWorkerConfigOutput)
}

func (i ClusterClusterConfigWorkerConfigArgs) ToClusterClusterConfigWorkerConfigPtrOutput() ClusterClusterConfigWorkerConfigPtrOutput {
	return i.ToClusterClusterConfigWorkerConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigWorkerConfigArgs) ToClusterClusterConfigWorkerConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigWorkerConfigOutput).ToClusterClusterConfigWorkerConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigWorkerConfigPtrInput is an input type that accepts ClusterClusterConfigWorkerConfigArgs, ClusterClusterConfigWorkerConfigPtr and ClusterClusterConfigWorkerConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigWorkerConfigPtrInput` via:
//
// 		 ClusterClusterConfigWorkerConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigWorkerConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigWorkerConfigPtrOutput() ClusterClusterConfigWorkerConfigPtrOutput
	ToClusterClusterConfigWorkerConfigPtrOutputWithContext(context.Context) ClusterClusterConfigWorkerConfigPtrOutput
}

type clusterClusterConfigWorkerConfigPtrType ClusterClusterConfigWorkerConfigArgs

func ClusterClusterConfigWorkerConfigPtr(v *ClusterClusterConfigWorkerConfigArgs) ClusterClusterConfigWorkerConfigPtrInput {
	return (*clusterClusterConfigWorkerConfigPtrType)(v)
}

func (*clusterClusterConfigWorkerConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigWorkerConfig)(nil)).Elem()
}

func (i *clusterClusterConfigWorkerConfigPtrType) ToClusterClusterConfigWorkerConfigPtrOutput() ClusterClusterConfigWorkerConfigPtrOutput {
	return i.ToClusterClusterConfigWorkerConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigWorkerConfigPtrType) ToClusterClusterConfigWorkerConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigWorkerConfigPtrOutput)
}

type ClusterClusterConfigWorkerConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigWorkerConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigWorkerConfig)(nil)).Elem()
}

func (o ClusterClusterConfigWorkerConfigOutput) ToClusterClusterConfigWorkerConfigOutput() ClusterClusterConfigWorkerConfigOutput {
	return o
}

func (o ClusterClusterConfigWorkerConfigOutput) ToClusterClusterConfigWorkerConfigOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigOutput {
	return o
}

func (o ClusterClusterConfigWorkerConfigOutput) ToClusterClusterConfigWorkerConfigPtrOutput() ClusterClusterConfigWorkerConfigPtrOutput {
	return o.ToClusterClusterConfigWorkerConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigWorkerConfigOutput) ToClusterClusterConfigWorkerConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfig) *ClusterClusterConfigWorkerConfig {
		return &v
	}).(ClusterClusterConfigWorkerConfigPtrOutput)
}

// The Compute Engine accelerator configuration for these instances. Can be specified multiple times.
func (o ClusterClusterConfigWorkerConfigOutput) Accelerators() ClusterClusterConfigWorkerConfigAcceleratorArrayOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfig) []ClusterClusterConfigWorkerConfigAccelerator {
		return v.Accelerators
	}).(ClusterClusterConfigWorkerConfigAcceleratorArrayOutput)
}

// Disk Config
func (o ClusterClusterConfigWorkerConfigOutput) DiskConfig() ClusterClusterConfigWorkerConfigDiskConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfig) *ClusterClusterConfigWorkerConfigDiskConfig {
		return v.DiskConfig
	}).(ClusterClusterConfigWorkerConfigDiskConfigPtrOutput)
}

// The URI for the image to use for this worker.  See [the guide](https://cloud.google.com/dataproc/docs/guides/dataproc-images)
// for more information.
func (o ClusterClusterConfigWorkerConfigOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfig) *string { return v.ImageUri }).(pulumi.StringPtrOutput)
}

func (o ClusterClusterConfigWorkerConfigOutput) InstanceNames() pulumi.StringArrayOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfig) []string { return v.InstanceNames }).(pulumi.StringArrayOutput)
}

// The name of a Google Compute Engine machine type
// to create for the worker nodes. If not specified, GCP will default to a predetermined
// computed value (currently `n1-standard-4`).
func (o ClusterClusterConfigWorkerConfigOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfig) *string { return v.MachineType }).(pulumi.StringPtrOutput)
}

// The name of a minimum generation of CPU family
// for the master. If not specified, GCP will default to a predetermined computed value
// for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
// for details about which CPU families are available (and defaulted) for each zone.
func (o ClusterClusterConfigWorkerConfigOutput) MinCpuPlatform() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfig) *string { return v.MinCpuPlatform }).(pulumi.StringPtrOutput)
}

// Specifies the number of preemptible nodes to create.
// Defaults to 0.
func (o ClusterClusterConfigWorkerConfigOutput) NumInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfig) *int { return v.NumInstances }).(pulumi.IntPtrOutput)
}

type ClusterClusterConfigWorkerConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigWorkerConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigWorkerConfig)(nil)).Elem()
}

func (o ClusterClusterConfigWorkerConfigPtrOutput) ToClusterClusterConfigWorkerConfigPtrOutput() ClusterClusterConfigWorkerConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigWorkerConfigPtrOutput) ToClusterClusterConfigWorkerConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigWorkerConfigPtrOutput) Elem() ClusterClusterConfigWorkerConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigWorkerConfig) ClusterClusterConfigWorkerConfig { return *v }).(ClusterClusterConfigWorkerConfigOutput)
}

// The Compute Engine accelerator configuration for these instances. Can be specified multiple times.
func (o ClusterClusterConfigWorkerConfigPtrOutput) Accelerators() ClusterClusterConfigWorkerConfigAcceleratorArrayOutput {
	return o.ApplyT(func(v *ClusterClusterConfigWorkerConfig) []ClusterClusterConfigWorkerConfigAccelerator {
		if v == nil {
			return nil
		}
		return v.Accelerators
	}).(ClusterClusterConfigWorkerConfigAcceleratorArrayOutput)
}

// Disk Config
func (o ClusterClusterConfigWorkerConfigPtrOutput) DiskConfig() ClusterClusterConfigWorkerConfigDiskConfigPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigWorkerConfig) *ClusterClusterConfigWorkerConfigDiskConfig {
		if v == nil {
			return nil
		}
		return v.DiskConfig
	}).(ClusterClusterConfigWorkerConfigDiskConfigPtrOutput)
}

// The URI for the image to use for this worker.  See [the guide](https://cloud.google.com/dataproc/docs/guides/dataproc-images)
// for more information.
func (o ClusterClusterConfigWorkerConfigPtrOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigWorkerConfig) *string {
		if v == nil {
			return nil
		}
		return v.ImageUri
	}).(pulumi.StringPtrOutput)
}

func (o ClusterClusterConfigWorkerConfigPtrOutput) InstanceNames() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *ClusterClusterConfigWorkerConfig) []string {
		if v == nil {
			return nil
		}
		return v.InstanceNames
	}).(pulumi.StringArrayOutput)
}

// The name of a Google Compute Engine machine type
// to create for the worker nodes. If not specified, GCP will default to a predetermined
// computed value (currently `n1-standard-4`).
func (o ClusterClusterConfigWorkerConfigPtrOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigWorkerConfig) *string {
		if v == nil {
			return nil
		}
		return v.MachineType
	}).(pulumi.StringPtrOutput)
}

// The name of a minimum generation of CPU family
// for the master. If not specified, GCP will default to a predetermined computed value
// for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
// for details about which CPU families are available (and defaulted) for each zone.
func (o ClusterClusterConfigWorkerConfigPtrOutput) MinCpuPlatform() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigWorkerConfig) *string {
		if v == nil {
			return nil
		}
		return v.MinCpuPlatform
	}).(pulumi.StringPtrOutput)
}

// Specifies the number of preemptible nodes to create.
// Defaults to 0.
func (o ClusterClusterConfigWorkerConfigPtrOutput) NumInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigWorkerConfig) *int {
		if v == nil {
			return nil
		}
		return v.NumInstances
	}).(pulumi.IntPtrOutput)
}

type ClusterClusterConfigWorkerConfigAccelerator struct {
	// The number of the accelerator cards of this type exposed to this instance. Often restricted to one of `1`, `2`, `4`, or `8`.
	AcceleratorCount int `pulumi:"acceleratorCount"`
	// The short name of the accelerator type to expose to this instance. For example, `nvidia-tesla-k80`.
	AcceleratorType string `pulumi:"acceleratorType"`
}

// ClusterClusterConfigWorkerConfigAcceleratorInput is an input type that accepts ClusterClusterConfigWorkerConfigAcceleratorArgs and ClusterClusterConfigWorkerConfigAcceleratorOutput values.
// You can construct a concrete instance of `ClusterClusterConfigWorkerConfigAcceleratorInput` via:
//
// 		 ClusterClusterConfigWorkerConfigAcceleratorArgs{...}
//
type ClusterClusterConfigWorkerConfigAcceleratorInput interface {
	pulumi.Input

	ToClusterClusterConfigWorkerConfigAcceleratorOutput() ClusterClusterConfigWorkerConfigAcceleratorOutput
	ToClusterClusterConfigWorkerConfigAcceleratorOutputWithContext(context.Context) ClusterClusterConfigWorkerConfigAcceleratorOutput
}

type ClusterClusterConfigWorkerConfigAcceleratorArgs struct {
	// The number of the accelerator cards of this type exposed to this instance. Often restricted to one of `1`, `2`, `4`, or `8`.
	AcceleratorCount pulumi.IntInput `pulumi:"acceleratorCount"`
	// The short name of the accelerator type to expose to this instance. For example, `nvidia-tesla-k80`.
	AcceleratorType pulumi.StringInput `pulumi:"acceleratorType"`
}

func (ClusterClusterConfigWorkerConfigAcceleratorArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigWorkerConfigAccelerator)(nil)).Elem()
}

func (i ClusterClusterConfigWorkerConfigAcceleratorArgs) ToClusterClusterConfigWorkerConfigAcceleratorOutput() ClusterClusterConfigWorkerConfigAcceleratorOutput {
	return i.ToClusterClusterConfigWorkerConfigAcceleratorOutputWithContext(context.Background())
}

func (i ClusterClusterConfigWorkerConfigAcceleratorArgs) ToClusterClusterConfigWorkerConfigAcceleratorOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigAcceleratorOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigWorkerConfigAcceleratorOutput)
}

// ClusterClusterConfigWorkerConfigAcceleratorArrayInput is an input type that accepts ClusterClusterConfigWorkerConfigAcceleratorArray and ClusterClusterConfigWorkerConfigAcceleratorArrayOutput values.
// You can construct a concrete instance of `ClusterClusterConfigWorkerConfigAcceleratorArrayInput` via:
//
// 		 ClusterClusterConfigWorkerConfigAcceleratorArray{ ClusterClusterConfigWorkerConfigAcceleratorArgs{...} }
//
type ClusterClusterConfigWorkerConfigAcceleratorArrayInput interface {
	pulumi.Input

	ToClusterClusterConfigWorkerConfigAcceleratorArrayOutput() ClusterClusterConfigWorkerConfigAcceleratorArrayOutput
	ToClusterClusterConfigWorkerConfigAcceleratorArrayOutputWithContext(context.Context) ClusterClusterConfigWorkerConfigAcceleratorArrayOutput
}

type ClusterClusterConfigWorkerConfigAcceleratorArray []ClusterClusterConfigWorkerConfigAcceleratorInput

func (ClusterClusterConfigWorkerConfigAcceleratorArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]ClusterClusterConfigWorkerConfigAccelerator)(nil)).Elem()
}

func (i ClusterClusterConfigWorkerConfigAcceleratorArray) ToClusterClusterConfigWorkerConfigAcceleratorArrayOutput() ClusterClusterConfigWorkerConfigAcceleratorArrayOutput {
	return i.ToClusterClusterConfigWorkerConfigAcceleratorArrayOutputWithContext(context.Background())
}

func (i ClusterClusterConfigWorkerConfigAcceleratorArray) ToClusterClusterConfigWorkerConfigAcceleratorArrayOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigAcceleratorArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigWorkerConfigAcceleratorArrayOutput)
}

type ClusterClusterConfigWorkerConfigAcceleratorOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigWorkerConfigAcceleratorOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigWorkerConfigAccelerator)(nil)).Elem()
}

func (o ClusterClusterConfigWorkerConfigAcceleratorOutput) ToClusterClusterConfigWorkerConfigAcceleratorOutput() ClusterClusterConfigWorkerConfigAcceleratorOutput {
	return o
}

func (o ClusterClusterConfigWorkerConfigAcceleratorOutput) ToClusterClusterConfigWorkerConfigAcceleratorOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigAcceleratorOutput {
	return o
}

// The number of the accelerator cards of this type exposed to this instance. Often restricted to one of `1`, `2`, `4`, or `8`.
func (o ClusterClusterConfigWorkerConfigAcceleratorOutput) AcceleratorCount() pulumi.IntOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfigAccelerator) int { return v.AcceleratorCount }).(pulumi.IntOutput)
}

// The short name of the accelerator type to expose to this instance. For example, `nvidia-tesla-k80`.
func (o ClusterClusterConfigWorkerConfigAcceleratorOutput) AcceleratorType() pulumi.StringOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfigAccelerator) string { return v.AcceleratorType }).(pulumi.StringOutput)
}

type ClusterClusterConfigWorkerConfigAcceleratorArrayOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigWorkerConfigAcceleratorArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]ClusterClusterConfigWorkerConfigAccelerator)(nil)).Elem()
}

func (o ClusterClusterConfigWorkerConfigAcceleratorArrayOutput) ToClusterClusterConfigWorkerConfigAcceleratorArrayOutput() ClusterClusterConfigWorkerConfigAcceleratorArrayOutput {
	return o
}

func (o ClusterClusterConfigWorkerConfigAcceleratorArrayOutput) ToClusterClusterConfigWorkerConfigAcceleratorArrayOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigAcceleratorArrayOutput {
	return o
}

func (o ClusterClusterConfigWorkerConfigAcceleratorArrayOutput) Index(i pulumi.IntInput) ClusterClusterConfigWorkerConfigAcceleratorOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) ClusterClusterConfigWorkerConfigAccelerator {
		return vs[0].([]ClusterClusterConfigWorkerConfigAccelerator)[vs[1].(int)]
	}).(ClusterClusterConfigWorkerConfigAcceleratorOutput)
}

type ClusterClusterConfigWorkerConfigDiskConfig struct {
	// Size of the primary disk attached to each preemptible worker node, specified
	// in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
	// computed value if not set (currently 500GB). Note: If SSDs are not
	// attached, it also contains the HDFS data blocks and Hadoop working directories.
	BootDiskSizeGb *int `pulumi:"bootDiskSizeGb"`
	// The disk type of the primary disk attached to each preemptible worker node.
	// One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
	BootDiskType *string `pulumi:"bootDiskType"`
	// The amount of local SSD disks that will be
	// attached to each preemptible worker node. Defaults to 0.
	NumLocalSsds *int `pulumi:"numLocalSsds"`
}

// ClusterClusterConfigWorkerConfigDiskConfigInput is an input type that accepts ClusterClusterConfigWorkerConfigDiskConfigArgs and ClusterClusterConfigWorkerConfigDiskConfigOutput values.
// You can construct a concrete instance of `ClusterClusterConfigWorkerConfigDiskConfigInput` via:
//
// 		 ClusterClusterConfigWorkerConfigDiskConfigArgs{...}
//
type ClusterClusterConfigWorkerConfigDiskConfigInput interface {
	pulumi.Input

	ToClusterClusterConfigWorkerConfigDiskConfigOutput() ClusterClusterConfigWorkerConfigDiskConfigOutput
	ToClusterClusterConfigWorkerConfigDiskConfigOutputWithContext(context.Context) ClusterClusterConfigWorkerConfigDiskConfigOutput
}

type ClusterClusterConfigWorkerConfigDiskConfigArgs struct {
	// Size of the primary disk attached to each preemptible worker node, specified
	// in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
	// computed value if not set (currently 500GB). Note: If SSDs are not
	// attached, it also contains the HDFS data blocks and Hadoop working directories.
	BootDiskSizeGb pulumi.IntPtrInput `pulumi:"bootDiskSizeGb"`
	// The disk type of the primary disk attached to each preemptible worker node.
	// One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
	BootDiskType pulumi.StringPtrInput `pulumi:"bootDiskType"`
	// The amount of local SSD disks that will be
	// attached to each preemptible worker node. Defaults to 0.
	NumLocalSsds pulumi.IntPtrInput `pulumi:"numLocalSsds"`
}

func (ClusterClusterConfigWorkerConfigDiskConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigWorkerConfigDiskConfig)(nil)).Elem()
}

func (i ClusterClusterConfigWorkerConfigDiskConfigArgs) ToClusterClusterConfigWorkerConfigDiskConfigOutput() ClusterClusterConfigWorkerConfigDiskConfigOutput {
	return i.ToClusterClusterConfigWorkerConfigDiskConfigOutputWithContext(context.Background())
}

func (i ClusterClusterConfigWorkerConfigDiskConfigArgs) ToClusterClusterConfigWorkerConfigDiskConfigOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigDiskConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigWorkerConfigDiskConfigOutput)
}

func (i ClusterClusterConfigWorkerConfigDiskConfigArgs) ToClusterClusterConfigWorkerConfigDiskConfigPtrOutput() ClusterClusterConfigWorkerConfigDiskConfigPtrOutput {
	return i.ToClusterClusterConfigWorkerConfigDiskConfigPtrOutputWithContext(context.Background())
}

func (i ClusterClusterConfigWorkerConfigDiskConfigArgs) ToClusterClusterConfigWorkerConfigDiskConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigDiskConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigWorkerConfigDiskConfigOutput).ToClusterClusterConfigWorkerConfigDiskConfigPtrOutputWithContext(ctx)
}

// ClusterClusterConfigWorkerConfigDiskConfigPtrInput is an input type that accepts ClusterClusterConfigWorkerConfigDiskConfigArgs, ClusterClusterConfigWorkerConfigDiskConfigPtr and ClusterClusterConfigWorkerConfigDiskConfigPtrOutput values.
// You can construct a concrete instance of `ClusterClusterConfigWorkerConfigDiskConfigPtrInput` via:
//
// 		 ClusterClusterConfigWorkerConfigDiskConfigArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterClusterConfigWorkerConfigDiskConfigPtrInput interface {
	pulumi.Input

	ToClusterClusterConfigWorkerConfigDiskConfigPtrOutput() ClusterClusterConfigWorkerConfigDiskConfigPtrOutput
	ToClusterClusterConfigWorkerConfigDiskConfigPtrOutputWithContext(context.Context) ClusterClusterConfigWorkerConfigDiskConfigPtrOutput
}

type clusterClusterConfigWorkerConfigDiskConfigPtrType ClusterClusterConfigWorkerConfigDiskConfigArgs

func ClusterClusterConfigWorkerConfigDiskConfigPtr(v *ClusterClusterConfigWorkerConfigDiskConfigArgs) ClusterClusterConfigWorkerConfigDiskConfigPtrInput {
	return (*clusterClusterConfigWorkerConfigDiskConfigPtrType)(v)
}

func (*clusterClusterConfigWorkerConfigDiskConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigWorkerConfigDiskConfig)(nil)).Elem()
}

func (i *clusterClusterConfigWorkerConfigDiskConfigPtrType) ToClusterClusterConfigWorkerConfigDiskConfigPtrOutput() ClusterClusterConfigWorkerConfigDiskConfigPtrOutput {
	return i.ToClusterClusterConfigWorkerConfigDiskConfigPtrOutputWithContext(context.Background())
}

func (i *clusterClusterConfigWorkerConfigDiskConfigPtrType) ToClusterClusterConfigWorkerConfigDiskConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigDiskConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterClusterConfigWorkerConfigDiskConfigPtrOutput)
}

type ClusterClusterConfigWorkerConfigDiskConfigOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigWorkerConfigDiskConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterClusterConfigWorkerConfigDiskConfig)(nil)).Elem()
}

func (o ClusterClusterConfigWorkerConfigDiskConfigOutput) ToClusterClusterConfigWorkerConfigDiskConfigOutput() ClusterClusterConfigWorkerConfigDiskConfigOutput {
	return o
}

func (o ClusterClusterConfigWorkerConfigDiskConfigOutput) ToClusterClusterConfigWorkerConfigDiskConfigOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigDiskConfigOutput {
	return o
}

func (o ClusterClusterConfigWorkerConfigDiskConfigOutput) ToClusterClusterConfigWorkerConfigDiskConfigPtrOutput() ClusterClusterConfigWorkerConfigDiskConfigPtrOutput {
	return o.ToClusterClusterConfigWorkerConfigDiskConfigPtrOutputWithContext(context.Background())
}

func (o ClusterClusterConfigWorkerConfigDiskConfigOutput) ToClusterClusterConfigWorkerConfigDiskConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigDiskConfigPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfigDiskConfig) *ClusterClusterConfigWorkerConfigDiskConfig {
		return &v
	}).(ClusterClusterConfigWorkerConfigDiskConfigPtrOutput)
}

// Size of the primary disk attached to each preemptible worker node, specified
// in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
// computed value if not set (currently 500GB). Note: If SSDs are not
// attached, it also contains the HDFS data blocks and Hadoop working directories.
func (o ClusterClusterConfigWorkerConfigDiskConfigOutput) BootDiskSizeGb() pulumi.IntPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfigDiskConfig) *int { return v.BootDiskSizeGb }).(pulumi.IntPtrOutput)
}

// The disk type of the primary disk attached to each preemptible worker node.
// One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
func (o ClusterClusterConfigWorkerConfigDiskConfigOutput) BootDiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfigDiskConfig) *string { return v.BootDiskType }).(pulumi.StringPtrOutput)
}

// The amount of local SSD disks that will be
// attached to each preemptible worker node. Defaults to 0.
func (o ClusterClusterConfigWorkerConfigDiskConfigOutput) NumLocalSsds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v ClusterClusterConfigWorkerConfigDiskConfig) *int { return v.NumLocalSsds }).(pulumi.IntPtrOutput)
}

type ClusterClusterConfigWorkerConfigDiskConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterClusterConfigWorkerConfigDiskConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterClusterConfigWorkerConfigDiskConfig)(nil)).Elem()
}

func (o ClusterClusterConfigWorkerConfigDiskConfigPtrOutput) ToClusterClusterConfigWorkerConfigDiskConfigPtrOutput() ClusterClusterConfigWorkerConfigDiskConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigWorkerConfigDiskConfigPtrOutput) ToClusterClusterConfigWorkerConfigDiskConfigPtrOutputWithContext(ctx context.Context) ClusterClusterConfigWorkerConfigDiskConfigPtrOutput {
	return o
}

func (o ClusterClusterConfigWorkerConfigDiskConfigPtrOutput) Elem() ClusterClusterConfigWorkerConfigDiskConfigOutput {
	return o.ApplyT(func(v *ClusterClusterConfigWorkerConfigDiskConfig) ClusterClusterConfigWorkerConfigDiskConfig {
		return *v
	}).(ClusterClusterConfigWorkerConfigDiskConfigOutput)
}

// Size of the primary disk attached to each preemptible worker node, specified
// in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
// computed value if not set (currently 500GB). Note: If SSDs are not
// attached, it also contains the HDFS data blocks and Hadoop working directories.
func (o ClusterClusterConfigWorkerConfigDiskConfigPtrOutput) BootDiskSizeGb() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigWorkerConfigDiskConfig) *int {
		if v == nil {
			return nil
		}
		return v.BootDiskSizeGb
	}).(pulumi.IntPtrOutput)
}

// The disk type of the primary disk attached to each preemptible worker node.
// One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
func (o ClusterClusterConfigWorkerConfigDiskConfigPtrOutput) BootDiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigWorkerConfigDiskConfig) *string {
		if v == nil {
			return nil
		}
		return v.BootDiskType
	}).(pulumi.StringPtrOutput)
}

// The amount of local SSD disks that will be
// attached to each preemptible worker node. Defaults to 0.
func (o ClusterClusterConfigWorkerConfigDiskConfigPtrOutput) NumLocalSsds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *ClusterClusterConfigWorkerConfigDiskConfig) *int {
		if v == nil {
			return nil
		}
		return v.NumLocalSsds
	}).(pulumi.IntPtrOutput)
}

type ClusterIAMBindingCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// ClusterIAMBindingConditionInput is an input type that accepts ClusterIAMBindingConditionArgs and ClusterIAMBindingConditionOutput values.
// You can construct a concrete instance of `ClusterIAMBindingConditionInput` via:
//
// 		 ClusterIAMBindingConditionArgs{...}
//
type ClusterIAMBindingConditionInput interface {
	pulumi.Input

	ToClusterIAMBindingConditionOutput() ClusterIAMBindingConditionOutput
	ToClusterIAMBindingConditionOutputWithContext(context.Context) ClusterIAMBindingConditionOutput
}

type ClusterIAMBindingConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (ClusterIAMBindingConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterIAMBindingCondition)(nil)).Elem()
}

func (i ClusterIAMBindingConditionArgs) ToClusterIAMBindingConditionOutput() ClusterIAMBindingConditionOutput {
	return i.ToClusterIAMBindingConditionOutputWithContext(context.Background())
}

func (i ClusterIAMBindingConditionArgs) ToClusterIAMBindingConditionOutputWithContext(ctx context.Context) ClusterIAMBindingConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterIAMBindingConditionOutput)
}

func (i ClusterIAMBindingConditionArgs) ToClusterIAMBindingConditionPtrOutput() ClusterIAMBindingConditionPtrOutput {
	return i.ToClusterIAMBindingConditionPtrOutputWithContext(context.Background())
}

func (i ClusterIAMBindingConditionArgs) ToClusterIAMBindingConditionPtrOutputWithContext(ctx context.Context) ClusterIAMBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterIAMBindingConditionOutput).ToClusterIAMBindingConditionPtrOutputWithContext(ctx)
}

// ClusterIAMBindingConditionPtrInput is an input type that accepts ClusterIAMBindingConditionArgs, ClusterIAMBindingConditionPtr and ClusterIAMBindingConditionPtrOutput values.
// You can construct a concrete instance of `ClusterIAMBindingConditionPtrInput` via:
//
// 		 ClusterIAMBindingConditionArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterIAMBindingConditionPtrInput interface {
	pulumi.Input

	ToClusterIAMBindingConditionPtrOutput() ClusterIAMBindingConditionPtrOutput
	ToClusterIAMBindingConditionPtrOutputWithContext(context.Context) ClusterIAMBindingConditionPtrOutput
}

type clusterIAMBindingConditionPtrType ClusterIAMBindingConditionArgs

func ClusterIAMBindingConditionPtr(v *ClusterIAMBindingConditionArgs) ClusterIAMBindingConditionPtrInput {
	return (*clusterIAMBindingConditionPtrType)(v)
}

func (*clusterIAMBindingConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterIAMBindingCondition)(nil)).Elem()
}

func (i *clusterIAMBindingConditionPtrType) ToClusterIAMBindingConditionPtrOutput() ClusterIAMBindingConditionPtrOutput {
	return i.ToClusterIAMBindingConditionPtrOutputWithContext(context.Background())
}

func (i *clusterIAMBindingConditionPtrType) ToClusterIAMBindingConditionPtrOutputWithContext(ctx context.Context) ClusterIAMBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterIAMBindingConditionPtrOutput)
}

type ClusterIAMBindingConditionOutput struct{ *pulumi.OutputState }

func (ClusterIAMBindingConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterIAMBindingCondition)(nil)).Elem()
}

func (o ClusterIAMBindingConditionOutput) ToClusterIAMBindingConditionOutput() ClusterIAMBindingConditionOutput {
	return o
}

func (o ClusterIAMBindingConditionOutput) ToClusterIAMBindingConditionOutputWithContext(ctx context.Context) ClusterIAMBindingConditionOutput {
	return o
}

func (o ClusterIAMBindingConditionOutput) ToClusterIAMBindingConditionPtrOutput() ClusterIAMBindingConditionPtrOutput {
	return o.ToClusterIAMBindingConditionPtrOutputWithContext(context.Background())
}

func (o ClusterIAMBindingConditionOutput) ToClusterIAMBindingConditionPtrOutputWithContext(ctx context.Context) ClusterIAMBindingConditionPtrOutput {
	return o.ApplyT(func(v ClusterIAMBindingCondition) *ClusterIAMBindingCondition {
		return &v
	}).(ClusterIAMBindingConditionPtrOutput)
}
func (o ClusterIAMBindingConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterIAMBindingCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o ClusterIAMBindingConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v ClusterIAMBindingCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o ClusterIAMBindingConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v ClusterIAMBindingCondition) string { return v.Title }).(pulumi.StringOutput)
}

type ClusterIAMBindingConditionPtrOutput struct{ *pulumi.OutputState }

func (ClusterIAMBindingConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterIAMBindingCondition)(nil)).Elem()
}

func (o ClusterIAMBindingConditionPtrOutput) ToClusterIAMBindingConditionPtrOutput() ClusterIAMBindingConditionPtrOutput {
	return o
}

func (o ClusterIAMBindingConditionPtrOutput) ToClusterIAMBindingConditionPtrOutputWithContext(ctx context.Context) ClusterIAMBindingConditionPtrOutput {
	return o
}

func (o ClusterIAMBindingConditionPtrOutput) Elem() ClusterIAMBindingConditionOutput {
	return o.ApplyT(func(v *ClusterIAMBindingCondition) ClusterIAMBindingCondition { return *v }).(ClusterIAMBindingConditionOutput)
}

func (o ClusterIAMBindingConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterIAMBindingCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o ClusterIAMBindingConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterIAMBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o ClusterIAMBindingConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterIAMBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type ClusterIAMMemberCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// ClusterIAMMemberConditionInput is an input type that accepts ClusterIAMMemberConditionArgs and ClusterIAMMemberConditionOutput values.
// You can construct a concrete instance of `ClusterIAMMemberConditionInput` via:
//
// 		 ClusterIAMMemberConditionArgs{...}
//
type ClusterIAMMemberConditionInput interface {
	pulumi.Input

	ToClusterIAMMemberConditionOutput() ClusterIAMMemberConditionOutput
	ToClusterIAMMemberConditionOutputWithContext(context.Context) ClusterIAMMemberConditionOutput
}

type ClusterIAMMemberConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (ClusterIAMMemberConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterIAMMemberCondition)(nil)).Elem()
}

func (i ClusterIAMMemberConditionArgs) ToClusterIAMMemberConditionOutput() ClusterIAMMemberConditionOutput {
	return i.ToClusterIAMMemberConditionOutputWithContext(context.Background())
}

func (i ClusterIAMMemberConditionArgs) ToClusterIAMMemberConditionOutputWithContext(ctx context.Context) ClusterIAMMemberConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterIAMMemberConditionOutput)
}

func (i ClusterIAMMemberConditionArgs) ToClusterIAMMemberConditionPtrOutput() ClusterIAMMemberConditionPtrOutput {
	return i.ToClusterIAMMemberConditionPtrOutputWithContext(context.Background())
}

func (i ClusterIAMMemberConditionArgs) ToClusterIAMMemberConditionPtrOutputWithContext(ctx context.Context) ClusterIAMMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterIAMMemberConditionOutput).ToClusterIAMMemberConditionPtrOutputWithContext(ctx)
}

// ClusterIAMMemberConditionPtrInput is an input type that accepts ClusterIAMMemberConditionArgs, ClusterIAMMemberConditionPtr and ClusterIAMMemberConditionPtrOutput values.
// You can construct a concrete instance of `ClusterIAMMemberConditionPtrInput` via:
//
// 		 ClusterIAMMemberConditionArgs{...}
//
//  or:
//
// 		 nil
//
type ClusterIAMMemberConditionPtrInput interface {
	pulumi.Input

	ToClusterIAMMemberConditionPtrOutput() ClusterIAMMemberConditionPtrOutput
	ToClusterIAMMemberConditionPtrOutputWithContext(context.Context) ClusterIAMMemberConditionPtrOutput
}

type clusterIAMMemberConditionPtrType ClusterIAMMemberConditionArgs

func ClusterIAMMemberConditionPtr(v *ClusterIAMMemberConditionArgs) ClusterIAMMemberConditionPtrInput {
	return (*clusterIAMMemberConditionPtrType)(v)
}

func (*clusterIAMMemberConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterIAMMemberCondition)(nil)).Elem()
}

func (i *clusterIAMMemberConditionPtrType) ToClusterIAMMemberConditionPtrOutput() ClusterIAMMemberConditionPtrOutput {
	return i.ToClusterIAMMemberConditionPtrOutputWithContext(context.Background())
}

func (i *clusterIAMMemberConditionPtrType) ToClusterIAMMemberConditionPtrOutputWithContext(ctx context.Context) ClusterIAMMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterIAMMemberConditionPtrOutput)
}

type ClusterIAMMemberConditionOutput struct{ *pulumi.OutputState }

func (ClusterIAMMemberConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterIAMMemberCondition)(nil)).Elem()
}

func (o ClusterIAMMemberConditionOutput) ToClusterIAMMemberConditionOutput() ClusterIAMMemberConditionOutput {
	return o
}

func (o ClusterIAMMemberConditionOutput) ToClusterIAMMemberConditionOutputWithContext(ctx context.Context) ClusterIAMMemberConditionOutput {
	return o
}

func (o ClusterIAMMemberConditionOutput) ToClusterIAMMemberConditionPtrOutput() ClusterIAMMemberConditionPtrOutput {
	return o.ToClusterIAMMemberConditionPtrOutputWithContext(context.Background())
}

func (o ClusterIAMMemberConditionOutput) ToClusterIAMMemberConditionPtrOutputWithContext(ctx context.Context) ClusterIAMMemberConditionPtrOutput {
	return o.ApplyT(func(v ClusterIAMMemberCondition) *ClusterIAMMemberCondition {
		return &v
	}).(ClusterIAMMemberConditionPtrOutput)
}
func (o ClusterIAMMemberConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterIAMMemberCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o ClusterIAMMemberConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v ClusterIAMMemberCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o ClusterIAMMemberConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v ClusterIAMMemberCondition) string { return v.Title }).(pulumi.StringOutput)
}

type ClusterIAMMemberConditionPtrOutput struct{ *pulumi.OutputState }

func (ClusterIAMMemberConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterIAMMemberCondition)(nil)).Elem()
}

func (o ClusterIAMMemberConditionPtrOutput) ToClusterIAMMemberConditionPtrOutput() ClusterIAMMemberConditionPtrOutput {
	return o
}

func (o ClusterIAMMemberConditionPtrOutput) ToClusterIAMMemberConditionPtrOutputWithContext(ctx context.Context) ClusterIAMMemberConditionPtrOutput {
	return o
}

func (o ClusterIAMMemberConditionPtrOutput) Elem() ClusterIAMMemberConditionOutput {
	return o.ApplyT(func(v *ClusterIAMMemberCondition) ClusterIAMMemberCondition { return *v }).(ClusterIAMMemberConditionOutput)
}

func (o ClusterIAMMemberConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterIAMMemberCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o ClusterIAMMemberConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterIAMMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o ClusterIAMMemberConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterIAMMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type JobHadoopConfig struct {
	// HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
	ArchiveUris []string `pulumi:"archiveUris"`
	// The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args []string `pulumi:"args"`
	// HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
	FileUris []string `pulumi:"fileUris"`
	// HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris   []string                      `pulumi:"jarFileUris"`
	LoggingConfig *JobHadoopConfigLoggingConfig `pulumi:"loggingConfig"`
	// The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jarFileUris`. Conflicts with `mainJarFileUri`
	MainClass *string `pulumi:"mainClass"`
	// The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'. Conflicts with `mainClass`
	MainJarFileUri *string `pulumi:"mainJarFileUri"`
	// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
	Properties map[string]string `pulumi:"properties"`
}

// JobHadoopConfigInput is an input type that accepts JobHadoopConfigArgs and JobHadoopConfigOutput values.
// You can construct a concrete instance of `JobHadoopConfigInput` via:
//
// 		 JobHadoopConfigArgs{...}
//
type JobHadoopConfigInput interface {
	pulumi.Input

	ToJobHadoopConfigOutput() JobHadoopConfigOutput
	ToJobHadoopConfigOutputWithContext(context.Context) JobHadoopConfigOutput
}

type JobHadoopConfigArgs struct {
	// HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
	ArchiveUris pulumi.StringArrayInput `pulumi:"archiveUris"`
	// The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args pulumi.StringArrayInput `pulumi:"args"`
	// HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
	FileUris pulumi.StringArrayInput `pulumi:"fileUris"`
	// HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris   pulumi.StringArrayInput              `pulumi:"jarFileUris"`
	LoggingConfig JobHadoopConfigLoggingConfigPtrInput `pulumi:"loggingConfig"`
	// The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jarFileUris`. Conflicts with `mainJarFileUri`
	MainClass pulumi.StringPtrInput `pulumi:"mainClass"`
	// The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'. Conflicts with `mainClass`
	MainJarFileUri pulumi.StringPtrInput `pulumi:"mainJarFileUri"`
	// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
	Properties pulumi.StringMapInput `pulumi:"properties"`
}

func (JobHadoopConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobHadoopConfig)(nil)).Elem()
}

func (i JobHadoopConfigArgs) ToJobHadoopConfigOutput() JobHadoopConfigOutput {
	return i.ToJobHadoopConfigOutputWithContext(context.Background())
}

func (i JobHadoopConfigArgs) ToJobHadoopConfigOutputWithContext(ctx context.Context) JobHadoopConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobHadoopConfigOutput)
}

func (i JobHadoopConfigArgs) ToJobHadoopConfigPtrOutput() JobHadoopConfigPtrOutput {
	return i.ToJobHadoopConfigPtrOutputWithContext(context.Background())
}

func (i JobHadoopConfigArgs) ToJobHadoopConfigPtrOutputWithContext(ctx context.Context) JobHadoopConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobHadoopConfigOutput).ToJobHadoopConfigPtrOutputWithContext(ctx)
}

// JobHadoopConfigPtrInput is an input type that accepts JobHadoopConfigArgs, JobHadoopConfigPtr and JobHadoopConfigPtrOutput values.
// You can construct a concrete instance of `JobHadoopConfigPtrInput` via:
//
// 		 JobHadoopConfigArgs{...}
//
//  or:
//
// 		 nil
//
type JobHadoopConfigPtrInput interface {
	pulumi.Input

	ToJobHadoopConfigPtrOutput() JobHadoopConfigPtrOutput
	ToJobHadoopConfigPtrOutputWithContext(context.Context) JobHadoopConfigPtrOutput
}

type jobHadoopConfigPtrType JobHadoopConfigArgs

func JobHadoopConfigPtr(v *JobHadoopConfigArgs) JobHadoopConfigPtrInput {
	return (*jobHadoopConfigPtrType)(v)
}

func (*jobHadoopConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobHadoopConfig)(nil)).Elem()
}

func (i *jobHadoopConfigPtrType) ToJobHadoopConfigPtrOutput() JobHadoopConfigPtrOutput {
	return i.ToJobHadoopConfigPtrOutputWithContext(context.Background())
}

func (i *jobHadoopConfigPtrType) ToJobHadoopConfigPtrOutputWithContext(ctx context.Context) JobHadoopConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobHadoopConfigPtrOutput)
}

type JobHadoopConfigOutput struct{ *pulumi.OutputState }

func (JobHadoopConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobHadoopConfig)(nil)).Elem()
}

func (o JobHadoopConfigOutput) ToJobHadoopConfigOutput() JobHadoopConfigOutput {
	return o
}

func (o JobHadoopConfigOutput) ToJobHadoopConfigOutputWithContext(ctx context.Context) JobHadoopConfigOutput {
	return o
}

func (o JobHadoopConfigOutput) ToJobHadoopConfigPtrOutput() JobHadoopConfigPtrOutput {
	return o.ToJobHadoopConfigPtrOutputWithContext(context.Background())
}

func (o JobHadoopConfigOutput) ToJobHadoopConfigPtrOutputWithContext(ctx context.Context) JobHadoopConfigPtrOutput {
	return o.ApplyT(func(v JobHadoopConfig) *JobHadoopConfig {
		return &v
	}).(JobHadoopConfigPtrOutput)
}

// HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
func (o JobHadoopConfigOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobHadoopConfig) []string { return v.ArchiveUris }).(pulumi.StringArrayOutput)
}

// The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o JobHadoopConfigOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobHadoopConfig) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
func (o JobHadoopConfigOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobHadoopConfig) []string { return v.FileUris }).(pulumi.StringArrayOutput)
}

// HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o JobHadoopConfigOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobHadoopConfig) []string { return v.JarFileUris }).(pulumi.StringArrayOutput)
}

func (o JobHadoopConfigOutput) LoggingConfig() JobHadoopConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v JobHadoopConfig) *JobHadoopConfigLoggingConfig { return v.LoggingConfig }).(JobHadoopConfigLoggingConfigPtrOutput)
}

// The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jarFileUris`. Conflicts with `mainJarFileUri`
func (o JobHadoopConfigOutput) MainClass() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobHadoopConfig) *string { return v.MainClass }).(pulumi.StringPtrOutput)
}

// The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'. Conflicts with `mainClass`
func (o JobHadoopConfigOutput) MainJarFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobHadoopConfig) *string { return v.MainJarFileUri }).(pulumi.StringPtrOutput)
}

// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
func (o JobHadoopConfigOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobHadoopConfig) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

type JobHadoopConfigPtrOutput struct{ *pulumi.OutputState }

func (JobHadoopConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobHadoopConfig)(nil)).Elem()
}

func (o JobHadoopConfigPtrOutput) ToJobHadoopConfigPtrOutput() JobHadoopConfigPtrOutput {
	return o
}

func (o JobHadoopConfigPtrOutput) ToJobHadoopConfigPtrOutputWithContext(ctx context.Context) JobHadoopConfigPtrOutput {
	return o
}

func (o JobHadoopConfigPtrOutput) Elem() JobHadoopConfigOutput {
	return o.ApplyT(func(v *JobHadoopConfig) JobHadoopConfig { return *v }).(JobHadoopConfigOutput)
}

// HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
func (o JobHadoopConfigPtrOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobHadoopConfig) []string {
		if v == nil {
			return nil
		}
		return v.ArchiveUris
	}).(pulumi.StringArrayOutput)
}

// The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o JobHadoopConfigPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobHadoopConfig) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
func (o JobHadoopConfigPtrOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobHadoopConfig) []string {
		if v == nil {
			return nil
		}
		return v.FileUris
	}).(pulumi.StringArrayOutput)
}

// HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o JobHadoopConfigPtrOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobHadoopConfig) []string {
		if v == nil {
			return nil
		}
		return v.JarFileUris
	}).(pulumi.StringArrayOutput)
}

func (o JobHadoopConfigPtrOutput) LoggingConfig() JobHadoopConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v *JobHadoopConfig) *JobHadoopConfigLoggingConfig {
		if v == nil {
			return nil
		}
		return v.LoggingConfig
	}).(JobHadoopConfigLoggingConfigPtrOutput)
}

// The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jarFileUris`. Conflicts with `mainJarFileUri`
func (o JobHadoopConfigPtrOutput) MainClass() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobHadoopConfig) *string {
		if v == nil {
			return nil
		}
		return v.MainClass
	}).(pulumi.StringPtrOutput)
}

// The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'. Conflicts with `mainClass`
func (o JobHadoopConfigPtrOutput) MainJarFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobHadoopConfig) *string {
		if v == nil {
			return nil
		}
		return v.MainJarFileUri
	}).(pulumi.StringPtrOutput)
}

// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
func (o JobHadoopConfigPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobHadoopConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

type JobHadoopConfigLoggingConfig struct {
	DriverLogLevels map[string]string `pulumi:"driverLogLevels"`
}

// JobHadoopConfigLoggingConfigInput is an input type that accepts JobHadoopConfigLoggingConfigArgs and JobHadoopConfigLoggingConfigOutput values.
// You can construct a concrete instance of `JobHadoopConfigLoggingConfigInput` via:
//
// 		 JobHadoopConfigLoggingConfigArgs{...}
//
type JobHadoopConfigLoggingConfigInput interface {
	pulumi.Input

	ToJobHadoopConfigLoggingConfigOutput() JobHadoopConfigLoggingConfigOutput
	ToJobHadoopConfigLoggingConfigOutputWithContext(context.Context) JobHadoopConfigLoggingConfigOutput
}

type JobHadoopConfigLoggingConfigArgs struct {
	DriverLogLevels pulumi.StringMapInput `pulumi:"driverLogLevels"`
}

func (JobHadoopConfigLoggingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobHadoopConfigLoggingConfig)(nil)).Elem()
}

func (i JobHadoopConfigLoggingConfigArgs) ToJobHadoopConfigLoggingConfigOutput() JobHadoopConfigLoggingConfigOutput {
	return i.ToJobHadoopConfigLoggingConfigOutputWithContext(context.Background())
}

func (i JobHadoopConfigLoggingConfigArgs) ToJobHadoopConfigLoggingConfigOutputWithContext(ctx context.Context) JobHadoopConfigLoggingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobHadoopConfigLoggingConfigOutput)
}

func (i JobHadoopConfigLoggingConfigArgs) ToJobHadoopConfigLoggingConfigPtrOutput() JobHadoopConfigLoggingConfigPtrOutput {
	return i.ToJobHadoopConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (i JobHadoopConfigLoggingConfigArgs) ToJobHadoopConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobHadoopConfigLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobHadoopConfigLoggingConfigOutput).ToJobHadoopConfigLoggingConfigPtrOutputWithContext(ctx)
}

// JobHadoopConfigLoggingConfigPtrInput is an input type that accepts JobHadoopConfigLoggingConfigArgs, JobHadoopConfigLoggingConfigPtr and JobHadoopConfigLoggingConfigPtrOutput values.
// You can construct a concrete instance of `JobHadoopConfigLoggingConfigPtrInput` via:
//
// 		 JobHadoopConfigLoggingConfigArgs{...}
//
//  or:
//
// 		 nil
//
type JobHadoopConfigLoggingConfigPtrInput interface {
	pulumi.Input

	ToJobHadoopConfigLoggingConfigPtrOutput() JobHadoopConfigLoggingConfigPtrOutput
	ToJobHadoopConfigLoggingConfigPtrOutputWithContext(context.Context) JobHadoopConfigLoggingConfigPtrOutput
}

type jobHadoopConfigLoggingConfigPtrType JobHadoopConfigLoggingConfigArgs

func JobHadoopConfigLoggingConfigPtr(v *JobHadoopConfigLoggingConfigArgs) JobHadoopConfigLoggingConfigPtrInput {
	return (*jobHadoopConfigLoggingConfigPtrType)(v)
}

func (*jobHadoopConfigLoggingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobHadoopConfigLoggingConfig)(nil)).Elem()
}

func (i *jobHadoopConfigLoggingConfigPtrType) ToJobHadoopConfigLoggingConfigPtrOutput() JobHadoopConfigLoggingConfigPtrOutput {
	return i.ToJobHadoopConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (i *jobHadoopConfigLoggingConfigPtrType) ToJobHadoopConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobHadoopConfigLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobHadoopConfigLoggingConfigPtrOutput)
}

type JobHadoopConfigLoggingConfigOutput struct{ *pulumi.OutputState }

func (JobHadoopConfigLoggingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobHadoopConfigLoggingConfig)(nil)).Elem()
}

func (o JobHadoopConfigLoggingConfigOutput) ToJobHadoopConfigLoggingConfigOutput() JobHadoopConfigLoggingConfigOutput {
	return o
}

func (o JobHadoopConfigLoggingConfigOutput) ToJobHadoopConfigLoggingConfigOutputWithContext(ctx context.Context) JobHadoopConfigLoggingConfigOutput {
	return o
}

func (o JobHadoopConfigLoggingConfigOutput) ToJobHadoopConfigLoggingConfigPtrOutput() JobHadoopConfigLoggingConfigPtrOutput {
	return o.ToJobHadoopConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (o JobHadoopConfigLoggingConfigOutput) ToJobHadoopConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobHadoopConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v JobHadoopConfigLoggingConfig) *JobHadoopConfigLoggingConfig {
		return &v
	}).(JobHadoopConfigLoggingConfigPtrOutput)
}
func (o JobHadoopConfigLoggingConfigOutput) DriverLogLevels() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobHadoopConfigLoggingConfig) map[string]string { return v.DriverLogLevels }).(pulumi.StringMapOutput)
}

type JobHadoopConfigLoggingConfigPtrOutput struct{ *pulumi.OutputState }

func (JobHadoopConfigLoggingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobHadoopConfigLoggingConfig)(nil)).Elem()
}

func (o JobHadoopConfigLoggingConfigPtrOutput) ToJobHadoopConfigLoggingConfigPtrOutput() JobHadoopConfigLoggingConfigPtrOutput {
	return o
}

func (o JobHadoopConfigLoggingConfigPtrOutput) ToJobHadoopConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobHadoopConfigLoggingConfigPtrOutput {
	return o
}

func (o JobHadoopConfigLoggingConfigPtrOutput) Elem() JobHadoopConfigLoggingConfigOutput {
	return o.ApplyT(func(v *JobHadoopConfigLoggingConfig) JobHadoopConfigLoggingConfig { return *v }).(JobHadoopConfigLoggingConfigOutput)
}

func (o JobHadoopConfigLoggingConfigPtrOutput) DriverLogLevels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobHadoopConfigLoggingConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.DriverLogLevels
	}).(pulumi.StringMapOutput)
}

type JobHiveConfig struct {
	// Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.
	ContinueOnFailure *bool `pulumi:"continueOnFailure"`
	// HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris []string `pulumi:"jarFileUris"`
	// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
	Properties map[string]string `pulumi:"properties"`
	// The HCFS URI of the script that contains SQL queries.
	// Conflicts with `queryList`
	QueryFileUri *string `pulumi:"queryFileUri"`
	// The list of SQL queries or statements to execute as part of the job.
	// Conflicts with `queryFileUri`
	QueryLists []string `pulumi:"queryLists"`
	// Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
	ScriptVariables map[string]string `pulumi:"scriptVariables"`
}

// JobHiveConfigInput is an input type that accepts JobHiveConfigArgs and JobHiveConfigOutput values.
// You can construct a concrete instance of `JobHiveConfigInput` via:
//
// 		 JobHiveConfigArgs{...}
//
type JobHiveConfigInput interface {
	pulumi.Input

	ToJobHiveConfigOutput() JobHiveConfigOutput
	ToJobHiveConfigOutputWithContext(context.Context) JobHiveConfigOutput
}

type JobHiveConfigArgs struct {
	// Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.
	ContinueOnFailure pulumi.BoolPtrInput `pulumi:"continueOnFailure"`
	// HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris pulumi.StringArrayInput `pulumi:"jarFileUris"`
	// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
	Properties pulumi.StringMapInput `pulumi:"properties"`
	// The HCFS URI of the script that contains SQL queries.
	// Conflicts with `queryList`
	QueryFileUri pulumi.StringPtrInput `pulumi:"queryFileUri"`
	// The list of SQL queries or statements to execute as part of the job.
	// Conflicts with `queryFileUri`
	QueryLists pulumi.StringArrayInput `pulumi:"queryLists"`
	// Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
	ScriptVariables pulumi.StringMapInput `pulumi:"scriptVariables"`
}

func (JobHiveConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobHiveConfig)(nil)).Elem()
}

func (i JobHiveConfigArgs) ToJobHiveConfigOutput() JobHiveConfigOutput {
	return i.ToJobHiveConfigOutputWithContext(context.Background())
}

func (i JobHiveConfigArgs) ToJobHiveConfigOutputWithContext(ctx context.Context) JobHiveConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobHiveConfigOutput)
}

func (i JobHiveConfigArgs) ToJobHiveConfigPtrOutput() JobHiveConfigPtrOutput {
	return i.ToJobHiveConfigPtrOutputWithContext(context.Background())
}

func (i JobHiveConfigArgs) ToJobHiveConfigPtrOutputWithContext(ctx context.Context) JobHiveConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobHiveConfigOutput).ToJobHiveConfigPtrOutputWithContext(ctx)
}

// JobHiveConfigPtrInput is an input type that accepts JobHiveConfigArgs, JobHiveConfigPtr and JobHiveConfigPtrOutput values.
// You can construct a concrete instance of `JobHiveConfigPtrInput` via:
//
// 		 JobHiveConfigArgs{...}
//
//  or:
//
// 		 nil
//
type JobHiveConfigPtrInput interface {
	pulumi.Input

	ToJobHiveConfigPtrOutput() JobHiveConfigPtrOutput
	ToJobHiveConfigPtrOutputWithContext(context.Context) JobHiveConfigPtrOutput
}

type jobHiveConfigPtrType JobHiveConfigArgs

func JobHiveConfigPtr(v *JobHiveConfigArgs) JobHiveConfigPtrInput {
	return (*jobHiveConfigPtrType)(v)
}

func (*jobHiveConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobHiveConfig)(nil)).Elem()
}

func (i *jobHiveConfigPtrType) ToJobHiveConfigPtrOutput() JobHiveConfigPtrOutput {
	return i.ToJobHiveConfigPtrOutputWithContext(context.Background())
}

func (i *jobHiveConfigPtrType) ToJobHiveConfigPtrOutputWithContext(ctx context.Context) JobHiveConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobHiveConfigPtrOutput)
}

type JobHiveConfigOutput struct{ *pulumi.OutputState }

func (JobHiveConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobHiveConfig)(nil)).Elem()
}

func (o JobHiveConfigOutput) ToJobHiveConfigOutput() JobHiveConfigOutput {
	return o
}

func (o JobHiveConfigOutput) ToJobHiveConfigOutputWithContext(ctx context.Context) JobHiveConfigOutput {
	return o
}

func (o JobHiveConfigOutput) ToJobHiveConfigPtrOutput() JobHiveConfigPtrOutput {
	return o.ToJobHiveConfigPtrOutputWithContext(context.Background())
}

func (o JobHiveConfigOutput) ToJobHiveConfigPtrOutputWithContext(ctx context.Context) JobHiveConfigPtrOutput {
	return o.ApplyT(func(v JobHiveConfig) *JobHiveConfig {
		return &v
	}).(JobHiveConfigPtrOutput)
}

// Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.
func (o JobHiveConfigOutput) ContinueOnFailure() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v JobHiveConfig) *bool { return v.ContinueOnFailure }).(pulumi.BoolPtrOutput)
}

// HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o JobHiveConfigOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobHiveConfig) []string { return v.JarFileUris }).(pulumi.StringArrayOutput)
}

// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
func (o JobHiveConfigOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobHiveConfig) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains SQL queries.
// Conflicts with `queryList`
func (o JobHiveConfigOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobHiveConfig) *string { return v.QueryFileUri }).(pulumi.StringPtrOutput)
}

// The list of SQL queries or statements to execute as part of the job.
// Conflicts with `queryFileUri`
func (o JobHiveConfigOutput) QueryLists() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobHiveConfig) []string { return v.QueryLists }).(pulumi.StringArrayOutput)
}

// Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
func (o JobHiveConfigOutput) ScriptVariables() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobHiveConfig) map[string]string { return v.ScriptVariables }).(pulumi.StringMapOutput)
}

type JobHiveConfigPtrOutput struct{ *pulumi.OutputState }

func (JobHiveConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobHiveConfig)(nil)).Elem()
}

func (o JobHiveConfigPtrOutput) ToJobHiveConfigPtrOutput() JobHiveConfigPtrOutput {
	return o
}

func (o JobHiveConfigPtrOutput) ToJobHiveConfigPtrOutputWithContext(ctx context.Context) JobHiveConfigPtrOutput {
	return o
}

func (o JobHiveConfigPtrOutput) Elem() JobHiveConfigOutput {
	return o.ApplyT(func(v *JobHiveConfig) JobHiveConfig { return *v }).(JobHiveConfigOutput)
}

// Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.
func (o JobHiveConfigPtrOutput) ContinueOnFailure() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *JobHiveConfig) *bool {
		if v == nil {
			return nil
		}
		return v.ContinueOnFailure
	}).(pulumi.BoolPtrOutput)
}

// HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o JobHiveConfigPtrOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobHiveConfig) []string {
		if v == nil {
			return nil
		}
		return v.JarFileUris
	}).(pulumi.StringArrayOutput)
}

// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
func (o JobHiveConfigPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobHiveConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains SQL queries.
// Conflicts with `queryList`
func (o JobHiveConfigPtrOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobHiveConfig) *string {
		if v == nil {
			return nil
		}
		return v.QueryFileUri
	}).(pulumi.StringPtrOutput)
}

// The list of SQL queries or statements to execute as part of the job.
// Conflicts with `queryFileUri`
func (o JobHiveConfigPtrOutput) QueryLists() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobHiveConfig) []string {
		if v == nil {
			return nil
		}
		return v.QueryLists
	}).(pulumi.StringArrayOutput)
}

// Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
func (o JobHiveConfigPtrOutput) ScriptVariables() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobHiveConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.ScriptVariables
	}).(pulumi.StringMapOutput)
}

type JobIAMBindingCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// JobIAMBindingConditionInput is an input type that accepts JobIAMBindingConditionArgs and JobIAMBindingConditionOutput values.
// You can construct a concrete instance of `JobIAMBindingConditionInput` via:
//
// 		 JobIAMBindingConditionArgs{...}
//
type JobIAMBindingConditionInput interface {
	pulumi.Input

	ToJobIAMBindingConditionOutput() JobIAMBindingConditionOutput
	ToJobIAMBindingConditionOutputWithContext(context.Context) JobIAMBindingConditionOutput
}

type JobIAMBindingConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (JobIAMBindingConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobIAMBindingCondition)(nil)).Elem()
}

func (i JobIAMBindingConditionArgs) ToJobIAMBindingConditionOutput() JobIAMBindingConditionOutput {
	return i.ToJobIAMBindingConditionOutputWithContext(context.Background())
}

func (i JobIAMBindingConditionArgs) ToJobIAMBindingConditionOutputWithContext(ctx context.Context) JobIAMBindingConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobIAMBindingConditionOutput)
}

func (i JobIAMBindingConditionArgs) ToJobIAMBindingConditionPtrOutput() JobIAMBindingConditionPtrOutput {
	return i.ToJobIAMBindingConditionPtrOutputWithContext(context.Background())
}

func (i JobIAMBindingConditionArgs) ToJobIAMBindingConditionPtrOutputWithContext(ctx context.Context) JobIAMBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobIAMBindingConditionOutput).ToJobIAMBindingConditionPtrOutputWithContext(ctx)
}

// JobIAMBindingConditionPtrInput is an input type that accepts JobIAMBindingConditionArgs, JobIAMBindingConditionPtr and JobIAMBindingConditionPtrOutput values.
// You can construct a concrete instance of `JobIAMBindingConditionPtrInput` via:
//
// 		 JobIAMBindingConditionArgs{...}
//
//  or:
//
// 		 nil
//
type JobIAMBindingConditionPtrInput interface {
	pulumi.Input

	ToJobIAMBindingConditionPtrOutput() JobIAMBindingConditionPtrOutput
	ToJobIAMBindingConditionPtrOutputWithContext(context.Context) JobIAMBindingConditionPtrOutput
}

type jobIAMBindingConditionPtrType JobIAMBindingConditionArgs

func JobIAMBindingConditionPtr(v *JobIAMBindingConditionArgs) JobIAMBindingConditionPtrInput {
	return (*jobIAMBindingConditionPtrType)(v)
}

func (*jobIAMBindingConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobIAMBindingCondition)(nil)).Elem()
}

func (i *jobIAMBindingConditionPtrType) ToJobIAMBindingConditionPtrOutput() JobIAMBindingConditionPtrOutput {
	return i.ToJobIAMBindingConditionPtrOutputWithContext(context.Background())
}

func (i *jobIAMBindingConditionPtrType) ToJobIAMBindingConditionPtrOutputWithContext(ctx context.Context) JobIAMBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobIAMBindingConditionPtrOutput)
}

type JobIAMBindingConditionOutput struct{ *pulumi.OutputState }

func (JobIAMBindingConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobIAMBindingCondition)(nil)).Elem()
}

func (o JobIAMBindingConditionOutput) ToJobIAMBindingConditionOutput() JobIAMBindingConditionOutput {
	return o
}

func (o JobIAMBindingConditionOutput) ToJobIAMBindingConditionOutputWithContext(ctx context.Context) JobIAMBindingConditionOutput {
	return o
}

func (o JobIAMBindingConditionOutput) ToJobIAMBindingConditionPtrOutput() JobIAMBindingConditionPtrOutput {
	return o.ToJobIAMBindingConditionPtrOutputWithContext(context.Background())
}

func (o JobIAMBindingConditionOutput) ToJobIAMBindingConditionPtrOutputWithContext(ctx context.Context) JobIAMBindingConditionPtrOutput {
	return o.ApplyT(func(v JobIAMBindingCondition) *JobIAMBindingCondition {
		return &v
	}).(JobIAMBindingConditionPtrOutput)
}
func (o JobIAMBindingConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobIAMBindingCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o JobIAMBindingConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v JobIAMBindingCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o JobIAMBindingConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v JobIAMBindingCondition) string { return v.Title }).(pulumi.StringOutput)
}

type JobIAMBindingConditionPtrOutput struct{ *pulumi.OutputState }

func (JobIAMBindingConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobIAMBindingCondition)(nil)).Elem()
}

func (o JobIAMBindingConditionPtrOutput) ToJobIAMBindingConditionPtrOutput() JobIAMBindingConditionPtrOutput {
	return o
}

func (o JobIAMBindingConditionPtrOutput) ToJobIAMBindingConditionPtrOutputWithContext(ctx context.Context) JobIAMBindingConditionPtrOutput {
	return o
}

func (o JobIAMBindingConditionPtrOutput) Elem() JobIAMBindingConditionOutput {
	return o.ApplyT(func(v *JobIAMBindingCondition) JobIAMBindingCondition { return *v }).(JobIAMBindingConditionOutput)
}

func (o JobIAMBindingConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobIAMBindingCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o JobIAMBindingConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobIAMBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o JobIAMBindingConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobIAMBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type JobIAMMemberCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// JobIAMMemberConditionInput is an input type that accepts JobIAMMemberConditionArgs and JobIAMMemberConditionOutput values.
// You can construct a concrete instance of `JobIAMMemberConditionInput` via:
//
// 		 JobIAMMemberConditionArgs{...}
//
type JobIAMMemberConditionInput interface {
	pulumi.Input

	ToJobIAMMemberConditionOutput() JobIAMMemberConditionOutput
	ToJobIAMMemberConditionOutputWithContext(context.Context) JobIAMMemberConditionOutput
}

type JobIAMMemberConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (JobIAMMemberConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobIAMMemberCondition)(nil)).Elem()
}

func (i JobIAMMemberConditionArgs) ToJobIAMMemberConditionOutput() JobIAMMemberConditionOutput {
	return i.ToJobIAMMemberConditionOutputWithContext(context.Background())
}

func (i JobIAMMemberConditionArgs) ToJobIAMMemberConditionOutputWithContext(ctx context.Context) JobIAMMemberConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobIAMMemberConditionOutput)
}

func (i JobIAMMemberConditionArgs) ToJobIAMMemberConditionPtrOutput() JobIAMMemberConditionPtrOutput {
	return i.ToJobIAMMemberConditionPtrOutputWithContext(context.Background())
}

func (i JobIAMMemberConditionArgs) ToJobIAMMemberConditionPtrOutputWithContext(ctx context.Context) JobIAMMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobIAMMemberConditionOutput).ToJobIAMMemberConditionPtrOutputWithContext(ctx)
}

// JobIAMMemberConditionPtrInput is an input type that accepts JobIAMMemberConditionArgs, JobIAMMemberConditionPtr and JobIAMMemberConditionPtrOutput values.
// You can construct a concrete instance of `JobIAMMemberConditionPtrInput` via:
//
// 		 JobIAMMemberConditionArgs{...}
//
//  or:
//
// 		 nil
//
type JobIAMMemberConditionPtrInput interface {
	pulumi.Input

	ToJobIAMMemberConditionPtrOutput() JobIAMMemberConditionPtrOutput
	ToJobIAMMemberConditionPtrOutputWithContext(context.Context) JobIAMMemberConditionPtrOutput
}

type jobIAMMemberConditionPtrType JobIAMMemberConditionArgs

func JobIAMMemberConditionPtr(v *JobIAMMemberConditionArgs) JobIAMMemberConditionPtrInput {
	return (*jobIAMMemberConditionPtrType)(v)
}

func (*jobIAMMemberConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobIAMMemberCondition)(nil)).Elem()
}

func (i *jobIAMMemberConditionPtrType) ToJobIAMMemberConditionPtrOutput() JobIAMMemberConditionPtrOutput {
	return i.ToJobIAMMemberConditionPtrOutputWithContext(context.Background())
}

func (i *jobIAMMemberConditionPtrType) ToJobIAMMemberConditionPtrOutputWithContext(ctx context.Context) JobIAMMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobIAMMemberConditionPtrOutput)
}

type JobIAMMemberConditionOutput struct{ *pulumi.OutputState }

func (JobIAMMemberConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobIAMMemberCondition)(nil)).Elem()
}

func (o JobIAMMemberConditionOutput) ToJobIAMMemberConditionOutput() JobIAMMemberConditionOutput {
	return o
}

func (o JobIAMMemberConditionOutput) ToJobIAMMemberConditionOutputWithContext(ctx context.Context) JobIAMMemberConditionOutput {
	return o
}

func (o JobIAMMemberConditionOutput) ToJobIAMMemberConditionPtrOutput() JobIAMMemberConditionPtrOutput {
	return o.ToJobIAMMemberConditionPtrOutputWithContext(context.Background())
}

func (o JobIAMMemberConditionOutput) ToJobIAMMemberConditionPtrOutputWithContext(ctx context.Context) JobIAMMemberConditionPtrOutput {
	return o.ApplyT(func(v JobIAMMemberCondition) *JobIAMMemberCondition {
		return &v
	}).(JobIAMMemberConditionPtrOutput)
}
func (o JobIAMMemberConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobIAMMemberCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o JobIAMMemberConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v JobIAMMemberCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o JobIAMMemberConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v JobIAMMemberCondition) string { return v.Title }).(pulumi.StringOutput)
}

type JobIAMMemberConditionPtrOutput struct{ *pulumi.OutputState }

func (JobIAMMemberConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobIAMMemberCondition)(nil)).Elem()
}

func (o JobIAMMemberConditionPtrOutput) ToJobIAMMemberConditionPtrOutput() JobIAMMemberConditionPtrOutput {
	return o
}

func (o JobIAMMemberConditionPtrOutput) ToJobIAMMemberConditionPtrOutputWithContext(ctx context.Context) JobIAMMemberConditionPtrOutput {
	return o
}

func (o JobIAMMemberConditionPtrOutput) Elem() JobIAMMemberConditionOutput {
	return o.ApplyT(func(v *JobIAMMemberCondition) JobIAMMemberCondition { return *v }).(JobIAMMemberConditionOutput)
}

func (o JobIAMMemberConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobIAMMemberCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o JobIAMMemberConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobIAMMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o JobIAMMemberConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobIAMMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type JobPigConfig struct {
	// Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.
	ContinueOnFailure *bool `pulumi:"continueOnFailure"`
	// HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris   []string                   `pulumi:"jarFileUris"`
	LoggingConfig *JobPigConfigLoggingConfig `pulumi:"loggingConfig"`
	// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
	Properties map[string]string `pulumi:"properties"`
	// The HCFS URI of the script that contains SQL queries.
	// Conflicts with `queryList`
	QueryFileUri *string `pulumi:"queryFileUri"`
	// The list of SQL queries or statements to execute as part of the job.
	// Conflicts with `queryFileUri`
	QueryLists []string `pulumi:"queryLists"`
	// Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
	ScriptVariables map[string]string `pulumi:"scriptVariables"`
}

// JobPigConfigInput is an input type that accepts JobPigConfigArgs and JobPigConfigOutput values.
// You can construct a concrete instance of `JobPigConfigInput` via:
//
// 		 JobPigConfigArgs{...}
//
type JobPigConfigInput interface {
	pulumi.Input

	ToJobPigConfigOutput() JobPigConfigOutput
	ToJobPigConfigOutputWithContext(context.Context) JobPigConfigOutput
}

type JobPigConfigArgs struct {
	// Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.
	ContinueOnFailure pulumi.BoolPtrInput `pulumi:"continueOnFailure"`
	// HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris   pulumi.StringArrayInput           `pulumi:"jarFileUris"`
	LoggingConfig JobPigConfigLoggingConfigPtrInput `pulumi:"loggingConfig"`
	// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
	Properties pulumi.StringMapInput `pulumi:"properties"`
	// The HCFS URI of the script that contains SQL queries.
	// Conflicts with `queryList`
	QueryFileUri pulumi.StringPtrInput `pulumi:"queryFileUri"`
	// The list of SQL queries or statements to execute as part of the job.
	// Conflicts with `queryFileUri`
	QueryLists pulumi.StringArrayInput `pulumi:"queryLists"`
	// Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
	ScriptVariables pulumi.StringMapInput `pulumi:"scriptVariables"`
}

func (JobPigConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobPigConfig)(nil)).Elem()
}

func (i JobPigConfigArgs) ToJobPigConfigOutput() JobPigConfigOutput {
	return i.ToJobPigConfigOutputWithContext(context.Background())
}

func (i JobPigConfigArgs) ToJobPigConfigOutputWithContext(ctx context.Context) JobPigConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPigConfigOutput)
}

func (i JobPigConfigArgs) ToJobPigConfigPtrOutput() JobPigConfigPtrOutput {
	return i.ToJobPigConfigPtrOutputWithContext(context.Background())
}

func (i JobPigConfigArgs) ToJobPigConfigPtrOutputWithContext(ctx context.Context) JobPigConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPigConfigOutput).ToJobPigConfigPtrOutputWithContext(ctx)
}

// JobPigConfigPtrInput is an input type that accepts JobPigConfigArgs, JobPigConfigPtr and JobPigConfigPtrOutput values.
// You can construct a concrete instance of `JobPigConfigPtrInput` via:
//
// 		 JobPigConfigArgs{...}
//
//  or:
//
// 		 nil
//
type JobPigConfigPtrInput interface {
	pulumi.Input

	ToJobPigConfigPtrOutput() JobPigConfigPtrOutput
	ToJobPigConfigPtrOutputWithContext(context.Context) JobPigConfigPtrOutput
}

type jobPigConfigPtrType JobPigConfigArgs

func JobPigConfigPtr(v *JobPigConfigArgs) JobPigConfigPtrInput {
	return (*jobPigConfigPtrType)(v)
}

func (*jobPigConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobPigConfig)(nil)).Elem()
}

func (i *jobPigConfigPtrType) ToJobPigConfigPtrOutput() JobPigConfigPtrOutput {
	return i.ToJobPigConfigPtrOutputWithContext(context.Background())
}

func (i *jobPigConfigPtrType) ToJobPigConfigPtrOutputWithContext(ctx context.Context) JobPigConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPigConfigPtrOutput)
}

type JobPigConfigOutput struct{ *pulumi.OutputState }

func (JobPigConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobPigConfig)(nil)).Elem()
}

func (o JobPigConfigOutput) ToJobPigConfigOutput() JobPigConfigOutput {
	return o
}

func (o JobPigConfigOutput) ToJobPigConfigOutputWithContext(ctx context.Context) JobPigConfigOutput {
	return o
}

func (o JobPigConfigOutput) ToJobPigConfigPtrOutput() JobPigConfigPtrOutput {
	return o.ToJobPigConfigPtrOutputWithContext(context.Background())
}

func (o JobPigConfigOutput) ToJobPigConfigPtrOutputWithContext(ctx context.Context) JobPigConfigPtrOutput {
	return o.ApplyT(func(v JobPigConfig) *JobPigConfig {
		return &v
	}).(JobPigConfigPtrOutput)
}

// Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.
func (o JobPigConfigOutput) ContinueOnFailure() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v JobPigConfig) *bool { return v.ContinueOnFailure }).(pulumi.BoolPtrOutput)
}

// HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o JobPigConfigOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobPigConfig) []string { return v.JarFileUris }).(pulumi.StringArrayOutput)
}

func (o JobPigConfigOutput) LoggingConfig() JobPigConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v JobPigConfig) *JobPigConfigLoggingConfig { return v.LoggingConfig }).(JobPigConfigLoggingConfigPtrOutput)
}

// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
func (o JobPigConfigOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobPigConfig) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains SQL queries.
// Conflicts with `queryList`
func (o JobPigConfigOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobPigConfig) *string { return v.QueryFileUri }).(pulumi.StringPtrOutput)
}

// The list of SQL queries or statements to execute as part of the job.
// Conflicts with `queryFileUri`
func (o JobPigConfigOutput) QueryLists() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobPigConfig) []string { return v.QueryLists }).(pulumi.StringArrayOutput)
}

// Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
func (o JobPigConfigOutput) ScriptVariables() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobPigConfig) map[string]string { return v.ScriptVariables }).(pulumi.StringMapOutput)
}

type JobPigConfigPtrOutput struct{ *pulumi.OutputState }

func (JobPigConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobPigConfig)(nil)).Elem()
}

func (o JobPigConfigPtrOutput) ToJobPigConfigPtrOutput() JobPigConfigPtrOutput {
	return o
}

func (o JobPigConfigPtrOutput) ToJobPigConfigPtrOutputWithContext(ctx context.Context) JobPigConfigPtrOutput {
	return o
}

func (o JobPigConfigPtrOutput) Elem() JobPigConfigOutput {
	return o.ApplyT(func(v *JobPigConfig) JobPigConfig { return *v }).(JobPigConfigOutput)
}

// Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.
func (o JobPigConfigPtrOutput) ContinueOnFailure() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *JobPigConfig) *bool {
		if v == nil {
			return nil
		}
		return v.ContinueOnFailure
	}).(pulumi.BoolPtrOutput)
}

// HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o JobPigConfigPtrOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobPigConfig) []string {
		if v == nil {
			return nil
		}
		return v.JarFileUris
	}).(pulumi.StringArrayOutput)
}

func (o JobPigConfigPtrOutput) LoggingConfig() JobPigConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v *JobPigConfig) *JobPigConfigLoggingConfig {
		if v == nil {
			return nil
		}
		return v.LoggingConfig
	}).(JobPigConfigLoggingConfigPtrOutput)
}

// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
func (o JobPigConfigPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobPigConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains SQL queries.
// Conflicts with `queryList`
func (o JobPigConfigPtrOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobPigConfig) *string {
		if v == nil {
			return nil
		}
		return v.QueryFileUri
	}).(pulumi.StringPtrOutput)
}

// The list of SQL queries or statements to execute as part of the job.
// Conflicts with `queryFileUri`
func (o JobPigConfigPtrOutput) QueryLists() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobPigConfig) []string {
		if v == nil {
			return nil
		}
		return v.QueryLists
	}).(pulumi.StringArrayOutput)
}

// Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
func (o JobPigConfigPtrOutput) ScriptVariables() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobPigConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.ScriptVariables
	}).(pulumi.StringMapOutput)
}

type JobPigConfigLoggingConfig struct {
	DriverLogLevels map[string]string `pulumi:"driverLogLevels"`
}

// JobPigConfigLoggingConfigInput is an input type that accepts JobPigConfigLoggingConfigArgs and JobPigConfigLoggingConfigOutput values.
// You can construct a concrete instance of `JobPigConfigLoggingConfigInput` via:
//
// 		 JobPigConfigLoggingConfigArgs{...}
//
type JobPigConfigLoggingConfigInput interface {
	pulumi.Input

	ToJobPigConfigLoggingConfigOutput() JobPigConfigLoggingConfigOutput
	ToJobPigConfigLoggingConfigOutputWithContext(context.Context) JobPigConfigLoggingConfigOutput
}

type JobPigConfigLoggingConfigArgs struct {
	DriverLogLevels pulumi.StringMapInput `pulumi:"driverLogLevels"`
}

func (JobPigConfigLoggingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobPigConfigLoggingConfig)(nil)).Elem()
}

func (i JobPigConfigLoggingConfigArgs) ToJobPigConfigLoggingConfigOutput() JobPigConfigLoggingConfigOutput {
	return i.ToJobPigConfigLoggingConfigOutputWithContext(context.Background())
}

func (i JobPigConfigLoggingConfigArgs) ToJobPigConfigLoggingConfigOutputWithContext(ctx context.Context) JobPigConfigLoggingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPigConfigLoggingConfigOutput)
}

func (i JobPigConfigLoggingConfigArgs) ToJobPigConfigLoggingConfigPtrOutput() JobPigConfigLoggingConfigPtrOutput {
	return i.ToJobPigConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (i JobPigConfigLoggingConfigArgs) ToJobPigConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobPigConfigLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPigConfigLoggingConfigOutput).ToJobPigConfigLoggingConfigPtrOutputWithContext(ctx)
}

// JobPigConfigLoggingConfigPtrInput is an input type that accepts JobPigConfigLoggingConfigArgs, JobPigConfigLoggingConfigPtr and JobPigConfigLoggingConfigPtrOutput values.
// You can construct a concrete instance of `JobPigConfigLoggingConfigPtrInput` via:
//
// 		 JobPigConfigLoggingConfigArgs{...}
//
//  or:
//
// 		 nil
//
type JobPigConfigLoggingConfigPtrInput interface {
	pulumi.Input

	ToJobPigConfigLoggingConfigPtrOutput() JobPigConfigLoggingConfigPtrOutput
	ToJobPigConfigLoggingConfigPtrOutputWithContext(context.Context) JobPigConfigLoggingConfigPtrOutput
}

type jobPigConfigLoggingConfigPtrType JobPigConfigLoggingConfigArgs

func JobPigConfigLoggingConfigPtr(v *JobPigConfigLoggingConfigArgs) JobPigConfigLoggingConfigPtrInput {
	return (*jobPigConfigLoggingConfigPtrType)(v)
}

func (*jobPigConfigLoggingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobPigConfigLoggingConfig)(nil)).Elem()
}

func (i *jobPigConfigLoggingConfigPtrType) ToJobPigConfigLoggingConfigPtrOutput() JobPigConfigLoggingConfigPtrOutput {
	return i.ToJobPigConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (i *jobPigConfigLoggingConfigPtrType) ToJobPigConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobPigConfigLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPigConfigLoggingConfigPtrOutput)
}

type JobPigConfigLoggingConfigOutput struct{ *pulumi.OutputState }

func (JobPigConfigLoggingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobPigConfigLoggingConfig)(nil)).Elem()
}

func (o JobPigConfigLoggingConfigOutput) ToJobPigConfigLoggingConfigOutput() JobPigConfigLoggingConfigOutput {
	return o
}

func (o JobPigConfigLoggingConfigOutput) ToJobPigConfigLoggingConfigOutputWithContext(ctx context.Context) JobPigConfigLoggingConfigOutput {
	return o
}

func (o JobPigConfigLoggingConfigOutput) ToJobPigConfigLoggingConfigPtrOutput() JobPigConfigLoggingConfigPtrOutput {
	return o.ToJobPigConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (o JobPigConfigLoggingConfigOutput) ToJobPigConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobPigConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v JobPigConfigLoggingConfig) *JobPigConfigLoggingConfig {
		return &v
	}).(JobPigConfigLoggingConfigPtrOutput)
}
func (o JobPigConfigLoggingConfigOutput) DriverLogLevels() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobPigConfigLoggingConfig) map[string]string { return v.DriverLogLevels }).(pulumi.StringMapOutput)
}

type JobPigConfigLoggingConfigPtrOutput struct{ *pulumi.OutputState }

func (JobPigConfigLoggingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobPigConfigLoggingConfig)(nil)).Elem()
}

func (o JobPigConfigLoggingConfigPtrOutput) ToJobPigConfigLoggingConfigPtrOutput() JobPigConfigLoggingConfigPtrOutput {
	return o
}

func (o JobPigConfigLoggingConfigPtrOutput) ToJobPigConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobPigConfigLoggingConfigPtrOutput {
	return o
}

func (o JobPigConfigLoggingConfigPtrOutput) Elem() JobPigConfigLoggingConfigOutput {
	return o.ApplyT(func(v *JobPigConfigLoggingConfig) JobPigConfigLoggingConfig { return *v }).(JobPigConfigLoggingConfigOutput)
}

func (o JobPigConfigLoggingConfigPtrOutput) DriverLogLevels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobPigConfigLoggingConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.DriverLogLevels
	}).(pulumi.StringMapOutput)
}

type JobPlacement struct {
	ClusterName string  `pulumi:"clusterName"`
	ClusterUuid *string `pulumi:"clusterUuid"`
}

// JobPlacementInput is an input type that accepts JobPlacementArgs and JobPlacementOutput values.
// You can construct a concrete instance of `JobPlacementInput` via:
//
// 		 JobPlacementArgs{...}
//
type JobPlacementInput interface {
	pulumi.Input

	ToJobPlacementOutput() JobPlacementOutput
	ToJobPlacementOutputWithContext(context.Context) JobPlacementOutput
}

type JobPlacementArgs struct {
	ClusterName pulumi.StringInput    `pulumi:"clusterName"`
	ClusterUuid pulumi.StringPtrInput `pulumi:"clusterUuid"`
}

func (JobPlacementArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobPlacement)(nil)).Elem()
}

func (i JobPlacementArgs) ToJobPlacementOutput() JobPlacementOutput {
	return i.ToJobPlacementOutputWithContext(context.Background())
}

func (i JobPlacementArgs) ToJobPlacementOutputWithContext(ctx context.Context) JobPlacementOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPlacementOutput)
}

func (i JobPlacementArgs) ToJobPlacementPtrOutput() JobPlacementPtrOutput {
	return i.ToJobPlacementPtrOutputWithContext(context.Background())
}

func (i JobPlacementArgs) ToJobPlacementPtrOutputWithContext(ctx context.Context) JobPlacementPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPlacementOutput).ToJobPlacementPtrOutputWithContext(ctx)
}

// JobPlacementPtrInput is an input type that accepts JobPlacementArgs, JobPlacementPtr and JobPlacementPtrOutput values.
// You can construct a concrete instance of `JobPlacementPtrInput` via:
//
// 		 JobPlacementArgs{...}
//
//  or:
//
// 		 nil
//
type JobPlacementPtrInput interface {
	pulumi.Input

	ToJobPlacementPtrOutput() JobPlacementPtrOutput
	ToJobPlacementPtrOutputWithContext(context.Context) JobPlacementPtrOutput
}

type jobPlacementPtrType JobPlacementArgs

func JobPlacementPtr(v *JobPlacementArgs) JobPlacementPtrInput {
	return (*jobPlacementPtrType)(v)
}

func (*jobPlacementPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobPlacement)(nil)).Elem()
}

func (i *jobPlacementPtrType) ToJobPlacementPtrOutput() JobPlacementPtrOutput {
	return i.ToJobPlacementPtrOutputWithContext(context.Background())
}

func (i *jobPlacementPtrType) ToJobPlacementPtrOutputWithContext(ctx context.Context) JobPlacementPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPlacementPtrOutput)
}

type JobPlacementOutput struct{ *pulumi.OutputState }

func (JobPlacementOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobPlacement)(nil)).Elem()
}

func (o JobPlacementOutput) ToJobPlacementOutput() JobPlacementOutput {
	return o
}

func (o JobPlacementOutput) ToJobPlacementOutputWithContext(ctx context.Context) JobPlacementOutput {
	return o
}

func (o JobPlacementOutput) ToJobPlacementPtrOutput() JobPlacementPtrOutput {
	return o.ToJobPlacementPtrOutputWithContext(context.Background())
}

func (o JobPlacementOutput) ToJobPlacementPtrOutputWithContext(ctx context.Context) JobPlacementPtrOutput {
	return o.ApplyT(func(v JobPlacement) *JobPlacement {
		return &v
	}).(JobPlacementPtrOutput)
}
func (o JobPlacementOutput) ClusterName() pulumi.StringOutput {
	return o.ApplyT(func(v JobPlacement) string { return v.ClusterName }).(pulumi.StringOutput)
}

func (o JobPlacementOutput) ClusterUuid() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobPlacement) *string { return v.ClusterUuid }).(pulumi.StringPtrOutput)
}

type JobPlacementPtrOutput struct{ *pulumi.OutputState }

func (JobPlacementPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobPlacement)(nil)).Elem()
}

func (o JobPlacementPtrOutput) ToJobPlacementPtrOutput() JobPlacementPtrOutput {
	return o
}

func (o JobPlacementPtrOutput) ToJobPlacementPtrOutputWithContext(ctx context.Context) JobPlacementPtrOutput {
	return o
}

func (o JobPlacementPtrOutput) Elem() JobPlacementOutput {
	return o.ApplyT(func(v *JobPlacement) JobPlacement { return *v }).(JobPlacementOutput)
}

func (o JobPlacementPtrOutput) ClusterName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobPlacement) *string {
		if v == nil {
			return nil
		}
		return &v.ClusterName
	}).(pulumi.StringPtrOutput)
}

func (o JobPlacementPtrOutput) ClusterUuid() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobPlacement) *string {
		if v == nil {
			return nil
		}
		return v.ClusterUuid
	}).(pulumi.StringPtrOutput)
}

type JobPysparkConfig struct {
	// HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
	ArchiveUris []string `pulumi:"archiveUris"`
	// The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args []string `pulumi:"args"`
	// HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
	FileUris []string `pulumi:"fileUris"`
	// HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris   []string                       `pulumi:"jarFileUris"`
	LoggingConfig *JobPysparkConfigLoggingConfig `pulumi:"loggingConfig"`
	// The HCFS URI of the main Python file to use as the driver. Must be a .py file.
	MainPythonFileUri string `pulumi:"mainPythonFileUri"`
	// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
	Properties map[string]string `pulumi:"properties"`
	// HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
	PythonFileUris []string `pulumi:"pythonFileUris"`
}

// JobPysparkConfigInput is an input type that accepts JobPysparkConfigArgs and JobPysparkConfigOutput values.
// You can construct a concrete instance of `JobPysparkConfigInput` via:
//
// 		 JobPysparkConfigArgs{...}
//
type JobPysparkConfigInput interface {
	pulumi.Input

	ToJobPysparkConfigOutput() JobPysparkConfigOutput
	ToJobPysparkConfigOutputWithContext(context.Context) JobPysparkConfigOutput
}

type JobPysparkConfigArgs struct {
	// HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
	ArchiveUris pulumi.StringArrayInput `pulumi:"archiveUris"`
	// The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args pulumi.StringArrayInput `pulumi:"args"`
	// HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
	FileUris pulumi.StringArrayInput `pulumi:"fileUris"`
	// HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris   pulumi.StringArrayInput               `pulumi:"jarFileUris"`
	LoggingConfig JobPysparkConfigLoggingConfigPtrInput `pulumi:"loggingConfig"`
	// The HCFS URI of the main Python file to use as the driver. Must be a .py file.
	MainPythonFileUri pulumi.StringInput `pulumi:"mainPythonFileUri"`
	// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
	Properties pulumi.StringMapInput `pulumi:"properties"`
	// HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
	PythonFileUris pulumi.StringArrayInput `pulumi:"pythonFileUris"`
}

func (JobPysparkConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobPysparkConfig)(nil)).Elem()
}

func (i JobPysparkConfigArgs) ToJobPysparkConfigOutput() JobPysparkConfigOutput {
	return i.ToJobPysparkConfigOutputWithContext(context.Background())
}

func (i JobPysparkConfigArgs) ToJobPysparkConfigOutputWithContext(ctx context.Context) JobPysparkConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPysparkConfigOutput)
}

func (i JobPysparkConfigArgs) ToJobPysparkConfigPtrOutput() JobPysparkConfigPtrOutput {
	return i.ToJobPysparkConfigPtrOutputWithContext(context.Background())
}

func (i JobPysparkConfigArgs) ToJobPysparkConfigPtrOutputWithContext(ctx context.Context) JobPysparkConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPysparkConfigOutput).ToJobPysparkConfigPtrOutputWithContext(ctx)
}

// JobPysparkConfigPtrInput is an input type that accepts JobPysparkConfigArgs, JobPysparkConfigPtr and JobPysparkConfigPtrOutput values.
// You can construct a concrete instance of `JobPysparkConfigPtrInput` via:
//
// 		 JobPysparkConfigArgs{...}
//
//  or:
//
// 		 nil
//
type JobPysparkConfigPtrInput interface {
	pulumi.Input

	ToJobPysparkConfigPtrOutput() JobPysparkConfigPtrOutput
	ToJobPysparkConfigPtrOutputWithContext(context.Context) JobPysparkConfigPtrOutput
}

type jobPysparkConfigPtrType JobPysparkConfigArgs

func JobPysparkConfigPtr(v *JobPysparkConfigArgs) JobPysparkConfigPtrInput {
	return (*jobPysparkConfigPtrType)(v)
}

func (*jobPysparkConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobPysparkConfig)(nil)).Elem()
}

func (i *jobPysparkConfigPtrType) ToJobPysparkConfigPtrOutput() JobPysparkConfigPtrOutput {
	return i.ToJobPysparkConfigPtrOutputWithContext(context.Background())
}

func (i *jobPysparkConfigPtrType) ToJobPysparkConfigPtrOutputWithContext(ctx context.Context) JobPysparkConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPysparkConfigPtrOutput)
}

type JobPysparkConfigOutput struct{ *pulumi.OutputState }

func (JobPysparkConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobPysparkConfig)(nil)).Elem()
}

func (o JobPysparkConfigOutput) ToJobPysparkConfigOutput() JobPysparkConfigOutput {
	return o
}

func (o JobPysparkConfigOutput) ToJobPysparkConfigOutputWithContext(ctx context.Context) JobPysparkConfigOutput {
	return o
}

func (o JobPysparkConfigOutput) ToJobPysparkConfigPtrOutput() JobPysparkConfigPtrOutput {
	return o.ToJobPysparkConfigPtrOutputWithContext(context.Background())
}

func (o JobPysparkConfigOutput) ToJobPysparkConfigPtrOutputWithContext(ctx context.Context) JobPysparkConfigPtrOutput {
	return o.ApplyT(func(v JobPysparkConfig) *JobPysparkConfig {
		return &v
	}).(JobPysparkConfigPtrOutput)
}

// HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
func (o JobPysparkConfigOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobPysparkConfig) []string { return v.ArchiveUris }).(pulumi.StringArrayOutput)
}

// The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o JobPysparkConfigOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobPysparkConfig) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
func (o JobPysparkConfigOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobPysparkConfig) []string { return v.FileUris }).(pulumi.StringArrayOutput)
}

// HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o JobPysparkConfigOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobPysparkConfig) []string { return v.JarFileUris }).(pulumi.StringArrayOutput)
}

func (o JobPysparkConfigOutput) LoggingConfig() JobPysparkConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v JobPysparkConfig) *JobPysparkConfigLoggingConfig { return v.LoggingConfig }).(JobPysparkConfigLoggingConfigPtrOutput)
}

// The HCFS URI of the main Python file to use as the driver. Must be a .py file.
func (o JobPysparkConfigOutput) MainPythonFileUri() pulumi.StringOutput {
	return o.ApplyT(func(v JobPysparkConfig) string { return v.MainPythonFileUri }).(pulumi.StringOutput)
}

// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
func (o JobPysparkConfigOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobPysparkConfig) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

// HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
func (o JobPysparkConfigOutput) PythonFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobPysparkConfig) []string { return v.PythonFileUris }).(pulumi.StringArrayOutput)
}

type JobPysparkConfigPtrOutput struct{ *pulumi.OutputState }

func (JobPysparkConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobPysparkConfig)(nil)).Elem()
}

func (o JobPysparkConfigPtrOutput) ToJobPysparkConfigPtrOutput() JobPysparkConfigPtrOutput {
	return o
}

func (o JobPysparkConfigPtrOutput) ToJobPysparkConfigPtrOutputWithContext(ctx context.Context) JobPysparkConfigPtrOutput {
	return o
}

func (o JobPysparkConfigPtrOutput) Elem() JobPysparkConfigOutput {
	return o.ApplyT(func(v *JobPysparkConfig) JobPysparkConfig { return *v }).(JobPysparkConfigOutput)
}

// HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
func (o JobPysparkConfigPtrOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobPysparkConfig) []string {
		if v == nil {
			return nil
		}
		return v.ArchiveUris
	}).(pulumi.StringArrayOutput)
}

// The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o JobPysparkConfigPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobPysparkConfig) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
func (o JobPysparkConfigPtrOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobPysparkConfig) []string {
		if v == nil {
			return nil
		}
		return v.FileUris
	}).(pulumi.StringArrayOutput)
}

// HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o JobPysparkConfigPtrOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobPysparkConfig) []string {
		if v == nil {
			return nil
		}
		return v.JarFileUris
	}).(pulumi.StringArrayOutput)
}

func (o JobPysparkConfigPtrOutput) LoggingConfig() JobPysparkConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v *JobPysparkConfig) *JobPysparkConfigLoggingConfig {
		if v == nil {
			return nil
		}
		return v.LoggingConfig
	}).(JobPysparkConfigLoggingConfigPtrOutput)
}

// The HCFS URI of the main Python file to use as the driver. Must be a .py file.
func (o JobPysparkConfigPtrOutput) MainPythonFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobPysparkConfig) *string {
		if v == nil {
			return nil
		}
		return &v.MainPythonFileUri
	}).(pulumi.StringPtrOutput)
}

// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
func (o JobPysparkConfigPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobPysparkConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
func (o JobPysparkConfigPtrOutput) PythonFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobPysparkConfig) []string {
		if v == nil {
			return nil
		}
		return v.PythonFileUris
	}).(pulumi.StringArrayOutput)
}

type JobPysparkConfigLoggingConfig struct {
	DriverLogLevels map[string]string `pulumi:"driverLogLevels"`
}

// JobPysparkConfigLoggingConfigInput is an input type that accepts JobPysparkConfigLoggingConfigArgs and JobPysparkConfigLoggingConfigOutput values.
// You can construct a concrete instance of `JobPysparkConfigLoggingConfigInput` via:
//
// 		 JobPysparkConfigLoggingConfigArgs{...}
//
type JobPysparkConfigLoggingConfigInput interface {
	pulumi.Input

	ToJobPysparkConfigLoggingConfigOutput() JobPysparkConfigLoggingConfigOutput
	ToJobPysparkConfigLoggingConfigOutputWithContext(context.Context) JobPysparkConfigLoggingConfigOutput
}

type JobPysparkConfigLoggingConfigArgs struct {
	DriverLogLevels pulumi.StringMapInput `pulumi:"driverLogLevels"`
}

func (JobPysparkConfigLoggingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobPysparkConfigLoggingConfig)(nil)).Elem()
}

func (i JobPysparkConfigLoggingConfigArgs) ToJobPysparkConfigLoggingConfigOutput() JobPysparkConfigLoggingConfigOutput {
	return i.ToJobPysparkConfigLoggingConfigOutputWithContext(context.Background())
}

func (i JobPysparkConfigLoggingConfigArgs) ToJobPysparkConfigLoggingConfigOutputWithContext(ctx context.Context) JobPysparkConfigLoggingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPysparkConfigLoggingConfigOutput)
}

func (i JobPysparkConfigLoggingConfigArgs) ToJobPysparkConfigLoggingConfigPtrOutput() JobPysparkConfigLoggingConfigPtrOutput {
	return i.ToJobPysparkConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (i JobPysparkConfigLoggingConfigArgs) ToJobPysparkConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobPysparkConfigLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPysparkConfigLoggingConfigOutput).ToJobPysparkConfigLoggingConfigPtrOutputWithContext(ctx)
}

// JobPysparkConfigLoggingConfigPtrInput is an input type that accepts JobPysparkConfigLoggingConfigArgs, JobPysparkConfigLoggingConfigPtr and JobPysparkConfigLoggingConfigPtrOutput values.
// You can construct a concrete instance of `JobPysparkConfigLoggingConfigPtrInput` via:
//
// 		 JobPysparkConfigLoggingConfigArgs{...}
//
//  or:
//
// 		 nil
//
type JobPysparkConfigLoggingConfigPtrInput interface {
	pulumi.Input

	ToJobPysparkConfigLoggingConfigPtrOutput() JobPysparkConfigLoggingConfigPtrOutput
	ToJobPysparkConfigLoggingConfigPtrOutputWithContext(context.Context) JobPysparkConfigLoggingConfigPtrOutput
}

type jobPysparkConfigLoggingConfigPtrType JobPysparkConfigLoggingConfigArgs

func JobPysparkConfigLoggingConfigPtr(v *JobPysparkConfigLoggingConfigArgs) JobPysparkConfigLoggingConfigPtrInput {
	return (*jobPysparkConfigLoggingConfigPtrType)(v)
}

func (*jobPysparkConfigLoggingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobPysparkConfigLoggingConfig)(nil)).Elem()
}

func (i *jobPysparkConfigLoggingConfigPtrType) ToJobPysparkConfigLoggingConfigPtrOutput() JobPysparkConfigLoggingConfigPtrOutput {
	return i.ToJobPysparkConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (i *jobPysparkConfigLoggingConfigPtrType) ToJobPysparkConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobPysparkConfigLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobPysparkConfigLoggingConfigPtrOutput)
}

type JobPysparkConfigLoggingConfigOutput struct{ *pulumi.OutputState }

func (JobPysparkConfigLoggingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobPysparkConfigLoggingConfig)(nil)).Elem()
}

func (o JobPysparkConfigLoggingConfigOutput) ToJobPysparkConfigLoggingConfigOutput() JobPysparkConfigLoggingConfigOutput {
	return o
}

func (o JobPysparkConfigLoggingConfigOutput) ToJobPysparkConfigLoggingConfigOutputWithContext(ctx context.Context) JobPysparkConfigLoggingConfigOutput {
	return o
}

func (o JobPysparkConfigLoggingConfigOutput) ToJobPysparkConfigLoggingConfigPtrOutput() JobPysparkConfigLoggingConfigPtrOutput {
	return o.ToJobPysparkConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (o JobPysparkConfigLoggingConfigOutput) ToJobPysparkConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobPysparkConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v JobPysparkConfigLoggingConfig) *JobPysparkConfigLoggingConfig {
		return &v
	}).(JobPysparkConfigLoggingConfigPtrOutput)
}
func (o JobPysparkConfigLoggingConfigOutput) DriverLogLevels() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobPysparkConfigLoggingConfig) map[string]string { return v.DriverLogLevels }).(pulumi.StringMapOutput)
}

type JobPysparkConfigLoggingConfigPtrOutput struct{ *pulumi.OutputState }

func (JobPysparkConfigLoggingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobPysparkConfigLoggingConfig)(nil)).Elem()
}

func (o JobPysparkConfigLoggingConfigPtrOutput) ToJobPysparkConfigLoggingConfigPtrOutput() JobPysparkConfigLoggingConfigPtrOutput {
	return o
}

func (o JobPysparkConfigLoggingConfigPtrOutput) ToJobPysparkConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobPysparkConfigLoggingConfigPtrOutput {
	return o
}

func (o JobPysparkConfigLoggingConfigPtrOutput) Elem() JobPysparkConfigLoggingConfigOutput {
	return o.ApplyT(func(v *JobPysparkConfigLoggingConfig) JobPysparkConfigLoggingConfig { return *v }).(JobPysparkConfigLoggingConfigOutput)
}

func (o JobPysparkConfigLoggingConfigPtrOutput) DriverLogLevels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobPysparkConfigLoggingConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.DriverLogLevels
	}).(pulumi.StringMapOutput)
}

type JobReference struct {
	JobId *string `pulumi:"jobId"`
}

// JobReferenceInput is an input type that accepts JobReferenceArgs and JobReferenceOutput values.
// You can construct a concrete instance of `JobReferenceInput` via:
//
// 		 JobReferenceArgs{...}
//
type JobReferenceInput interface {
	pulumi.Input

	ToJobReferenceOutput() JobReferenceOutput
	ToJobReferenceOutputWithContext(context.Context) JobReferenceOutput
}

type JobReferenceArgs struct {
	JobId pulumi.StringPtrInput `pulumi:"jobId"`
}

func (JobReferenceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobReference)(nil)).Elem()
}

func (i JobReferenceArgs) ToJobReferenceOutput() JobReferenceOutput {
	return i.ToJobReferenceOutputWithContext(context.Background())
}

func (i JobReferenceArgs) ToJobReferenceOutputWithContext(ctx context.Context) JobReferenceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobReferenceOutput)
}

func (i JobReferenceArgs) ToJobReferencePtrOutput() JobReferencePtrOutput {
	return i.ToJobReferencePtrOutputWithContext(context.Background())
}

func (i JobReferenceArgs) ToJobReferencePtrOutputWithContext(ctx context.Context) JobReferencePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobReferenceOutput).ToJobReferencePtrOutputWithContext(ctx)
}

// JobReferencePtrInput is an input type that accepts JobReferenceArgs, JobReferencePtr and JobReferencePtrOutput values.
// You can construct a concrete instance of `JobReferencePtrInput` via:
//
// 		 JobReferenceArgs{...}
//
//  or:
//
// 		 nil
//
type JobReferencePtrInput interface {
	pulumi.Input

	ToJobReferencePtrOutput() JobReferencePtrOutput
	ToJobReferencePtrOutputWithContext(context.Context) JobReferencePtrOutput
}

type jobReferencePtrType JobReferenceArgs

func JobReferencePtr(v *JobReferenceArgs) JobReferencePtrInput {
	return (*jobReferencePtrType)(v)
}

func (*jobReferencePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobReference)(nil)).Elem()
}

func (i *jobReferencePtrType) ToJobReferencePtrOutput() JobReferencePtrOutput {
	return i.ToJobReferencePtrOutputWithContext(context.Background())
}

func (i *jobReferencePtrType) ToJobReferencePtrOutputWithContext(ctx context.Context) JobReferencePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobReferencePtrOutput)
}

type JobReferenceOutput struct{ *pulumi.OutputState }

func (JobReferenceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobReference)(nil)).Elem()
}

func (o JobReferenceOutput) ToJobReferenceOutput() JobReferenceOutput {
	return o
}

func (o JobReferenceOutput) ToJobReferenceOutputWithContext(ctx context.Context) JobReferenceOutput {
	return o
}

func (o JobReferenceOutput) ToJobReferencePtrOutput() JobReferencePtrOutput {
	return o.ToJobReferencePtrOutputWithContext(context.Background())
}

func (o JobReferenceOutput) ToJobReferencePtrOutputWithContext(ctx context.Context) JobReferencePtrOutput {
	return o.ApplyT(func(v JobReference) *JobReference {
		return &v
	}).(JobReferencePtrOutput)
}
func (o JobReferenceOutput) JobId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobReference) *string { return v.JobId }).(pulumi.StringPtrOutput)
}

type JobReferencePtrOutput struct{ *pulumi.OutputState }

func (JobReferencePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobReference)(nil)).Elem()
}

func (o JobReferencePtrOutput) ToJobReferencePtrOutput() JobReferencePtrOutput {
	return o
}

func (o JobReferencePtrOutput) ToJobReferencePtrOutputWithContext(ctx context.Context) JobReferencePtrOutput {
	return o
}

func (o JobReferencePtrOutput) Elem() JobReferenceOutput {
	return o.ApplyT(func(v *JobReference) JobReference { return *v }).(JobReferenceOutput)
}

func (o JobReferencePtrOutput) JobId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobReference) *string {
		if v == nil {
			return nil
		}
		return v.JobId
	}).(pulumi.StringPtrOutput)
}

type JobScheduling struct {
	MaxFailuresPerHour int `pulumi:"maxFailuresPerHour"`
}

// JobSchedulingInput is an input type that accepts JobSchedulingArgs and JobSchedulingOutput values.
// You can construct a concrete instance of `JobSchedulingInput` via:
//
// 		 JobSchedulingArgs{...}
//
type JobSchedulingInput interface {
	pulumi.Input

	ToJobSchedulingOutput() JobSchedulingOutput
	ToJobSchedulingOutputWithContext(context.Context) JobSchedulingOutput
}

type JobSchedulingArgs struct {
	MaxFailuresPerHour pulumi.IntInput `pulumi:"maxFailuresPerHour"`
}

func (JobSchedulingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobScheduling)(nil)).Elem()
}

func (i JobSchedulingArgs) ToJobSchedulingOutput() JobSchedulingOutput {
	return i.ToJobSchedulingOutputWithContext(context.Background())
}

func (i JobSchedulingArgs) ToJobSchedulingOutputWithContext(ctx context.Context) JobSchedulingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSchedulingOutput)
}

func (i JobSchedulingArgs) ToJobSchedulingPtrOutput() JobSchedulingPtrOutput {
	return i.ToJobSchedulingPtrOutputWithContext(context.Background())
}

func (i JobSchedulingArgs) ToJobSchedulingPtrOutputWithContext(ctx context.Context) JobSchedulingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSchedulingOutput).ToJobSchedulingPtrOutputWithContext(ctx)
}

// JobSchedulingPtrInput is an input type that accepts JobSchedulingArgs, JobSchedulingPtr and JobSchedulingPtrOutput values.
// You can construct a concrete instance of `JobSchedulingPtrInput` via:
//
// 		 JobSchedulingArgs{...}
//
//  or:
//
// 		 nil
//
type JobSchedulingPtrInput interface {
	pulumi.Input

	ToJobSchedulingPtrOutput() JobSchedulingPtrOutput
	ToJobSchedulingPtrOutputWithContext(context.Context) JobSchedulingPtrOutput
}

type jobSchedulingPtrType JobSchedulingArgs

func JobSchedulingPtr(v *JobSchedulingArgs) JobSchedulingPtrInput {
	return (*jobSchedulingPtrType)(v)
}

func (*jobSchedulingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobScheduling)(nil)).Elem()
}

func (i *jobSchedulingPtrType) ToJobSchedulingPtrOutput() JobSchedulingPtrOutput {
	return i.ToJobSchedulingPtrOutputWithContext(context.Background())
}

func (i *jobSchedulingPtrType) ToJobSchedulingPtrOutputWithContext(ctx context.Context) JobSchedulingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSchedulingPtrOutput)
}

type JobSchedulingOutput struct{ *pulumi.OutputState }

func (JobSchedulingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobScheduling)(nil)).Elem()
}

func (o JobSchedulingOutput) ToJobSchedulingOutput() JobSchedulingOutput {
	return o
}

func (o JobSchedulingOutput) ToJobSchedulingOutputWithContext(ctx context.Context) JobSchedulingOutput {
	return o
}

func (o JobSchedulingOutput) ToJobSchedulingPtrOutput() JobSchedulingPtrOutput {
	return o.ToJobSchedulingPtrOutputWithContext(context.Background())
}

func (o JobSchedulingOutput) ToJobSchedulingPtrOutputWithContext(ctx context.Context) JobSchedulingPtrOutput {
	return o.ApplyT(func(v JobScheduling) *JobScheduling {
		return &v
	}).(JobSchedulingPtrOutput)
}
func (o JobSchedulingOutput) MaxFailuresPerHour() pulumi.IntOutput {
	return o.ApplyT(func(v JobScheduling) int { return v.MaxFailuresPerHour }).(pulumi.IntOutput)
}

type JobSchedulingPtrOutput struct{ *pulumi.OutputState }

func (JobSchedulingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobScheduling)(nil)).Elem()
}

func (o JobSchedulingPtrOutput) ToJobSchedulingPtrOutput() JobSchedulingPtrOutput {
	return o
}

func (o JobSchedulingPtrOutput) ToJobSchedulingPtrOutputWithContext(ctx context.Context) JobSchedulingPtrOutput {
	return o
}

func (o JobSchedulingPtrOutput) Elem() JobSchedulingOutput {
	return o.ApplyT(func(v *JobScheduling) JobScheduling { return *v }).(JobSchedulingOutput)
}

func (o JobSchedulingPtrOutput) MaxFailuresPerHour() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *JobScheduling) *int {
		if v == nil {
			return nil
		}
		return &v.MaxFailuresPerHour
	}).(pulumi.IntPtrOutput)
}

type JobSparkConfig struct {
	// HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
	ArchiveUris []string `pulumi:"archiveUris"`
	// The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args []string `pulumi:"args"`
	// HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
	FileUris []string `pulumi:"fileUris"`
	// HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris   []string                     `pulumi:"jarFileUris"`
	LoggingConfig *JobSparkConfigLoggingConfig `pulumi:"loggingConfig"`
	// The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jarFileUris`. Conflicts with `mainJarFileUri`
	MainClass *string `pulumi:"mainClass"`
	// The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'. Conflicts with `mainClass`
	MainJarFileUri *string `pulumi:"mainJarFileUri"`
	// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
	Properties map[string]string `pulumi:"properties"`
}

// JobSparkConfigInput is an input type that accepts JobSparkConfigArgs and JobSparkConfigOutput values.
// You can construct a concrete instance of `JobSparkConfigInput` via:
//
// 		 JobSparkConfigArgs{...}
//
type JobSparkConfigInput interface {
	pulumi.Input

	ToJobSparkConfigOutput() JobSparkConfigOutput
	ToJobSparkConfigOutputWithContext(context.Context) JobSparkConfigOutput
}

type JobSparkConfigArgs struct {
	// HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
	ArchiveUris pulumi.StringArrayInput `pulumi:"archiveUris"`
	// The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args pulumi.StringArrayInput `pulumi:"args"`
	// HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
	FileUris pulumi.StringArrayInput `pulumi:"fileUris"`
	// HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris   pulumi.StringArrayInput             `pulumi:"jarFileUris"`
	LoggingConfig JobSparkConfigLoggingConfigPtrInput `pulumi:"loggingConfig"`
	// The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jarFileUris`. Conflicts with `mainJarFileUri`
	MainClass pulumi.StringPtrInput `pulumi:"mainClass"`
	// The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'. Conflicts with `mainClass`
	MainJarFileUri pulumi.StringPtrInput `pulumi:"mainJarFileUri"`
	// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
	Properties pulumi.StringMapInput `pulumi:"properties"`
}

func (JobSparkConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobSparkConfig)(nil)).Elem()
}

func (i JobSparkConfigArgs) ToJobSparkConfigOutput() JobSparkConfigOutput {
	return i.ToJobSparkConfigOutputWithContext(context.Background())
}

func (i JobSparkConfigArgs) ToJobSparkConfigOutputWithContext(ctx context.Context) JobSparkConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSparkConfigOutput)
}

func (i JobSparkConfigArgs) ToJobSparkConfigPtrOutput() JobSparkConfigPtrOutput {
	return i.ToJobSparkConfigPtrOutputWithContext(context.Background())
}

func (i JobSparkConfigArgs) ToJobSparkConfigPtrOutputWithContext(ctx context.Context) JobSparkConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSparkConfigOutput).ToJobSparkConfigPtrOutputWithContext(ctx)
}

// JobSparkConfigPtrInput is an input type that accepts JobSparkConfigArgs, JobSparkConfigPtr and JobSparkConfigPtrOutput values.
// You can construct a concrete instance of `JobSparkConfigPtrInput` via:
//
// 		 JobSparkConfigArgs{...}
//
//  or:
//
// 		 nil
//
type JobSparkConfigPtrInput interface {
	pulumi.Input

	ToJobSparkConfigPtrOutput() JobSparkConfigPtrOutput
	ToJobSparkConfigPtrOutputWithContext(context.Context) JobSparkConfigPtrOutput
}

type jobSparkConfigPtrType JobSparkConfigArgs

func JobSparkConfigPtr(v *JobSparkConfigArgs) JobSparkConfigPtrInput {
	return (*jobSparkConfigPtrType)(v)
}

func (*jobSparkConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobSparkConfig)(nil)).Elem()
}

func (i *jobSparkConfigPtrType) ToJobSparkConfigPtrOutput() JobSparkConfigPtrOutput {
	return i.ToJobSparkConfigPtrOutputWithContext(context.Background())
}

func (i *jobSparkConfigPtrType) ToJobSparkConfigPtrOutputWithContext(ctx context.Context) JobSparkConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSparkConfigPtrOutput)
}

type JobSparkConfigOutput struct{ *pulumi.OutputState }

func (JobSparkConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobSparkConfig)(nil)).Elem()
}

func (o JobSparkConfigOutput) ToJobSparkConfigOutput() JobSparkConfigOutput {
	return o
}

func (o JobSparkConfigOutput) ToJobSparkConfigOutputWithContext(ctx context.Context) JobSparkConfigOutput {
	return o
}

func (o JobSparkConfigOutput) ToJobSparkConfigPtrOutput() JobSparkConfigPtrOutput {
	return o.ToJobSparkConfigPtrOutputWithContext(context.Background())
}

func (o JobSparkConfigOutput) ToJobSparkConfigPtrOutputWithContext(ctx context.Context) JobSparkConfigPtrOutput {
	return o.ApplyT(func(v JobSparkConfig) *JobSparkConfig {
		return &v
	}).(JobSparkConfigPtrOutput)
}

// HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
func (o JobSparkConfigOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobSparkConfig) []string { return v.ArchiveUris }).(pulumi.StringArrayOutput)
}

// The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o JobSparkConfigOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobSparkConfig) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
func (o JobSparkConfigOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobSparkConfig) []string { return v.FileUris }).(pulumi.StringArrayOutput)
}

// HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o JobSparkConfigOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobSparkConfig) []string { return v.JarFileUris }).(pulumi.StringArrayOutput)
}

func (o JobSparkConfigOutput) LoggingConfig() JobSparkConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v JobSparkConfig) *JobSparkConfigLoggingConfig { return v.LoggingConfig }).(JobSparkConfigLoggingConfigPtrOutput)
}

// The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jarFileUris`. Conflicts with `mainJarFileUri`
func (o JobSparkConfigOutput) MainClass() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobSparkConfig) *string { return v.MainClass }).(pulumi.StringPtrOutput)
}

// The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'. Conflicts with `mainClass`
func (o JobSparkConfigOutput) MainJarFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobSparkConfig) *string { return v.MainJarFileUri }).(pulumi.StringPtrOutput)
}

// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
func (o JobSparkConfigOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobSparkConfig) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

type JobSparkConfigPtrOutput struct{ *pulumi.OutputState }

func (JobSparkConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobSparkConfig)(nil)).Elem()
}

func (o JobSparkConfigPtrOutput) ToJobSparkConfigPtrOutput() JobSparkConfigPtrOutput {
	return o
}

func (o JobSparkConfigPtrOutput) ToJobSparkConfigPtrOutputWithContext(ctx context.Context) JobSparkConfigPtrOutput {
	return o
}

func (o JobSparkConfigPtrOutput) Elem() JobSparkConfigOutput {
	return o.ApplyT(func(v *JobSparkConfig) JobSparkConfig { return *v }).(JobSparkConfigOutput)
}

// HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
func (o JobSparkConfigPtrOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobSparkConfig) []string {
		if v == nil {
			return nil
		}
		return v.ArchiveUris
	}).(pulumi.StringArrayOutput)
}

// The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o JobSparkConfigPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobSparkConfig) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
func (o JobSparkConfigPtrOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobSparkConfig) []string {
		if v == nil {
			return nil
		}
		return v.FileUris
	}).(pulumi.StringArrayOutput)
}

// HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o JobSparkConfigPtrOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobSparkConfig) []string {
		if v == nil {
			return nil
		}
		return v.JarFileUris
	}).(pulumi.StringArrayOutput)
}

func (o JobSparkConfigPtrOutput) LoggingConfig() JobSparkConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v *JobSparkConfig) *JobSparkConfigLoggingConfig {
		if v == nil {
			return nil
		}
		return v.LoggingConfig
	}).(JobSparkConfigLoggingConfigPtrOutput)
}

// The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jarFileUris`. Conflicts with `mainJarFileUri`
func (o JobSparkConfigPtrOutput) MainClass() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobSparkConfig) *string {
		if v == nil {
			return nil
		}
		return v.MainClass
	}).(pulumi.StringPtrOutput)
}

// The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'. Conflicts with `mainClass`
func (o JobSparkConfigPtrOutput) MainJarFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobSparkConfig) *string {
		if v == nil {
			return nil
		}
		return v.MainJarFileUri
	}).(pulumi.StringPtrOutput)
}

// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
func (o JobSparkConfigPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobSparkConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

type JobSparkConfigLoggingConfig struct {
	DriverLogLevels map[string]string `pulumi:"driverLogLevels"`
}

// JobSparkConfigLoggingConfigInput is an input type that accepts JobSparkConfigLoggingConfigArgs and JobSparkConfigLoggingConfigOutput values.
// You can construct a concrete instance of `JobSparkConfigLoggingConfigInput` via:
//
// 		 JobSparkConfigLoggingConfigArgs{...}
//
type JobSparkConfigLoggingConfigInput interface {
	pulumi.Input

	ToJobSparkConfigLoggingConfigOutput() JobSparkConfigLoggingConfigOutput
	ToJobSparkConfigLoggingConfigOutputWithContext(context.Context) JobSparkConfigLoggingConfigOutput
}

type JobSparkConfigLoggingConfigArgs struct {
	DriverLogLevels pulumi.StringMapInput `pulumi:"driverLogLevels"`
}

func (JobSparkConfigLoggingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobSparkConfigLoggingConfig)(nil)).Elem()
}

func (i JobSparkConfigLoggingConfigArgs) ToJobSparkConfigLoggingConfigOutput() JobSparkConfigLoggingConfigOutput {
	return i.ToJobSparkConfigLoggingConfigOutputWithContext(context.Background())
}

func (i JobSparkConfigLoggingConfigArgs) ToJobSparkConfigLoggingConfigOutputWithContext(ctx context.Context) JobSparkConfigLoggingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSparkConfigLoggingConfigOutput)
}

func (i JobSparkConfigLoggingConfigArgs) ToJobSparkConfigLoggingConfigPtrOutput() JobSparkConfigLoggingConfigPtrOutput {
	return i.ToJobSparkConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (i JobSparkConfigLoggingConfigArgs) ToJobSparkConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobSparkConfigLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSparkConfigLoggingConfigOutput).ToJobSparkConfigLoggingConfigPtrOutputWithContext(ctx)
}

// JobSparkConfigLoggingConfigPtrInput is an input type that accepts JobSparkConfigLoggingConfigArgs, JobSparkConfigLoggingConfigPtr and JobSparkConfigLoggingConfigPtrOutput values.
// You can construct a concrete instance of `JobSparkConfigLoggingConfigPtrInput` via:
//
// 		 JobSparkConfigLoggingConfigArgs{...}
//
//  or:
//
// 		 nil
//
type JobSparkConfigLoggingConfigPtrInput interface {
	pulumi.Input

	ToJobSparkConfigLoggingConfigPtrOutput() JobSparkConfigLoggingConfigPtrOutput
	ToJobSparkConfigLoggingConfigPtrOutputWithContext(context.Context) JobSparkConfigLoggingConfigPtrOutput
}

type jobSparkConfigLoggingConfigPtrType JobSparkConfigLoggingConfigArgs

func JobSparkConfigLoggingConfigPtr(v *JobSparkConfigLoggingConfigArgs) JobSparkConfigLoggingConfigPtrInput {
	return (*jobSparkConfigLoggingConfigPtrType)(v)
}

func (*jobSparkConfigLoggingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobSparkConfigLoggingConfig)(nil)).Elem()
}

func (i *jobSparkConfigLoggingConfigPtrType) ToJobSparkConfigLoggingConfigPtrOutput() JobSparkConfigLoggingConfigPtrOutput {
	return i.ToJobSparkConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (i *jobSparkConfigLoggingConfigPtrType) ToJobSparkConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobSparkConfigLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSparkConfigLoggingConfigPtrOutput)
}

type JobSparkConfigLoggingConfigOutput struct{ *pulumi.OutputState }

func (JobSparkConfigLoggingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobSparkConfigLoggingConfig)(nil)).Elem()
}

func (o JobSparkConfigLoggingConfigOutput) ToJobSparkConfigLoggingConfigOutput() JobSparkConfigLoggingConfigOutput {
	return o
}

func (o JobSparkConfigLoggingConfigOutput) ToJobSparkConfigLoggingConfigOutputWithContext(ctx context.Context) JobSparkConfigLoggingConfigOutput {
	return o
}

func (o JobSparkConfigLoggingConfigOutput) ToJobSparkConfigLoggingConfigPtrOutput() JobSparkConfigLoggingConfigPtrOutput {
	return o.ToJobSparkConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (o JobSparkConfigLoggingConfigOutput) ToJobSparkConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobSparkConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v JobSparkConfigLoggingConfig) *JobSparkConfigLoggingConfig {
		return &v
	}).(JobSparkConfigLoggingConfigPtrOutput)
}
func (o JobSparkConfigLoggingConfigOutput) DriverLogLevels() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobSparkConfigLoggingConfig) map[string]string { return v.DriverLogLevels }).(pulumi.StringMapOutput)
}

type JobSparkConfigLoggingConfigPtrOutput struct{ *pulumi.OutputState }

func (JobSparkConfigLoggingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobSparkConfigLoggingConfig)(nil)).Elem()
}

func (o JobSparkConfigLoggingConfigPtrOutput) ToJobSparkConfigLoggingConfigPtrOutput() JobSparkConfigLoggingConfigPtrOutput {
	return o
}

func (o JobSparkConfigLoggingConfigPtrOutput) ToJobSparkConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobSparkConfigLoggingConfigPtrOutput {
	return o
}

func (o JobSparkConfigLoggingConfigPtrOutput) Elem() JobSparkConfigLoggingConfigOutput {
	return o.ApplyT(func(v *JobSparkConfigLoggingConfig) JobSparkConfigLoggingConfig { return *v }).(JobSparkConfigLoggingConfigOutput)
}

func (o JobSparkConfigLoggingConfigPtrOutput) DriverLogLevels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobSparkConfigLoggingConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.DriverLogLevels
	}).(pulumi.StringMapOutput)
}

type JobSparksqlConfig struct {
	// HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris   []string                        `pulumi:"jarFileUris"`
	LoggingConfig *JobSparksqlConfigLoggingConfig `pulumi:"loggingConfig"`
	// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
	Properties map[string]string `pulumi:"properties"`
	// The HCFS URI of the script that contains SQL queries.
	// Conflicts with `queryList`
	QueryFileUri *string `pulumi:"queryFileUri"`
	// The list of SQL queries or statements to execute as part of the job.
	// Conflicts with `queryFileUri`
	QueryLists []string `pulumi:"queryLists"`
	// Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
	ScriptVariables map[string]string `pulumi:"scriptVariables"`
}

// JobSparksqlConfigInput is an input type that accepts JobSparksqlConfigArgs and JobSparksqlConfigOutput values.
// You can construct a concrete instance of `JobSparksqlConfigInput` via:
//
// 		 JobSparksqlConfigArgs{...}
//
type JobSparksqlConfigInput interface {
	pulumi.Input

	ToJobSparksqlConfigOutput() JobSparksqlConfigOutput
	ToJobSparksqlConfigOutputWithContext(context.Context) JobSparksqlConfigOutput
}

type JobSparksqlConfigArgs struct {
	// HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris   pulumi.StringArrayInput                `pulumi:"jarFileUris"`
	LoggingConfig JobSparksqlConfigLoggingConfigPtrInput `pulumi:"loggingConfig"`
	// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
	Properties pulumi.StringMapInput `pulumi:"properties"`
	// The HCFS URI of the script that contains SQL queries.
	// Conflicts with `queryList`
	QueryFileUri pulumi.StringPtrInput `pulumi:"queryFileUri"`
	// The list of SQL queries or statements to execute as part of the job.
	// Conflicts with `queryFileUri`
	QueryLists pulumi.StringArrayInput `pulumi:"queryLists"`
	// Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
	ScriptVariables pulumi.StringMapInput `pulumi:"scriptVariables"`
}

func (JobSparksqlConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobSparksqlConfig)(nil)).Elem()
}

func (i JobSparksqlConfigArgs) ToJobSparksqlConfigOutput() JobSparksqlConfigOutput {
	return i.ToJobSparksqlConfigOutputWithContext(context.Background())
}

func (i JobSparksqlConfigArgs) ToJobSparksqlConfigOutputWithContext(ctx context.Context) JobSparksqlConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSparksqlConfigOutput)
}

func (i JobSparksqlConfigArgs) ToJobSparksqlConfigPtrOutput() JobSparksqlConfigPtrOutput {
	return i.ToJobSparksqlConfigPtrOutputWithContext(context.Background())
}

func (i JobSparksqlConfigArgs) ToJobSparksqlConfigPtrOutputWithContext(ctx context.Context) JobSparksqlConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSparksqlConfigOutput).ToJobSparksqlConfigPtrOutputWithContext(ctx)
}

// JobSparksqlConfigPtrInput is an input type that accepts JobSparksqlConfigArgs, JobSparksqlConfigPtr and JobSparksqlConfigPtrOutput values.
// You can construct a concrete instance of `JobSparksqlConfigPtrInput` via:
//
// 		 JobSparksqlConfigArgs{...}
//
//  or:
//
// 		 nil
//
type JobSparksqlConfigPtrInput interface {
	pulumi.Input

	ToJobSparksqlConfigPtrOutput() JobSparksqlConfigPtrOutput
	ToJobSparksqlConfigPtrOutputWithContext(context.Context) JobSparksqlConfigPtrOutput
}

type jobSparksqlConfigPtrType JobSparksqlConfigArgs

func JobSparksqlConfigPtr(v *JobSparksqlConfigArgs) JobSparksqlConfigPtrInput {
	return (*jobSparksqlConfigPtrType)(v)
}

func (*jobSparksqlConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobSparksqlConfig)(nil)).Elem()
}

func (i *jobSparksqlConfigPtrType) ToJobSparksqlConfigPtrOutput() JobSparksqlConfigPtrOutput {
	return i.ToJobSparksqlConfigPtrOutputWithContext(context.Background())
}

func (i *jobSparksqlConfigPtrType) ToJobSparksqlConfigPtrOutputWithContext(ctx context.Context) JobSparksqlConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSparksqlConfigPtrOutput)
}

type JobSparksqlConfigOutput struct{ *pulumi.OutputState }

func (JobSparksqlConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobSparksqlConfig)(nil)).Elem()
}

func (o JobSparksqlConfigOutput) ToJobSparksqlConfigOutput() JobSparksqlConfigOutput {
	return o
}

func (o JobSparksqlConfigOutput) ToJobSparksqlConfigOutputWithContext(ctx context.Context) JobSparksqlConfigOutput {
	return o
}

func (o JobSparksqlConfigOutput) ToJobSparksqlConfigPtrOutput() JobSparksqlConfigPtrOutput {
	return o.ToJobSparksqlConfigPtrOutputWithContext(context.Background())
}

func (o JobSparksqlConfigOutput) ToJobSparksqlConfigPtrOutputWithContext(ctx context.Context) JobSparksqlConfigPtrOutput {
	return o.ApplyT(func(v JobSparksqlConfig) *JobSparksqlConfig {
		return &v
	}).(JobSparksqlConfigPtrOutput)
}

// HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o JobSparksqlConfigOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobSparksqlConfig) []string { return v.JarFileUris }).(pulumi.StringArrayOutput)
}

func (o JobSparksqlConfigOutput) LoggingConfig() JobSparksqlConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v JobSparksqlConfig) *JobSparksqlConfigLoggingConfig { return v.LoggingConfig }).(JobSparksqlConfigLoggingConfigPtrOutput)
}

// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
func (o JobSparksqlConfigOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobSparksqlConfig) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains SQL queries.
// Conflicts with `queryList`
func (o JobSparksqlConfigOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobSparksqlConfig) *string { return v.QueryFileUri }).(pulumi.StringPtrOutput)
}

// The list of SQL queries or statements to execute as part of the job.
// Conflicts with `queryFileUri`
func (o JobSparksqlConfigOutput) QueryLists() pulumi.StringArrayOutput {
	return o.ApplyT(func(v JobSparksqlConfig) []string { return v.QueryLists }).(pulumi.StringArrayOutput)
}

// Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
func (o JobSparksqlConfigOutput) ScriptVariables() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobSparksqlConfig) map[string]string { return v.ScriptVariables }).(pulumi.StringMapOutput)
}

type JobSparksqlConfigPtrOutput struct{ *pulumi.OutputState }

func (JobSparksqlConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobSparksqlConfig)(nil)).Elem()
}

func (o JobSparksqlConfigPtrOutput) ToJobSparksqlConfigPtrOutput() JobSparksqlConfigPtrOutput {
	return o
}

func (o JobSparksqlConfigPtrOutput) ToJobSparksqlConfigPtrOutputWithContext(ctx context.Context) JobSparksqlConfigPtrOutput {
	return o
}

func (o JobSparksqlConfigPtrOutput) Elem() JobSparksqlConfigOutput {
	return o.ApplyT(func(v *JobSparksqlConfig) JobSparksqlConfig { return *v }).(JobSparksqlConfigOutput)
}

// HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o JobSparksqlConfigPtrOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobSparksqlConfig) []string {
		if v == nil {
			return nil
		}
		return v.JarFileUris
	}).(pulumi.StringArrayOutput)
}

func (o JobSparksqlConfigPtrOutput) LoggingConfig() JobSparksqlConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v *JobSparksqlConfig) *JobSparksqlConfigLoggingConfig {
		if v == nil {
			return nil
		}
		return v.LoggingConfig
	}).(JobSparksqlConfigLoggingConfigPtrOutput)
}

// A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
func (o JobSparksqlConfigPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobSparksqlConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains SQL queries.
// Conflicts with `queryList`
func (o JobSparksqlConfigPtrOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobSparksqlConfig) *string {
		if v == nil {
			return nil
		}
		return v.QueryFileUri
	}).(pulumi.StringPtrOutput)
}

// The list of SQL queries or statements to execute as part of the job.
// Conflicts with `queryFileUri`
func (o JobSparksqlConfigPtrOutput) QueryLists() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *JobSparksqlConfig) []string {
		if v == nil {
			return nil
		}
		return v.QueryLists
	}).(pulumi.StringArrayOutput)
}

// Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
func (o JobSparksqlConfigPtrOutput) ScriptVariables() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobSparksqlConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.ScriptVariables
	}).(pulumi.StringMapOutput)
}

type JobSparksqlConfigLoggingConfig struct {
	DriverLogLevels map[string]string `pulumi:"driverLogLevels"`
}

// JobSparksqlConfigLoggingConfigInput is an input type that accepts JobSparksqlConfigLoggingConfigArgs and JobSparksqlConfigLoggingConfigOutput values.
// You can construct a concrete instance of `JobSparksqlConfigLoggingConfigInput` via:
//
// 		 JobSparksqlConfigLoggingConfigArgs{...}
//
type JobSparksqlConfigLoggingConfigInput interface {
	pulumi.Input

	ToJobSparksqlConfigLoggingConfigOutput() JobSparksqlConfigLoggingConfigOutput
	ToJobSparksqlConfigLoggingConfigOutputWithContext(context.Context) JobSparksqlConfigLoggingConfigOutput
}

type JobSparksqlConfigLoggingConfigArgs struct {
	DriverLogLevels pulumi.StringMapInput `pulumi:"driverLogLevels"`
}

func (JobSparksqlConfigLoggingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobSparksqlConfigLoggingConfig)(nil)).Elem()
}

func (i JobSparksqlConfigLoggingConfigArgs) ToJobSparksqlConfigLoggingConfigOutput() JobSparksqlConfigLoggingConfigOutput {
	return i.ToJobSparksqlConfigLoggingConfigOutputWithContext(context.Background())
}

func (i JobSparksqlConfigLoggingConfigArgs) ToJobSparksqlConfigLoggingConfigOutputWithContext(ctx context.Context) JobSparksqlConfigLoggingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSparksqlConfigLoggingConfigOutput)
}

func (i JobSparksqlConfigLoggingConfigArgs) ToJobSparksqlConfigLoggingConfigPtrOutput() JobSparksqlConfigLoggingConfigPtrOutput {
	return i.ToJobSparksqlConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (i JobSparksqlConfigLoggingConfigArgs) ToJobSparksqlConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobSparksqlConfigLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSparksqlConfigLoggingConfigOutput).ToJobSparksqlConfigLoggingConfigPtrOutputWithContext(ctx)
}

// JobSparksqlConfigLoggingConfigPtrInput is an input type that accepts JobSparksqlConfigLoggingConfigArgs, JobSparksqlConfigLoggingConfigPtr and JobSparksqlConfigLoggingConfigPtrOutput values.
// You can construct a concrete instance of `JobSparksqlConfigLoggingConfigPtrInput` via:
//
// 		 JobSparksqlConfigLoggingConfigArgs{...}
//
//  or:
//
// 		 nil
//
type JobSparksqlConfigLoggingConfigPtrInput interface {
	pulumi.Input

	ToJobSparksqlConfigLoggingConfigPtrOutput() JobSparksqlConfigLoggingConfigPtrOutput
	ToJobSparksqlConfigLoggingConfigPtrOutputWithContext(context.Context) JobSparksqlConfigLoggingConfigPtrOutput
}

type jobSparksqlConfigLoggingConfigPtrType JobSparksqlConfigLoggingConfigArgs

func JobSparksqlConfigLoggingConfigPtr(v *JobSparksqlConfigLoggingConfigArgs) JobSparksqlConfigLoggingConfigPtrInput {
	return (*jobSparksqlConfigLoggingConfigPtrType)(v)
}

func (*jobSparksqlConfigLoggingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobSparksqlConfigLoggingConfig)(nil)).Elem()
}

func (i *jobSparksqlConfigLoggingConfigPtrType) ToJobSparksqlConfigLoggingConfigPtrOutput() JobSparksqlConfigLoggingConfigPtrOutput {
	return i.ToJobSparksqlConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (i *jobSparksqlConfigLoggingConfigPtrType) ToJobSparksqlConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobSparksqlConfigLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSparksqlConfigLoggingConfigPtrOutput)
}

type JobSparksqlConfigLoggingConfigOutput struct{ *pulumi.OutputState }

func (JobSparksqlConfigLoggingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobSparksqlConfigLoggingConfig)(nil)).Elem()
}

func (o JobSparksqlConfigLoggingConfigOutput) ToJobSparksqlConfigLoggingConfigOutput() JobSparksqlConfigLoggingConfigOutput {
	return o
}

func (o JobSparksqlConfigLoggingConfigOutput) ToJobSparksqlConfigLoggingConfigOutputWithContext(ctx context.Context) JobSparksqlConfigLoggingConfigOutput {
	return o
}

func (o JobSparksqlConfigLoggingConfigOutput) ToJobSparksqlConfigLoggingConfigPtrOutput() JobSparksqlConfigLoggingConfigPtrOutput {
	return o.ToJobSparksqlConfigLoggingConfigPtrOutputWithContext(context.Background())
}

func (o JobSparksqlConfigLoggingConfigOutput) ToJobSparksqlConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobSparksqlConfigLoggingConfigPtrOutput {
	return o.ApplyT(func(v JobSparksqlConfigLoggingConfig) *JobSparksqlConfigLoggingConfig {
		return &v
	}).(JobSparksqlConfigLoggingConfigPtrOutput)
}
func (o JobSparksqlConfigLoggingConfigOutput) DriverLogLevels() pulumi.StringMapOutput {
	return o.ApplyT(func(v JobSparksqlConfigLoggingConfig) map[string]string { return v.DriverLogLevels }).(pulumi.StringMapOutput)
}

type JobSparksqlConfigLoggingConfigPtrOutput struct{ *pulumi.OutputState }

func (JobSparksqlConfigLoggingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobSparksqlConfigLoggingConfig)(nil)).Elem()
}

func (o JobSparksqlConfigLoggingConfigPtrOutput) ToJobSparksqlConfigLoggingConfigPtrOutput() JobSparksqlConfigLoggingConfigPtrOutput {
	return o
}

func (o JobSparksqlConfigLoggingConfigPtrOutput) ToJobSparksqlConfigLoggingConfigPtrOutputWithContext(ctx context.Context) JobSparksqlConfigLoggingConfigPtrOutput {
	return o
}

func (o JobSparksqlConfigLoggingConfigPtrOutput) Elem() JobSparksqlConfigLoggingConfigOutput {
	return o.ApplyT(func(v *JobSparksqlConfigLoggingConfig) JobSparksqlConfigLoggingConfig { return *v }).(JobSparksqlConfigLoggingConfigOutput)
}

func (o JobSparksqlConfigLoggingConfigPtrOutput) DriverLogLevels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *JobSparksqlConfigLoggingConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.DriverLogLevels
	}).(pulumi.StringMapOutput)
}

type JobStatus struct {
	Details        *string `pulumi:"details"`
	State          *string `pulumi:"state"`
	StateStartTime *string `pulumi:"stateStartTime"`
	Substate       *string `pulumi:"substate"`
}

// JobStatusInput is an input type that accepts JobStatusArgs and JobStatusOutput values.
// You can construct a concrete instance of `JobStatusInput` via:
//
// 		 JobStatusArgs{...}
//
type JobStatusInput interface {
	pulumi.Input

	ToJobStatusOutput() JobStatusOutput
	ToJobStatusOutputWithContext(context.Context) JobStatusOutput
}

type JobStatusArgs struct {
	Details        pulumi.StringPtrInput `pulumi:"details"`
	State          pulumi.StringPtrInput `pulumi:"state"`
	StateStartTime pulumi.StringPtrInput `pulumi:"stateStartTime"`
	Substate       pulumi.StringPtrInput `pulumi:"substate"`
}

func (JobStatusArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobStatus)(nil)).Elem()
}

func (i JobStatusArgs) ToJobStatusOutput() JobStatusOutput {
	return i.ToJobStatusOutputWithContext(context.Background())
}

func (i JobStatusArgs) ToJobStatusOutputWithContext(ctx context.Context) JobStatusOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobStatusOutput)
}

func (i JobStatusArgs) ToJobStatusPtrOutput() JobStatusPtrOutput {
	return i.ToJobStatusPtrOutputWithContext(context.Background())
}

func (i JobStatusArgs) ToJobStatusPtrOutputWithContext(ctx context.Context) JobStatusPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobStatusOutput).ToJobStatusPtrOutputWithContext(ctx)
}

// JobStatusPtrInput is an input type that accepts JobStatusArgs, JobStatusPtr and JobStatusPtrOutput values.
// You can construct a concrete instance of `JobStatusPtrInput` via:
//
// 		 JobStatusArgs{...}
//
//  or:
//
// 		 nil
//
type JobStatusPtrInput interface {
	pulumi.Input

	ToJobStatusPtrOutput() JobStatusPtrOutput
	ToJobStatusPtrOutputWithContext(context.Context) JobStatusPtrOutput
}

type jobStatusPtrType JobStatusArgs

func JobStatusPtr(v *JobStatusArgs) JobStatusPtrInput {
	return (*jobStatusPtrType)(v)
}

func (*jobStatusPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobStatus)(nil)).Elem()
}

func (i *jobStatusPtrType) ToJobStatusPtrOutput() JobStatusPtrOutput {
	return i.ToJobStatusPtrOutputWithContext(context.Background())
}

func (i *jobStatusPtrType) ToJobStatusPtrOutputWithContext(ctx context.Context) JobStatusPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobStatusPtrOutput)
}

type JobStatusOutput struct{ *pulumi.OutputState }

func (JobStatusOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobStatus)(nil)).Elem()
}

func (o JobStatusOutput) ToJobStatusOutput() JobStatusOutput {
	return o
}

func (o JobStatusOutput) ToJobStatusOutputWithContext(ctx context.Context) JobStatusOutput {
	return o
}

func (o JobStatusOutput) ToJobStatusPtrOutput() JobStatusPtrOutput {
	return o.ToJobStatusPtrOutputWithContext(context.Background())
}

func (o JobStatusOutput) ToJobStatusPtrOutputWithContext(ctx context.Context) JobStatusPtrOutput {
	return o.ApplyT(func(v JobStatus) *JobStatus {
		return &v
	}).(JobStatusPtrOutput)
}
func (o JobStatusOutput) Details() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobStatus) *string { return v.Details }).(pulumi.StringPtrOutput)
}

func (o JobStatusOutput) State() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobStatus) *string { return v.State }).(pulumi.StringPtrOutput)
}

func (o JobStatusOutput) StateStartTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobStatus) *string { return v.StateStartTime }).(pulumi.StringPtrOutput)
}

func (o JobStatusOutput) Substate() pulumi.StringPtrOutput {
	return o.ApplyT(func(v JobStatus) *string { return v.Substate }).(pulumi.StringPtrOutput)
}

type JobStatusPtrOutput struct{ *pulumi.OutputState }

func (JobStatusPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobStatus)(nil)).Elem()
}

func (o JobStatusPtrOutput) ToJobStatusPtrOutput() JobStatusPtrOutput {
	return o
}

func (o JobStatusPtrOutput) ToJobStatusPtrOutputWithContext(ctx context.Context) JobStatusPtrOutput {
	return o
}

func (o JobStatusPtrOutput) Elem() JobStatusOutput {
	return o.ApplyT(func(v *JobStatus) JobStatus { return *v }).(JobStatusOutput)
}

func (o JobStatusPtrOutput) Details() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobStatus) *string {
		if v == nil {
			return nil
		}
		return v.Details
	}).(pulumi.StringPtrOutput)
}

func (o JobStatusPtrOutput) State() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobStatus) *string {
		if v == nil {
			return nil
		}
		return v.State
	}).(pulumi.StringPtrOutput)
}

func (o JobStatusPtrOutput) StateStartTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobStatus) *string {
		if v == nil {
			return nil
		}
		return v.StateStartTime
	}).(pulumi.StringPtrOutput)
}

func (o JobStatusPtrOutput) Substate() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *JobStatus) *string {
		if v == nil {
			return nil
		}
		return v.Substate
	}).(pulumi.StringPtrOutput)
}

func init() {
	pulumi.RegisterOutputType(AutoscalingPolicyBasicAlgorithmOutput{})
	pulumi.RegisterOutputType(AutoscalingPolicyBasicAlgorithmPtrOutput{})
	pulumi.RegisterOutputType(AutoscalingPolicyBasicAlgorithmYarnConfigOutput{})
	pulumi.RegisterOutputType(AutoscalingPolicyBasicAlgorithmYarnConfigPtrOutput{})
	pulumi.RegisterOutputType(AutoscalingPolicySecondaryWorkerConfigOutput{})
	pulumi.RegisterOutputType(AutoscalingPolicySecondaryWorkerConfigPtrOutput{})
	pulumi.RegisterOutputType(AutoscalingPolicyWorkerConfigOutput{})
	pulumi.RegisterOutputType(AutoscalingPolicyWorkerConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigAutoscalingConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigAutoscalingConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigEncryptionConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigEncryptionConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigGceClusterConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigGceClusterConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigInitializationActionOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigInitializationActionArrayOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigLifecycleConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigLifecycleConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigMasterConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigMasterConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigMasterConfigAcceleratorOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigMasterConfigAcceleratorArrayOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigMasterConfigDiskConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigMasterConfigDiskConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigPreemptibleWorkerConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigPreemptibleWorkerConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigPreemptibleWorkerConfigDiskConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigPreemptibleWorkerConfigDiskConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigSecurityConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigSecurityConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigSecurityConfigKerberosConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigSecurityConfigKerberosConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigSoftwareConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigSoftwareConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigWorkerConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigWorkerConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigWorkerConfigAcceleratorOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigWorkerConfigAcceleratorArrayOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigWorkerConfigDiskConfigOutput{})
	pulumi.RegisterOutputType(ClusterClusterConfigWorkerConfigDiskConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterIAMBindingConditionOutput{})
	pulumi.RegisterOutputType(ClusterIAMBindingConditionPtrOutput{})
	pulumi.RegisterOutputType(ClusterIAMMemberConditionOutput{})
	pulumi.RegisterOutputType(ClusterIAMMemberConditionPtrOutput{})
	pulumi.RegisterOutputType(JobHadoopConfigOutput{})
	pulumi.RegisterOutputType(JobHadoopConfigPtrOutput{})
	pulumi.RegisterOutputType(JobHadoopConfigLoggingConfigOutput{})
	pulumi.RegisterOutputType(JobHadoopConfigLoggingConfigPtrOutput{})
	pulumi.RegisterOutputType(JobHiveConfigOutput{})
	pulumi.RegisterOutputType(JobHiveConfigPtrOutput{})
	pulumi.RegisterOutputType(JobIAMBindingConditionOutput{})
	pulumi.RegisterOutputType(JobIAMBindingConditionPtrOutput{})
	pulumi.RegisterOutputType(JobIAMMemberConditionOutput{})
	pulumi.RegisterOutputType(JobIAMMemberConditionPtrOutput{})
	pulumi.RegisterOutputType(JobPigConfigOutput{})
	pulumi.RegisterOutputType(JobPigConfigPtrOutput{})
	pulumi.RegisterOutputType(JobPigConfigLoggingConfigOutput{})
	pulumi.RegisterOutputType(JobPigConfigLoggingConfigPtrOutput{})
	pulumi.RegisterOutputType(JobPlacementOutput{})
	pulumi.RegisterOutputType(JobPlacementPtrOutput{})
	pulumi.RegisterOutputType(JobPysparkConfigOutput{})
	pulumi.RegisterOutputType(JobPysparkConfigPtrOutput{})
	pulumi.RegisterOutputType(JobPysparkConfigLoggingConfigOutput{})
	pulumi.RegisterOutputType(JobPysparkConfigLoggingConfigPtrOutput{})
	pulumi.RegisterOutputType(JobReferenceOutput{})
	pulumi.RegisterOutputType(JobReferencePtrOutput{})
	pulumi.RegisterOutputType(JobSchedulingOutput{})
	pulumi.RegisterOutputType(JobSchedulingPtrOutput{})
	pulumi.RegisterOutputType(JobSparkConfigOutput{})
	pulumi.RegisterOutputType(JobSparkConfigPtrOutput{})
	pulumi.RegisterOutputType(JobSparkConfigLoggingConfigOutput{})
	pulumi.RegisterOutputType(JobSparkConfigLoggingConfigPtrOutput{})
	pulumi.RegisterOutputType(JobSparksqlConfigOutput{})
	pulumi.RegisterOutputType(JobSparksqlConfigPtrOutput{})
	pulumi.RegisterOutputType(JobSparksqlConfigLoggingConfigOutput{})
	pulumi.RegisterOutputType(JobSparksqlConfigLoggingConfigPtrOutput{})
	pulumi.RegisterOutputType(JobStatusOutput{})
	pulumi.RegisterOutputType(JobStatusPtrOutput{})
}
