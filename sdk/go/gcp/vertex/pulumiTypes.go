// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package vertex

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi-gcp/sdk/v6/go/gcp/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

var _ = internal.GetEnvOrDefault

type AiDatasetEncryptionSpec struct {
	// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
	// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
	KmsKeyName *string `pulumi:"kmsKeyName"`
}

// AiDatasetEncryptionSpecInput is an input type that accepts AiDatasetEncryptionSpecArgs and AiDatasetEncryptionSpecOutput values.
// You can construct a concrete instance of `AiDatasetEncryptionSpecInput` via:
//
//	AiDatasetEncryptionSpecArgs{...}
type AiDatasetEncryptionSpecInput interface {
	pulumi.Input

	ToAiDatasetEncryptionSpecOutput() AiDatasetEncryptionSpecOutput
	ToAiDatasetEncryptionSpecOutputWithContext(context.Context) AiDatasetEncryptionSpecOutput
}

type AiDatasetEncryptionSpecArgs struct {
	// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
	// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
	KmsKeyName pulumi.StringPtrInput `pulumi:"kmsKeyName"`
}

func (AiDatasetEncryptionSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiDatasetEncryptionSpec)(nil)).Elem()
}

func (i AiDatasetEncryptionSpecArgs) ToAiDatasetEncryptionSpecOutput() AiDatasetEncryptionSpecOutput {
	return i.ToAiDatasetEncryptionSpecOutputWithContext(context.Background())
}

func (i AiDatasetEncryptionSpecArgs) ToAiDatasetEncryptionSpecOutputWithContext(ctx context.Context) AiDatasetEncryptionSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDatasetEncryptionSpecOutput)
}

func (i AiDatasetEncryptionSpecArgs) ToAiDatasetEncryptionSpecPtrOutput() AiDatasetEncryptionSpecPtrOutput {
	return i.ToAiDatasetEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i AiDatasetEncryptionSpecArgs) ToAiDatasetEncryptionSpecPtrOutputWithContext(ctx context.Context) AiDatasetEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDatasetEncryptionSpecOutput).ToAiDatasetEncryptionSpecPtrOutputWithContext(ctx)
}

// AiDatasetEncryptionSpecPtrInput is an input type that accepts AiDatasetEncryptionSpecArgs, AiDatasetEncryptionSpecPtr and AiDatasetEncryptionSpecPtrOutput values.
// You can construct a concrete instance of `AiDatasetEncryptionSpecPtrInput` via:
//
//	        AiDatasetEncryptionSpecArgs{...}
//
//	or:
//
//	        nil
type AiDatasetEncryptionSpecPtrInput interface {
	pulumi.Input

	ToAiDatasetEncryptionSpecPtrOutput() AiDatasetEncryptionSpecPtrOutput
	ToAiDatasetEncryptionSpecPtrOutputWithContext(context.Context) AiDatasetEncryptionSpecPtrOutput
}

type aiDatasetEncryptionSpecPtrType AiDatasetEncryptionSpecArgs

func AiDatasetEncryptionSpecPtr(v *AiDatasetEncryptionSpecArgs) AiDatasetEncryptionSpecPtrInput {
	return (*aiDatasetEncryptionSpecPtrType)(v)
}

func (*aiDatasetEncryptionSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiDatasetEncryptionSpec)(nil)).Elem()
}

func (i *aiDatasetEncryptionSpecPtrType) ToAiDatasetEncryptionSpecPtrOutput() AiDatasetEncryptionSpecPtrOutput {
	return i.ToAiDatasetEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i *aiDatasetEncryptionSpecPtrType) ToAiDatasetEncryptionSpecPtrOutputWithContext(ctx context.Context) AiDatasetEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDatasetEncryptionSpecPtrOutput)
}

type AiDatasetEncryptionSpecOutput struct{ *pulumi.OutputState }

func (AiDatasetEncryptionSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiDatasetEncryptionSpec)(nil)).Elem()
}

func (o AiDatasetEncryptionSpecOutput) ToAiDatasetEncryptionSpecOutput() AiDatasetEncryptionSpecOutput {
	return o
}

func (o AiDatasetEncryptionSpecOutput) ToAiDatasetEncryptionSpecOutputWithContext(ctx context.Context) AiDatasetEncryptionSpecOutput {
	return o
}

func (o AiDatasetEncryptionSpecOutput) ToAiDatasetEncryptionSpecPtrOutput() AiDatasetEncryptionSpecPtrOutput {
	return o.ToAiDatasetEncryptionSpecPtrOutputWithContext(context.Background())
}

func (o AiDatasetEncryptionSpecOutput) ToAiDatasetEncryptionSpecPtrOutputWithContext(ctx context.Context) AiDatasetEncryptionSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiDatasetEncryptionSpec) *AiDatasetEncryptionSpec {
		return &v
	}).(AiDatasetEncryptionSpecPtrOutput)
}

// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
func (o AiDatasetEncryptionSpecOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiDatasetEncryptionSpec) *string { return v.KmsKeyName }).(pulumi.StringPtrOutput)
}

type AiDatasetEncryptionSpecPtrOutput struct{ *pulumi.OutputState }

func (AiDatasetEncryptionSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiDatasetEncryptionSpec)(nil)).Elem()
}

func (o AiDatasetEncryptionSpecPtrOutput) ToAiDatasetEncryptionSpecPtrOutput() AiDatasetEncryptionSpecPtrOutput {
	return o
}

func (o AiDatasetEncryptionSpecPtrOutput) ToAiDatasetEncryptionSpecPtrOutputWithContext(ctx context.Context) AiDatasetEncryptionSpecPtrOutput {
	return o
}

func (o AiDatasetEncryptionSpecPtrOutput) Elem() AiDatasetEncryptionSpecOutput {
	return o.ApplyT(func(v *AiDatasetEncryptionSpec) AiDatasetEncryptionSpec {
		if v != nil {
			return *v
		}
		var ret AiDatasetEncryptionSpec
		return ret
	}).(AiDatasetEncryptionSpecOutput)
}

// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
func (o AiDatasetEncryptionSpecPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiDatasetEncryptionSpec) *string {
		if v == nil {
			return nil
		}
		return v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type AiEndpointDeployedModel struct {
	// (Output)
	// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.
	// Structure is documented below.
	AutomaticResources []AiEndpointDeployedModelAutomaticResource `pulumi:"automaticResources"`
	// (Output)
	// Output only. Timestamp when the DeployedModel was created.
	CreateTime *string `pulumi:"createTime"`
	// (Output)
	// A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
	// Structure is documented below.
	DedicatedResources []AiEndpointDeployedModelDedicatedResource `pulumi:"dedicatedResources"`
	// Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName *string `pulumi:"displayName"`
	// (Output)
	// These logs are like standard server access logs, containing information like timestamp and latency for each prediction request. Note that Stackdriver logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.
	EnableAccessLogging *bool `pulumi:"enableAccessLogging"`
	// (Output)
	// If true, the container of the DeployedModel instances will send `stderr` and `stdout` streams to Stackdriver Logging. Only supported for custom-trained Models and AutoML Tabular Models.
	EnableContainerLogging *bool `pulumi:"enableContainerLogging"`
	// (Output)
	// The ID of the DeployedModel. If not provided upon deployment, Vertex AI will generate a value for this ID. This value should be 1-10 characters, and valid characters are /[0-9]/.
	Id *string `pulumi:"id"`
	// (Output)
	// The name of the Model that this is the deployment of. Note that the Model may be in a different location than the DeployedModel's Endpoint.
	Model *string `pulumi:"model"`
	// (Output)
	// Output only. The version ID of the model that is deployed.
	ModelVersionId *string `pulumi:"modelVersionId"`
	// (Output)
	// Output only. Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
	// Structure is documented below.
	PrivateEndpoints []AiEndpointDeployedModelPrivateEndpoint `pulumi:"privateEndpoints"`
	// (Output)
	// The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project. Users deploying the Model must have the `iam.serviceAccounts.actAs` permission on this service account.
	ServiceAccount *string `pulumi:"serviceAccount"`
	// (Output)
	// The resource name of the shared DeploymentResourcePool to deploy on. Format: projects/{project}/locations/{location}/deploymentResourcePools/{deployment_resource_pool}
	SharedResources *string `pulumi:"sharedResources"`
}

// AiEndpointDeployedModelInput is an input type that accepts AiEndpointDeployedModelArgs and AiEndpointDeployedModelOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelInput` via:
//
//	AiEndpointDeployedModelArgs{...}
type AiEndpointDeployedModelInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelOutput() AiEndpointDeployedModelOutput
	ToAiEndpointDeployedModelOutputWithContext(context.Context) AiEndpointDeployedModelOutput
}

type AiEndpointDeployedModelArgs struct {
	// (Output)
	// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.
	// Structure is documented below.
	AutomaticResources AiEndpointDeployedModelAutomaticResourceArrayInput `pulumi:"automaticResources"`
	// (Output)
	// Output only. Timestamp when the DeployedModel was created.
	CreateTime pulumi.StringPtrInput `pulumi:"createTime"`
	// (Output)
	// A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
	// Structure is documented below.
	DedicatedResources AiEndpointDeployedModelDedicatedResourceArrayInput `pulumi:"dedicatedResources"`
	// Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName pulumi.StringPtrInput `pulumi:"displayName"`
	// (Output)
	// These logs are like standard server access logs, containing information like timestamp and latency for each prediction request. Note that Stackdriver logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.
	EnableAccessLogging pulumi.BoolPtrInput `pulumi:"enableAccessLogging"`
	// (Output)
	// If true, the container of the DeployedModel instances will send `stderr` and `stdout` streams to Stackdriver Logging. Only supported for custom-trained Models and AutoML Tabular Models.
	EnableContainerLogging pulumi.BoolPtrInput `pulumi:"enableContainerLogging"`
	// (Output)
	// The ID of the DeployedModel. If not provided upon deployment, Vertex AI will generate a value for this ID. This value should be 1-10 characters, and valid characters are /[0-9]/.
	Id pulumi.StringPtrInput `pulumi:"id"`
	// (Output)
	// The name of the Model that this is the deployment of. Note that the Model may be in a different location than the DeployedModel's Endpoint.
	Model pulumi.StringPtrInput `pulumi:"model"`
	// (Output)
	// Output only. The version ID of the model that is deployed.
	ModelVersionId pulumi.StringPtrInput `pulumi:"modelVersionId"`
	// (Output)
	// Output only. Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
	// Structure is documented below.
	PrivateEndpoints AiEndpointDeployedModelPrivateEndpointArrayInput `pulumi:"privateEndpoints"`
	// (Output)
	// The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project. Users deploying the Model must have the `iam.serviceAccounts.actAs` permission on this service account.
	ServiceAccount pulumi.StringPtrInput `pulumi:"serviceAccount"`
	// (Output)
	// The resource name of the shared DeploymentResourcePool to deploy on. Format: projects/{project}/locations/{location}/deploymentResourcePools/{deployment_resource_pool}
	SharedResources pulumi.StringPtrInput `pulumi:"sharedResources"`
}

func (AiEndpointDeployedModelArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModel)(nil)).Elem()
}

func (i AiEndpointDeployedModelArgs) ToAiEndpointDeployedModelOutput() AiEndpointDeployedModelOutput {
	return i.ToAiEndpointDeployedModelOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelArgs) ToAiEndpointDeployedModelOutputWithContext(ctx context.Context) AiEndpointDeployedModelOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelOutput)
}

// AiEndpointDeployedModelArrayInput is an input type that accepts AiEndpointDeployedModelArray and AiEndpointDeployedModelArrayOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelArrayInput` via:
//
//	AiEndpointDeployedModelArray{ AiEndpointDeployedModelArgs{...} }
type AiEndpointDeployedModelArrayInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelArrayOutput() AiEndpointDeployedModelArrayOutput
	ToAiEndpointDeployedModelArrayOutputWithContext(context.Context) AiEndpointDeployedModelArrayOutput
}

type AiEndpointDeployedModelArray []AiEndpointDeployedModelInput

func (AiEndpointDeployedModelArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModel)(nil)).Elem()
}

func (i AiEndpointDeployedModelArray) ToAiEndpointDeployedModelArrayOutput() AiEndpointDeployedModelArrayOutput {
	return i.ToAiEndpointDeployedModelArrayOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelArray) ToAiEndpointDeployedModelArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelArrayOutput)
}

type AiEndpointDeployedModelOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModel)(nil)).Elem()
}

func (o AiEndpointDeployedModelOutput) ToAiEndpointDeployedModelOutput() AiEndpointDeployedModelOutput {
	return o
}

func (o AiEndpointDeployedModelOutput) ToAiEndpointDeployedModelOutputWithContext(ctx context.Context) AiEndpointDeployedModelOutput {
	return o
}

// (Output)
// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.
// Structure is documented below.
func (o AiEndpointDeployedModelOutput) AutomaticResources() AiEndpointDeployedModelAutomaticResourceArrayOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) []AiEndpointDeployedModelAutomaticResource {
		return v.AutomaticResources
	}).(AiEndpointDeployedModelAutomaticResourceArrayOutput)
}

// (Output)
// Output only. Timestamp when the DeployedModel was created.
func (o AiEndpointDeployedModelOutput) CreateTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.CreateTime }).(pulumi.StringPtrOutput)
}

// (Output)
// A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
// Structure is documented below.
func (o AiEndpointDeployedModelOutput) DedicatedResources() AiEndpointDeployedModelDedicatedResourceArrayOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) []AiEndpointDeployedModelDedicatedResource {
		return v.DedicatedResources
	}).(AiEndpointDeployedModelDedicatedResourceArrayOutput)
}

// Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o AiEndpointDeployedModelOutput) DisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.DisplayName }).(pulumi.StringPtrOutput)
}

// (Output)
// These logs are like standard server access logs, containing information like timestamp and latency for each prediction request. Note that Stackdriver logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.
func (o AiEndpointDeployedModelOutput) EnableAccessLogging() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *bool { return v.EnableAccessLogging }).(pulumi.BoolPtrOutput)
}

// (Output)
// If true, the container of the DeployedModel instances will send `stderr` and `stdout` streams to Stackdriver Logging. Only supported for custom-trained Models and AutoML Tabular Models.
func (o AiEndpointDeployedModelOutput) EnableContainerLogging() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *bool { return v.EnableContainerLogging }).(pulumi.BoolPtrOutput)
}

// (Output)
// The ID of the DeployedModel. If not provided upon deployment, Vertex AI will generate a value for this ID. This value should be 1-10 characters, and valid characters are /[0-9]/.
func (o AiEndpointDeployedModelOutput) Id() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.Id }).(pulumi.StringPtrOutput)
}

// (Output)
// The name of the Model that this is the deployment of. Note that the Model may be in a different location than the DeployedModel's Endpoint.
func (o AiEndpointDeployedModelOutput) Model() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.Model }).(pulumi.StringPtrOutput)
}

// (Output)
// Output only. The version ID of the model that is deployed.
func (o AiEndpointDeployedModelOutput) ModelVersionId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.ModelVersionId }).(pulumi.StringPtrOutput)
}

// (Output)
// Output only. Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
// Structure is documented below.
func (o AiEndpointDeployedModelOutput) PrivateEndpoints() AiEndpointDeployedModelPrivateEndpointArrayOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) []AiEndpointDeployedModelPrivateEndpoint { return v.PrivateEndpoints }).(AiEndpointDeployedModelPrivateEndpointArrayOutput)
}

// (Output)
// The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project. Users deploying the Model must have the `iam.serviceAccounts.actAs` permission on this service account.
func (o AiEndpointDeployedModelOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.ServiceAccount }).(pulumi.StringPtrOutput)
}

// (Output)
// The resource name of the shared DeploymentResourcePool to deploy on. Format: projects/{project}/locations/{location}/deploymentResourcePools/{deployment_resource_pool}
func (o AiEndpointDeployedModelOutput) SharedResources() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.SharedResources }).(pulumi.StringPtrOutput)
}

type AiEndpointDeployedModelArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModel)(nil)).Elem()
}

func (o AiEndpointDeployedModelArrayOutput) ToAiEndpointDeployedModelArrayOutput() AiEndpointDeployedModelArrayOutput {
	return o
}

func (o AiEndpointDeployedModelArrayOutput) ToAiEndpointDeployedModelArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelArrayOutput {
	return o
}

func (o AiEndpointDeployedModelArrayOutput) Index(i pulumi.IntInput) AiEndpointDeployedModelOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointDeployedModel {
		return vs[0].([]AiEndpointDeployedModel)[vs[1].(int)]
	}).(AiEndpointDeployedModelOutput)
}

type AiEndpointDeployedModelAutomaticResource struct {
	// (Output)
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
	MaxReplicaCount *int `pulumi:"maxReplicaCount"`
	// (Output)
	// The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
	MinReplicaCount *int `pulumi:"minReplicaCount"`
}

// AiEndpointDeployedModelAutomaticResourceInput is an input type that accepts AiEndpointDeployedModelAutomaticResourceArgs and AiEndpointDeployedModelAutomaticResourceOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelAutomaticResourceInput` via:
//
//	AiEndpointDeployedModelAutomaticResourceArgs{...}
type AiEndpointDeployedModelAutomaticResourceInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelAutomaticResourceOutput() AiEndpointDeployedModelAutomaticResourceOutput
	ToAiEndpointDeployedModelAutomaticResourceOutputWithContext(context.Context) AiEndpointDeployedModelAutomaticResourceOutput
}

type AiEndpointDeployedModelAutomaticResourceArgs struct {
	// (Output)
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
	MaxReplicaCount pulumi.IntPtrInput `pulumi:"maxReplicaCount"`
	// (Output)
	// The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
	MinReplicaCount pulumi.IntPtrInput `pulumi:"minReplicaCount"`
}

func (AiEndpointDeployedModelAutomaticResourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelAutomaticResource)(nil)).Elem()
}

func (i AiEndpointDeployedModelAutomaticResourceArgs) ToAiEndpointDeployedModelAutomaticResourceOutput() AiEndpointDeployedModelAutomaticResourceOutput {
	return i.ToAiEndpointDeployedModelAutomaticResourceOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelAutomaticResourceArgs) ToAiEndpointDeployedModelAutomaticResourceOutputWithContext(ctx context.Context) AiEndpointDeployedModelAutomaticResourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelAutomaticResourceOutput)
}

// AiEndpointDeployedModelAutomaticResourceArrayInput is an input type that accepts AiEndpointDeployedModelAutomaticResourceArray and AiEndpointDeployedModelAutomaticResourceArrayOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelAutomaticResourceArrayInput` via:
//
//	AiEndpointDeployedModelAutomaticResourceArray{ AiEndpointDeployedModelAutomaticResourceArgs{...} }
type AiEndpointDeployedModelAutomaticResourceArrayInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelAutomaticResourceArrayOutput() AiEndpointDeployedModelAutomaticResourceArrayOutput
	ToAiEndpointDeployedModelAutomaticResourceArrayOutputWithContext(context.Context) AiEndpointDeployedModelAutomaticResourceArrayOutput
}

type AiEndpointDeployedModelAutomaticResourceArray []AiEndpointDeployedModelAutomaticResourceInput

func (AiEndpointDeployedModelAutomaticResourceArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelAutomaticResource)(nil)).Elem()
}

func (i AiEndpointDeployedModelAutomaticResourceArray) ToAiEndpointDeployedModelAutomaticResourceArrayOutput() AiEndpointDeployedModelAutomaticResourceArrayOutput {
	return i.ToAiEndpointDeployedModelAutomaticResourceArrayOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelAutomaticResourceArray) ToAiEndpointDeployedModelAutomaticResourceArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelAutomaticResourceArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelAutomaticResourceArrayOutput)
}

type AiEndpointDeployedModelAutomaticResourceOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelAutomaticResourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelAutomaticResource)(nil)).Elem()
}

func (o AiEndpointDeployedModelAutomaticResourceOutput) ToAiEndpointDeployedModelAutomaticResourceOutput() AiEndpointDeployedModelAutomaticResourceOutput {
	return o
}

func (o AiEndpointDeployedModelAutomaticResourceOutput) ToAiEndpointDeployedModelAutomaticResourceOutputWithContext(ctx context.Context) AiEndpointDeployedModelAutomaticResourceOutput {
	return o
}

// (Output)
// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
func (o AiEndpointDeployedModelAutomaticResourceOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelAutomaticResource) *int { return v.MaxReplicaCount }).(pulumi.IntPtrOutput)
}

// (Output)
// The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
func (o AiEndpointDeployedModelAutomaticResourceOutput) MinReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelAutomaticResource) *int { return v.MinReplicaCount }).(pulumi.IntPtrOutput)
}

type AiEndpointDeployedModelAutomaticResourceArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelAutomaticResourceArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelAutomaticResource)(nil)).Elem()
}

func (o AiEndpointDeployedModelAutomaticResourceArrayOutput) ToAiEndpointDeployedModelAutomaticResourceArrayOutput() AiEndpointDeployedModelAutomaticResourceArrayOutput {
	return o
}

func (o AiEndpointDeployedModelAutomaticResourceArrayOutput) ToAiEndpointDeployedModelAutomaticResourceArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelAutomaticResourceArrayOutput {
	return o
}

func (o AiEndpointDeployedModelAutomaticResourceArrayOutput) Index(i pulumi.IntInput) AiEndpointDeployedModelAutomaticResourceOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointDeployedModelAutomaticResource {
		return vs[0].([]AiEndpointDeployedModelAutomaticResource)[vs[1].(int)]
	}).(AiEndpointDeployedModelAutomaticResourceOutput)
}

type AiEndpointDeployedModelDedicatedResource struct {
	// (Output)
	// The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
	// Structure is documented below.
	AutoscalingMetricSpecs []AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec `pulumi:"autoscalingMetricSpecs"`
	// (Output)
	// The specification of a single machine used by the prediction.
	// Structure is documented below.
	MachineSpecs []AiEndpointDeployedModelDedicatedResourceMachineSpec `pulumi:"machineSpecs"`
	// (Output)
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
	MaxReplicaCount *int `pulumi:"maxReplicaCount"`
	// (Output)
	// The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
	MinReplicaCount *int `pulumi:"minReplicaCount"`
}

// AiEndpointDeployedModelDedicatedResourceInput is an input type that accepts AiEndpointDeployedModelDedicatedResourceArgs and AiEndpointDeployedModelDedicatedResourceOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelDedicatedResourceInput` via:
//
//	AiEndpointDeployedModelDedicatedResourceArgs{...}
type AiEndpointDeployedModelDedicatedResourceInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelDedicatedResourceOutput() AiEndpointDeployedModelDedicatedResourceOutput
	ToAiEndpointDeployedModelDedicatedResourceOutputWithContext(context.Context) AiEndpointDeployedModelDedicatedResourceOutput
}

type AiEndpointDeployedModelDedicatedResourceArgs struct {
	// (Output)
	// The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
	// Structure is documented below.
	AutoscalingMetricSpecs AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayInput `pulumi:"autoscalingMetricSpecs"`
	// (Output)
	// The specification of a single machine used by the prediction.
	// Structure is documented below.
	MachineSpecs AiEndpointDeployedModelDedicatedResourceMachineSpecArrayInput `pulumi:"machineSpecs"`
	// (Output)
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
	MaxReplicaCount pulumi.IntPtrInput `pulumi:"maxReplicaCount"`
	// (Output)
	// The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
	MinReplicaCount pulumi.IntPtrInput `pulumi:"minReplicaCount"`
}

func (AiEndpointDeployedModelDedicatedResourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelDedicatedResource)(nil)).Elem()
}

func (i AiEndpointDeployedModelDedicatedResourceArgs) ToAiEndpointDeployedModelDedicatedResourceOutput() AiEndpointDeployedModelDedicatedResourceOutput {
	return i.ToAiEndpointDeployedModelDedicatedResourceOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelDedicatedResourceArgs) ToAiEndpointDeployedModelDedicatedResourceOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelDedicatedResourceOutput)
}

// AiEndpointDeployedModelDedicatedResourceArrayInput is an input type that accepts AiEndpointDeployedModelDedicatedResourceArray and AiEndpointDeployedModelDedicatedResourceArrayOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelDedicatedResourceArrayInput` via:
//
//	AiEndpointDeployedModelDedicatedResourceArray{ AiEndpointDeployedModelDedicatedResourceArgs{...} }
type AiEndpointDeployedModelDedicatedResourceArrayInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelDedicatedResourceArrayOutput() AiEndpointDeployedModelDedicatedResourceArrayOutput
	ToAiEndpointDeployedModelDedicatedResourceArrayOutputWithContext(context.Context) AiEndpointDeployedModelDedicatedResourceArrayOutput
}

type AiEndpointDeployedModelDedicatedResourceArray []AiEndpointDeployedModelDedicatedResourceInput

func (AiEndpointDeployedModelDedicatedResourceArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelDedicatedResource)(nil)).Elem()
}

func (i AiEndpointDeployedModelDedicatedResourceArray) ToAiEndpointDeployedModelDedicatedResourceArrayOutput() AiEndpointDeployedModelDedicatedResourceArrayOutput {
	return i.ToAiEndpointDeployedModelDedicatedResourceArrayOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelDedicatedResourceArray) ToAiEndpointDeployedModelDedicatedResourceArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelDedicatedResourceArrayOutput)
}

type AiEndpointDeployedModelDedicatedResourceOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelDedicatedResourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelDedicatedResource)(nil)).Elem()
}

func (o AiEndpointDeployedModelDedicatedResourceOutput) ToAiEndpointDeployedModelDedicatedResourceOutput() AiEndpointDeployedModelDedicatedResourceOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceOutput) ToAiEndpointDeployedModelDedicatedResourceOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceOutput {
	return o
}

// (Output)
// The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
// Structure is documented below.
func (o AiEndpointDeployedModelDedicatedResourceOutput) AutoscalingMetricSpecs() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResource) []AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec {
		return v.AutoscalingMetricSpecs
	}).(AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput)
}

// (Output)
// The specification of a single machine used by the prediction.
// Structure is documented below.
func (o AiEndpointDeployedModelDedicatedResourceOutput) MachineSpecs() AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResource) []AiEndpointDeployedModelDedicatedResourceMachineSpec {
		return v.MachineSpecs
	}).(AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput)
}

// (Output)
// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
func (o AiEndpointDeployedModelDedicatedResourceOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResource) *int { return v.MaxReplicaCount }).(pulumi.IntPtrOutput)
}

// (Output)
// The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
func (o AiEndpointDeployedModelDedicatedResourceOutput) MinReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResource) *int { return v.MinReplicaCount }).(pulumi.IntPtrOutput)
}

type AiEndpointDeployedModelDedicatedResourceArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelDedicatedResourceArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelDedicatedResource)(nil)).Elem()
}

func (o AiEndpointDeployedModelDedicatedResourceArrayOutput) ToAiEndpointDeployedModelDedicatedResourceArrayOutput() AiEndpointDeployedModelDedicatedResourceArrayOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceArrayOutput) ToAiEndpointDeployedModelDedicatedResourceArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceArrayOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceArrayOutput) Index(i pulumi.IntInput) AiEndpointDeployedModelDedicatedResourceOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointDeployedModelDedicatedResource {
		return vs[0].([]AiEndpointDeployedModelDedicatedResource)[vs[1].(int)]
	}).(AiEndpointDeployedModelDedicatedResourceOutput)
}

type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec struct {
	// (Output)
	// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName *string `pulumi:"metricName"`
	// (Output)
	// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
	Target *int `pulumi:"target"`
}

// AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecInput is an input type that accepts AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs and AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecInput` via:
//
//	AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs{...}
type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput
	ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutputWithContext(context.Context) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput
}

type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs struct {
	// (Output)
	// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName pulumi.StringPtrInput `pulumi:"metricName"`
	// (Output)
	// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
	Target pulumi.IntPtrInput `pulumi:"target"`
}

func (AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec)(nil)).Elem()
}

func (i AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput {
	return i.ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput)
}

// AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayInput is an input type that accepts AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray and AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayInput` via:
//
//	AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray{ AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs{...} }
type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput
	ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutputWithContext(context.Context) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput
}

type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray []AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecInput

func (AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec)(nil)).Elem()
}

func (i AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput {
	return i.ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput)
}

type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec)(nil)).Elem()
}

func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput {
	return o
}

// (Output)
// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput) MetricName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec) *string { return v.MetricName }).(pulumi.StringPtrOutput)
}

// (Output)
// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput) Target() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec) *int { return v.Target }).(pulumi.IntPtrOutput)
}

type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec)(nil)).Elem()
}

func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput) Index(i pulumi.IntInput) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec {
		return vs[0].([]AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec)[vs[1].(int)]
	}).(AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput)
}

type AiEndpointDeployedModelDedicatedResourceMachineSpec struct {
	// (Output)
	// The number of accelerators to attach to the machine.
	AcceleratorCount *int `pulumi:"acceleratorCount"`
	// (Output)
	// The type of accelerator(s) that may be attached to the machine as per accelerator_count. See possible values [here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType).
	AcceleratorType *string `pulumi:"acceleratorType"`
	// (Output)
	// The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required. TODO(rsurowka): Try to better unify the required vs optional.
	MachineType *string `pulumi:"machineType"`
}

// AiEndpointDeployedModelDedicatedResourceMachineSpecInput is an input type that accepts AiEndpointDeployedModelDedicatedResourceMachineSpecArgs and AiEndpointDeployedModelDedicatedResourceMachineSpecOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelDedicatedResourceMachineSpecInput` via:
//
//	AiEndpointDeployedModelDedicatedResourceMachineSpecArgs{...}
type AiEndpointDeployedModelDedicatedResourceMachineSpecInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutput() AiEndpointDeployedModelDedicatedResourceMachineSpecOutput
	ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutputWithContext(context.Context) AiEndpointDeployedModelDedicatedResourceMachineSpecOutput
}

type AiEndpointDeployedModelDedicatedResourceMachineSpecArgs struct {
	// (Output)
	// The number of accelerators to attach to the machine.
	AcceleratorCount pulumi.IntPtrInput `pulumi:"acceleratorCount"`
	// (Output)
	// The type of accelerator(s) that may be attached to the machine as per accelerator_count. See possible values [here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType).
	AcceleratorType pulumi.StringPtrInput `pulumi:"acceleratorType"`
	// (Output)
	// The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required. TODO(rsurowka): Try to better unify the required vs optional.
	MachineType pulumi.StringPtrInput `pulumi:"machineType"`
}

func (AiEndpointDeployedModelDedicatedResourceMachineSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceMachineSpec)(nil)).Elem()
}

func (i AiEndpointDeployedModelDedicatedResourceMachineSpecArgs) ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutput() AiEndpointDeployedModelDedicatedResourceMachineSpecOutput {
	return i.ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelDedicatedResourceMachineSpecArgs) ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceMachineSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelDedicatedResourceMachineSpecOutput)
}

// AiEndpointDeployedModelDedicatedResourceMachineSpecArrayInput is an input type that accepts AiEndpointDeployedModelDedicatedResourceMachineSpecArray and AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelDedicatedResourceMachineSpecArrayInput` via:
//
//	AiEndpointDeployedModelDedicatedResourceMachineSpecArray{ AiEndpointDeployedModelDedicatedResourceMachineSpecArgs{...} }
type AiEndpointDeployedModelDedicatedResourceMachineSpecArrayInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput() AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput
	ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutputWithContext(context.Context) AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput
}

type AiEndpointDeployedModelDedicatedResourceMachineSpecArray []AiEndpointDeployedModelDedicatedResourceMachineSpecInput

func (AiEndpointDeployedModelDedicatedResourceMachineSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelDedicatedResourceMachineSpec)(nil)).Elem()
}

func (i AiEndpointDeployedModelDedicatedResourceMachineSpecArray) ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput() AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput {
	return i.ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelDedicatedResourceMachineSpecArray) ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput)
}

type AiEndpointDeployedModelDedicatedResourceMachineSpecOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelDedicatedResourceMachineSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceMachineSpec)(nil)).Elem()
}

func (o AiEndpointDeployedModelDedicatedResourceMachineSpecOutput) ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutput() AiEndpointDeployedModelDedicatedResourceMachineSpecOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceMachineSpecOutput) ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceMachineSpecOutput {
	return o
}

// (Output)
// The number of accelerators to attach to the machine.
func (o AiEndpointDeployedModelDedicatedResourceMachineSpecOutput) AcceleratorCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResourceMachineSpec) *int { return v.AcceleratorCount }).(pulumi.IntPtrOutput)
}

// (Output)
// The type of accelerator(s) that may be attached to the machine as per accelerator_count. See possible values [here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType).
func (o AiEndpointDeployedModelDedicatedResourceMachineSpecOutput) AcceleratorType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResourceMachineSpec) *string { return v.AcceleratorType }).(pulumi.StringPtrOutput)
}

// (Output)
// The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required. TODO(rsurowka): Try to better unify the required vs optional.
func (o AiEndpointDeployedModelDedicatedResourceMachineSpecOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResourceMachineSpec) *string { return v.MachineType }).(pulumi.StringPtrOutput)
}

type AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelDedicatedResourceMachineSpec)(nil)).Elem()
}

func (o AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput) ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput() AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput) ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput) Index(i pulumi.IntInput) AiEndpointDeployedModelDedicatedResourceMachineSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointDeployedModelDedicatedResourceMachineSpec {
		return vs[0].([]AiEndpointDeployedModelDedicatedResourceMachineSpec)[vs[1].(int)]
	}).(AiEndpointDeployedModelDedicatedResourceMachineSpecOutput)
}

type AiEndpointDeployedModelPrivateEndpoint struct {
	// (Output)
	// Output only. Http(s) path to send explain requests.
	ExplainHttpUri *string `pulumi:"explainHttpUri"`
	// (Output)
	// Output only. Http(s) path to send health check requests.
	HealthHttpUri *string `pulumi:"healthHttpUri"`
	// (Output)
	// Output only. Http(s) path to send prediction requests.
	PredictHttpUri *string `pulumi:"predictHttpUri"`
	// (Output)
	// Output only. The name of the service attachment resource. Populated if private service connect is enabled.
	ServiceAttachment *string `pulumi:"serviceAttachment"`
}

// AiEndpointDeployedModelPrivateEndpointInput is an input type that accepts AiEndpointDeployedModelPrivateEndpointArgs and AiEndpointDeployedModelPrivateEndpointOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelPrivateEndpointInput` via:
//
//	AiEndpointDeployedModelPrivateEndpointArgs{...}
type AiEndpointDeployedModelPrivateEndpointInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelPrivateEndpointOutput() AiEndpointDeployedModelPrivateEndpointOutput
	ToAiEndpointDeployedModelPrivateEndpointOutputWithContext(context.Context) AiEndpointDeployedModelPrivateEndpointOutput
}

type AiEndpointDeployedModelPrivateEndpointArgs struct {
	// (Output)
	// Output only. Http(s) path to send explain requests.
	ExplainHttpUri pulumi.StringPtrInput `pulumi:"explainHttpUri"`
	// (Output)
	// Output only. Http(s) path to send health check requests.
	HealthHttpUri pulumi.StringPtrInput `pulumi:"healthHttpUri"`
	// (Output)
	// Output only. Http(s) path to send prediction requests.
	PredictHttpUri pulumi.StringPtrInput `pulumi:"predictHttpUri"`
	// (Output)
	// Output only. The name of the service attachment resource. Populated if private service connect is enabled.
	ServiceAttachment pulumi.StringPtrInput `pulumi:"serviceAttachment"`
}

func (AiEndpointDeployedModelPrivateEndpointArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelPrivateEndpoint)(nil)).Elem()
}

func (i AiEndpointDeployedModelPrivateEndpointArgs) ToAiEndpointDeployedModelPrivateEndpointOutput() AiEndpointDeployedModelPrivateEndpointOutput {
	return i.ToAiEndpointDeployedModelPrivateEndpointOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelPrivateEndpointArgs) ToAiEndpointDeployedModelPrivateEndpointOutputWithContext(ctx context.Context) AiEndpointDeployedModelPrivateEndpointOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelPrivateEndpointOutput)
}

// AiEndpointDeployedModelPrivateEndpointArrayInput is an input type that accepts AiEndpointDeployedModelPrivateEndpointArray and AiEndpointDeployedModelPrivateEndpointArrayOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelPrivateEndpointArrayInput` via:
//
//	AiEndpointDeployedModelPrivateEndpointArray{ AiEndpointDeployedModelPrivateEndpointArgs{...} }
type AiEndpointDeployedModelPrivateEndpointArrayInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelPrivateEndpointArrayOutput() AiEndpointDeployedModelPrivateEndpointArrayOutput
	ToAiEndpointDeployedModelPrivateEndpointArrayOutputWithContext(context.Context) AiEndpointDeployedModelPrivateEndpointArrayOutput
}

type AiEndpointDeployedModelPrivateEndpointArray []AiEndpointDeployedModelPrivateEndpointInput

func (AiEndpointDeployedModelPrivateEndpointArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelPrivateEndpoint)(nil)).Elem()
}

func (i AiEndpointDeployedModelPrivateEndpointArray) ToAiEndpointDeployedModelPrivateEndpointArrayOutput() AiEndpointDeployedModelPrivateEndpointArrayOutput {
	return i.ToAiEndpointDeployedModelPrivateEndpointArrayOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelPrivateEndpointArray) ToAiEndpointDeployedModelPrivateEndpointArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelPrivateEndpointArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelPrivateEndpointArrayOutput)
}

type AiEndpointDeployedModelPrivateEndpointOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelPrivateEndpointOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelPrivateEndpoint)(nil)).Elem()
}

func (o AiEndpointDeployedModelPrivateEndpointOutput) ToAiEndpointDeployedModelPrivateEndpointOutput() AiEndpointDeployedModelPrivateEndpointOutput {
	return o
}

func (o AiEndpointDeployedModelPrivateEndpointOutput) ToAiEndpointDeployedModelPrivateEndpointOutputWithContext(ctx context.Context) AiEndpointDeployedModelPrivateEndpointOutput {
	return o
}

// (Output)
// Output only. Http(s) path to send explain requests.
func (o AiEndpointDeployedModelPrivateEndpointOutput) ExplainHttpUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelPrivateEndpoint) *string { return v.ExplainHttpUri }).(pulumi.StringPtrOutput)
}

// (Output)
// Output only. Http(s) path to send health check requests.
func (o AiEndpointDeployedModelPrivateEndpointOutput) HealthHttpUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelPrivateEndpoint) *string { return v.HealthHttpUri }).(pulumi.StringPtrOutput)
}

// (Output)
// Output only. Http(s) path to send prediction requests.
func (o AiEndpointDeployedModelPrivateEndpointOutput) PredictHttpUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelPrivateEndpoint) *string { return v.PredictHttpUri }).(pulumi.StringPtrOutput)
}

// (Output)
// Output only. The name of the service attachment resource. Populated if private service connect is enabled.
func (o AiEndpointDeployedModelPrivateEndpointOutput) ServiceAttachment() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelPrivateEndpoint) *string { return v.ServiceAttachment }).(pulumi.StringPtrOutput)
}

type AiEndpointDeployedModelPrivateEndpointArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelPrivateEndpointArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelPrivateEndpoint)(nil)).Elem()
}

func (o AiEndpointDeployedModelPrivateEndpointArrayOutput) ToAiEndpointDeployedModelPrivateEndpointArrayOutput() AiEndpointDeployedModelPrivateEndpointArrayOutput {
	return o
}

func (o AiEndpointDeployedModelPrivateEndpointArrayOutput) ToAiEndpointDeployedModelPrivateEndpointArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelPrivateEndpointArrayOutput {
	return o
}

func (o AiEndpointDeployedModelPrivateEndpointArrayOutput) Index(i pulumi.IntInput) AiEndpointDeployedModelPrivateEndpointOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointDeployedModelPrivateEndpoint {
		return vs[0].([]AiEndpointDeployedModelPrivateEndpoint)[vs[1].(int)]
	}).(AiEndpointDeployedModelPrivateEndpointOutput)
}

type AiEndpointEncryptionSpec struct {
	// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// AiEndpointEncryptionSpecInput is an input type that accepts AiEndpointEncryptionSpecArgs and AiEndpointEncryptionSpecOutput values.
// You can construct a concrete instance of `AiEndpointEncryptionSpecInput` via:
//
//	AiEndpointEncryptionSpecArgs{...}
type AiEndpointEncryptionSpecInput interface {
	pulumi.Input

	ToAiEndpointEncryptionSpecOutput() AiEndpointEncryptionSpecOutput
	ToAiEndpointEncryptionSpecOutputWithContext(context.Context) AiEndpointEncryptionSpecOutput
}

type AiEndpointEncryptionSpecArgs struct {
	// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (AiEndpointEncryptionSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointEncryptionSpec)(nil)).Elem()
}

func (i AiEndpointEncryptionSpecArgs) ToAiEndpointEncryptionSpecOutput() AiEndpointEncryptionSpecOutput {
	return i.ToAiEndpointEncryptionSpecOutputWithContext(context.Background())
}

func (i AiEndpointEncryptionSpecArgs) ToAiEndpointEncryptionSpecOutputWithContext(ctx context.Context) AiEndpointEncryptionSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointEncryptionSpecOutput)
}

func (i AiEndpointEncryptionSpecArgs) ToAiEndpointEncryptionSpecPtrOutput() AiEndpointEncryptionSpecPtrOutput {
	return i.ToAiEndpointEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i AiEndpointEncryptionSpecArgs) ToAiEndpointEncryptionSpecPtrOutputWithContext(ctx context.Context) AiEndpointEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointEncryptionSpecOutput).ToAiEndpointEncryptionSpecPtrOutputWithContext(ctx)
}

// AiEndpointEncryptionSpecPtrInput is an input type that accepts AiEndpointEncryptionSpecArgs, AiEndpointEncryptionSpecPtr and AiEndpointEncryptionSpecPtrOutput values.
// You can construct a concrete instance of `AiEndpointEncryptionSpecPtrInput` via:
//
//	        AiEndpointEncryptionSpecArgs{...}
//
//	or:
//
//	        nil
type AiEndpointEncryptionSpecPtrInput interface {
	pulumi.Input

	ToAiEndpointEncryptionSpecPtrOutput() AiEndpointEncryptionSpecPtrOutput
	ToAiEndpointEncryptionSpecPtrOutputWithContext(context.Context) AiEndpointEncryptionSpecPtrOutput
}

type aiEndpointEncryptionSpecPtrType AiEndpointEncryptionSpecArgs

func AiEndpointEncryptionSpecPtr(v *AiEndpointEncryptionSpecArgs) AiEndpointEncryptionSpecPtrInput {
	return (*aiEndpointEncryptionSpecPtrType)(v)
}

func (*aiEndpointEncryptionSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointEncryptionSpec)(nil)).Elem()
}

func (i *aiEndpointEncryptionSpecPtrType) ToAiEndpointEncryptionSpecPtrOutput() AiEndpointEncryptionSpecPtrOutput {
	return i.ToAiEndpointEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i *aiEndpointEncryptionSpecPtrType) ToAiEndpointEncryptionSpecPtrOutputWithContext(ctx context.Context) AiEndpointEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointEncryptionSpecPtrOutput)
}

type AiEndpointEncryptionSpecOutput struct{ *pulumi.OutputState }

func (AiEndpointEncryptionSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointEncryptionSpec)(nil)).Elem()
}

func (o AiEndpointEncryptionSpecOutput) ToAiEndpointEncryptionSpecOutput() AiEndpointEncryptionSpecOutput {
	return o
}

func (o AiEndpointEncryptionSpecOutput) ToAiEndpointEncryptionSpecOutputWithContext(ctx context.Context) AiEndpointEncryptionSpecOutput {
	return o
}

func (o AiEndpointEncryptionSpecOutput) ToAiEndpointEncryptionSpecPtrOutput() AiEndpointEncryptionSpecPtrOutput {
	return o.ToAiEndpointEncryptionSpecPtrOutputWithContext(context.Background())
}

func (o AiEndpointEncryptionSpecOutput) ToAiEndpointEncryptionSpecPtrOutputWithContext(ctx context.Context) AiEndpointEncryptionSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointEncryptionSpec) *AiEndpointEncryptionSpec {
		return &v
	}).(AiEndpointEncryptionSpecPtrOutput)
}

// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
func (o AiEndpointEncryptionSpecOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v AiEndpointEncryptionSpec) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type AiEndpointEncryptionSpecPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointEncryptionSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointEncryptionSpec)(nil)).Elem()
}

func (o AiEndpointEncryptionSpecPtrOutput) ToAiEndpointEncryptionSpecPtrOutput() AiEndpointEncryptionSpecPtrOutput {
	return o
}

func (o AiEndpointEncryptionSpecPtrOutput) ToAiEndpointEncryptionSpecPtrOutputWithContext(ctx context.Context) AiEndpointEncryptionSpecPtrOutput {
	return o
}

func (o AiEndpointEncryptionSpecPtrOutput) Elem() AiEndpointEncryptionSpecOutput {
	return o.ApplyT(func(v *AiEndpointEncryptionSpec) AiEndpointEncryptionSpec {
		if v != nil {
			return *v
		}
		var ret AiEndpointEncryptionSpec
		return ret
	}).(AiEndpointEncryptionSpecOutput)
}

// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
func (o AiEndpointEncryptionSpecPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointEncryptionSpec) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreEncryptionSpec struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// AiFeatureStoreEncryptionSpecInput is an input type that accepts AiFeatureStoreEncryptionSpecArgs and AiFeatureStoreEncryptionSpecOutput values.
// You can construct a concrete instance of `AiFeatureStoreEncryptionSpecInput` via:
//
//	AiFeatureStoreEncryptionSpecArgs{...}
type AiFeatureStoreEncryptionSpecInput interface {
	pulumi.Input

	ToAiFeatureStoreEncryptionSpecOutput() AiFeatureStoreEncryptionSpecOutput
	ToAiFeatureStoreEncryptionSpecOutputWithContext(context.Context) AiFeatureStoreEncryptionSpecOutput
}

type AiFeatureStoreEncryptionSpecArgs struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (AiFeatureStoreEncryptionSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEncryptionSpec)(nil)).Elem()
}

func (i AiFeatureStoreEncryptionSpecArgs) ToAiFeatureStoreEncryptionSpecOutput() AiFeatureStoreEncryptionSpecOutput {
	return i.ToAiFeatureStoreEncryptionSpecOutputWithContext(context.Background())
}

func (i AiFeatureStoreEncryptionSpecArgs) ToAiFeatureStoreEncryptionSpecOutputWithContext(ctx context.Context) AiFeatureStoreEncryptionSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEncryptionSpecOutput)
}

func (i AiFeatureStoreEncryptionSpecArgs) ToAiFeatureStoreEncryptionSpecPtrOutput() AiFeatureStoreEncryptionSpecPtrOutput {
	return i.ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEncryptionSpecArgs) ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiFeatureStoreEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEncryptionSpecOutput).ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(ctx)
}

// AiFeatureStoreEncryptionSpecPtrInput is an input type that accepts AiFeatureStoreEncryptionSpecArgs, AiFeatureStoreEncryptionSpecPtr and AiFeatureStoreEncryptionSpecPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEncryptionSpecPtrInput` via:
//
//	        AiFeatureStoreEncryptionSpecArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEncryptionSpecPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEncryptionSpecPtrOutput() AiFeatureStoreEncryptionSpecPtrOutput
	ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(context.Context) AiFeatureStoreEncryptionSpecPtrOutput
}

type aiFeatureStoreEncryptionSpecPtrType AiFeatureStoreEncryptionSpecArgs

func AiFeatureStoreEncryptionSpecPtr(v *AiFeatureStoreEncryptionSpecArgs) AiFeatureStoreEncryptionSpecPtrInput {
	return (*aiFeatureStoreEncryptionSpecPtrType)(v)
}

func (*aiFeatureStoreEncryptionSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEncryptionSpec)(nil)).Elem()
}

func (i *aiFeatureStoreEncryptionSpecPtrType) ToAiFeatureStoreEncryptionSpecPtrOutput() AiFeatureStoreEncryptionSpecPtrOutput {
	return i.ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEncryptionSpecPtrType) ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiFeatureStoreEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEncryptionSpecPtrOutput)
}

type AiFeatureStoreEncryptionSpecOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEncryptionSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEncryptionSpec)(nil)).Elem()
}

func (o AiFeatureStoreEncryptionSpecOutput) ToAiFeatureStoreEncryptionSpecOutput() AiFeatureStoreEncryptionSpecOutput {
	return o
}

func (o AiFeatureStoreEncryptionSpecOutput) ToAiFeatureStoreEncryptionSpecOutputWithContext(ctx context.Context) AiFeatureStoreEncryptionSpecOutput {
	return o
}

func (o AiFeatureStoreEncryptionSpecOutput) ToAiFeatureStoreEncryptionSpecPtrOutput() AiFeatureStoreEncryptionSpecPtrOutput {
	return o.ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEncryptionSpecOutput) ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiFeatureStoreEncryptionSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEncryptionSpec) *AiFeatureStoreEncryptionSpec {
		return &v
	}).(AiFeatureStoreEncryptionSpecPtrOutput)
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the compute resource is created.
func (o AiFeatureStoreEncryptionSpecOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreEncryptionSpec) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type AiFeatureStoreEncryptionSpecPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEncryptionSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEncryptionSpec)(nil)).Elem()
}

func (o AiFeatureStoreEncryptionSpecPtrOutput) ToAiFeatureStoreEncryptionSpecPtrOutput() AiFeatureStoreEncryptionSpecPtrOutput {
	return o
}

func (o AiFeatureStoreEncryptionSpecPtrOutput) ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiFeatureStoreEncryptionSpecPtrOutput {
	return o
}

func (o AiFeatureStoreEncryptionSpecPtrOutput) Elem() AiFeatureStoreEncryptionSpecOutput {
	return o.ApplyT(func(v *AiFeatureStoreEncryptionSpec) AiFeatureStoreEncryptionSpec {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEncryptionSpec
		return ret
	}).(AiFeatureStoreEncryptionSpecOutput)
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the compute resource is created.
func (o AiFeatureStoreEncryptionSpecPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEncryptionSpec) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreEntityTypeIamBindingCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureStoreEntityTypeIamBindingConditionInput is an input type that accepts AiFeatureStoreEntityTypeIamBindingConditionArgs and AiFeatureStoreEntityTypeIamBindingConditionOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeIamBindingConditionInput` via:
//
//	AiFeatureStoreEntityTypeIamBindingConditionArgs{...}
type AiFeatureStoreEntityTypeIamBindingConditionInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeIamBindingConditionOutput() AiFeatureStoreEntityTypeIamBindingConditionOutput
	ToAiFeatureStoreEntityTypeIamBindingConditionOutputWithContext(context.Context) AiFeatureStoreEntityTypeIamBindingConditionOutput
}

type AiFeatureStoreEntityTypeIamBindingConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureStoreEntityTypeIamBindingConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeIamBindingCondition)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeIamBindingConditionArgs) ToAiFeatureStoreEntityTypeIamBindingConditionOutput() AiFeatureStoreEntityTypeIamBindingConditionOutput {
	return i.ToAiFeatureStoreEntityTypeIamBindingConditionOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeIamBindingConditionArgs) ToAiFeatureStoreEntityTypeIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamBindingConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeIamBindingConditionOutput)
}

func (i AiFeatureStoreEntityTypeIamBindingConditionArgs) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutput() AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return i.ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeIamBindingConditionArgs) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeIamBindingConditionOutput).ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeIamBindingConditionPtrInput is an input type that accepts AiFeatureStoreEntityTypeIamBindingConditionArgs, AiFeatureStoreEntityTypeIamBindingConditionPtr and AiFeatureStoreEntityTypeIamBindingConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeIamBindingConditionPtrInput` via:
//
//	        AiFeatureStoreEntityTypeIamBindingConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeIamBindingConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutput() AiFeatureStoreEntityTypeIamBindingConditionPtrOutput
	ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeIamBindingConditionPtrOutput
}

type aiFeatureStoreEntityTypeIamBindingConditionPtrType AiFeatureStoreEntityTypeIamBindingConditionArgs

func AiFeatureStoreEntityTypeIamBindingConditionPtr(v *AiFeatureStoreEntityTypeIamBindingConditionArgs) AiFeatureStoreEntityTypeIamBindingConditionPtrInput {
	return (*aiFeatureStoreEntityTypeIamBindingConditionPtrType)(v)
}

func (*aiFeatureStoreEntityTypeIamBindingConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeIamBindingCondition)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeIamBindingConditionPtrType) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutput() AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return i.ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeIamBindingConditionPtrType) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeIamBindingConditionPtrOutput)
}

type AiFeatureStoreEntityTypeIamBindingConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeIamBindingConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) ToAiFeatureStoreEntityTypeIamBindingConditionOutput() AiFeatureStoreEntityTypeIamBindingConditionOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) ToAiFeatureStoreEntityTypeIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamBindingConditionOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutput() AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return o.ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeIamBindingCondition) *AiFeatureStoreEntityTypeIamBindingCondition {
		return &v
	}).(AiFeatureStoreEntityTypeIamBindingConditionPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeIamBindingCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeIamBindingCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeIamBindingCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureStoreEntityTypeIamBindingConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutput() AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) Elem() AiFeatureStoreEntityTypeIamBindingConditionOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamBindingCondition) AiFeatureStoreEntityTypeIamBindingCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeIamBindingCondition
		return ret
	}).(AiFeatureStoreEntityTypeIamBindingConditionOutput)
}

func (o AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreEntityTypeIamMemberCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureStoreEntityTypeIamMemberConditionInput is an input type that accepts AiFeatureStoreEntityTypeIamMemberConditionArgs and AiFeatureStoreEntityTypeIamMemberConditionOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeIamMemberConditionInput` via:
//
//	AiFeatureStoreEntityTypeIamMemberConditionArgs{...}
type AiFeatureStoreEntityTypeIamMemberConditionInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeIamMemberConditionOutput() AiFeatureStoreEntityTypeIamMemberConditionOutput
	ToAiFeatureStoreEntityTypeIamMemberConditionOutputWithContext(context.Context) AiFeatureStoreEntityTypeIamMemberConditionOutput
}

type AiFeatureStoreEntityTypeIamMemberConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureStoreEntityTypeIamMemberConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeIamMemberCondition)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeIamMemberConditionArgs) ToAiFeatureStoreEntityTypeIamMemberConditionOutput() AiFeatureStoreEntityTypeIamMemberConditionOutput {
	return i.ToAiFeatureStoreEntityTypeIamMemberConditionOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeIamMemberConditionArgs) ToAiFeatureStoreEntityTypeIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamMemberConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeIamMemberConditionOutput)
}

func (i AiFeatureStoreEntityTypeIamMemberConditionArgs) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutput() AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return i.ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeIamMemberConditionArgs) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeIamMemberConditionOutput).ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeIamMemberConditionPtrInput is an input type that accepts AiFeatureStoreEntityTypeIamMemberConditionArgs, AiFeatureStoreEntityTypeIamMemberConditionPtr and AiFeatureStoreEntityTypeIamMemberConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeIamMemberConditionPtrInput` via:
//
//	        AiFeatureStoreEntityTypeIamMemberConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeIamMemberConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutput() AiFeatureStoreEntityTypeIamMemberConditionPtrOutput
	ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeIamMemberConditionPtrOutput
}

type aiFeatureStoreEntityTypeIamMemberConditionPtrType AiFeatureStoreEntityTypeIamMemberConditionArgs

func AiFeatureStoreEntityTypeIamMemberConditionPtr(v *AiFeatureStoreEntityTypeIamMemberConditionArgs) AiFeatureStoreEntityTypeIamMemberConditionPtrInput {
	return (*aiFeatureStoreEntityTypeIamMemberConditionPtrType)(v)
}

func (*aiFeatureStoreEntityTypeIamMemberConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeIamMemberCondition)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeIamMemberConditionPtrType) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutput() AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return i.ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeIamMemberConditionPtrType) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeIamMemberConditionPtrOutput)
}

type AiFeatureStoreEntityTypeIamMemberConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeIamMemberConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) ToAiFeatureStoreEntityTypeIamMemberConditionOutput() AiFeatureStoreEntityTypeIamMemberConditionOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) ToAiFeatureStoreEntityTypeIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamMemberConditionOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutput() AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return o.ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeIamMemberCondition) *AiFeatureStoreEntityTypeIamMemberCondition {
		return &v
	}).(AiFeatureStoreEntityTypeIamMemberConditionPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeIamMemberCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeIamMemberCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeIamMemberCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureStoreEntityTypeIamMemberConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutput() AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) Elem() AiFeatureStoreEntityTypeIamMemberConditionOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamMemberCondition) AiFeatureStoreEntityTypeIamMemberCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeIamMemberCondition
		return ret
	}).(AiFeatureStoreEntityTypeIamMemberConditionOutput)
}

func (o AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfig struct {
	// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
	// Structure is documented below.
	CategoricalThresholdConfig *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig `pulumi:"categoricalThresholdConfig"`
	// The config for ImportFeatures Analysis Based Feature Monitoring.
	// Structure is documented below.
	ImportFeaturesAnalysis *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis `pulumi:"importFeaturesAnalysis"`
	// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
	// Structure is documented below.
	NumericalThresholdConfig *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig `pulumi:"numericalThresholdConfig"`
	// The config for Snapshot Analysis Based Feature Monitoring.
	// Structure is documented below.
	SnapshotAnalysis *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis `pulumi:"snapshotAnalysis"`
}

// AiFeatureStoreEntityTypeMonitoringConfigInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigArgs and AiFeatureStoreEntityTypeMonitoringConfigOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigInput` via:
//
//	AiFeatureStoreEntityTypeMonitoringConfigArgs{...}
type AiFeatureStoreEntityTypeMonitoringConfigInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigOutput
}

type AiFeatureStoreEntityTypeMonitoringConfigArgs struct {
	// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
	// Structure is documented below.
	CategoricalThresholdConfig AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrInput `pulumi:"categoricalThresholdConfig"`
	// The config for ImportFeatures Analysis Based Feature Monitoring.
	// Structure is documented below.
	ImportFeaturesAnalysis AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrInput `pulumi:"importFeaturesAnalysis"`
	// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
	// Structure is documented below.
	NumericalThresholdConfig AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrInput `pulumi:"numericalThresholdConfig"`
	// The config for Snapshot Analysis Based Feature Monitoring.
	// Structure is documented below.
	SnapshotAnalysis AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrInput `pulumi:"snapshotAnalysis"`
}

func (AiFeatureStoreEntityTypeMonitoringConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfig)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeMonitoringConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigOutput)
}

func (i AiFeatureStoreEntityTypeMonitoringConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigOutput).ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeMonitoringConfigPtrInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigArgs, AiFeatureStoreEntityTypeMonitoringConfigPtr and AiFeatureStoreEntityTypeMonitoringConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigPtrInput` via:
//
//	        AiFeatureStoreEntityTypeMonitoringConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeMonitoringConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigPtrOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigPtrOutput
}

type aiFeatureStoreEntityTypeMonitoringConfigPtrType AiFeatureStoreEntityTypeMonitoringConfigArgs

func AiFeatureStoreEntityTypeMonitoringConfigPtr(v *AiFeatureStoreEntityTypeMonitoringConfigArgs) AiFeatureStoreEntityTypeMonitoringConfigPtrInput {
	return (*aiFeatureStoreEntityTypeMonitoringConfigPtrType)(v)
}

func (*aiFeatureStoreEntityTypeMonitoringConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfig)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfig)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return o.ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfig {
		return &v
	}).(AiFeatureStoreEntityTypeMonitoringConfigPtrOutput)
}

// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) CategoricalThresholdConfig() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig {
		return v.CategoricalThresholdConfig
	}).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput)
}

// The config for ImportFeatures Analysis Based Feature Monitoring.
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) ImportFeaturesAnalysis() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis {
		return v.ImportFeaturesAnalysis
	}).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) NumericalThresholdConfig() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig {
		return v.NumericalThresholdConfig
	}).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput)
}

// The config for Snapshot Analysis Based Feature Monitoring.
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) SnapshotAnalysis() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis {
		return v.SnapshotAnalysis
	}).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfig)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) Elem() AiFeatureStoreEntityTypeMonitoringConfigOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfig) AiFeatureStoreEntityTypeMonitoringConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeMonitoringConfig
		return ret
	}).(AiFeatureStoreEntityTypeMonitoringConfigOutput)
}

// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) CategoricalThresholdConfig() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig {
		if v == nil {
			return nil
		}
		return v.CategoricalThresholdConfig
	}).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput)
}

// The config for ImportFeatures Analysis Based Feature Monitoring.
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) ImportFeaturesAnalysis() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis {
		if v == nil {
			return nil
		}
		return v.ImportFeaturesAnalysis
	}).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) NumericalThresholdConfig() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig {
		if v == nil {
			return nil
		}
		return v.NumericalThresholdConfig
	}).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput)
}

// The config for Snapshot Analysis Based Feature Monitoring.
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) SnapshotAnalysis() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis {
		if v == nil {
			return nil
		}
		return v.SnapshotAnalysis
	}).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig struct {
	// Specify a threshold value that can trigger the alert. For categorical feature, the distribution distance is calculated by L-inifinity norm. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
	Value float64 `pulumi:"value"`
}

// AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs and AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigInput` via:
//
//	AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs{...}
type AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput
}

type AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs struct {
	// Specify a threshold value that can trigger the alert. For categorical feature, the distribution distance is calculated by L-inifinity norm. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
	Value pulumi.Float64Input `pulumi:"value"`
}

func (AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput)
}

func (i AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput).ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs, AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtr and AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrInput` via:
//
//	        AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput
}

type aiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrType AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs

func AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtr(v *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrInput {
	return (*aiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrType)(v)
}

func (*aiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return o.ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig) *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig {
		return &v
	}).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput)
}

// Specify a threshold value that can trigger the alert. For categorical feature, the distribution distance is calculated by L-inifinity norm. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput) Value() pulumi.Float64Output {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig) float64 { return v.Value }).(pulumi.Float64Output)
}

type AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput) Elem() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig
		return ret
	}).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput)
}

// Specify a threshold value that can trigger the alert. For categorical feature, the distribution distance is calculated by L-inifinity norm. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput) Value() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig) *float64 {
		if v == nil {
			return nil
		}
		return &v.Value
	}).(pulumi.Float64PtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis struct {
	// Defines the baseline to do anomaly detection for feature values imported by each [entityTypes.importFeatureValues][] operation. The value must be one of the values below:
	// * LATEST_STATS: Choose the later one statistics generated by either most recent snapshot analysis or previous import features analysis. If non of them exists, skip anomaly detection and only generate a statistics.
	// * MOST_RECENT_SNAPSHOT_STATS: Use the statistics generated by the most recent snapshot analysis if exists.
	// * PREVIOUS_IMPORT_FEATURES_STATS: Use the statistics generated by the previous import features analysis if exists.
	AnomalyDetectionBaseline *string `pulumi:"anomalyDetectionBaseline"`
	// Whether to enable / disable / inherite default hebavior for import features analysis. The value must be one of the values below:
	// * DEFAULT: The default behavior of whether to enable the monitoring. EntityType-level config: disabled.
	// * ENABLED: Explicitly enables import features analysis. EntityType-level config: by default enables import features analysis for all Features under it.
	// * DISABLED: Explicitly disables import features analysis. EntityType-level config: by default disables import features analysis for all Features under it.
	State *string `pulumi:"state"`
}

// AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs and AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisInput` via:
//
//	AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs{...}
type AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput
}

type AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs struct {
	// Defines the baseline to do anomaly detection for feature values imported by each [entityTypes.importFeatureValues][] operation. The value must be one of the values below:
	// * LATEST_STATS: Choose the later one statistics generated by either most recent snapshot analysis or previous import features analysis. If non of them exists, skip anomaly detection and only generate a statistics.
	// * MOST_RECENT_SNAPSHOT_STATS: Use the statistics generated by the most recent snapshot analysis if exists.
	// * PREVIOUS_IMPORT_FEATURES_STATS: Use the statistics generated by the previous import features analysis if exists.
	AnomalyDetectionBaseline pulumi.StringPtrInput `pulumi:"anomalyDetectionBaseline"`
	// Whether to enable / disable / inherite default hebavior for import features analysis. The value must be one of the values below:
	// * DEFAULT: The default behavior of whether to enable the monitoring. EntityType-level config: disabled.
	// * ENABLED: Explicitly enables import features analysis. EntityType-level config: by default enables import features analysis for all Features under it.
	// * DISABLED: Explicitly disables import features analysis. EntityType-level config: by default disables import features analysis for all Features under it.
	State pulumi.StringPtrInput `pulumi:"state"`
}

func (AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput)
}

func (i AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput).ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs, AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtr and AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrInput` via:
//
//	        AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput
}

type aiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrType AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs

func AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtr(v *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrInput {
	return (*aiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrType)(v)
}

func (*aiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis) *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis {
		return &v
	}).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// Defines the baseline to do anomaly detection for feature values imported by each [entityTypes.importFeatureValues][] operation. The value must be one of the values below:
// * LATEST_STATS: Choose the later one statistics generated by either most recent snapshot analysis or previous import features analysis. If non of them exists, skip anomaly detection and only generate a statistics.
// * MOST_RECENT_SNAPSHOT_STATS: Use the statistics generated by the most recent snapshot analysis if exists.
// * PREVIOUS_IMPORT_FEATURES_STATS: Use the statistics generated by the previous import features analysis if exists.
func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) AnomalyDetectionBaseline() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis) *string {
		return v.AnomalyDetectionBaseline
	}).(pulumi.StringPtrOutput)
}

// Whether to enable / disable / inherite default hebavior for import features analysis. The value must be one of the values below:
// * DEFAULT: The default behavior of whether to enable the monitoring. EntityType-level config: disabled.
// * ENABLED: Explicitly enables import features analysis. EntityType-level config: by default enables import features analysis for all Features under it.
// * DISABLED: Explicitly disables import features analysis. EntityType-level config: by default disables import features analysis for all Features under it.
func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) State() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis) *string { return v.State }).(pulumi.StringPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput) Elem() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis
		return ret
	}).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput)
}

// Defines the baseline to do anomaly detection for feature values imported by each [entityTypes.importFeatureValues][] operation. The value must be one of the values below:
// * LATEST_STATS: Choose the later one statistics generated by either most recent snapshot analysis or previous import features analysis. If non of them exists, skip anomaly detection and only generate a statistics.
// * MOST_RECENT_SNAPSHOT_STATS: Use the statistics generated by the most recent snapshot analysis if exists.
// * PREVIOUS_IMPORT_FEATURES_STATS: Use the statistics generated by the previous import features analysis if exists.
func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput) AnomalyDetectionBaseline() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis) *string {
		if v == nil {
			return nil
		}
		return v.AnomalyDetectionBaseline
	}).(pulumi.StringPtrOutput)
}

// Whether to enable / disable / inherite default hebavior for import features analysis. The value must be one of the values below:
// * DEFAULT: The default behavior of whether to enable the monitoring. EntityType-level config: disabled.
// * ENABLED: Explicitly enables import features analysis. EntityType-level config: by default enables import features analysis for all Features under it.
// * DISABLED: Explicitly disables import features analysis. EntityType-level config: by default disables import features analysis for all Features under it.
func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput) State() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis) *string {
		if v == nil {
			return nil
		}
		return v.State
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig struct {
	// Specify a threshold value that can trigger the alert. For numerical feature, the distribution distance is calculated by JensenShannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
	Value float64 `pulumi:"value"`
}

// AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs and AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigInput` via:
//
//	AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs{...}
type AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput
}

type AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs struct {
	// Specify a threshold value that can trigger the alert. For numerical feature, the distribution distance is calculated by JensenShannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
	Value pulumi.Float64Input `pulumi:"value"`
}

func (AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput)
}

func (i AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput).ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs, AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtr and AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrInput` via:
//
//	        AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput
}

type aiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrType AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs

func AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtr(v *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrInput {
	return (*aiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrType)(v)
}

func (*aiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return o.ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig) *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig {
		return &v
	}).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput)
}

// Specify a threshold value that can trigger the alert. For numerical feature, the distribution distance is calculated by JensenShannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput) Value() pulumi.Float64Output {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig) float64 { return v.Value }).(pulumi.Float64Output)
}

type AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput) Elem() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig
		return ret
	}).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput)
}

// Specify a threshold value that can trigger the alert. For numerical feature, the distribution distance is calculated by JensenShannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput) Value() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig) *float64 {
		if v == nil {
			return nil
		}
		return &v.Value
	}).(pulumi.Float64PtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis struct {
	// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoringInterval for Features under it.
	Disabled *bool `pulumi:"disabled"`
	// Deprecated: This field is unavailable in the GA provider and will be removed from the beta provider in a future release.
	MonitoringInterval *string `pulumi:"monitoringInterval"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days. The default value is 1.
	// If both FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days and [FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval][] are set when creating/updating EntityTypes/Features, FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days will be used.
	MonitoringIntervalDays *int `pulumi:"monitoringIntervalDays"`
	// Customized export features time window for snapshot analysis. Unit is one day. The default value is 21 days. Minimum value is 1 day. Maximum value is 4000 days.
	StalenessDays *int `pulumi:"stalenessDays"`
}

// AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs and AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisInput` via:
//
//	AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs{...}
type AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput
}

type AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs struct {
	// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoringInterval for Features under it.
	Disabled pulumi.BoolPtrInput `pulumi:"disabled"`
	// Deprecated: This field is unavailable in the GA provider and will be removed from the beta provider in a future release.
	MonitoringInterval pulumi.StringPtrInput `pulumi:"monitoringInterval"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days. The default value is 1.
	// If both FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days and [FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval][] are set when creating/updating EntityTypes/Features, FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days will be used.
	MonitoringIntervalDays pulumi.IntPtrInput `pulumi:"monitoringIntervalDays"`
	// Customized export features time window for snapshot analysis. Unit is one day. The default value is 21 days. Minimum value is 1 day. Maximum value is 4000 days.
	StalenessDays pulumi.IntPtrInput `pulumi:"stalenessDays"`
}

func (AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput)
}

func (i AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput).ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs, AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtr and AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrInput` via:
//
//	        AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput
}

type aiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrType AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs

func AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtr(v *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrInput {
	return (*aiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrType)(v)
}

func (*aiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis {
		return &v
	}).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput)
}

// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoringInterval for Features under it.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) Disabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *bool { return v.Disabled }).(pulumi.BoolPtrOutput)
}

// Deprecated: This field is unavailable in the GA provider and will be removed from the beta provider in a future release.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) MonitoringInterval() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *string { return v.MonitoringInterval }).(pulumi.StringPtrOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days. The default value is 1.
// If both FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days and [FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval][] are set when creating/updating EntityTypes/Features, FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days will be used.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) MonitoringIntervalDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *int { return v.MonitoringIntervalDays }).(pulumi.IntPtrOutput)
}

// Customized export features time window for snapshot analysis. Unit is one day. The default value is 21 days. Minimum value is 1 day. Maximum value is 4000 days.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) StalenessDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *int { return v.StalenessDays }).(pulumi.IntPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) Elem() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis
		return ret
	}).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput)
}

// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoringInterval for Features under it.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) Disabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *bool {
		if v == nil {
			return nil
		}
		return v.Disabled
	}).(pulumi.BoolPtrOutput)
}

// Deprecated: This field is unavailable in the GA provider and will be removed from the beta provider in a future release.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) MonitoringInterval() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *string {
		if v == nil {
			return nil
		}
		return v.MonitoringInterval
	}).(pulumi.StringPtrOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days. The default value is 1.
// If both FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days and [FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval][] are set when creating/updating EntityTypes/Features, FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days will be used.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) MonitoringIntervalDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *int {
		if v == nil {
			return nil
		}
		return v.MonitoringIntervalDays
	}).(pulumi.IntPtrOutput)
}

// Customized export features time window for snapshot analysis. Unit is one day. The default value is 21 days. Minimum value is 1 day. Maximum value is 4000 days.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) StalenessDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *int {
		if v == nil {
			return nil
		}
		return v.StalenessDays
	}).(pulumi.IntPtrOutput)
}

type AiFeatureStoreIamBindingCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureStoreIamBindingConditionInput is an input type that accepts AiFeatureStoreIamBindingConditionArgs and AiFeatureStoreIamBindingConditionOutput values.
// You can construct a concrete instance of `AiFeatureStoreIamBindingConditionInput` via:
//
//	AiFeatureStoreIamBindingConditionArgs{...}
type AiFeatureStoreIamBindingConditionInput interface {
	pulumi.Input

	ToAiFeatureStoreIamBindingConditionOutput() AiFeatureStoreIamBindingConditionOutput
	ToAiFeatureStoreIamBindingConditionOutputWithContext(context.Context) AiFeatureStoreIamBindingConditionOutput
}

type AiFeatureStoreIamBindingConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureStoreIamBindingConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreIamBindingCondition)(nil)).Elem()
}

func (i AiFeatureStoreIamBindingConditionArgs) ToAiFeatureStoreIamBindingConditionOutput() AiFeatureStoreIamBindingConditionOutput {
	return i.ToAiFeatureStoreIamBindingConditionOutputWithContext(context.Background())
}

func (i AiFeatureStoreIamBindingConditionArgs) ToAiFeatureStoreIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureStoreIamBindingConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreIamBindingConditionOutput)
}

func (i AiFeatureStoreIamBindingConditionArgs) ToAiFeatureStoreIamBindingConditionPtrOutput() AiFeatureStoreIamBindingConditionPtrOutput {
	return i.ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreIamBindingConditionArgs) ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreIamBindingConditionOutput).ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(ctx)
}

// AiFeatureStoreIamBindingConditionPtrInput is an input type that accepts AiFeatureStoreIamBindingConditionArgs, AiFeatureStoreIamBindingConditionPtr and AiFeatureStoreIamBindingConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreIamBindingConditionPtrInput` via:
//
//	        AiFeatureStoreIamBindingConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreIamBindingConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreIamBindingConditionPtrOutput() AiFeatureStoreIamBindingConditionPtrOutput
	ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(context.Context) AiFeatureStoreIamBindingConditionPtrOutput
}

type aiFeatureStoreIamBindingConditionPtrType AiFeatureStoreIamBindingConditionArgs

func AiFeatureStoreIamBindingConditionPtr(v *AiFeatureStoreIamBindingConditionArgs) AiFeatureStoreIamBindingConditionPtrInput {
	return (*aiFeatureStoreIamBindingConditionPtrType)(v)
}

func (*aiFeatureStoreIamBindingConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreIamBindingCondition)(nil)).Elem()
}

func (i *aiFeatureStoreIamBindingConditionPtrType) ToAiFeatureStoreIamBindingConditionPtrOutput() AiFeatureStoreIamBindingConditionPtrOutput {
	return i.ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreIamBindingConditionPtrType) ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreIamBindingConditionPtrOutput)
}

type AiFeatureStoreIamBindingConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreIamBindingConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureStoreIamBindingConditionOutput) ToAiFeatureStoreIamBindingConditionOutput() AiFeatureStoreIamBindingConditionOutput {
	return o
}

func (o AiFeatureStoreIamBindingConditionOutput) ToAiFeatureStoreIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureStoreIamBindingConditionOutput {
	return o
}

func (o AiFeatureStoreIamBindingConditionOutput) ToAiFeatureStoreIamBindingConditionPtrOutput() AiFeatureStoreIamBindingConditionPtrOutput {
	return o.ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreIamBindingConditionOutput) ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamBindingConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreIamBindingCondition) *AiFeatureStoreIamBindingCondition {
		return &v
	}).(AiFeatureStoreIamBindingConditionPtrOutput)
}

func (o AiFeatureStoreIamBindingConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreIamBindingCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreIamBindingConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreIamBindingCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureStoreIamBindingConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreIamBindingCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureStoreIamBindingConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreIamBindingConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureStoreIamBindingConditionPtrOutput) ToAiFeatureStoreIamBindingConditionPtrOutput() AiFeatureStoreIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureStoreIamBindingConditionPtrOutput) ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureStoreIamBindingConditionPtrOutput) Elem() AiFeatureStoreIamBindingConditionOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamBindingCondition) AiFeatureStoreIamBindingCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreIamBindingCondition
		return ret
	}).(AiFeatureStoreIamBindingConditionOutput)
}

func (o AiFeatureStoreIamBindingConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreIamBindingConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreIamBindingConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreIamMemberCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureStoreIamMemberConditionInput is an input type that accepts AiFeatureStoreIamMemberConditionArgs and AiFeatureStoreIamMemberConditionOutput values.
// You can construct a concrete instance of `AiFeatureStoreIamMemberConditionInput` via:
//
//	AiFeatureStoreIamMemberConditionArgs{...}
type AiFeatureStoreIamMemberConditionInput interface {
	pulumi.Input

	ToAiFeatureStoreIamMemberConditionOutput() AiFeatureStoreIamMemberConditionOutput
	ToAiFeatureStoreIamMemberConditionOutputWithContext(context.Context) AiFeatureStoreIamMemberConditionOutput
}

type AiFeatureStoreIamMemberConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureStoreIamMemberConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreIamMemberCondition)(nil)).Elem()
}

func (i AiFeatureStoreIamMemberConditionArgs) ToAiFeatureStoreIamMemberConditionOutput() AiFeatureStoreIamMemberConditionOutput {
	return i.ToAiFeatureStoreIamMemberConditionOutputWithContext(context.Background())
}

func (i AiFeatureStoreIamMemberConditionArgs) ToAiFeatureStoreIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureStoreIamMemberConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreIamMemberConditionOutput)
}

func (i AiFeatureStoreIamMemberConditionArgs) ToAiFeatureStoreIamMemberConditionPtrOutput() AiFeatureStoreIamMemberConditionPtrOutput {
	return i.ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreIamMemberConditionArgs) ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreIamMemberConditionOutput).ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(ctx)
}

// AiFeatureStoreIamMemberConditionPtrInput is an input type that accepts AiFeatureStoreIamMemberConditionArgs, AiFeatureStoreIamMemberConditionPtr and AiFeatureStoreIamMemberConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreIamMemberConditionPtrInput` via:
//
//	        AiFeatureStoreIamMemberConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreIamMemberConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreIamMemberConditionPtrOutput() AiFeatureStoreIamMemberConditionPtrOutput
	ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(context.Context) AiFeatureStoreIamMemberConditionPtrOutput
}

type aiFeatureStoreIamMemberConditionPtrType AiFeatureStoreIamMemberConditionArgs

func AiFeatureStoreIamMemberConditionPtr(v *AiFeatureStoreIamMemberConditionArgs) AiFeatureStoreIamMemberConditionPtrInput {
	return (*aiFeatureStoreIamMemberConditionPtrType)(v)
}

func (*aiFeatureStoreIamMemberConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreIamMemberCondition)(nil)).Elem()
}

func (i *aiFeatureStoreIamMemberConditionPtrType) ToAiFeatureStoreIamMemberConditionPtrOutput() AiFeatureStoreIamMemberConditionPtrOutput {
	return i.ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreIamMemberConditionPtrType) ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreIamMemberConditionPtrOutput)
}

type AiFeatureStoreIamMemberConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreIamMemberConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureStoreIamMemberConditionOutput) ToAiFeatureStoreIamMemberConditionOutput() AiFeatureStoreIamMemberConditionOutput {
	return o
}

func (o AiFeatureStoreIamMemberConditionOutput) ToAiFeatureStoreIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureStoreIamMemberConditionOutput {
	return o
}

func (o AiFeatureStoreIamMemberConditionOutput) ToAiFeatureStoreIamMemberConditionPtrOutput() AiFeatureStoreIamMemberConditionPtrOutput {
	return o.ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreIamMemberConditionOutput) ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamMemberConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreIamMemberCondition) *AiFeatureStoreIamMemberCondition {
		return &v
	}).(AiFeatureStoreIamMemberConditionPtrOutput)
}

func (o AiFeatureStoreIamMemberConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreIamMemberCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreIamMemberConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreIamMemberCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureStoreIamMemberConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreIamMemberCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureStoreIamMemberConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreIamMemberConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureStoreIamMemberConditionPtrOutput) ToAiFeatureStoreIamMemberConditionPtrOutput() AiFeatureStoreIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureStoreIamMemberConditionPtrOutput) ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureStoreIamMemberConditionPtrOutput) Elem() AiFeatureStoreIamMemberConditionOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamMemberCondition) AiFeatureStoreIamMemberCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreIamMemberCondition
		return ret
	}).(AiFeatureStoreIamMemberConditionOutput)
}

func (o AiFeatureStoreIamMemberConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreIamMemberConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreIamMemberConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreOnlineServingConfig struct {
	// The number of nodes for each cluster. The number of nodes will not scale automatically but can be scaled manually by providing different values when updating.
	FixedNodeCount *int `pulumi:"fixedNodeCount"`
	// Online serving scaling configuration. Only one of fixedNodeCount and scaling can be set. Setting one will reset the other.
	// Structure is documented below.
	Scaling *AiFeatureStoreOnlineServingConfigScaling `pulumi:"scaling"`
}

// AiFeatureStoreOnlineServingConfigInput is an input type that accepts AiFeatureStoreOnlineServingConfigArgs and AiFeatureStoreOnlineServingConfigOutput values.
// You can construct a concrete instance of `AiFeatureStoreOnlineServingConfigInput` via:
//
//	AiFeatureStoreOnlineServingConfigArgs{...}
type AiFeatureStoreOnlineServingConfigInput interface {
	pulumi.Input

	ToAiFeatureStoreOnlineServingConfigOutput() AiFeatureStoreOnlineServingConfigOutput
	ToAiFeatureStoreOnlineServingConfigOutputWithContext(context.Context) AiFeatureStoreOnlineServingConfigOutput
}

type AiFeatureStoreOnlineServingConfigArgs struct {
	// The number of nodes for each cluster. The number of nodes will not scale automatically but can be scaled manually by providing different values when updating.
	FixedNodeCount pulumi.IntPtrInput `pulumi:"fixedNodeCount"`
	// Online serving scaling configuration. Only one of fixedNodeCount and scaling can be set. Setting one will reset the other.
	// Structure is documented below.
	Scaling AiFeatureStoreOnlineServingConfigScalingPtrInput `pulumi:"scaling"`
}

func (AiFeatureStoreOnlineServingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreOnlineServingConfig)(nil)).Elem()
}

func (i AiFeatureStoreOnlineServingConfigArgs) ToAiFeatureStoreOnlineServingConfigOutput() AiFeatureStoreOnlineServingConfigOutput {
	return i.ToAiFeatureStoreOnlineServingConfigOutputWithContext(context.Background())
}

func (i AiFeatureStoreOnlineServingConfigArgs) ToAiFeatureStoreOnlineServingConfigOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreOnlineServingConfigOutput)
}

func (i AiFeatureStoreOnlineServingConfigArgs) ToAiFeatureStoreOnlineServingConfigPtrOutput() AiFeatureStoreOnlineServingConfigPtrOutput {
	return i.ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreOnlineServingConfigArgs) ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreOnlineServingConfigOutput).ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(ctx)
}

// AiFeatureStoreOnlineServingConfigPtrInput is an input type that accepts AiFeatureStoreOnlineServingConfigArgs, AiFeatureStoreOnlineServingConfigPtr and AiFeatureStoreOnlineServingConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreOnlineServingConfigPtrInput` via:
//
//	        AiFeatureStoreOnlineServingConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreOnlineServingConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreOnlineServingConfigPtrOutput() AiFeatureStoreOnlineServingConfigPtrOutput
	ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(context.Context) AiFeatureStoreOnlineServingConfigPtrOutput
}

type aiFeatureStoreOnlineServingConfigPtrType AiFeatureStoreOnlineServingConfigArgs

func AiFeatureStoreOnlineServingConfigPtr(v *AiFeatureStoreOnlineServingConfigArgs) AiFeatureStoreOnlineServingConfigPtrInput {
	return (*aiFeatureStoreOnlineServingConfigPtrType)(v)
}

func (*aiFeatureStoreOnlineServingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreOnlineServingConfig)(nil)).Elem()
}

func (i *aiFeatureStoreOnlineServingConfigPtrType) ToAiFeatureStoreOnlineServingConfigPtrOutput() AiFeatureStoreOnlineServingConfigPtrOutput {
	return i.ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreOnlineServingConfigPtrType) ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreOnlineServingConfigPtrOutput)
}

type AiFeatureStoreOnlineServingConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreOnlineServingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreOnlineServingConfig)(nil)).Elem()
}

func (o AiFeatureStoreOnlineServingConfigOutput) ToAiFeatureStoreOnlineServingConfigOutput() AiFeatureStoreOnlineServingConfigOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigOutput) ToAiFeatureStoreOnlineServingConfigOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigOutput) ToAiFeatureStoreOnlineServingConfigPtrOutput() AiFeatureStoreOnlineServingConfigPtrOutput {
	return o.ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreOnlineServingConfigOutput) ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreOnlineServingConfig) *AiFeatureStoreOnlineServingConfig {
		return &v
	}).(AiFeatureStoreOnlineServingConfigPtrOutput)
}

// The number of nodes for each cluster. The number of nodes will not scale automatically but can be scaled manually by providing different values when updating.
func (o AiFeatureStoreOnlineServingConfigOutput) FixedNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreOnlineServingConfig) *int { return v.FixedNodeCount }).(pulumi.IntPtrOutput)
}

// Online serving scaling configuration. Only one of fixedNodeCount and scaling can be set. Setting one will reset the other.
// Structure is documented below.
func (o AiFeatureStoreOnlineServingConfigOutput) Scaling() AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreOnlineServingConfig) *AiFeatureStoreOnlineServingConfigScaling { return v.Scaling }).(AiFeatureStoreOnlineServingConfigScalingPtrOutput)
}

type AiFeatureStoreOnlineServingConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreOnlineServingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreOnlineServingConfig)(nil)).Elem()
}

func (o AiFeatureStoreOnlineServingConfigPtrOutput) ToAiFeatureStoreOnlineServingConfigPtrOutput() AiFeatureStoreOnlineServingConfigPtrOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigPtrOutput) ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigPtrOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigPtrOutput) Elem() AiFeatureStoreOnlineServingConfigOutput {
	return o.ApplyT(func(v *AiFeatureStoreOnlineServingConfig) AiFeatureStoreOnlineServingConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreOnlineServingConfig
		return ret
	}).(AiFeatureStoreOnlineServingConfigOutput)
}

// The number of nodes for each cluster. The number of nodes will not scale automatically but can be scaled manually by providing different values when updating.
func (o AiFeatureStoreOnlineServingConfigPtrOutput) FixedNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreOnlineServingConfig) *int {
		if v == nil {
			return nil
		}
		return v.FixedNodeCount
	}).(pulumi.IntPtrOutput)
}

// Online serving scaling configuration. Only one of fixedNodeCount and scaling can be set. Setting one will reset the other.
// Structure is documented below.
func (o AiFeatureStoreOnlineServingConfigPtrOutput) Scaling() AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreOnlineServingConfig) *AiFeatureStoreOnlineServingConfigScaling {
		if v == nil {
			return nil
		}
		return v.Scaling
	}).(AiFeatureStoreOnlineServingConfigScalingPtrOutput)
}

type AiFeatureStoreOnlineServingConfigScaling struct {
	// The maximum number of nodes to scale up to. Must be greater than minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
	MaxNodeCount int `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount int `pulumi:"minNodeCount"`
}

// AiFeatureStoreOnlineServingConfigScalingInput is an input type that accepts AiFeatureStoreOnlineServingConfigScalingArgs and AiFeatureStoreOnlineServingConfigScalingOutput values.
// You can construct a concrete instance of `AiFeatureStoreOnlineServingConfigScalingInput` via:
//
//	AiFeatureStoreOnlineServingConfigScalingArgs{...}
type AiFeatureStoreOnlineServingConfigScalingInput interface {
	pulumi.Input

	ToAiFeatureStoreOnlineServingConfigScalingOutput() AiFeatureStoreOnlineServingConfigScalingOutput
	ToAiFeatureStoreOnlineServingConfigScalingOutputWithContext(context.Context) AiFeatureStoreOnlineServingConfigScalingOutput
}

type AiFeatureStoreOnlineServingConfigScalingArgs struct {
	// The maximum number of nodes to scale up to. Must be greater than minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
	MaxNodeCount pulumi.IntInput `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount pulumi.IntInput `pulumi:"minNodeCount"`
}

func (AiFeatureStoreOnlineServingConfigScalingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreOnlineServingConfigScaling)(nil)).Elem()
}

func (i AiFeatureStoreOnlineServingConfigScalingArgs) ToAiFeatureStoreOnlineServingConfigScalingOutput() AiFeatureStoreOnlineServingConfigScalingOutput {
	return i.ToAiFeatureStoreOnlineServingConfigScalingOutputWithContext(context.Background())
}

func (i AiFeatureStoreOnlineServingConfigScalingArgs) ToAiFeatureStoreOnlineServingConfigScalingOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigScalingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreOnlineServingConfigScalingOutput)
}

func (i AiFeatureStoreOnlineServingConfigScalingArgs) ToAiFeatureStoreOnlineServingConfigScalingPtrOutput() AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return i.ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreOnlineServingConfigScalingArgs) ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreOnlineServingConfigScalingOutput).ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(ctx)
}

// AiFeatureStoreOnlineServingConfigScalingPtrInput is an input type that accepts AiFeatureStoreOnlineServingConfigScalingArgs, AiFeatureStoreOnlineServingConfigScalingPtr and AiFeatureStoreOnlineServingConfigScalingPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreOnlineServingConfigScalingPtrInput` via:
//
//	        AiFeatureStoreOnlineServingConfigScalingArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreOnlineServingConfigScalingPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreOnlineServingConfigScalingPtrOutput() AiFeatureStoreOnlineServingConfigScalingPtrOutput
	ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(context.Context) AiFeatureStoreOnlineServingConfigScalingPtrOutput
}

type aiFeatureStoreOnlineServingConfigScalingPtrType AiFeatureStoreOnlineServingConfigScalingArgs

func AiFeatureStoreOnlineServingConfigScalingPtr(v *AiFeatureStoreOnlineServingConfigScalingArgs) AiFeatureStoreOnlineServingConfigScalingPtrInput {
	return (*aiFeatureStoreOnlineServingConfigScalingPtrType)(v)
}

func (*aiFeatureStoreOnlineServingConfigScalingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreOnlineServingConfigScaling)(nil)).Elem()
}

func (i *aiFeatureStoreOnlineServingConfigScalingPtrType) ToAiFeatureStoreOnlineServingConfigScalingPtrOutput() AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return i.ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreOnlineServingConfigScalingPtrType) ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreOnlineServingConfigScalingPtrOutput)
}

type AiFeatureStoreOnlineServingConfigScalingOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreOnlineServingConfigScalingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreOnlineServingConfigScaling)(nil)).Elem()
}

func (o AiFeatureStoreOnlineServingConfigScalingOutput) ToAiFeatureStoreOnlineServingConfigScalingOutput() AiFeatureStoreOnlineServingConfigScalingOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigScalingOutput) ToAiFeatureStoreOnlineServingConfigScalingOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigScalingOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigScalingOutput) ToAiFeatureStoreOnlineServingConfigScalingPtrOutput() AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return o.ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreOnlineServingConfigScalingOutput) ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreOnlineServingConfigScaling) *AiFeatureStoreOnlineServingConfigScaling {
		return &v
	}).(AiFeatureStoreOnlineServingConfigScalingPtrOutput)
}

// The maximum number of nodes to scale up to. Must be greater than minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
func (o AiFeatureStoreOnlineServingConfigScalingOutput) MaxNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v AiFeatureStoreOnlineServingConfigScaling) int { return v.MaxNodeCount }).(pulumi.IntOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o AiFeatureStoreOnlineServingConfigScalingOutput) MinNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v AiFeatureStoreOnlineServingConfigScaling) int { return v.MinNodeCount }).(pulumi.IntOutput)
}

type AiFeatureStoreOnlineServingConfigScalingPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreOnlineServingConfigScalingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreOnlineServingConfigScaling)(nil)).Elem()
}

func (o AiFeatureStoreOnlineServingConfigScalingPtrOutput) ToAiFeatureStoreOnlineServingConfigScalingPtrOutput() AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigScalingPtrOutput) ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigScalingPtrOutput) Elem() AiFeatureStoreOnlineServingConfigScalingOutput {
	return o.ApplyT(func(v *AiFeatureStoreOnlineServingConfigScaling) AiFeatureStoreOnlineServingConfigScaling {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreOnlineServingConfigScaling
		return ret
	}).(AiFeatureStoreOnlineServingConfigScalingOutput)
}

// The maximum number of nodes to scale up to. Must be greater than minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
func (o AiFeatureStoreOnlineServingConfigScalingPtrOutput) MaxNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreOnlineServingConfigScaling) *int {
		if v == nil {
			return nil
		}
		return &v.MaxNodeCount
	}).(pulumi.IntPtrOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o AiFeatureStoreOnlineServingConfigScalingPtrOutput) MinNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreOnlineServingConfigScaling) *int {
		if v == nil {
			return nil
		}
		return &v.MinNodeCount
	}).(pulumi.IntPtrOutput)
}

type AiIndexDeployedIndex struct {
	// (Output)
	// The ID of the DeployedIndex in the above IndexEndpoint.
	DeployedIndexId *string `pulumi:"deployedIndexId"`
	// (Output)
	// A resource name of the IndexEndpoint.
	IndexEndpoint *string `pulumi:"indexEndpoint"`
}

// AiIndexDeployedIndexInput is an input type that accepts AiIndexDeployedIndexArgs and AiIndexDeployedIndexOutput values.
// You can construct a concrete instance of `AiIndexDeployedIndexInput` via:
//
//	AiIndexDeployedIndexArgs{...}
type AiIndexDeployedIndexInput interface {
	pulumi.Input

	ToAiIndexDeployedIndexOutput() AiIndexDeployedIndexOutput
	ToAiIndexDeployedIndexOutputWithContext(context.Context) AiIndexDeployedIndexOutput
}

type AiIndexDeployedIndexArgs struct {
	// (Output)
	// The ID of the DeployedIndex in the above IndexEndpoint.
	DeployedIndexId pulumi.StringPtrInput `pulumi:"deployedIndexId"`
	// (Output)
	// A resource name of the IndexEndpoint.
	IndexEndpoint pulumi.StringPtrInput `pulumi:"indexEndpoint"`
}

func (AiIndexDeployedIndexArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexDeployedIndex)(nil)).Elem()
}

func (i AiIndexDeployedIndexArgs) ToAiIndexDeployedIndexOutput() AiIndexDeployedIndexOutput {
	return i.ToAiIndexDeployedIndexOutputWithContext(context.Background())
}

func (i AiIndexDeployedIndexArgs) ToAiIndexDeployedIndexOutputWithContext(ctx context.Context) AiIndexDeployedIndexOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexDeployedIndexOutput)
}

// AiIndexDeployedIndexArrayInput is an input type that accepts AiIndexDeployedIndexArray and AiIndexDeployedIndexArrayOutput values.
// You can construct a concrete instance of `AiIndexDeployedIndexArrayInput` via:
//
//	AiIndexDeployedIndexArray{ AiIndexDeployedIndexArgs{...} }
type AiIndexDeployedIndexArrayInput interface {
	pulumi.Input

	ToAiIndexDeployedIndexArrayOutput() AiIndexDeployedIndexArrayOutput
	ToAiIndexDeployedIndexArrayOutputWithContext(context.Context) AiIndexDeployedIndexArrayOutput
}

type AiIndexDeployedIndexArray []AiIndexDeployedIndexInput

func (AiIndexDeployedIndexArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiIndexDeployedIndex)(nil)).Elem()
}

func (i AiIndexDeployedIndexArray) ToAiIndexDeployedIndexArrayOutput() AiIndexDeployedIndexArrayOutput {
	return i.ToAiIndexDeployedIndexArrayOutputWithContext(context.Background())
}

func (i AiIndexDeployedIndexArray) ToAiIndexDeployedIndexArrayOutputWithContext(ctx context.Context) AiIndexDeployedIndexArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexDeployedIndexArrayOutput)
}

type AiIndexDeployedIndexOutput struct{ *pulumi.OutputState }

func (AiIndexDeployedIndexOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexDeployedIndex)(nil)).Elem()
}

func (o AiIndexDeployedIndexOutput) ToAiIndexDeployedIndexOutput() AiIndexDeployedIndexOutput {
	return o
}

func (o AiIndexDeployedIndexOutput) ToAiIndexDeployedIndexOutputWithContext(ctx context.Context) AiIndexDeployedIndexOutput {
	return o
}

// (Output)
// The ID of the DeployedIndex in the above IndexEndpoint.
func (o AiIndexDeployedIndexOutput) DeployedIndexId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexDeployedIndex) *string { return v.DeployedIndexId }).(pulumi.StringPtrOutput)
}

// (Output)
// A resource name of the IndexEndpoint.
func (o AiIndexDeployedIndexOutput) IndexEndpoint() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexDeployedIndex) *string { return v.IndexEndpoint }).(pulumi.StringPtrOutput)
}

type AiIndexDeployedIndexArrayOutput struct{ *pulumi.OutputState }

func (AiIndexDeployedIndexArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiIndexDeployedIndex)(nil)).Elem()
}

func (o AiIndexDeployedIndexArrayOutput) ToAiIndexDeployedIndexArrayOutput() AiIndexDeployedIndexArrayOutput {
	return o
}

func (o AiIndexDeployedIndexArrayOutput) ToAiIndexDeployedIndexArrayOutputWithContext(ctx context.Context) AiIndexDeployedIndexArrayOutput {
	return o
}

func (o AiIndexDeployedIndexArrayOutput) Index(i pulumi.IntInput) AiIndexDeployedIndexOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiIndexDeployedIndex {
		return vs[0].([]AiIndexDeployedIndex)[vs[1].(int)]
	}).(AiIndexDeployedIndexOutput)
}

type AiIndexIndexStat struct {
	// (Output)
	// The number of shards in the Index.
	ShardsCount *int `pulumi:"shardsCount"`
	// (Output)
	// The number of vectors in the Index.
	VectorsCount *string `pulumi:"vectorsCount"`
}

// AiIndexIndexStatInput is an input type that accepts AiIndexIndexStatArgs and AiIndexIndexStatOutput values.
// You can construct a concrete instance of `AiIndexIndexStatInput` via:
//
//	AiIndexIndexStatArgs{...}
type AiIndexIndexStatInput interface {
	pulumi.Input

	ToAiIndexIndexStatOutput() AiIndexIndexStatOutput
	ToAiIndexIndexStatOutputWithContext(context.Context) AiIndexIndexStatOutput
}

type AiIndexIndexStatArgs struct {
	// (Output)
	// The number of shards in the Index.
	ShardsCount pulumi.IntPtrInput `pulumi:"shardsCount"`
	// (Output)
	// The number of vectors in the Index.
	VectorsCount pulumi.StringPtrInput `pulumi:"vectorsCount"`
}

func (AiIndexIndexStatArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexIndexStat)(nil)).Elem()
}

func (i AiIndexIndexStatArgs) ToAiIndexIndexStatOutput() AiIndexIndexStatOutput {
	return i.ToAiIndexIndexStatOutputWithContext(context.Background())
}

func (i AiIndexIndexStatArgs) ToAiIndexIndexStatOutputWithContext(ctx context.Context) AiIndexIndexStatOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexIndexStatOutput)
}

// AiIndexIndexStatArrayInput is an input type that accepts AiIndexIndexStatArray and AiIndexIndexStatArrayOutput values.
// You can construct a concrete instance of `AiIndexIndexStatArrayInput` via:
//
//	AiIndexIndexStatArray{ AiIndexIndexStatArgs{...} }
type AiIndexIndexStatArrayInput interface {
	pulumi.Input

	ToAiIndexIndexStatArrayOutput() AiIndexIndexStatArrayOutput
	ToAiIndexIndexStatArrayOutputWithContext(context.Context) AiIndexIndexStatArrayOutput
}

type AiIndexIndexStatArray []AiIndexIndexStatInput

func (AiIndexIndexStatArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiIndexIndexStat)(nil)).Elem()
}

func (i AiIndexIndexStatArray) ToAiIndexIndexStatArrayOutput() AiIndexIndexStatArrayOutput {
	return i.ToAiIndexIndexStatArrayOutputWithContext(context.Background())
}

func (i AiIndexIndexStatArray) ToAiIndexIndexStatArrayOutputWithContext(ctx context.Context) AiIndexIndexStatArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexIndexStatArrayOutput)
}

type AiIndexIndexStatOutput struct{ *pulumi.OutputState }

func (AiIndexIndexStatOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexIndexStat)(nil)).Elem()
}

func (o AiIndexIndexStatOutput) ToAiIndexIndexStatOutput() AiIndexIndexStatOutput {
	return o
}

func (o AiIndexIndexStatOutput) ToAiIndexIndexStatOutputWithContext(ctx context.Context) AiIndexIndexStatOutput {
	return o
}

// (Output)
// The number of shards in the Index.
func (o AiIndexIndexStatOutput) ShardsCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiIndexIndexStat) *int { return v.ShardsCount }).(pulumi.IntPtrOutput)
}

// (Output)
// The number of vectors in the Index.
func (o AiIndexIndexStatOutput) VectorsCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexIndexStat) *string { return v.VectorsCount }).(pulumi.StringPtrOutput)
}

type AiIndexIndexStatArrayOutput struct{ *pulumi.OutputState }

func (AiIndexIndexStatArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiIndexIndexStat)(nil)).Elem()
}

func (o AiIndexIndexStatArrayOutput) ToAiIndexIndexStatArrayOutput() AiIndexIndexStatArrayOutput {
	return o
}

func (o AiIndexIndexStatArrayOutput) ToAiIndexIndexStatArrayOutputWithContext(ctx context.Context) AiIndexIndexStatArrayOutput {
	return o
}

func (o AiIndexIndexStatArrayOutput) Index(i pulumi.IntInput) AiIndexIndexStatOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiIndexIndexStat {
		return vs[0].([]AiIndexIndexStat)[vs[1].(int)]
	}).(AiIndexIndexStatOutput)
}

type AiIndexMetadata struct {
	// The configuration of the Matching Engine Index.
	// Structure is documented below.
	Config *AiIndexMetadataConfig `pulumi:"config"`
	// Allows inserting, updating  or deleting the contents of the Matching Engine Index.
	// The string must be a valid Cloud Storage directory path. If this
	// field is set when calling IndexService.UpdateIndex, then no other
	// Index field can be also updated as part of the same call.
	// The expected structure and format of the files this URI points to is
	// described at https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#input-data-format
	ContentsDeltaUri *string `pulumi:"contentsDeltaUri"`
	// If this field is set together with contentsDeltaUri when calling IndexService.UpdateIndex,
	// then existing content of the Index will be replaced by the data from the contentsDeltaUri.
	IsCompleteOverwrite *bool `pulumi:"isCompleteOverwrite"`
}

// AiIndexMetadataInput is an input type that accepts AiIndexMetadataArgs and AiIndexMetadataOutput values.
// You can construct a concrete instance of `AiIndexMetadataInput` via:
//
//	AiIndexMetadataArgs{...}
type AiIndexMetadataInput interface {
	pulumi.Input

	ToAiIndexMetadataOutput() AiIndexMetadataOutput
	ToAiIndexMetadataOutputWithContext(context.Context) AiIndexMetadataOutput
}

type AiIndexMetadataArgs struct {
	// The configuration of the Matching Engine Index.
	// Structure is documented below.
	Config AiIndexMetadataConfigPtrInput `pulumi:"config"`
	// Allows inserting, updating  or deleting the contents of the Matching Engine Index.
	// The string must be a valid Cloud Storage directory path. If this
	// field is set when calling IndexService.UpdateIndex, then no other
	// Index field can be also updated as part of the same call.
	// The expected structure and format of the files this URI points to is
	// described at https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#input-data-format
	ContentsDeltaUri pulumi.StringPtrInput `pulumi:"contentsDeltaUri"`
	// If this field is set together with contentsDeltaUri when calling IndexService.UpdateIndex,
	// then existing content of the Index will be replaced by the data from the contentsDeltaUri.
	IsCompleteOverwrite pulumi.BoolPtrInput `pulumi:"isCompleteOverwrite"`
}

func (AiIndexMetadataArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadata)(nil)).Elem()
}

func (i AiIndexMetadataArgs) ToAiIndexMetadataOutput() AiIndexMetadataOutput {
	return i.ToAiIndexMetadataOutputWithContext(context.Background())
}

func (i AiIndexMetadataArgs) ToAiIndexMetadataOutputWithContext(ctx context.Context) AiIndexMetadataOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataOutput)
}

func (i AiIndexMetadataArgs) ToAiIndexMetadataPtrOutput() AiIndexMetadataPtrOutput {
	return i.ToAiIndexMetadataPtrOutputWithContext(context.Background())
}

func (i AiIndexMetadataArgs) ToAiIndexMetadataPtrOutputWithContext(ctx context.Context) AiIndexMetadataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataOutput).ToAiIndexMetadataPtrOutputWithContext(ctx)
}

// AiIndexMetadataPtrInput is an input type that accepts AiIndexMetadataArgs, AiIndexMetadataPtr and AiIndexMetadataPtrOutput values.
// You can construct a concrete instance of `AiIndexMetadataPtrInput` via:
//
//	        AiIndexMetadataArgs{...}
//
//	or:
//
//	        nil
type AiIndexMetadataPtrInput interface {
	pulumi.Input

	ToAiIndexMetadataPtrOutput() AiIndexMetadataPtrOutput
	ToAiIndexMetadataPtrOutputWithContext(context.Context) AiIndexMetadataPtrOutput
}

type aiIndexMetadataPtrType AiIndexMetadataArgs

func AiIndexMetadataPtr(v *AiIndexMetadataArgs) AiIndexMetadataPtrInput {
	return (*aiIndexMetadataPtrType)(v)
}

func (*aiIndexMetadataPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadata)(nil)).Elem()
}

func (i *aiIndexMetadataPtrType) ToAiIndexMetadataPtrOutput() AiIndexMetadataPtrOutput {
	return i.ToAiIndexMetadataPtrOutputWithContext(context.Background())
}

func (i *aiIndexMetadataPtrType) ToAiIndexMetadataPtrOutputWithContext(ctx context.Context) AiIndexMetadataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataPtrOutput)
}

type AiIndexMetadataOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadata)(nil)).Elem()
}

func (o AiIndexMetadataOutput) ToAiIndexMetadataOutput() AiIndexMetadataOutput {
	return o
}

func (o AiIndexMetadataOutput) ToAiIndexMetadataOutputWithContext(ctx context.Context) AiIndexMetadataOutput {
	return o
}

func (o AiIndexMetadataOutput) ToAiIndexMetadataPtrOutput() AiIndexMetadataPtrOutput {
	return o.ToAiIndexMetadataPtrOutputWithContext(context.Background())
}

func (o AiIndexMetadataOutput) ToAiIndexMetadataPtrOutputWithContext(ctx context.Context) AiIndexMetadataPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexMetadata) *AiIndexMetadata {
		return &v
	}).(AiIndexMetadataPtrOutput)
}

// The configuration of the Matching Engine Index.
// Structure is documented below.
func (o AiIndexMetadataOutput) Config() AiIndexMetadataConfigPtrOutput {
	return o.ApplyT(func(v AiIndexMetadata) *AiIndexMetadataConfig { return v.Config }).(AiIndexMetadataConfigPtrOutput)
}

// Allows inserting, updating  or deleting the contents of the Matching Engine Index.
// The string must be a valid Cloud Storage directory path. If this
// field is set when calling IndexService.UpdateIndex, then no other
// Index field can be also updated as part of the same call.
// The expected structure and format of the files this URI points to is
// described at https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#input-data-format
func (o AiIndexMetadataOutput) ContentsDeltaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexMetadata) *string { return v.ContentsDeltaUri }).(pulumi.StringPtrOutput)
}

// If this field is set together with contentsDeltaUri when calling IndexService.UpdateIndex,
// then existing content of the Index will be replaced by the data from the contentsDeltaUri.
func (o AiIndexMetadataOutput) IsCompleteOverwrite() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiIndexMetadata) *bool { return v.IsCompleteOverwrite }).(pulumi.BoolPtrOutput)
}

type AiIndexMetadataPtrOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadata)(nil)).Elem()
}

func (o AiIndexMetadataPtrOutput) ToAiIndexMetadataPtrOutput() AiIndexMetadataPtrOutput {
	return o
}

func (o AiIndexMetadataPtrOutput) ToAiIndexMetadataPtrOutputWithContext(ctx context.Context) AiIndexMetadataPtrOutput {
	return o
}

func (o AiIndexMetadataPtrOutput) Elem() AiIndexMetadataOutput {
	return o.ApplyT(func(v *AiIndexMetadata) AiIndexMetadata {
		if v != nil {
			return *v
		}
		var ret AiIndexMetadata
		return ret
	}).(AiIndexMetadataOutput)
}

// The configuration of the Matching Engine Index.
// Structure is documented below.
func (o AiIndexMetadataPtrOutput) Config() AiIndexMetadataConfigPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadata) *AiIndexMetadataConfig {
		if v == nil {
			return nil
		}
		return v.Config
	}).(AiIndexMetadataConfigPtrOutput)
}

// Allows inserting, updating  or deleting the contents of the Matching Engine Index.
// The string must be a valid Cloud Storage directory path. If this
// field is set when calling IndexService.UpdateIndex, then no other
// Index field can be also updated as part of the same call.
// The expected structure and format of the files this URI points to is
// described at https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#input-data-format
func (o AiIndexMetadataPtrOutput) ContentsDeltaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadata) *string {
		if v == nil {
			return nil
		}
		return v.ContentsDeltaUri
	}).(pulumi.StringPtrOutput)
}

// If this field is set together with contentsDeltaUri when calling IndexService.UpdateIndex,
// then existing content of the Index will be replaced by the data from the contentsDeltaUri.
func (o AiIndexMetadataPtrOutput) IsCompleteOverwrite() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadata) *bool {
		if v == nil {
			return nil
		}
		return v.IsCompleteOverwrite
	}).(pulumi.BoolPtrOutput)
}

type AiIndexMetadataConfig struct {
	// The configuration with regard to the algorithms used for efficient search.
	// Structure is documented below.
	AlgorithmConfig *AiIndexMetadataConfigAlgorithmConfig `pulumi:"algorithmConfig"`
	// The default number of neighbors to find via approximate search before exact reordering is
	// performed. Exact reordering is a procedure where results returned by an
	// approximate search algorithm are reordered via a more expensive distance computation.
	// Required if tree-AH algorithm is used.
	ApproximateNeighborsCount *int `pulumi:"approximateNeighborsCount"`
	// The number of dimensions of the input vectors.
	Dimensions int `pulumi:"dimensions"`
	// The distance measure used in nearest neighbor search. The value must be one of the followings:
	// * SQUARED_L2_DISTANCE: Euclidean (L_2) Distance
	// * L1_DISTANCE: Manhattan (L_1) Distance
	// * COSINE_DISTANCE: Cosine Distance. Defined as 1 - cosine similarity.
	// * DOT_PRODUCT_DISTANCE: Dot Product Distance. Defined as a negative of the dot product
	DistanceMeasureType *string `pulumi:"distanceMeasureType"`
	// Type of normalization to be carried out on each vector. The value must be one of the followings:
	// * UNIT_L2_NORM: Unit L2 normalization type
	// * NONE: No normalization type is specified.
	FeatureNormType *string `pulumi:"featureNormType"`
	// Index data is split into equal parts to be processed. These are called "shards".
	// The shard size must be specified when creating an index. The value must be one of the followings:
	// * SHARD_SIZE_SMALL: Small (2GB)
	// * SHARD_SIZE_MEDIUM: Medium (20GB)
	// * SHARD_SIZE_LARGE: Large (50GB)
	ShardSize *string `pulumi:"shardSize"`
}

// AiIndexMetadataConfigInput is an input type that accepts AiIndexMetadataConfigArgs and AiIndexMetadataConfigOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigInput` via:
//
//	AiIndexMetadataConfigArgs{...}
type AiIndexMetadataConfigInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigOutput() AiIndexMetadataConfigOutput
	ToAiIndexMetadataConfigOutputWithContext(context.Context) AiIndexMetadataConfigOutput
}

type AiIndexMetadataConfigArgs struct {
	// The configuration with regard to the algorithms used for efficient search.
	// Structure is documented below.
	AlgorithmConfig AiIndexMetadataConfigAlgorithmConfigPtrInput `pulumi:"algorithmConfig"`
	// The default number of neighbors to find via approximate search before exact reordering is
	// performed. Exact reordering is a procedure where results returned by an
	// approximate search algorithm are reordered via a more expensive distance computation.
	// Required if tree-AH algorithm is used.
	ApproximateNeighborsCount pulumi.IntPtrInput `pulumi:"approximateNeighborsCount"`
	// The number of dimensions of the input vectors.
	Dimensions pulumi.IntInput `pulumi:"dimensions"`
	// The distance measure used in nearest neighbor search. The value must be one of the followings:
	// * SQUARED_L2_DISTANCE: Euclidean (L_2) Distance
	// * L1_DISTANCE: Manhattan (L_1) Distance
	// * COSINE_DISTANCE: Cosine Distance. Defined as 1 - cosine similarity.
	// * DOT_PRODUCT_DISTANCE: Dot Product Distance. Defined as a negative of the dot product
	DistanceMeasureType pulumi.StringPtrInput `pulumi:"distanceMeasureType"`
	// Type of normalization to be carried out on each vector. The value must be one of the followings:
	// * UNIT_L2_NORM: Unit L2 normalization type
	// * NONE: No normalization type is specified.
	FeatureNormType pulumi.StringPtrInput `pulumi:"featureNormType"`
	// Index data is split into equal parts to be processed. These are called "shards".
	// The shard size must be specified when creating an index. The value must be one of the followings:
	// * SHARD_SIZE_SMALL: Small (2GB)
	// * SHARD_SIZE_MEDIUM: Medium (20GB)
	// * SHARD_SIZE_LARGE: Large (50GB)
	ShardSize pulumi.StringPtrInput `pulumi:"shardSize"`
}

func (AiIndexMetadataConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfig)(nil)).Elem()
}

func (i AiIndexMetadataConfigArgs) ToAiIndexMetadataConfigOutput() AiIndexMetadataConfigOutput {
	return i.ToAiIndexMetadataConfigOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigArgs) ToAiIndexMetadataConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigOutput)
}

func (i AiIndexMetadataConfigArgs) ToAiIndexMetadataConfigPtrOutput() AiIndexMetadataConfigPtrOutput {
	return i.ToAiIndexMetadataConfigPtrOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigArgs) ToAiIndexMetadataConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigOutput).ToAiIndexMetadataConfigPtrOutputWithContext(ctx)
}

// AiIndexMetadataConfigPtrInput is an input type that accepts AiIndexMetadataConfigArgs, AiIndexMetadataConfigPtr and AiIndexMetadataConfigPtrOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigPtrInput` via:
//
//	        AiIndexMetadataConfigArgs{...}
//
//	or:
//
//	        nil
type AiIndexMetadataConfigPtrInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigPtrOutput() AiIndexMetadataConfigPtrOutput
	ToAiIndexMetadataConfigPtrOutputWithContext(context.Context) AiIndexMetadataConfigPtrOutput
}

type aiIndexMetadataConfigPtrType AiIndexMetadataConfigArgs

func AiIndexMetadataConfigPtr(v *AiIndexMetadataConfigArgs) AiIndexMetadataConfigPtrInput {
	return (*aiIndexMetadataConfigPtrType)(v)
}

func (*aiIndexMetadataConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfig)(nil)).Elem()
}

func (i *aiIndexMetadataConfigPtrType) ToAiIndexMetadataConfigPtrOutput() AiIndexMetadataConfigPtrOutput {
	return i.ToAiIndexMetadataConfigPtrOutputWithContext(context.Background())
}

func (i *aiIndexMetadataConfigPtrType) ToAiIndexMetadataConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigPtrOutput)
}

type AiIndexMetadataConfigOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigOutput) ToAiIndexMetadataConfigOutput() AiIndexMetadataConfigOutput {
	return o
}

func (o AiIndexMetadataConfigOutput) ToAiIndexMetadataConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigOutput {
	return o
}

func (o AiIndexMetadataConfigOutput) ToAiIndexMetadataConfigPtrOutput() AiIndexMetadataConfigPtrOutput {
	return o.ToAiIndexMetadataConfigPtrOutputWithContext(context.Background())
}

func (o AiIndexMetadataConfigOutput) ToAiIndexMetadataConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexMetadataConfig) *AiIndexMetadataConfig {
		return &v
	}).(AiIndexMetadataConfigPtrOutput)
}

// The configuration with regard to the algorithms used for efficient search.
// Structure is documented below.
func (o AiIndexMetadataConfigOutput) AlgorithmConfig() AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfig) *AiIndexMetadataConfigAlgorithmConfig { return v.AlgorithmConfig }).(AiIndexMetadataConfigAlgorithmConfigPtrOutput)
}

// The default number of neighbors to find via approximate search before exact reordering is
// performed. Exact reordering is a procedure where results returned by an
// approximate search algorithm are reordered via a more expensive distance computation.
// Required if tree-AH algorithm is used.
func (o AiIndexMetadataConfigOutput) ApproximateNeighborsCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfig) *int { return v.ApproximateNeighborsCount }).(pulumi.IntPtrOutput)
}

// The number of dimensions of the input vectors.
func (o AiIndexMetadataConfigOutput) Dimensions() pulumi.IntOutput {
	return o.ApplyT(func(v AiIndexMetadataConfig) int { return v.Dimensions }).(pulumi.IntOutput)
}

// The distance measure used in nearest neighbor search. The value must be one of the followings:
// * SQUARED_L2_DISTANCE: Euclidean (L_2) Distance
// * L1_DISTANCE: Manhattan (L_1) Distance
// * COSINE_DISTANCE: Cosine Distance. Defined as 1 - cosine similarity.
// * DOT_PRODUCT_DISTANCE: Dot Product Distance. Defined as a negative of the dot product
func (o AiIndexMetadataConfigOutput) DistanceMeasureType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfig) *string { return v.DistanceMeasureType }).(pulumi.StringPtrOutput)
}

// Type of normalization to be carried out on each vector. The value must be one of the followings:
// * UNIT_L2_NORM: Unit L2 normalization type
// * NONE: No normalization type is specified.
func (o AiIndexMetadataConfigOutput) FeatureNormType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfig) *string { return v.FeatureNormType }).(pulumi.StringPtrOutput)
}

// Index data is split into equal parts to be processed. These are called "shards".
// The shard size must be specified when creating an index. The value must be one of the followings:
// * SHARD_SIZE_SMALL: Small (2GB)
// * SHARD_SIZE_MEDIUM: Medium (20GB)
// * SHARD_SIZE_LARGE: Large (50GB)
func (o AiIndexMetadataConfigOutput) ShardSize() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfig) *string { return v.ShardSize }).(pulumi.StringPtrOutput)
}

type AiIndexMetadataConfigPtrOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigPtrOutput) ToAiIndexMetadataConfigPtrOutput() AiIndexMetadataConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigPtrOutput) ToAiIndexMetadataConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigPtrOutput) Elem() AiIndexMetadataConfigOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) AiIndexMetadataConfig {
		if v != nil {
			return *v
		}
		var ret AiIndexMetadataConfig
		return ret
	}).(AiIndexMetadataConfigOutput)
}

// The configuration with regard to the algorithms used for efficient search.
// Structure is documented below.
func (o AiIndexMetadataConfigPtrOutput) AlgorithmConfig() AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) *AiIndexMetadataConfigAlgorithmConfig {
		if v == nil {
			return nil
		}
		return v.AlgorithmConfig
	}).(AiIndexMetadataConfigAlgorithmConfigPtrOutput)
}

// The default number of neighbors to find via approximate search before exact reordering is
// performed. Exact reordering is a procedure where results returned by an
// approximate search algorithm are reordered via a more expensive distance computation.
// Required if tree-AH algorithm is used.
func (o AiIndexMetadataConfigPtrOutput) ApproximateNeighborsCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) *int {
		if v == nil {
			return nil
		}
		return v.ApproximateNeighborsCount
	}).(pulumi.IntPtrOutput)
}

// The number of dimensions of the input vectors.
func (o AiIndexMetadataConfigPtrOutput) Dimensions() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) *int {
		if v == nil {
			return nil
		}
		return &v.Dimensions
	}).(pulumi.IntPtrOutput)
}

// The distance measure used in nearest neighbor search. The value must be one of the followings:
// * SQUARED_L2_DISTANCE: Euclidean (L_2) Distance
// * L1_DISTANCE: Manhattan (L_1) Distance
// * COSINE_DISTANCE: Cosine Distance. Defined as 1 - cosine similarity.
// * DOT_PRODUCT_DISTANCE: Dot Product Distance. Defined as a negative of the dot product
func (o AiIndexMetadataConfigPtrOutput) DistanceMeasureType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) *string {
		if v == nil {
			return nil
		}
		return v.DistanceMeasureType
	}).(pulumi.StringPtrOutput)
}

// Type of normalization to be carried out on each vector. The value must be one of the followings:
// * UNIT_L2_NORM: Unit L2 normalization type
// * NONE: No normalization type is specified.
func (o AiIndexMetadataConfigPtrOutput) FeatureNormType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) *string {
		if v == nil {
			return nil
		}
		return v.FeatureNormType
	}).(pulumi.StringPtrOutput)
}

// Index data is split into equal parts to be processed. These are called "shards".
// The shard size must be specified when creating an index. The value must be one of the followings:
// * SHARD_SIZE_SMALL: Small (2GB)
// * SHARD_SIZE_MEDIUM: Medium (20GB)
// * SHARD_SIZE_LARGE: Large (50GB)
func (o AiIndexMetadataConfigPtrOutput) ShardSize() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) *string {
		if v == nil {
			return nil
		}
		return v.ShardSize
	}).(pulumi.StringPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfig struct {
	// Configuration options for using brute force search, which simply implements the
	// standard linear search in the database for each query.
	BruteForceConfig *AiIndexMetadataConfigAlgorithmConfigBruteForceConfig `pulumi:"bruteForceConfig"`
	// Configuration options for using the tree-AH algorithm (Shallow tree + Asymmetric Hashing).
	// Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
	// Structure is documented below.
	TreeAhConfig *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig `pulumi:"treeAhConfig"`
}

// AiIndexMetadataConfigAlgorithmConfigInput is an input type that accepts AiIndexMetadataConfigAlgorithmConfigArgs and AiIndexMetadataConfigAlgorithmConfigOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigAlgorithmConfigInput` via:
//
//	AiIndexMetadataConfigAlgorithmConfigArgs{...}
type AiIndexMetadataConfigAlgorithmConfigInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigAlgorithmConfigOutput() AiIndexMetadataConfigAlgorithmConfigOutput
	ToAiIndexMetadataConfigAlgorithmConfigOutputWithContext(context.Context) AiIndexMetadataConfigAlgorithmConfigOutput
}

type AiIndexMetadataConfigAlgorithmConfigArgs struct {
	// Configuration options for using brute force search, which simply implements the
	// standard linear search in the database for each query.
	BruteForceConfig AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrInput `pulumi:"bruteForceConfig"`
	// Configuration options for using the tree-AH algorithm (Shallow tree + Asymmetric Hashing).
	// Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
	// Structure is documented below.
	TreeAhConfig AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrInput `pulumi:"treeAhConfig"`
}

func (AiIndexMetadataConfigAlgorithmConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (i AiIndexMetadataConfigAlgorithmConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigOutput() AiIndexMetadataConfigAlgorithmConfigOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigAlgorithmConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigOutput)
}

func (i AiIndexMetadataConfigAlgorithmConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigAlgorithmConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigOutput).ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(ctx)
}

// AiIndexMetadataConfigAlgorithmConfigPtrInput is an input type that accepts AiIndexMetadataConfigAlgorithmConfigArgs, AiIndexMetadataConfigAlgorithmConfigPtr and AiIndexMetadataConfigAlgorithmConfigPtrOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigAlgorithmConfigPtrInput` via:
//
//	        AiIndexMetadataConfigAlgorithmConfigArgs{...}
//
//	or:
//
//	        nil
type AiIndexMetadataConfigAlgorithmConfigPtrInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigAlgorithmConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigPtrOutput
	ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(context.Context) AiIndexMetadataConfigAlgorithmConfigPtrOutput
}

type aiIndexMetadataConfigAlgorithmConfigPtrType AiIndexMetadataConfigAlgorithmConfigArgs

func AiIndexMetadataConfigAlgorithmConfigPtr(v *AiIndexMetadataConfigAlgorithmConfigArgs) AiIndexMetadataConfigAlgorithmConfigPtrInput {
	return (*aiIndexMetadataConfigAlgorithmConfigPtrType)(v)
}

func (*aiIndexMetadataConfigAlgorithmConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (i *aiIndexMetadataConfigAlgorithmConfigPtrType) ToAiIndexMetadataConfigAlgorithmConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(context.Background())
}

func (i *aiIndexMetadataConfigAlgorithmConfigPtrType) ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigAlgorithmConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigAlgorithmConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigOutput() AiIndexMetadataConfigAlgorithmConfigOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return o.ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(context.Background())
}

func (o AiIndexMetadataConfigAlgorithmConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexMetadataConfigAlgorithmConfig) *AiIndexMetadataConfigAlgorithmConfig {
		return &v
	}).(AiIndexMetadataConfigAlgorithmConfigPtrOutput)
}

// Configuration options for using brute force search, which simply implements the
// standard linear search in the database for each query.
func (o AiIndexMetadataConfigAlgorithmConfigOutput) BruteForceConfig() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfigAlgorithmConfig) *AiIndexMetadataConfigAlgorithmConfigBruteForceConfig {
		return v.BruteForceConfig
	}).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput)
}

// Configuration options for using the tree-AH algorithm (Shallow tree + Asymmetric Hashing).
// Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
// Structure is documented below.
func (o AiIndexMetadataConfigAlgorithmConfigOutput) TreeAhConfig() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfigAlgorithmConfig) *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig {
		return v.TreeAhConfig
	}).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigPtrOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigAlgorithmConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigAlgorithmConfigPtrOutput) ToAiIndexMetadataConfigAlgorithmConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigPtrOutput) ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigPtrOutput) Elem() AiIndexMetadataConfigAlgorithmConfigOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfig) AiIndexMetadataConfigAlgorithmConfig {
		if v != nil {
			return *v
		}
		var ret AiIndexMetadataConfigAlgorithmConfig
		return ret
	}).(AiIndexMetadataConfigAlgorithmConfigOutput)
}

// Configuration options for using brute force search, which simply implements the
// standard linear search in the database for each query.
func (o AiIndexMetadataConfigAlgorithmConfigPtrOutput) BruteForceConfig() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfig) *AiIndexMetadataConfigAlgorithmConfigBruteForceConfig {
		if v == nil {
			return nil
		}
		return v.BruteForceConfig
	}).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput)
}

// Configuration options for using the tree-AH algorithm (Shallow tree + Asymmetric Hashing).
// Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
// Structure is documented below.
func (o AiIndexMetadataConfigAlgorithmConfigPtrOutput) TreeAhConfig() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfig) *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig {
		if v == nil {
			return nil
		}
		return v.TreeAhConfig
	}).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigBruteForceConfig struct {
}

// AiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput is an input type that accepts AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs and AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput` via:
//
//	AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{...}
type AiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput
	ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput
}

type AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs struct {
}

func (AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (i AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput)
}

func (i AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput).ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(ctx)
}

// AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrInput is an input type that accepts AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs, AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtr and AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrInput` via:
//
//	        AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{...}
//
//	or:
//
//	        nil
type AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput
	ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput
}

type aiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrType AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs

func AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtr(v *AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrInput {
	return (*aiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrType)(v)
}

func (*aiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (i *aiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrType) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(context.Background())
}

func (i *aiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrType) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return o.ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(context.Background())
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexMetadataConfigAlgorithmConfigBruteForceConfig) *AiIndexMetadataConfigAlgorithmConfigBruteForceConfig {
		return &v
	}).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput) Elem() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfigBruteForceConfig) AiIndexMetadataConfigAlgorithmConfigBruteForceConfig {
		if v != nil {
			return *v
		}
		var ret AiIndexMetadataConfigAlgorithmConfigBruteForceConfig
		return ret
	}).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput)
}

type AiIndexMetadataConfigAlgorithmConfigTreeAhConfig struct {
	// Number of embeddings on each leaf node. The default value is 1000 if not set.
	LeafNodeEmbeddingCount *int `pulumi:"leafNodeEmbeddingCount"`
	// The default percentage of leaf nodes that any query may be searched. Must be in
	// range 1-100, inclusive. The default value is 10 (means 10%) if not set.
	LeafNodesToSearchPercent *int `pulumi:"leafNodesToSearchPercent"`
}

// AiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput is an input type that accepts AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs and AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput` via:
//
//	AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{...}
type AiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput
	ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput
}

type AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs struct {
	// Number of embeddings on each leaf node. The default value is 1000 if not set.
	LeafNodeEmbeddingCount pulumi.IntPtrInput `pulumi:"leafNodeEmbeddingCount"`
	// The default percentage of leaf nodes that any query may be searched. Must be in
	// range 1-100, inclusive. The default value is 10 (means 10%) if not set.
	LeafNodesToSearchPercent pulumi.IntPtrInput `pulumi:"leafNodesToSearchPercent"`
}

func (AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (i AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput)
}

func (i AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput).ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(ctx)
}

// AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrInput is an input type that accepts AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs, AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtr and AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrInput` via:
//
//	        AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{...}
//
//	or:
//
//	        nil
type AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput
	ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput
}

type aiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrType AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs

func AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtr(v *AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrInput {
	return (*aiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrType)(v)
}

func (*aiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (i *aiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrType) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(context.Background())
}

func (i *aiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrType) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return o.ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(context.Background())
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexMetadataConfigAlgorithmConfigTreeAhConfig) *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig {
		return &v
	}).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput)
}

// Number of embeddings on each leaf node. The default value is 1000 if not set.
func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) LeafNodeEmbeddingCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfigAlgorithmConfigTreeAhConfig) *int { return v.LeafNodeEmbeddingCount }).(pulumi.IntPtrOutput)
}

// The default percentage of leaf nodes that any query may be searched. Must be in
// range 1-100, inclusive. The default value is 10 (means 10%) if not set.
func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) LeafNodesToSearchPercent() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfigAlgorithmConfigTreeAhConfig) *int { return v.LeafNodesToSearchPercent }).(pulumi.IntPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput) Elem() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig) AiIndexMetadataConfigAlgorithmConfigTreeAhConfig {
		if v != nil {
			return *v
		}
		var ret AiIndexMetadataConfigAlgorithmConfigTreeAhConfig
		return ret
	}).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput)
}

// Number of embeddings on each leaf node. The default value is 1000 if not set.
func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput) LeafNodeEmbeddingCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig) *int {
		if v == nil {
			return nil
		}
		return v.LeafNodeEmbeddingCount
	}).(pulumi.IntPtrOutput)
}

// The default percentage of leaf nodes that any query may be searched. Must be in
// range 1-100, inclusive. The default value is 10 (means 10%) if not set.
func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput) LeafNodesToSearchPercent() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig) *int {
		if v == nil {
			return nil
		}
		return v.LeafNodesToSearchPercent
	}).(pulumi.IntPtrOutput)
}

type AiMetadataStoreEncryptionSpec struct {
	// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
	// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
	KmsKeyName *string `pulumi:"kmsKeyName"`
}

// AiMetadataStoreEncryptionSpecInput is an input type that accepts AiMetadataStoreEncryptionSpecArgs and AiMetadataStoreEncryptionSpecOutput values.
// You can construct a concrete instance of `AiMetadataStoreEncryptionSpecInput` via:
//
//	AiMetadataStoreEncryptionSpecArgs{...}
type AiMetadataStoreEncryptionSpecInput interface {
	pulumi.Input

	ToAiMetadataStoreEncryptionSpecOutput() AiMetadataStoreEncryptionSpecOutput
	ToAiMetadataStoreEncryptionSpecOutputWithContext(context.Context) AiMetadataStoreEncryptionSpecOutput
}

type AiMetadataStoreEncryptionSpecArgs struct {
	// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
	// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
	KmsKeyName pulumi.StringPtrInput `pulumi:"kmsKeyName"`
}

func (AiMetadataStoreEncryptionSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiMetadataStoreEncryptionSpec)(nil)).Elem()
}

func (i AiMetadataStoreEncryptionSpecArgs) ToAiMetadataStoreEncryptionSpecOutput() AiMetadataStoreEncryptionSpecOutput {
	return i.ToAiMetadataStoreEncryptionSpecOutputWithContext(context.Background())
}

func (i AiMetadataStoreEncryptionSpecArgs) ToAiMetadataStoreEncryptionSpecOutputWithContext(ctx context.Context) AiMetadataStoreEncryptionSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiMetadataStoreEncryptionSpecOutput)
}

func (i AiMetadataStoreEncryptionSpecArgs) ToAiMetadataStoreEncryptionSpecPtrOutput() AiMetadataStoreEncryptionSpecPtrOutput {
	return i.ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i AiMetadataStoreEncryptionSpecArgs) ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiMetadataStoreEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiMetadataStoreEncryptionSpecOutput).ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(ctx)
}

// AiMetadataStoreEncryptionSpecPtrInput is an input type that accepts AiMetadataStoreEncryptionSpecArgs, AiMetadataStoreEncryptionSpecPtr and AiMetadataStoreEncryptionSpecPtrOutput values.
// You can construct a concrete instance of `AiMetadataStoreEncryptionSpecPtrInput` via:
//
//	        AiMetadataStoreEncryptionSpecArgs{...}
//
//	or:
//
//	        nil
type AiMetadataStoreEncryptionSpecPtrInput interface {
	pulumi.Input

	ToAiMetadataStoreEncryptionSpecPtrOutput() AiMetadataStoreEncryptionSpecPtrOutput
	ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(context.Context) AiMetadataStoreEncryptionSpecPtrOutput
}

type aiMetadataStoreEncryptionSpecPtrType AiMetadataStoreEncryptionSpecArgs

func AiMetadataStoreEncryptionSpecPtr(v *AiMetadataStoreEncryptionSpecArgs) AiMetadataStoreEncryptionSpecPtrInput {
	return (*aiMetadataStoreEncryptionSpecPtrType)(v)
}

func (*aiMetadataStoreEncryptionSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiMetadataStoreEncryptionSpec)(nil)).Elem()
}

func (i *aiMetadataStoreEncryptionSpecPtrType) ToAiMetadataStoreEncryptionSpecPtrOutput() AiMetadataStoreEncryptionSpecPtrOutput {
	return i.ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i *aiMetadataStoreEncryptionSpecPtrType) ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiMetadataStoreEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiMetadataStoreEncryptionSpecPtrOutput)
}

type AiMetadataStoreEncryptionSpecOutput struct{ *pulumi.OutputState }

func (AiMetadataStoreEncryptionSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiMetadataStoreEncryptionSpec)(nil)).Elem()
}

func (o AiMetadataStoreEncryptionSpecOutput) ToAiMetadataStoreEncryptionSpecOutput() AiMetadataStoreEncryptionSpecOutput {
	return o
}

func (o AiMetadataStoreEncryptionSpecOutput) ToAiMetadataStoreEncryptionSpecOutputWithContext(ctx context.Context) AiMetadataStoreEncryptionSpecOutput {
	return o
}

func (o AiMetadataStoreEncryptionSpecOutput) ToAiMetadataStoreEncryptionSpecPtrOutput() AiMetadataStoreEncryptionSpecPtrOutput {
	return o.ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(context.Background())
}

func (o AiMetadataStoreEncryptionSpecOutput) ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiMetadataStoreEncryptionSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiMetadataStoreEncryptionSpec) *AiMetadataStoreEncryptionSpec {
		return &v
	}).(AiMetadataStoreEncryptionSpecPtrOutput)
}

// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
func (o AiMetadataStoreEncryptionSpecOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiMetadataStoreEncryptionSpec) *string { return v.KmsKeyName }).(pulumi.StringPtrOutput)
}

type AiMetadataStoreEncryptionSpecPtrOutput struct{ *pulumi.OutputState }

func (AiMetadataStoreEncryptionSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiMetadataStoreEncryptionSpec)(nil)).Elem()
}

func (o AiMetadataStoreEncryptionSpecPtrOutput) ToAiMetadataStoreEncryptionSpecPtrOutput() AiMetadataStoreEncryptionSpecPtrOutput {
	return o
}

func (o AiMetadataStoreEncryptionSpecPtrOutput) ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiMetadataStoreEncryptionSpecPtrOutput {
	return o
}

func (o AiMetadataStoreEncryptionSpecPtrOutput) Elem() AiMetadataStoreEncryptionSpecOutput {
	return o.ApplyT(func(v *AiMetadataStoreEncryptionSpec) AiMetadataStoreEncryptionSpec {
		if v != nil {
			return *v
		}
		var ret AiMetadataStoreEncryptionSpec
		return ret
	}).(AiMetadataStoreEncryptionSpecOutput)
}

// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
func (o AiMetadataStoreEncryptionSpecPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiMetadataStoreEncryptionSpec) *string {
		if v == nil {
			return nil
		}
		return v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type AiMetadataStoreStateType struct {
	// (Output)
	// The disk utilization of the MetadataStore in bytes.
	DiskUtilizationBytes *string `pulumi:"diskUtilizationBytes"`
}

// AiMetadataStoreStateTypeInput is an input type that accepts AiMetadataStoreStateTypeArgs and AiMetadataStoreStateTypeOutput values.
// You can construct a concrete instance of `AiMetadataStoreStateTypeInput` via:
//
//	AiMetadataStoreStateTypeArgs{...}
type AiMetadataStoreStateTypeInput interface {
	pulumi.Input

	ToAiMetadataStoreStateTypeOutput() AiMetadataStoreStateTypeOutput
	ToAiMetadataStoreStateTypeOutputWithContext(context.Context) AiMetadataStoreStateTypeOutput
}

type AiMetadataStoreStateTypeArgs struct {
	// (Output)
	// The disk utilization of the MetadataStore in bytes.
	DiskUtilizationBytes pulumi.StringPtrInput `pulumi:"diskUtilizationBytes"`
}

func (AiMetadataStoreStateTypeArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiMetadataStoreStateType)(nil)).Elem()
}

func (i AiMetadataStoreStateTypeArgs) ToAiMetadataStoreStateTypeOutput() AiMetadataStoreStateTypeOutput {
	return i.ToAiMetadataStoreStateTypeOutputWithContext(context.Background())
}

func (i AiMetadataStoreStateTypeArgs) ToAiMetadataStoreStateTypeOutputWithContext(ctx context.Context) AiMetadataStoreStateTypeOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiMetadataStoreStateTypeOutput)
}

// AiMetadataStoreStateTypeArrayInput is an input type that accepts AiMetadataStoreStateTypeArray and AiMetadataStoreStateTypeArrayOutput values.
// You can construct a concrete instance of `AiMetadataStoreStateTypeArrayInput` via:
//
//	AiMetadataStoreStateTypeArray{ AiMetadataStoreStateTypeArgs{...} }
type AiMetadataStoreStateTypeArrayInput interface {
	pulumi.Input

	ToAiMetadataStoreStateTypeArrayOutput() AiMetadataStoreStateTypeArrayOutput
	ToAiMetadataStoreStateTypeArrayOutputWithContext(context.Context) AiMetadataStoreStateTypeArrayOutput
}

type AiMetadataStoreStateTypeArray []AiMetadataStoreStateTypeInput

func (AiMetadataStoreStateTypeArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiMetadataStoreStateType)(nil)).Elem()
}

func (i AiMetadataStoreStateTypeArray) ToAiMetadataStoreStateTypeArrayOutput() AiMetadataStoreStateTypeArrayOutput {
	return i.ToAiMetadataStoreStateTypeArrayOutputWithContext(context.Background())
}

func (i AiMetadataStoreStateTypeArray) ToAiMetadataStoreStateTypeArrayOutputWithContext(ctx context.Context) AiMetadataStoreStateTypeArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiMetadataStoreStateTypeArrayOutput)
}

type AiMetadataStoreStateTypeOutput struct{ *pulumi.OutputState }

func (AiMetadataStoreStateTypeOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiMetadataStoreStateType)(nil)).Elem()
}

func (o AiMetadataStoreStateTypeOutput) ToAiMetadataStoreStateTypeOutput() AiMetadataStoreStateTypeOutput {
	return o
}

func (o AiMetadataStoreStateTypeOutput) ToAiMetadataStoreStateTypeOutputWithContext(ctx context.Context) AiMetadataStoreStateTypeOutput {
	return o
}

// (Output)
// The disk utilization of the MetadataStore in bytes.
func (o AiMetadataStoreStateTypeOutput) DiskUtilizationBytes() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiMetadataStoreStateType) *string { return v.DiskUtilizationBytes }).(pulumi.StringPtrOutput)
}

type AiMetadataStoreStateTypeArrayOutput struct{ *pulumi.OutputState }

func (AiMetadataStoreStateTypeArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiMetadataStoreStateType)(nil)).Elem()
}

func (o AiMetadataStoreStateTypeArrayOutput) ToAiMetadataStoreStateTypeArrayOutput() AiMetadataStoreStateTypeArrayOutput {
	return o
}

func (o AiMetadataStoreStateTypeArrayOutput) ToAiMetadataStoreStateTypeArrayOutputWithContext(ctx context.Context) AiMetadataStoreStateTypeArrayOutput {
	return o
}

func (o AiMetadataStoreStateTypeArrayOutput) Index(i pulumi.IntInput) AiMetadataStoreStateTypeOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiMetadataStoreStateType {
		return vs[0].([]AiMetadataStoreStateType)[vs[1].(int)]
	}).(AiMetadataStoreStateTypeOutput)
}

type AiTensorboardEncryptionSpec struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
	// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// AiTensorboardEncryptionSpecInput is an input type that accepts AiTensorboardEncryptionSpecArgs and AiTensorboardEncryptionSpecOutput values.
// You can construct a concrete instance of `AiTensorboardEncryptionSpecInput` via:
//
//	AiTensorboardEncryptionSpecArgs{...}
type AiTensorboardEncryptionSpecInput interface {
	pulumi.Input

	ToAiTensorboardEncryptionSpecOutput() AiTensorboardEncryptionSpecOutput
	ToAiTensorboardEncryptionSpecOutputWithContext(context.Context) AiTensorboardEncryptionSpecOutput
}

type AiTensorboardEncryptionSpecArgs struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
	// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (AiTensorboardEncryptionSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiTensorboardEncryptionSpec)(nil)).Elem()
}

func (i AiTensorboardEncryptionSpecArgs) ToAiTensorboardEncryptionSpecOutput() AiTensorboardEncryptionSpecOutput {
	return i.ToAiTensorboardEncryptionSpecOutputWithContext(context.Background())
}

func (i AiTensorboardEncryptionSpecArgs) ToAiTensorboardEncryptionSpecOutputWithContext(ctx context.Context) AiTensorboardEncryptionSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiTensorboardEncryptionSpecOutput)
}

func (i AiTensorboardEncryptionSpecArgs) ToAiTensorboardEncryptionSpecPtrOutput() AiTensorboardEncryptionSpecPtrOutput {
	return i.ToAiTensorboardEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i AiTensorboardEncryptionSpecArgs) ToAiTensorboardEncryptionSpecPtrOutputWithContext(ctx context.Context) AiTensorboardEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiTensorboardEncryptionSpecOutput).ToAiTensorboardEncryptionSpecPtrOutputWithContext(ctx)
}

// AiTensorboardEncryptionSpecPtrInput is an input type that accepts AiTensorboardEncryptionSpecArgs, AiTensorboardEncryptionSpecPtr and AiTensorboardEncryptionSpecPtrOutput values.
// You can construct a concrete instance of `AiTensorboardEncryptionSpecPtrInput` via:
//
//	        AiTensorboardEncryptionSpecArgs{...}
//
//	or:
//
//	        nil
type AiTensorboardEncryptionSpecPtrInput interface {
	pulumi.Input

	ToAiTensorboardEncryptionSpecPtrOutput() AiTensorboardEncryptionSpecPtrOutput
	ToAiTensorboardEncryptionSpecPtrOutputWithContext(context.Context) AiTensorboardEncryptionSpecPtrOutput
}

type aiTensorboardEncryptionSpecPtrType AiTensorboardEncryptionSpecArgs

func AiTensorboardEncryptionSpecPtr(v *AiTensorboardEncryptionSpecArgs) AiTensorboardEncryptionSpecPtrInput {
	return (*aiTensorboardEncryptionSpecPtrType)(v)
}

func (*aiTensorboardEncryptionSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiTensorboardEncryptionSpec)(nil)).Elem()
}

func (i *aiTensorboardEncryptionSpecPtrType) ToAiTensorboardEncryptionSpecPtrOutput() AiTensorboardEncryptionSpecPtrOutput {
	return i.ToAiTensorboardEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i *aiTensorboardEncryptionSpecPtrType) ToAiTensorboardEncryptionSpecPtrOutputWithContext(ctx context.Context) AiTensorboardEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiTensorboardEncryptionSpecPtrOutput)
}

type AiTensorboardEncryptionSpecOutput struct{ *pulumi.OutputState }

func (AiTensorboardEncryptionSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiTensorboardEncryptionSpec)(nil)).Elem()
}

func (o AiTensorboardEncryptionSpecOutput) ToAiTensorboardEncryptionSpecOutput() AiTensorboardEncryptionSpecOutput {
	return o
}

func (o AiTensorboardEncryptionSpecOutput) ToAiTensorboardEncryptionSpecOutputWithContext(ctx context.Context) AiTensorboardEncryptionSpecOutput {
	return o
}

func (o AiTensorboardEncryptionSpecOutput) ToAiTensorboardEncryptionSpecPtrOutput() AiTensorboardEncryptionSpecPtrOutput {
	return o.ToAiTensorboardEncryptionSpecPtrOutputWithContext(context.Background())
}

func (o AiTensorboardEncryptionSpecOutput) ToAiTensorboardEncryptionSpecPtrOutputWithContext(ctx context.Context) AiTensorboardEncryptionSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiTensorboardEncryptionSpec) *AiTensorboardEncryptionSpec {
		return &v
	}).(AiTensorboardEncryptionSpecPtrOutput)
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
func (o AiTensorboardEncryptionSpecOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v AiTensorboardEncryptionSpec) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type AiTensorboardEncryptionSpecPtrOutput struct{ *pulumi.OutputState }

func (AiTensorboardEncryptionSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiTensorboardEncryptionSpec)(nil)).Elem()
}

func (o AiTensorboardEncryptionSpecPtrOutput) ToAiTensorboardEncryptionSpecPtrOutput() AiTensorboardEncryptionSpecPtrOutput {
	return o
}

func (o AiTensorboardEncryptionSpecPtrOutput) ToAiTensorboardEncryptionSpecPtrOutputWithContext(ctx context.Context) AiTensorboardEncryptionSpecPtrOutput {
	return o
}

func (o AiTensorboardEncryptionSpecPtrOutput) Elem() AiTensorboardEncryptionSpecOutput {
	return o.ApplyT(func(v *AiTensorboardEncryptionSpec) AiTensorboardEncryptionSpec {
		if v != nil {
			return *v
		}
		var ret AiTensorboardEncryptionSpec
		return ret
	}).(AiTensorboardEncryptionSpecOutput)
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
func (o AiTensorboardEncryptionSpecPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiTensorboardEncryptionSpec) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type GetAiIndexDeployedIndex struct {
	DeployedIndexId string `pulumi:"deployedIndexId"`
	IndexEndpoint   string `pulumi:"indexEndpoint"`
}

// GetAiIndexDeployedIndexInput is an input type that accepts GetAiIndexDeployedIndexArgs and GetAiIndexDeployedIndexOutput values.
// You can construct a concrete instance of `GetAiIndexDeployedIndexInput` via:
//
//	GetAiIndexDeployedIndexArgs{...}
type GetAiIndexDeployedIndexInput interface {
	pulumi.Input

	ToGetAiIndexDeployedIndexOutput() GetAiIndexDeployedIndexOutput
	ToGetAiIndexDeployedIndexOutputWithContext(context.Context) GetAiIndexDeployedIndexOutput
}

type GetAiIndexDeployedIndexArgs struct {
	DeployedIndexId pulumi.StringInput `pulumi:"deployedIndexId"`
	IndexEndpoint   pulumi.StringInput `pulumi:"indexEndpoint"`
}

func (GetAiIndexDeployedIndexArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexDeployedIndex)(nil)).Elem()
}

func (i GetAiIndexDeployedIndexArgs) ToGetAiIndexDeployedIndexOutput() GetAiIndexDeployedIndexOutput {
	return i.ToGetAiIndexDeployedIndexOutputWithContext(context.Background())
}

func (i GetAiIndexDeployedIndexArgs) ToGetAiIndexDeployedIndexOutputWithContext(ctx context.Context) GetAiIndexDeployedIndexOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexDeployedIndexOutput)
}

// GetAiIndexDeployedIndexArrayInput is an input type that accepts GetAiIndexDeployedIndexArray and GetAiIndexDeployedIndexArrayOutput values.
// You can construct a concrete instance of `GetAiIndexDeployedIndexArrayInput` via:
//
//	GetAiIndexDeployedIndexArray{ GetAiIndexDeployedIndexArgs{...} }
type GetAiIndexDeployedIndexArrayInput interface {
	pulumi.Input

	ToGetAiIndexDeployedIndexArrayOutput() GetAiIndexDeployedIndexArrayOutput
	ToGetAiIndexDeployedIndexArrayOutputWithContext(context.Context) GetAiIndexDeployedIndexArrayOutput
}

type GetAiIndexDeployedIndexArray []GetAiIndexDeployedIndexInput

func (GetAiIndexDeployedIndexArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexDeployedIndex)(nil)).Elem()
}

func (i GetAiIndexDeployedIndexArray) ToGetAiIndexDeployedIndexArrayOutput() GetAiIndexDeployedIndexArrayOutput {
	return i.ToGetAiIndexDeployedIndexArrayOutputWithContext(context.Background())
}

func (i GetAiIndexDeployedIndexArray) ToGetAiIndexDeployedIndexArrayOutputWithContext(ctx context.Context) GetAiIndexDeployedIndexArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexDeployedIndexArrayOutput)
}

type GetAiIndexDeployedIndexOutput struct{ *pulumi.OutputState }

func (GetAiIndexDeployedIndexOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexDeployedIndex)(nil)).Elem()
}

func (o GetAiIndexDeployedIndexOutput) ToGetAiIndexDeployedIndexOutput() GetAiIndexDeployedIndexOutput {
	return o
}

func (o GetAiIndexDeployedIndexOutput) ToGetAiIndexDeployedIndexOutputWithContext(ctx context.Context) GetAiIndexDeployedIndexOutput {
	return o
}

func (o GetAiIndexDeployedIndexOutput) DeployedIndexId() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexDeployedIndex) string { return v.DeployedIndexId }).(pulumi.StringOutput)
}

func (o GetAiIndexDeployedIndexOutput) IndexEndpoint() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexDeployedIndex) string { return v.IndexEndpoint }).(pulumi.StringOutput)
}

type GetAiIndexDeployedIndexArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexDeployedIndexArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexDeployedIndex)(nil)).Elem()
}

func (o GetAiIndexDeployedIndexArrayOutput) ToGetAiIndexDeployedIndexArrayOutput() GetAiIndexDeployedIndexArrayOutput {
	return o
}

func (o GetAiIndexDeployedIndexArrayOutput) ToGetAiIndexDeployedIndexArrayOutputWithContext(ctx context.Context) GetAiIndexDeployedIndexArrayOutput {
	return o
}

func (o GetAiIndexDeployedIndexArrayOutput) Index(i pulumi.IntInput) GetAiIndexDeployedIndexOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexDeployedIndex {
		return vs[0].([]GetAiIndexDeployedIndex)[vs[1].(int)]
	}).(GetAiIndexDeployedIndexOutput)
}

type GetAiIndexIndexStat struct {
	ShardsCount  int    `pulumi:"shardsCount"`
	VectorsCount string `pulumi:"vectorsCount"`
}

// GetAiIndexIndexStatInput is an input type that accepts GetAiIndexIndexStatArgs and GetAiIndexIndexStatOutput values.
// You can construct a concrete instance of `GetAiIndexIndexStatInput` via:
//
//	GetAiIndexIndexStatArgs{...}
type GetAiIndexIndexStatInput interface {
	pulumi.Input

	ToGetAiIndexIndexStatOutput() GetAiIndexIndexStatOutput
	ToGetAiIndexIndexStatOutputWithContext(context.Context) GetAiIndexIndexStatOutput
}

type GetAiIndexIndexStatArgs struct {
	ShardsCount  pulumi.IntInput    `pulumi:"shardsCount"`
	VectorsCount pulumi.StringInput `pulumi:"vectorsCount"`
}

func (GetAiIndexIndexStatArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexIndexStat)(nil)).Elem()
}

func (i GetAiIndexIndexStatArgs) ToGetAiIndexIndexStatOutput() GetAiIndexIndexStatOutput {
	return i.ToGetAiIndexIndexStatOutputWithContext(context.Background())
}

func (i GetAiIndexIndexStatArgs) ToGetAiIndexIndexStatOutputWithContext(ctx context.Context) GetAiIndexIndexStatOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexIndexStatOutput)
}

// GetAiIndexIndexStatArrayInput is an input type that accepts GetAiIndexIndexStatArray and GetAiIndexIndexStatArrayOutput values.
// You can construct a concrete instance of `GetAiIndexIndexStatArrayInput` via:
//
//	GetAiIndexIndexStatArray{ GetAiIndexIndexStatArgs{...} }
type GetAiIndexIndexStatArrayInput interface {
	pulumi.Input

	ToGetAiIndexIndexStatArrayOutput() GetAiIndexIndexStatArrayOutput
	ToGetAiIndexIndexStatArrayOutputWithContext(context.Context) GetAiIndexIndexStatArrayOutput
}

type GetAiIndexIndexStatArray []GetAiIndexIndexStatInput

func (GetAiIndexIndexStatArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexIndexStat)(nil)).Elem()
}

func (i GetAiIndexIndexStatArray) ToGetAiIndexIndexStatArrayOutput() GetAiIndexIndexStatArrayOutput {
	return i.ToGetAiIndexIndexStatArrayOutputWithContext(context.Background())
}

func (i GetAiIndexIndexStatArray) ToGetAiIndexIndexStatArrayOutputWithContext(ctx context.Context) GetAiIndexIndexStatArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexIndexStatArrayOutput)
}

type GetAiIndexIndexStatOutput struct{ *pulumi.OutputState }

func (GetAiIndexIndexStatOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexIndexStat)(nil)).Elem()
}

func (o GetAiIndexIndexStatOutput) ToGetAiIndexIndexStatOutput() GetAiIndexIndexStatOutput {
	return o
}

func (o GetAiIndexIndexStatOutput) ToGetAiIndexIndexStatOutputWithContext(ctx context.Context) GetAiIndexIndexStatOutput {
	return o
}

func (o GetAiIndexIndexStatOutput) ShardsCount() pulumi.IntOutput {
	return o.ApplyT(func(v GetAiIndexIndexStat) int { return v.ShardsCount }).(pulumi.IntOutput)
}

func (o GetAiIndexIndexStatOutput) VectorsCount() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexIndexStat) string { return v.VectorsCount }).(pulumi.StringOutput)
}

type GetAiIndexIndexStatArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexIndexStatArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexIndexStat)(nil)).Elem()
}

func (o GetAiIndexIndexStatArrayOutput) ToGetAiIndexIndexStatArrayOutput() GetAiIndexIndexStatArrayOutput {
	return o
}

func (o GetAiIndexIndexStatArrayOutput) ToGetAiIndexIndexStatArrayOutputWithContext(ctx context.Context) GetAiIndexIndexStatArrayOutput {
	return o
}

func (o GetAiIndexIndexStatArrayOutput) Index(i pulumi.IntInput) GetAiIndexIndexStatOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexIndexStat {
		return vs[0].([]GetAiIndexIndexStat)[vs[1].(int)]
	}).(GetAiIndexIndexStatOutput)
}

type GetAiIndexMetadata struct {
	Configs             []GetAiIndexMetadataConfig `pulumi:"configs"`
	ContentsDeltaUri    string                     `pulumi:"contentsDeltaUri"`
	IsCompleteOverwrite bool                       `pulumi:"isCompleteOverwrite"`
}

// GetAiIndexMetadataInput is an input type that accepts GetAiIndexMetadataArgs and GetAiIndexMetadataOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataInput` via:
//
//	GetAiIndexMetadataArgs{...}
type GetAiIndexMetadataInput interface {
	pulumi.Input

	ToGetAiIndexMetadataOutput() GetAiIndexMetadataOutput
	ToGetAiIndexMetadataOutputWithContext(context.Context) GetAiIndexMetadataOutput
}

type GetAiIndexMetadataArgs struct {
	Configs             GetAiIndexMetadataConfigArrayInput `pulumi:"configs"`
	ContentsDeltaUri    pulumi.StringInput                 `pulumi:"contentsDeltaUri"`
	IsCompleteOverwrite pulumi.BoolInput                   `pulumi:"isCompleteOverwrite"`
}

func (GetAiIndexMetadataArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadata)(nil)).Elem()
}

func (i GetAiIndexMetadataArgs) ToGetAiIndexMetadataOutput() GetAiIndexMetadataOutput {
	return i.ToGetAiIndexMetadataOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataArgs) ToGetAiIndexMetadataOutputWithContext(ctx context.Context) GetAiIndexMetadataOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataOutput)
}

// GetAiIndexMetadataArrayInput is an input type that accepts GetAiIndexMetadataArray and GetAiIndexMetadataArrayOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataArrayInput` via:
//
//	GetAiIndexMetadataArray{ GetAiIndexMetadataArgs{...} }
type GetAiIndexMetadataArrayInput interface {
	pulumi.Input

	ToGetAiIndexMetadataArrayOutput() GetAiIndexMetadataArrayOutput
	ToGetAiIndexMetadataArrayOutputWithContext(context.Context) GetAiIndexMetadataArrayOutput
}

type GetAiIndexMetadataArray []GetAiIndexMetadataInput

func (GetAiIndexMetadataArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadata)(nil)).Elem()
}

func (i GetAiIndexMetadataArray) ToGetAiIndexMetadataArrayOutput() GetAiIndexMetadataArrayOutput {
	return i.ToGetAiIndexMetadataArrayOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataArray) ToGetAiIndexMetadataArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataArrayOutput)
}

type GetAiIndexMetadataOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadata)(nil)).Elem()
}

func (o GetAiIndexMetadataOutput) ToGetAiIndexMetadataOutput() GetAiIndexMetadataOutput {
	return o
}

func (o GetAiIndexMetadataOutput) ToGetAiIndexMetadataOutputWithContext(ctx context.Context) GetAiIndexMetadataOutput {
	return o
}

func (o GetAiIndexMetadataOutput) Configs() GetAiIndexMetadataConfigArrayOutput {
	return o.ApplyT(func(v GetAiIndexMetadata) []GetAiIndexMetadataConfig { return v.Configs }).(GetAiIndexMetadataConfigArrayOutput)
}

func (o GetAiIndexMetadataOutput) ContentsDeltaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexMetadata) string { return v.ContentsDeltaUri }).(pulumi.StringOutput)
}

func (o GetAiIndexMetadataOutput) IsCompleteOverwrite() pulumi.BoolOutput {
	return o.ApplyT(func(v GetAiIndexMetadata) bool { return v.IsCompleteOverwrite }).(pulumi.BoolOutput)
}

type GetAiIndexMetadataArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadata)(nil)).Elem()
}

func (o GetAiIndexMetadataArrayOutput) ToGetAiIndexMetadataArrayOutput() GetAiIndexMetadataArrayOutput {
	return o
}

func (o GetAiIndexMetadataArrayOutput) ToGetAiIndexMetadataArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataArrayOutput {
	return o
}

func (o GetAiIndexMetadataArrayOutput) Index(i pulumi.IntInput) GetAiIndexMetadataOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexMetadata {
		return vs[0].([]GetAiIndexMetadata)[vs[1].(int)]
	}).(GetAiIndexMetadataOutput)
}

type GetAiIndexMetadataConfig struct {
	AlgorithmConfigs          []GetAiIndexMetadataConfigAlgorithmConfig `pulumi:"algorithmConfigs"`
	ApproximateNeighborsCount int                                       `pulumi:"approximateNeighborsCount"`
	Dimensions                int                                       `pulumi:"dimensions"`
	DistanceMeasureType       string                                    `pulumi:"distanceMeasureType"`
	FeatureNormType           string                                    `pulumi:"featureNormType"`
	ShardSize                 string                                    `pulumi:"shardSize"`
}

// GetAiIndexMetadataConfigInput is an input type that accepts GetAiIndexMetadataConfigArgs and GetAiIndexMetadataConfigOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigInput` via:
//
//	GetAiIndexMetadataConfigArgs{...}
type GetAiIndexMetadataConfigInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigOutput() GetAiIndexMetadataConfigOutput
	ToGetAiIndexMetadataConfigOutputWithContext(context.Context) GetAiIndexMetadataConfigOutput
}

type GetAiIndexMetadataConfigArgs struct {
	AlgorithmConfigs          GetAiIndexMetadataConfigAlgorithmConfigArrayInput `pulumi:"algorithmConfigs"`
	ApproximateNeighborsCount pulumi.IntInput                                   `pulumi:"approximateNeighborsCount"`
	Dimensions                pulumi.IntInput                                   `pulumi:"dimensions"`
	DistanceMeasureType       pulumi.StringInput                                `pulumi:"distanceMeasureType"`
	FeatureNormType           pulumi.StringInput                                `pulumi:"featureNormType"`
	ShardSize                 pulumi.StringInput                                `pulumi:"shardSize"`
}

func (GetAiIndexMetadataConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigArgs) ToGetAiIndexMetadataConfigOutput() GetAiIndexMetadataConfigOutput {
	return i.ToGetAiIndexMetadataConfigOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigArgs) ToGetAiIndexMetadataConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigOutput)
}

// GetAiIndexMetadataConfigArrayInput is an input type that accepts GetAiIndexMetadataConfigArray and GetAiIndexMetadataConfigArrayOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigArrayInput` via:
//
//	GetAiIndexMetadataConfigArray{ GetAiIndexMetadataConfigArgs{...} }
type GetAiIndexMetadataConfigArrayInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigArrayOutput() GetAiIndexMetadataConfigArrayOutput
	ToGetAiIndexMetadataConfigArrayOutputWithContext(context.Context) GetAiIndexMetadataConfigArrayOutput
}

type GetAiIndexMetadataConfigArray []GetAiIndexMetadataConfigInput

func (GetAiIndexMetadataConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigArray) ToGetAiIndexMetadataConfigArrayOutput() GetAiIndexMetadataConfigArrayOutput {
	return i.ToGetAiIndexMetadataConfigArrayOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigArray) ToGetAiIndexMetadataConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigArrayOutput)
}

type GetAiIndexMetadataConfigOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigOutput) ToGetAiIndexMetadataConfigOutput() GetAiIndexMetadataConfigOutput {
	return o
}

func (o GetAiIndexMetadataConfigOutput) ToGetAiIndexMetadataConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigOutput {
	return o
}

func (o GetAiIndexMetadataConfigOutput) AlgorithmConfigs() GetAiIndexMetadataConfigAlgorithmConfigArrayOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfig) []GetAiIndexMetadataConfigAlgorithmConfig { return v.AlgorithmConfigs }).(GetAiIndexMetadataConfigAlgorithmConfigArrayOutput)
}

func (o GetAiIndexMetadataConfigOutput) ApproximateNeighborsCount() pulumi.IntOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfig) int { return v.ApproximateNeighborsCount }).(pulumi.IntOutput)
}

func (o GetAiIndexMetadataConfigOutput) Dimensions() pulumi.IntOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfig) int { return v.Dimensions }).(pulumi.IntOutput)
}

func (o GetAiIndexMetadataConfigOutput) DistanceMeasureType() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfig) string { return v.DistanceMeasureType }).(pulumi.StringOutput)
}

func (o GetAiIndexMetadataConfigOutput) FeatureNormType() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfig) string { return v.FeatureNormType }).(pulumi.StringOutput)
}

func (o GetAiIndexMetadataConfigOutput) ShardSize() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfig) string { return v.ShardSize }).(pulumi.StringOutput)
}

type GetAiIndexMetadataConfigArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigArrayOutput) ToGetAiIndexMetadataConfigArrayOutput() GetAiIndexMetadataConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigArrayOutput) ToGetAiIndexMetadataConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigArrayOutput) Index(i pulumi.IntInput) GetAiIndexMetadataConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexMetadataConfig {
		return vs[0].([]GetAiIndexMetadataConfig)[vs[1].(int)]
	}).(GetAiIndexMetadataConfigOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfig struct {
	BruteForceConfigs []GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig `pulumi:"bruteForceConfigs"`
	TreeAhConfigs     []GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig     `pulumi:"treeAhConfigs"`
}

// GetAiIndexMetadataConfigAlgorithmConfigInput is an input type that accepts GetAiIndexMetadataConfigAlgorithmConfigArgs and GetAiIndexMetadataConfigAlgorithmConfigOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigAlgorithmConfigInput` via:
//
//	GetAiIndexMetadataConfigAlgorithmConfigArgs{...}
type GetAiIndexMetadataConfigAlgorithmConfigInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigAlgorithmConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigOutput
	ToGetAiIndexMetadataConfigAlgorithmConfigOutputWithContext(context.Context) GetAiIndexMetadataConfigAlgorithmConfigOutput
}

type GetAiIndexMetadataConfigAlgorithmConfigArgs struct {
	BruteForceConfigs GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayInput `pulumi:"bruteForceConfigs"`
	TreeAhConfigs     GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayInput     `pulumi:"treeAhConfigs"`
}

func (GetAiIndexMetadataConfigAlgorithmConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigAlgorithmConfigArgs) ToGetAiIndexMetadataConfigAlgorithmConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigOutput {
	return i.ToGetAiIndexMetadataConfigAlgorithmConfigOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigAlgorithmConfigArgs) ToGetAiIndexMetadataConfigAlgorithmConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigAlgorithmConfigOutput)
}

// GetAiIndexMetadataConfigAlgorithmConfigArrayInput is an input type that accepts GetAiIndexMetadataConfigAlgorithmConfigArray and GetAiIndexMetadataConfigAlgorithmConfigArrayOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigAlgorithmConfigArrayInput` via:
//
//	GetAiIndexMetadataConfigAlgorithmConfigArray{ GetAiIndexMetadataConfigAlgorithmConfigArgs{...} }
type GetAiIndexMetadataConfigAlgorithmConfigArrayInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigArrayOutput
	ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutputWithContext(context.Context) GetAiIndexMetadataConfigAlgorithmConfigArrayOutput
}

type GetAiIndexMetadataConfigAlgorithmConfigArray []GetAiIndexMetadataConfigAlgorithmConfigInput

func (GetAiIndexMetadataConfigAlgorithmConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigAlgorithmConfigArray) ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigArrayOutput {
	return i.ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigAlgorithmConfigArray) ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigAlgorithmConfigArrayOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigAlgorithmConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigAlgorithmConfigOutput) ToGetAiIndexMetadataConfigAlgorithmConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigOutput) ToGetAiIndexMetadataConfigAlgorithmConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigOutput) BruteForceConfigs() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfigAlgorithmConfig) []GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig {
		return v.BruteForceConfigs
	}).(GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput)
}

func (o GetAiIndexMetadataConfigAlgorithmConfigOutput) TreeAhConfigs() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfigAlgorithmConfig) []GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig {
		return v.TreeAhConfigs
	}).(GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigAlgorithmConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigAlgorithmConfigArrayOutput) ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigArrayOutput) ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigArrayOutput) Index(i pulumi.IntInput) GetAiIndexMetadataConfigAlgorithmConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexMetadataConfigAlgorithmConfig {
		return vs[0].([]GetAiIndexMetadataConfigAlgorithmConfig)[vs[1].(int)]
	}).(GetAiIndexMetadataConfigAlgorithmConfigOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig struct {
}

// GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput is an input type that accepts GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs and GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput` via:
//
//	GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{...}
type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput
	ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(context.Context) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput
}

type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs struct {
}

func (GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return i.ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput)
}

// GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayInput is an input type that accepts GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray and GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayInput` via:
//
//	GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray{ GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{...} }
type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput
	ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutputWithContext(context.Context) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput
}

type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray []GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput

func (GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput {
	return i.ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return o
}

type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput) Index(i pulumi.IntInput) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig {
		return vs[0].([]GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig)[vs[1].(int)]
	}).(GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig struct {
	LeafNodeEmbeddingCount   int `pulumi:"leafNodeEmbeddingCount"`
	LeafNodesToSearchPercent int `pulumi:"leafNodesToSearchPercent"`
}

// GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput is an input type that accepts GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs and GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput` via:
//
//	GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{...}
type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput
	ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(context.Context) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput
}

type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs struct {
	LeafNodeEmbeddingCount   pulumi.IntInput `pulumi:"leafNodeEmbeddingCount"`
	LeafNodesToSearchPercent pulumi.IntInput `pulumi:"leafNodesToSearchPercent"`
}

func (GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return i.ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput)
}

// GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayInput is an input type that accepts GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray and GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayInput` via:
//
//	GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray{ GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{...} }
type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput
	ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutputWithContext(context.Context) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput
}

type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray []GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput

func (GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput {
	return i.ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) LeafNodeEmbeddingCount() pulumi.IntOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig) int { return v.LeafNodeEmbeddingCount }).(pulumi.IntOutput)
}

func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) LeafNodesToSearchPercent() pulumi.IntOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig) int { return v.LeafNodesToSearchPercent }).(pulumi.IntOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput) Index(i pulumi.IntInput) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig {
		return vs[0].([]GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig)[vs[1].(int)]
	}).(GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*AiDatasetEncryptionSpecInput)(nil)).Elem(), AiDatasetEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiDatasetEncryptionSpecPtrInput)(nil)).Elem(), AiDatasetEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelInput)(nil)).Elem(), AiEndpointDeployedModelArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelArrayInput)(nil)).Elem(), AiEndpointDeployedModelArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelAutomaticResourceInput)(nil)).Elem(), AiEndpointDeployedModelAutomaticResourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelAutomaticResourceArrayInput)(nil)).Elem(), AiEndpointDeployedModelAutomaticResourceArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceInput)(nil)).Elem(), AiEndpointDeployedModelDedicatedResourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceArrayInput)(nil)).Elem(), AiEndpointDeployedModelDedicatedResourceArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecInput)(nil)).Elem(), AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayInput)(nil)).Elem(), AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceMachineSpecInput)(nil)).Elem(), AiEndpointDeployedModelDedicatedResourceMachineSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceMachineSpecArrayInput)(nil)).Elem(), AiEndpointDeployedModelDedicatedResourceMachineSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelPrivateEndpointInput)(nil)).Elem(), AiEndpointDeployedModelPrivateEndpointArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelPrivateEndpointArrayInput)(nil)).Elem(), AiEndpointDeployedModelPrivateEndpointArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointEncryptionSpecInput)(nil)).Elem(), AiEndpointEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointEncryptionSpecPtrInput)(nil)).Elem(), AiEndpointEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEncryptionSpecInput)(nil)).Elem(), AiFeatureStoreEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEncryptionSpecPtrInput)(nil)).Elem(), AiFeatureStoreEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeIamBindingConditionInput)(nil)).Elem(), AiFeatureStoreEntityTypeIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeIamBindingConditionPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeIamMemberConditionInput)(nil)).Elem(), AiFeatureStoreEntityTypeIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeIamMemberConditionPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreIamBindingConditionInput)(nil)).Elem(), AiFeatureStoreIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreIamBindingConditionPtrInput)(nil)).Elem(), AiFeatureStoreIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreIamMemberConditionInput)(nil)).Elem(), AiFeatureStoreIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreIamMemberConditionPtrInput)(nil)).Elem(), AiFeatureStoreIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreOnlineServingConfigInput)(nil)).Elem(), AiFeatureStoreOnlineServingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreOnlineServingConfigPtrInput)(nil)).Elem(), AiFeatureStoreOnlineServingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreOnlineServingConfigScalingInput)(nil)).Elem(), AiFeatureStoreOnlineServingConfigScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreOnlineServingConfigScalingPtrInput)(nil)).Elem(), AiFeatureStoreOnlineServingConfigScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexDeployedIndexInput)(nil)).Elem(), AiIndexDeployedIndexArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexDeployedIndexArrayInput)(nil)).Elem(), AiIndexDeployedIndexArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexIndexStatInput)(nil)).Elem(), AiIndexIndexStatArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexIndexStatArrayInput)(nil)).Elem(), AiIndexIndexStatArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataInput)(nil)).Elem(), AiIndexMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataPtrInput)(nil)).Elem(), AiIndexMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigInput)(nil)).Elem(), AiIndexMetadataConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigPtrInput)(nil)).Elem(), AiIndexMetadataConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigInput)(nil)).Elem(), AiIndexMetadataConfigAlgorithmConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigPtrInput)(nil)).Elem(), AiIndexMetadataConfigAlgorithmConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput)(nil)).Elem(), AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrInput)(nil)).Elem(), AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput)(nil)).Elem(), AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrInput)(nil)).Elem(), AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiMetadataStoreEncryptionSpecInput)(nil)).Elem(), AiMetadataStoreEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiMetadataStoreEncryptionSpecPtrInput)(nil)).Elem(), AiMetadataStoreEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiMetadataStoreStateTypeInput)(nil)).Elem(), AiMetadataStoreStateTypeArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiMetadataStoreStateTypeArrayInput)(nil)).Elem(), AiMetadataStoreStateTypeArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiTensorboardEncryptionSpecInput)(nil)).Elem(), AiTensorboardEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiTensorboardEncryptionSpecPtrInput)(nil)).Elem(), AiTensorboardEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexDeployedIndexInput)(nil)).Elem(), GetAiIndexDeployedIndexArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexDeployedIndexArrayInput)(nil)).Elem(), GetAiIndexDeployedIndexArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexIndexStatInput)(nil)).Elem(), GetAiIndexIndexStatArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexIndexStatArrayInput)(nil)).Elem(), GetAiIndexIndexStatArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataInput)(nil)).Elem(), GetAiIndexMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataArrayInput)(nil)).Elem(), GetAiIndexMetadataArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigInput)(nil)).Elem(), GetAiIndexMetadataConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigArrayInput)(nil)).Elem(), GetAiIndexMetadataConfigArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigInput)(nil)).Elem(), GetAiIndexMetadataConfigAlgorithmConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigArrayInput)(nil)).Elem(), GetAiIndexMetadataConfigAlgorithmConfigArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput)(nil)).Elem(), GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayInput)(nil)).Elem(), GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput)(nil)).Elem(), GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayInput)(nil)).Elem(), GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray{})
	pulumi.RegisterOutputType(AiDatasetEncryptionSpecOutput{})
	pulumi.RegisterOutputType(AiDatasetEncryptionSpecPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelAutomaticResourceOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelAutomaticResourceArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelDedicatedResourceOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelDedicatedResourceArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelDedicatedResourceMachineSpecOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelPrivateEndpointOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelPrivateEndpointArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointEncryptionSpecOutput{})
	pulumi.RegisterOutputType(AiEndpointEncryptionSpecPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEncryptionSpecOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEncryptionSpecPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeIamBindingConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeIamBindingConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeIamMemberConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeIamMemberConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreIamBindingConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreIamBindingConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreIamMemberConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreIamMemberConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreOnlineServingConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreOnlineServingConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreOnlineServingConfigScalingOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreOnlineServingConfigScalingPtrOutput{})
	pulumi.RegisterOutputType(AiIndexDeployedIndexOutput{})
	pulumi.RegisterOutputType(AiIndexDeployedIndexArrayOutput{})
	pulumi.RegisterOutputType(AiIndexIndexStatOutput{})
	pulumi.RegisterOutputType(AiIndexIndexStatArrayOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataPtrOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigPtrOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigAlgorithmConfigOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigAlgorithmConfigPtrOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput{})
	pulumi.RegisterOutputType(AiMetadataStoreEncryptionSpecOutput{})
	pulumi.RegisterOutputType(AiMetadataStoreEncryptionSpecPtrOutput{})
	pulumi.RegisterOutputType(AiMetadataStoreStateTypeOutput{})
	pulumi.RegisterOutputType(AiMetadataStoreStateTypeArrayOutput{})
	pulumi.RegisterOutputType(AiTensorboardEncryptionSpecOutput{})
	pulumi.RegisterOutputType(AiTensorboardEncryptionSpecPtrOutput{})
	pulumi.RegisterOutputType(GetAiIndexDeployedIndexOutput{})
	pulumi.RegisterOutputType(GetAiIndexDeployedIndexArrayOutput{})
	pulumi.RegisterOutputType(GetAiIndexIndexStatOutput{})
	pulumi.RegisterOutputType(GetAiIndexIndexStatArrayOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataArrayOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigArrayOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigAlgorithmConfigOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigAlgorithmConfigArrayOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput{})
}
