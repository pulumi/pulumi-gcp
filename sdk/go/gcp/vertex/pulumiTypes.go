// Code generated by pulumi-language-go DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package vertex

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi-gcp/sdk/v9/go/gcp/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

var _ = internal.GetEnvOrDefault

type AiDatasetEncryptionSpec struct {
	// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
	// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
	KmsKeyName *string `pulumi:"kmsKeyName"`
}

// AiDatasetEncryptionSpecInput is an input type that accepts AiDatasetEncryptionSpecArgs and AiDatasetEncryptionSpecOutput values.
// You can construct a concrete instance of `AiDatasetEncryptionSpecInput` via:
//
//	AiDatasetEncryptionSpecArgs{...}
type AiDatasetEncryptionSpecInput interface {
	pulumi.Input

	ToAiDatasetEncryptionSpecOutput() AiDatasetEncryptionSpecOutput
	ToAiDatasetEncryptionSpecOutputWithContext(context.Context) AiDatasetEncryptionSpecOutput
}

type AiDatasetEncryptionSpecArgs struct {
	// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
	// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
	KmsKeyName pulumi.StringPtrInput `pulumi:"kmsKeyName"`
}

func (AiDatasetEncryptionSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiDatasetEncryptionSpec)(nil)).Elem()
}

func (i AiDatasetEncryptionSpecArgs) ToAiDatasetEncryptionSpecOutput() AiDatasetEncryptionSpecOutput {
	return i.ToAiDatasetEncryptionSpecOutputWithContext(context.Background())
}

func (i AiDatasetEncryptionSpecArgs) ToAiDatasetEncryptionSpecOutputWithContext(ctx context.Context) AiDatasetEncryptionSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDatasetEncryptionSpecOutput)
}

func (i AiDatasetEncryptionSpecArgs) ToAiDatasetEncryptionSpecPtrOutput() AiDatasetEncryptionSpecPtrOutput {
	return i.ToAiDatasetEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i AiDatasetEncryptionSpecArgs) ToAiDatasetEncryptionSpecPtrOutputWithContext(ctx context.Context) AiDatasetEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDatasetEncryptionSpecOutput).ToAiDatasetEncryptionSpecPtrOutputWithContext(ctx)
}

// AiDatasetEncryptionSpecPtrInput is an input type that accepts AiDatasetEncryptionSpecArgs, AiDatasetEncryptionSpecPtr and AiDatasetEncryptionSpecPtrOutput values.
// You can construct a concrete instance of `AiDatasetEncryptionSpecPtrInput` via:
//
//	        AiDatasetEncryptionSpecArgs{...}
//
//	or:
//
//	        nil
type AiDatasetEncryptionSpecPtrInput interface {
	pulumi.Input

	ToAiDatasetEncryptionSpecPtrOutput() AiDatasetEncryptionSpecPtrOutput
	ToAiDatasetEncryptionSpecPtrOutputWithContext(context.Context) AiDatasetEncryptionSpecPtrOutput
}

type aiDatasetEncryptionSpecPtrType AiDatasetEncryptionSpecArgs

func AiDatasetEncryptionSpecPtr(v *AiDatasetEncryptionSpecArgs) AiDatasetEncryptionSpecPtrInput {
	return (*aiDatasetEncryptionSpecPtrType)(v)
}

func (*aiDatasetEncryptionSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiDatasetEncryptionSpec)(nil)).Elem()
}

func (i *aiDatasetEncryptionSpecPtrType) ToAiDatasetEncryptionSpecPtrOutput() AiDatasetEncryptionSpecPtrOutput {
	return i.ToAiDatasetEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i *aiDatasetEncryptionSpecPtrType) ToAiDatasetEncryptionSpecPtrOutputWithContext(ctx context.Context) AiDatasetEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDatasetEncryptionSpecPtrOutput)
}

type AiDatasetEncryptionSpecOutput struct{ *pulumi.OutputState }

func (AiDatasetEncryptionSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiDatasetEncryptionSpec)(nil)).Elem()
}

func (o AiDatasetEncryptionSpecOutput) ToAiDatasetEncryptionSpecOutput() AiDatasetEncryptionSpecOutput {
	return o
}

func (o AiDatasetEncryptionSpecOutput) ToAiDatasetEncryptionSpecOutputWithContext(ctx context.Context) AiDatasetEncryptionSpecOutput {
	return o
}

func (o AiDatasetEncryptionSpecOutput) ToAiDatasetEncryptionSpecPtrOutput() AiDatasetEncryptionSpecPtrOutput {
	return o.ToAiDatasetEncryptionSpecPtrOutputWithContext(context.Background())
}

func (o AiDatasetEncryptionSpecOutput) ToAiDatasetEncryptionSpecPtrOutputWithContext(ctx context.Context) AiDatasetEncryptionSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiDatasetEncryptionSpec) *AiDatasetEncryptionSpec {
		return &v
	}).(AiDatasetEncryptionSpecPtrOutput)
}

// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
func (o AiDatasetEncryptionSpecOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiDatasetEncryptionSpec) *string { return v.KmsKeyName }).(pulumi.StringPtrOutput)
}

type AiDatasetEncryptionSpecPtrOutput struct{ *pulumi.OutputState }

func (AiDatasetEncryptionSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiDatasetEncryptionSpec)(nil)).Elem()
}

func (o AiDatasetEncryptionSpecPtrOutput) ToAiDatasetEncryptionSpecPtrOutput() AiDatasetEncryptionSpecPtrOutput {
	return o
}

func (o AiDatasetEncryptionSpecPtrOutput) ToAiDatasetEncryptionSpecPtrOutputWithContext(ctx context.Context) AiDatasetEncryptionSpecPtrOutput {
	return o
}

func (o AiDatasetEncryptionSpecPtrOutput) Elem() AiDatasetEncryptionSpecOutput {
	return o.ApplyT(func(v *AiDatasetEncryptionSpec) AiDatasetEncryptionSpec {
		if v != nil {
			return *v
		}
		var ret AiDatasetEncryptionSpec
		return ret
	}).(AiDatasetEncryptionSpecOutput)
}

// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
func (o AiDatasetEncryptionSpecPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiDatasetEncryptionSpec) *string {
		if v == nil {
			return nil
		}
		return v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type AiDeploymentResourcePoolDedicatedResources struct {
	// A list of the metric specifications that overrides a resource utilization metric.
	// Structure is documented below.
	AutoscalingMetricSpecs []AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpec `pulumi:"autoscalingMetricSpecs"`
	// The specification of a single machine used by the prediction
	// Structure is documented below.
	MachineSpec AiDeploymentResourcePoolDedicatedResourcesMachineSpec `pulumi:"machineSpec"`
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use minReplicaCount as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for maxReplicaCount * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
	MaxReplicaCount *int `pulumi:"maxReplicaCount"`
	// The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
	MinReplicaCount int `pulumi:"minReplicaCount"`
}

// AiDeploymentResourcePoolDedicatedResourcesInput is an input type that accepts AiDeploymentResourcePoolDedicatedResourcesArgs and AiDeploymentResourcePoolDedicatedResourcesOutput values.
// You can construct a concrete instance of `AiDeploymentResourcePoolDedicatedResourcesInput` via:
//
//	AiDeploymentResourcePoolDedicatedResourcesArgs{...}
type AiDeploymentResourcePoolDedicatedResourcesInput interface {
	pulumi.Input

	ToAiDeploymentResourcePoolDedicatedResourcesOutput() AiDeploymentResourcePoolDedicatedResourcesOutput
	ToAiDeploymentResourcePoolDedicatedResourcesOutputWithContext(context.Context) AiDeploymentResourcePoolDedicatedResourcesOutput
}

type AiDeploymentResourcePoolDedicatedResourcesArgs struct {
	// A list of the metric specifications that overrides a resource utilization metric.
	// Structure is documented below.
	AutoscalingMetricSpecs AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayInput `pulumi:"autoscalingMetricSpecs"`
	// The specification of a single machine used by the prediction
	// Structure is documented below.
	MachineSpec AiDeploymentResourcePoolDedicatedResourcesMachineSpecInput `pulumi:"machineSpec"`
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use minReplicaCount as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for maxReplicaCount * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
	MaxReplicaCount pulumi.IntPtrInput `pulumi:"maxReplicaCount"`
	// The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
	MinReplicaCount pulumi.IntInput `pulumi:"minReplicaCount"`
}

func (AiDeploymentResourcePoolDedicatedResourcesArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiDeploymentResourcePoolDedicatedResources)(nil)).Elem()
}

func (i AiDeploymentResourcePoolDedicatedResourcesArgs) ToAiDeploymentResourcePoolDedicatedResourcesOutput() AiDeploymentResourcePoolDedicatedResourcesOutput {
	return i.ToAiDeploymentResourcePoolDedicatedResourcesOutputWithContext(context.Background())
}

func (i AiDeploymentResourcePoolDedicatedResourcesArgs) ToAiDeploymentResourcePoolDedicatedResourcesOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDeploymentResourcePoolDedicatedResourcesOutput)
}

func (i AiDeploymentResourcePoolDedicatedResourcesArgs) ToAiDeploymentResourcePoolDedicatedResourcesPtrOutput() AiDeploymentResourcePoolDedicatedResourcesPtrOutput {
	return i.ToAiDeploymentResourcePoolDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (i AiDeploymentResourcePoolDedicatedResourcesArgs) ToAiDeploymentResourcePoolDedicatedResourcesPtrOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDeploymentResourcePoolDedicatedResourcesOutput).ToAiDeploymentResourcePoolDedicatedResourcesPtrOutputWithContext(ctx)
}

// AiDeploymentResourcePoolDedicatedResourcesPtrInput is an input type that accepts AiDeploymentResourcePoolDedicatedResourcesArgs, AiDeploymentResourcePoolDedicatedResourcesPtr and AiDeploymentResourcePoolDedicatedResourcesPtrOutput values.
// You can construct a concrete instance of `AiDeploymentResourcePoolDedicatedResourcesPtrInput` via:
//
//	        AiDeploymentResourcePoolDedicatedResourcesArgs{...}
//
//	or:
//
//	        nil
type AiDeploymentResourcePoolDedicatedResourcesPtrInput interface {
	pulumi.Input

	ToAiDeploymentResourcePoolDedicatedResourcesPtrOutput() AiDeploymentResourcePoolDedicatedResourcesPtrOutput
	ToAiDeploymentResourcePoolDedicatedResourcesPtrOutputWithContext(context.Context) AiDeploymentResourcePoolDedicatedResourcesPtrOutput
}

type aiDeploymentResourcePoolDedicatedResourcesPtrType AiDeploymentResourcePoolDedicatedResourcesArgs

func AiDeploymentResourcePoolDedicatedResourcesPtr(v *AiDeploymentResourcePoolDedicatedResourcesArgs) AiDeploymentResourcePoolDedicatedResourcesPtrInput {
	return (*aiDeploymentResourcePoolDedicatedResourcesPtrType)(v)
}

func (*aiDeploymentResourcePoolDedicatedResourcesPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiDeploymentResourcePoolDedicatedResources)(nil)).Elem()
}

func (i *aiDeploymentResourcePoolDedicatedResourcesPtrType) ToAiDeploymentResourcePoolDedicatedResourcesPtrOutput() AiDeploymentResourcePoolDedicatedResourcesPtrOutput {
	return i.ToAiDeploymentResourcePoolDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (i *aiDeploymentResourcePoolDedicatedResourcesPtrType) ToAiDeploymentResourcePoolDedicatedResourcesPtrOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDeploymentResourcePoolDedicatedResourcesPtrOutput)
}

type AiDeploymentResourcePoolDedicatedResourcesOutput struct{ *pulumi.OutputState }

func (AiDeploymentResourcePoolDedicatedResourcesOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiDeploymentResourcePoolDedicatedResources)(nil)).Elem()
}

func (o AiDeploymentResourcePoolDedicatedResourcesOutput) ToAiDeploymentResourcePoolDedicatedResourcesOutput() AiDeploymentResourcePoolDedicatedResourcesOutput {
	return o
}

func (o AiDeploymentResourcePoolDedicatedResourcesOutput) ToAiDeploymentResourcePoolDedicatedResourcesOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesOutput {
	return o
}

func (o AiDeploymentResourcePoolDedicatedResourcesOutput) ToAiDeploymentResourcePoolDedicatedResourcesPtrOutput() AiDeploymentResourcePoolDedicatedResourcesPtrOutput {
	return o.ToAiDeploymentResourcePoolDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (o AiDeploymentResourcePoolDedicatedResourcesOutput) ToAiDeploymentResourcePoolDedicatedResourcesPtrOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiDeploymentResourcePoolDedicatedResources) *AiDeploymentResourcePoolDedicatedResources {
		return &v
	}).(AiDeploymentResourcePoolDedicatedResourcesPtrOutput)
}

// A list of the metric specifications that overrides a resource utilization metric.
// Structure is documented below.
func (o AiDeploymentResourcePoolDedicatedResourcesOutput) AutoscalingMetricSpecs() AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput {
	return o.ApplyT(func(v AiDeploymentResourcePoolDedicatedResources) []AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpec {
		return v.AutoscalingMetricSpecs
	}).(AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput)
}

// The specification of a single machine used by the prediction
// Structure is documented below.
func (o AiDeploymentResourcePoolDedicatedResourcesOutput) MachineSpec() AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput {
	return o.ApplyT(func(v AiDeploymentResourcePoolDedicatedResources) AiDeploymentResourcePoolDedicatedResourcesMachineSpec {
		return v.MachineSpec
	}).(AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput)
}

// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use minReplicaCount as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for maxReplicaCount * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
func (o AiDeploymentResourcePoolDedicatedResourcesOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiDeploymentResourcePoolDedicatedResources) *int { return v.MaxReplicaCount }).(pulumi.IntPtrOutput)
}

// The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
func (o AiDeploymentResourcePoolDedicatedResourcesOutput) MinReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v AiDeploymentResourcePoolDedicatedResources) int { return v.MinReplicaCount }).(pulumi.IntOutput)
}

type AiDeploymentResourcePoolDedicatedResourcesPtrOutput struct{ *pulumi.OutputState }

func (AiDeploymentResourcePoolDedicatedResourcesPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiDeploymentResourcePoolDedicatedResources)(nil)).Elem()
}

func (o AiDeploymentResourcePoolDedicatedResourcesPtrOutput) ToAiDeploymentResourcePoolDedicatedResourcesPtrOutput() AiDeploymentResourcePoolDedicatedResourcesPtrOutput {
	return o
}

func (o AiDeploymentResourcePoolDedicatedResourcesPtrOutput) ToAiDeploymentResourcePoolDedicatedResourcesPtrOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesPtrOutput {
	return o
}

func (o AiDeploymentResourcePoolDedicatedResourcesPtrOutput) Elem() AiDeploymentResourcePoolDedicatedResourcesOutput {
	return o.ApplyT(func(v *AiDeploymentResourcePoolDedicatedResources) AiDeploymentResourcePoolDedicatedResources {
		if v != nil {
			return *v
		}
		var ret AiDeploymentResourcePoolDedicatedResources
		return ret
	}).(AiDeploymentResourcePoolDedicatedResourcesOutput)
}

// A list of the metric specifications that overrides a resource utilization metric.
// Structure is documented below.
func (o AiDeploymentResourcePoolDedicatedResourcesPtrOutput) AutoscalingMetricSpecs() AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput {
	return o.ApplyT(func(v *AiDeploymentResourcePoolDedicatedResources) []AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpec {
		if v == nil {
			return nil
		}
		return v.AutoscalingMetricSpecs
	}).(AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput)
}

// The specification of a single machine used by the prediction
// Structure is documented below.
func (o AiDeploymentResourcePoolDedicatedResourcesPtrOutput) MachineSpec() AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput {
	return o.ApplyT(func(v *AiDeploymentResourcePoolDedicatedResources) *AiDeploymentResourcePoolDedicatedResourcesMachineSpec {
		if v == nil {
			return nil
		}
		return &v.MachineSpec
	}).(AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput)
}

// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use minReplicaCount as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for maxReplicaCount * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
func (o AiDeploymentResourcePoolDedicatedResourcesPtrOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiDeploymentResourcePoolDedicatedResources) *int {
		if v == nil {
			return nil
		}
		return v.MaxReplicaCount
	}).(pulumi.IntPtrOutput)
}

// The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
func (o AiDeploymentResourcePoolDedicatedResourcesPtrOutput) MinReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiDeploymentResourcePoolDedicatedResources) *int {
		if v == nil {
			return nil
		}
		return &v.MinReplicaCount
	}).(pulumi.IntPtrOutput)
}

type AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpec struct {
	// The resource metric name. Supported metrics: For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName string `pulumi:"metricName"`
	// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
	Target *int `pulumi:"target"`
}

// AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecInput is an input type that accepts AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArgs and AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput values.
// You can construct a concrete instance of `AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecInput` via:
//
//	AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArgs{...}
type AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecInput interface {
	pulumi.Input

	ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput() AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput
	ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutputWithContext(context.Context) AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput
}

type AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArgs struct {
	// The resource metric name. Supported metrics: For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName pulumi.StringInput `pulumi:"metricName"`
	// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
	Target pulumi.IntPtrInput `pulumi:"target"`
}

func (AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpec)(nil)).Elem()
}

func (i AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArgs) ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput() AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput {
	return i.ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutputWithContext(context.Background())
}

func (i AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArgs) ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput)
}

// AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayInput is an input type that accepts AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArray and AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput values.
// You can construct a concrete instance of `AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayInput` via:
//
//	AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArray{ AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArgs{...} }
type AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayInput interface {
	pulumi.Input

	ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput() AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput
	ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutputWithContext(context.Context) AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput
}

type AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArray []AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecInput

func (AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpec)(nil)).Elem()
}

func (i AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArray) ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput() AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput {
	return i.ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutputWithContext(context.Background())
}

func (i AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArray) ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput)
}

type AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput struct{ *pulumi.OutputState }

func (AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpec)(nil)).Elem()
}

func (o AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput) ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput() AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput {
	return o
}

func (o AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput) ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput {
	return o
}

// The resource metric name. Supported metrics: For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
func (o AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput) MetricName() pulumi.StringOutput {
	return o.ApplyT(func(v AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpec) string { return v.MetricName }).(pulumi.StringOutput)
}

// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
func (o AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput) Target() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpec) *int { return v.Target }).(pulumi.IntPtrOutput)
}

type AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput struct{ *pulumi.OutputState }

func (AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpec)(nil)).Elem()
}

func (o AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput) ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput() AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput {
	return o
}

func (o AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput) ToAiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput {
	return o
}

func (o AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput) Index(i pulumi.IntInput) AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpec {
		return vs[0].([]AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpec)[vs[1].(int)]
	}).(AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput)
}

type AiDeploymentResourcePoolDedicatedResourcesMachineSpec struct {
	// The number of accelerators to attach to the machine.
	AcceleratorCount *int `pulumi:"acceleratorCount"`
	// The type of accelerator(s) that may be attached to the machine as per accelerator_count. See possible values [here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType).
	AcceleratorType *string `pulumi:"acceleratorType"`
	// The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types).
	MachineType *string `pulumi:"machineType"`
}

// AiDeploymentResourcePoolDedicatedResourcesMachineSpecInput is an input type that accepts AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs and AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput values.
// You can construct a concrete instance of `AiDeploymentResourcePoolDedicatedResourcesMachineSpecInput` via:
//
//	AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs{...}
type AiDeploymentResourcePoolDedicatedResourcesMachineSpecInput interface {
	pulumi.Input

	ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput() AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput
	ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecOutputWithContext(context.Context) AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput
}

type AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs struct {
	// The number of accelerators to attach to the machine.
	AcceleratorCount pulumi.IntPtrInput `pulumi:"acceleratorCount"`
	// The type of accelerator(s) that may be attached to the machine as per accelerator_count. See possible values [here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType).
	AcceleratorType pulumi.StringPtrInput `pulumi:"acceleratorType"`
	// The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types).
	MachineType pulumi.StringPtrInput `pulumi:"machineType"`
}

func (AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiDeploymentResourcePoolDedicatedResourcesMachineSpec)(nil)).Elem()
}

func (i AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs) ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput() AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput {
	return i.ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecOutputWithContext(context.Background())
}

func (i AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs) ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput)
}

func (i AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs) ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput() AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput {
	return i.ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutputWithContext(context.Background())
}

func (i AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs) ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput).ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutputWithContext(ctx)
}

// AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrInput is an input type that accepts AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs, AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtr and AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput values.
// You can construct a concrete instance of `AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrInput` via:
//
//	        AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs{...}
//
//	or:
//
//	        nil
type AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrInput interface {
	pulumi.Input

	ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput() AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput
	ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutputWithContext(context.Context) AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput
}

type aiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrType AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs

func AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtr(v *AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs) AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrInput {
	return (*aiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrType)(v)
}

func (*aiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiDeploymentResourcePoolDedicatedResourcesMachineSpec)(nil)).Elem()
}

func (i *aiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrType) ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput() AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput {
	return i.ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutputWithContext(context.Background())
}

func (i *aiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrType) ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput)
}

type AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput struct{ *pulumi.OutputState }

func (AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiDeploymentResourcePoolDedicatedResourcesMachineSpec)(nil)).Elem()
}

func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput) ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput() AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput {
	return o
}

func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput) ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput {
	return o
}

func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput) ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput() AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput {
	return o.ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutputWithContext(context.Background())
}

func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput) ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiDeploymentResourcePoolDedicatedResourcesMachineSpec) *AiDeploymentResourcePoolDedicatedResourcesMachineSpec {
		return &v
	}).(AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput)
}

// The number of accelerators to attach to the machine.
func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput) AcceleratorCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiDeploymentResourcePoolDedicatedResourcesMachineSpec) *int { return v.AcceleratorCount }).(pulumi.IntPtrOutput)
}

// The type of accelerator(s) that may be attached to the machine as per accelerator_count. See possible values [here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType).
func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput) AcceleratorType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiDeploymentResourcePoolDedicatedResourcesMachineSpec) *string { return v.AcceleratorType }).(pulumi.StringPtrOutput)
}

// The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types).
func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiDeploymentResourcePoolDedicatedResourcesMachineSpec) *string { return v.MachineType }).(pulumi.StringPtrOutput)
}

type AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput struct{ *pulumi.OutputState }

func (AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiDeploymentResourcePoolDedicatedResourcesMachineSpec)(nil)).Elem()
}

func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput) ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput() AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput {
	return o
}

func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput) ToAiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutputWithContext(ctx context.Context) AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput {
	return o
}

func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput) Elem() AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput {
	return o.ApplyT(func(v *AiDeploymentResourcePoolDedicatedResourcesMachineSpec) AiDeploymentResourcePoolDedicatedResourcesMachineSpec {
		if v != nil {
			return *v
		}
		var ret AiDeploymentResourcePoolDedicatedResourcesMachineSpec
		return ret
	}).(AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput)
}

// The number of accelerators to attach to the machine.
func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput) AcceleratorCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiDeploymentResourcePoolDedicatedResourcesMachineSpec) *int {
		if v == nil {
			return nil
		}
		return v.AcceleratorCount
	}).(pulumi.IntPtrOutput)
}

// The type of accelerator(s) that may be attached to the machine as per accelerator_count. See possible values [here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType).
func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput) AcceleratorType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiDeploymentResourcePoolDedicatedResourcesMachineSpec) *string {
		if v == nil {
			return nil
		}
		return v.AcceleratorType
	}).(pulumi.StringPtrOutput)
}

// The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types).
func (o AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiDeploymentResourcePoolDedicatedResourcesMachineSpec) *string {
		if v == nil {
			return nil
		}
		return v.MachineType
	}).(pulumi.StringPtrOutput)
}

type AiEndpointDeployedModel struct {
	// (Output)
	// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.
	// Structure is documented below.
	AutomaticResources []AiEndpointDeployedModelAutomaticResource `pulumi:"automaticResources"`
	// (Output)
	// Output only. Timestamp when the DeployedModel was created.
	CreateTime *string `pulumi:"createTime"`
	// (Output)
	// A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
	// Structure is documented below.
	DedicatedResources []AiEndpointDeployedModelDedicatedResource `pulumi:"dedicatedResources"`
	// Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName *string `pulumi:"displayName"`
	// (Output)
	// These logs are like standard server access logs, containing information like timestamp and latency for each prediction request. Note that Stackdriver logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.
	EnableAccessLogging *bool `pulumi:"enableAccessLogging"`
	// (Output)
	// If true, the container of the DeployedModel instances will send `stderr` and `stdout` streams to Stackdriver Logging. Only supported for custom-trained Models and AutoML Tabular Models.
	EnableContainerLogging *bool `pulumi:"enableContainerLogging"`
	// (Output)
	// The ID of the DeployedModel. If not provided upon deployment, Vertex AI will generate a value for this ID. This value should be 1-10 characters, and valid characters are /[0-9]/.
	Id *string `pulumi:"id"`
	// (Output)
	// The name of the Model that this is the deployment of. Note that the Model may be in a different location than the DeployedModel's Endpoint.
	Model *string `pulumi:"model"`
	// (Output)
	// Output only. The version ID of the model that is deployed.
	ModelVersionId *string `pulumi:"modelVersionId"`
	// (Output)
	// Output only. Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
	// Structure is documented below.
	PrivateEndpoints []AiEndpointDeployedModelPrivateEndpoint `pulumi:"privateEndpoints"`
	// (Output)
	// The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project. Users deploying the Model must have the `iam.serviceAccounts.actAs` permission on this service account.
	ServiceAccount *string `pulumi:"serviceAccount"`
	// (Output)
	// The resource name of the shared DeploymentResourcePool to deploy on. Format: projects/{project}/locations/{location}/deploymentResourcePools/{deployment_resource_pool}
	SharedResources *string `pulumi:"sharedResources"`
}

// AiEndpointDeployedModelInput is an input type that accepts AiEndpointDeployedModelArgs and AiEndpointDeployedModelOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelInput` via:
//
//	AiEndpointDeployedModelArgs{...}
type AiEndpointDeployedModelInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelOutput() AiEndpointDeployedModelOutput
	ToAiEndpointDeployedModelOutputWithContext(context.Context) AiEndpointDeployedModelOutput
}

type AiEndpointDeployedModelArgs struct {
	// (Output)
	// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.
	// Structure is documented below.
	AutomaticResources AiEndpointDeployedModelAutomaticResourceArrayInput `pulumi:"automaticResources"`
	// (Output)
	// Output only. Timestamp when the DeployedModel was created.
	CreateTime pulumi.StringPtrInput `pulumi:"createTime"`
	// (Output)
	// A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
	// Structure is documented below.
	DedicatedResources AiEndpointDeployedModelDedicatedResourceArrayInput `pulumi:"dedicatedResources"`
	// Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
	DisplayName pulumi.StringPtrInput `pulumi:"displayName"`
	// (Output)
	// These logs are like standard server access logs, containing information like timestamp and latency for each prediction request. Note that Stackdriver logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.
	EnableAccessLogging pulumi.BoolPtrInput `pulumi:"enableAccessLogging"`
	// (Output)
	// If true, the container of the DeployedModel instances will send `stderr` and `stdout` streams to Stackdriver Logging. Only supported for custom-trained Models and AutoML Tabular Models.
	EnableContainerLogging pulumi.BoolPtrInput `pulumi:"enableContainerLogging"`
	// (Output)
	// The ID of the DeployedModel. If not provided upon deployment, Vertex AI will generate a value for this ID. This value should be 1-10 characters, and valid characters are /[0-9]/.
	Id pulumi.StringPtrInput `pulumi:"id"`
	// (Output)
	// The name of the Model that this is the deployment of. Note that the Model may be in a different location than the DeployedModel's Endpoint.
	Model pulumi.StringPtrInput `pulumi:"model"`
	// (Output)
	// Output only. The version ID of the model that is deployed.
	ModelVersionId pulumi.StringPtrInput `pulumi:"modelVersionId"`
	// (Output)
	// Output only. Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
	// Structure is documented below.
	PrivateEndpoints AiEndpointDeployedModelPrivateEndpointArrayInput `pulumi:"privateEndpoints"`
	// (Output)
	// The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project. Users deploying the Model must have the `iam.serviceAccounts.actAs` permission on this service account.
	ServiceAccount pulumi.StringPtrInput `pulumi:"serviceAccount"`
	// (Output)
	// The resource name of the shared DeploymentResourcePool to deploy on. Format: projects/{project}/locations/{location}/deploymentResourcePools/{deployment_resource_pool}
	SharedResources pulumi.StringPtrInput `pulumi:"sharedResources"`
}

func (AiEndpointDeployedModelArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModel)(nil)).Elem()
}

func (i AiEndpointDeployedModelArgs) ToAiEndpointDeployedModelOutput() AiEndpointDeployedModelOutput {
	return i.ToAiEndpointDeployedModelOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelArgs) ToAiEndpointDeployedModelOutputWithContext(ctx context.Context) AiEndpointDeployedModelOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelOutput)
}

// AiEndpointDeployedModelArrayInput is an input type that accepts AiEndpointDeployedModelArray and AiEndpointDeployedModelArrayOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelArrayInput` via:
//
//	AiEndpointDeployedModelArray{ AiEndpointDeployedModelArgs{...} }
type AiEndpointDeployedModelArrayInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelArrayOutput() AiEndpointDeployedModelArrayOutput
	ToAiEndpointDeployedModelArrayOutputWithContext(context.Context) AiEndpointDeployedModelArrayOutput
}

type AiEndpointDeployedModelArray []AiEndpointDeployedModelInput

func (AiEndpointDeployedModelArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModel)(nil)).Elem()
}

func (i AiEndpointDeployedModelArray) ToAiEndpointDeployedModelArrayOutput() AiEndpointDeployedModelArrayOutput {
	return i.ToAiEndpointDeployedModelArrayOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelArray) ToAiEndpointDeployedModelArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelArrayOutput)
}

type AiEndpointDeployedModelOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModel)(nil)).Elem()
}

func (o AiEndpointDeployedModelOutput) ToAiEndpointDeployedModelOutput() AiEndpointDeployedModelOutput {
	return o
}

func (o AiEndpointDeployedModelOutput) ToAiEndpointDeployedModelOutputWithContext(ctx context.Context) AiEndpointDeployedModelOutput {
	return o
}

// (Output)
// A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.
// Structure is documented below.
func (o AiEndpointDeployedModelOutput) AutomaticResources() AiEndpointDeployedModelAutomaticResourceArrayOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) []AiEndpointDeployedModelAutomaticResource {
		return v.AutomaticResources
	}).(AiEndpointDeployedModelAutomaticResourceArrayOutput)
}

// (Output)
// Output only. Timestamp when the DeployedModel was created.
func (o AiEndpointDeployedModelOutput) CreateTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.CreateTime }).(pulumi.StringPtrOutput)
}

// (Output)
// A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
// Structure is documented below.
func (o AiEndpointDeployedModelOutput) DedicatedResources() AiEndpointDeployedModelDedicatedResourceArrayOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) []AiEndpointDeployedModelDedicatedResource {
		return v.DedicatedResources
	}).(AiEndpointDeployedModelDedicatedResourceArrayOutput)
}

// Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
func (o AiEndpointDeployedModelOutput) DisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.DisplayName }).(pulumi.StringPtrOutput)
}

// (Output)
// These logs are like standard server access logs, containing information like timestamp and latency for each prediction request. Note that Stackdriver logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.
func (o AiEndpointDeployedModelOutput) EnableAccessLogging() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *bool { return v.EnableAccessLogging }).(pulumi.BoolPtrOutput)
}

// (Output)
// If true, the container of the DeployedModel instances will send `stderr` and `stdout` streams to Stackdriver Logging. Only supported for custom-trained Models and AutoML Tabular Models.
func (o AiEndpointDeployedModelOutput) EnableContainerLogging() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *bool { return v.EnableContainerLogging }).(pulumi.BoolPtrOutput)
}

// (Output)
// The ID of the DeployedModel. If not provided upon deployment, Vertex AI will generate a value for this ID. This value should be 1-10 characters, and valid characters are /[0-9]/.
func (o AiEndpointDeployedModelOutput) Id() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.Id }).(pulumi.StringPtrOutput)
}

// (Output)
// The name of the Model that this is the deployment of. Note that the Model may be in a different location than the DeployedModel's Endpoint.
func (o AiEndpointDeployedModelOutput) Model() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.Model }).(pulumi.StringPtrOutput)
}

// (Output)
// Output only. The version ID of the model that is deployed.
func (o AiEndpointDeployedModelOutput) ModelVersionId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.ModelVersionId }).(pulumi.StringPtrOutput)
}

// (Output)
// Output only. Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
// Structure is documented below.
func (o AiEndpointDeployedModelOutput) PrivateEndpoints() AiEndpointDeployedModelPrivateEndpointArrayOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) []AiEndpointDeployedModelPrivateEndpoint { return v.PrivateEndpoints }).(AiEndpointDeployedModelPrivateEndpointArrayOutput)
}

// (Output)
// The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project. Users deploying the Model must have the `iam.serviceAccounts.actAs` permission on this service account.
func (o AiEndpointDeployedModelOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.ServiceAccount }).(pulumi.StringPtrOutput)
}

// (Output)
// The resource name of the shared DeploymentResourcePool to deploy on. Format: projects/{project}/locations/{location}/deploymentResourcePools/{deployment_resource_pool}
func (o AiEndpointDeployedModelOutput) SharedResources() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModel) *string { return v.SharedResources }).(pulumi.StringPtrOutput)
}

type AiEndpointDeployedModelArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModel)(nil)).Elem()
}

func (o AiEndpointDeployedModelArrayOutput) ToAiEndpointDeployedModelArrayOutput() AiEndpointDeployedModelArrayOutput {
	return o
}

func (o AiEndpointDeployedModelArrayOutput) ToAiEndpointDeployedModelArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelArrayOutput {
	return o
}

func (o AiEndpointDeployedModelArrayOutput) Index(i pulumi.IntInput) AiEndpointDeployedModelOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointDeployedModel {
		return vs[0].([]AiEndpointDeployedModel)[vs[1].(int)]
	}).(AiEndpointDeployedModelOutput)
}

type AiEndpointDeployedModelAutomaticResource struct {
	// (Output)
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
	MaxReplicaCount *int `pulumi:"maxReplicaCount"`
	// (Output)
	// The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
	MinReplicaCount *int `pulumi:"minReplicaCount"`
}

// AiEndpointDeployedModelAutomaticResourceInput is an input type that accepts AiEndpointDeployedModelAutomaticResourceArgs and AiEndpointDeployedModelAutomaticResourceOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelAutomaticResourceInput` via:
//
//	AiEndpointDeployedModelAutomaticResourceArgs{...}
type AiEndpointDeployedModelAutomaticResourceInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelAutomaticResourceOutput() AiEndpointDeployedModelAutomaticResourceOutput
	ToAiEndpointDeployedModelAutomaticResourceOutputWithContext(context.Context) AiEndpointDeployedModelAutomaticResourceOutput
}

type AiEndpointDeployedModelAutomaticResourceArgs struct {
	// (Output)
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
	MaxReplicaCount pulumi.IntPtrInput `pulumi:"maxReplicaCount"`
	// (Output)
	// The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
	MinReplicaCount pulumi.IntPtrInput `pulumi:"minReplicaCount"`
}

func (AiEndpointDeployedModelAutomaticResourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelAutomaticResource)(nil)).Elem()
}

func (i AiEndpointDeployedModelAutomaticResourceArgs) ToAiEndpointDeployedModelAutomaticResourceOutput() AiEndpointDeployedModelAutomaticResourceOutput {
	return i.ToAiEndpointDeployedModelAutomaticResourceOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelAutomaticResourceArgs) ToAiEndpointDeployedModelAutomaticResourceOutputWithContext(ctx context.Context) AiEndpointDeployedModelAutomaticResourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelAutomaticResourceOutput)
}

// AiEndpointDeployedModelAutomaticResourceArrayInput is an input type that accepts AiEndpointDeployedModelAutomaticResourceArray and AiEndpointDeployedModelAutomaticResourceArrayOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelAutomaticResourceArrayInput` via:
//
//	AiEndpointDeployedModelAutomaticResourceArray{ AiEndpointDeployedModelAutomaticResourceArgs{...} }
type AiEndpointDeployedModelAutomaticResourceArrayInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelAutomaticResourceArrayOutput() AiEndpointDeployedModelAutomaticResourceArrayOutput
	ToAiEndpointDeployedModelAutomaticResourceArrayOutputWithContext(context.Context) AiEndpointDeployedModelAutomaticResourceArrayOutput
}

type AiEndpointDeployedModelAutomaticResourceArray []AiEndpointDeployedModelAutomaticResourceInput

func (AiEndpointDeployedModelAutomaticResourceArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelAutomaticResource)(nil)).Elem()
}

func (i AiEndpointDeployedModelAutomaticResourceArray) ToAiEndpointDeployedModelAutomaticResourceArrayOutput() AiEndpointDeployedModelAutomaticResourceArrayOutput {
	return i.ToAiEndpointDeployedModelAutomaticResourceArrayOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelAutomaticResourceArray) ToAiEndpointDeployedModelAutomaticResourceArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelAutomaticResourceArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelAutomaticResourceArrayOutput)
}

type AiEndpointDeployedModelAutomaticResourceOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelAutomaticResourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelAutomaticResource)(nil)).Elem()
}

func (o AiEndpointDeployedModelAutomaticResourceOutput) ToAiEndpointDeployedModelAutomaticResourceOutput() AiEndpointDeployedModelAutomaticResourceOutput {
	return o
}

func (o AiEndpointDeployedModelAutomaticResourceOutput) ToAiEndpointDeployedModelAutomaticResourceOutputWithContext(ctx context.Context) AiEndpointDeployedModelAutomaticResourceOutput {
	return o
}

// (Output)
// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
func (o AiEndpointDeployedModelAutomaticResourceOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelAutomaticResource) *int { return v.MaxReplicaCount }).(pulumi.IntPtrOutput)
}

// (Output)
// The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
func (o AiEndpointDeployedModelAutomaticResourceOutput) MinReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelAutomaticResource) *int { return v.MinReplicaCount }).(pulumi.IntPtrOutput)
}

type AiEndpointDeployedModelAutomaticResourceArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelAutomaticResourceArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelAutomaticResource)(nil)).Elem()
}

func (o AiEndpointDeployedModelAutomaticResourceArrayOutput) ToAiEndpointDeployedModelAutomaticResourceArrayOutput() AiEndpointDeployedModelAutomaticResourceArrayOutput {
	return o
}

func (o AiEndpointDeployedModelAutomaticResourceArrayOutput) ToAiEndpointDeployedModelAutomaticResourceArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelAutomaticResourceArrayOutput {
	return o
}

func (o AiEndpointDeployedModelAutomaticResourceArrayOutput) Index(i pulumi.IntInput) AiEndpointDeployedModelAutomaticResourceOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointDeployedModelAutomaticResource {
		return vs[0].([]AiEndpointDeployedModelAutomaticResource)[vs[1].(int)]
	}).(AiEndpointDeployedModelAutomaticResourceOutput)
}

type AiEndpointDeployedModelDedicatedResource struct {
	// (Output)
	// The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
	// Structure is documented below.
	AutoscalingMetricSpecs []AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec `pulumi:"autoscalingMetricSpecs"`
	// (Output)
	// The specification of a single machine used by the prediction.
	// Structure is documented below.
	MachineSpecs []AiEndpointDeployedModelDedicatedResourceMachineSpec `pulumi:"machineSpecs"`
	// (Output)
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
	MaxReplicaCount *int `pulumi:"maxReplicaCount"`
	// (Output)
	// The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
	MinReplicaCount *int `pulumi:"minReplicaCount"`
}

// AiEndpointDeployedModelDedicatedResourceInput is an input type that accepts AiEndpointDeployedModelDedicatedResourceArgs and AiEndpointDeployedModelDedicatedResourceOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelDedicatedResourceInput` via:
//
//	AiEndpointDeployedModelDedicatedResourceArgs{...}
type AiEndpointDeployedModelDedicatedResourceInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelDedicatedResourceOutput() AiEndpointDeployedModelDedicatedResourceOutput
	ToAiEndpointDeployedModelDedicatedResourceOutputWithContext(context.Context) AiEndpointDeployedModelDedicatedResourceOutput
}

type AiEndpointDeployedModelDedicatedResourceArgs struct {
	// (Output)
	// The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
	// Structure is documented below.
	AutoscalingMetricSpecs AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayInput `pulumi:"autoscalingMetricSpecs"`
	// (Output)
	// The specification of a single machine used by the prediction.
	// Structure is documented below.
	MachineSpecs AiEndpointDeployedModelDedicatedResourceMachineSpecArrayInput `pulumi:"machineSpecs"`
	// (Output)
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
	MaxReplicaCount pulumi.IntPtrInput `pulumi:"maxReplicaCount"`
	// (Output)
	// The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
	MinReplicaCount pulumi.IntPtrInput `pulumi:"minReplicaCount"`
}

func (AiEndpointDeployedModelDedicatedResourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelDedicatedResource)(nil)).Elem()
}

func (i AiEndpointDeployedModelDedicatedResourceArgs) ToAiEndpointDeployedModelDedicatedResourceOutput() AiEndpointDeployedModelDedicatedResourceOutput {
	return i.ToAiEndpointDeployedModelDedicatedResourceOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelDedicatedResourceArgs) ToAiEndpointDeployedModelDedicatedResourceOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelDedicatedResourceOutput)
}

// AiEndpointDeployedModelDedicatedResourceArrayInput is an input type that accepts AiEndpointDeployedModelDedicatedResourceArray and AiEndpointDeployedModelDedicatedResourceArrayOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelDedicatedResourceArrayInput` via:
//
//	AiEndpointDeployedModelDedicatedResourceArray{ AiEndpointDeployedModelDedicatedResourceArgs{...} }
type AiEndpointDeployedModelDedicatedResourceArrayInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelDedicatedResourceArrayOutput() AiEndpointDeployedModelDedicatedResourceArrayOutput
	ToAiEndpointDeployedModelDedicatedResourceArrayOutputWithContext(context.Context) AiEndpointDeployedModelDedicatedResourceArrayOutput
}

type AiEndpointDeployedModelDedicatedResourceArray []AiEndpointDeployedModelDedicatedResourceInput

func (AiEndpointDeployedModelDedicatedResourceArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelDedicatedResource)(nil)).Elem()
}

func (i AiEndpointDeployedModelDedicatedResourceArray) ToAiEndpointDeployedModelDedicatedResourceArrayOutput() AiEndpointDeployedModelDedicatedResourceArrayOutput {
	return i.ToAiEndpointDeployedModelDedicatedResourceArrayOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelDedicatedResourceArray) ToAiEndpointDeployedModelDedicatedResourceArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelDedicatedResourceArrayOutput)
}

type AiEndpointDeployedModelDedicatedResourceOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelDedicatedResourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelDedicatedResource)(nil)).Elem()
}

func (o AiEndpointDeployedModelDedicatedResourceOutput) ToAiEndpointDeployedModelDedicatedResourceOutput() AiEndpointDeployedModelDedicatedResourceOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceOutput) ToAiEndpointDeployedModelDedicatedResourceOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceOutput {
	return o
}

// (Output)
// The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
// Structure is documented below.
func (o AiEndpointDeployedModelDedicatedResourceOutput) AutoscalingMetricSpecs() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResource) []AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec {
		return v.AutoscalingMetricSpecs
	}).(AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput)
}

// (Output)
// The specification of a single machine used by the prediction.
// Structure is documented below.
func (o AiEndpointDeployedModelDedicatedResourceOutput) MachineSpecs() AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResource) []AiEndpointDeployedModelDedicatedResourceMachineSpec {
		return v.MachineSpecs
	}).(AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput)
}

// (Output)
// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
func (o AiEndpointDeployedModelDedicatedResourceOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResource) *int { return v.MaxReplicaCount }).(pulumi.IntPtrOutput)
}

// (Output)
// The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
func (o AiEndpointDeployedModelDedicatedResourceOutput) MinReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResource) *int { return v.MinReplicaCount }).(pulumi.IntPtrOutput)
}

type AiEndpointDeployedModelDedicatedResourceArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelDedicatedResourceArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelDedicatedResource)(nil)).Elem()
}

func (o AiEndpointDeployedModelDedicatedResourceArrayOutput) ToAiEndpointDeployedModelDedicatedResourceArrayOutput() AiEndpointDeployedModelDedicatedResourceArrayOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceArrayOutput) ToAiEndpointDeployedModelDedicatedResourceArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceArrayOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceArrayOutput) Index(i pulumi.IntInput) AiEndpointDeployedModelDedicatedResourceOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointDeployedModelDedicatedResource {
		return vs[0].([]AiEndpointDeployedModelDedicatedResource)[vs[1].(int)]
	}).(AiEndpointDeployedModelDedicatedResourceOutput)
}

type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec struct {
	// (Output)
	// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName *string `pulumi:"metricName"`
	// (Output)
	// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
	Target *int `pulumi:"target"`
}

// AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecInput is an input type that accepts AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs and AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecInput` via:
//
//	AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs{...}
type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput
	ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutputWithContext(context.Context) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput
}

type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs struct {
	// (Output)
	// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName pulumi.StringPtrInput `pulumi:"metricName"`
	// (Output)
	// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
	Target pulumi.IntPtrInput `pulumi:"target"`
}

func (AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec)(nil)).Elem()
}

func (i AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput {
	return i.ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput)
}

// AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayInput is an input type that accepts AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray and AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayInput` via:
//
//	AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray{ AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs{...} }
type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput
	ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutputWithContext(context.Context) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput
}

type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray []AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecInput

func (AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec)(nil)).Elem()
}

func (i AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput {
	return i.ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput)
}

type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec)(nil)).Elem()
}

func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput {
	return o
}

// (Output)
// The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput) MetricName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec) *string { return v.MetricName }).(pulumi.StringPtrOutput)
}

// (Output)
// The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput) Target() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec) *int { return v.Target }).(pulumi.IntPtrOutput)
}

type AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec)(nil)).Elem()
}

func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput() AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput) ToAiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput) Index(i pulumi.IntInput) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec {
		return vs[0].([]AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpec)[vs[1].(int)]
	}).(AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput)
}

type AiEndpointDeployedModelDedicatedResourceMachineSpec struct {
	// (Output)
	// The number of accelerators to attach to the machine.
	AcceleratorCount *int `pulumi:"acceleratorCount"`
	// (Output)
	// The type of accelerator(s) that may be attached to the machine as per accelerator_count. See possible values [here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType).
	AcceleratorType *string `pulumi:"acceleratorType"`
	// (Output)
	// The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required. TODO: Try to better unify the required vs optional.
	MachineType *string `pulumi:"machineType"`
}

// AiEndpointDeployedModelDedicatedResourceMachineSpecInput is an input type that accepts AiEndpointDeployedModelDedicatedResourceMachineSpecArgs and AiEndpointDeployedModelDedicatedResourceMachineSpecOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelDedicatedResourceMachineSpecInput` via:
//
//	AiEndpointDeployedModelDedicatedResourceMachineSpecArgs{...}
type AiEndpointDeployedModelDedicatedResourceMachineSpecInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutput() AiEndpointDeployedModelDedicatedResourceMachineSpecOutput
	ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutputWithContext(context.Context) AiEndpointDeployedModelDedicatedResourceMachineSpecOutput
}

type AiEndpointDeployedModelDedicatedResourceMachineSpecArgs struct {
	// (Output)
	// The number of accelerators to attach to the machine.
	AcceleratorCount pulumi.IntPtrInput `pulumi:"acceleratorCount"`
	// (Output)
	// The type of accelerator(s) that may be attached to the machine as per accelerator_count. See possible values [here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType).
	AcceleratorType pulumi.StringPtrInput `pulumi:"acceleratorType"`
	// (Output)
	// The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required. TODO: Try to better unify the required vs optional.
	MachineType pulumi.StringPtrInput `pulumi:"machineType"`
}

func (AiEndpointDeployedModelDedicatedResourceMachineSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceMachineSpec)(nil)).Elem()
}

func (i AiEndpointDeployedModelDedicatedResourceMachineSpecArgs) ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutput() AiEndpointDeployedModelDedicatedResourceMachineSpecOutput {
	return i.ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelDedicatedResourceMachineSpecArgs) ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceMachineSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelDedicatedResourceMachineSpecOutput)
}

// AiEndpointDeployedModelDedicatedResourceMachineSpecArrayInput is an input type that accepts AiEndpointDeployedModelDedicatedResourceMachineSpecArray and AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelDedicatedResourceMachineSpecArrayInput` via:
//
//	AiEndpointDeployedModelDedicatedResourceMachineSpecArray{ AiEndpointDeployedModelDedicatedResourceMachineSpecArgs{...} }
type AiEndpointDeployedModelDedicatedResourceMachineSpecArrayInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput() AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput
	ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutputWithContext(context.Context) AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput
}

type AiEndpointDeployedModelDedicatedResourceMachineSpecArray []AiEndpointDeployedModelDedicatedResourceMachineSpecInput

func (AiEndpointDeployedModelDedicatedResourceMachineSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelDedicatedResourceMachineSpec)(nil)).Elem()
}

func (i AiEndpointDeployedModelDedicatedResourceMachineSpecArray) ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput() AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput {
	return i.ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelDedicatedResourceMachineSpecArray) ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput)
}

type AiEndpointDeployedModelDedicatedResourceMachineSpecOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelDedicatedResourceMachineSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceMachineSpec)(nil)).Elem()
}

func (o AiEndpointDeployedModelDedicatedResourceMachineSpecOutput) ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutput() AiEndpointDeployedModelDedicatedResourceMachineSpecOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceMachineSpecOutput) ToAiEndpointDeployedModelDedicatedResourceMachineSpecOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceMachineSpecOutput {
	return o
}

// (Output)
// The number of accelerators to attach to the machine.
func (o AiEndpointDeployedModelDedicatedResourceMachineSpecOutput) AcceleratorCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResourceMachineSpec) *int { return v.AcceleratorCount }).(pulumi.IntPtrOutput)
}

// (Output)
// The type of accelerator(s) that may be attached to the machine as per accelerator_count. See possible values [here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType).
func (o AiEndpointDeployedModelDedicatedResourceMachineSpecOutput) AcceleratorType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResourceMachineSpec) *string { return v.AcceleratorType }).(pulumi.StringPtrOutput)
}

// (Output)
// The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required. TODO: Try to better unify the required vs optional.
func (o AiEndpointDeployedModelDedicatedResourceMachineSpecOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelDedicatedResourceMachineSpec) *string { return v.MachineType }).(pulumi.StringPtrOutput)
}

type AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelDedicatedResourceMachineSpec)(nil)).Elem()
}

func (o AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput) ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput() AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput) ToAiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput {
	return o
}

func (o AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput) Index(i pulumi.IntInput) AiEndpointDeployedModelDedicatedResourceMachineSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointDeployedModelDedicatedResourceMachineSpec {
		return vs[0].([]AiEndpointDeployedModelDedicatedResourceMachineSpec)[vs[1].(int)]
	}).(AiEndpointDeployedModelDedicatedResourceMachineSpecOutput)
}

type AiEndpointDeployedModelPrivateEndpoint struct {
	// (Output)
	// Output only. Http(s) path to send explain requests.
	ExplainHttpUri *string `pulumi:"explainHttpUri"`
	// (Output)
	// Output only. Http(s) path to send health check requests.
	HealthHttpUri *string `pulumi:"healthHttpUri"`
	// (Output)
	// Output only. Http(s) path to send prediction requests.
	PredictHttpUri *string `pulumi:"predictHttpUri"`
	// (Output)
	// Output only. The name of the service attachment resource. Populated if private service connect is enabled.
	ServiceAttachment *string `pulumi:"serviceAttachment"`
}

// AiEndpointDeployedModelPrivateEndpointInput is an input type that accepts AiEndpointDeployedModelPrivateEndpointArgs and AiEndpointDeployedModelPrivateEndpointOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelPrivateEndpointInput` via:
//
//	AiEndpointDeployedModelPrivateEndpointArgs{...}
type AiEndpointDeployedModelPrivateEndpointInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelPrivateEndpointOutput() AiEndpointDeployedModelPrivateEndpointOutput
	ToAiEndpointDeployedModelPrivateEndpointOutputWithContext(context.Context) AiEndpointDeployedModelPrivateEndpointOutput
}

type AiEndpointDeployedModelPrivateEndpointArgs struct {
	// (Output)
	// Output only. Http(s) path to send explain requests.
	ExplainHttpUri pulumi.StringPtrInput `pulumi:"explainHttpUri"`
	// (Output)
	// Output only. Http(s) path to send health check requests.
	HealthHttpUri pulumi.StringPtrInput `pulumi:"healthHttpUri"`
	// (Output)
	// Output only. Http(s) path to send prediction requests.
	PredictHttpUri pulumi.StringPtrInput `pulumi:"predictHttpUri"`
	// (Output)
	// Output only. The name of the service attachment resource. Populated if private service connect is enabled.
	ServiceAttachment pulumi.StringPtrInput `pulumi:"serviceAttachment"`
}

func (AiEndpointDeployedModelPrivateEndpointArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelPrivateEndpoint)(nil)).Elem()
}

func (i AiEndpointDeployedModelPrivateEndpointArgs) ToAiEndpointDeployedModelPrivateEndpointOutput() AiEndpointDeployedModelPrivateEndpointOutput {
	return i.ToAiEndpointDeployedModelPrivateEndpointOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelPrivateEndpointArgs) ToAiEndpointDeployedModelPrivateEndpointOutputWithContext(ctx context.Context) AiEndpointDeployedModelPrivateEndpointOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelPrivateEndpointOutput)
}

// AiEndpointDeployedModelPrivateEndpointArrayInput is an input type that accepts AiEndpointDeployedModelPrivateEndpointArray and AiEndpointDeployedModelPrivateEndpointArrayOutput values.
// You can construct a concrete instance of `AiEndpointDeployedModelPrivateEndpointArrayInput` via:
//
//	AiEndpointDeployedModelPrivateEndpointArray{ AiEndpointDeployedModelPrivateEndpointArgs{...} }
type AiEndpointDeployedModelPrivateEndpointArrayInput interface {
	pulumi.Input

	ToAiEndpointDeployedModelPrivateEndpointArrayOutput() AiEndpointDeployedModelPrivateEndpointArrayOutput
	ToAiEndpointDeployedModelPrivateEndpointArrayOutputWithContext(context.Context) AiEndpointDeployedModelPrivateEndpointArrayOutput
}

type AiEndpointDeployedModelPrivateEndpointArray []AiEndpointDeployedModelPrivateEndpointInput

func (AiEndpointDeployedModelPrivateEndpointArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelPrivateEndpoint)(nil)).Elem()
}

func (i AiEndpointDeployedModelPrivateEndpointArray) ToAiEndpointDeployedModelPrivateEndpointArrayOutput() AiEndpointDeployedModelPrivateEndpointArrayOutput {
	return i.ToAiEndpointDeployedModelPrivateEndpointArrayOutputWithContext(context.Background())
}

func (i AiEndpointDeployedModelPrivateEndpointArray) ToAiEndpointDeployedModelPrivateEndpointArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelPrivateEndpointArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointDeployedModelPrivateEndpointArrayOutput)
}

type AiEndpointDeployedModelPrivateEndpointOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelPrivateEndpointOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointDeployedModelPrivateEndpoint)(nil)).Elem()
}

func (o AiEndpointDeployedModelPrivateEndpointOutput) ToAiEndpointDeployedModelPrivateEndpointOutput() AiEndpointDeployedModelPrivateEndpointOutput {
	return o
}

func (o AiEndpointDeployedModelPrivateEndpointOutput) ToAiEndpointDeployedModelPrivateEndpointOutputWithContext(ctx context.Context) AiEndpointDeployedModelPrivateEndpointOutput {
	return o
}

// (Output)
// Output only. Http(s) path to send explain requests.
func (o AiEndpointDeployedModelPrivateEndpointOutput) ExplainHttpUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelPrivateEndpoint) *string { return v.ExplainHttpUri }).(pulumi.StringPtrOutput)
}

// (Output)
// Output only. Http(s) path to send health check requests.
func (o AiEndpointDeployedModelPrivateEndpointOutput) HealthHttpUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelPrivateEndpoint) *string { return v.HealthHttpUri }).(pulumi.StringPtrOutput)
}

// (Output)
// Output only. Http(s) path to send prediction requests.
func (o AiEndpointDeployedModelPrivateEndpointOutput) PredictHttpUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelPrivateEndpoint) *string { return v.PredictHttpUri }).(pulumi.StringPtrOutput)
}

// (Output)
// Output only. The name of the service attachment resource. Populated if private service connect is enabled.
func (o AiEndpointDeployedModelPrivateEndpointOutput) ServiceAttachment() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointDeployedModelPrivateEndpoint) *string { return v.ServiceAttachment }).(pulumi.StringPtrOutput)
}

type AiEndpointDeployedModelPrivateEndpointArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointDeployedModelPrivateEndpointArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointDeployedModelPrivateEndpoint)(nil)).Elem()
}

func (o AiEndpointDeployedModelPrivateEndpointArrayOutput) ToAiEndpointDeployedModelPrivateEndpointArrayOutput() AiEndpointDeployedModelPrivateEndpointArrayOutput {
	return o
}

func (o AiEndpointDeployedModelPrivateEndpointArrayOutput) ToAiEndpointDeployedModelPrivateEndpointArrayOutputWithContext(ctx context.Context) AiEndpointDeployedModelPrivateEndpointArrayOutput {
	return o
}

func (o AiEndpointDeployedModelPrivateEndpointArrayOutput) Index(i pulumi.IntInput) AiEndpointDeployedModelPrivateEndpointOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointDeployedModelPrivateEndpoint {
		return vs[0].([]AiEndpointDeployedModelPrivateEndpoint)[vs[1].(int)]
	}).(AiEndpointDeployedModelPrivateEndpointOutput)
}

type AiEndpointEncryptionSpec struct {
	// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// AiEndpointEncryptionSpecInput is an input type that accepts AiEndpointEncryptionSpecArgs and AiEndpointEncryptionSpecOutput values.
// You can construct a concrete instance of `AiEndpointEncryptionSpecInput` via:
//
//	AiEndpointEncryptionSpecArgs{...}
type AiEndpointEncryptionSpecInput interface {
	pulumi.Input

	ToAiEndpointEncryptionSpecOutput() AiEndpointEncryptionSpecOutput
	ToAiEndpointEncryptionSpecOutputWithContext(context.Context) AiEndpointEncryptionSpecOutput
}

type AiEndpointEncryptionSpecArgs struct {
	// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (AiEndpointEncryptionSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointEncryptionSpec)(nil)).Elem()
}

func (i AiEndpointEncryptionSpecArgs) ToAiEndpointEncryptionSpecOutput() AiEndpointEncryptionSpecOutput {
	return i.ToAiEndpointEncryptionSpecOutputWithContext(context.Background())
}

func (i AiEndpointEncryptionSpecArgs) ToAiEndpointEncryptionSpecOutputWithContext(ctx context.Context) AiEndpointEncryptionSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointEncryptionSpecOutput)
}

func (i AiEndpointEncryptionSpecArgs) ToAiEndpointEncryptionSpecPtrOutput() AiEndpointEncryptionSpecPtrOutput {
	return i.ToAiEndpointEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i AiEndpointEncryptionSpecArgs) ToAiEndpointEncryptionSpecPtrOutputWithContext(ctx context.Context) AiEndpointEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointEncryptionSpecOutput).ToAiEndpointEncryptionSpecPtrOutputWithContext(ctx)
}

// AiEndpointEncryptionSpecPtrInput is an input type that accepts AiEndpointEncryptionSpecArgs, AiEndpointEncryptionSpecPtr and AiEndpointEncryptionSpecPtrOutput values.
// You can construct a concrete instance of `AiEndpointEncryptionSpecPtrInput` via:
//
//	        AiEndpointEncryptionSpecArgs{...}
//
//	or:
//
//	        nil
type AiEndpointEncryptionSpecPtrInput interface {
	pulumi.Input

	ToAiEndpointEncryptionSpecPtrOutput() AiEndpointEncryptionSpecPtrOutput
	ToAiEndpointEncryptionSpecPtrOutputWithContext(context.Context) AiEndpointEncryptionSpecPtrOutput
}

type aiEndpointEncryptionSpecPtrType AiEndpointEncryptionSpecArgs

func AiEndpointEncryptionSpecPtr(v *AiEndpointEncryptionSpecArgs) AiEndpointEncryptionSpecPtrInput {
	return (*aiEndpointEncryptionSpecPtrType)(v)
}

func (*aiEndpointEncryptionSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointEncryptionSpec)(nil)).Elem()
}

func (i *aiEndpointEncryptionSpecPtrType) ToAiEndpointEncryptionSpecPtrOutput() AiEndpointEncryptionSpecPtrOutput {
	return i.ToAiEndpointEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i *aiEndpointEncryptionSpecPtrType) ToAiEndpointEncryptionSpecPtrOutputWithContext(ctx context.Context) AiEndpointEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointEncryptionSpecPtrOutput)
}

type AiEndpointEncryptionSpecOutput struct{ *pulumi.OutputState }

func (AiEndpointEncryptionSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointEncryptionSpec)(nil)).Elem()
}

func (o AiEndpointEncryptionSpecOutput) ToAiEndpointEncryptionSpecOutput() AiEndpointEncryptionSpecOutput {
	return o
}

func (o AiEndpointEncryptionSpecOutput) ToAiEndpointEncryptionSpecOutputWithContext(ctx context.Context) AiEndpointEncryptionSpecOutput {
	return o
}

func (o AiEndpointEncryptionSpecOutput) ToAiEndpointEncryptionSpecPtrOutput() AiEndpointEncryptionSpecPtrOutput {
	return o.ToAiEndpointEncryptionSpecPtrOutputWithContext(context.Background())
}

func (o AiEndpointEncryptionSpecOutput) ToAiEndpointEncryptionSpecPtrOutputWithContext(ctx context.Context) AiEndpointEncryptionSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointEncryptionSpec) *AiEndpointEncryptionSpec {
		return &v
	}).(AiEndpointEncryptionSpecPtrOutput)
}

// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
func (o AiEndpointEncryptionSpecOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v AiEndpointEncryptionSpec) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type AiEndpointEncryptionSpecPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointEncryptionSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointEncryptionSpec)(nil)).Elem()
}

func (o AiEndpointEncryptionSpecPtrOutput) ToAiEndpointEncryptionSpecPtrOutput() AiEndpointEncryptionSpecPtrOutput {
	return o
}

func (o AiEndpointEncryptionSpecPtrOutput) ToAiEndpointEncryptionSpecPtrOutputWithContext(ctx context.Context) AiEndpointEncryptionSpecPtrOutput {
	return o
}

func (o AiEndpointEncryptionSpecPtrOutput) Elem() AiEndpointEncryptionSpecOutput {
	return o.ApplyT(func(v *AiEndpointEncryptionSpec) AiEndpointEncryptionSpec {
		if v != nil {
			return *v
		}
		var ret AiEndpointEncryptionSpec
		return ret
	}).(AiEndpointEncryptionSpecOutput)
}

// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.
func (o AiEndpointEncryptionSpecPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointEncryptionSpec) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type AiEndpointIamBindingCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiEndpointIamBindingConditionInput is an input type that accepts AiEndpointIamBindingConditionArgs and AiEndpointIamBindingConditionOutput values.
// You can construct a concrete instance of `AiEndpointIamBindingConditionInput` via:
//
//	AiEndpointIamBindingConditionArgs{...}
type AiEndpointIamBindingConditionInput interface {
	pulumi.Input

	ToAiEndpointIamBindingConditionOutput() AiEndpointIamBindingConditionOutput
	ToAiEndpointIamBindingConditionOutputWithContext(context.Context) AiEndpointIamBindingConditionOutput
}

type AiEndpointIamBindingConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiEndpointIamBindingConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointIamBindingCondition)(nil)).Elem()
}

func (i AiEndpointIamBindingConditionArgs) ToAiEndpointIamBindingConditionOutput() AiEndpointIamBindingConditionOutput {
	return i.ToAiEndpointIamBindingConditionOutputWithContext(context.Background())
}

func (i AiEndpointIamBindingConditionArgs) ToAiEndpointIamBindingConditionOutputWithContext(ctx context.Context) AiEndpointIamBindingConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointIamBindingConditionOutput)
}

func (i AiEndpointIamBindingConditionArgs) ToAiEndpointIamBindingConditionPtrOutput() AiEndpointIamBindingConditionPtrOutput {
	return i.ToAiEndpointIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i AiEndpointIamBindingConditionArgs) ToAiEndpointIamBindingConditionPtrOutputWithContext(ctx context.Context) AiEndpointIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointIamBindingConditionOutput).ToAiEndpointIamBindingConditionPtrOutputWithContext(ctx)
}

// AiEndpointIamBindingConditionPtrInput is an input type that accepts AiEndpointIamBindingConditionArgs, AiEndpointIamBindingConditionPtr and AiEndpointIamBindingConditionPtrOutput values.
// You can construct a concrete instance of `AiEndpointIamBindingConditionPtrInput` via:
//
//	        AiEndpointIamBindingConditionArgs{...}
//
//	or:
//
//	        nil
type AiEndpointIamBindingConditionPtrInput interface {
	pulumi.Input

	ToAiEndpointIamBindingConditionPtrOutput() AiEndpointIamBindingConditionPtrOutput
	ToAiEndpointIamBindingConditionPtrOutputWithContext(context.Context) AiEndpointIamBindingConditionPtrOutput
}

type aiEndpointIamBindingConditionPtrType AiEndpointIamBindingConditionArgs

func AiEndpointIamBindingConditionPtr(v *AiEndpointIamBindingConditionArgs) AiEndpointIamBindingConditionPtrInput {
	return (*aiEndpointIamBindingConditionPtrType)(v)
}

func (*aiEndpointIamBindingConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointIamBindingCondition)(nil)).Elem()
}

func (i *aiEndpointIamBindingConditionPtrType) ToAiEndpointIamBindingConditionPtrOutput() AiEndpointIamBindingConditionPtrOutput {
	return i.ToAiEndpointIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i *aiEndpointIamBindingConditionPtrType) ToAiEndpointIamBindingConditionPtrOutputWithContext(ctx context.Context) AiEndpointIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointIamBindingConditionPtrOutput)
}

type AiEndpointIamBindingConditionOutput struct{ *pulumi.OutputState }

func (AiEndpointIamBindingConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointIamBindingCondition)(nil)).Elem()
}

func (o AiEndpointIamBindingConditionOutput) ToAiEndpointIamBindingConditionOutput() AiEndpointIamBindingConditionOutput {
	return o
}

func (o AiEndpointIamBindingConditionOutput) ToAiEndpointIamBindingConditionOutputWithContext(ctx context.Context) AiEndpointIamBindingConditionOutput {
	return o
}

func (o AiEndpointIamBindingConditionOutput) ToAiEndpointIamBindingConditionPtrOutput() AiEndpointIamBindingConditionPtrOutput {
	return o.ToAiEndpointIamBindingConditionPtrOutputWithContext(context.Background())
}

func (o AiEndpointIamBindingConditionOutput) ToAiEndpointIamBindingConditionPtrOutputWithContext(ctx context.Context) AiEndpointIamBindingConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointIamBindingCondition) *AiEndpointIamBindingCondition {
		return &v
	}).(AiEndpointIamBindingConditionPtrOutput)
}

func (o AiEndpointIamBindingConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointIamBindingCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiEndpointIamBindingConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiEndpointIamBindingCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiEndpointIamBindingConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiEndpointIamBindingCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiEndpointIamBindingConditionPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointIamBindingConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointIamBindingCondition)(nil)).Elem()
}

func (o AiEndpointIamBindingConditionPtrOutput) ToAiEndpointIamBindingConditionPtrOutput() AiEndpointIamBindingConditionPtrOutput {
	return o
}

func (o AiEndpointIamBindingConditionPtrOutput) ToAiEndpointIamBindingConditionPtrOutputWithContext(ctx context.Context) AiEndpointIamBindingConditionPtrOutput {
	return o
}

func (o AiEndpointIamBindingConditionPtrOutput) Elem() AiEndpointIamBindingConditionOutput {
	return o.ApplyT(func(v *AiEndpointIamBindingCondition) AiEndpointIamBindingCondition {
		if v != nil {
			return *v
		}
		var ret AiEndpointIamBindingCondition
		return ret
	}).(AiEndpointIamBindingConditionOutput)
}

func (o AiEndpointIamBindingConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiEndpointIamBindingConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiEndpointIamBindingConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiEndpointIamMemberCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiEndpointIamMemberConditionInput is an input type that accepts AiEndpointIamMemberConditionArgs and AiEndpointIamMemberConditionOutput values.
// You can construct a concrete instance of `AiEndpointIamMemberConditionInput` via:
//
//	AiEndpointIamMemberConditionArgs{...}
type AiEndpointIamMemberConditionInput interface {
	pulumi.Input

	ToAiEndpointIamMemberConditionOutput() AiEndpointIamMemberConditionOutput
	ToAiEndpointIamMemberConditionOutputWithContext(context.Context) AiEndpointIamMemberConditionOutput
}

type AiEndpointIamMemberConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiEndpointIamMemberConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointIamMemberCondition)(nil)).Elem()
}

func (i AiEndpointIamMemberConditionArgs) ToAiEndpointIamMemberConditionOutput() AiEndpointIamMemberConditionOutput {
	return i.ToAiEndpointIamMemberConditionOutputWithContext(context.Background())
}

func (i AiEndpointIamMemberConditionArgs) ToAiEndpointIamMemberConditionOutputWithContext(ctx context.Context) AiEndpointIamMemberConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointIamMemberConditionOutput)
}

func (i AiEndpointIamMemberConditionArgs) ToAiEndpointIamMemberConditionPtrOutput() AiEndpointIamMemberConditionPtrOutput {
	return i.ToAiEndpointIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i AiEndpointIamMemberConditionArgs) ToAiEndpointIamMemberConditionPtrOutputWithContext(ctx context.Context) AiEndpointIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointIamMemberConditionOutput).ToAiEndpointIamMemberConditionPtrOutputWithContext(ctx)
}

// AiEndpointIamMemberConditionPtrInput is an input type that accepts AiEndpointIamMemberConditionArgs, AiEndpointIamMemberConditionPtr and AiEndpointIamMemberConditionPtrOutput values.
// You can construct a concrete instance of `AiEndpointIamMemberConditionPtrInput` via:
//
//	        AiEndpointIamMemberConditionArgs{...}
//
//	or:
//
//	        nil
type AiEndpointIamMemberConditionPtrInput interface {
	pulumi.Input

	ToAiEndpointIamMemberConditionPtrOutput() AiEndpointIamMemberConditionPtrOutput
	ToAiEndpointIamMemberConditionPtrOutputWithContext(context.Context) AiEndpointIamMemberConditionPtrOutput
}

type aiEndpointIamMemberConditionPtrType AiEndpointIamMemberConditionArgs

func AiEndpointIamMemberConditionPtr(v *AiEndpointIamMemberConditionArgs) AiEndpointIamMemberConditionPtrInput {
	return (*aiEndpointIamMemberConditionPtrType)(v)
}

func (*aiEndpointIamMemberConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointIamMemberCondition)(nil)).Elem()
}

func (i *aiEndpointIamMemberConditionPtrType) ToAiEndpointIamMemberConditionPtrOutput() AiEndpointIamMemberConditionPtrOutput {
	return i.ToAiEndpointIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i *aiEndpointIamMemberConditionPtrType) ToAiEndpointIamMemberConditionPtrOutputWithContext(ctx context.Context) AiEndpointIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointIamMemberConditionPtrOutput)
}

type AiEndpointIamMemberConditionOutput struct{ *pulumi.OutputState }

func (AiEndpointIamMemberConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointIamMemberCondition)(nil)).Elem()
}

func (o AiEndpointIamMemberConditionOutput) ToAiEndpointIamMemberConditionOutput() AiEndpointIamMemberConditionOutput {
	return o
}

func (o AiEndpointIamMemberConditionOutput) ToAiEndpointIamMemberConditionOutputWithContext(ctx context.Context) AiEndpointIamMemberConditionOutput {
	return o
}

func (o AiEndpointIamMemberConditionOutput) ToAiEndpointIamMemberConditionPtrOutput() AiEndpointIamMemberConditionPtrOutput {
	return o.ToAiEndpointIamMemberConditionPtrOutputWithContext(context.Background())
}

func (o AiEndpointIamMemberConditionOutput) ToAiEndpointIamMemberConditionPtrOutputWithContext(ctx context.Context) AiEndpointIamMemberConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointIamMemberCondition) *AiEndpointIamMemberCondition {
		return &v
	}).(AiEndpointIamMemberConditionPtrOutput)
}

func (o AiEndpointIamMemberConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointIamMemberCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiEndpointIamMemberConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiEndpointIamMemberCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiEndpointIamMemberConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiEndpointIamMemberCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiEndpointIamMemberConditionPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointIamMemberConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointIamMemberCondition)(nil)).Elem()
}

func (o AiEndpointIamMemberConditionPtrOutput) ToAiEndpointIamMemberConditionPtrOutput() AiEndpointIamMemberConditionPtrOutput {
	return o
}

func (o AiEndpointIamMemberConditionPtrOutput) ToAiEndpointIamMemberConditionPtrOutputWithContext(ctx context.Context) AiEndpointIamMemberConditionPtrOutput {
	return o
}

func (o AiEndpointIamMemberConditionPtrOutput) Elem() AiEndpointIamMemberConditionOutput {
	return o.ApplyT(func(v *AiEndpointIamMemberCondition) AiEndpointIamMemberCondition {
		if v != nil {
			return *v
		}
		var ret AiEndpointIamMemberCondition
		return ret
	}).(AiEndpointIamMemberConditionOutput)
}

func (o AiEndpointIamMemberConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiEndpointIamMemberConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiEndpointIamMemberConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiEndpointPredictRequestResponseLoggingConfig struct {
	// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging_<endpoint-display-name>_<endpoint-id>` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `requestResponseLogging`
	// Structure is documented below.
	BigqueryDestination *AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination `pulumi:"bigqueryDestination"`
	// If logging is enabled or not.
	Enabled *bool `pulumi:"enabled"`
	// Percentage of requests to be logged, expressed as a fraction in range(0,1]
	SamplingRate *float64 `pulumi:"samplingRate"`
}

// AiEndpointPredictRequestResponseLoggingConfigInput is an input type that accepts AiEndpointPredictRequestResponseLoggingConfigArgs and AiEndpointPredictRequestResponseLoggingConfigOutput values.
// You can construct a concrete instance of `AiEndpointPredictRequestResponseLoggingConfigInput` via:
//
//	AiEndpointPredictRequestResponseLoggingConfigArgs{...}
type AiEndpointPredictRequestResponseLoggingConfigInput interface {
	pulumi.Input

	ToAiEndpointPredictRequestResponseLoggingConfigOutput() AiEndpointPredictRequestResponseLoggingConfigOutput
	ToAiEndpointPredictRequestResponseLoggingConfigOutputWithContext(context.Context) AiEndpointPredictRequestResponseLoggingConfigOutput
}

type AiEndpointPredictRequestResponseLoggingConfigArgs struct {
	// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging_<endpoint-display-name>_<endpoint-id>` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `requestResponseLogging`
	// Structure is documented below.
	BigqueryDestination AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrInput `pulumi:"bigqueryDestination"`
	// If logging is enabled or not.
	Enabled pulumi.BoolPtrInput `pulumi:"enabled"`
	// Percentage of requests to be logged, expressed as a fraction in range(0,1]
	SamplingRate pulumi.Float64PtrInput `pulumi:"samplingRate"`
}

func (AiEndpointPredictRequestResponseLoggingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointPredictRequestResponseLoggingConfig)(nil)).Elem()
}

func (i AiEndpointPredictRequestResponseLoggingConfigArgs) ToAiEndpointPredictRequestResponseLoggingConfigOutput() AiEndpointPredictRequestResponseLoggingConfigOutput {
	return i.ToAiEndpointPredictRequestResponseLoggingConfigOutputWithContext(context.Background())
}

func (i AiEndpointPredictRequestResponseLoggingConfigArgs) ToAiEndpointPredictRequestResponseLoggingConfigOutputWithContext(ctx context.Context) AiEndpointPredictRequestResponseLoggingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointPredictRequestResponseLoggingConfigOutput)
}

func (i AiEndpointPredictRequestResponseLoggingConfigArgs) ToAiEndpointPredictRequestResponseLoggingConfigPtrOutput() AiEndpointPredictRequestResponseLoggingConfigPtrOutput {
	return i.ToAiEndpointPredictRequestResponseLoggingConfigPtrOutputWithContext(context.Background())
}

func (i AiEndpointPredictRequestResponseLoggingConfigArgs) ToAiEndpointPredictRequestResponseLoggingConfigPtrOutputWithContext(ctx context.Context) AiEndpointPredictRequestResponseLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointPredictRequestResponseLoggingConfigOutput).ToAiEndpointPredictRequestResponseLoggingConfigPtrOutputWithContext(ctx)
}

// AiEndpointPredictRequestResponseLoggingConfigPtrInput is an input type that accepts AiEndpointPredictRequestResponseLoggingConfigArgs, AiEndpointPredictRequestResponseLoggingConfigPtr and AiEndpointPredictRequestResponseLoggingConfigPtrOutput values.
// You can construct a concrete instance of `AiEndpointPredictRequestResponseLoggingConfigPtrInput` via:
//
//	        AiEndpointPredictRequestResponseLoggingConfigArgs{...}
//
//	or:
//
//	        nil
type AiEndpointPredictRequestResponseLoggingConfigPtrInput interface {
	pulumi.Input

	ToAiEndpointPredictRequestResponseLoggingConfigPtrOutput() AiEndpointPredictRequestResponseLoggingConfigPtrOutput
	ToAiEndpointPredictRequestResponseLoggingConfigPtrOutputWithContext(context.Context) AiEndpointPredictRequestResponseLoggingConfigPtrOutput
}

type aiEndpointPredictRequestResponseLoggingConfigPtrType AiEndpointPredictRequestResponseLoggingConfigArgs

func AiEndpointPredictRequestResponseLoggingConfigPtr(v *AiEndpointPredictRequestResponseLoggingConfigArgs) AiEndpointPredictRequestResponseLoggingConfigPtrInput {
	return (*aiEndpointPredictRequestResponseLoggingConfigPtrType)(v)
}

func (*aiEndpointPredictRequestResponseLoggingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointPredictRequestResponseLoggingConfig)(nil)).Elem()
}

func (i *aiEndpointPredictRequestResponseLoggingConfigPtrType) ToAiEndpointPredictRequestResponseLoggingConfigPtrOutput() AiEndpointPredictRequestResponseLoggingConfigPtrOutput {
	return i.ToAiEndpointPredictRequestResponseLoggingConfigPtrOutputWithContext(context.Background())
}

func (i *aiEndpointPredictRequestResponseLoggingConfigPtrType) ToAiEndpointPredictRequestResponseLoggingConfigPtrOutputWithContext(ctx context.Context) AiEndpointPredictRequestResponseLoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointPredictRequestResponseLoggingConfigPtrOutput)
}

type AiEndpointPredictRequestResponseLoggingConfigOutput struct{ *pulumi.OutputState }

func (AiEndpointPredictRequestResponseLoggingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointPredictRequestResponseLoggingConfig)(nil)).Elem()
}

func (o AiEndpointPredictRequestResponseLoggingConfigOutput) ToAiEndpointPredictRequestResponseLoggingConfigOutput() AiEndpointPredictRequestResponseLoggingConfigOutput {
	return o
}

func (o AiEndpointPredictRequestResponseLoggingConfigOutput) ToAiEndpointPredictRequestResponseLoggingConfigOutputWithContext(ctx context.Context) AiEndpointPredictRequestResponseLoggingConfigOutput {
	return o
}

func (o AiEndpointPredictRequestResponseLoggingConfigOutput) ToAiEndpointPredictRequestResponseLoggingConfigPtrOutput() AiEndpointPredictRequestResponseLoggingConfigPtrOutput {
	return o.ToAiEndpointPredictRequestResponseLoggingConfigPtrOutputWithContext(context.Background())
}

func (o AiEndpointPredictRequestResponseLoggingConfigOutput) ToAiEndpointPredictRequestResponseLoggingConfigPtrOutputWithContext(ctx context.Context) AiEndpointPredictRequestResponseLoggingConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointPredictRequestResponseLoggingConfig) *AiEndpointPredictRequestResponseLoggingConfig {
		return &v
	}).(AiEndpointPredictRequestResponseLoggingConfigPtrOutput)
}

// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging_<endpoint-display-name>_<endpoint-id>` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `requestResponseLogging`
// Structure is documented below.
func (o AiEndpointPredictRequestResponseLoggingConfigOutput) BigqueryDestination() AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput {
	return o.ApplyT(func(v AiEndpointPredictRequestResponseLoggingConfig) *AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination {
		return v.BigqueryDestination
	}).(AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput)
}

// If logging is enabled or not.
func (o AiEndpointPredictRequestResponseLoggingConfigOutput) Enabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiEndpointPredictRequestResponseLoggingConfig) *bool { return v.Enabled }).(pulumi.BoolPtrOutput)
}

// Percentage of requests to be logged, expressed as a fraction in range(0,1]
func (o AiEndpointPredictRequestResponseLoggingConfigOutput) SamplingRate() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v AiEndpointPredictRequestResponseLoggingConfig) *float64 { return v.SamplingRate }).(pulumi.Float64PtrOutput)
}

type AiEndpointPredictRequestResponseLoggingConfigPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointPredictRequestResponseLoggingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointPredictRequestResponseLoggingConfig)(nil)).Elem()
}

func (o AiEndpointPredictRequestResponseLoggingConfigPtrOutput) ToAiEndpointPredictRequestResponseLoggingConfigPtrOutput() AiEndpointPredictRequestResponseLoggingConfigPtrOutput {
	return o
}

func (o AiEndpointPredictRequestResponseLoggingConfigPtrOutput) ToAiEndpointPredictRequestResponseLoggingConfigPtrOutputWithContext(ctx context.Context) AiEndpointPredictRequestResponseLoggingConfigPtrOutput {
	return o
}

func (o AiEndpointPredictRequestResponseLoggingConfigPtrOutput) Elem() AiEndpointPredictRequestResponseLoggingConfigOutput {
	return o.ApplyT(func(v *AiEndpointPredictRequestResponseLoggingConfig) AiEndpointPredictRequestResponseLoggingConfig {
		if v != nil {
			return *v
		}
		var ret AiEndpointPredictRequestResponseLoggingConfig
		return ret
	}).(AiEndpointPredictRequestResponseLoggingConfigOutput)
}

// BigQuery table for logging. If only given a project, a new dataset will be created with name `logging_<endpoint-display-name>_<endpoint-id>` where will be made BigQuery-dataset-name compatible (e.g. most special characters will become underscores). If no table name is given, a new table will be created with name `requestResponseLogging`
// Structure is documented below.
func (o AiEndpointPredictRequestResponseLoggingConfigPtrOutput) BigqueryDestination() AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput {
	return o.ApplyT(func(v *AiEndpointPredictRequestResponseLoggingConfig) *AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination {
		if v == nil {
			return nil
		}
		return v.BigqueryDestination
	}).(AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput)
}

// If logging is enabled or not.
func (o AiEndpointPredictRequestResponseLoggingConfigPtrOutput) Enabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiEndpointPredictRequestResponseLoggingConfig) *bool {
		if v == nil {
			return nil
		}
		return v.Enabled
	}).(pulumi.BoolPtrOutput)
}

// Percentage of requests to be logged, expressed as a fraction in range(0,1]
func (o AiEndpointPredictRequestResponseLoggingConfigPtrOutput) SamplingRate() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *AiEndpointPredictRequestResponseLoggingConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.SamplingRate
	}).(pulumi.Float64PtrOutput)
}

type AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination struct {
	// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: - BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
	OutputUri *string `pulumi:"outputUri"`
}

// AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationInput is an input type that accepts AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs and AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput values.
// You can construct a concrete instance of `AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationInput` via:
//
//	AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs{...}
type AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationInput interface {
	pulumi.Input

	ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput() AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput
	ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutputWithContext(context.Context) AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput
}

type AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs struct {
	// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: - BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
	OutputUri pulumi.StringPtrInput `pulumi:"outputUri"`
}

func (AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination)(nil)).Elem()
}

func (i AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs) ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput() AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput {
	return i.ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutputWithContext(context.Background())
}

func (i AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs) ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutputWithContext(ctx context.Context) AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput)
}

func (i AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs) ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput() AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput {
	return i.ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutputWithContext(context.Background())
}

func (i AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs) ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutputWithContext(ctx context.Context) AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput).ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutputWithContext(ctx)
}

// AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrInput is an input type that accepts AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs, AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtr and AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput values.
// You can construct a concrete instance of `AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrInput` via:
//
//	        AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs{...}
//
//	or:
//
//	        nil
type AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrInput interface {
	pulumi.Input

	ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput() AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput
	ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutputWithContext(context.Context) AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput
}

type aiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrType AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs

func AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtr(v *AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs) AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrInput {
	return (*aiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrType)(v)
}

func (*aiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination)(nil)).Elem()
}

func (i *aiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrType) ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput() AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput {
	return i.ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutputWithContext(context.Background())
}

func (i *aiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrType) ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutputWithContext(ctx context.Context) AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput)
}

type AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput struct{ *pulumi.OutputState }

func (AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination)(nil)).Elem()
}

func (o AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput) ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput() AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput {
	return o
}

func (o AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput) ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutputWithContext(ctx context.Context) AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput {
	return o
}

func (o AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput) ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput() AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput {
	return o.ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutputWithContext(context.Background())
}

func (o AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput) ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutputWithContext(ctx context.Context) AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination) *AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination {
		return &v
	}).(AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput)
}

// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: - BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
func (o AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput) OutputUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination) *string { return v.OutputUri }).(pulumi.StringPtrOutput)
}

type AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination)(nil)).Elem()
}

func (o AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput) ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput() AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput {
	return o
}

func (o AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput) ToAiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutputWithContext(ctx context.Context) AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput {
	return o
}

func (o AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput) Elem() AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput {
	return o.ApplyT(func(v *AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination) AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination {
		if v != nil {
			return *v
		}
		var ret AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination
		return ret
	}).(AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput)
}

// BigQuery URI to a project or table, up to 2000 characters long. When only the project is specified, the Dataset and Table is created. When the full table reference is specified, the Dataset must exist and table must not exist. Accepted forms: - BigQuery path. For example: `bq://projectId` or `bq://projectId.bqDatasetId` or `bq://projectId.bqDatasetId.bqTableId`.
func (o AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput) OutputUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointPredictRequestResponseLoggingConfigBigqueryDestination) *string {
		if v == nil {
			return nil
		}
		return v.OutputUri
	}).(pulumi.StringPtrOutput)
}

type AiEndpointPrivateServiceConnectConfig struct {
	// Required. If true, expose the IndexEndpoint via private service connect.
	EnablePrivateServiceConnect bool `pulumi:"enablePrivateServiceConnect"`
	// If set to true, enable secure private service connect with IAM authorization. Otherwise, private service connect will be done without authorization. Note latency will be slightly increased if authorization is enabled.
	EnableSecurePrivateServiceConnect *bool `pulumi:"enableSecurePrivateServiceConnect"`
	// A list of Projects from which the forwarding rule will target the service attachment.
	ProjectAllowlists []string `pulumi:"projectAllowlists"`
}

// AiEndpointPrivateServiceConnectConfigInput is an input type that accepts AiEndpointPrivateServiceConnectConfigArgs and AiEndpointPrivateServiceConnectConfigOutput values.
// You can construct a concrete instance of `AiEndpointPrivateServiceConnectConfigInput` via:
//
//	AiEndpointPrivateServiceConnectConfigArgs{...}
type AiEndpointPrivateServiceConnectConfigInput interface {
	pulumi.Input

	ToAiEndpointPrivateServiceConnectConfigOutput() AiEndpointPrivateServiceConnectConfigOutput
	ToAiEndpointPrivateServiceConnectConfigOutputWithContext(context.Context) AiEndpointPrivateServiceConnectConfigOutput
}

type AiEndpointPrivateServiceConnectConfigArgs struct {
	// Required. If true, expose the IndexEndpoint via private service connect.
	EnablePrivateServiceConnect pulumi.BoolInput `pulumi:"enablePrivateServiceConnect"`
	// If set to true, enable secure private service connect with IAM authorization. Otherwise, private service connect will be done without authorization. Note latency will be slightly increased if authorization is enabled.
	EnableSecurePrivateServiceConnect pulumi.BoolPtrInput `pulumi:"enableSecurePrivateServiceConnect"`
	// A list of Projects from which the forwarding rule will target the service attachment.
	ProjectAllowlists pulumi.StringArrayInput `pulumi:"projectAllowlists"`
}

func (AiEndpointPrivateServiceConnectConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointPrivateServiceConnectConfig)(nil)).Elem()
}

func (i AiEndpointPrivateServiceConnectConfigArgs) ToAiEndpointPrivateServiceConnectConfigOutput() AiEndpointPrivateServiceConnectConfigOutput {
	return i.ToAiEndpointPrivateServiceConnectConfigOutputWithContext(context.Background())
}

func (i AiEndpointPrivateServiceConnectConfigArgs) ToAiEndpointPrivateServiceConnectConfigOutputWithContext(ctx context.Context) AiEndpointPrivateServiceConnectConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointPrivateServiceConnectConfigOutput)
}

func (i AiEndpointPrivateServiceConnectConfigArgs) ToAiEndpointPrivateServiceConnectConfigPtrOutput() AiEndpointPrivateServiceConnectConfigPtrOutput {
	return i.ToAiEndpointPrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (i AiEndpointPrivateServiceConnectConfigArgs) ToAiEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) AiEndpointPrivateServiceConnectConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointPrivateServiceConnectConfigOutput).ToAiEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx)
}

// AiEndpointPrivateServiceConnectConfigPtrInput is an input type that accepts AiEndpointPrivateServiceConnectConfigArgs, AiEndpointPrivateServiceConnectConfigPtr and AiEndpointPrivateServiceConnectConfigPtrOutput values.
// You can construct a concrete instance of `AiEndpointPrivateServiceConnectConfigPtrInput` via:
//
//	        AiEndpointPrivateServiceConnectConfigArgs{...}
//
//	or:
//
//	        nil
type AiEndpointPrivateServiceConnectConfigPtrInput interface {
	pulumi.Input

	ToAiEndpointPrivateServiceConnectConfigPtrOutput() AiEndpointPrivateServiceConnectConfigPtrOutput
	ToAiEndpointPrivateServiceConnectConfigPtrOutputWithContext(context.Context) AiEndpointPrivateServiceConnectConfigPtrOutput
}

type aiEndpointPrivateServiceConnectConfigPtrType AiEndpointPrivateServiceConnectConfigArgs

func AiEndpointPrivateServiceConnectConfigPtr(v *AiEndpointPrivateServiceConnectConfigArgs) AiEndpointPrivateServiceConnectConfigPtrInput {
	return (*aiEndpointPrivateServiceConnectConfigPtrType)(v)
}

func (*aiEndpointPrivateServiceConnectConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointPrivateServiceConnectConfig)(nil)).Elem()
}

func (i *aiEndpointPrivateServiceConnectConfigPtrType) ToAiEndpointPrivateServiceConnectConfigPtrOutput() AiEndpointPrivateServiceConnectConfigPtrOutput {
	return i.ToAiEndpointPrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (i *aiEndpointPrivateServiceConnectConfigPtrType) ToAiEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) AiEndpointPrivateServiceConnectConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointPrivateServiceConnectConfigPtrOutput)
}

type AiEndpointPrivateServiceConnectConfigOutput struct{ *pulumi.OutputState }

func (AiEndpointPrivateServiceConnectConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointPrivateServiceConnectConfig)(nil)).Elem()
}

func (o AiEndpointPrivateServiceConnectConfigOutput) ToAiEndpointPrivateServiceConnectConfigOutput() AiEndpointPrivateServiceConnectConfigOutput {
	return o
}

func (o AiEndpointPrivateServiceConnectConfigOutput) ToAiEndpointPrivateServiceConnectConfigOutputWithContext(ctx context.Context) AiEndpointPrivateServiceConnectConfigOutput {
	return o
}

func (o AiEndpointPrivateServiceConnectConfigOutput) ToAiEndpointPrivateServiceConnectConfigPtrOutput() AiEndpointPrivateServiceConnectConfigPtrOutput {
	return o.ToAiEndpointPrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (o AiEndpointPrivateServiceConnectConfigOutput) ToAiEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) AiEndpointPrivateServiceConnectConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointPrivateServiceConnectConfig) *AiEndpointPrivateServiceConnectConfig {
		return &v
	}).(AiEndpointPrivateServiceConnectConfigPtrOutput)
}

// Required. If true, expose the IndexEndpoint via private service connect.
func (o AiEndpointPrivateServiceConnectConfigOutput) EnablePrivateServiceConnect() pulumi.BoolOutput {
	return o.ApplyT(func(v AiEndpointPrivateServiceConnectConfig) bool { return v.EnablePrivateServiceConnect }).(pulumi.BoolOutput)
}

// If set to true, enable secure private service connect with IAM authorization. Otherwise, private service connect will be done without authorization. Note latency will be slightly increased if authorization is enabled.
func (o AiEndpointPrivateServiceConnectConfigOutput) EnableSecurePrivateServiceConnect() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiEndpointPrivateServiceConnectConfig) *bool { return v.EnableSecurePrivateServiceConnect }).(pulumi.BoolPtrOutput)
}

// A list of Projects from which the forwarding rule will target the service attachment.
func (o AiEndpointPrivateServiceConnectConfigOutput) ProjectAllowlists() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiEndpointPrivateServiceConnectConfig) []string { return v.ProjectAllowlists }).(pulumi.StringArrayOutput)
}

type AiEndpointPrivateServiceConnectConfigPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointPrivateServiceConnectConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointPrivateServiceConnectConfig)(nil)).Elem()
}

func (o AiEndpointPrivateServiceConnectConfigPtrOutput) ToAiEndpointPrivateServiceConnectConfigPtrOutput() AiEndpointPrivateServiceConnectConfigPtrOutput {
	return o
}

func (o AiEndpointPrivateServiceConnectConfigPtrOutput) ToAiEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) AiEndpointPrivateServiceConnectConfigPtrOutput {
	return o
}

func (o AiEndpointPrivateServiceConnectConfigPtrOutput) Elem() AiEndpointPrivateServiceConnectConfigOutput {
	return o.ApplyT(func(v *AiEndpointPrivateServiceConnectConfig) AiEndpointPrivateServiceConnectConfig {
		if v != nil {
			return *v
		}
		var ret AiEndpointPrivateServiceConnectConfig
		return ret
	}).(AiEndpointPrivateServiceConnectConfigOutput)
}

// Required. If true, expose the IndexEndpoint via private service connect.
func (o AiEndpointPrivateServiceConnectConfigPtrOutput) EnablePrivateServiceConnect() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiEndpointPrivateServiceConnectConfig) *bool {
		if v == nil {
			return nil
		}
		return &v.EnablePrivateServiceConnect
	}).(pulumi.BoolPtrOutput)
}

// If set to true, enable secure private service connect with IAM authorization. Otherwise, private service connect will be done without authorization. Note latency will be slightly increased if authorization is enabled.
func (o AiEndpointPrivateServiceConnectConfigPtrOutput) EnableSecurePrivateServiceConnect() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiEndpointPrivateServiceConnectConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EnableSecurePrivateServiceConnect
	}).(pulumi.BoolPtrOutput)
}

// A list of Projects from which the forwarding rule will target the service attachment.
func (o AiEndpointPrivateServiceConnectConfigPtrOutput) ProjectAllowlists() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiEndpointPrivateServiceConnectConfig) []string {
		if v == nil {
			return nil
		}
		return v.ProjectAllowlists
	}).(pulumi.StringArrayOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfig struct {
	// A description of resources that are dedicated to a DeployedModel or
	// DeployedIndex, and that need a higher degree of manual configuration.
	// Structure is documented below.
	DedicatedResources *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources `pulumi:"dedicatedResources"`
	// If true, enable the QMT fast tryout feature for this model if possible.
	FastTryoutEnabled *bool `pulumi:"fastTryoutEnabled"`
	// System labels for Model Garden deployments.
	// These labels are managed by Google and for tracking purposes only.
	SystemLabels map[string]string `pulumi:"systemLabels"`
}

// AiEndpointWithModelGardenDeploymentDeployConfigInput is an input type that accepts AiEndpointWithModelGardenDeploymentDeployConfigArgs and AiEndpointWithModelGardenDeploymentDeployConfigOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentDeployConfigInput` via:
//
//	AiEndpointWithModelGardenDeploymentDeployConfigArgs{...}
type AiEndpointWithModelGardenDeploymentDeployConfigInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentDeployConfigOutput() AiEndpointWithModelGardenDeploymentDeployConfigOutput
	ToAiEndpointWithModelGardenDeploymentDeployConfigOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentDeployConfigOutput
}

type AiEndpointWithModelGardenDeploymentDeployConfigArgs struct {
	// A description of resources that are dedicated to a DeployedModel or
	// DeployedIndex, and that need a higher degree of manual configuration.
	// Structure is documented below.
	DedicatedResources AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrInput `pulumi:"dedicatedResources"`
	// If true, enable the QMT fast tryout feature for this model if possible.
	FastTryoutEnabled pulumi.BoolPtrInput `pulumi:"fastTryoutEnabled"`
	// System labels for Model Garden deployments.
	// These labels are managed by Google and for tracking purposes only.
	SystemLabels pulumi.StringMapInput `pulumi:"systemLabels"`
}

func (AiEndpointWithModelGardenDeploymentDeployConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfig)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigOutput() AiEndpointWithModelGardenDeploymentDeployConfigOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigOutput)
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigOutput).ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentDeployConfigPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentDeployConfigArgs, AiEndpointWithModelGardenDeploymentDeployConfigPtr and AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentDeployConfigPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentDeployConfigArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentDeployConfigPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput
	ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput
}

type aiEndpointWithModelGardenDeploymentDeployConfigPtrType AiEndpointWithModelGardenDeploymentDeployConfigArgs

func AiEndpointWithModelGardenDeploymentDeployConfigPtr(v *AiEndpointWithModelGardenDeploymentDeployConfigArgs) AiEndpointWithModelGardenDeploymentDeployConfigPtrInput {
	return (*aiEndpointWithModelGardenDeploymentDeployConfigPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentDeployConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentDeployConfig)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentDeployConfigPtrType) ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentDeployConfigPtrType) ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentDeployConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfig)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigOutput() AiEndpointWithModelGardenDeploymentDeployConfigOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentDeployConfig) *AiEndpointWithModelGardenDeploymentDeployConfig {
		return &v
	}).(AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput)
}

// A description of resources that are dedicated to a DeployedModel or
// DeployedIndex, and that need a higher degree of manual configuration.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentDeployConfigOutput) DedicatedResources() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfig) *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources {
		return v.DedicatedResources
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput)
}

// If true, enable the QMT fast tryout feature for this model if possible.
func (o AiEndpointWithModelGardenDeploymentDeployConfigOutput) FastTryoutEnabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfig) *bool { return v.FastTryoutEnabled }).(pulumi.BoolPtrOutput)
}

// System labels for Model Garden deployments.
// These labels are managed by Google and for tracking purposes only.
func (o AiEndpointWithModelGardenDeploymentDeployConfigOutput) SystemLabels() pulumi.StringMapOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfig) map[string]string { return v.SystemLabels }).(pulumi.StringMapOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentDeployConfig)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput) Elem() AiEndpointWithModelGardenDeploymentDeployConfigOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfig) AiEndpointWithModelGardenDeploymentDeployConfig {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentDeployConfig
		return ret
	}).(AiEndpointWithModelGardenDeploymentDeployConfigOutput)
}

// A description of resources that are dedicated to a DeployedModel or
// DeployedIndex, and that need a higher degree of manual configuration.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput) DedicatedResources() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfig) *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources {
		if v == nil {
			return nil
		}
		return v.DedicatedResources
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput)
}

// If true, enable the QMT fast tryout feature for this model if possible.
func (o AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput) FastTryoutEnabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfig) *bool {
		if v == nil {
			return nil
		}
		return v.FastTryoutEnabled
	}).(pulumi.BoolPtrOutput)
}

// System labels for Model Garden deployments.
// These labels are managed by Google and for tracking purposes only.
func (o AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput) SystemLabels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.SystemLabels
	}).(pulumi.StringMapOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources struct {
	// The metric specifications that overrides a resource
	// utilization metric (CPU utilization, accelerator's duty cycle, and so on)
	// target value (default to 60 if not set). At most one entry is allowed per
	// metric.
	// If machine_spec.accelerator_count is
	// above 0, the autoscaling will be based on both CPU utilization and
	// accelerator's duty cycle metrics and scale up when either metrics exceeds
	// its target value while scale down if both metrics are under their target
	// value. The default target value is 60 for both metrics.
	// If machine_spec.accelerator_count is
	// 0, the autoscaling will be based on CPU utilization metric only with
	// default target value 60 if not explicitly set.
	// For example, in the case of Online Prediction, if you want to override
	// target CPU utilization to 80, you should set
	// autoscaling_metric_specs.metric_name
	// to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and
	// autoscaling_metric_specs.target to `80`.
	// Structure is documented below.
	AutoscalingMetricSpecs []AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpec `pulumi:"autoscalingMetricSpecs"`
	// Specification of a single machine.
	// Structure is documented below.
	MachineSpec AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec `pulumi:"machineSpec"`
	// The maximum number of replicas that may be deployed on when the traffic
	// against it increases. If the requested value is too large, the deployment
	// will error, but if deployment succeeds then the ability to scale to that
	// many replicas is guaranteed (barring service outages). If traffic increases
	// beyond what its replicas at maximum may handle, a portion of the traffic
	// will be dropped. If this value is not provided, will use
	// minReplicaCount as the default value.
	// The value of this field impacts the charge against Vertex CPU and GPU
	// quotas. Specifically, you will be charged for (max_replica_count *
	// number of cores in the selected machine type) and (max_replica_count *
	// number of GPUs per replica in the selected machine type).
	MaxReplicaCount *int `pulumi:"maxReplicaCount"`
	// The minimum number of machine replicas that will be always deployed on.
	// This value must be greater than or equal to 1.
	// If traffic increases, it may dynamically be deployed onto more replicas,
	// and as traffic decreases, some of these extra replicas may be freed.
	MinReplicaCount int `pulumi:"minReplicaCount"`
	// Number of required available replicas for the deployment to succeed.
	// This field is only needed when partial deployment/mutation is
	// desired. If set, the deploy/mutate operation will succeed once
	// availableReplicaCount reaches required_replica_count, and the rest of
	// the replicas will be retried. If not set, the default
	// requiredReplicaCount will be min_replica_count.
	RequiredReplicaCount *int `pulumi:"requiredReplicaCount"`
	// If true, schedule the deployment workload on [spot
	// VMs](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms).
	Spot *bool `pulumi:"spot"`
}

// AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesInput is an input type that accepts AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs and AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesInput` via:
//
//	AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs{...}
type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput
	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs struct {
	// The metric specifications that overrides a resource
	// utilization metric (CPU utilization, accelerator's duty cycle, and so on)
	// target value (default to 60 if not set). At most one entry is allowed per
	// metric.
	// If machine_spec.accelerator_count is
	// above 0, the autoscaling will be based on both CPU utilization and
	// accelerator's duty cycle metrics and scale up when either metrics exceeds
	// its target value while scale down if both metrics are under their target
	// value. The default target value is 60 for both metrics.
	// If machine_spec.accelerator_count is
	// 0, the autoscaling will be based on CPU utilization metric only with
	// default target value 60 if not explicitly set.
	// For example, in the case of Online Prediction, if you want to override
	// target CPU utilization to 80, you should set
	// autoscaling_metric_specs.metric_name
	// to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and
	// autoscaling_metric_specs.target to `80`.
	// Structure is documented below.
	AutoscalingMetricSpecs AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayInput `pulumi:"autoscalingMetricSpecs"`
	// Specification of a single machine.
	// Structure is documented below.
	MachineSpec AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecInput `pulumi:"machineSpec"`
	// The maximum number of replicas that may be deployed on when the traffic
	// against it increases. If the requested value is too large, the deployment
	// will error, but if deployment succeeds then the ability to scale to that
	// many replicas is guaranteed (barring service outages). If traffic increases
	// beyond what its replicas at maximum may handle, a portion of the traffic
	// will be dropped. If this value is not provided, will use
	// minReplicaCount as the default value.
	// The value of this field impacts the charge against Vertex CPU and GPU
	// quotas. Specifically, you will be charged for (max_replica_count *
	// number of cores in the selected machine type) and (max_replica_count *
	// number of GPUs per replica in the selected machine type).
	MaxReplicaCount pulumi.IntPtrInput `pulumi:"maxReplicaCount"`
	// The minimum number of machine replicas that will be always deployed on.
	// This value must be greater than or equal to 1.
	// If traffic increases, it may dynamically be deployed onto more replicas,
	// and as traffic decreases, some of these extra replicas may be freed.
	MinReplicaCount pulumi.IntInput `pulumi:"minReplicaCount"`
	// Number of required available replicas for the deployment to succeed.
	// This field is only needed when partial deployment/mutation is
	// desired. If set, the deploy/mutate operation will succeed once
	// availableReplicaCount reaches required_replica_count, and the rest of
	// the replicas will be retried. If not set, the default
	// requiredReplicaCount will be min_replica_count.
	RequiredReplicaCount pulumi.IntPtrInput `pulumi:"requiredReplicaCount"`
	// If true, schedule the deployment workload on [spot
	// VMs](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms).
	Spot pulumi.BoolPtrInput `pulumi:"spot"`
}

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput)
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput).ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs, AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtr and AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput
	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput
}

type aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrType AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs

func AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtr(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrInput {
	return (*aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrType) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrType) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources {
		return &v
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput)
}

// The metric specifications that overrides a resource
// utilization metric (CPU utilization, accelerator's duty cycle, and so on)
// target value (default to 60 if not set). At most one entry is allowed per
// metric.
// If machine_spec.accelerator_count is
// above 0, the autoscaling will be based on both CPU utilization and
// accelerator's duty cycle metrics and scale up when either metrics exceeds
// its target value while scale down if both metrics are under their target
// value. The default target value is 60 for both metrics.
// If machine_spec.accelerator_count is
// 0, the autoscaling will be based on CPU utilization metric only with
// default target value 60 if not explicitly set.
// For example, in the case of Online Prediction, if you want to override
// target CPU utilization to 80, you should set
// autoscaling_metric_specs.metric_name
// to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and
// autoscaling_metric_specs.target to `80`.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput) AutoscalingMetricSpecs() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) []AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpec {
		return v.AutoscalingMetricSpecs
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput)
}

// Specification of a single machine.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput) MachineSpec() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec {
		return v.MachineSpec
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput)
}

// The maximum number of replicas that may be deployed on when the traffic
// against it increases. If the requested value is too large, the deployment
// will error, but if deployment succeeds then the ability to scale to that
// many replicas is guaranteed (barring service outages). If traffic increases
// beyond what its replicas at maximum may handle, a portion of the traffic
// will be dropped. If this value is not provided, will use
// minReplicaCount as the default value.
// The value of this field impacts the charge against Vertex CPU and GPU
// quotas. Specifically, you will be charged for (max_replica_count *
// number of cores in the selected machine type) and (max_replica_count *
// number of GPUs per replica in the selected machine type).
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) *int {
		return v.MaxReplicaCount
	}).(pulumi.IntPtrOutput)
}

// The minimum number of machine replicas that will be always deployed on.
// This value must be greater than or equal to 1.
// If traffic increases, it may dynamically be deployed onto more replicas,
// and as traffic decreases, some of these extra replicas may be freed.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput) MinReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) int {
		return v.MinReplicaCount
	}).(pulumi.IntOutput)
}

// Number of required available replicas for the deployment to succeed.
// This field is only needed when partial deployment/mutation is
// desired. If set, the deploy/mutate operation will succeed once
// availableReplicaCount reaches required_replica_count, and the rest of
// the replicas will be retried. If not set, the default
// requiredReplicaCount will be min_replica_count.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput) RequiredReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) *int {
		return v.RequiredReplicaCount
	}).(pulumi.IntPtrOutput)
}

// If true, schedule the deployment workload on [spot
// VMs](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms).
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput) Spot() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) *bool { return v.Spot }).(pulumi.BoolPtrOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput) Elem() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources
		return ret
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput)
}

// The metric specifications that overrides a resource
// utilization metric (CPU utilization, accelerator's duty cycle, and so on)
// target value (default to 60 if not set). At most one entry is allowed per
// metric.
// If machine_spec.accelerator_count is
// above 0, the autoscaling will be based on both CPU utilization and
// accelerator's duty cycle metrics and scale up when either metrics exceeds
// its target value while scale down if both metrics are under their target
// value. The default target value is 60 for both metrics.
// If machine_spec.accelerator_count is
// 0, the autoscaling will be based on CPU utilization metric only with
// default target value 60 if not explicitly set.
// For example, in the case of Online Prediction, if you want to override
// target CPU utilization to 80, you should set
// autoscaling_metric_specs.metric_name
// to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and
// autoscaling_metric_specs.target to `80`.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput) AutoscalingMetricSpecs() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) []AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpec {
		if v == nil {
			return nil
		}
		return v.AutoscalingMetricSpecs
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput)
}

// Specification of a single machine.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput) MachineSpec() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec {
		if v == nil {
			return nil
		}
		return &v.MachineSpec
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput)
}

// The maximum number of replicas that may be deployed on when the traffic
// against it increases. If the requested value is too large, the deployment
// will error, but if deployment succeeds then the ability to scale to that
// many replicas is guaranteed (barring service outages). If traffic increases
// beyond what its replicas at maximum may handle, a portion of the traffic
// will be dropped. If this value is not provided, will use
// minReplicaCount as the default value.
// The value of this field impacts the charge against Vertex CPU and GPU
// quotas. Specifically, you will be charged for (max_replica_count *
// number of cores in the selected machine type) and (max_replica_count *
// number of GPUs per replica in the selected machine type).
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) *int {
		if v == nil {
			return nil
		}
		return v.MaxReplicaCount
	}).(pulumi.IntPtrOutput)
}

// The minimum number of machine replicas that will be always deployed on.
// This value must be greater than or equal to 1.
// If traffic increases, it may dynamically be deployed onto more replicas,
// and as traffic decreases, some of these extra replicas may be freed.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput) MinReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) *int {
		if v == nil {
			return nil
		}
		return &v.MinReplicaCount
	}).(pulumi.IntPtrOutput)
}

// Number of required available replicas for the deployment to succeed.
// This field is only needed when partial deployment/mutation is
// desired. If set, the deploy/mutate operation will succeed once
// availableReplicaCount reaches required_replica_count, and the rest of
// the replicas will be retried. If not set, the default
// requiredReplicaCount will be min_replica_count.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput) RequiredReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) *int {
		if v == nil {
			return nil
		}
		return v.RequiredReplicaCount
	}).(pulumi.IntPtrOutput)
}

// If true, schedule the deployment workload on [spot
// VMs](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms).
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput) Spot() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResources) *bool {
		if v == nil {
			return nil
		}
		return v.Spot
	}).(pulumi.BoolPtrOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpec struct {
	// The resource metric name.
	// Supported metrics:
	// * For Online Prediction:
	// * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle`
	// * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName string `pulumi:"metricName"`
	// The target resource utilization in percentage (1% - 100%) for the given
	// metric; once the real usage deviates from the target by a certain
	// percentage, the machine replicas change. The default value is 60
	// (representing 60%) if not provided.
	Target *int `pulumi:"target"`
}

// AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecInput is an input type that accepts AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArgs and AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecInput` via:
//
//	AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArgs{...}
type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput
	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArgs struct {
	// The resource metric name.
	// Supported metrics:
	// * For Online Prediction:
	// * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle`
	// * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
	MetricName pulumi.StringInput `pulumi:"metricName"`
	// The target resource utilization in percentage (1% - 100%) for the given
	// metric; once the real usage deviates from the target by a certain
	// percentage, the machine replicas change. The default value is 60
	// (representing 60%) if not provided.
	Target pulumi.IntPtrInput `pulumi:"target"`
}

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpec)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput)
}

// AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayInput is an input type that accepts AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArray and AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayInput` via:
//
//	AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArray{ AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArgs{...} }
type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput
	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArray []AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecInput

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpec)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArray) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArray) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpec)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput {
	return o
}

// The resource metric name.
// Supported metrics:
// * For Online Prediction:
// * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle`
// * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput) MetricName() pulumi.StringOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpec) string {
		return v.MetricName
	}).(pulumi.StringOutput)
}

// The target resource utilization in percentage (1% - 100%) for the given
// metric; once the real usage deviates from the target by a certain
// percentage, the machine replicas change. The default value is 60
// (representing 60%) if not provided.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput) Target() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpec) *int {
		return v.Target
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpec)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput) Index(i pulumi.IntInput) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpec {
		return vs[0].([]AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpec)[vs[1].(int)]
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec struct {
	// The number of accelerators to attach to the machine.
	AcceleratorCount *int `pulumi:"acceleratorCount"`
	// Possible values:
	// ACCELERATOR_TYPE_UNSPECIFIED
	// NVIDIA_TESLA_K80
	// NVIDIA_TESLA_P100
	// NVIDIA_TESLA_V100
	// NVIDIA_TESLA_P4
	// NVIDIA_TESLA_T4
	// NVIDIA_TESLA_A100
	// NVIDIA_A100_80GB
	// NVIDIA_L4
	// NVIDIA_H100_80GB
	// NVIDIA_H100_MEGA_80GB
	// NVIDIA_H200_141GB
	// NVIDIA_B200
	// TPU_V2
	// TPU_V3
	// TPU_V4_POD
	// TPU_V5_LITEPOD
	AcceleratorType *string `pulumi:"acceleratorType"`
	// The type of the machine.
	// See the [list of machine types supported for
	// prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)
	// See the [list of machine types supported for custom
	// training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
	// For DeployedModel this field is optional, and the default
	// value is `n1-standard-2`. For BatchPredictionJob or as part of
	// WorkerPoolSpec this field is required.
	MachineType *string `pulumi:"machineType"`
	// The number of nodes per replica for multihost GPU deployments.
	MultihostGpuNodeCount *int `pulumi:"multihostGpuNodeCount"`
	// A ReservationAffinity can be used to configure a Vertex AI resource (e.g., a
	// DeployedModel) to draw its Compute Engine resources from a Shared
	// Reservation, or exclusively from on-demand capacity.
	// Structure is documented below.
	ReservationAffinity *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity `pulumi:"reservationAffinity"`
	// The topology of the TPUs. Corresponds to the TPU topologies available from
	// GKE. (Example: tpu_topology: "2x2x1").
	TpuTopology *string `pulumi:"tpuTopology"`
}

// AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecInput is an input type that accepts AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs and AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecInput` via:
//
//	AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs{...}
type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput
	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs struct {
	// The number of accelerators to attach to the machine.
	AcceleratorCount pulumi.IntPtrInput `pulumi:"acceleratorCount"`
	// Possible values:
	// ACCELERATOR_TYPE_UNSPECIFIED
	// NVIDIA_TESLA_K80
	// NVIDIA_TESLA_P100
	// NVIDIA_TESLA_V100
	// NVIDIA_TESLA_P4
	// NVIDIA_TESLA_T4
	// NVIDIA_TESLA_A100
	// NVIDIA_A100_80GB
	// NVIDIA_L4
	// NVIDIA_H100_80GB
	// NVIDIA_H100_MEGA_80GB
	// NVIDIA_H200_141GB
	// NVIDIA_B200
	// TPU_V2
	// TPU_V3
	// TPU_V4_POD
	// TPU_V5_LITEPOD
	AcceleratorType pulumi.StringPtrInput `pulumi:"acceleratorType"`
	// The type of the machine.
	// See the [list of machine types supported for
	// prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)
	// See the [list of machine types supported for custom
	// training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
	// For DeployedModel this field is optional, and the default
	// value is `n1-standard-2`. For BatchPredictionJob or as part of
	// WorkerPoolSpec this field is required.
	MachineType pulumi.StringPtrInput `pulumi:"machineType"`
	// The number of nodes per replica for multihost GPU deployments.
	MultihostGpuNodeCount pulumi.IntPtrInput `pulumi:"multihostGpuNodeCount"`
	// A ReservationAffinity can be used to configure a Vertex AI resource (e.g., a
	// DeployedModel) to draw its Compute Engine resources from a Shared
	// Reservation, or exclusively from on-demand capacity.
	// Structure is documented below.
	ReservationAffinity AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrInput `pulumi:"reservationAffinity"`
	// The topology of the TPUs. Corresponds to the TPU topologies available from
	// GKE. (Example: tpu_topology: "2x2x1").
	TpuTopology pulumi.StringPtrInput `pulumi:"tpuTopology"`
}

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput)
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput).ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs, AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtr and AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput
	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput
}

type aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrType AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs

func AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtr(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrInput {
	return (*aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrType) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrType) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec {
		return &v
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput)
}

// The number of accelerators to attach to the machine.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput) AcceleratorCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *int {
		return v.AcceleratorCount
	}).(pulumi.IntPtrOutput)
}

// Possible values:
// ACCELERATOR_TYPE_UNSPECIFIED
// NVIDIA_TESLA_K80
// NVIDIA_TESLA_P100
// NVIDIA_TESLA_V100
// NVIDIA_TESLA_P4
// NVIDIA_TESLA_T4
// NVIDIA_TESLA_A100
// NVIDIA_A100_80GB
// NVIDIA_L4
// NVIDIA_H100_80GB
// NVIDIA_H100_MEGA_80GB
// NVIDIA_H200_141GB
// NVIDIA_B200
// TPU_V2
// TPU_V3
// TPU_V4_POD
// TPU_V5_LITEPOD
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput) AcceleratorType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *string {
		return v.AcceleratorType
	}).(pulumi.StringPtrOutput)
}

// The type of the machine.
// See the [list of machine types supported for
// prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)
// See the [list of machine types supported for custom
// training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
// For DeployedModel this field is optional, and the default
// value is `n1-standard-2`. For BatchPredictionJob or as part of
// WorkerPoolSpec this field is required.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *string {
		return v.MachineType
	}).(pulumi.StringPtrOutput)
}

// The number of nodes per replica for multihost GPU deployments.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput) MultihostGpuNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *int {
		return v.MultihostGpuNodeCount
	}).(pulumi.IntPtrOutput)
}

// A ReservationAffinity can be used to configure a Vertex AI resource (e.g., a
// DeployedModel) to draw its Compute Engine resources from a Shared
// Reservation, or exclusively from on-demand capacity.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput) ReservationAffinity() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity {
		return v.ReservationAffinity
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput)
}

// The topology of the TPUs. Corresponds to the TPU topologies available from
// GKE. (Example: tpu_topology: "2x2x1").
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput) TpuTopology() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *string {
		return v.TpuTopology
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput) Elem() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec
		return ret
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput)
}

// The number of accelerators to attach to the machine.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput) AcceleratorCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *int {
		if v == nil {
			return nil
		}
		return v.AcceleratorCount
	}).(pulumi.IntPtrOutput)
}

// Possible values:
// ACCELERATOR_TYPE_UNSPECIFIED
// NVIDIA_TESLA_K80
// NVIDIA_TESLA_P100
// NVIDIA_TESLA_V100
// NVIDIA_TESLA_P4
// NVIDIA_TESLA_T4
// NVIDIA_TESLA_A100
// NVIDIA_A100_80GB
// NVIDIA_L4
// NVIDIA_H100_80GB
// NVIDIA_H100_MEGA_80GB
// NVIDIA_H200_141GB
// NVIDIA_B200
// TPU_V2
// TPU_V3
// TPU_V4_POD
// TPU_V5_LITEPOD
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput) AcceleratorType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *string {
		if v == nil {
			return nil
		}
		return v.AcceleratorType
	}).(pulumi.StringPtrOutput)
}

// The type of the machine.
// See the [list of machine types supported for
// prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)
// See the [list of machine types supported for custom
// training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
// For DeployedModel this field is optional, and the default
// value is `n1-standard-2`. For BatchPredictionJob or as part of
// WorkerPoolSpec this field is required.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *string {
		if v == nil {
			return nil
		}
		return v.MachineType
	}).(pulumi.StringPtrOutput)
}

// The number of nodes per replica for multihost GPU deployments.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput) MultihostGpuNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *int {
		if v == nil {
			return nil
		}
		return v.MultihostGpuNodeCount
	}).(pulumi.IntPtrOutput)
}

// A ReservationAffinity can be used to configure a Vertex AI resource (e.g., a
// DeployedModel) to draw its Compute Engine resources from a Shared
// Reservation, or exclusively from on-demand capacity.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput) ReservationAffinity() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity {
		if v == nil {
			return nil
		}
		return v.ReservationAffinity
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput)
}

// The topology of the TPUs. Corresponds to the TPU topologies available from
// GKE. (Example: tpu_topology: "2x2x1").
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput) TpuTopology() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpec) *string {
		if v == nil {
			return nil
		}
		return v.TpuTopology
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity struct {
	// Corresponds to the label key of a reservation resource. To target a
	// SPECIFIC_RESERVATION by name, use `compute.googleapis.com/reservation-name`
	// as the key and specify the name of your reservation as its value.
	Key *string `pulumi:"key"`
	// Specifies the reservation affinity type.
	// Possible values:
	// TYPE_UNSPECIFIED
	// NO_RESERVATION
	// ANY_RESERVATION
	// SPECIFIC_RESERVATION
	ReservationAffinityType string `pulumi:"reservationAffinityType"`
	// Corresponds to the label values of a reservation resource. This must be the
	// full resource name of the reservation or reservation block.
	Values []string `pulumi:"values"`
}

// AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityInput is an input type that accepts AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs and AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityInput` via:
//
//	AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs{...}
type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput
	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs struct {
	// Corresponds to the label key of a reservation resource. To target a
	// SPECIFIC_RESERVATION by name, use `compute.googleapis.com/reservation-name`
	// as the key and specify the name of your reservation as its value.
	Key pulumi.StringPtrInput `pulumi:"key"`
	// Specifies the reservation affinity type.
	// Possible values:
	// TYPE_UNSPECIFIED
	// NO_RESERVATION
	// ANY_RESERVATION
	// SPECIFIC_RESERVATION
	ReservationAffinityType pulumi.StringInput `pulumi:"reservationAffinityType"`
	// Corresponds to the label values of a reservation resource. This must be the
	// full resource name of the reservation or reservation block.
	Values pulumi.StringArrayInput `pulumi:"values"`
}

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput)
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput).ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs, AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtr and AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput
	ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput
}

type aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrType AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs

func AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtr(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrInput {
	return (*aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrType) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrType) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity) *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity {
		return &v
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput)
}

// Corresponds to the label key of a reservation resource. To target a
// SPECIFIC_RESERVATION by name, use `compute.googleapis.com/reservation-name`
// as the key and specify the name of your reservation as its value.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput) Key() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity) *string {
		return v.Key
	}).(pulumi.StringPtrOutput)
}

// Specifies the reservation affinity type.
// Possible values:
// TYPE_UNSPECIFIED
// NO_RESERVATION
// ANY_RESERVATION
// SPECIFIC_RESERVATION
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput) ReservationAffinityType() pulumi.StringOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity) string {
		return v.ReservationAffinityType
	}).(pulumi.StringOutput)
}

// Corresponds to the label values of a reservation resource. This must be the
// full resource name of the reservation or reservation block.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity) []string {
		return v.Values
	}).(pulumi.StringArrayOutput)
}

type AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput) ToAiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput) Elem() AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity) AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity
		return ret
	}).(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput)
}

// Corresponds to the label key of a reservation resource. To target a
// SPECIFIC_RESERVATION by name, use `compute.googleapis.com/reservation-name`
// as the key and specify the name of your reservation as its value.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput) Key() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity) *string {
		if v == nil {
			return nil
		}
		return v.Key
	}).(pulumi.StringPtrOutput)
}

// Specifies the reservation affinity type.
// Possible values:
// TYPE_UNSPECIFIED
// NO_RESERVATION
// ANY_RESERVATION
// SPECIFIC_RESERVATION
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput) ReservationAffinityType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity) *string {
		if v == nil {
			return nil
		}
		return &v.ReservationAffinityType
	}).(pulumi.StringPtrOutput)
}

// Corresponds to the label values of a reservation resource. This must be the
// full resource name of the reservation or reservation block.
func (o AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinity) []string {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.StringArrayOutput)
}

type AiEndpointWithModelGardenDeploymentEndpointConfig struct {
	// If true, the endpoint will be exposed through a dedicated
	// DNS [Endpoint.dedicated_endpoint_dns]. Your request to the dedicated DNS
	// will be isolated from other users' traffic and will have better
	// performance and reliability. Note: Once you enabled dedicated endpoint,
	// you won't be able to send request to the shared DNS
	// {region}-aiplatform.googleapis.com. The limitations will be removed soon.
	DedicatedEndpointEnabled *bool `pulumi:"dedicatedEndpointEnabled"`
	// The user-specified display name of the endpoint. If not set, a
	// default name will be used.
	EndpointDisplayName *string `pulumi:"endpointDisplayName"`
}

// AiEndpointWithModelGardenDeploymentEndpointConfigInput is an input type that accepts AiEndpointWithModelGardenDeploymentEndpointConfigArgs and AiEndpointWithModelGardenDeploymentEndpointConfigOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentEndpointConfigInput` via:
//
//	AiEndpointWithModelGardenDeploymentEndpointConfigArgs{...}
type AiEndpointWithModelGardenDeploymentEndpointConfigInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentEndpointConfigOutput() AiEndpointWithModelGardenDeploymentEndpointConfigOutput
	ToAiEndpointWithModelGardenDeploymentEndpointConfigOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentEndpointConfigOutput
}

type AiEndpointWithModelGardenDeploymentEndpointConfigArgs struct {
	// If true, the endpoint will be exposed through a dedicated
	// DNS [Endpoint.dedicated_endpoint_dns]. Your request to the dedicated DNS
	// will be isolated from other users' traffic and will have better
	// performance and reliability. Note: Once you enabled dedicated endpoint,
	// you won't be able to send request to the shared DNS
	// {region}-aiplatform.googleapis.com. The limitations will be removed soon.
	DedicatedEndpointEnabled pulumi.BoolPtrInput `pulumi:"dedicatedEndpointEnabled"`
	// The user-specified display name of the endpoint. If not set, a
	// default name will be used.
	EndpointDisplayName pulumi.StringPtrInput `pulumi:"endpointDisplayName"`
}

func (AiEndpointWithModelGardenDeploymentEndpointConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentEndpointConfig)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentEndpointConfigArgs) ToAiEndpointWithModelGardenDeploymentEndpointConfigOutput() AiEndpointWithModelGardenDeploymentEndpointConfigOutput {
	return i.ToAiEndpointWithModelGardenDeploymentEndpointConfigOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentEndpointConfigArgs) ToAiEndpointWithModelGardenDeploymentEndpointConfigOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentEndpointConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentEndpointConfigOutput)
}

func (i AiEndpointWithModelGardenDeploymentEndpointConfigArgs) ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput() AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentEndpointConfigArgs) ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentEndpointConfigOutput).ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentEndpointConfigPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentEndpointConfigArgs, AiEndpointWithModelGardenDeploymentEndpointConfigPtr and AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentEndpointConfigPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentEndpointConfigArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentEndpointConfigPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput() AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput
	ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput
}

type aiEndpointWithModelGardenDeploymentEndpointConfigPtrType AiEndpointWithModelGardenDeploymentEndpointConfigArgs

func AiEndpointWithModelGardenDeploymentEndpointConfigPtr(v *AiEndpointWithModelGardenDeploymentEndpointConfigArgs) AiEndpointWithModelGardenDeploymentEndpointConfigPtrInput {
	return (*aiEndpointWithModelGardenDeploymentEndpointConfigPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentEndpointConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentEndpointConfig)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentEndpointConfigPtrType) ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput() AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentEndpointConfigPtrType) ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput)
}

type AiEndpointWithModelGardenDeploymentEndpointConfigOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentEndpointConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentEndpointConfig)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentEndpointConfigOutput) ToAiEndpointWithModelGardenDeploymentEndpointConfigOutput() AiEndpointWithModelGardenDeploymentEndpointConfigOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentEndpointConfigOutput) ToAiEndpointWithModelGardenDeploymentEndpointConfigOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentEndpointConfigOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentEndpointConfigOutput) ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput() AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentEndpointConfigOutput) ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentEndpointConfig) *AiEndpointWithModelGardenDeploymentEndpointConfig {
		return &v
	}).(AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput)
}

// If true, the endpoint will be exposed through a dedicated
// DNS [Endpoint.dedicated_endpoint_dns]. Your request to the dedicated DNS
// will be isolated from other users' traffic and will have better
// performance and reliability. Note: Once you enabled dedicated endpoint,
// you won't be able to send request to the shared DNS
// {region}-aiplatform.googleapis.com. The limitations will be removed soon.
func (o AiEndpointWithModelGardenDeploymentEndpointConfigOutput) DedicatedEndpointEnabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentEndpointConfig) *bool { return v.DedicatedEndpointEnabled }).(pulumi.BoolPtrOutput)
}

// The user-specified display name of the endpoint. If not set, a
// default name will be used.
func (o AiEndpointWithModelGardenDeploymentEndpointConfigOutput) EndpointDisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentEndpointConfig) *string { return v.EndpointDisplayName }).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentEndpointConfig)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput) ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput() AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput) ToAiEndpointWithModelGardenDeploymentEndpointConfigPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput) Elem() AiEndpointWithModelGardenDeploymentEndpointConfigOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentEndpointConfig) AiEndpointWithModelGardenDeploymentEndpointConfig {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentEndpointConfig
		return ret
	}).(AiEndpointWithModelGardenDeploymentEndpointConfigOutput)
}

// If true, the endpoint will be exposed through a dedicated
// DNS [Endpoint.dedicated_endpoint_dns]. Your request to the dedicated DNS
// will be isolated from other users' traffic and will have better
// performance and reliability. Note: Once you enabled dedicated endpoint,
// you won't be able to send request to the shared DNS
// {region}-aiplatform.googleapis.com. The limitations will be removed soon.
func (o AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput) DedicatedEndpointEnabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentEndpointConfig) *bool {
		if v == nil {
			return nil
		}
		return v.DedicatedEndpointEnabled
	}).(pulumi.BoolPtrOutput)
}

// The user-specified display name of the endpoint. If not set, a
// default name will be used.
func (o AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput) EndpointDisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentEndpointConfig) *string {
		if v == nil {
			return nil
		}
		return v.EndpointDisplayName
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfig struct {
	// Whether the user accepts the End User License Agreement (EULA)
	// for the model.
	AcceptEula *bool `pulumi:"acceptEula"`
	// Specification of a container for serving predictions. Some fields in this
	// message correspond to fields in the [Kubernetes Container v1 core
	// specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	// Structure is documented below.
	ContainerSpec *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec `pulumi:"containerSpec"`
	// The Hugging Face read access token used to access the model
	// artifacts of gated models.
	HuggingFaceAccessToken *string `pulumi:"huggingFaceAccessToken"`
	// If true, the model will deploy with a cached version instead of directly
	// downloading the model artifacts from Hugging Face. This is suitable for
	// VPC-SC users with limited internet access.
	HuggingFaceCacheEnabled *bool `pulumi:"huggingFaceCacheEnabled"`
	// The user-specified display name of the uploaded model. If not
	// set, a default name will be used.
	ModelDisplayName *string `pulumi:"modelDisplayName"`
}

// AiEndpointWithModelGardenDeploymentModelConfigInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigArgs and AiEndpointWithModelGardenDeploymentModelConfigOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigOutput() AiEndpointWithModelGardenDeploymentModelConfigOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigArgs struct {
	// Whether the user accepts the End User License Agreement (EULA)
	// for the model.
	AcceptEula pulumi.BoolPtrInput `pulumi:"acceptEula"`
	// Specification of a container for serving predictions. Some fields in this
	// message correspond to fields in the [Kubernetes Container v1 core
	// specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	// Structure is documented below.
	ContainerSpec AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrInput `pulumi:"containerSpec"`
	// The Hugging Face read access token used to access the model
	// artifacts of gated models.
	HuggingFaceAccessToken pulumi.StringPtrInput `pulumi:"huggingFaceAccessToken"`
	// If true, the model will deploy with a cached version instead of directly
	// downloading the model artifacts from Hugging Face. This is suitable for
	// VPC-SC users with limited internet access.
	HuggingFaceCacheEnabled pulumi.BoolPtrInput `pulumi:"huggingFaceCacheEnabled"`
	// The user-specified display name of the uploaded model. If not
	// set, a default name will be used.
	ModelDisplayName pulumi.StringPtrInput `pulumi:"modelDisplayName"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfig)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigArgs) ToAiEndpointWithModelGardenDeploymentModelConfigOutput() AiEndpointWithModelGardenDeploymentModelConfigOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigArgs) ToAiEndpointWithModelGardenDeploymentModelConfigOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigArgs) ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigArgs) ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigOutput).ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigArgs, AiEndpointWithModelGardenDeploymentModelConfigPtr and AiEndpointWithModelGardenDeploymentModelConfigPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigPtrType AiEndpointWithModelGardenDeploymentModelConfigArgs

func AiEndpointWithModelGardenDeploymentModelConfigPtr(v *AiEndpointWithModelGardenDeploymentModelConfigArgs) AiEndpointWithModelGardenDeploymentModelConfigPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfig)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfig)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigOutput) ToAiEndpointWithModelGardenDeploymentModelConfigOutput() AiEndpointWithModelGardenDeploymentModelConfigOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigOutput) ToAiEndpointWithModelGardenDeploymentModelConfigOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigOutput) ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigOutput) ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfig) *AiEndpointWithModelGardenDeploymentModelConfig {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigPtrOutput)
}

// Whether the user accepts the End User License Agreement (EULA)
// for the model.
func (o AiEndpointWithModelGardenDeploymentModelConfigOutput) AcceptEula() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfig) *bool { return v.AcceptEula }).(pulumi.BoolPtrOutput)
}

// Specification of a container for serving predictions. Some fields in this
// message correspond to fields in the [Kubernetes Container v1 core
// specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigOutput) ContainerSpec() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfig) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec {
		return v.ContainerSpec
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput)
}

// The Hugging Face read access token used to access the model
// artifacts of gated models.
func (o AiEndpointWithModelGardenDeploymentModelConfigOutput) HuggingFaceAccessToken() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfig) *string { return v.HuggingFaceAccessToken }).(pulumi.StringPtrOutput)
}

// If true, the model will deploy with a cached version instead of directly
// downloading the model artifacts from Hugging Face. This is suitable for
// VPC-SC users with limited internet access.
func (o AiEndpointWithModelGardenDeploymentModelConfigOutput) HuggingFaceCacheEnabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfig) *bool { return v.HuggingFaceCacheEnabled }).(pulumi.BoolPtrOutput)
}

// The user-specified display name of the uploaded model. If not
// set, a default name will be used.
func (o AiEndpointWithModelGardenDeploymentModelConfigOutput) ModelDisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfig) *string { return v.ModelDisplayName }).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfig)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfig) AiEndpointWithModelGardenDeploymentModelConfig {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfig
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigOutput)
}

// Whether the user accepts the End User License Agreement (EULA)
// for the model.
func (o AiEndpointWithModelGardenDeploymentModelConfigPtrOutput) AcceptEula() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfig) *bool {
		if v == nil {
			return nil
		}
		return v.AcceptEula
	}).(pulumi.BoolPtrOutput)
}

// Specification of a container for serving predictions. Some fields in this
// message correspond to fields in the [Kubernetes Container v1 core
// specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigPtrOutput) ContainerSpec() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfig) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec {
		if v == nil {
			return nil
		}
		return v.ContainerSpec
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput)
}

// The Hugging Face read access token used to access the model
// artifacts of gated models.
func (o AiEndpointWithModelGardenDeploymentModelConfigPtrOutput) HuggingFaceAccessToken() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfig) *string {
		if v == nil {
			return nil
		}
		return v.HuggingFaceAccessToken
	}).(pulumi.StringPtrOutput)
}

// If true, the model will deploy with a cached version instead of directly
// downloading the model artifacts from Hugging Face. This is suitable for
// VPC-SC users with limited internet access.
func (o AiEndpointWithModelGardenDeploymentModelConfigPtrOutput) HuggingFaceCacheEnabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfig) *bool {
		if v == nil {
			return nil
		}
		return v.HuggingFaceCacheEnabled
	}).(pulumi.BoolPtrOutput)
}

// The user-specified display name of the uploaded model. If not
// set, a default name will be used.
func (o AiEndpointWithModelGardenDeploymentModelConfigPtrOutput) ModelDisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfig) *string {
		if v == nil {
			return nil
		}
		return v.ModelDisplayName
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpec struct {
	// Specifies arguments for the command that runs when the container starts.
	// This overrides the container's
	// [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify
	// this field as an array of executable and arguments, similar to a Docker
	// `CMD`'s "default parameters" form.
	// If you don't specify this field but do specify the
	// command field, then the command from the
	// `command` field runs without any additional arguments. See the
	// [Kubernetes documentation about how the
	// `command` and `args` fields interact with a container's `ENTRYPOINT` and
	// `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
	// If you don't specify this field and don't specify the `command` field,
	// then the container's
	// [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and
	// `CMD` determine what runs based on their default behavior. See the Docker
	// documentation about [how `CMD` and `ENTRYPOINT`
	// interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
	// In this field, you can reference [environment variables
	// set by Vertex
	// AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
	// and environment variables set in the env field.
	// You cannot reference environment variables set in the Docker image. In
	// order for environment variables to be expanded, reference them by using the
	// following syntax:$(VARIABLE_NAME)
	// Note that this differs from Bash variable expansion, which does not use
	// parentheses. If a variable cannot be resolved, the reference in the input
	// string is used unchanged. To avoid variable expansion, you can escape this
	// syntax with `$$`; for example:$$(VARIABLE_NAME)
	// This field corresponds to the `args` field of the Kubernetes Containers
	// [v1 core
	// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Args []string `pulumi:"args"`
	// Specifies the command that runs when the container starts. This overrides
	// the container's
	// [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint).
	// Specify this field as an array of executable and arguments, similar to a
	// Docker `ENTRYPOINT`'s "exec" form, not its "shell" form.
	// If you do not specify this field, then the container's `ENTRYPOINT` runs,
	// in conjunction with the args field or the
	// container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd),
	// if either exists. If this field is not specified and the container does not
	// have an `ENTRYPOINT`, then refer to the Docker documentation about [how
	// `CMD` and `ENTRYPOINT`
	// interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
	// If you specify this field, then you can also specify the `args` field to
	// provide additional arguments for this command. However, if you specify this
	// field, then the container's `CMD` is ignored. See the
	// [Kubernetes documentation about how the
	// `command` and `args` fields interact with a container's `ENTRYPOINT` and
	// `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
	// In this field, you can reference [environment variables set by Vertex
	// AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
	// and environment variables set in the env field.
	// You cannot reference environment variables set in the Docker image. In
	// order for environment variables to be expanded, reference them by using the
	// following syntax:$(VARIABLE_NAME)
	// Note that this differs from Bash variable expansion, which does not use
	// parentheses. If a variable cannot be resolved, the reference in the input
	// string is used unchanged. To avoid variable expansion, you can escape this
	// syntax with `$$`; for example:$$(VARIABLE_NAME)
	// This field corresponds to the `command` field of the Kubernetes Containers
	// [v1 core
	// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Commands []string `pulumi:"commands"`
	// Deployment timeout.
	// Limit for deployment timeout is 2 hours.
	DeploymentTimeout *string `pulumi:"deploymentTimeout"`
	// List of environment variables to set in the container. After the container
	// starts running, code running in the container can read these environment
	// variables.
	// Additionally, the command and
	// args fields can reference these variables. Later
	// entries in this list can also reference earlier entries. For example, the
	// following example sets the variable `VAR_2` to have the value `foo bar`:
	//
	// If you switch the order of the variables in the example, then the expansion
	// does not occur.
	// This field corresponds to the `env` field of the Kubernetes Containers
	// [v1 core
	// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	// Structure is documented below.
	Envs []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv `pulumi:"envs"`
	// List of ports to expose from the container. Vertex AI sends gRPC
	// prediction requests that it receives to the first port on this list. Vertex
	// AI also sends liveness and health checks to this port.
	// If you do not specify this field, gRPC requests to the container will be
	// disabled.
	// Vertex AI does not use ports other than the first one listed. This field
	// corresponds to the `ports` field of the Kubernetes Containers v1 core API.
	// Structure is documented below.
	GrpcPorts []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort `pulumi:"grpcPorts"`
	// Probe describes a health check to be performed against a container to
	// determine whether it is alive or ready to receive traffic.
	// Structure is documented below.
	HealthProbe *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe `pulumi:"healthProbe"`
	// HTTP path on the container to send health checks to. Vertex AI
	// intermittently sends GET requests to this path on the container's IP
	// address and port to check that the container is healthy. Read more about
	// [health
	// checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health).
	// For example, if you set this field to `/bar`, then Vertex AI
	// intermittently sends a GET request to the `/bar` path on the port of your
	// container specified by the first value of this `ModelContainerSpec`'s
	// ports field.
	// If you don't specify this field, it defaults to the following value when
	// you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
	// The placeholders in this value are replaced as follows:
	// * ENDPOINT: The last segment (following `endpoints/`)of the
	//   Endpoint.name][] field of the Endpoint where this Model has been
	//   deployed. (Vertex AI makes this value available to your container code
	//   as the [`AIP_ENDPOINT_ID` environment
	//   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	// * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
	//   (Vertex AI makes this value available to your container code as the
	//   [`AIP_DEPLOYED_MODEL_ID` environment
	//   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	HealthRoute *string `pulumi:"healthRoute"`
	// URI of the Docker image to be used as the custom container for serving
	// predictions. This URI must identify an image in Artifact Registry or
	// Container Registry. Learn more about the [container publishing
	// requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing),
	// including permissions requirements for the Vertex AI Service Agent.
	// The container image is ingested upon ModelService.UploadModel, stored
	// internally, and this original path is afterwards not used.
	// To learn about the requirements for the Docker image itself, see
	// [Custom container
	// requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#).
	// You can use the URI to one of Vertex AI's [pre-built container images for
	// prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)
	// in this field.
	ImageUri string `pulumi:"imageUri"`
	// Probe describes a health check to be performed against a container to
	// determine whether it is alive or ready to receive traffic.
	// Structure is documented below.
	LivenessProbe *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe `pulumi:"livenessProbe"`
	// List of ports to expose from the container. Vertex AI sends any
	// prediction requests that it receives to the first port on this list. Vertex
	// AI also sends
	// [liveness and health
	// checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness)
	// to this port.
	// If you do not specify this field, it defaults to following value:
	//
	// Vertex AI does not use ports other than the first one listed. This field
	// corresponds to the `ports` field of the Kubernetes Containers
	// [v1 core
	// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	// Structure is documented below.
	Ports []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort `pulumi:"ports"`
	// HTTP path on the container to send prediction requests to. Vertex AI
	// forwards requests sent using
	// projects.locations.endpoints.predict to this
	// path on the container's IP address and port. Vertex AI then returns the
	// container's response in the API response.
	// For example, if you set this field to `/foo`, then when Vertex AI
	// receives a prediction request, it forwards the request body in a POST
	// request to the `/foo` path on the port of your container specified by the
	// first value of this `ModelContainerSpec`'s
	// ports field.
	// If you don't specify this field, it defaults to the following value when
	// you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
	// The placeholders in this value are replaced as follows:
	// * ENDPOINT: The last segment (following `endpoints/`)of the
	//   Endpoint.name][] field of the Endpoint where this Model has been
	//   deployed. (Vertex AI makes this value available to your container code
	//   as the [`AIP_ENDPOINT_ID` environment
	//   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	// * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
	//   (Vertex AI makes this value available to your container code
	//   as the [`AIP_DEPLOYED_MODEL_ID` environment
	//   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	PredictRoute *string `pulumi:"predictRoute"`
	// The amount of the VM memory to reserve as the shared memory for the model
	// in megabytes.
	SharedMemorySizeMb *string `pulumi:"sharedMemorySizeMb"`
	// Probe describes a health check to be performed against a container to
	// determine whether it is alive or ready to receive traffic.
	// Structure is documented below.
	StartupProbe *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe `pulumi:"startupProbe"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs struct {
	// Specifies arguments for the command that runs when the container starts.
	// This overrides the container's
	// [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify
	// this field as an array of executable and arguments, similar to a Docker
	// `CMD`'s "default parameters" form.
	// If you don't specify this field but do specify the
	// command field, then the command from the
	// `command` field runs without any additional arguments. See the
	// [Kubernetes documentation about how the
	// `command` and `args` fields interact with a container's `ENTRYPOINT` and
	// `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
	// If you don't specify this field and don't specify the `command` field,
	// then the container's
	// [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and
	// `CMD` determine what runs based on their default behavior. See the Docker
	// documentation about [how `CMD` and `ENTRYPOINT`
	// interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
	// In this field, you can reference [environment variables
	// set by Vertex
	// AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
	// and environment variables set in the env field.
	// You cannot reference environment variables set in the Docker image. In
	// order for environment variables to be expanded, reference them by using the
	// following syntax:$(VARIABLE_NAME)
	// Note that this differs from Bash variable expansion, which does not use
	// parentheses. If a variable cannot be resolved, the reference in the input
	// string is used unchanged. To avoid variable expansion, you can escape this
	// syntax with `$$`; for example:$$(VARIABLE_NAME)
	// This field corresponds to the `args` field of the Kubernetes Containers
	// [v1 core
	// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Args pulumi.StringArrayInput `pulumi:"args"`
	// Specifies the command that runs when the container starts. This overrides
	// the container's
	// [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint).
	// Specify this field as an array of executable and arguments, similar to a
	// Docker `ENTRYPOINT`'s "exec" form, not its "shell" form.
	// If you do not specify this field, then the container's `ENTRYPOINT` runs,
	// in conjunction with the args field or the
	// container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd),
	// if either exists. If this field is not specified and the container does not
	// have an `ENTRYPOINT`, then refer to the Docker documentation about [how
	// `CMD` and `ENTRYPOINT`
	// interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
	// If you specify this field, then you can also specify the `args` field to
	// provide additional arguments for this command. However, if you specify this
	// field, then the container's `CMD` is ignored. See the
	// [Kubernetes documentation about how the
	// `command` and `args` fields interact with a container's `ENTRYPOINT` and
	// `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
	// In this field, you can reference [environment variables set by Vertex
	// AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
	// and environment variables set in the env field.
	// You cannot reference environment variables set in the Docker image. In
	// order for environment variables to be expanded, reference them by using the
	// following syntax:$(VARIABLE_NAME)
	// Note that this differs from Bash variable expansion, which does not use
	// parentheses. If a variable cannot be resolved, the reference in the input
	// string is used unchanged. To avoid variable expansion, you can escape this
	// syntax with `$$`; for example:$$(VARIABLE_NAME)
	// This field corresponds to the `command` field of the Kubernetes Containers
	// [v1 core
	// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	Commands pulumi.StringArrayInput `pulumi:"commands"`
	// Deployment timeout.
	// Limit for deployment timeout is 2 hours.
	DeploymentTimeout pulumi.StringPtrInput `pulumi:"deploymentTimeout"`
	// List of environment variables to set in the container. After the container
	// starts running, code running in the container can read these environment
	// variables.
	// Additionally, the command and
	// args fields can reference these variables. Later
	// entries in this list can also reference earlier entries. For example, the
	// following example sets the variable `VAR_2` to have the value `foo bar`:
	//
	// If you switch the order of the variables in the example, then the expansion
	// does not occur.
	// This field corresponds to the `env` field of the Kubernetes Containers
	// [v1 core
	// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	// Structure is documented below.
	Envs AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayInput `pulumi:"envs"`
	// List of ports to expose from the container. Vertex AI sends gRPC
	// prediction requests that it receives to the first port on this list. Vertex
	// AI also sends liveness and health checks to this port.
	// If you do not specify this field, gRPC requests to the container will be
	// disabled.
	// Vertex AI does not use ports other than the first one listed. This field
	// corresponds to the `ports` field of the Kubernetes Containers v1 core API.
	// Structure is documented below.
	GrpcPorts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayInput `pulumi:"grpcPorts"`
	// Probe describes a health check to be performed against a container to
	// determine whether it is alive or ready to receive traffic.
	// Structure is documented below.
	HealthProbe AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrInput `pulumi:"healthProbe"`
	// HTTP path on the container to send health checks to. Vertex AI
	// intermittently sends GET requests to this path on the container's IP
	// address and port to check that the container is healthy. Read more about
	// [health
	// checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health).
	// For example, if you set this field to `/bar`, then Vertex AI
	// intermittently sends a GET request to the `/bar` path on the port of your
	// container specified by the first value of this `ModelContainerSpec`'s
	// ports field.
	// If you don't specify this field, it defaults to the following value when
	// you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
	// The placeholders in this value are replaced as follows:
	// * ENDPOINT: The last segment (following `endpoints/`)of the
	//   Endpoint.name][] field of the Endpoint where this Model has been
	//   deployed. (Vertex AI makes this value available to your container code
	//   as the [`AIP_ENDPOINT_ID` environment
	//   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	// * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
	//   (Vertex AI makes this value available to your container code as the
	//   [`AIP_DEPLOYED_MODEL_ID` environment
	//   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	HealthRoute pulumi.StringPtrInput `pulumi:"healthRoute"`
	// URI of the Docker image to be used as the custom container for serving
	// predictions. This URI must identify an image in Artifact Registry or
	// Container Registry. Learn more about the [container publishing
	// requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing),
	// including permissions requirements for the Vertex AI Service Agent.
	// The container image is ingested upon ModelService.UploadModel, stored
	// internally, and this original path is afterwards not used.
	// To learn about the requirements for the Docker image itself, see
	// [Custom container
	// requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#).
	// You can use the URI to one of Vertex AI's [pre-built container images for
	// prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)
	// in this field.
	ImageUri pulumi.StringInput `pulumi:"imageUri"`
	// Probe describes a health check to be performed against a container to
	// determine whether it is alive or ready to receive traffic.
	// Structure is documented below.
	LivenessProbe AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrInput `pulumi:"livenessProbe"`
	// List of ports to expose from the container. Vertex AI sends any
	// prediction requests that it receives to the first port on this list. Vertex
	// AI also sends
	// [liveness and health
	// checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness)
	// to this port.
	// If you do not specify this field, it defaults to following value:
	//
	// Vertex AI does not use ports other than the first one listed. This field
	// corresponds to the `ports` field of the Kubernetes Containers
	// [v1 core
	// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
	// Structure is documented below.
	Ports AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayInput `pulumi:"ports"`
	// HTTP path on the container to send prediction requests to. Vertex AI
	// forwards requests sent using
	// projects.locations.endpoints.predict to this
	// path on the container's IP address and port. Vertex AI then returns the
	// container's response in the API response.
	// For example, if you set this field to `/foo`, then when Vertex AI
	// receives a prediction request, it forwards the request body in a POST
	// request to the `/foo` path on the port of your container specified by the
	// first value of this `ModelContainerSpec`'s
	// ports field.
	// If you don't specify this field, it defaults to the following value when
	// you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
	// The placeholders in this value are replaced as follows:
	// * ENDPOINT: The last segment (following `endpoints/`)of the
	//   Endpoint.name][] field of the Endpoint where this Model has been
	//   deployed. (Vertex AI makes this value available to your container code
	//   as the [`AIP_ENDPOINT_ID` environment
	//   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	// * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
	//   (Vertex AI makes this value available to your container code
	//   as the [`AIP_DEPLOYED_MODEL_ID` environment
	//   variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
	PredictRoute pulumi.StringPtrInput `pulumi:"predictRoute"`
	// The amount of the VM memory to reserve as the shared memory for the model
	// in megabytes.
	SharedMemorySizeMb pulumi.StringPtrInput `pulumi:"sharedMemorySizeMb"`
	// Probe describes a health check to be performed against a container to
	// determine whether it is alive or ready to receive traffic.
	// Structure is documented below.
	StartupProbe AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrInput `pulumi:"startupProbe"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpec)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpec)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpec)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput)
}

// Specifies arguments for the command that runs when the container starts.
// This overrides the container's
// [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify
// this field as an array of executable and arguments, similar to a Docker
// `CMD`'s "default parameters" form.
// If you don't specify this field but do specify the
// command field, then the command from the
// `command` field runs without any additional arguments. See the
// [Kubernetes documentation about how the
// `command` and `args` fields interact with a container's `ENTRYPOINT` and
// `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
// If you don't specify this field and don't specify the `command` field,
// then the container's
// [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and
// `CMD` determine what runs based on their default behavior. See the Docker
// documentation about [how `CMD` and `ENTRYPOINT`
// interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
// In this field, you can reference [environment variables
// set by Vertex
// AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
// and environment variables set in the env field.
// You cannot reference environment variables set in the Docker image. In
// order for environment variables to be expanded, reference them by using the
// following syntax:$(VARIABLE_NAME)
// Note that this differs from Bash variable expansion, which does not use
// parentheses. If a variable cannot be resolved, the reference in the input
// string is used unchanged. To avoid variable expansion, you can escape this
// syntax with `$$`; for example:$$(VARIABLE_NAME)
// This field corresponds to the `args` field of the Kubernetes Containers
// [v1 core
// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Specifies the command that runs when the container starts. This overrides
// the container's
// [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint).
// Specify this field as an array of executable and arguments, similar to a
// Docker `ENTRYPOINT`'s "exec" form, not its "shell" form.
// If you do not specify this field, then the container's `ENTRYPOINT` runs,
// in conjunction with the args field or the
// container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd),
// if either exists. If this field is not specified and the container does not
// have an `ENTRYPOINT`, then refer to the Docker documentation about [how
// `CMD` and `ENTRYPOINT`
// interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
// If you specify this field, then you can also specify the `args` field to
// provide additional arguments for this command. However, if you specify this
// field, then the container's `CMD` is ignored. See the
// [Kubernetes documentation about how the
// `command` and `args` fields interact with a container's `ENTRYPOINT` and
// `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
// In this field, you can reference [environment variables set by Vertex
// AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
// and environment variables set in the env field.
// You cannot reference environment variables set in the Docker image. In
// order for environment variables to be expanded, reference them by using the
// following syntax:$(VARIABLE_NAME)
// Note that this differs from Bash variable expansion, which does not use
// parentheses. If a variable cannot be resolved, the reference in the input
// string is used unchanged. To avoid variable expansion, you can escape this
// syntax with `$$`; for example:$$(VARIABLE_NAME)
// This field corresponds to the `command` field of the Kubernetes Containers
// [v1 core
// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) Commands() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) []string { return v.Commands }).(pulumi.StringArrayOutput)
}

// Deployment timeout.
// Limit for deployment timeout is 2 hours.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) DeploymentTimeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *string {
		return v.DeploymentTimeout
	}).(pulumi.StringPtrOutput)
}

// List of environment variables to set in the container. After the container
// starts running, code running in the container can read these environment
// variables.
// Additionally, the command and
// args fields can reference these variables. Later
// entries in this list can also reference earlier entries. For example, the
// following example sets the variable `VAR_2` to have the value `foo bar`:
//
// If you switch the order of the variables in the example, then the expansion
// does not occur.
// This field corresponds to the `env` field of the Kubernetes Containers
// [v1 core
// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) Envs() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv {
		return v.Envs
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput)
}

// List of ports to expose from the container. Vertex AI sends gRPC
// prediction requests that it receives to the first port on this list. Vertex
// AI also sends liveness and health checks to this port.
// If you do not specify this field, gRPC requests to the container will be
// disabled.
// Vertex AI does not use ports other than the first one listed. This field
// corresponds to the `ports` field of the Kubernetes Containers v1 core API.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) GrpcPorts() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort {
		return v.GrpcPorts
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput)
}

// Probe describes a health check to be performed against a container to
// determine whether it is alive or ready to receive traffic.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) HealthProbe() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe {
		return v.HealthProbe
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput)
}

// HTTP path on the container to send health checks to. Vertex AI
// intermittently sends GET requests to this path on the container's IP
// address and port to check that the container is healthy. Read more about
// [health
// checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health).
// For example, if you set this field to `/bar`, then Vertex AI
// intermittently sends a GET request to the `/bar` path on the port of your
// container specified by the first value of this `ModelContainerSpec`'s
// ports field.
// If you don't specify this field, it defaults to the following value when
// you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
// The placeholders in this value are replaced as follows:
//   - ENDPOINT: The last segment (following `endpoints/`)of the
//     Endpoint.name][] field of the Endpoint where this Model has been
//     deployed. (Vertex AI makes this value available to your container code
//     as the [`AIP_ENDPOINT_ID` environment
//     variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
//   - DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
//     (Vertex AI makes this value available to your container code as the
//     [`AIP_DEPLOYED_MODEL_ID` environment
//     variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) HealthRoute() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *string { return v.HealthRoute }).(pulumi.StringPtrOutput)
}

// URI of the Docker image to be used as the custom container for serving
// predictions. This URI must identify an image in Artifact Registry or
// Container Registry. Learn more about the [container publishing
// requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing),
// including permissions requirements for the Vertex AI Service Agent.
// The container image is ingested upon ModelService.UploadModel, stored
// internally, and this original path is afterwards not used.
// To learn about the requirements for the Docker image itself, see
// [Custom container
// requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#).
// You can use the URI to one of Vertex AI's [pre-built container images for
// prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)
// in this field.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) ImageUri() pulumi.StringOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) string { return v.ImageUri }).(pulumi.StringOutput)
}

// Probe describes a health check to be performed against a container to
// determine whether it is alive or ready to receive traffic.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) LivenessProbe() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe {
		return v.LivenessProbe
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput)
}

// List of ports to expose from the container. Vertex AI sends any
// prediction requests that it receives to the first port on this list. Vertex
// AI also sends
// [liveness and health
// checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness)
// to this port.
// If you do not specify this field, it defaults to following value:
//
// Vertex AI does not use ports other than the first one listed. This field
// corresponds to the `ports` field of the Kubernetes Containers
// [v1 core
// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) Ports() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort {
		return v.Ports
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput)
}

// HTTP path on the container to send prediction requests to. Vertex AI
// forwards requests sent using
// projects.locations.endpoints.predict to this
// path on the container's IP address and port. Vertex AI then returns the
// container's response in the API response.
// For example, if you set this field to `/foo`, then when Vertex AI
// receives a prediction request, it forwards the request body in a POST
// request to the `/foo` path on the port of your container specified by the
// first value of this `ModelContainerSpec`'s
// ports field.
// If you don't specify this field, it defaults to the following value when
// you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
// The placeholders in this value are replaced as follows:
//   - ENDPOINT: The last segment (following `endpoints/`)of the
//     Endpoint.name][] field of the Endpoint where this Model has been
//     deployed. (Vertex AI makes this value available to your container code
//     as the [`AIP_ENDPOINT_ID` environment
//     variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
//   - DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
//     (Vertex AI makes this value available to your container code
//     as the [`AIP_DEPLOYED_MODEL_ID` environment
//     variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) PredictRoute() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *string { return v.PredictRoute }).(pulumi.StringPtrOutput)
}

// The amount of the VM memory to reserve as the shared memory for the model
// in megabytes.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) SharedMemorySizeMb() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *string {
		return v.SharedMemorySizeMb
	}).(pulumi.StringPtrOutput)
}

// Probe describes a health check to be performed against a container to
// determine whether it is alive or ready to receive traffic.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput) StartupProbe() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe {
		return v.StartupProbe
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpec)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) AiEndpointWithModelGardenDeploymentModelConfigContainerSpec {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpec
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput)
}

// Specifies arguments for the command that runs when the container starts.
// This overrides the container's
// [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify
// this field as an array of executable and arguments, similar to a Docker
// `CMD`'s "default parameters" form.
// If you don't specify this field but do specify the
// command field, then the command from the
// `command` field runs without any additional arguments. See the
// [Kubernetes documentation about how the
// `command` and `args` fields interact with a container's `ENTRYPOINT` and
// `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
// If you don't specify this field and don't specify the `command` field,
// then the container's
// [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and
// `CMD` determine what runs based on their default behavior. See the Docker
// documentation about [how `CMD` and `ENTRYPOINT`
// interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
// In this field, you can reference [environment variables
// set by Vertex
// AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
// and environment variables set in the env field.
// You cannot reference environment variables set in the Docker image. In
// order for environment variables to be expanded, reference them by using the
// following syntax:$(VARIABLE_NAME)
// Note that this differs from Bash variable expansion, which does not use
// parentheses. If a variable cannot be resolved, the reference in the input
// string is used unchanged. To avoid variable expansion, you can escape this
// syntax with `$$`; for example:$$(VARIABLE_NAME)
// This field corresponds to the `args` field of the Kubernetes Containers
// [v1 core
// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// Specifies the command that runs when the container starts. This overrides
// the container's
// [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint).
// Specify this field as an array of executable and arguments, similar to a
// Docker `ENTRYPOINT`'s "exec" form, not its "shell" form.
// If you do not specify this field, then the container's `ENTRYPOINT` runs,
// in conjunction with the args field or the
// container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd),
// if either exists. If this field is not specified and the container does not
// have an `ENTRYPOINT`, then refer to the Docker documentation about [how
// `CMD` and `ENTRYPOINT`
// interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
// If you specify this field, then you can also specify the `args` field to
// provide additional arguments for this command. However, if you specify this
// field, then the container's `CMD` is ignored. See the
// [Kubernetes documentation about how the
// `command` and `args` fields interact with a container's `ENTRYPOINT` and
// `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
// In this field, you can reference [environment variables set by Vertex
// AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
// and environment variables set in the env field.
// You cannot reference environment variables set in the Docker image. In
// order for environment variables to be expanded, reference them by using the
// following syntax:$(VARIABLE_NAME)
// Note that this differs from Bash variable expansion, which does not use
// parentheses. If a variable cannot be resolved, the reference in the input
// string is used unchanged. To avoid variable expansion, you can escape this
// syntax with `$$`; for example:$$(VARIABLE_NAME)
// This field corresponds to the `command` field of the Kubernetes Containers
// [v1 core
// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) Commands() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) []string {
		if v == nil {
			return nil
		}
		return v.Commands
	}).(pulumi.StringArrayOutput)
}

// Deployment timeout.
// Limit for deployment timeout is 2 hours.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) DeploymentTimeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *string {
		if v == nil {
			return nil
		}
		return v.DeploymentTimeout
	}).(pulumi.StringPtrOutput)
}

// List of environment variables to set in the container. After the container
// starts running, code running in the container can read these environment
// variables.
// Additionally, the command and
// args fields can reference these variables. Later
// entries in this list can also reference earlier entries. For example, the
// following example sets the variable `VAR_2` to have the value `foo bar`:
//
// If you switch the order of the variables in the example, then the expansion
// does not occur.
// This field corresponds to the `env` field of the Kubernetes Containers
// [v1 core
// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) Envs() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv {
		if v == nil {
			return nil
		}
		return v.Envs
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput)
}

// List of ports to expose from the container. Vertex AI sends gRPC
// prediction requests that it receives to the first port on this list. Vertex
// AI also sends liveness and health checks to this port.
// If you do not specify this field, gRPC requests to the container will be
// disabled.
// Vertex AI does not use ports other than the first one listed. This field
// corresponds to the `ports` field of the Kubernetes Containers v1 core API.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) GrpcPorts() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort {
		if v == nil {
			return nil
		}
		return v.GrpcPorts
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput)
}

// Probe describes a health check to be performed against a container to
// determine whether it is alive or ready to receive traffic.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) HealthProbe() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe {
		if v == nil {
			return nil
		}
		return v.HealthProbe
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput)
}

// HTTP path on the container to send health checks to. Vertex AI
// intermittently sends GET requests to this path on the container's IP
// address and port to check that the container is healthy. Read more about
// [health
// checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health).
// For example, if you set this field to `/bar`, then Vertex AI
// intermittently sends a GET request to the `/bar` path on the port of your
// container specified by the first value of this `ModelContainerSpec`'s
// ports field.
// If you don't specify this field, it defaults to the following value when
// you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
// The placeholders in this value are replaced as follows:
//   - ENDPOINT: The last segment (following `endpoints/`)of the
//     Endpoint.name][] field of the Endpoint where this Model has been
//     deployed. (Vertex AI makes this value available to your container code
//     as the [`AIP_ENDPOINT_ID` environment
//     variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
//   - DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
//     (Vertex AI makes this value available to your container code as the
//     [`AIP_DEPLOYED_MODEL_ID` environment
//     variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) HealthRoute() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *string {
		if v == nil {
			return nil
		}
		return v.HealthRoute
	}).(pulumi.StringPtrOutput)
}

// URI of the Docker image to be used as the custom container for serving
// predictions. This URI must identify an image in Artifact Registry or
// Container Registry. Learn more about the [container publishing
// requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing),
// including permissions requirements for the Vertex AI Service Agent.
// The container image is ingested upon ModelService.UploadModel, stored
// internally, and this original path is afterwards not used.
// To learn about the requirements for the Docker image itself, see
// [Custom container
// requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#).
// You can use the URI to one of Vertex AI's [pre-built container images for
// prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)
// in this field.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *string {
		if v == nil {
			return nil
		}
		return &v.ImageUri
	}).(pulumi.StringPtrOutput)
}

// Probe describes a health check to be performed against a container to
// determine whether it is alive or ready to receive traffic.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) LivenessProbe() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe {
		if v == nil {
			return nil
		}
		return v.LivenessProbe
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput)
}

// List of ports to expose from the container. Vertex AI sends any
// prediction requests that it receives to the first port on this list. Vertex
// AI also sends
// [liveness and health
// checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness)
// to this port.
// If you do not specify this field, it defaults to following value:
//
// Vertex AI does not use ports other than the first one listed. This field
// corresponds to the `ports` field of the Kubernetes Containers
// [v1 core
// API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) Ports() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort {
		if v == nil {
			return nil
		}
		return v.Ports
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput)
}

// HTTP path on the container to send prediction requests to. Vertex AI
// forwards requests sent using
// projects.locations.endpoints.predict to this
// path on the container's IP address and port. Vertex AI then returns the
// container's response in the API response.
// For example, if you set this field to `/foo`, then when Vertex AI
// receives a prediction request, it forwards the request body in a POST
// request to the `/foo` path on the port of your container specified by the
// first value of this `ModelContainerSpec`'s
// ports field.
// If you don't specify this field, it defaults to the following value when
// you deploy this Model to an Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict
// The placeholders in this value are replaced as follows:
//   - ENDPOINT: The last segment (following `endpoints/`)of the
//     Endpoint.name][] field of the Endpoint where this Model has been
//     deployed. (Vertex AI makes this value available to your container code
//     as the [`AIP_ENDPOINT_ID` environment
//     variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
//   - DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`.
//     (Vertex AI makes this value available to your container code
//     as the [`AIP_DEPLOYED_MODEL_ID` environment
//     variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) PredictRoute() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *string {
		if v == nil {
			return nil
		}
		return v.PredictRoute
	}).(pulumi.StringPtrOutput)
}

// The amount of the VM memory to reserve as the shared memory for the model
// in megabytes.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) SharedMemorySizeMb() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *string {
		if v == nil {
			return nil
		}
		return v.SharedMemorySizeMb
	}).(pulumi.StringPtrOutput)
}

// Probe describes a health check to be performed against a container to
// determine whether it is alive or ready to receive traffic.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput) StartupProbe() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpec) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe {
		if v == nil {
			return nil
		}
		return v.StartupProbe
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv struct {
	// Name of the environment variable. Must be a valid C identifier.
	Name string `pulumi:"name"`
	// Variables that reference a $(VAR_NAME) are expanded
	// using the previous defined environment variables in the container and
	// any service environment variables. If a variable cannot be resolved,
	// the reference in the input string will be unchanged. The $(VAR_NAME)
	// syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped
	// references will never be expanded, regardless of whether the variable
	// exists or not.
	Value string `pulumi:"value"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArgs struct {
	// Name of the environment variable. Must be a valid C identifier.
	Name pulumi.StringInput `pulumi:"name"`
	// Variables that reference a $(VAR_NAME) are expanded
	// using the previous defined environment variables in the container and
	// any service environment variables. If a variable cannot be resolved,
	// the reference in the input string will be unchanged. The $(VAR_NAME)
	// syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped
	// references will never be expanded, regardless of whether the variable
	// exists or not.
	Value pulumi.StringInput `pulumi:"value"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArray and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArray{ AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArgs{...} }
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArray []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvInput

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArray) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArray) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput {
	return o
}

// Name of the environment variable. Must be a valid C identifier.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv) string { return v.Name }).(pulumi.StringOutput)
}

// Variables that reference a $(VAR_NAME) are expanded
// using the previous defined environment variables in the container and
// any service environment variables. If a variable cannot be resolved,
// the reference in the input string will be unchanged. The $(VAR_NAME)
// syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped
// references will never be expanded, regardless of whether the variable
// exists or not.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput) Value() pulumi.StringOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv) string { return v.Value }).(pulumi.StringOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput) Index(i pulumi.IntInput) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv {
		return vs[0].([]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnv)[vs[1].(int)]
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort struct {
	// The number of the port to expose on the pod's IP address.
	// Must be a valid port number, between 1 and 65535 inclusive.
	ContainerPort *int `pulumi:"containerPort"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArgs struct {
	// The number of the port to expose on the pod's IP address.
	// Must be a valid port number, between 1 and 65535 inclusive.
	ContainerPort pulumi.IntPtrInput `pulumi:"containerPort"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArray and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArray{ AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArgs{...} }
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArray []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortInput

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArray) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArray) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput {
	return o
}

// The number of the port to expose on the pod's IP address.
// Must be a valid port number, between 1 and 65535 inclusive.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput) ContainerPort() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort) *int {
		return v.ContainerPort
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput) Index(i pulumi.IntInput) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort {
		return vs[0].([]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPort)[vs[1].(int)]
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe struct {
	// ExecAction specifies a command to execute.
	// Structure is documented below.
	Exec *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec `pulumi:"exec"`
	// Number of consecutive failures before the probe is considered failed.
	// Defaults to 3. Minimum value is 1.
	// Maps to Kubernetes probe argument 'failureThreshold'.
	FailureThreshold *int `pulumi:"failureThreshold"`
	// GrpcAction checks the health of a container using a gRPC service.
	// Structure is documented below.
	Grpc *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc `pulumi:"grpc"`
	// HttpGetAction describes an action based on HTTP Get requests.
	// Structure is documented below.
	HttpGet *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet `pulumi:"httpGet"`
	// Number of seconds to wait before starting the probe. Defaults to 0.
	// Minimum value is 0.
	// Maps to Kubernetes probe argument 'initialDelaySeconds'.
	InitialDelaySeconds *int `pulumi:"initialDelaySeconds"`
	// How often (in seconds) to perform the probe. Default to 10 seconds.
	// Minimum value is 1. Must be less than timeout_seconds.
	// Maps to Kubernetes probe argument 'periodSeconds'.
	PeriodSeconds *int `pulumi:"periodSeconds"`
	// Number of consecutive successes before the probe is considered successful.
	// Defaults to 1. Minimum value is 1.
	// Maps to Kubernetes probe argument 'successThreshold'.
	SuccessThreshold *int `pulumi:"successThreshold"`
	// TcpSocketAction probes the health of a container by opening a TCP socket
	// connection.
	// Structure is documented below.
	TcpSocket *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket `pulumi:"tcpSocket"`
	// Number of seconds after which the probe times out. Defaults to 1 second.
	// Minimum value is 1. Must be greater or equal to period_seconds.
	// Maps to Kubernetes probe argument 'timeoutSeconds'.
	TimeoutSeconds *int `pulumi:"timeoutSeconds"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs struct {
	// ExecAction specifies a command to execute.
	// Structure is documented below.
	Exec AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrInput `pulumi:"exec"`
	// Number of consecutive failures before the probe is considered failed.
	// Defaults to 3. Minimum value is 1.
	// Maps to Kubernetes probe argument 'failureThreshold'.
	FailureThreshold pulumi.IntPtrInput `pulumi:"failureThreshold"`
	// GrpcAction checks the health of a container using a gRPC service.
	// Structure is documented below.
	Grpc AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrInput `pulumi:"grpc"`
	// HttpGetAction describes an action based on HTTP Get requests.
	// Structure is documented below.
	HttpGet AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrInput `pulumi:"httpGet"`
	// Number of seconds to wait before starting the probe. Defaults to 0.
	// Minimum value is 0.
	// Maps to Kubernetes probe argument 'initialDelaySeconds'.
	InitialDelaySeconds pulumi.IntPtrInput `pulumi:"initialDelaySeconds"`
	// How often (in seconds) to perform the probe. Default to 10 seconds.
	// Minimum value is 1. Must be less than timeout_seconds.
	// Maps to Kubernetes probe argument 'periodSeconds'.
	PeriodSeconds pulumi.IntPtrInput `pulumi:"periodSeconds"`
	// Number of consecutive successes before the probe is considered successful.
	// Defaults to 1. Minimum value is 1.
	// Maps to Kubernetes probe argument 'successThreshold'.
	SuccessThreshold pulumi.IntPtrInput `pulumi:"successThreshold"`
	// TcpSocketAction probes the health of a container by opening a TCP socket
	// connection.
	// Structure is documented below.
	TcpSocket AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrInput `pulumi:"tcpSocket"`
	// Number of seconds after which the probe times out. Defaults to 1 second.
	// Minimum value is 1. Must be greater or equal to period_seconds.
	// Maps to Kubernetes probe argument 'timeoutSeconds'.
	TimeoutSeconds pulumi.IntPtrInput `pulumi:"timeoutSeconds"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput)
}

// ExecAction specifies a command to execute.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) Exec() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec {
		return v.Exec
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput)
}

// Number of consecutive failures before the probe is considered failed.
// Defaults to 3. Minimum value is 1.
// Maps to Kubernetes probe argument 'failureThreshold'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) FailureThreshold() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *int {
		return v.FailureThreshold
	}).(pulumi.IntPtrOutput)
}

// GrpcAction checks the health of a container using a gRPC service.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) Grpc() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc {
		return v.Grpc
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput)
}

// HttpGetAction describes an action based on HTTP Get requests.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) HttpGet() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet {
		return v.HttpGet
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput)
}

// Number of seconds to wait before starting the probe. Defaults to 0.
// Minimum value is 0.
// Maps to Kubernetes probe argument 'initialDelaySeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) InitialDelaySeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *int {
		return v.InitialDelaySeconds
	}).(pulumi.IntPtrOutput)
}

// How often (in seconds) to perform the probe. Default to 10 seconds.
// Minimum value is 1. Must be less than timeout_seconds.
// Maps to Kubernetes probe argument 'periodSeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) PeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *int {
		return v.PeriodSeconds
	}).(pulumi.IntPtrOutput)
}

// Number of consecutive successes before the probe is considered successful.
// Defaults to 1. Minimum value is 1.
// Maps to Kubernetes probe argument 'successThreshold'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) SuccessThreshold() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *int {
		return v.SuccessThreshold
	}).(pulumi.IntPtrOutput)
}

// TcpSocketAction probes the health of a container by opening a TCP socket
// connection.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) TcpSocket() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket {
		return v.TcpSocket
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput)
}

// Number of seconds after which the probe times out. Defaults to 1 second.
// Minimum value is 1. Must be greater or equal to period_seconds.
// Maps to Kubernetes probe argument 'timeoutSeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput) TimeoutSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *int {
		return v.TimeoutSeconds
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput)
}

// ExecAction specifies a command to execute.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) Exec() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec {
		if v == nil {
			return nil
		}
		return v.Exec
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput)
}

// Number of consecutive failures before the probe is considered failed.
// Defaults to 3. Minimum value is 1.
// Maps to Kubernetes probe argument 'failureThreshold'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) FailureThreshold() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *int {
		if v == nil {
			return nil
		}
		return v.FailureThreshold
	}).(pulumi.IntPtrOutput)
}

// GrpcAction checks the health of a container using a gRPC service.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) Grpc() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc {
		if v == nil {
			return nil
		}
		return v.Grpc
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput)
}

// HttpGetAction describes an action based on HTTP Get requests.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) HttpGet() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet {
		if v == nil {
			return nil
		}
		return v.HttpGet
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput)
}

// Number of seconds to wait before starting the probe. Defaults to 0.
// Minimum value is 0.
// Maps to Kubernetes probe argument 'initialDelaySeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) InitialDelaySeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *int {
		if v == nil {
			return nil
		}
		return v.InitialDelaySeconds
	}).(pulumi.IntPtrOutput)
}

// How often (in seconds) to perform the probe. Default to 10 seconds.
// Minimum value is 1. Must be less than timeout_seconds.
// Maps to Kubernetes probe argument 'periodSeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) PeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *int {
		if v == nil {
			return nil
		}
		return v.PeriodSeconds
	}).(pulumi.IntPtrOutput)
}

// Number of consecutive successes before the probe is considered successful.
// Defaults to 1. Minimum value is 1.
// Maps to Kubernetes probe argument 'successThreshold'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) SuccessThreshold() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *int {
		if v == nil {
			return nil
		}
		return v.SuccessThreshold
	}).(pulumi.IntPtrOutput)
}

// TcpSocketAction probes the health of a container by opening a TCP socket
// connection.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) TcpSocket() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket {
		if v == nil {
			return nil
		}
		return v.TcpSocket
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput)
}

// Number of seconds after which the probe times out. Defaults to 1 second.
// Minimum value is 1. Must be greater or equal to period_seconds.
// Maps to Kubernetes probe argument 'timeoutSeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput) TimeoutSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbe) *int {
		if v == nil {
			return nil
		}
		return v.TimeoutSeconds
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec struct {
	// Command is the command line to execute inside the container, the working
	// directory for the command is root ('/') in the container's filesystem.
	// The command is simply exec'd, it is not run inside a shell, so
	// traditional shell instructions ('|', etc) won't work. To use a shell, you
	// need to explicitly call out to that shell. Exit status of 0 is treated as
	// live/healthy and non-zero is unhealthy.
	Commands []string `pulumi:"commands"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs struct {
	// Command is the command line to execute inside the container, the working
	// directory for the command is root ('/') in the container's filesystem.
	// The command is simply exec'd, it is not run inside a shell, so
	// traditional shell instructions ('|', etc) won't work. To use a shell, you
	// need to explicitly call out to that shell. Exit status of 0 is treated as
	// live/healthy and non-zero is unhealthy.
	Commands pulumi.StringArrayInput `pulumi:"commands"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput)
}

// Command is the command line to execute inside the container, the working
// directory for the command is root ('/') in the container's filesystem.
// The command is simply exec'd, it is not run inside a shell, so
// traditional shell instructions ('|', etc) won't work. To use a shell, you
// need to explicitly call out to that shell. Exit status of 0 is treated as
// live/healthy and non-zero is unhealthy.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput) Commands() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec) []string {
		return v.Commands
	}).(pulumi.StringArrayOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput)
}

// Command is the command line to execute inside the container, the working
// directory for the command is root ('/') in the container's filesystem.
// The command is simply exec'd, it is not run inside a shell, so
// traditional shell instructions ('|', etc) won't work. To use a shell, you
// need to explicitly call out to that shell. Exit status of 0 is treated as
// live/healthy and non-zero is unhealthy.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput) Commands() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExec) []string {
		if v == nil {
			return nil
		}
		return v.Commands
	}).(pulumi.StringArrayOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc struct {
	// Port number of the gRPC service. Number must be in the range 1 to 65535.
	Port *int `pulumi:"port"`
	// Service is the name of the service to place in the gRPC
	// HealthCheckRequest. See
	// https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
	// If this is not specified, the default behavior is defined by gRPC.
	Service *string `pulumi:"service"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs struct {
	// Port number of the gRPC service. Number must be in the range 1 to 65535.
	Port pulumi.IntPtrInput `pulumi:"port"`
	// Service is the name of the service to place in the gRPC
	// HealthCheckRequest. See
	// https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
	// If this is not specified, the default behavior is defined by gRPC.
	Service pulumi.StringPtrInput `pulumi:"service"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput)
}

// Port number of the gRPC service. Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc) *int { return v.Port }).(pulumi.IntPtrOutput)
}

// Service is the name of the service to place in the gRPC
// HealthCheckRequest. See
// https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
// If this is not specified, the default behavior is defined by gRPC.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput) Service() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc) *string {
		return v.Service
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput)
}

// Port number of the gRPC service. Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc) *int {
		if v == nil {
			return nil
		}
		return v.Port
	}).(pulumi.IntPtrOutput)
}

// Service is the name of the service to place in the gRPC
// HealthCheckRequest. See
// https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
// If this is not specified, the default behavior is defined by gRPC.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput) Service() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpc) *string {
		if v == nil {
			return nil
		}
		return v.Service
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet struct {
	// Host name to connect to, defaults to the model serving container's IP.
	// You probably want to set "Host" in httpHeaders instead.
	Host *string `pulumi:"host"`
	// Custom headers to set in the request. HTTP allows repeated headers.
	// Structure is documented below.
	HttpHeaders []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeader `pulumi:"httpHeaders"`
	// Path to access on the HTTP server.
	Path *string `pulumi:"path"`
	// Number of the port to access on the container.
	// Number must be in the range 1 to 65535.
	Port *int `pulumi:"port"`
	// Scheme to use for connecting to the host.
	// Defaults to HTTP. Acceptable values are "HTTP" or "HTTPS".
	Scheme *string `pulumi:"scheme"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs struct {
	// Host name to connect to, defaults to the model serving container's IP.
	// You probably want to set "Host" in httpHeaders instead.
	Host pulumi.StringPtrInput `pulumi:"host"`
	// Custom headers to set in the request. HTTP allows repeated headers.
	// Structure is documented below.
	HttpHeaders AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayInput `pulumi:"httpHeaders"`
	// Path to access on the HTTP server.
	Path pulumi.StringPtrInput `pulumi:"path"`
	// Number of the port to access on the container.
	// Number must be in the range 1 to 65535.
	Port pulumi.IntPtrInput `pulumi:"port"`
	// Scheme to use for connecting to the host.
	// Defaults to HTTP. Acceptable values are "HTTP" or "HTTPS".
	Scheme pulumi.StringPtrInput `pulumi:"scheme"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput)
}

// Host name to connect to, defaults to the model serving container's IP.
// You probably want to set "Host" in httpHeaders instead.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput) Host() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet) *string {
		return v.Host
	}).(pulumi.StringPtrOutput)
}

// Custom headers to set in the request. HTTP allows repeated headers.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput) HttpHeaders() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet) []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeader {
		return v.HttpHeaders
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput)
}

// Path to access on the HTTP server.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput) Path() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet) *string {
		return v.Path
	}).(pulumi.StringPtrOutput)
}

// Number of the port to access on the container.
// Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet) *int {
		return v.Port
	}).(pulumi.IntPtrOutput)
}

// Scheme to use for connecting to the host.
// Defaults to HTTP. Acceptable values are "HTTP" or "HTTPS".
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput) Scheme() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet) *string {
		return v.Scheme
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput)
}

// Host name to connect to, defaults to the model serving container's IP.
// You probably want to set "Host" in httpHeaders instead.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput) Host() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet) *string {
		if v == nil {
			return nil
		}
		return v.Host
	}).(pulumi.StringPtrOutput)
}

// Custom headers to set in the request. HTTP allows repeated headers.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput) HttpHeaders() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet) []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeader {
		if v == nil {
			return nil
		}
		return v.HttpHeaders
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput)
}

// Path to access on the HTTP server.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput) Path() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet) *string {
		if v == nil {
			return nil
		}
		return v.Path
	}).(pulumi.StringPtrOutput)
}

// Number of the port to access on the container.
// Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet) *int {
		if v == nil {
			return nil
		}
		return v.Port
	}).(pulumi.IntPtrOutput)
}

// Scheme to use for connecting to the host.
// Defaults to HTTP. Acceptable values are "HTTP" or "HTTPS".
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput) Scheme() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGet) *string {
		if v == nil {
			return nil
		}
		return v.Scheme
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeader struct {
	// The header field name.
	// This will be canonicalized upon output, so case-variant names will be
	// understood as the same header.
	Name *string `pulumi:"name"`
	// The header field value
	Value *string `pulumi:"value"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArgs struct {
	// The header field name.
	// This will be canonicalized upon output, so case-variant names will be
	// understood as the same header.
	Name pulumi.StringPtrInput `pulumi:"name"`
	// The header field value
	Value pulumi.StringPtrInput `pulumi:"value"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeader)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArray and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArray{ AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArgs{...} }
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArray []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderInput

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeader)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArray) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArray) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeader)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput {
	return o
}

// The header field name.
// This will be canonicalized upon output, so case-variant names will be
// understood as the same header.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput) Name() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeader) *string {
		return v.Name
	}).(pulumi.StringPtrOutput)
}

// The header field value
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput) Value() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeader) *string {
		return v.Value
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeader)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput) Index(i pulumi.IntInput) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeader {
		return vs[0].([]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeader)[vs[1].(int)]
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket struct {
	// Optional: Host name to connect to, defaults to the model serving
	// container's IP.
	Host *string `pulumi:"host"`
	// Number of the port to access on the container.
	// Number must be in the range 1 to 65535.
	Port *int `pulumi:"port"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs struct {
	// Optional: Host name to connect to, defaults to the model serving
	// container's IP.
	Host pulumi.StringPtrInput `pulumi:"host"`
	// Number of the port to access on the container.
	// Number must be in the range 1 to 65535.
	Port pulumi.IntPtrInput `pulumi:"port"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput)
}

// Optional: Host name to connect to, defaults to the model serving
// container's IP.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput) Host() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket) *string {
		return v.Host
	}).(pulumi.StringPtrOutput)
}

// Number of the port to access on the container.
// Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket) *int {
		return v.Port
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput)
}

// Optional: Host name to connect to, defaults to the model serving
// container's IP.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput) Host() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket) *string {
		if v == nil {
			return nil
		}
		return v.Host
	}).(pulumi.StringPtrOutput)
}

// Number of the port to access on the container.
// Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocket) *int {
		if v == nil {
			return nil
		}
		return v.Port
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe struct {
	// ExecAction specifies a command to execute.
	// Structure is documented below.
	Exec *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec `pulumi:"exec"`
	// Number of consecutive failures before the probe is considered failed.
	// Defaults to 3. Minimum value is 1.
	// Maps to Kubernetes probe argument 'failureThreshold'.
	FailureThreshold *int `pulumi:"failureThreshold"`
	// GrpcAction checks the health of a container using a gRPC service.
	// Structure is documented below.
	Grpc *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc `pulumi:"grpc"`
	// HttpGetAction describes an action based on HTTP Get requests.
	// Structure is documented below.
	HttpGet *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet `pulumi:"httpGet"`
	// Number of seconds to wait before starting the probe. Defaults to 0.
	// Minimum value is 0.
	// Maps to Kubernetes probe argument 'initialDelaySeconds'.
	InitialDelaySeconds *int `pulumi:"initialDelaySeconds"`
	// How often (in seconds) to perform the probe. Default to 10 seconds.
	// Minimum value is 1. Must be less than timeout_seconds.
	// Maps to Kubernetes probe argument 'periodSeconds'.
	PeriodSeconds *int `pulumi:"periodSeconds"`
	// Number of consecutive successes before the probe is considered successful.
	// Defaults to 1. Minimum value is 1.
	// Maps to Kubernetes probe argument 'successThreshold'.
	SuccessThreshold *int `pulumi:"successThreshold"`
	// TcpSocketAction probes the health of a container by opening a TCP socket
	// connection.
	// Structure is documented below.
	TcpSocket *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket `pulumi:"tcpSocket"`
	// Number of seconds after which the probe times out. Defaults to 1 second.
	// Minimum value is 1. Must be greater or equal to period_seconds.
	// Maps to Kubernetes probe argument 'timeoutSeconds'.
	TimeoutSeconds *int `pulumi:"timeoutSeconds"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs struct {
	// ExecAction specifies a command to execute.
	// Structure is documented below.
	Exec AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrInput `pulumi:"exec"`
	// Number of consecutive failures before the probe is considered failed.
	// Defaults to 3. Minimum value is 1.
	// Maps to Kubernetes probe argument 'failureThreshold'.
	FailureThreshold pulumi.IntPtrInput `pulumi:"failureThreshold"`
	// GrpcAction checks the health of a container using a gRPC service.
	// Structure is documented below.
	Grpc AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrInput `pulumi:"grpc"`
	// HttpGetAction describes an action based on HTTP Get requests.
	// Structure is documented below.
	HttpGet AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrInput `pulumi:"httpGet"`
	// Number of seconds to wait before starting the probe. Defaults to 0.
	// Minimum value is 0.
	// Maps to Kubernetes probe argument 'initialDelaySeconds'.
	InitialDelaySeconds pulumi.IntPtrInput `pulumi:"initialDelaySeconds"`
	// How often (in seconds) to perform the probe. Default to 10 seconds.
	// Minimum value is 1. Must be less than timeout_seconds.
	// Maps to Kubernetes probe argument 'periodSeconds'.
	PeriodSeconds pulumi.IntPtrInput `pulumi:"periodSeconds"`
	// Number of consecutive successes before the probe is considered successful.
	// Defaults to 1. Minimum value is 1.
	// Maps to Kubernetes probe argument 'successThreshold'.
	SuccessThreshold pulumi.IntPtrInput `pulumi:"successThreshold"`
	// TcpSocketAction probes the health of a container by opening a TCP socket
	// connection.
	// Structure is documented below.
	TcpSocket AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrInput `pulumi:"tcpSocket"`
	// Number of seconds after which the probe times out. Defaults to 1 second.
	// Minimum value is 1. Must be greater or equal to period_seconds.
	// Maps to Kubernetes probe argument 'timeoutSeconds'.
	TimeoutSeconds pulumi.IntPtrInput `pulumi:"timeoutSeconds"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput)
}

// ExecAction specifies a command to execute.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) Exec() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec {
		return v.Exec
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput)
}

// Number of consecutive failures before the probe is considered failed.
// Defaults to 3. Minimum value is 1.
// Maps to Kubernetes probe argument 'failureThreshold'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) FailureThreshold() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *int {
		return v.FailureThreshold
	}).(pulumi.IntPtrOutput)
}

// GrpcAction checks the health of a container using a gRPC service.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) Grpc() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc {
		return v.Grpc
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput)
}

// HttpGetAction describes an action based on HTTP Get requests.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) HttpGet() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet {
		return v.HttpGet
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput)
}

// Number of seconds to wait before starting the probe. Defaults to 0.
// Minimum value is 0.
// Maps to Kubernetes probe argument 'initialDelaySeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) InitialDelaySeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *int {
		return v.InitialDelaySeconds
	}).(pulumi.IntPtrOutput)
}

// How often (in seconds) to perform the probe. Default to 10 seconds.
// Minimum value is 1. Must be less than timeout_seconds.
// Maps to Kubernetes probe argument 'periodSeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) PeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *int {
		return v.PeriodSeconds
	}).(pulumi.IntPtrOutput)
}

// Number of consecutive successes before the probe is considered successful.
// Defaults to 1. Minimum value is 1.
// Maps to Kubernetes probe argument 'successThreshold'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) SuccessThreshold() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *int {
		return v.SuccessThreshold
	}).(pulumi.IntPtrOutput)
}

// TcpSocketAction probes the health of a container by opening a TCP socket
// connection.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) TcpSocket() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket {
		return v.TcpSocket
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput)
}

// Number of seconds after which the probe times out. Defaults to 1 second.
// Minimum value is 1. Must be greater or equal to period_seconds.
// Maps to Kubernetes probe argument 'timeoutSeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput) TimeoutSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *int {
		return v.TimeoutSeconds
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput)
}

// ExecAction specifies a command to execute.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) Exec() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec {
		if v == nil {
			return nil
		}
		return v.Exec
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput)
}

// Number of consecutive failures before the probe is considered failed.
// Defaults to 3. Minimum value is 1.
// Maps to Kubernetes probe argument 'failureThreshold'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) FailureThreshold() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *int {
		if v == nil {
			return nil
		}
		return v.FailureThreshold
	}).(pulumi.IntPtrOutput)
}

// GrpcAction checks the health of a container using a gRPC service.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) Grpc() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc {
		if v == nil {
			return nil
		}
		return v.Grpc
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput)
}

// HttpGetAction describes an action based on HTTP Get requests.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) HttpGet() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet {
		if v == nil {
			return nil
		}
		return v.HttpGet
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput)
}

// Number of seconds to wait before starting the probe. Defaults to 0.
// Minimum value is 0.
// Maps to Kubernetes probe argument 'initialDelaySeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) InitialDelaySeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *int {
		if v == nil {
			return nil
		}
		return v.InitialDelaySeconds
	}).(pulumi.IntPtrOutput)
}

// How often (in seconds) to perform the probe. Default to 10 seconds.
// Minimum value is 1. Must be less than timeout_seconds.
// Maps to Kubernetes probe argument 'periodSeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) PeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *int {
		if v == nil {
			return nil
		}
		return v.PeriodSeconds
	}).(pulumi.IntPtrOutput)
}

// Number of consecutive successes before the probe is considered successful.
// Defaults to 1. Minimum value is 1.
// Maps to Kubernetes probe argument 'successThreshold'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) SuccessThreshold() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *int {
		if v == nil {
			return nil
		}
		return v.SuccessThreshold
	}).(pulumi.IntPtrOutput)
}

// TcpSocketAction probes the health of a container by opening a TCP socket
// connection.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) TcpSocket() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket {
		if v == nil {
			return nil
		}
		return v.TcpSocket
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput)
}

// Number of seconds after which the probe times out. Defaults to 1 second.
// Minimum value is 1. Must be greater or equal to period_seconds.
// Maps to Kubernetes probe argument 'timeoutSeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput) TimeoutSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbe) *int {
		if v == nil {
			return nil
		}
		return v.TimeoutSeconds
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec struct {
	// Command is the command line to execute inside the container, the working
	// directory for the command is root ('/') in the container's filesystem.
	// The command is simply exec'd, it is not run inside a shell, so
	// traditional shell instructions ('|', etc) won't work. To use a shell, you
	// need to explicitly call out to that shell. Exit status of 0 is treated as
	// live/healthy and non-zero is unhealthy.
	Commands []string `pulumi:"commands"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs struct {
	// Command is the command line to execute inside the container, the working
	// directory for the command is root ('/') in the container's filesystem.
	// The command is simply exec'd, it is not run inside a shell, so
	// traditional shell instructions ('|', etc) won't work. To use a shell, you
	// need to explicitly call out to that shell. Exit status of 0 is treated as
	// live/healthy and non-zero is unhealthy.
	Commands pulumi.StringArrayInput `pulumi:"commands"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput)
}

// Command is the command line to execute inside the container, the working
// directory for the command is root ('/') in the container's filesystem.
// The command is simply exec'd, it is not run inside a shell, so
// traditional shell instructions ('|', etc) won't work. To use a shell, you
// need to explicitly call out to that shell. Exit status of 0 is treated as
// live/healthy and non-zero is unhealthy.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput) Commands() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec) []string {
		return v.Commands
	}).(pulumi.StringArrayOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput)
}

// Command is the command line to execute inside the container, the working
// directory for the command is root ('/') in the container's filesystem.
// The command is simply exec'd, it is not run inside a shell, so
// traditional shell instructions ('|', etc) won't work. To use a shell, you
// need to explicitly call out to that shell. Exit status of 0 is treated as
// live/healthy and non-zero is unhealthy.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput) Commands() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExec) []string {
		if v == nil {
			return nil
		}
		return v.Commands
	}).(pulumi.StringArrayOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc struct {
	// Port number of the gRPC service. Number must be in the range 1 to 65535.
	Port *int `pulumi:"port"`
	// Service is the name of the service to place in the gRPC
	// HealthCheckRequest. See
	// https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
	// If this is not specified, the default behavior is defined by gRPC.
	Service *string `pulumi:"service"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs struct {
	// Port number of the gRPC service. Number must be in the range 1 to 65535.
	Port pulumi.IntPtrInput `pulumi:"port"`
	// Service is the name of the service to place in the gRPC
	// HealthCheckRequest. See
	// https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
	// If this is not specified, the default behavior is defined by gRPC.
	Service pulumi.StringPtrInput `pulumi:"service"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput)
}

// Port number of the gRPC service. Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc) *int {
		return v.Port
	}).(pulumi.IntPtrOutput)
}

// Service is the name of the service to place in the gRPC
// HealthCheckRequest. See
// https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
// If this is not specified, the default behavior is defined by gRPC.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput) Service() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc) *string {
		return v.Service
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput)
}

// Port number of the gRPC service. Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc) *int {
		if v == nil {
			return nil
		}
		return v.Port
	}).(pulumi.IntPtrOutput)
}

// Service is the name of the service to place in the gRPC
// HealthCheckRequest. See
// https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
// If this is not specified, the default behavior is defined by gRPC.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput) Service() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpc) *string {
		if v == nil {
			return nil
		}
		return v.Service
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet struct {
	// Host name to connect to, defaults to the model serving container's IP.
	// You probably want to set "Host" in httpHeaders instead.
	Host *string `pulumi:"host"`
	// Custom headers to set in the request. HTTP allows repeated headers.
	// Structure is documented below.
	HttpHeaders []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeader `pulumi:"httpHeaders"`
	// Path to access on the HTTP server.
	Path *string `pulumi:"path"`
	// Number of the port to access on the container.
	// Number must be in the range 1 to 65535.
	Port *int `pulumi:"port"`
	// Scheme to use for connecting to the host.
	// Defaults to HTTP. Acceptable values are "HTTP" or "HTTPS".
	Scheme *string `pulumi:"scheme"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs struct {
	// Host name to connect to, defaults to the model serving container's IP.
	// You probably want to set "Host" in httpHeaders instead.
	Host pulumi.StringPtrInput `pulumi:"host"`
	// Custom headers to set in the request. HTTP allows repeated headers.
	// Structure is documented below.
	HttpHeaders AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayInput `pulumi:"httpHeaders"`
	// Path to access on the HTTP server.
	Path pulumi.StringPtrInput `pulumi:"path"`
	// Number of the port to access on the container.
	// Number must be in the range 1 to 65535.
	Port pulumi.IntPtrInput `pulumi:"port"`
	// Scheme to use for connecting to the host.
	// Defaults to HTTP. Acceptable values are "HTTP" or "HTTPS".
	Scheme pulumi.StringPtrInput `pulumi:"scheme"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput)
}

// Host name to connect to, defaults to the model serving container's IP.
// You probably want to set "Host" in httpHeaders instead.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput) Host() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet) *string {
		return v.Host
	}).(pulumi.StringPtrOutput)
}

// Custom headers to set in the request. HTTP allows repeated headers.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput) HttpHeaders() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet) []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeader {
		return v.HttpHeaders
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput)
}

// Path to access on the HTTP server.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput) Path() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet) *string {
		return v.Path
	}).(pulumi.StringPtrOutput)
}

// Number of the port to access on the container.
// Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet) *int {
		return v.Port
	}).(pulumi.IntPtrOutput)
}

// Scheme to use for connecting to the host.
// Defaults to HTTP. Acceptable values are "HTTP" or "HTTPS".
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput) Scheme() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet) *string {
		return v.Scheme
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput)
}

// Host name to connect to, defaults to the model serving container's IP.
// You probably want to set "Host" in httpHeaders instead.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput) Host() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet) *string {
		if v == nil {
			return nil
		}
		return v.Host
	}).(pulumi.StringPtrOutput)
}

// Custom headers to set in the request. HTTP allows repeated headers.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput) HttpHeaders() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet) []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeader {
		if v == nil {
			return nil
		}
		return v.HttpHeaders
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput)
}

// Path to access on the HTTP server.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput) Path() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet) *string {
		if v == nil {
			return nil
		}
		return v.Path
	}).(pulumi.StringPtrOutput)
}

// Number of the port to access on the container.
// Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet) *int {
		if v == nil {
			return nil
		}
		return v.Port
	}).(pulumi.IntPtrOutput)
}

// Scheme to use for connecting to the host.
// Defaults to HTTP. Acceptable values are "HTTP" or "HTTPS".
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput) Scheme() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGet) *string {
		if v == nil {
			return nil
		}
		return v.Scheme
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeader struct {
	// The header field name.
	// This will be canonicalized upon output, so case-variant names will be
	// understood as the same header.
	Name *string `pulumi:"name"`
	// The header field value
	Value *string `pulumi:"value"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArgs struct {
	// The header field name.
	// This will be canonicalized upon output, so case-variant names will be
	// understood as the same header.
	Name pulumi.StringPtrInput `pulumi:"name"`
	// The header field value
	Value pulumi.StringPtrInput `pulumi:"value"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeader)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArray and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArray{ AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArgs{...} }
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArray []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderInput

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeader)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArray) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArray) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeader)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput {
	return o
}

// The header field name.
// This will be canonicalized upon output, so case-variant names will be
// understood as the same header.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput) Name() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeader) *string {
		return v.Name
	}).(pulumi.StringPtrOutput)
}

// The header field value
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput) Value() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeader) *string {
		return v.Value
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeader)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput) Index(i pulumi.IntInput) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeader {
		return vs[0].([]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeader)[vs[1].(int)]
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket struct {
	// Optional: Host name to connect to, defaults to the model serving
	// container's IP.
	Host *string `pulumi:"host"`
	// Number of the port to access on the container.
	// Number must be in the range 1 to 65535.
	Port *int `pulumi:"port"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs struct {
	// Optional: Host name to connect to, defaults to the model serving
	// container's IP.
	Host pulumi.StringPtrInput `pulumi:"host"`
	// Number of the port to access on the container.
	// Number must be in the range 1 to 65535.
	Port pulumi.IntPtrInput `pulumi:"port"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput)
}

// Optional: Host name to connect to, defaults to the model serving
// container's IP.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput) Host() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket) *string {
		return v.Host
	}).(pulumi.StringPtrOutput)
}

// Number of the port to access on the container.
// Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket) *int {
		return v.Port
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput)
}

// Optional: Host name to connect to, defaults to the model serving
// container's IP.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput) Host() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket) *string {
		if v == nil {
			return nil
		}
		return v.Host
	}).(pulumi.StringPtrOutput)
}

// Number of the port to access on the container.
// Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocket) *int {
		if v == nil {
			return nil
		}
		return v.Port
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort struct {
	// The number of the port to expose on the pod's IP address.
	// Must be a valid port number, between 1 and 65535 inclusive.
	ContainerPort *int `pulumi:"containerPort"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArgs struct {
	// The number of the port to expose on the pod's IP address.
	// Must be a valid port number, between 1 and 65535 inclusive.
	ContainerPort pulumi.IntPtrInput `pulumi:"containerPort"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArray and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArray{ AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArgs{...} }
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArray []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortInput

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArray) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArray) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput {
	return o
}

// The number of the port to expose on the pod's IP address.
// Must be a valid port number, between 1 and 65535 inclusive.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput) ContainerPort() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort) *int { return v.ContainerPort }).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput) Index(i pulumi.IntInput) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort {
		return vs[0].([]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPort)[vs[1].(int)]
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe struct {
	// ExecAction specifies a command to execute.
	// Structure is documented below.
	Exec *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec `pulumi:"exec"`
	// Number of consecutive failures before the probe is considered failed.
	// Defaults to 3. Minimum value is 1.
	// Maps to Kubernetes probe argument 'failureThreshold'.
	FailureThreshold *int `pulumi:"failureThreshold"`
	// GrpcAction checks the health of a container using a gRPC service.
	// Structure is documented below.
	Grpc *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc `pulumi:"grpc"`
	// HttpGetAction describes an action based on HTTP Get requests.
	// Structure is documented below.
	HttpGet *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet `pulumi:"httpGet"`
	// Number of seconds to wait before starting the probe. Defaults to 0.
	// Minimum value is 0.
	// Maps to Kubernetes probe argument 'initialDelaySeconds'.
	InitialDelaySeconds *int `pulumi:"initialDelaySeconds"`
	// How often (in seconds) to perform the probe. Default to 10 seconds.
	// Minimum value is 1. Must be less than timeout_seconds.
	// Maps to Kubernetes probe argument 'periodSeconds'.
	PeriodSeconds *int `pulumi:"periodSeconds"`
	// Number of consecutive successes before the probe is considered successful.
	// Defaults to 1. Minimum value is 1.
	// Maps to Kubernetes probe argument 'successThreshold'.
	SuccessThreshold *int `pulumi:"successThreshold"`
	// TcpSocketAction probes the health of a container by opening a TCP socket
	// connection.
	// Structure is documented below.
	TcpSocket *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket `pulumi:"tcpSocket"`
	// Number of seconds after which the probe times out. Defaults to 1 second.
	// Minimum value is 1. Must be greater or equal to period_seconds.
	// Maps to Kubernetes probe argument 'timeoutSeconds'.
	TimeoutSeconds *int `pulumi:"timeoutSeconds"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs struct {
	// ExecAction specifies a command to execute.
	// Structure is documented below.
	Exec AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrInput `pulumi:"exec"`
	// Number of consecutive failures before the probe is considered failed.
	// Defaults to 3. Minimum value is 1.
	// Maps to Kubernetes probe argument 'failureThreshold'.
	FailureThreshold pulumi.IntPtrInput `pulumi:"failureThreshold"`
	// GrpcAction checks the health of a container using a gRPC service.
	// Structure is documented below.
	Grpc AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrInput `pulumi:"grpc"`
	// HttpGetAction describes an action based on HTTP Get requests.
	// Structure is documented below.
	HttpGet AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrInput `pulumi:"httpGet"`
	// Number of seconds to wait before starting the probe. Defaults to 0.
	// Minimum value is 0.
	// Maps to Kubernetes probe argument 'initialDelaySeconds'.
	InitialDelaySeconds pulumi.IntPtrInput `pulumi:"initialDelaySeconds"`
	// How often (in seconds) to perform the probe. Default to 10 seconds.
	// Minimum value is 1. Must be less than timeout_seconds.
	// Maps to Kubernetes probe argument 'periodSeconds'.
	PeriodSeconds pulumi.IntPtrInput `pulumi:"periodSeconds"`
	// Number of consecutive successes before the probe is considered successful.
	// Defaults to 1. Minimum value is 1.
	// Maps to Kubernetes probe argument 'successThreshold'.
	SuccessThreshold pulumi.IntPtrInput `pulumi:"successThreshold"`
	// TcpSocketAction probes the health of a container by opening a TCP socket
	// connection.
	// Structure is documented below.
	TcpSocket AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrInput `pulumi:"tcpSocket"`
	// Number of seconds after which the probe times out. Defaults to 1 second.
	// Minimum value is 1. Must be greater or equal to period_seconds.
	// Maps to Kubernetes probe argument 'timeoutSeconds'.
	TimeoutSeconds pulumi.IntPtrInput `pulumi:"timeoutSeconds"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput)
}

// ExecAction specifies a command to execute.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) Exec() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec {
		return v.Exec
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput)
}

// Number of consecutive failures before the probe is considered failed.
// Defaults to 3. Minimum value is 1.
// Maps to Kubernetes probe argument 'failureThreshold'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) FailureThreshold() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *int {
		return v.FailureThreshold
	}).(pulumi.IntPtrOutput)
}

// GrpcAction checks the health of a container using a gRPC service.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) Grpc() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc {
		return v.Grpc
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput)
}

// HttpGetAction describes an action based on HTTP Get requests.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) HttpGet() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet {
		return v.HttpGet
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput)
}

// Number of seconds to wait before starting the probe. Defaults to 0.
// Minimum value is 0.
// Maps to Kubernetes probe argument 'initialDelaySeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) InitialDelaySeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *int {
		return v.InitialDelaySeconds
	}).(pulumi.IntPtrOutput)
}

// How often (in seconds) to perform the probe. Default to 10 seconds.
// Minimum value is 1. Must be less than timeout_seconds.
// Maps to Kubernetes probe argument 'periodSeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) PeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *int {
		return v.PeriodSeconds
	}).(pulumi.IntPtrOutput)
}

// Number of consecutive successes before the probe is considered successful.
// Defaults to 1. Minimum value is 1.
// Maps to Kubernetes probe argument 'successThreshold'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) SuccessThreshold() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *int {
		return v.SuccessThreshold
	}).(pulumi.IntPtrOutput)
}

// TcpSocketAction probes the health of a container by opening a TCP socket
// connection.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) TcpSocket() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket {
		return v.TcpSocket
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput)
}

// Number of seconds after which the probe times out. Defaults to 1 second.
// Minimum value is 1. Must be greater or equal to period_seconds.
// Maps to Kubernetes probe argument 'timeoutSeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput) TimeoutSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *int {
		return v.TimeoutSeconds
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput)
}

// ExecAction specifies a command to execute.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) Exec() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec {
		if v == nil {
			return nil
		}
		return v.Exec
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput)
}

// Number of consecutive failures before the probe is considered failed.
// Defaults to 3. Minimum value is 1.
// Maps to Kubernetes probe argument 'failureThreshold'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) FailureThreshold() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *int {
		if v == nil {
			return nil
		}
		return v.FailureThreshold
	}).(pulumi.IntPtrOutput)
}

// GrpcAction checks the health of a container using a gRPC service.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) Grpc() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc {
		if v == nil {
			return nil
		}
		return v.Grpc
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput)
}

// HttpGetAction describes an action based on HTTP Get requests.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) HttpGet() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet {
		if v == nil {
			return nil
		}
		return v.HttpGet
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput)
}

// Number of seconds to wait before starting the probe. Defaults to 0.
// Minimum value is 0.
// Maps to Kubernetes probe argument 'initialDelaySeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) InitialDelaySeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *int {
		if v == nil {
			return nil
		}
		return v.InitialDelaySeconds
	}).(pulumi.IntPtrOutput)
}

// How often (in seconds) to perform the probe. Default to 10 seconds.
// Minimum value is 1. Must be less than timeout_seconds.
// Maps to Kubernetes probe argument 'periodSeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) PeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *int {
		if v == nil {
			return nil
		}
		return v.PeriodSeconds
	}).(pulumi.IntPtrOutput)
}

// Number of consecutive successes before the probe is considered successful.
// Defaults to 1. Minimum value is 1.
// Maps to Kubernetes probe argument 'successThreshold'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) SuccessThreshold() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *int {
		if v == nil {
			return nil
		}
		return v.SuccessThreshold
	}).(pulumi.IntPtrOutput)
}

// TcpSocketAction probes the health of a container by opening a TCP socket
// connection.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) TcpSocket() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket {
		if v == nil {
			return nil
		}
		return v.TcpSocket
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput)
}

// Number of seconds after which the probe times out. Defaults to 1 second.
// Minimum value is 1. Must be greater or equal to period_seconds.
// Maps to Kubernetes probe argument 'timeoutSeconds'.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput) TimeoutSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbe) *int {
		if v == nil {
			return nil
		}
		return v.TimeoutSeconds
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec struct {
	// Command is the command line to execute inside the container, the working
	// directory for the command is root ('/') in the container's filesystem.
	// The command is simply exec'd, it is not run inside a shell, so
	// traditional shell instructions ('|', etc) won't work. To use a shell, you
	// need to explicitly call out to that shell. Exit status of 0 is treated as
	// live/healthy and non-zero is unhealthy.
	Commands []string `pulumi:"commands"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs struct {
	// Command is the command line to execute inside the container, the working
	// directory for the command is root ('/') in the container's filesystem.
	// The command is simply exec'd, it is not run inside a shell, so
	// traditional shell instructions ('|', etc) won't work. To use a shell, you
	// need to explicitly call out to that shell. Exit status of 0 is treated as
	// live/healthy and non-zero is unhealthy.
	Commands pulumi.StringArrayInput `pulumi:"commands"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput)
}

// Command is the command line to execute inside the container, the working
// directory for the command is root ('/') in the container's filesystem.
// The command is simply exec'd, it is not run inside a shell, so
// traditional shell instructions ('|', etc) won't work. To use a shell, you
// need to explicitly call out to that shell. Exit status of 0 is treated as
// live/healthy and non-zero is unhealthy.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput) Commands() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec) []string {
		return v.Commands
	}).(pulumi.StringArrayOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput)
}

// Command is the command line to execute inside the container, the working
// directory for the command is root ('/') in the container's filesystem.
// The command is simply exec'd, it is not run inside a shell, so
// traditional shell instructions ('|', etc) won't work. To use a shell, you
// need to explicitly call out to that shell. Exit status of 0 is treated as
// live/healthy and non-zero is unhealthy.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput) Commands() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExec) []string {
		if v == nil {
			return nil
		}
		return v.Commands
	}).(pulumi.StringArrayOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc struct {
	// Port number of the gRPC service. Number must be in the range 1 to 65535.
	Port *int `pulumi:"port"`
	// Service is the name of the service to place in the gRPC
	// HealthCheckRequest. See
	// https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
	// If this is not specified, the default behavior is defined by gRPC.
	Service *string `pulumi:"service"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs struct {
	// Port number of the gRPC service. Number must be in the range 1 to 65535.
	Port pulumi.IntPtrInput `pulumi:"port"`
	// Service is the name of the service to place in the gRPC
	// HealthCheckRequest. See
	// https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
	// If this is not specified, the default behavior is defined by gRPC.
	Service pulumi.StringPtrInput `pulumi:"service"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput)
}

// Port number of the gRPC service. Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc) *int {
		return v.Port
	}).(pulumi.IntPtrOutput)
}

// Service is the name of the service to place in the gRPC
// HealthCheckRequest. See
// https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
// If this is not specified, the default behavior is defined by gRPC.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput) Service() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc) *string {
		return v.Service
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput)
}

// Port number of the gRPC service. Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc) *int {
		if v == nil {
			return nil
		}
		return v.Port
	}).(pulumi.IntPtrOutput)
}

// Service is the name of the service to place in the gRPC
// HealthCheckRequest. See
// https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
// If this is not specified, the default behavior is defined by gRPC.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput) Service() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpc) *string {
		if v == nil {
			return nil
		}
		return v.Service
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet struct {
	// Host name to connect to, defaults to the model serving container's IP.
	// You probably want to set "Host" in httpHeaders instead.
	Host *string `pulumi:"host"`
	// Custom headers to set in the request. HTTP allows repeated headers.
	// Structure is documented below.
	HttpHeaders []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeader `pulumi:"httpHeaders"`
	// Path to access on the HTTP server.
	Path *string `pulumi:"path"`
	// Number of the port to access on the container.
	// Number must be in the range 1 to 65535.
	Port *int `pulumi:"port"`
	// Scheme to use for connecting to the host.
	// Defaults to HTTP. Acceptable values are "HTTP" or "HTTPS".
	Scheme *string `pulumi:"scheme"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs struct {
	// Host name to connect to, defaults to the model serving container's IP.
	// You probably want to set "Host" in httpHeaders instead.
	Host pulumi.StringPtrInput `pulumi:"host"`
	// Custom headers to set in the request. HTTP allows repeated headers.
	// Structure is documented below.
	HttpHeaders AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayInput `pulumi:"httpHeaders"`
	// Path to access on the HTTP server.
	Path pulumi.StringPtrInput `pulumi:"path"`
	// Number of the port to access on the container.
	// Number must be in the range 1 to 65535.
	Port pulumi.IntPtrInput `pulumi:"port"`
	// Scheme to use for connecting to the host.
	// Defaults to HTTP. Acceptable values are "HTTP" or "HTTPS".
	Scheme pulumi.StringPtrInput `pulumi:"scheme"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput)
}

// Host name to connect to, defaults to the model serving container's IP.
// You probably want to set "Host" in httpHeaders instead.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput) Host() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet) *string {
		return v.Host
	}).(pulumi.StringPtrOutput)
}

// Custom headers to set in the request. HTTP allows repeated headers.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput) HttpHeaders() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet) []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeader {
		return v.HttpHeaders
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput)
}

// Path to access on the HTTP server.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput) Path() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet) *string {
		return v.Path
	}).(pulumi.StringPtrOutput)
}

// Number of the port to access on the container.
// Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet) *int {
		return v.Port
	}).(pulumi.IntPtrOutput)
}

// Scheme to use for connecting to the host.
// Defaults to HTTP. Acceptable values are "HTTP" or "HTTPS".
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput) Scheme() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet) *string {
		return v.Scheme
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput)
}

// Host name to connect to, defaults to the model serving container's IP.
// You probably want to set "Host" in httpHeaders instead.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput) Host() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet) *string {
		if v == nil {
			return nil
		}
		return v.Host
	}).(pulumi.StringPtrOutput)
}

// Custom headers to set in the request. HTTP allows repeated headers.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput) HttpHeaders() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet) []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeader {
		if v == nil {
			return nil
		}
		return v.HttpHeaders
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput)
}

// Path to access on the HTTP server.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput) Path() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet) *string {
		if v == nil {
			return nil
		}
		return v.Path
	}).(pulumi.StringPtrOutput)
}

// Number of the port to access on the container.
// Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet) *int {
		if v == nil {
			return nil
		}
		return v.Port
	}).(pulumi.IntPtrOutput)
}

// Scheme to use for connecting to the host.
// Defaults to HTTP. Acceptable values are "HTTP" or "HTTPS".
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput) Scheme() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGet) *string {
		if v == nil {
			return nil
		}
		return v.Scheme
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeader struct {
	// The header field name.
	// This will be canonicalized upon output, so case-variant names will be
	// understood as the same header.
	Name *string `pulumi:"name"`
	// The header field value
	Value *string `pulumi:"value"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArgs struct {
	// The header field name.
	// This will be canonicalized upon output, so case-variant names will be
	// understood as the same header.
	Name pulumi.StringPtrInput `pulumi:"name"`
	// The header field value
	Value pulumi.StringPtrInput `pulumi:"value"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeader)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArray and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArray{ AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArgs{...} }
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArray []AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderInput

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeader)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArray) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArray) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeader)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput {
	return o
}

// The header field name.
// This will be canonicalized upon output, so case-variant names will be
// understood as the same header.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput) Name() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeader) *string {
		return v.Name
	}).(pulumi.StringPtrOutput)
}

// The header field value
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput) Value() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeader) *string {
		return v.Value
	}).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeader)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput) Index(i pulumi.IntInput) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeader {
		return vs[0].([]AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeader)[vs[1].(int)]
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket struct {
	// Optional: Host name to connect to, defaults to the model serving
	// container's IP.
	Host *string `pulumi:"host"`
	// Number of the port to access on the container.
	// Number must be in the range 1 to 65535.
	Port *int `pulumi:"port"`
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketInput` via:
//
//	AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs{...}
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs struct {
	// Optional: Host name to connect to, defaults to the model serving
	// container's IP.
	Host pulumi.StringPtrInput `pulumi:"host"`
	// Number of the port to access on the container.
	// Number must be in the range 1 to 65535.
	Port pulumi.IntPtrInput `pulumi:"port"`
}

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput)
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput).ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutputWithContext(ctx)
}

// AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrInput is an input type that accepts AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs, AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtr and AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrInput` via:
//
//	        AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs{...}
//
//	or:
//
//	        nil
type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput
	ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput
}

type aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrType AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs

func AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtr(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrInput {
	return (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrType)(v)
}

func (*aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket)(nil)).Elem()
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput {
	return i.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutputWithContext(context.Background())
}

func (i *aiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrType) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput {
	return o.ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutputWithContext(context.Background())
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket) *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket {
		return &v
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput)
}

// Optional: Host name to connect to, defaults to the model serving
// container's IP.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput) Host() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket) *string {
		return v.Host
	}).(pulumi.StringPtrOutput)
}

// Number of the port to access on the container.
// Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket) *int {
		return v.Port
	}).(pulumi.IntPtrOutput)
}

type AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput) ToAiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput) Elem() AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket) AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket {
		if v != nil {
			return *v
		}
		var ret AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket
		return ret
	}).(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput)
}

// Optional: Host name to connect to, defaults to the model serving
// container's IP.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput) Host() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket) *string {
		if v == nil {
			return nil
		}
		return v.Host
	}).(pulumi.StringPtrOutput)
}

// Number of the port to access on the container.
// Number must be in the range 1 to 65535.
func (o AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput) Port() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocket) *int {
		if v == nil {
			return nil
		}
		return v.Port
	}).(pulumi.IntPtrOutput)
}

type AiFeatureGroupBigQuery struct {
	// The BigQuery source URI that points to either a BigQuery Table or View.
	// Structure is documented below.
	BigQuerySource AiFeatureGroupBigQueryBigQuerySource `pulumi:"bigQuerySource"`
	// Columns to construct entityId / row keys. If not provided defaults to entityId.
	EntityIdColumns []string `pulumi:"entityIdColumns"`
}

// AiFeatureGroupBigQueryInput is an input type that accepts AiFeatureGroupBigQueryArgs and AiFeatureGroupBigQueryOutput values.
// You can construct a concrete instance of `AiFeatureGroupBigQueryInput` via:
//
//	AiFeatureGroupBigQueryArgs{...}
type AiFeatureGroupBigQueryInput interface {
	pulumi.Input

	ToAiFeatureGroupBigQueryOutput() AiFeatureGroupBigQueryOutput
	ToAiFeatureGroupBigQueryOutputWithContext(context.Context) AiFeatureGroupBigQueryOutput
}

type AiFeatureGroupBigQueryArgs struct {
	// The BigQuery source URI that points to either a BigQuery Table or View.
	// Structure is documented below.
	BigQuerySource AiFeatureGroupBigQueryBigQuerySourceInput `pulumi:"bigQuerySource"`
	// Columns to construct entityId / row keys. If not provided defaults to entityId.
	EntityIdColumns pulumi.StringArrayInput `pulumi:"entityIdColumns"`
}

func (AiFeatureGroupBigQueryArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureGroupBigQuery)(nil)).Elem()
}

func (i AiFeatureGroupBigQueryArgs) ToAiFeatureGroupBigQueryOutput() AiFeatureGroupBigQueryOutput {
	return i.ToAiFeatureGroupBigQueryOutputWithContext(context.Background())
}

func (i AiFeatureGroupBigQueryArgs) ToAiFeatureGroupBigQueryOutputWithContext(ctx context.Context) AiFeatureGroupBigQueryOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureGroupBigQueryOutput)
}

func (i AiFeatureGroupBigQueryArgs) ToAiFeatureGroupBigQueryPtrOutput() AiFeatureGroupBigQueryPtrOutput {
	return i.ToAiFeatureGroupBigQueryPtrOutputWithContext(context.Background())
}

func (i AiFeatureGroupBigQueryArgs) ToAiFeatureGroupBigQueryPtrOutputWithContext(ctx context.Context) AiFeatureGroupBigQueryPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureGroupBigQueryOutput).ToAiFeatureGroupBigQueryPtrOutputWithContext(ctx)
}

// AiFeatureGroupBigQueryPtrInput is an input type that accepts AiFeatureGroupBigQueryArgs, AiFeatureGroupBigQueryPtr and AiFeatureGroupBigQueryPtrOutput values.
// You can construct a concrete instance of `AiFeatureGroupBigQueryPtrInput` via:
//
//	        AiFeatureGroupBigQueryArgs{...}
//
//	or:
//
//	        nil
type AiFeatureGroupBigQueryPtrInput interface {
	pulumi.Input

	ToAiFeatureGroupBigQueryPtrOutput() AiFeatureGroupBigQueryPtrOutput
	ToAiFeatureGroupBigQueryPtrOutputWithContext(context.Context) AiFeatureGroupBigQueryPtrOutput
}

type aiFeatureGroupBigQueryPtrType AiFeatureGroupBigQueryArgs

func AiFeatureGroupBigQueryPtr(v *AiFeatureGroupBigQueryArgs) AiFeatureGroupBigQueryPtrInput {
	return (*aiFeatureGroupBigQueryPtrType)(v)
}

func (*aiFeatureGroupBigQueryPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureGroupBigQuery)(nil)).Elem()
}

func (i *aiFeatureGroupBigQueryPtrType) ToAiFeatureGroupBigQueryPtrOutput() AiFeatureGroupBigQueryPtrOutput {
	return i.ToAiFeatureGroupBigQueryPtrOutputWithContext(context.Background())
}

func (i *aiFeatureGroupBigQueryPtrType) ToAiFeatureGroupBigQueryPtrOutputWithContext(ctx context.Context) AiFeatureGroupBigQueryPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureGroupBigQueryPtrOutput)
}

type AiFeatureGroupBigQueryOutput struct{ *pulumi.OutputState }

func (AiFeatureGroupBigQueryOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureGroupBigQuery)(nil)).Elem()
}

func (o AiFeatureGroupBigQueryOutput) ToAiFeatureGroupBigQueryOutput() AiFeatureGroupBigQueryOutput {
	return o
}

func (o AiFeatureGroupBigQueryOutput) ToAiFeatureGroupBigQueryOutputWithContext(ctx context.Context) AiFeatureGroupBigQueryOutput {
	return o
}

func (o AiFeatureGroupBigQueryOutput) ToAiFeatureGroupBigQueryPtrOutput() AiFeatureGroupBigQueryPtrOutput {
	return o.ToAiFeatureGroupBigQueryPtrOutputWithContext(context.Background())
}

func (o AiFeatureGroupBigQueryOutput) ToAiFeatureGroupBigQueryPtrOutputWithContext(ctx context.Context) AiFeatureGroupBigQueryPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureGroupBigQuery) *AiFeatureGroupBigQuery {
		return &v
	}).(AiFeatureGroupBigQueryPtrOutput)
}

// The BigQuery source URI that points to either a BigQuery Table or View.
// Structure is documented below.
func (o AiFeatureGroupBigQueryOutput) BigQuerySource() AiFeatureGroupBigQueryBigQuerySourceOutput {
	return o.ApplyT(func(v AiFeatureGroupBigQuery) AiFeatureGroupBigQueryBigQuerySource { return v.BigQuerySource }).(AiFeatureGroupBigQueryBigQuerySourceOutput)
}

// Columns to construct entityId / row keys. If not provided defaults to entityId.
func (o AiFeatureGroupBigQueryOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiFeatureGroupBigQuery) []string { return v.EntityIdColumns }).(pulumi.StringArrayOutput)
}

type AiFeatureGroupBigQueryPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureGroupBigQueryPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureGroupBigQuery)(nil)).Elem()
}

func (o AiFeatureGroupBigQueryPtrOutput) ToAiFeatureGroupBigQueryPtrOutput() AiFeatureGroupBigQueryPtrOutput {
	return o
}

func (o AiFeatureGroupBigQueryPtrOutput) ToAiFeatureGroupBigQueryPtrOutputWithContext(ctx context.Context) AiFeatureGroupBigQueryPtrOutput {
	return o
}

func (o AiFeatureGroupBigQueryPtrOutput) Elem() AiFeatureGroupBigQueryOutput {
	return o.ApplyT(func(v *AiFeatureGroupBigQuery) AiFeatureGroupBigQuery {
		if v != nil {
			return *v
		}
		var ret AiFeatureGroupBigQuery
		return ret
	}).(AiFeatureGroupBigQueryOutput)
}

// The BigQuery source URI that points to either a BigQuery Table or View.
// Structure is documented below.
func (o AiFeatureGroupBigQueryPtrOutput) BigQuerySource() AiFeatureGroupBigQueryBigQuerySourcePtrOutput {
	return o.ApplyT(func(v *AiFeatureGroupBigQuery) *AiFeatureGroupBigQueryBigQuerySource {
		if v == nil {
			return nil
		}
		return &v.BigQuerySource
	}).(AiFeatureGroupBigQueryBigQuerySourcePtrOutput)
}

// Columns to construct entityId / row keys. If not provided defaults to entityId.
func (o AiFeatureGroupBigQueryPtrOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiFeatureGroupBigQuery) []string {
		if v == nil {
			return nil
		}
		return v.EntityIdColumns
	}).(pulumi.StringArrayOutput)
}

type AiFeatureGroupBigQueryBigQuerySource struct {
	// BigQuery URI to a table, up to 2000 characters long. For example: `bq://projectId.bqDatasetId.bqTableId.`
	InputUri string `pulumi:"inputUri"`
}

// AiFeatureGroupBigQueryBigQuerySourceInput is an input type that accepts AiFeatureGroupBigQueryBigQuerySourceArgs and AiFeatureGroupBigQueryBigQuerySourceOutput values.
// You can construct a concrete instance of `AiFeatureGroupBigQueryBigQuerySourceInput` via:
//
//	AiFeatureGroupBigQueryBigQuerySourceArgs{...}
type AiFeatureGroupBigQueryBigQuerySourceInput interface {
	pulumi.Input

	ToAiFeatureGroupBigQueryBigQuerySourceOutput() AiFeatureGroupBigQueryBigQuerySourceOutput
	ToAiFeatureGroupBigQueryBigQuerySourceOutputWithContext(context.Context) AiFeatureGroupBigQueryBigQuerySourceOutput
}

type AiFeatureGroupBigQueryBigQuerySourceArgs struct {
	// BigQuery URI to a table, up to 2000 characters long. For example: `bq://projectId.bqDatasetId.bqTableId.`
	InputUri pulumi.StringInput `pulumi:"inputUri"`
}

func (AiFeatureGroupBigQueryBigQuerySourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureGroupBigQueryBigQuerySource)(nil)).Elem()
}

func (i AiFeatureGroupBigQueryBigQuerySourceArgs) ToAiFeatureGroupBigQueryBigQuerySourceOutput() AiFeatureGroupBigQueryBigQuerySourceOutput {
	return i.ToAiFeatureGroupBigQueryBigQuerySourceOutputWithContext(context.Background())
}

func (i AiFeatureGroupBigQueryBigQuerySourceArgs) ToAiFeatureGroupBigQueryBigQuerySourceOutputWithContext(ctx context.Context) AiFeatureGroupBigQueryBigQuerySourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureGroupBigQueryBigQuerySourceOutput)
}

func (i AiFeatureGroupBigQueryBigQuerySourceArgs) ToAiFeatureGroupBigQueryBigQuerySourcePtrOutput() AiFeatureGroupBigQueryBigQuerySourcePtrOutput {
	return i.ToAiFeatureGroupBigQueryBigQuerySourcePtrOutputWithContext(context.Background())
}

func (i AiFeatureGroupBigQueryBigQuerySourceArgs) ToAiFeatureGroupBigQueryBigQuerySourcePtrOutputWithContext(ctx context.Context) AiFeatureGroupBigQueryBigQuerySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureGroupBigQueryBigQuerySourceOutput).ToAiFeatureGroupBigQueryBigQuerySourcePtrOutputWithContext(ctx)
}

// AiFeatureGroupBigQueryBigQuerySourcePtrInput is an input type that accepts AiFeatureGroupBigQueryBigQuerySourceArgs, AiFeatureGroupBigQueryBigQuerySourcePtr and AiFeatureGroupBigQueryBigQuerySourcePtrOutput values.
// You can construct a concrete instance of `AiFeatureGroupBigQueryBigQuerySourcePtrInput` via:
//
//	        AiFeatureGroupBigQueryBigQuerySourceArgs{...}
//
//	or:
//
//	        nil
type AiFeatureGroupBigQueryBigQuerySourcePtrInput interface {
	pulumi.Input

	ToAiFeatureGroupBigQueryBigQuerySourcePtrOutput() AiFeatureGroupBigQueryBigQuerySourcePtrOutput
	ToAiFeatureGroupBigQueryBigQuerySourcePtrOutputWithContext(context.Context) AiFeatureGroupBigQueryBigQuerySourcePtrOutput
}

type aiFeatureGroupBigQueryBigQuerySourcePtrType AiFeatureGroupBigQueryBigQuerySourceArgs

func AiFeatureGroupBigQueryBigQuerySourcePtr(v *AiFeatureGroupBigQueryBigQuerySourceArgs) AiFeatureGroupBigQueryBigQuerySourcePtrInput {
	return (*aiFeatureGroupBigQueryBigQuerySourcePtrType)(v)
}

func (*aiFeatureGroupBigQueryBigQuerySourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureGroupBigQueryBigQuerySource)(nil)).Elem()
}

func (i *aiFeatureGroupBigQueryBigQuerySourcePtrType) ToAiFeatureGroupBigQueryBigQuerySourcePtrOutput() AiFeatureGroupBigQueryBigQuerySourcePtrOutput {
	return i.ToAiFeatureGroupBigQueryBigQuerySourcePtrOutputWithContext(context.Background())
}

func (i *aiFeatureGroupBigQueryBigQuerySourcePtrType) ToAiFeatureGroupBigQueryBigQuerySourcePtrOutputWithContext(ctx context.Context) AiFeatureGroupBigQueryBigQuerySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureGroupBigQueryBigQuerySourcePtrOutput)
}

type AiFeatureGroupBigQueryBigQuerySourceOutput struct{ *pulumi.OutputState }

func (AiFeatureGroupBigQueryBigQuerySourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureGroupBigQueryBigQuerySource)(nil)).Elem()
}

func (o AiFeatureGroupBigQueryBigQuerySourceOutput) ToAiFeatureGroupBigQueryBigQuerySourceOutput() AiFeatureGroupBigQueryBigQuerySourceOutput {
	return o
}

func (o AiFeatureGroupBigQueryBigQuerySourceOutput) ToAiFeatureGroupBigQueryBigQuerySourceOutputWithContext(ctx context.Context) AiFeatureGroupBigQueryBigQuerySourceOutput {
	return o
}

func (o AiFeatureGroupBigQueryBigQuerySourceOutput) ToAiFeatureGroupBigQueryBigQuerySourcePtrOutput() AiFeatureGroupBigQueryBigQuerySourcePtrOutput {
	return o.ToAiFeatureGroupBigQueryBigQuerySourcePtrOutputWithContext(context.Background())
}

func (o AiFeatureGroupBigQueryBigQuerySourceOutput) ToAiFeatureGroupBigQueryBigQuerySourcePtrOutputWithContext(ctx context.Context) AiFeatureGroupBigQueryBigQuerySourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureGroupBigQueryBigQuerySource) *AiFeatureGroupBigQueryBigQuerySource {
		return &v
	}).(AiFeatureGroupBigQueryBigQuerySourcePtrOutput)
}

// BigQuery URI to a table, up to 2000 characters long. For example: `bq://projectId.bqDatasetId.bqTableId.`
func (o AiFeatureGroupBigQueryBigQuerySourceOutput) InputUri() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureGroupBigQueryBigQuerySource) string { return v.InputUri }).(pulumi.StringOutput)
}

type AiFeatureGroupBigQueryBigQuerySourcePtrOutput struct{ *pulumi.OutputState }

func (AiFeatureGroupBigQueryBigQuerySourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureGroupBigQueryBigQuerySource)(nil)).Elem()
}

func (o AiFeatureGroupBigQueryBigQuerySourcePtrOutput) ToAiFeatureGroupBigQueryBigQuerySourcePtrOutput() AiFeatureGroupBigQueryBigQuerySourcePtrOutput {
	return o
}

func (o AiFeatureGroupBigQueryBigQuerySourcePtrOutput) ToAiFeatureGroupBigQueryBigQuerySourcePtrOutputWithContext(ctx context.Context) AiFeatureGroupBigQueryBigQuerySourcePtrOutput {
	return o
}

func (o AiFeatureGroupBigQueryBigQuerySourcePtrOutput) Elem() AiFeatureGroupBigQueryBigQuerySourceOutput {
	return o.ApplyT(func(v *AiFeatureGroupBigQueryBigQuerySource) AiFeatureGroupBigQueryBigQuerySource {
		if v != nil {
			return *v
		}
		var ret AiFeatureGroupBigQueryBigQuerySource
		return ret
	}).(AiFeatureGroupBigQueryBigQuerySourceOutput)
}

// BigQuery URI to a table, up to 2000 characters long. For example: `bq://projectId.bqDatasetId.bqTableId.`
func (o AiFeatureGroupBigQueryBigQuerySourcePtrOutput) InputUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureGroupBigQueryBigQuerySource) *string {
		if v == nil {
			return nil
		}
		return &v.InputUri
	}).(pulumi.StringPtrOutput)
}

type AiFeatureGroupIamBindingCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureGroupIamBindingConditionInput is an input type that accepts AiFeatureGroupIamBindingConditionArgs and AiFeatureGroupIamBindingConditionOutput values.
// You can construct a concrete instance of `AiFeatureGroupIamBindingConditionInput` via:
//
//	AiFeatureGroupIamBindingConditionArgs{...}
type AiFeatureGroupIamBindingConditionInput interface {
	pulumi.Input

	ToAiFeatureGroupIamBindingConditionOutput() AiFeatureGroupIamBindingConditionOutput
	ToAiFeatureGroupIamBindingConditionOutputWithContext(context.Context) AiFeatureGroupIamBindingConditionOutput
}

type AiFeatureGroupIamBindingConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureGroupIamBindingConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureGroupIamBindingCondition)(nil)).Elem()
}

func (i AiFeatureGroupIamBindingConditionArgs) ToAiFeatureGroupIamBindingConditionOutput() AiFeatureGroupIamBindingConditionOutput {
	return i.ToAiFeatureGroupIamBindingConditionOutputWithContext(context.Background())
}

func (i AiFeatureGroupIamBindingConditionArgs) ToAiFeatureGroupIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureGroupIamBindingConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureGroupIamBindingConditionOutput)
}

func (i AiFeatureGroupIamBindingConditionArgs) ToAiFeatureGroupIamBindingConditionPtrOutput() AiFeatureGroupIamBindingConditionPtrOutput {
	return i.ToAiFeatureGroupIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureGroupIamBindingConditionArgs) ToAiFeatureGroupIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureGroupIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureGroupIamBindingConditionOutput).ToAiFeatureGroupIamBindingConditionPtrOutputWithContext(ctx)
}

// AiFeatureGroupIamBindingConditionPtrInput is an input type that accepts AiFeatureGroupIamBindingConditionArgs, AiFeatureGroupIamBindingConditionPtr and AiFeatureGroupIamBindingConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureGroupIamBindingConditionPtrInput` via:
//
//	        AiFeatureGroupIamBindingConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureGroupIamBindingConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureGroupIamBindingConditionPtrOutput() AiFeatureGroupIamBindingConditionPtrOutput
	ToAiFeatureGroupIamBindingConditionPtrOutputWithContext(context.Context) AiFeatureGroupIamBindingConditionPtrOutput
}

type aiFeatureGroupIamBindingConditionPtrType AiFeatureGroupIamBindingConditionArgs

func AiFeatureGroupIamBindingConditionPtr(v *AiFeatureGroupIamBindingConditionArgs) AiFeatureGroupIamBindingConditionPtrInput {
	return (*aiFeatureGroupIamBindingConditionPtrType)(v)
}

func (*aiFeatureGroupIamBindingConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureGroupIamBindingCondition)(nil)).Elem()
}

func (i *aiFeatureGroupIamBindingConditionPtrType) ToAiFeatureGroupIamBindingConditionPtrOutput() AiFeatureGroupIamBindingConditionPtrOutput {
	return i.ToAiFeatureGroupIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureGroupIamBindingConditionPtrType) ToAiFeatureGroupIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureGroupIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureGroupIamBindingConditionPtrOutput)
}

type AiFeatureGroupIamBindingConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureGroupIamBindingConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureGroupIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureGroupIamBindingConditionOutput) ToAiFeatureGroupIamBindingConditionOutput() AiFeatureGroupIamBindingConditionOutput {
	return o
}

func (o AiFeatureGroupIamBindingConditionOutput) ToAiFeatureGroupIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureGroupIamBindingConditionOutput {
	return o
}

func (o AiFeatureGroupIamBindingConditionOutput) ToAiFeatureGroupIamBindingConditionPtrOutput() AiFeatureGroupIamBindingConditionPtrOutput {
	return o.ToAiFeatureGroupIamBindingConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureGroupIamBindingConditionOutput) ToAiFeatureGroupIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureGroupIamBindingConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureGroupIamBindingCondition) *AiFeatureGroupIamBindingCondition {
		return &v
	}).(AiFeatureGroupIamBindingConditionPtrOutput)
}

func (o AiFeatureGroupIamBindingConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureGroupIamBindingCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureGroupIamBindingConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureGroupIamBindingCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureGroupIamBindingConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureGroupIamBindingCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureGroupIamBindingConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureGroupIamBindingConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureGroupIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureGroupIamBindingConditionPtrOutput) ToAiFeatureGroupIamBindingConditionPtrOutput() AiFeatureGroupIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureGroupIamBindingConditionPtrOutput) ToAiFeatureGroupIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureGroupIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureGroupIamBindingConditionPtrOutput) Elem() AiFeatureGroupIamBindingConditionOutput {
	return o.ApplyT(func(v *AiFeatureGroupIamBindingCondition) AiFeatureGroupIamBindingCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureGroupIamBindingCondition
		return ret
	}).(AiFeatureGroupIamBindingConditionOutput)
}

func (o AiFeatureGroupIamBindingConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureGroupIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureGroupIamBindingConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureGroupIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureGroupIamBindingConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureGroupIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureGroupIamMemberCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureGroupIamMemberConditionInput is an input type that accepts AiFeatureGroupIamMemberConditionArgs and AiFeatureGroupIamMemberConditionOutput values.
// You can construct a concrete instance of `AiFeatureGroupIamMemberConditionInput` via:
//
//	AiFeatureGroupIamMemberConditionArgs{...}
type AiFeatureGroupIamMemberConditionInput interface {
	pulumi.Input

	ToAiFeatureGroupIamMemberConditionOutput() AiFeatureGroupIamMemberConditionOutput
	ToAiFeatureGroupIamMemberConditionOutputWithContext(context.Context) AiFeatureGroupIamMemberConditionOutput
}

type AiFeatureGroupIamMemberConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureGroupIamMemberConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureGroupIamMemberCondition)(nil)).Elem()
}

func (i AiFeatureGroupIamMemberConditionArgs) ToAiFeatureGroupIamMemberConditionOutput() AiFeatureGroupIamMemberConditionOutput {
	return i.ToAiFeatureGroupIamMemberConditionOutputWithContext(context.Background())
}

func (i AiFeatureGroupIamMemberConditionArgs) ToAiFeatureGroupIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureGroupIamMemberConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureGroupIamMemberConditionOutput)
}

func (i AiFeatureGroupIamMemberConditionArgs) ToAiFeatureGroupIamMemberConditionPtrOutput() AiFeatureGroupIamMemberConditionPtrOutput {
	return i.ToAiFeatureGroupIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureGroupIamMemberConditionArgs) ToAiFeatureGroupIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureGroupIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureGroupIamMemberConditionOutput).ToAiFeatureGroupIamMemberConditionPtrOutputWithContext(ctx)
}

// AiFeatureGroupIamMemberConditionPtrInput is an input type that accepts AiFeatureGroupIamMemberConditionArgs, AiFeatureGroupIamMemberConditionPtr and AiFeatureGroupIamMemberConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureGroupIamMemberConditionPtrInput` via:
//
//	        AiFeatureGroupIamMemberConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureGroupIamMemberConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureGroupIamMemberConditionPtrOutput() AiFeatureGroupIamMemberConditionPtrOutput
	ToAiFeatureGroupIamMemberConditionPtrOutputWithContext(context.Context) AiFeatureGroupIamMemberConditionPtrOutput
}

type aiFeatureGroupIamMemberConditionPtrType AiFeatureGroupIamMemberConditionArgs

func AiFeatureGroupIamMemberConditionPtr(v *AiFeatureGroupIamMemberConditionArgs) AiFeatureGroupIamMemberConditionPtrInput {
	return (*aiFeatureGroupIamMemberConditionPtrType)(v)
}

func (*aiFeatureGroupIamMemberConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureGroupIamMemberCondition)(nil)).Elem()
}

func (i *aiFeatureGroupIamMemberConditionPtrType) ToAiFeatureGroupIamMemberConditionPtrOutput() AiFeatureGroupIamMemberConditionPtrOutput {
	return i.ToAiFeatureGroupIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureGroupIamMemberConditionPtrType) ToAiFeatureGroupIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureGroupIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureGroupIamMemberConditionPtrOutput)
}

type AiFeatureGroupIamMemberConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureGroupIamMemberConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureGroupIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureGroupIamMemberConditionOutput) ToAiFeatureGroupIamMemberConditionOutput() AiFeatureGroupIamMemberConditionOutput {
	return o
}

func (o AiFeatureGroupIamMemberConditionOutput) ToAiFeatureGroupIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureGroupIamMemberConditionOutput {
	return o
}

func (o AiFeatureGroupIamMemberConditionOutput) ToAiFeatureGroupIamMemberConditionPtrOutput() AiFeatureGroupIamMemberConditionPtrOutput {
	return o.ToAiFeatureGroupIamMemberConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureGroupIamMemberConditionOutput) ToAiFeatureGroupIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureGroupIamMemberConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureGroupIamMemberCondition) *AiFeatureGroupIamMemberCondition {
		return &v
	}).(AiFeatureGroupIamMemberConditionPtrOutput)
}

func (o AiFeatureGroupIamMemberConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureGroupIamMemberCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureGroupIamMemberConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureGroupIamMemberCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureGroupIamMemberConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureGroupIamMemberCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureGroupIamMemberConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureGroupIamMemberConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureGroupIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureGroupIamMemberConditionPtrOutput) ToAiFeatureGroupIamMemberConditionPtrOutput() AiFeatureGroupIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureGroupIamMemberConditionPtrOutput) ToAiFeatureGroupIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureGroupIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureGroupIamMemberConditionPtrOutput) Elem() AiFeatureGroupIamMemberConditionOutput {
	return o.ApplyT(func(v *AiFeatureGroupIamMemberCondition) AiFeatureGroupIamMemberCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureGroupIamMemberCondition
		return ret
	}).(AiFeatureGroupIamMemberConditionOutput)
}

func (o AiFeatureGroupIamMemberConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureGroupIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureGroupIamMemberConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureGroupIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureGroupIamMemberConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureGroupIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreBigtable struct {
	// Autoscaling config applied to Bigtable Instance.
	// Structure is documented below.
	AutoScaling AiFeatureOnlineStoreBigtableAutoScaling `pulumi:"autoScaling"`
}

// AiFeatureOnlineStoreBigtableInput is an input type that accepts AiFeatureOnlineStoreBigtableArgs and AiFeatureOnlineStoreBigtableOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreBigtableInput` via:
//
//	AiFeatureOnlineStoreBigtableArgs{...}
type AiFeatureOnlineStoreBigtableInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreBigtableOutput() AiFeatureOnlineStoreBigtableOutput
	ToAiFeatureOnlineStoreBigtableOutputWithContext(context.Context) AiFeatureOnlineStoreBigtableOutput
}

type AiFeatureOnlineStoreBigtableArgs struct {
	// Autoscaling config applied to Bigtable Instance.
	// Structure is documented below.
	AutoScaling AiFeatureOnlineStoreBigtableAutoScalingInput `pulumi:"autoScaling"`
}

func (AiFeatureOnlineStoreBigtableArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreBigtable)(nil)).Elem()
}

func (i AiFeatureOnlineStoreBigtableArgs) ToAiFeatureOnlineStoreBigtableOutput() AiFeatureOnlineStoreBigtableOutput {
	return i.ToAiFeatureOnlineStoreBigtableOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreBigtableArgs) ToAiFeatureOnlineStoreBigtableOutputWithContext(ctx context.Context) AiFeatureOnlineStoreBigtableOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreBigtableOutput)
}

func (i AiFeatureOnlineStoreBigtableArgs) ToAiFeatureOnlineStoreBigtablePtrOutput() AiFeatureOnlineStoreBigtablePtrOutput {
	return i.ToAiFeatureOnlineStoreBigtablePtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreBigtableArgs) ToAiFeatureOnlineStoreBigtablePtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreBigtablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreBigtableOutput).ToAiFeatureOnlineStoreBigtablePtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreBigtablePtrInput is an input type that accepts AiFeatureOnlineStoreBigtableArgs, AiFeatureOnlineStoreBigtablePtr and AiFeatureOnlineStoreBigtablePtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreBigtablePtrInput` via:
//
//	        AiFeatureOnlineStoreBigtableArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreBigtablePtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreBigtablePtrOutput() AiFeatureOnlineStoreBigtablePtrOutput
	ToAiFeatureOnlineStoreBigtablePtrOutputWithContext(context.Context) AiFeatureOnlineStoreBigtablePtrOutput
}

type aiFeatureOnlineStoreBigtablePtrType AiFeatureOnlineStoreBigtableArgs

func AiFeatureOnlineStoreBigtablePtr(v *AiFeatureOnlineStoreBigtableArgs) AiFeatureOnlineStoreBigtablePtrInput {
	return (*aiFeatureOnlineStoreBigtablePtrType)(v)
}

func (*aiFeatureOnlineStoreBigtablePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreBigtable)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreBigtablePtrType) ToAiFeatureOnlineStoreBigtablePtrOutput() AiFeatureOnlineStoreBigtablePtrOutput {
	return i.ToAiFeatureOnlineStoreBigtablePtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreBigtablePtrType) ToAiFeatureOnlineStoreBigtablePtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreBigtablePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreBigtablePtrOutput)
}

type AiFeatureOnlineStoreBigtableOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreBigtableOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreBigtable)(nil)).Elem()
}

func (o AiFeatureOnlineStoreBigtableOutput) ToAiFeatureOnlineStoreBigtableOutput() AiFeatureOnlineStoreBigtableOutput {
	return o
}

func (o AiFeatureOnlineStoreBigtableOutput) ToAiFeatureOnlineStoreBigtableOutputWithContext(ctx context.Context) AiFeatureOnlineStoreBigtableOutput {
	return o
}

func (o AiFeatureOnlineStoreBigtableOutput) ToAiFeatureOnlineStoreBigtablePtrOutput() AiFeatureOnlineStoreBigtablePtrOutput {
	return o.ToAiFeatureOnlineStoreBigtablePtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreBigtableOutput) ToAiFeatureOnlineStoreBigtablePtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreBigtablePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreBigtable) *AiFeatureOnlineStoreBigtable {
		return &v
	}).(AiFeatureOnlineStoreBigtablePtrOutput)
}

// Autoscaling config applied to Bigtable Instance.
// Structure is documented below.
func (o AiFeatureOnlineStoreBigtableOutput) AutoScaling() AiFeatureOnlineStoreBigtableAutoScalingOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreBigtable) AiFeatureOnlineStoreBigtableAutoScaling { return v.AutoScaling }).(AiFeatureOnlineStoreBigtableAutoScalingOutput)
}

type AiFeatureOnlineStoreBigtablePtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreBigtablePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreBigtable)(nil)).Elem()
}

func (o AiFeatureOnlineStoreBigtablePtrOutput) ToAiFeatureOnlineStoreBigtablePtrOutput() AiFeatureOnlineStoreBigtablePtrOutput {
	return o
}

func (o AiFeatureOnlineStoreBigtablePtrOutput) ToAiFeatureOnlineStoreBigtablePtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreBigtablePtrOutput {
	return o
}

func (o AiFeatureOnlineStoreBigtablePtrOutput) Elem() AiFeatureOnlineStoreBigtableOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreBigtable) AiFeatureOnlineStoreBigtable {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreBigtable
		return ret
	}).(AiFeatureOnlineStoreBigtableOutput)
}

// Autoscaling config applied to Bigtable Instance.
// Structure is documented below.
func (o AiFeatureOnlineStoreBigtablePtrOutput) AutoScaling() AiFeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreBigtable) *AiFeatureOnlineStoreBigtableAutoScaling {
		if v == nil {
			return nil
		}
		return &v.AutoScaling
	}).(AiFeatureOnlineStoreBigtableAutoScalingPtrOutput)
}

type AiFeatureOnlineStoreBigtableAutoScaling struct {
	// A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
	CpuUtilizationTarget *int `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than or equal to minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
	MaxNodeCount int `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount int `pulumi:"minNodeCount"`
}

// AiFeatureOnlineStoreBigtableAutoScalingInput is an input type that accepts AiFeatureOnlineStoreBigtableAutoScalingArgs and AiFeatureOnlineStoreBigtableAutoScalingOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreBigtableAutoScalingInput` via:
//
//	AiFeatureOnlineStoreBigtableAutoScalingArgs{...}
type AiFeatureOnlineStoreBigtableAutoScalingInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreBigtableAutoScalingOutput() AiFeatureOnlineStoreBigtableAutoScalingOutput
	ToAiFeatureOnlineStoreBigtableAutoScalingOutputWithContext(context.Context) AiFeatureOnlineStoreBigtableAutoScalingOutput
}

type AiFeatureOnlineStoreBigtableAutoScalingArgs struct {
	// A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
	CpuUtilizationTarget pulumi.IntPtrInput `pulumi:"cpuUtilizationTarget"`
	// The maximum number of nodes to scale up to. Must be greater than or equal to minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
	MaxNodeCount pulumi.IntInput `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount pulumi.IntInput `pulumi:"minNodeCount"`
}

func (AiFeatureOnlineStoreBigtableAutoScalingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreBigtableAutoScaling)(nil)).Elem()
}

func (i AiFeatureOnlineStoreBigtableAutoScalingArgs) ToAiFeatureOnlineStoreBigtableAutoScalingOutput() AiFeatureOnlineStoreBigtableAutoScalingOutput {
	return i.ToAiFeatureOnlineStoreBigtableAutoScalingOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreBigtableAutoScalingArgs) ToAiFeatureOnlineStoreBigtableAutoScalingOutputWithContext(ctx context.Context) AiFeatureOnlineStoreBigtableAutoScalingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreBigtableAutoScalingOutput)
}

func (i AiFeatureOnlineStoreBigtableAutoScalingArgs) ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutput() AiFeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return i.ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreBigtableAutoScalingArgs) ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreBigtableAutoScalingOutput).ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreBigtableAutoScalingPtrInput is an input type that accepts AiFeatureOnlineStoreBigtableAutoScalingArgs, AiFeatureOnlineStoreBigtableAutoScalingPtr and AiFeatureOnlineStoreBigtableAutoScalingPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreBigtableAutoScalingPtrInput` via:
//
//	        AiFeatureOnlineStoreBigtableAutoScalingArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreBigtableAutoScalingPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutput() AiFeatureOnlineStoreBigtableAutoScalingPtrOutput
	ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(context.Context) AiFeatureOnlineStoreBigtableAutoScalingPtrOutput
}

type aiFeatureOnlineStoreBigtableAutoScalingPtrType AiFeatureOnlineStoreBigtableAutoScalingArgs

func AiFeatureOnlineStoreBigtableAutoScalingPtr(v *AiFeatureOnlineStoreBigtableAutoScalingArgs) AiFeatureOnlineStoreBigtableAutoScalingPtrInput {
	return (*aiFeatureOnlineStoreBigtableAutoScalingPtrType)(v)
}

func (*aiFeatureOnlineStoreBigtableAutoScalingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreBigtableAutoScaling)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreBigtableAutoScalingPtrType) ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutput() AiFeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return i.ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreBigtableAutoScalingPtrType) ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreBigtableAutoScalingPtrOutput)
}

type AiFeatureOnlineStoreBigtableAutoScalingOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreBigtableAutoScalingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreBigtableAutoScaling)(nil)).Elem()
}

func (o AiFeatureOnlineStoreBigtableAutoScalingOutput) ToAiFeatureOnlineStoreBigtableAutoScalingOutput() AiFeatureOnlineStoreBigtableAutoScalingOutput {
	return o
}

func (o AiFeatureOnlineStoreBigtableAutoScalingOutput) ToAiFeatureOnlineStoreBigtableAutoScalingOutputWithContext(ctx context.Context) AiFeatureOnlineStoreBigtableAutoScalingOutput {
	return o
}

func (o AiFeatureOnlineStoreBigtableAutoScalingOutput) ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutput() AiFeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o.ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreBigtableAutoScalingOutput) ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreBigtableAutoScaling) *AiFeatureOnlineStoreBigtableAutoScaling {
		return &v
	}).(AiFeatureOnlineStoreBigtableAutoScalingPtrOutput)
}

// A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
func (o AiFeatureOnlineStoreBigtableAutoScalingOutput) CpuUtilizationTarget() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreBigtableAutoScaling) *int { return v.CpuUtilizationTarget }).(pulumi.IntPtrOutput)
}

// The maximum number of nodes to scale up to. Must be greater than or equal to minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
func (o AiFeatureOnlineStoreBigtableAutoScalingOutput) MaxNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreBigtableAutoScaling) int { return v.MaxNodeCount }).(pulumi.IntOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o AiFeatureOnlineStoreBigtableAutoScalingOutput) MinNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreBigtableAutoScaling) int { return v.MinNodeCount }).(pulumi.IntOutput)
}

type AiFeatureOnlineStoreBigtableAutoScalingPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreBigtableAutoScalingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreBigtableAutoScaling)(nil)).Elem()
}

func (o AiFeatureOnlineStoreBigtableAutoScalingPtrOutput) ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutput() AiFeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreBigtableAutoScalingPtrOutput) ToAiFeatureOnlineStoreBigtableAutoScalingPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreBigtableAutoScalingPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreBigtableAutoScalingPtrOutput) Elem() AiFeatureOnlineStoreBigtableAutoScalingOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreBigtableAutoScaling) AiFeatureOnlineStoreBigtableAutoScaling {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreBigtableAutoScaling
		return ret
	}).(AiFeatureOnlineStoreBigtableAutoScalingOutput)
}

// A percentage of the cluster's CPU capacity. Can be from 10% to 80%. When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster. When CPU utilization is substantially lower than the target, Bigtable removes nodes. If not set will default to 50%.
func (o AiFeatureOnlineStoreBigtableAutoScalingPtrOutput) CpuUtilizationTarget() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreBigtableAutoScaling) *int {
		if v == nil {
			return nil
		}
		return v.CpuUtilizationTarget
	}).(pulumi.IntPtrOutput)
}

// The maximum number of nodes to scale up to. Must be greater than or equal to minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
func (o AiFeatureOnlineStoreBigtableAutoScalingPtrOutput) MaxNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreBigtableAutoScaling) *int {
		if v == nil {
			return nil
		}
		return &v.MaxNodeCount
	}).(pulumi.IntPtrOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o AiFeatureOnlineStoreBigtableAutoScalingPtrOutput) MinNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreBigtableAutoScaling) *int {
		if v == nil {
			return nil
		}
		return &v.MinNodeCount
	}).(pulumi.IntPtrOutput)
}

type AiFeatureOnlineStoreDedicatedServingEndpoint struct {
	// Private service connect config.
	// Structure is documented below.
	PrivateServiceConnectConfig *AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig `pulumi:"privateServiceConnectConfig"`
	// (Output)
	// Domain name to use for this FeatureOnlineStore
	PublicEndpointDomainName *string `pulumi:"publicEndpointDomainName"`
	// (Output)
	// Name of the service attachment resource. Applicable only if private service connect is enabled and after FeatureViewSync is created.
	ServiceAttachment *string `pulumi:"serviceAttachment"`
}

// AiFeatureOnlineStoreDedicatedServingEndpointInput is an input type that accepts AiFeatureOnlineStoreDedicatedServingEndpointArgs and AiFeatureOnlineStoreDedicatedServingEndpointOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreDedicatedServingEndpointInput` via:
//
//	AiFeatureOnlineStoreDedicatedServingEndpointArgs{...}
type AiFeatureOnlineStoreDedicatedServingEndpointInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreDedicatedServingEndpointOutput() AiFeatureOnlineStoreDedicatedServingEndpointOutput
	ToAiFeatureOnlineStoreDedicatedServingEndpointOutputWithContext(context.Context) AiFeatureOnlineStoreDedicatedServingEndpointOutput
}

type AiFeatureOnlineStoreDedicatedServingEndpointArgs struct {
	// Private service connect config.
	// Structure is documented below.
	PrivateServiceConnectConfig AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrInput `pulumi:"privateServiceConnectConfig"`
	// (Output)
	// Domain name to use for this FeatureOnlineStore
	PublicEndpointDomainName pulumi.StringPtrInput `pulumi:"publicEndpointDomainName"`
	// (Output)
	// Name of the service attachment resource. Applicable only if private service connect is enabled and after FeatureViewSync is created.
	ServiceAttachment pulumi.StringPtrInput `pulumi:"serviceAttachment"`
}

func (AiFeatureOnlineStoreDedicatedServingEndpointArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreDedicatedServingEndpoint)(nil)).Elem()
}

func (i AiFeatureOnlineStoreDedicatedServingEndpointArgs) ToAiFeatureOnlineStoreDedicatedServingEndpointOutput() AiFeatureOnlineStoreDedicatedServingEndpointOutput {
	return i.ToAiFeatureOnlineStoreDedicatedServingEndpointOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreDedicatedServingEndpointArgs) ToAiFeatureOnlineStoreDedicatedServingEndpointOutputWithContext(ctx context.Context) AiFeatureOnlineStoreDedicatedServingEndpointOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreDedicatedServingEndpointOutput)
}

func (i AiFeatureOnlineStoreDedicatedServingEndpointArgs) ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutput() AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return i.ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreDedicatedServingEndpointArgs) ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreDedicatedServingEndpointOutput).ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreDedicatedServingEndpointPtrInput is an input type that accepts AiFeatureOnlineStoreDedicatedServingEndpointArgs, AiFeatureOnlineStoreDedicatedServingEndpointPtr and AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreDedicatedServingEndpointPtrInput` via:
//
//	        AiFeatureOnlineStoreDedicatedServingEndpointArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreDedicatedServingEndpointPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutput() AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput
	ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput
}

type aiFeatureOnlineStoreDedicatedServingEndpointPtrType AiFeatureOnlineStoreDedicatedServingEndpointArgs

func AiFeatureOnlineStoreDedicatedServingEndpointPtr(v *AiFeatureOnlineStoreDedicatedServingEndpointArgs) AiFeatureOnlineStoreDedicatedServingEndpointPtrInput {
	return (*aiFeatureOnlineStoreDedicatedServingEndpointPtrType)(v)
}

func (*aiFeatureOnlineStoreDedicatedServingEndpointPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreDedicatedServingEndpoint)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreDedicatedServingEndpointPtrType) ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutput() AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return i.ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreDedicatedServingEndpointPtrType) ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput)
}

type AiFeatureOnlineStoreDedicatedServingEndpointOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreDedicatedServingEndpointOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreDedicatedServingEndpoint)(nil)).Elem()
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointOutput) ToAiFeatureOnlineStoreDedicatedServingEndpointOutput() AiFeatureOnlineStoreDedicatedServingEndpointOutput {
	return o
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointOutput) ToAiFeatureOnlineStoreDedicatedServingEndpointOutputWithContext(ctx context.Context) AiFeatureOnlineStoreDedicatedServingEndpointOutput {
	return o
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointOutput) ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutput() AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return o.ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointOutput) ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreDedicatedServingEndpoint) *AiFeatureOnlineStoreDedicatedServingEndpoint {
		return &v
	}).(AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput)
}

// Private service connect config.
// Structure is documented below.
func (o AiFeatureOnlineStoreDedicatedServingEndpointOutput) PrivateServiceConnectConfig() AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreDedicatedServingEndpoint) *AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig {
		return v.PrivateServiceConnectConfig
	}).(AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput)
}

// (Output)
// Domain name to use for this FeatureOnlineStore
func (o AiFeatureOnlineStoreDedicatedServingEndpointOutput) PublicEndpointDomainName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreDedicatedServingEndpoint) *string { return v.PublicEndpointDomainName }).(pulumi.StringPtrOutput)
}

// (Output)
// Name of the service attachment resource. Applicable only if private service connect is enabled and after FeatureViewSync is created.
func (o AiFeatureOnlineStoreDedicatedServingEndpointOutput) ServiceAttachment() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreDedicatedServingEndpoint) *string { return v.ServiceAttachment }).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreDedicatedServingEndpoint)(nil)).Elem()
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput) ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutput() AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput) ToAiFeatureOnlineStoreDedicatedServingEndpointPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput) Elem() AiFeatureOnlineStoreDedicatedServingEndpointOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreDedicatedServingEndpoint) AiFeatureOnlineStoreDedicatedServingEndpoint {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreDedicatedServingEndpoint
		return ret
	}).(AiFeatureOnlineStoreDedicatedServingEndpointOutput)
}

// Private service connect config.
// Structure is documented below.
func (o AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput) PrivateServiceConnectConfig() AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreDedicatedServingEndpoint) *AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig {
		if v == nil {
			return nil
		}
		return v.PrivateServiceConnectConfig
	}).(AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput)
}

// (Output)
// Domain name to use for this FeatureOnlineStore
func (o AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput) PublicEndpointDomainName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreDedicatedServingEndpoint) *string {
		if v == nil {
			return nil
		}
		return v.PublicEndpointDomainName
	}).(pulumi.StringPtrOutput)
}

// (Output)
// Name of the service attachment resource. Applicable only if private service connect is enabled and after FeatureViewSync is created.
func (o AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput) ServiceAttachment() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreDedicatedServingEndpoint) *string {
		if v == nil {
			return nil
		}
		return v.ServiceAttachment
	}).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig struct {
	// If set to true, customers will use private service connection to send request. Otherwise, the connection will set to public endpoint.
	EnablePrivateServiceConnect bool `pulumi:"enablePrivateServiceConnect"`
	// A list of Projects from which the forwarding rule will target the service attachment.
	ProjectAllowlists []string `pulumi:"projectAllowlists"`
}

// AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigInput is an input type that accepts AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs and AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigInput` via:
//
//	AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs{...}
type AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput() AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput
	ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutputWithContext(context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput
}

type AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs struct {
	// If set to true, customers will use private service connection to send request. Otherwise, the connection will set to public endpoint.
	EnablePrivateServiceConnect pulumi.BoolInput `pulumi:"enablePrivateServiceConnect"`
	// A list of Projects from which the forwarding rule will target the service attachment.
	ProjectAllowlists pulumi.StringArrayInput `pulumi:"projectAllowlists"`
}

func (AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig)(nil)).Elem()
}

func (i AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs) ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput() AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput {
	return i.ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs) ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutputWithContext(ctx context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput)
}

func (i AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs) ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput() AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput {
	return i.ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs) ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput).ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrInput is an input type that accepts AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs, AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtr and AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrInput` via:
//
//	        AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput() AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput
	ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutputWithContext(context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput
}

type aiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrType AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs

func AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtr(v *AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs) AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrInput {
	return (*aiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrType)(v)
}

func (*aiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrType) ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput() AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput {
	return i.ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrType) ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput)
}

type AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig)(nil)).Elem()
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput) ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput() AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput {
	return o
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput) ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutputWithContext(ctx context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput {
	return o
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput) ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput() AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput {
	return o.ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput) ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig) *AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig {
		return &v
	}).(AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput)
}

// If set to true, customers will use private service connection to send request. Otherwise, the connection will set to public endpoint.
func (o AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput) EnablePrivateServiceConnect() pulumi.BoolOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig) bool {
		return v.EnablePrivateServiceConnect
	}).(pulumi.BoolOutput)
}

// A list of Projects from which the forwarding rule will target the service attachment.
func (o AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput) ProjectAllowlists() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig) []string {
		return v.ProjectAllowlists
	}).(pulumi.StringArrayOutput)
}

type AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig)(nil)).Elem()
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput) ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput() AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput) ToAiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput) Elem() AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig) AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig
		return ret
	}).(AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput)
}

// If set to true, customers will use private service connection to send request. Otherwise, the connection will set to public endpoint.
func (o AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput) EnablePrivateServiceConnect() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig) *bool {
		if v == nil {
			return nil
		}
		return &v.EnablePrivateServiceConnect
	}).(pulumi.BoolPtrOutput)
}

// A list of Projects from which the forwarding rule will target the service attachment.
func (o AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput) ProjectAllowlists() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfig) []string {
		if v == nil {
			return nil
		}
		return v.ProjectAllowlists
	}).(pulumi.StringArrayOutput)
}

type AiFeatureOnlineStoreEmbeddingManagement struct {
	// Enable embedding management.
	Enabled *bool `pulumi:"enabled"`
}

// AiFeatureOnlineStoreEmbeddingManagementInput is an input type that accepts AiFeatureOnlineStoreEmbeddingManagementArgs and AiFeatureOnlineStoreEmbeddingManagementOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreEmbeddingManagementInput` via:
//
//	AiFeatureOnlineStoreEmbeddingManagementArgs{...}
type AiFeatureOnlineStoreEmbeddingManagementInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreEmbeddingManagementOutput() AiFeatureOnlineStoreEmbeddingManagementOutput
	ToAiFeatureOnlineStoreEmbeddingManagementOutputWithContext(context.Context) AiFeatureOnlineStoreEmbeddingManagementOutput
}

type AiFeatureOnlineStoreEmbeddingManagementArgs struct {
	// Enable embedding management.
	Enabled pulumi.BoolPtrInput `pulumi:"enabled"`
}

func (AiFeatureOnlineStoreEmbeddingManagementArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreEmbeddingManagement)(nil)).Elem()
}

func (i AiFeatureOnlineStoreEmbeddingManagementArgs) ToAiFeatureOnlineStoreEmbeddingManagementOutput() AiFeatureOnlineStoreEmbeddingManagementOutput {
	return i.ToAiFeatureOnlineStoreEmbeddingManagementOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreEmbeddingManagementArgs) ToAiFeatureOnlineStoreEmbeddingManagementOutputWithContext(ctx context.Context) AiFeatureOnlineStoreEmbeddingManagementOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreEmbeddingManagementOutput)
}

func (i AiFeatureOnlineStoreEmbeddingManagementArgs) ToAiFeatureOnlineStoreEmbeddingManagementPtrOutput() AiFeatureOnlineStoreEmbeddingManagementPtrOutput {
	return i.ToAiFeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreEmbeddingManagementArgs) ToAiFeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreEmbeddingManagementPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreEmbeddingManagementOutput).ToAiFeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreEmbeddingManagementPtrInput is an input type that accepts AiFeatureOnlineStoreEmbeddingManagementArgs, AiFeatureOnlineStoreEmbeddingManagementPtr and AiFeatureOnlineStoreEmbeddingManagementPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreEmbeddingManagementPtrInput` via:
//
//	        AiFeatureOnlineStoreEmbeddingManagementArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreEmbeddingManagementPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreEmbeddingManagementPtrOutput() AiFeatureOnlineStoreEmbeddingManagementPtrOutput
	ToAiFeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(context.Context) AiFeatureOnlineStoreEmbeddingManagementPtrOutput
}

type aiFeatureOnlineStoreEmbeddingManagementPtrType AiFeatureOnlineStoreEmbeddingManagementArgs

func AiFeatureOnlineStoreEmbeddingManagementPtr(v *AiFeatureOnlineStoreEmbeddingManagementArgs) AiFeatureOnlineStoreEmbeddingManagementPtrInput {
	return (*aiFeatureOnlineStoreEmbeddingManagementPtrType)(v)
}

func (*aiFeatureOnlineStoreEmbeddingManagementPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreEmbeddingManagement)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreEmbeddingManagementPtrType) ToAiFeatureOnlineStoreEmbeddingManagementPtrOutput() AiFeatureOnlineStoreEmbeddingManagementPtrOutput {
	return i.ToAiFeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreEmbeddingManagementPtrType) ToAiFeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreEmbeddingManagementPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreEmbeddingManagementPtrOutput)
}

type AiFeatureOnlineStoreEmbeddingManagementOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreEmbeddingManagementOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreEmbeddingManagement)(nil)).Elem()
}

func (o AiFeatureOnlineStoreEmbeddingManagementOutput) ToAiFeatureOnlineStoreEmbeddingManagementOutput() AiFeatureOnlineStoreEmbeddingManagementOutput {
	return o
}

func (o AiFeatureOnlineStoreEmbeddingManagementOutput) ToAiFeatureOnlineStoreEmbeddingManagementOutputWithContext(ctx context.Context) AiFeatureOnlineStoreEmbeddingManagementOutput {
	return o
}

func (o AiFeatureOnlineStoreEmbeddingManagementOutput) ToAiFeatureOnlineStoreEmbeddingManagementPtrOutput() AiFeatureOnlineStoreEmbeddingManagementPtrOutput {
	return o.ToAiFeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreEmbeddingManagementOutput) ToAiFeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreEmbeddingManagementPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreEmbeddingManagement) *AiFeatureOnlineStoreEmbeddingManagement {
		return &v
	}).(AiFeatureOnlineStoreEmbeddingManagementPtrOutput)
}

// Enable embedding management.
func (o AiFeatureOnlineStoreEmbeddingManagementOutput) Enabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreEmbeddingManagement) *bool { return v.Enabled }).(pulumi.BoolPtrOutput)
}

type AiFeatureOnlineStoreEmbeddingManagementPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreEmbeddingManagementPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreEmbeddingManagement)(nil)).Elem()
}

func (o AiFeatureOnlineStoreEmbeddingManagementPtrOutput) ToAiFeatureOnlineStoreEmbeddingManagementPtrOutput() AiFeatureOnlineStoreEmbeddingManagementPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreEmbeddingManagementPtrOutput) ToAiFeatureOnlineStoreEmbeddingManagementPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreEmbeddingManagementPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreEmbeddingManagementPtrOutput) Elem() AiFeatureOnlineStoreEmbeddingManagementOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreEmbeddingManagement) AiFeatureOnlineStoreEmbeddingManagement {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreEmbeddingManagement
		return ret
	}).(AiFeatureOnlineStoreEmbeddingManagementOutput)
}

// Enable embedding management.
func (o AiFeatureOnlineStoreEmbeddingManagementPtrOutput) Enabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreEmbeddingManagement) *bool {
		if v == nil {
			return nil
		}
		return v.Enabled
	}).(pulumi.BoolPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewBigQuerySource struct {
	// Columns to construct entityId / row keys. Start by supporting 1 only.
	EntityIdColumns []string `pulumi:"entityIdColumns"`
	// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
	Uri string `pulumi:"uri"`
}

// AiFeatureOnlineStoreFeatureviewBigQuerySourceInput is an input type that accepts AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs and AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewBigQuerySourceInput` via:
//
//	AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs{...}
type AiFeatureOnlineStoreFeatureviewBigQuerySourceInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewBigQuerySourceOutput() AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput
	ToAiFeatureOnlineStoreFeatureviewBigQuerySourceOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput
}

type AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs struct {
	// Columns to construct entityId / row keys. Start by supporting 1 only.
	EntityIdColumns pulumi.StringArrayInput `pulumi:"entityIdColumns"`
	// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
	Uri pulumi.StringInput `pulumi:"uri"`
}

func (AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewBigQuerySource)(nil)).Elem()
}

func (i AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs) ToAiFeatureOnlineStoreFeatureviewBigQuerySourceOutput() AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewBigQuerySourceOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs) ToAiFeatureOnlineStoreFeatureviewBigQuerySourceOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput)
}

func (i AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs) ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput() AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs) ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput).ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrInput is an input type that accepts AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs, AiFeatureOnlineStoreFeatureviewBigQuerySourcePtr and AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrInput` via:
//
//	        AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput() AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput
	ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput
}

type aiFeatureOnlineStoreFeatureviewBigQuerySourcePtrType AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs

func AiFeatureOnlineStoreFeatureviewBigQuerySourcePtr(v *AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs) AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrInput {
	return (*aiFeatureOnlineStoreFeatureviewBigQuerySourcePtrType)(v)
}

func (*aiFeatureOnlineStoreFeatureviewBigQuerySourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewBigQuerySource)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreFeatureviewBigQuerySourcePtrType) ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput() AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreFeatureviewBigQuerySourcePtrType) ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput)
}

type AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewBigQuerySource)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput) ToAiFeatureOnlineStoreFeatureviewBigQuerySourceOutput() AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput) ToAiFeatureOnlineStoreFeatureviewBigQuerySourceOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput) ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput() AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput {
	return o.ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput) ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreFeatureviewBigQuerySource) *AiFeatureOnlineStoreFeatureviewBigQuerySource {
		return &v
	}).(AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput)
}

// Columns to construct entityId / row keys. Start by supporting 1 only.
func (o AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewBigQuerySource) []string { return v.EntityIdColumns }).(pulumi.StringArrayOutput)
}

// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
func (o AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput) Uri() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewBigQuerySource) string { return v.Uri }).(pulumi.StringOutput)
}

type AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewBigQuerySource)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput) ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput() AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput) ToAiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput) Elem() AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewBigQuerySource) AiFeatureOnlineStoreFeatureviewBigQuerySource {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreFeatureviewBigQuerySource
		return ret
	}).(AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput)
}

// Columns to construct entityId / row keys. Start by supporting 1 only.
func (o AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput) EntityIdColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewBigQuerySource) []string {
		if v == nil {
			return nil
		}
		return v.EntityIdColumns
	}).(pulumi.StringArrayOutput)
}

// The BigQuery view URI that will be materialized on each sync trigger based on FeatureView.SyncConfig.
func (o AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput) Uri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewBigQuerySource) *string {
		if v == nil {
			return nil
		}
		return &v.Uri
	}).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewFeatureRegistrySource struct {
	// List of features that need to be synced to Online Store.
	// Structure is documented below.
	FeatureGroups []AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroup `pulumi:"featureGroups"`
	// The project number of the parent project of the feature Groups.
	ProjectNumber *string `pulumi:"projectNumber"`
}

// AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceInput is an input type that accepts AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs and AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceInput` via:
//
//	AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs{...}
type AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput
	ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput
}

type AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs struct {
	// List of features that need to be synced to Online Store.
	// Structure is documented below.
	FeatureGroups AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayInput `pulumi:"featureGroups"`
	// The project number of the parent project of the feature Groups.
	ProjectNumber pulumi.StringPtrInput `pulumi:"projectNumber"`
}

func (AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewFeatureRegistrySource)(nil)).Elem()
}

func (i AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput)
}

func (i AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput).ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrInput is an input type that accepts AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs, AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtr and AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrInput` via:
//
//	        AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput
	ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput
}

type aiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrType AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs

func AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtr(v *AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrInput {
	return (*aiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrType)(v)
}

func (*aiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewFeatureRegistrySource)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrType) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrType) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput)
}

type AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewFeatureRegistrySource)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput {
	return o.ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreFeatureviewFeatureRegistrySource) *AiFeatureOnlineStoreFeatureviewFeatureRegistrySource {
		return &v
	}).(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput)
}

// List of features that need to be synced to Online Store.
// Structure is documented below.
func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput) FeatureGroups() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewFeatureRegistrySource) []AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroup {
		return v.FeatureGroups
	}).(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput)
}

// The project number of the parent project of the feature Groups.
func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput) ProjectNumber() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewFeatureRegistrySource) *string { return v.ProjectNumber }).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewFeatureRegistrySource)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput) Elem() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewFeatureRegistrySource) AiFeatureOnlineStoreFeatureviewFeatureRegistrySource {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreFeatureviewFeatureRegistrySource
		return ret
	}).(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput)
}

// List of features that need to be synced to Online Store.
// Structure is documented below.
func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput) FeatureGroups() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewFeatureRegistrySource) []AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroup {
		if v == nil {
			return nil
		}
		return v.FeatureGroups
	}).(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput)
}

// The project number of the parent project of the feature Groups.
func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput) ProjectNumber() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewFeatureRegistrySource) *string {
		if v == nil {
			return nil
		}
		return v.ProjectNumber
	}).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroup struct {
	// Identifier of the feature group.
	FeatureGroupId string `pulumi:"featureGroupId"`
	// Identifiers of features under the feature group.
	FeatureIds []string `pulumi:"featureIds"`
}

// AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupInput is an input type that accepts AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArgs and AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupInput` via:
//
//	AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArgs{...}
type AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput
	ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput
}

type AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArgs struct {
	// Identifier of the feature group.
	FeatureGroupId pulumi.StringInput `pulumi:"featureGroupId"`
	// Identifiers of features under the feature group.
	FeatureIds pulumi.StringArrayInput `pulumi:"featureIds"`
}

func (AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroup)(nil)).Elem()
}

func (i AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArgs) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArgs) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput)
}

// AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayInput is an input type that accepts AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArray and AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayInput` via:
//
//	AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArray{ AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArgs{...} }
type AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput
	ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput
}

type AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArray []AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupInput

func (AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroup)(nil)).Elem()
}

func (i AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArray) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArray) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput)
}

type AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroup)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput {
	return o
}

// Identifier of the feature group.
func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput) FeatureGroupId() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroup) string {
		return v.FeatureGroupId
	}).(pulumi.StringOutput)
}

// Identifiers of features under the feature group.
func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput) FeatureIds() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroup) []string { return v.FeatureIds }).(pulumi.StringArrayOutput)
}

type AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroup)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput() AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput) ToAiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput) Index(i pulumi.IntInput) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroup {
		return vs[0].([]AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroup)[vs[1].(int)]
	}).(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput)
}

type AiFeatureOnlineStoreFeatureviewIamBindingCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureOnlineStoreFeatureviewIamBindingConditionInput is an input type that accepts AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs and AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewIamBindingConditionInput` via:
//
//	AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs{...}
type AiFeatureOnlineStoreFeatureviewIamBindingConditionInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewIamBindingConditionOutput() AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput
	ToAiFeatureOnlineStoreFeatureviewIamBindingConditionOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput
}

type AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewIamBindingCondition)(nil)).Elem()
}

func (i AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs) ToAiFeatureOnlineStoreFeatureviewIamBindingConditionOutput() AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewIamBindingConditionOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs) ToAiFeatureOnlineStoreFeatureviewIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput)
}

func (i AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs) ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput() AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs) ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput).ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrInput is an input type that accepts AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs, AiFeatureOnlineStoreFeatureviewIamBindingConditionPtr and AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrInput` via:
//
//	        AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput() AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput
	ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput
}

type aiFeatureOnlineStoreFeatureviewIamBindingConditionPtrType AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs

func AiFeatureOnlineStoreFeatureviewIamBindingConditionPtr(v *AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs) AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrInput {
	return (*aiFeatureOnlineStoreFeatureviewIamBindingConditionPtrType)(v)
}

func (*aiFeatureOnlineStoreFeatureviewIamBindingConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewIamBindingCondition)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreFeatureviewIamBindingConditionPtrType) ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput() AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreFeatureviewIamBindingConditionPtrType) ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput) ToAiFeatureOnlineStoreFeatureviewIamBindingConditionOutput() AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput) ToAiFeatureOnlineStoreFeatureviewIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput) ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput() AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput {
	return o.ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput) ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreFeatureviewIamBindingCondition) *AiFeatureOnlineStoreFeatureviewIamBindingCondition {
		return &v
	}).(AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput)
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewIamBindingCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewIamBindingCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewIamBindingCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput) ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput() AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput) ToAiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput) Elem() AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewIamBindingCondition) AiFeatureOnlineStoreFeatureviewIamBindingCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreFeatureviewIamBindingCondition
		return ret
	}).(AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput)
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewIamMemberCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureOnlineStoreFeatureviewIamMemberConditionInput is an input type that accepts AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs and AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewIamMemberConditionInput` via:
//
//	AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs{...}
type AiFeatureOnlineStoreFeatureviewIamMemberConditionInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewIamMemberConditionOutput() AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput
	ToAiFeatureOnlineStoreFeatureviewIamMemberConditionOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput
}

type AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewIamMemberCondition)(nil)).Elem()
}

func (i AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs) ToAiFeatureOnlineStoreFeatureviewIamMemberConditionOutput() AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewIamMemberConditionOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs) ToAiFeatureOnlineStoreFeatureviewIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput)
}

func (i AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs) ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput() AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs) ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput).ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrInput is an input type that accepts AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs, AiFeatureOnlineStoreFeatureviewIamMemberConditionPtr and AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrInput` via:
//
//	        AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput() AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput
	ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput
}

type aiFeatureOnlineStoreFeatureviewIamMemberConditionPtrType AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs

func AiFeatureOnlineStoreFeatureviewIamMemberConditionPtr(v *AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs) AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrInput {
	return (*aiFeatureOnlineStoreFeatureviewIamMemberConditionPtrType)(v)
}

func (*aiFeatureOnlineStoreFeatureviewIamMemberConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewIamMemberCondition)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreFeatureviewIamMemberConditionPtrType) ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput() AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreFeatureviewIamMemberConditionPtrType) ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput) ToAiFeatureOnlineStoreFeatureviewIamMemberConditionOutput() AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput) ToAiFeatureOnlineStoreFeatureviewIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput) ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput() AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput {
	return o.ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput) ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreFeatureviewIamMemberCondition) *AiFeatureOnlineStoreFeatureviewIamMemberCondition {
		return &v
	}).(AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput)
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewIamMemberCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewIamMemberCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewIamMemberCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput) ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput() AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput) ToAiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput) Elem() AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewIamMemberCondition) AiFeatureOnlineStoreFeatureviewIamMemberCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreFeatureviewIamMemberCondition
		return ret
	}).(AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput)
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewSyncConfig struct {
	// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs.
	// To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}".
	Cron *string `pulumi:"cron"`
}

// AiFeatureOnlineStoreFeatureviewSyncConfigInput is an input type that accepts AiFeatureOnlineStoreFeatureviewSyncConfigArgs and AiFeatureOnlineStoreFeatureviewSyncConfigOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewSyncConfigInput` via:
//
//	AiFeatureOnlineStoreFeatureviewSyncConfigArgs{...}
type AiFeatureOnlineStoreFeatureviewSyncConfigInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewSyncConfigOutput() AiFeatureOnlineStoreFeatureviewSyncConfigOutput
	ToAiFeatureOnlineStoreFeatureviewSyncConfigOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewSyncConfigOutput
}

type AiFeatureOnlineStoreFeatureviewSyncConfigArgs struct {
	// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs.
	// To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}".
	Cron pulumi.StringPtrInput `pulumi:"cron"`
}

func (AiFeatureOnlineStoreFeatureviewSyncConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewSyncConfig)(nil)).Elem()
}

func (i AiFeatureOnlineStoreFeatureviewSyncConfigArgs) ToAiFeatureOnlineStoreFeatureviewSyncConfigOutput() AiFeatureOnlineStoreFeatureviewSyncConfigOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewSyncConfigOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewSyncConfigArgs) ToAiFeatureOnlineStoreFeatureviewSyncConfigOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewSyncConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewSyncConfigOutput)
}

func (i AiFeatureOnlineStoreFeatureviewSyncConfigArgs) ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput() AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewSyncConfigArgs) ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewSyncConfigOutput).ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreFeatureviewSyncConfigPtrInput is an input type that accepts AiFeatureOnlineStoreFeatureviewSyncConfigArgs, AiFeatureOnlineStoreFeatureviewSyncConfigPtr and AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewSyncConfigPtrInput` via:
//
//	        AiFeatureOnlineStoreFeatureviewSyncConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreFeatureviewSyncConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput() AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput
	ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput
}

type aiFeatureOnlineStoreFeatureviewSyncConfigPtrType AiFeatureOnlineStoreFeatureviewSyncConfigArgs

func AiFeatureOnlineStoreFeatureviewSyncConfigPtr(v *AiFeatureOnlineStoreFeatureviewSyncConfigArgs) AiFeatureOnlineStoreFeatureviewSyncConfigPtrInput {
	return (*aiFeatureOnlineStoreFeatureviewSyncConfigPtrType)(v)
}

func (*aiFeatureOnlineStoreFeatureviewSyncConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewSyncConfig)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreFeatureviewSyncConfigPtrType) ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput() AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreFeatureviewSyncConfigPtrType) ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewSyncConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewSyncConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewSyncConfig)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewSyncConfigOutput) ToAiFeatureOnlineStoreFeatureviewSyncConfigOutput() AiFeatureOnlineStoreFeatureviewSyncConfigOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewSyncConfigOutput) ToAiFeatureOnlineStoreFeatureviewSyncConfigOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewSyncConfigOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewSyncConfigOutput) ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput() AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput {
	return o.ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreFeatureviewSyncConfigOutput) ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreFeatureviewSyncConfig) *AiFeatureOnlineStoreFeatureviewSyncConfig {
		return &v
	}).(AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput)
}

// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs.
// To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}".
func (o AiFeatureOnlineStoreFeatureviewSyncConfigOutput) Cron() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewSyncConfig) *string { return v.Cron }).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewSyncConfig)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput) ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput() AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput) ToAiFeatureOnlineStoreFeatureviewSyncConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput) Elem() AiFeatureOnlineStoreFeatureviewSyncConfigOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewSyncConfig) AiFeatureOnlineStoreFeatureviewSyncConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreFeatureviewSyncConfig
		return ret
	}).(AiFeatureOnlineStoreFeatureviewSyncConfigOutput)
}

// Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs.
// To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}".
func (o AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput) Cron() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewSyncConfig) *string {
		if v == nil {
			return nil
		}
		return v.Cron
	}).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewVectorSearchConfig struct {
	// Configuration options for using brute force search, which simply implements the standard linear search in the database for each query. It is primarily meant for benchmarking and to generate the ground truth for approximate search.
	BruteForceConfig *AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig `pulumi:"bruteForceConfig"`
	// Column of crowding. This column contains crowding attribute which is a constraint on a neighbor list produced by nearest neighbor search requiring that no more than some value k' of the k neighbors returned have the same value of crowdingAttribute.
	CrowdingColumn *string `pulumi:"crowdingColumn"`
	// The distance measure used in nearest neighbor search.
	// For details on allowed values, see the [API documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews#DistanceMeasureType).
	// Possible values are: `SQUARED_L2_DISTANCE`, `COSINE_DISTANCE`, `DOT_PRODUCT_DISTANCE`.
	DistanceMeasureType *string `pulumi:"distanceMeasureType"`
	// Column of embedding. This column contains the source data to create index for vector search.
	EmbeddingColumn string `pulumi:"embeddingColumn"`
	// The number of dimensions of the input embedding.
	EmbeddingDimension *int `pulumi:"embeddingDimension"`
	// Columns of features that are used to filter vector search results.
	FilterColumns []string `pulumi:"filterColumns"`
	// Configuration options for the tree-AH algorithm (Shallow tree + Asymmetric Hashing). Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
	// Structure is documented below.
	TreeAhConfig *AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig `pulumi:"treeAhConfig"`
}

// AiFeatureOnlineStoreFeatureviewVectorSearchConfigInput is an input type that accepts AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs and AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewVectorSearchConfigInput` via:
//
//	AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs{...}
type AiFeatureOnlineStoreFeatureviewVectorSearchConfigInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput
	ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput
}

type AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs struct {
	// Configuration options for using brute force search, which simply implements the standard linear search in the database for each query. It is primarily meant for benchmarking and to generate the ground truth for approximate search.
	BruteForceConfig AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrInput `pulumi:"bruteForceConfig"`
	// Column of crowding. This column contains crowding attribute which is a constraint on a neighbor list produced by nearest neighbor search requiring that no more than some value k' of the k neighbors returned have the same value of crowdingAttribute.
	CrowdingColumn pulumi.StringPtrInput `pulumi:"crowdingColumn"`
	// The distance measure used in nearest neighbor search.
	// For details on allowed values, see the [API documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews#DistanceMeasureType).
	// Possible values are: `SQUARED_L2_DISTANCE`, `COSINE_DISTANCE`, `DOT_PRODUCT_DISTANCE`.
	DistanceMeasureType pulumi.StringPtrInput `pulumi:"distanceMeasureType"`
	// Column of embedding. This column contains the source data to create index for vector search.
	EmbeddingColumn pulumi.StringInput `pulumi:"embeddingColumn"`
	// The number of dimensions of the input embedding.
	EmbeddingDimension pulumi.IntPtrInput `pulumi:"embeddingDimension"`
	// Columns of features that are used to filter vector search results.
	FilterColumns pulumi.StringArrayInput `pulumi:"filterColumns"`
	// Configuration options for the tree-AH algorithm (Shallow tree + Asymmetric Hashing). Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
	// Structure is documented below.
	TreeAhConfig AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrInput `pulumi:"treeAhConfig"`
}

func (AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewVectorSearchConfig)(nil)).Elem()
}

func (i AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput)
}

func (i AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput).ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrInput is an input type that accepts AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs, AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtr and AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrInput` via:
//
//	        AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput
	ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput
}

type aiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrType AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs

func AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtr(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs) AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrInput {
	return (*aiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrType)(v)
}

func (*aiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewVectorSearchConfig)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrType) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrType) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewVectorSearchConfig)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput {
	return o.ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreFeatureviewVectorSearchConfig) *AiFeatureOnlineStoreFeatureviewVectorSearchConfig {
		return &v
	}).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput)
}

// Configuration options for using brute force search, which simply implements the standard linear search in the database for each query. It is primarily meant for benchmarking and to generate the ground truth for approximate search.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput) BruteForceConfig() AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewVectorSearchConfig) *AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig {
		return v.BruteForceConfig
	}).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput)
}

// Column of crowding. This column contains crowding attribute which is a constraint on a neighbor list produced by nearest neighbor search requiring that no more than some value k' of the k neighbors returned have the same value of crowdingAttribute.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput) CrowdingColumn() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewVectorSearchConfig) *string { return v.CrowdingColumn }).(pulumi.StringPtrOutput)
}

// The distance measure used in nearest neighbor search.
// For details on allowed values, see the [API documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews#DistanceMeasureType).
// Possible values are: `SQUARED_L2_DISTANCE`, `COSINE_DISTANCE`, `DOT_PRODUCT_DISTANCE`.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput) DistanceMeasureType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewVectorSearchConfig) *string { return v.DistanceMeasureType }).(pulumi.StringPtrOutput)
}

// Column of embedding. This column contains the source data to create index for vector search.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput) EmbeddingColumn() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewVectorSearchConfig) string { return v.EmbeddingColumn }).(pulumi.StringOutput)
}

// The number of dimensions of the input embedding.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput) EmbeddingDimension() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewVectorSearchConfig) *int { return v.EmbeddingDimension }).(pulumi.IntPtrOutput)
}

// Columns of features that are used to filter vector search results.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput) FilterColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewVectorSearchConfig) []string { return v.FilterColumns }).(pulumi.StringArrayOutput)
}

// Configuration options for the tree-AH algorithm (Shallow tree + Asymmetric Hashing). Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
// Structure is documented below.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput) TreeAhConfig() AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewVectorSearchConfig) *AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig {
		return v.TreeAhConfig
	}).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewVectorSearchConfig)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput) Elem() AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfig) AiFeatureOnlineStoreFeatureviewVectorSearchConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreFeatureviewVectorSearchConfig
		return ret
	}).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput)
}

// Configuration options for using brute force search, which simply implements the standard linear search in the database for each query. It is primarily meant for benchmarking and to generate the ground truth for approximate search.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput) BruteForceConfig() AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfig) *AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig {
		if v == nil {
			return nil
		}
		return v.BruteForceConfig
	}).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput)
}

// Column of crowding. This column contains crowding attribute which is a constraint on a neighbor list produced by nearest neighbor search requiring that no more than some value k' of the k neighbors returned have the same value of crowdingAttribute.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput) CrowdingColumn() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfig) *string {
		if v == nil {
			return nil
		}
		return v.CrowdingColumn
	}).(pulumi.StringPtrOutput)
}

// The distance measure used in nearest neighbor search.
// For details on allowed values, see the [API documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews#DistanceMeasureType).
// Possible values are: `SQUARED_L2_DISTANCE`, `COSINE_DISTANCE`, `DOT_PRODUCT_DISTANCE`.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput) DistanceMeasureType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfig) *string {
		if v == nil {
			return nil
		}
		return v.DistanceMeasureType
	}).(pulumi.StringPtrOutput)
}

// Column of embedding. This column contains the source data to create index for vector search.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput) EmbeddingColumn() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfig) *string {
		if v == nil {
			return nil
		}
		return &v.EmbeddingColumn
	}).(pulumi.StringPtrOutput)
}

// The number of dimensions of the input embedding.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput) EmbeddingDimension() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfig) *int {
		if v == nil {
			return nil
		}
		return v.EmbeddingDimension
	}).(pulumi.IntPtrOutput)
}

// Columns of features that are used to filter vector search results.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput) FilterColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfig) []string {
		if v == nil {
			return nil
		}
		return v.FilterColumns
	}).(pulumi.StringArrayOutput)
}

// Configuration options for the tree-AH algorithm (Shallow tree + Asymmetric Hashing). Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
// Structure is documented below.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput) TreeAhConfig() AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfig) *AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig {
		if v == nil {
			return nil
		}
		return v.TreeAhConfig
	}).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig struct {
}

// AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigInput is an input type that accepts AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs and AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigInput` via:
//
//	AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs{...}
type AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput
	ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput
}

type AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs struct {
}

func (AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig)(nil)).Elem()
}

func (i AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput)
}

func (i AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput).ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrInput is an input type that accepts AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs, AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtr and AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrInput` via:
//
//	        AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput
	ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput
}

type aiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrType AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs

func AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtr(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs) AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrInput {
	return (*aiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrType)(v)
}

func (*aiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrType) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrType) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput {
	return o.ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig) *AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig {
		return &v
	}).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput) Elem() AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig) AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfig
		return ret
	}).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput)
}

type AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig struct {
	// Number of embeddings on each leaf node. The default value is 1000 if not set.
	LeafNodeEmbeddingCount *string `pulumi:"leafNodeEmbeddingCount"`
}

// AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigInput is an input type that accepts AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs and AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigInput` via:
//
//	AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs{...}
type AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput
	ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput
}

type AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs struct {
	// Number of embeddings on each leaf node. The default value is 1000 if not set.
	LeafNodeEmbeddingCount pulumi.StringPtrInput `pulumi:"leafNodeEmbeddingCount"`
}

func (AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig)(nil)).Elem()
}

func (i AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput)
}

func (i AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput).ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrInput is an input type that accepts AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs, AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtr and AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrInput` via:
//
//	        AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput
	ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutputWithContext(context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput
}

type aiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrType AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs

func AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtr(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs) AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrInput {
	return (*aiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrType)(v)
}

func (*aiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrType) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput {
	return i.ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrType) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput {
	return o.ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig) *AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig {
		return &v
	}).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput)
}

// Number of embeddings on each leaf node. The default value is 1000 if not set.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput) LeafNodeEmbeddingCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig) *string {
		return v.LeafNodeEmbeddingCount
	}).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig)(nil)).Elem()
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput() AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput) ToAiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput) Elem() AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig) AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig
		return ret
	}).(AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput)
}

// Number of embeddings on each leaf node. The default value is 1000 if not set.
func (o AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput) LeafNodeEmbeddingCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfig) *string {
		if v == nil {
			return nil
		}
		return v.LeafNodeEmbeddingCount
	}).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreIamBindingCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureOnlineStoreIamBindingConditionInput is an input type that accepts AiFeatureOnlineStoreIamBindingConditionArgs and AiFeatureOnlineStoreIamBindingConditionOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreIamBindingConditionInput` via:
//
//	AiFeatureOnlineStoreIamBindingConditionArgs{...}
type AiFeatureOnlineStoreIamBindingConditionInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreIamBindingConditionOutput() AiFeatureOnlineStoreIamBindingConditionOutput
	ToAiFeatureOnlineStoreIamBindingConditionOutputWithContext(context.Context) AiFeatureOnlineStoreIamBindingConditionOutput
}

type AiFeatureOnlineStoreIamBindingConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureOnlineStoreIamBindingConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreIamBindingCondition)(nil)).Elem()
}

func (i AiFeatureOnlineStoreIamBindingConditionArgs) ToAiFeatureOnlineStoreIamBindingConditionOutput() AiFeatureOnlineStoreIamBindingConditionOutput {
	return i.ToAiFeatureOnlineStoreIamBindingConditionOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreIamBindingConditionArgs) ToAiFeatureOnlineStoreIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureOnlineStoreIamBindingConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreIamBindingConditionOutput)
}

func (i AiFeatureOnlineStoreIamBindingConditionArgs) ToAiFeatureOnlineStoreIamBindingConditionPtrOutput() AiFeatureOnlineStoreIamBindingConditionPtrOutput {
	return i.ToAiFeatureOnlineStoreIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreIamBindingConditionArgs) ToAiFeatureOnlineStoreIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreIamBindingConditionOutput).ToAiFeatureOnlineStoreIamBindingConditionPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreIamBindingConditionPtrInput is an input type that accepts AiFeatureOnlineStoreIamBindingConditionArgs, AiFeatureOnlineStoreIamBindingConditionPtr and AiFeatureOnlineStoreIamBindingConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreIamBindingConditionPtrInput` via:
//
//	        AiFeatureOnlineStoreIamBindingConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreIamBindingConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreIamBindingConditionPtrOutput() AiFeatureOnlineStoreIamBindingConditionPtrOutput
	ToAiFeatureOnlineStoreIamBindingConditionPtrOutputWithContext(context.Context) AiFeatureOnlineStoreIamBindingConditionPtrOutput
}

type aiFeatureOnlineStoreIamBindingConditionPtrType AiFeatureOnlineStoreIamBindingConditionArgs

func AiFeatureOnlineStoreIamBindingConditionPtr(v *AiFeatureOnlineStoreIamBindingConditionArgs) AiFeatureOnlineStoreIamBindingConditionPtrInput {
	return (*aiFeatureOnlineStoreIamBindingConditionPtrType)(v)
}

func (*aiFeatureOnlineStoreIamBindingConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreIamBindingCondition)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreIamBindingConditionPtrType) ToAiFeatureOnlineStoreIamBindingConditionPtrOutput() AiFeatureOnlineStoreIamBindingConditionPtrOutput {
	return i.ToAiFeatureOnlineStoreIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreIamBindingConditionPtrType) ToAiFeatureOnlineStoreIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreIamBindingConditionPtrOutput)
}

type AiFeatureOnlineStoreIamBindingConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreIamBindingConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureOnlineStoreIamBindingConditionOutput) ToAiFeatureOnlineStoreIamBindingConditionOutput() AiFeatureOnlineStoreIamBindingConditionOutput {
	return o
}

func (o AiFeatureOnlineStoreIamBindingConditionOutput) ToAiFeatureOnlineStoreIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureOnlineStoreIamBindingConditionOutput {
	return o
}

func (o AiFeatureOnlineStoreIamBindingConditionOutput) ToAiFeatureOnlineStoreIamBindingConditionPtrOutput() AiFeatureOnlineStoreIamBindingConditionPtrOutput {
	return o.ToAiFeatureOnlineStoreIamBindingConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreIamBindingConditionOutput) ToAiFeatureOnlineStoreIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreIamBindingConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreIamBindingCondition) *AiFeatureOnlineStoreIamBindingCondition {
		return &v
	}).(AiFeatureOnlineStoreIamBindingConditionPtrOutput)
}

func (o AiFeatureOnlineStoreIamBindingConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreIamBindingCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureOnlineStoreIamBindingConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreIamBindingCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureOnlineStoreIamBindingConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreIamBindingCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureOnlineStoreIamBindingConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreIamBindingConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureOnlineStoreIamBindingConditionPtrOutput) ToAiFeatureOnlineStoreIamBindingConditionPtrOutput() AiFeatureOnlineStoreIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreIamBindingConditionPtrOutput) ToAiFeatureOnlineStoreIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreIamBindingConditionPtrOutput) Elem() AiFeatureOnlineStoreIamBindingConditionOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreIamBindingCondition) AiFeatureOnlineStoreIamBindingCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreIamBindingCondition
		return ret
	}).(AiFeatureOnlineStoreIamBindingConditionOutput)
}

func (o AiFeatureOnlineStoreIamBindingConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureOnlineStoreIamBindingConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureOnlineStoreIamBindingConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreIamMemberCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureOnlineStoreIamMemberConditionInput is an input type that accepts AiFeatureOnlineStoreIamMemberConditionArgs and AiFeatureOnlineStoreIamMemberConditionOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreIamMemberConditionInput` via:
//
//	AiFeatureOnlineStoreIamMemberConditionArgs{...}
type AiFeatureOnlineStoreIamMemberConditionInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreIamMemberConditionOutput() AiFeatureOnlineStoreIamMemberConditionOutput
	ToAiFeatureOnlineStoreIamMemberConditionOutputWithContext(context.Context) AiFeatureOnlineStoreIamMemberConditionOutput
}

type AiFeatureOnlineStoreIamMemberConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureOnlineStoreIamMemberConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreIamMemberCondition)(nil)).Elem()
}

func (i AiFeatureOnlineStoreIamMemberConditionArgs) ToAiFeatureOnlineStoreIamMemberConditionOutput() AiFeatureOnlineStoreIamMemberConditionOutput {
	return i.ToAiFeatureOnlineStoreIamMemberConditionOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreIamMemberConditionArgs) ToAiFeatureOnlineStoreIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureOnlineStoreIamMemberConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreIamMemberConditionOutput)
}

func (i AiFeatureOnlineStoreIamMemberConditionArgs) ToAiFeatureOnlineStoreIamMemberConditionPtrOutput() AiFeatureOnlineStoreIamMemberConditionPtrOutput {
	return i.ToAiFeatureOnlineStoreIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreIamMemberConditionArgs) ToAiFeatureOnlineStoreIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreIamMemberConditionOutput).ToAiFeatureOnlineStoreIamMemberConditionPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreIamMemberConditionPtrInput is an input type that accepts AiFeatureOnlineStoreIamMemberConditionArgs, AiFeatureOnlineStoreIamMemberConditionPtr and AiFeatureOnlineStoreIamMemberConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreIamMemberConditionPtrInput` via:
//
//	        AiFeatureOnlineStoreIamMemberConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreIamMemberConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreIamMemberConditionPtrOutput() AiFeatureOnlineStoreIamMemberConditionPtrOutput
	ToAiFeatureOnlineStoreIamMemberConditionPtrOutputWithContext(context.Context) AiFeatureOnlineStoreIamMemberConditionPtrOutput
}

type aiFeatureOnlineStoreIamMemberConditionPtrType AiFeatureOnlineStoreIamMemberConditionArgs

func AiFeatureOnlineStoreIamMemberConditionPtr(v *AiFeatureOnlineStoreIamMemberConditionArgs) AiFeatureOnlineStoreIamMemberConditionPtrInput {
	return (*aiFeatureOnlineStoreIamMemberConditionPtrType)(v)
}

func (*aiFeatureOnlineStoreIamMemberConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreIamMemberCondition)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreIamMemberConditionPtrType) ToAiFeatureOnlineStoreIamMemberConditionPtrOutput() AiFeatureOnlineStoreIamMemberConditionPtrOutput {
	return i.ToAiFeatureOnlineStoreIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreIamMemberConditionPtrType) ToAiFeatureOnlineStoreIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreIamMemberConditionPtrOutput)
}

type AiFeatureOnlineStoreIamMemberConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreIamMemberConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureOnlineStoreIamMemberConditionOutput) ToAiFeatureOnlineStoreIamMemberConditionOutput() AiFeatureOnlineStoreIamMemberConditionOutput {
	return o
}

func (o AiFeatureOnlineStoreIamMemberConditionOutput) ToAiFeatureOnlineStoreIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureOnlineStoreIamMemberConditionOutput {
	return o
}

func (o AiFeatureOnlineStoreIamMemberConditionOutput) ToAiFeatureOnlineStoreIamMemberConditionPtrOutput() AiFeatureOnlineStoreIamMemberConditionPtrOutput {
	return o.ToAiFeatureOnlineStoreIamMemberConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreIamMemberConditionOutput) ToAiFeatureOnlineStoreIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreIamMemberConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreIamMemberCondition) *AiFeatureOnlineStoreIamMemberCondition {
		return &v
	}).(AiFeatureOnlineStoreIamMemberConditionPtrOutput)
}

func (o AiFeatureOnlineStoreIamMemberConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreIamMemberCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureOnlineStoreIamMemberConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreIamMemberCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureOnlineStoreIamMemberConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureOnlineStoreIamMemberCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureOnlineStoreIamMemberConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreIamMemberConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureOnlineStoreIamMemberConditionPtrOutput) ToAiFeatureOnlineStoreIamMemberConditionPtrOutput() AiFeatureOnlineStoreIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreIamMemberConditionPtrOutput) ToAiFeatureOnlineStoreIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreIamMemberConditionPtrOutput) Elem() AiFeatureOnlineStoreIamMemberConditionOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreIamMemberCondition) AiFeatureOnlineStoreIamMemberCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreIamMemberCondition
		return ret
	}).(AiFeatureOnlineStoreIamMemberConditionOutput)
}

func (o AiFeatureOnlineStoreIamMemberConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureOnlineStoreIamMemberConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureOnlineStoreIamMemberConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureOnlineStoreOptimized struct {
}

// AiFeatureOnlineStoreOptimizedInput is an input type that accepts AiFeatureOnlineStoreOptimizedArgs and AiFeatureOnlineStoreOptimizedOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreOptimizedInput` via:
//
//	AiFeatureOnlineStoreOptimizedArgs{...}
type AiFeatureOnlineStoreOptimizedInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreOptimizedOutput() AiFeatureOnlineStoreOptimizedOutput
	ToAiFeatureOnlineStoreOptimizedOutputWithContext(context.Context) AiFeatureOnlineStoreOptimizedOutput
}

type AiFeatureOnlineStoreOptimizedArgs struct {
}

func (AiFeatureOnlineStoreOptimizedArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreOptimized)(nil)).Elem()
}

func (i AiFeatureOnlineStoreOptimizedArgs) ToAiFeatureOnlineStoreOptimizedOutput() AiFeatureOnlineStoreOptimizedOutput {
	return i.ToAiFeatureOnlineStoreOptimizedOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreOptimizedArgs) ToAiFeatureOnlineStoreOptimizedOutputWithContext(ctx context.Context) AiFeatureOnlineStoreOptimizedOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreOptimizedOutput)
}

func (i AiFeatureOnlineStoreOptimizedArgs) ToAiFeatureOnlineStoreOptimizedPtrOutput() AiFeatureOnlineStoreOptimizedPtrOutput {
	return i.ToAiFeatureOnlineStoreOptimizedPtrOutputWithContext(context.Background())
}

func (i AiFeatureOnlineStoreOptimizedArgs) ToAiFeatureOnlineStoreOptimizedPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreOptimizedPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreOptimizedOutput).ToAiFeatureOnlineStoreOptimizedPtrOutputWithContext(ctx)
}

// AiFeatureOnlineStoreOptimizedPtrInput is an input type that accepts AiFeatureOnlineStoreOptimizedArgs, AiFeatureOnlineStoreOptimizedPtr and AiFeatureOnlineStoreOptimizedPtrOutput values.
// You can construct a concrete instance of `AiFeatureOnlineStoreOptimizedPtrInput` via:
//
//	        AiFeatureOnlineStoreOptimizedArgs{...}
//
//	or:
//
//	        nil
type AiFeatureOnlineStoreOptimizedPtrInput interface {
	pulumi.Input

	ToAiFeatureOnlineStoreOptimizedPtrOutput() AiFeatureOnlineStoreOptimizedPtrOutput
	ToAiFeatureOnlineStoreOptimizedPtrOutputWithContext(context.Context) AiFeatureOnlineStoreOptimizedPtrOutput
}

type aiFeatureOnlineStoreOptimizedPtrType AiFeatureOnlineStoreOptimizedArgs

func AiFeatureOnlineStoreOptimizedPtr(v *AiFeatureOnlineStoreOptimizedArgs) AiFeatureOnlineStoreOptimizedPtrInput {
	return (*aiFeatureOnlineStoreOptimizedPtrType)(v)
}

func (*aiFeatureOnlineStoreOptimizedPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreOptimized)(nil)).Elem()
}

func (i *aiFeatureOnlineStoreOptimizedPtrType) ToAiFeatureOnlineStoreOptimizedPtrOutput() AiFeatureOnlineStoreOptimizedPtrOutput {
	return i.ToAiFeatureOnlineStoreOptimizedPtrOutputWithContext(context.Background())
}

func (i *aiFeatureOnlineStoreOptimizedPtrType) ToAiFeatureOnlineStoreOptimizedPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreOptimizedPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureOnlineStoreOptimizedPtrOutput)
}

type AiFeatureOnlineStoreOptimizedOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreOptimizedOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureOnlineStoreOptimized)(nil)).Elem()
}

func (o AiFeatureOnlineStoreOptimizedOutput) ToAiFeatureOnlineStoreOptimizedOutput() AiFeatureOnlineStoreOptimizedOutput {
	return o
}

func (o AiFeatureOnlineStoreOptimizedOutput) ToAiFeatureOnlineStoreOptimizedOutputWithContext(ctx context.Context) AiFeatureOnlineStoreOptimizedOutput {
	return o
}

func (o AiFeatureOnlineStoreOptimizedOutput) ToAiFeatureOnlineStoreOptimizedPtrOutput() AiFeatureOnlineStoreOptimizedPtrOutput {
	return o.ToAiFeatureOnlineStoreOptimizedPtrOutputWithContext(context.Background())
}

func (o AiFeatureOnlineStoreOptimizedOutput) ToAiFeatureOnlineStoreOptimizedPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreOptimizedPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureOnlineStoreOptimized) *AiFeatureOnlineStoreOptimized {
		return &v
	}).(AiFeatureOnlineStoreOptimizedPtrOutput)
}

type AiFeatureOnlineStoreOptimizedPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureOnlineStoreOptimizedPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureOnlineStoreOptimized)(nil)).Elem()
}

func (o AiFeatureOnlineStoreOptimizedPtrOutput) ToAiFeatureOnlineStoreOptimizedPtrOutput() AiFeatureOnlineStoreOptimizedPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreOptimizedPtrOutput) ToAiFeatureOnlineStoreOptimizedPtrOutputWithContext(ctx context.Context) AiFeatureOnlineStoreOptimizedPtrOutput {
	return o
}

func (o AiFeatureOnlineStoreOptimizedPtrOutput) Elem() AiFeatureOnlineStoreOptimizedOutput {
	return o.ApplyT(func(v *AiFeatureOnlineStoreOptimized) AiFeatureOnlineStoreOptimized {
		if v != nil {
			return *v
		}
		var ret AiFeatureOnlineStoreOptimized
		return ret
	}).(AiFeatureOnlineStoreOptimizedOutput)
}

type AiFeatureStoreEncryptionSpec struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// AiFeatureStoreEncryptionSpecInput is an input type that accepts AiFeatureStoreEncryptionSpecArgs and AiFeatureStoreEncryptionSpecOutput values.
// You can construct a concrete instance of `AiFeatureStoreEncryptionSpecInput` via:
//
//	AiFeatureStoreEncryptionSpecArgs{...}
type AiFeatureStoreEncryptionSpecInput interface {
	pulumi.Input

	ToAiFeatureStoreEncryptionSpecOutput() AiFeatureStoreEncryptionSpecOutput
	ToAiFeatureStoreEncryptionSpecOutputWithContext(context.Context) AiFeatureStoreEncryptionSpecOutput
}

type AiFeatureStoreEncryptionSpecArgs struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the compute resource is created.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (AiFeatureStoreEncryptionSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEncryptionSpec)(nil)).Elem()
}

func (i AiFeatureStoreEncryptionSpecArgs) ToAiFeatureStoreEncryptionSpecOutput() AiFeatureStoreEncryptionSpecOutput {
	return i.ToAiFeatureStoreEncryptionSpecOutputWithContext(context.Background())
}

func (i AiFeatureStoreEncryptionSpecArgs) ToAiFeatureStoreEncryptionSpecOutputWithContext(ctx context.Context) AiFeatureStoreEncryptionSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEncryptionSpecOutput)
}

func (i AiFeatureStoreEncryptionSpecArgs) ToAiFeatureStoreEncryptionSpecPtrOutput() AiFeatureStoreEncryptionSpecPtrOutput {
	return i.ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEncryptionSpecArgs) ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiFeatureStoreEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEncryptionSpecOutput).ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(ctx)
}

// AiFeatureStoreEncryptionSpecPtrInput is an input type that accepts AiFeatureStoreEncryptionSpecArgs, AiFeatureStoreEncryptionSpecPtr and AiFeatureStoreEncryptionSpecPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEncryptionSpecPtrInput` via:
//
//	        AiFeatureStoreEncryptionSpecArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEncryptionSpecPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEncryptionSpecPtrOutput() AiFeatureStoreEncryptionSpecPtrOutput
	ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(context.Context) AiFeatureStoreEncryptionSpecPtrOutput
}

type aiFeatureStoreEncryptionSpecPtrType AiFeatureStoreEncryptionSpecArgs

func AiFeatureStoreEncryptionSpecPtr(v *AiFeatureStoreEncryptionSpecArgs) AiFeatureStoreEncryptionSpecPtrInput {
	return (*aiFeatureStoreEncryptionSpecPtrType)(v)
}

func (*aiFeatureStoreEncryptionSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEncryptionSpec)(nil)).Elem()
}

func (i *aiFeatureStoreEncryptionSpecPtrType) ToAiFeatureStoreEncryptionSpecPtrOutput() AiFeatureStoreEncryptionSpecPtrOutput {
	return i.ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEncryptionSpecPtrType) ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiFeatureStoreEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEncryptionSpecPtrOutput)
}

type AiFeatureStoreEncryptionSpecOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEncryptionSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEncryptionSpec)(nil)).Elem()
}

func (o AiFeatureStoreEncryptionSpecOutput) ToAiFeatureStoreEncryptionSpecOutput() AiFeatureStoreEncryptionSpecOutput {
	return o
}

func (o AiFeatureStoreEncryptionSpecOutput) ToAiFeatureStoreEncryptionSpecOutputWithContext(ctx context.Context) AiFeatureStoreEncryptionSpecOutput {
	return o
}

func (o AiFeatureStoreEncryptionSpecOutput) ToAiFeatureStoreEncryptionSpecPtrOutput() AiFeatureStoreEncryptionSpecPtrOutput {
	return o.ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEncryptionSpecOutput) ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiFeatureStoreEncryptionSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEncryptionSpec) *AiFeatureStoreEncryptionSpec {
		return &v
	}).(AiFeatureStoreEncryptionSpecPtrOutput)
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the compute resource is created.
func (o AiFeatureStoreEncryptionSpecOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreEncryptionSpec) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type AiFeatureStoreEncryptionSpecPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEncryptionSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEncryptionSpec)(nil)).Elem()
}

func (o AiFeatureStoreEncryptionSpecPtrOutput) ToAiFeatureStoreEncryptionSpecPtrOutput() AiFeatureStoreEncryptionSpecPtrOutput {
	return o
}

func (o AiFeatureStoreEncryptionSpecPtrOutput) ToAiFeatureStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiFeatureStoreEncryptionSpecPtrOutput {
	return o
}

func (o AiFeatureStoreEncryptionSpecPtrOutput) Elem() AiFeatureStoreEncryptionSpecOutput {
	return o.ApplyT(func(v *AiFeatureStoreEncryptionSpec) AiFeatureStoreEncryptionSpec {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEncryptionSpec
		return ret
	}).(AiFeatureStoreEncryptionSpecOutput)
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the compute resource is created.
func (o AiFeatureStoreEncryptionSpecPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEncryptionSpec) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreEntityTypeIamBindingCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureStoreEntityTypeIamBindingConditionInput is an input type that accepts AiFeatureStoreEntityTypeIamBindingConditionArgs and AiFeatureStoreEntityTypeIamBindingConditionOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeIamBindingConditionInput` via:
//
//	AiFeatureStoreEntityTypeIamBindingConditionArgs{...}
type AiFeatureStoreEntityTypeIamBindingConditionInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeIamBindingConditionOutput() AiFeatureStoreEntityTypeIamBindingConditionOutput
	ToAiFeatureStoreEntityTypeIamBindingConditionOutputWithContext(context.Context) AiFeatureStoreEntityTypeIamBindingConditionOutput
}

type AiFeatureStoreEntityTypeIamBindingConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureStoreEntityTypeIamBindingConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeIamBindingCondition)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeIamBindingConditionArgs) ToAiFeatureStoreEntityTypeIamBindingConditionOutput() AiFeatureStoreEntityTypeIamBindingConditionOutput {
	return i.ToAiFeatureStoreEntityTypeIamBindingConditionOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeIamBindingConditionArgs) ToAiFeatureStoreEntityTypeIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamBindingConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeIamBindingConditionOutput)
}

func (i AiFeatureStoreEntityTypeIamBindingConditionArgs) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutput() AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return i.ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeIamBindingConditionArgs) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeIamBindingConditionOutput).ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeIamBindingConditionPtrInput is an input type that accepts AiFeatureStoreEntityTypeIamBindingConditionArgs, AiFeatureStoreEntityTypeIamBindingConditionPtr and AiFeatureStoreEntityTypeIamBindingConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeIamBindingConditionPtrInput` via:
//
//	        AiFeatureStoreEntityTypeIamBindingConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeIamBindingConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutput() AiFeatureStoreEntityTypeIamBindingConditionPtrOutput
	ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeIamBindingConditionPtrOutput
}

type aiFeatureStoreEntityTypeIamBindingConditionPtrType AiFeatureStoreEntityTypeIamBindingConditionArgs

func AiFeatureStoreEntityTypeIamBindingConditionPtr(v *AiFeatureStoreEntityTypeIamBindingConditionArgs) AiFeatureStoreEntityTypeIamBindingConditionPtrInput {
	return (*aiFeatureStoreEntityTypeIamBindingConditionPtrType)(v)
}

func (*aiFeatureStoreEntityTypeIamBindingConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeIamBindingCondition)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeIamBindingConditionPtrType) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutput() AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return i.ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeIamBindingConditionPtrType) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeIamBindingConditionPtrOutput)
}

type AiFeatureStoreEntityTypeIamBindingConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeIamBindingConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) ToAiFeatureStoreEntityTypeIamBindingConditionOutput() AiFeatureStoreEntityTypeIamBindingConditionOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) ToAiFeatureStoreEntityTypeIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamBindingConditionOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutput() AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return o.ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeIamBindingCondition) *AiFeatureStoreEntityTypeIamBindingCondition {
		return &v
	}).(AiFeatureStoreEntityTypeIamBindingConditionPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeIamBindingCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeIamBindingCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureStoreEntityTypeIamBindingConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeIamBindingCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureStoreEntityTypeIamBindingConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutput() AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) ToAiFeatureStoreEntityTypeIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) Elem() AiFeatureStoreEntityTypeIamBindingConditionOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamBindingCondition) AiFeatureStoreEntityTypeIamBindingCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeIamBindingCondition
		return ret
	}).(AiFeatureStoreEntityTypeIamBindingConditionOutput)
}

func (o AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamBindingConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreEntityTypeIamMemberCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureStoreEntityTypeIamMemberConditionInput is an input type that accepts AiFeatureStoreEntityTypeIamMemberConditionArgs and AiFeatureStoreEntityTypeIamMemberConditionOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeIamMemberConditionInput` via:
//
//	AiFeatureStoreEntityTypeIamMemberConditionArgs{...}
type AiFeatureStoreEntityTypeIamMemberConditionInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeIamMemberConditionOutput() AiFeatureStoreEntityTypeIamMemberConditionOutput
	ToAiFeatureStoreEntityTypeIamMemberConditionOutputWithContext(context.Context) AiFeatureStoreEntityTypeIamMemberConditionOutput
}

type AiFeatureStoreEntityTypeIamMemberConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureStoreEntityTypeIamMemberConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeIamMemberCondition)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeIamMemberConditionArgs) ToAiFeatureStoreEntityTypeIamMemberConditionOutput() AiFeatureStoreEntityTypeIamMemberConditionOutput {
	return i.ToAiFeatureStoreEntityTypeIamMemberConditionOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeIamMemberConditionArgs) ToAiFeatureStoreEntityTypeIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamMemberConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeIamMemberConditionOutput)
}

func (i AiFeatureStoreEntityTypeIamMemberConditionArgs) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutput() AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return i.ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeIamMemberConditionArgs) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeIamMemberConditionOutput).ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeIamMemberConditionPtrInput is an input type that accepts AiFeatureStoreEntityTypeIamMemberConditionArgs, AiFeatureStoreEntityTypeIamMemberConditionPtr and AiFeatureStoreEntityTypeIamMemberConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeIamMemberConditionPtrInput` via:
//
//	        AiFeatureStoreEntityTypeIamMemberConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeIamMemberConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutput() AiFeatureStoreEntityTypeIamMemberConditionPtrOutput
	ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeIamMemberConditionPtrOutput
}

type aiFeatureStoreEntityTypeIamMemberConditionPtrType AiFeatureStoreEntityTypeIamMemberConditionArgs

func AiFeatureStoreEntityTypeIamMemberConditionPtr(v *AiFeatureStoreEntityTypeIamMemberConditionArgs) AiFeatureStoreEntityTypeIamMemberConditionPtrInput {
	return (*aiFeatureStoreEntityTypeIamMemberConditionPtrType)(v)
}

func (*aiFeatureStoreEntityTypeIamMemberConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeIamMemberCondition)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeIamMemberConditionPtrType) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutput() AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return i.ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeIamMemberConditionPtrType) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeIamMemberConditionPtrOutput)
}

type AiFeatureStoreEntityTypeIamMemberConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeIamMemberConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) ToAiFeatureStoreEntityTypeIamMemberConditionOutput() AiFeatureStoreEntityTypeIamMemberConditionOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) ToAiFeatureStoreEntityTypeIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamMemberConditionOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutput() AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return o.ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeIamMemberCondition) *AiFeatureStoreEntityTypeIamMemberCondition {
		return &v
	}).(AiFeatureStoreEntityTypeIamMemberConditionPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeIamMemberCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeIamMemberCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureStoreEntityTypeIamMemberConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeIamMemberCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureStoreEntityTypeIamMemberConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutput() AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) ToAiFeatureStoreEntityTypeIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) Elem() AiFeatureStoreEntityTypeIamMemberConditionOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamMemberCondition) AiFeatureStoreEntityTypeIamMemberCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeIamMemberCondition
		return ret
	}).(AiFeatureStoreEntityTypeIamMemberConditionOutput)
}

func (o AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreEntityTypeIamMemberConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfig struct {
	// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
	// Structure is documented below.
	CategoricalThresholdConfig *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig `pulumi:"categoricalThresholdConfig"`
	// The config for ImportFeatures Analysis Based Feature Monitoring.
	// Structure is documented below.
	ImportFeaturesAnalysis *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis `pulumi:"importFeaturesAnalysis"`
	// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
	// Structure is documented below.
	NumericalThresholdConfig *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig `pulumi:"numericalThresholdConfig"`
	// The config for Snapshot Analysis Based Feature Monitoring.
	// Structure is documented below.
	SnapshotAnalysis *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis `pulumi:"snapshotAnalysis"`
}

// AiFeatureStoreEntityTypeMonitoringConfigInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigArgs and AiFeatureStoreEntityTypeMonitoringConfigOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigInput` via:
//
//	AiFeatureStoreEntityTypeMonitoringConfigArgs{...}
type AiFeatureStoreEntityTypeMonitoringConfigInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigOutput
}

type AiFeatureStoreEntityTypeMonitoringConfigArgs struct {
	// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
	// Structure is documented below.
	CategoricalThresholdConfig AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrInput `pulumi:"categoricalThresholdConfig"`
	// The config for ImportFeatures Analysis Based Feature Monitoring.
	// Structure is documented below.
	ImportFeaturesAnalysis AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrInput `pulumi:"importFeaturesAnalysis"`
	// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
	// Structure is documented below.
	NumericalThresholdConfig AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrInput `pulumi:"numericalThresholdConfig"`
	// The config for Snapshot Analysis Based Feature Monitoring.
	// Structure is documented below.
	SnapshotAnalysis AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrInput `pulumi:"snapshotAnalysis"`
}

func (AiFeatureStoreEntityTypeMonitoringConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfig)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeMonitoringConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigOutput)
}

func (i AiFeatureStoreEntityTypeMonitoringConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigOutput).ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeMonitoringConfigPtrInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigArgs, AiFeatureStoreEntityTypeMonitoringConfigPtr and AiFeatureStoreEntityTypeMonitoringConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigPtrInput` via:
//
//	        AiFeatureStoreEntityTypeMonitoringConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeMonitoringConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigPtrOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigPtrOutput
}

type aiFeatureStoreEntityTypeMonitoringConfigPtrType AiFeatureStoreEntityTypeMonitoringConfigArgs

func AiFeatureStoreEntityTypeMonitoringConfigPtr(v *AiFeatureStoreEntityTypeMonitoringConfigArgs) AiFeatureStoreEntityTypeMonitoringConfigPtrInput {
	return (*aiFeatureStoreEntityTypeMonitoringConfigPtrType)(v)
}

func (*aiFeatureStoreEntityTypeMonitoringConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfig)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfig)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return o.ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfig {
		return &v
	}).(AiFeatureStoreEntityTypeMonitoringConfigPtrOutput)
}

// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) CategoricalThresholdConfig() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig {
		return v.CategoricalThresholdConfig
	}).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput)
}

// The config for ImportFeatures Analysis Based Feature Monitoring.
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) ImportFeaturesAnalysis() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis {
		return v.ImportFeaturesAnalysis
	}).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) NumericalThresholdConfig() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig {
		return v.NumericalThresholdConfig
	}).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput)
}

// The config for Snapshot Analysis Based Feature Monitoring.
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigOutput) SnapshotAnalysis() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis {
		return v.SnapshotAnalysis
	}).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfig)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) Elem() AiFeatureStoreEntityTypeMonitoringConfigOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfig) AiFeatureStoreEntityTypeMonitoringConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeMonitoringConfig
		return ret
	}).(AiFeatureStoreEntityTypeMonitoringConfigOutput)
}

// Threshold for categorical features of anomaly detection. This is shared by all types of Featurestore Monitoring for categorical features (i.e. Features with type (Feature.ValueType) BOOL or STRING).
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) CategoricalThresholdConfig() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig {
		if v == nil {
			return nil
		}
		return v.CategoricalThresholdConfig
	}).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput)
}

// The config for ImportFeatures Analysis Based Feature Monitoring.
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) ImportFeaturesAnalysis() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis {
		if v == nil {
			return nil
		}
		return v.ImportFeaturesAnalysis
	}).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// Threshold for numerical features of anomaly detection. This is shared by all objectives of Featurestore Monitoring for numerical features (i.e. Features with type (Feature.ValueType) DOUBLE or INT64).
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) NumericalThresholdConfig() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig {
		if v == nil {
			return nil
		}
		return v.NumericalThresholdConfig
	}).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput)
}

// The config for Snapshot Analysis Based Feature Monitoring.
// Structure is documented below.
func (o AiFeatureStoreEntityTypeMonitoringConfigPtrOutput) SnapshotAnalysis() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfig) *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis {
		if v == nil {
			return nil
		}
		return v.SnapshotAnalysis
	}).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig struct {
	// Specify a threshold value that can trigger the alert. For categorical feature, the distribution distance is calculated by L-inifinity norm. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
	Value float64 `pulumi:"value"`
}

// AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs and AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigInput` via:
//
//	AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs{...}
type AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput
}

type AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs struct {
	// Specify a threshold value that can trigger the alert. For categorical feature, the distribution distance is calculated by L-inifinity norm. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
	Value pulumi.Float64Input `pulumi:"value"`
}

func (AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput)
}

func (i AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput).ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs, AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtr and AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrInput` via:
//
//	        AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput
}

type aiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrType AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs

func AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtr(v *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrInput {
	return (*aiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrType)(v)
}

func (*aiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return o.ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig) *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig {
		return &v
	}).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput)
}

// Specify a threshold value that can trigger the alert. For categorical feature, the distribution distance is calculated by L-inifinity norm. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput) Value() pulumi.Float64Output {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig) float64 { return v.Value }).(pulumi.Float64Output)
}

type AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput) Elem() AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig) AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig
		return ret
	}).(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput)
}

// Specify a threshold value that can trigger the alert. For categorical feature, the distribution distance is calculated by L-inifinity norm. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
func (o AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput) Value() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfig) *float64 {
		if v == nil {
			return nil
		}
		return &v.Value
	}).(pulumi.Float64PtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis struct {
	// Defines the baseline to do anomaly detection for feature values imported by each [entityTypes.importFeatureValues][] operation. The value must be one of the values below:
	// * LATEST_STATS: Choose the later one statistics generated by either most recent snapshot analysis or previous import features analysis. If non of them exists, skip anomaly detection and only generate a statistics.
	// * MOST_RECENT_SNAPSHOT_STATS: Use the statistics generated by the most recent snapshot analysis if exists.
	// * PREVIOUS_IMPORT_FEATURES_STATS: Use the statistics generated by the previous import features analysis if exists.
	AnomalyDetectionBaseline *string `pulumi:"anomalyDetectionBaseline"`
	// Whether to enable / disable / inherite default hebavior for import features analysis. The value must be one of the values below:
	// * DEFAULT: The default behavior of whether to enable the monitoring. EntityType-level config: disabled.
	// * ENABLED: Explicitly enables import features analysis. EntityType-level config: by default enables import features analysis for all Features under it.
	// * DISABLED: Explicitly disables import features analysis. EntityType-level config: by default disables import features analysis for all Features under it.
	State *string `pulumi:"state"`
}

// AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs and AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisInput` via:
//
//	AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs{...}
type AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput
}

type AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs struct {
	// Defines the baseline to do anomaly detection for feature values imported by each [entityTypes.importFeatureValues][] operation. The value must be one of the values below:
	// * LATEST_STATS: Choose the later one statistics generated by either most recent snapshot analysis or previous import features analysis. If non of them exists, skip anomaly detection and only generate a statistics.
	// * MOST_RECENT_SNAPSHOT_STATS: Use the statistics generated by the most recent snapshot analysis if exists.
	// * PREVIOUS_IMPORT_FEATURES_STATS: Use the statistics generated by the previous import features analysis if exists.
	AnomalyDetectionBaseline pulumi.StringPtrInput `pulumi:"anomalyDetectionBaseline"`
	// Whether to enable / disable / inherite default hebavior for import features analysis. The value must be one of the values below:
	// * DEFAULT: The default behavior of whether to enable the monitoring. EntityType-level config: disabled.
	// * ENABLED: Explicitly enables import features analysis. EntityType-level config: by default enables import features analysis for all Features under it.
	// * DISABLED: Explicitly disables import features analysis. EntityType-level config: by default disables import features analysis for all Features under it.
	State pulumi.StringPtrInput `pulumi:"state"`
}

func (AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput)
}

func (i AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput).ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs, AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtr and AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrInput` via:
//
//	        AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput
}

type aiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrType AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs

func AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtr(v *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrInput {
	return (*aiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrType)(v)
}

func (*aiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis) *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis {
		return &v
	}).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput)
}

// Defines the baseline to do anomaly detection for feature values imported by each [entityTypes.importFeatureValues][] operation. The value must be one of the values below:
// * LATEST_STATS: Choose the later one statistics generated by either most recent snapshot analysis or previous import features analysis. If non of them exists, skip anomaly detection and only generate a statistics.
// * MOST_RECENT_SNAPSHOT_STATS: Use the statistics generated by the most recent snapshot analysis if exists.
// * PREVIOUS_IMPORT_FEATURES_STATS: Use the statistics generated by the previous import features analysis if exists.
func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) AnomalyDetectionBaseline() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis) *string {
		return v.AnomalyDetectionBaseline
	}).(pulumi.StringPtrOutput)
}

// Whether to enable / disable / inherite default hebavior for import features analysis. The value must be one of the values below:
// * DEFAULT: The default behavior of whether to enable the monitoring. EntityType-level config: disabled.
// * ENABLED: Explicitly enables import features analysis. EntityType-level config: by default enables import features analysis for all Features under it.
// * DISABLED: Explicitly disables import features analysis. EntityType-level config: by default disables import features analysis for all Features under it.
func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput) State() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis) *string { return v.State }).(pulumi.StringPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput) Elem() AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis) AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis
		return ret
	}).(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput)
}

// Defines the baseline to do anomaly detection for feature values imported by each [entityTypes.importFeatureValues][] operation. The value must be one of the values below:
// * LATEST_STATS: Choose the later one statistics generated by either most recent snapshot analysis or previous import features analysis. If non of them exists, skip anomaly detection and only generate a statistics.
// * MOST_RECENT_SNAPSHOT_STATS: Use the statistics generated by the most recent snapshot analysis if exists.
// * PREVIOUS_IMPORT_FEATURES_STATS: Use the statistics generated by the previous import features analysis if exists.
func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput) AnomalyDetectionBaseline() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis) *string {
		if v == nil {
			return nil
		}
		return v.AnomalyDetectionBaseline
	}).(pulumi.StringPtrOutput)
}

// Whether to enable / disable / inherite default hebavior for import features analysis. The value must be one of the values below:
// * DEFAULT: The default behavior of whether to enable the monitoring. EntityType-level config: disabled.
// * ENABLED: Explicitly enables import features analysis. EntityType-level config: by default enables import features analysis for all Features under it.
// * DISABLED: Explicitly disables import features analysis. EntityType-level config: by default disables import features analysis for all Features under it.
func (o AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput) State() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysis) *string {
		if v == nil {
			return nil
		}
		return v.State
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig struct {
	// Specify a threshold value that can trigger the alert. For numerical feature, the distribution distance is calculated by JensenShannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
	Value float64 `pulumi:"value"`
}

// AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs and AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigInput` via:
//
//	AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs{...}
type AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput
}

type AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs struct {
	// Specify a threshold value that can trigger the alert. For numerical feature, the distribution distance is calculated by JensenShannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
	Value pulumi.Float64Input `pulumi:"value"`
}

func (AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput)
}

func (i AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput).ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs, AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtr and AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrInput` via:
//
//	        AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput
}

type aiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrType AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs

func AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtr(v *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrInput {
	return (*aiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrType)(v)
}

func (*aiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return o.ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig) *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig {
		return &v
	}).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput)
}

// Specify a threshold value that can trigger the alert. For numerical feature, the distribution distance is calculated by JensenShannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput) Value() pulumi.Float64Output {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig) float64 { return v.Value }).(pulumi.Float64Output)
}

type AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput) Elem() AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig) AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig
		return ret
	}).(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput)
}

// Specify a threshold value that can trigger the alert. For numerical feature, the distribution distance is calculated by JensenShannon divergence. Each feature must have a non-zero threshold if they need to be monitored. Otherwise no alert will be triggered for that feature. The default value is 0.3.
func (o AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput) Value() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfig) *float64 {
		if v == nil {
			return nil
		}
		return &v.Value
	}).(pulumi.Float64PtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis struct {
	// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoringInterval for Features under it.
	Disabled *bool `pulumi:"disabled"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value is rolled up to full day.
	// A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
	//
	// > **Warning:** `monitoringInterval` is deprecated and will be removed in a future release.
	//
	// Deprecated: `monitoringInterval` is deprecated and will be removed in a future release.
	MonitoringInterval *string `pulumi:"monitoringInterval"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days. The default value is 1.
	// If both FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days and [FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval][] are set when creating/updating EntityTypes/Features, FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days will be used.
	MonitoringIntervalDays *int `pulumi:"monitoringIntervalDays"`
	// Customized export features time window for snapshot analysis. Unit is one day. The default value is 21 days. Minimum value is 1 day. Maximum value is 4000 days.
	StalenessDays *int `pulumi:"stalenessDays"`
}

// AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs and AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisInput` via:
//
//	AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs{...}
type AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput
}

type AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs struct {
	// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoringInterval for Features under it.
	Disabled pulumi.BoolPtrInput `pulumi:"disabled"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value is rolled up to full day.
	// A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
	//
	// > **Warning:** `monitoringInterval` is deprecated and will be removed in a future release.
	//
	// Deprecated: `monitoringInterval` is deprecated and will be removed in a future release.
	MonitoringInterval pulumi.StringPtrInput `pulumi:"monitoringInterval"`
	// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days. The default value is 1.
	// If both FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days and [FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval][] are set when creating/updating EntityTypes/Features, FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days will be used.
	MonitoringIntervalDays pulumi.IntPtrInput `pulumi:"monitoringIntervalDays"`
	// Customized export features time window for snapshot analysis. Unit is one day. The default value is 21 days. Minimum value is 1 day. Maximum value is 4000 days.
	StalenessDays pulumi.IntPtrInput `pulumi:"stalenessDays"`
}

func (AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (i AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput)
}

func (i AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput).ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx)
}

// AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrInput is an input type that accepts AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs, AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtr and AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrInput` via:
//
//	        AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput
	ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput
}

type aiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrType AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs

func AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtr(v *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrInput {
	return (*aiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrType)(v)
}

func (*aiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return i.ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrType) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis {
		return &v
	}).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput)
}

// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoringInterval for Features under it.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) Disabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *bool { return v.Disabled }).(pulumi.BoolPtrOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value is rolled up to full day.
// A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
//
// > **Warning:** `monitoringInterval` is deprecated and will be removed in a future release.
//
// Deprecated: `monitoringInterval` is deprecated and will be removed in a future release.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) MonitoringInterval() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *string { return v.MonitoringInterval }).(pulumi.StringPtrOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days. The default value is 1.
// If both FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days and [FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval][] are set when creating/updating EntityTypes/Features, FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days will be used.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) MonitoringIntervalDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *int { return v.MonitoringIntervalDays }).(pulumi.IntPtrOutput)
}

// Customized export features time window for snapshot analysis. Unit is one day. The default value is 21 days. Minimum value is 1 day. Maximum value is 4000 days.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput) StalenessDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *int { return v.StalenessDays }).(pulumi.IntPtrOutput)
}

type AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis)(nil)).Elem()
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) ToAiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutputWithContext(ctx context.Context) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput {
	return o
}

func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) Elem() AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis
		return ret
	}).(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput)
}

// The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoringInterval for Features under it.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) Disabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *bool {
		if v == nil {
			return nil
		}
		return v.Disabled
	}).(pulumi.BoolPtrOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value is rolled up to full day.
// A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".
//
// > **Warning:** `monitoringInterval` is deprecated and will be removed in a future release.
//
// Deprecated: `monitoringInterval` is deprecated and will be removed in a future release.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) MonitoringInterval() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *string {
		if v == nil {
			return nil
		}
		return v.MonitoringInterval
	}).(pulumi.StringPtrOutput)
}

// Configuration of the snapshot analysis based monitoring pipeline running interval. The value indicates number of days. The default value is 1.
// If both FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days and [FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval][] are set when creating/updating EntityTypes/Features, FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days will be used.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) MonitoringIntervalDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *int {
		if v == nil {
			return nil
		}
		return v.MonitoringIntervalDays
	}).(pulumi.IntPtrOutput)
}

// Customized export features time window for snapshot analysis. Unit is one day. The default value is 21 days. Minimum value is 1 day. Maximum value is 4000 days.
func (o AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput) StalenessDays() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysis) *int {
		if v == nil {
			return nil
		}
		return v.StalenessDays
	}).(pulumi.IntPtrOutput)
}

type AiFeatureStoreIamBindingCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureStoreIamBindingConditionInput is an input type that accepts AiFeatureStoreIamBindingConditionArgs and AiFeatureStoreIamBindingConditionOutput values.
// You can construct a concrete instance of `AiFeatureStoreIamBindingConditionInput` via:
//
//	AiFeatureStoreIamBindingConditionArgs{...}
type AiFeatureStoreIamBindingConditionInput interface {
	pulumi.Input

	ToAiFeatureStoreIamBindingConditionOutput() AiFeatureStoreIamBindingConditionOutput
	ToAiFeatureStoreIamBindingConditionOutputWithContext(context.Context) AiFeatureStoreIamBindingConditionOutput
}

type AiFeatureStoreIamBindingConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureStoreIamBindingConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreIamBindingCondition)(nil)).Elem()
}

func (i AiFeatureStoreIamBindingConditionArgs) ToAiFeatureStoreIamBindingConditionOutput() AiFeatureStoreIamBindingConditionOutput {
	return i.ToAiFeatureStoreIamBindingConditionOutputWithContext(context.Background())
}

func (i AiFeatureStoreIamBindingConditionArgs) ToAiFeatureStoreIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureStoreIamBindingConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreIamBindingConditionOutput)
}

func (i AiFeatureStoreIamBindingConditionArgs) ToAiFeatureStoreIamBindingConditionPtrOutput() AiFeatureStoreIamBindingConditionPtrOutput {
	return i.ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreIamBindingConditionArgs) ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreIamBindingConditionOutput).ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(ctx)
}

// AiFeatureStoreIamBindingConditionPtrInput is an input type that accepts AiFeatureStoreIamBindingConditionArgs, AiFeatureStoreIamBindingConditionPtr and AiFeatureStoreIamBindingConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreIamBindingConditionPtrInput` via:
//
//	        AiFeatureStoreIamBindingConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreIamBindingConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreIamBindingConditionPtrOutput() AiFeatureStoreIamBindingConditionPtrOutput
	ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(context.Context) AiFeatureStoreIamBindingConditionPtrOutput
}

type aiFeatureStoreIamBindingConditionPtrType AiFeatureStoreIamBindingConditionArgs

func AiFeatureStoreIamBindingConditionPtr(v *AiFeatureStoreIamBindingConditionArgs) AiFeatureStoreIamBindingConditionPtrInput {
	return (*aiFeatureStoreIamBindingConditionPtrType)(v)
}

func (*aiFeatureStoreIamBindingConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreIamBindingCondition)(nil)).Elem()
}

func (i *aiFeatureStoreIamBindingConditionPtrType) ToAiFeatureStoreIamBindingConditionPtrOutput() AiFeatureStoreIamBindingConditionPtrOutput {
	return i.ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreIamBindingConditionPtrType) ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamBindingConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreIamBindingConditionPtrOutput)
}

type AiFeatureStoreIamBindingConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreIamBindingConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureStoreIamBindingConditionOutput) ToAiFeatureStoreIamBindingConditionOutput() AiFeatureStoreIamBindingConditionOutput {
	return o
}

func (o AiFeatureStoreIamBindingConditionOutput) ToAiFeatureStoreIamBindingConditionOutputWithContext(ctx context.Context) AiFeatureStoreIamBindingConditionOutput {
	return o
}

func (o AiFeatureStoreIamBindingConditionOutput) ToAiFeatureStoreIamBindingConditionPtrOutput() AiFeatureStoreIamBindingConditionPtrOutput {
	return o.ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreIamBindingConditionOutput) ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamBindingConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreIamBindingCondition) *AiFeatureStoreIamBindingCondition {
		return &v
	}).(AiFeatureStoreIamBindingConditionPtrOutput)
}

func (o AiFeatureStoreIamBindingConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreIamBindingCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreIamBindingConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreIamBindingCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureStoreIamBindingConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreIamBindingCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureStoreIamBindingConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreIamBindingConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreIamBindingCondition)(nil)).Elem()
}

func (o AiFeatureStoreIamBindingConditionPtrOutput) ToAiFeatureStoreIamBindingConditionPtrOutput() AiFeatureStoreIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureStoreIamBindingConditionPtrOutput) ToAiFeatureStoreIamBindingConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamBindingConditionPtrOutput {
	return o
}

func (o AiFeatureStoreIamBindingConditionPtrOutput) Elem() AiFeatureStoreIamBindingConditionOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamBindingCondition) AiFeatureStoreIamBindingCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreIamBindingCondition
		return ret
	}).(AiFeatureStoreIamBindingConditionOutput)
}

func (o AiFeatureStoreIamBindingConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreIamBindingConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreIamBindingConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamBindingCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreIamMemberCondition struct {
	Description *string `pulumi:"description"`
	Expression  string  `pulumi:"expression"`
	Title       string  `pulumi:"title"`
}

// AiFeatureStoreIamMemberConditionInput is an input type that accepts AiFeatureStoreIamMemberConditionArgs and AiFeatureStoreIamMemberConditionOutput values.
// You can construct a concrete instance of `AiFeatureStoreIamMemberConditionInput` via:
//
//	AiFeatureStoreIamMemberConditionArgs{...}
type AiFeatureStoreIamMemberConditionInput interface {
	pulumi.Input

	ToAiFeatureStoreIamMemberConditionOutput() AiFeatureStoreIamMemberConditionOutput
	ToAiFeatureStoreIamMemberConditionOutputWithContext(context.Context) AiFeatureStoreIamMemberConditionOutput
}

type AiFeatureStoreIamMemberConditionArgs struct {
	Description pulumi.StringPtrInput `pulumi:"description"`
	Expression  pulumi.StringInput    `pulumi:"expression"`
	Title       pulumi.StringInput    `pulumi:"title"`
}

func (AiFeatureStoreIamMemberConditionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreIamMemberCondition)(nil)).Elem()
}

func (i AiFeatureStoreIamMemberConditionArgs) ToAiFeatureStoreIamMemberConditionOutput() AiFeatureStoreIamMemberConditionOutput {
	return i.ToAiFeatureStoreIamMemberConditionOutputWithContext(context.Background())
}

func (i AiFeatureStoreIamMemberConditionArgs) ToAiFeatureStoreIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureStoreIamMemberConditionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreIamMemberConditionOutput)
}

func (i AiFeatureStoreIamMemberConditionArgs) ToAiFeatureStoreIamMemberConditionPtrOutput() AiFeatureStoreIamMemberConditionPtrOutput {
	return i.ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreIamMemberConditionArgs) ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreIamMemberConditionOutput).ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(ctx)
}

// AiFeatureStoreIamMemberConditionPtrInput is an input type that accepts AiFeatureStoreIamMemberConditionArgs, AiFeatureStoreIamMemberConditionPtr and AiFeatureStoreIamMemberConditionPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreIamMemberConditionPtrInput` via:
//
//	        AiFeatureStoreIamMemberConditionArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreIamMemberConditionPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreIamMemberConditionPtrOutput() AiFeatureStoreIamMemberConditionPtrOutput
	ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(context.Context) AiFeatureStoreIamMemberConditionPtrOutput
}

type aiFeatureStoreIamMemberConditionPtrType AiFeatureStoreIamMemberConditionArgs

func AiFeatureStoreIamMemberConditionPtr(v *AiFeatureStoreIamMemberConditionArgs) AiFeatureStoreIamMemberConditionPtrInput {
	return (*aiFeatureStoreIamMemberConditionPtrType)(v)
}

func (*aiFeatureStoreIamMemberConditionPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreIamMemberCondition)(nil)).Elem()
}

func (i *aiFeatureStoreIamMemberConditionPtrType) ToAiFeatureStoreIamMemberConditionPtrOutput() AiFeatureStoreIamMemberConditionPtrOutput {
	return i.ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreIamMemberConditionPtrType) ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamMemberConditionPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreIamMemberConditionPtrOutput)
}

type AiFeatureStoreIamMemberConditionOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreIamMemberConditionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureStoreIamMemberConditionOutput) ToAiFeatureStoreIamMemberConditionOutput() AiFeatureStoreIamMemberConditionOutput {
	return o
}

func (o AiFeatureStoreIamMemberConditionOutput) ToAiFeatureStoreIamMemberConditionOutputWithContext(ctx context.Context) AiFeatureStoreIamMemberConditionOutput {
	return o
}

func (o AiFeatureStoreIamMemberConditionOutput) ToAiFeatureStoreIamMemberConditionPtrOutput() AiFeatureStoreIamMemberConditionPtrOutput {
	return o.ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreIamMemberConditionOutput) ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamMemberConditionPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreIamMemberCondition) *AiFeatureStoreIamMemberCondition {
		return &v
	}).(AiFeatureStoreIamMemberConditionPtrOutput)
}

func (o AiFeatureStoreIamMemberConditionOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreIamMemberCondition) *string { return v.Description }).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreIamMemberConditionOutput) Expression() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreIamMemberCondition) string { return v.Expression }).(pulumi.StringOutput)
}

func (o AiFeatureStoreIamMemberConditionOutput) Title() pulumi.StringOutput {
	return o.ApplyT(func(v AiFeatureStoreIamMemberCondition) string { return v.Title }).(pulumi.StringOutput)
}

type AiFeatureStoreIamMemberConditionPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreIamMemberConditionPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreIamMemberCondition)(nil)).Elem()
}

func (o AiFeatureStoreIamMemberConditionPtrOutput) ToAiFeatureStoreIamMemberConditionPtrOutput() AiFeatureStoreIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureStoreIamMemberConditionPtrOutput) ToAiFeatureStoreIamMemberConditionPtrOutputWithContext(ctx context.Context) AiFeatureStoreIamMemberConditionPtrOutput {
	return o
}

func (o AiFeatureStoreIamMemberConditionPtrOutput) Elem() AiFeatureStoreIamMemberConditionOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamMemberCondition) AiFeatureStoreIamMemberCondition {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreIamMemberCondition
		return ret
	}).(AiFeatureStoreIamMemberConditionOutput)
}

func (o AiFeatureStoreIamMemberConditionPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreIamMemberConditionPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Expression
	}).(pulumi.StringPtrOutput)
}

func (o AiFeatureStoreIamMemberConditionPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreIamMemberCondition) *string {
		if v == nil {
			return nil
		}
		return &v.Title
	}).(pulumi.StringPtrOutput)
}

type AiFeatureStoreOnlineServingConfig struct {
	// The number of nodes for each cluster. The number of nodes will not scale automatically but can be scaled manually by providing different values when updating.
	FixedNodeCount *int `pulumi:"fixedNodeCount"`
	// Online serving scaling configuration. Only one of fixedNodeCount and scaling can be set. Setting one will reset the other.
	// Structure is documented below.
	Scaling *AiFeatureStoreOnlineServingConfigScaling `pulumi:"scaling"`
}

// AiFeatureStoreOnlineServingConfigInput is an input type that accepts AiFeatureStoreOnlineServingConfigArgs and AiFeatureStoreOnlineServingConfigOutput values.
// You can construct a concrete instance of `AiFeatureStoreOnlineServingConfigInput` via:
//
//	AiFeatureStoreOnlineServingConfigArgs{...}
type AiFeatureStoreOnlineServingConfigInput interface {
	pulumi.Input

	ToAiFeatureStoreOnlineServingConfigOutput() AiFeatureStoreOnlineServingConfigOutput
	ToAiFeatureStoreOnlineServingConfigOutputWithContext(context.Context) AiFeatureStoreOnlineServingConfigOutput
}

type AiFeatureStoreOnlineServingConfigArgs struct {
	// The number of nodes for each cluster. The number of nodes will not scale automatically but can be scaled manually by providing different values when updating.
	FixedNodeCount pulumi.IntPtrInput `pulumi:"fixedNodeCount"`
	// Online serving scaling configuration. Only one of fixedNodeCount and scaling can be set. Setting one will reset the other.
	// Structure is documented below.
	Scaling AiFeatureStoreOnlineServingConfigScalingPtrInput `pulumi:"scaling"`
}

func (AiFeatureStoreOnlineServingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreOnlineServingConfig)(nil)).Elem()
}

func (i AiFeatureStoreOnlineServingConfigArgs) ToAiFeatureStoreOnlineServingConfigOutput() AiFeatureStoreOnlineServingConfigOutput {
	return i.ToAiFeatureStoreOnlineServingConfigOutputWithContext(context.Background())
}

func (i AiFeatureStoreOnlineServingConfigArgs) ToAiFeatureStoreOnlineServingConfigOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreOnlineServingConfigOutput)
}

func (i AiFeatureStoreOnlineServingConfigArgs) ToAiFeatureStoreOnlineServingConfigPtrOutput() AiFeatureStoreOnlineServingConfigPtrOutput {
	return i.ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreOnlineServingConfigArgs) ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreOnlineServingConfigOutput).ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(ctx)
}

// AiFeatureStoreOnlineServingConfigPtrInput is an input type that accepts AiFeatureStoreOnlineServingConfigArgs, AiFeatureStoreOnlineServingConfigPtr and AiFeatureStoreOnlineServingConfigPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreOnlineServingConfigPtrInput` via:
//
//	        AiFeatureStoreOnlineServingConfigArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreOnlineServingConfigPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreOnlineServingConfigPtrOutput() AiFeatureStoreOnlineServingConfigPtrOutput
	ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(context.Context) AiFeatureStoreOnlineServingConfigPtrOutput
}

type aiFeatureStoreOnlineServingConfigPtrType AiFeatureStoreOnlineServingConfigArgs

func AiFeatureStoreOnlineServingConfigPtr(v *AiFeatureStoreOnlineServingConfigArgs) AiFeatureStoreOnlineServingConfigPtrInput {
	return (*aiFeatureStoreOnlineServingConfigPtrType)(v)
}

func (*aiFeatureStoreOnlineServingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreOnlineServingConfig)(nil)).Elem()
}

func (i *aiFeatureStoreOnlineServingConfigPtrType) ToAiFeatureStoreOnlineServingConfigPtrOutput() AiFeatureStoreOnlineServingConfigPtrOutput {
	return i.ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreOnlineServingConfigPtrType) ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreOnlineServingConfigPtrOutput)
}

type AiFeatureStoreOnlineServingConfigOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreOnlineServingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreOnlineServingConfig)(nil)).Elem()
}

func (o AiFeatureStoreOnlineServingConfigOutput) ToAiFeatureStoreOnlineServingConfigOutput() AiFeatureStoreOnlineServingConfigOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigOutput) ToAiFeatureStoreOnlineServingConfigOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigOutput) ToAiFeatureStoreOnlineServingConfigPtrOutput() AiFeatureStoreOnlineServingConfigPtrOutput {
	return o.ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreOnlineServingConfigOutput) ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreOnlineServingConfig) *AiFeatureStoreOnlineServingConfig {
		return &v
	}).(AiFeatureStoreOnlineServingConfigPtrOutput)
}

// The number of nodes for each cluster. The number of nodes will not scale automatically but can be scaled manually by providing different values when updating.
func (o AiFeatureStoreOnlineServingConfigOutput) FixedNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreOnlineServingConfig) *int { return v.FixedNodeCount }).(pulumi.IntPtrOutput)
}

// Online serving scaling configuration. Only one of fixedNodeCount and scaling can be set. Setting one will reset the other.
// Structure is documented below.
func (o AiFeatureStoreOnlineServingConfigOutput) Scaling() AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return o.ApplyT(func(v AiFeatureStoreOnlineServingConfig) *AiFeatureStoreOnlineServingConfigScaling { return v.Scaling }).(AiFeatureStoreOnlineServingConfigScalingPtrOutput)
}

type AiFeatureStoreOnlineServingConfigPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreOnlineServingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreOnlineServingConfig)(nil)).Elem()
}

func (o AiFeatureStoreOnlineServingConfigPtrOutput) ToAiFeatureStoreOnlineServingConfigPtrOutput() AiFeatureStoreOnlineServingConfigPtrOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigPtrOutput) ToAiFeatureStoreOnlineServingConfigPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigPtrOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigPtrOutput) Elem() AiFeatureStoreOnlineServingConfigOutput {
	return o.ApplyT(func(v *AiFeatureStoreOnlineServingConfig) AiFeatureStoreOnlineServingConfig {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreOnlineServingConfig
		return ret
	}).(AiFeatureStoreOnlineServingConfigOutput)
}

// The number of nodes for each cluster. The number of nodes will not scale automatically but can be scaled manually by providing different values when updating.
func (o AiFeatureStoreOnlineServingConfigPtrOutput) FixedNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreOnlineServingConfig) *int {
		if v == nil {
			return nil
		}
		return v.FixedNodeCount
	}).(pulumi.IntPtrOutput)
}

// Online serving scaling configuration. Only one of fixedNodeCount and scaling can be set. Setting one will reset the other.
// Structure is documented below.
func (o AiFeatureStoreOnlineServingConfigPtrOutput) Scaling() AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreOnlineServingConfig) *AiFeatureStoreOnlineServingConfigScaling {
		if v == nil {
			return nil
		}
		return v.Scaling
	}).(AiFeatureStoreOnlineServingConfigScalingPtrOutput)
}

type AiFeatureStoreOnlineServingConfigScaling struct {
	// The maximum number of nodes to scale up to. Must be greater than minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
	MaxNodeCount int `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount int `pulumi:"minNodeCount"`
}

// AiFeatureStoreOnlineServingConfigScalingInput is an input type that accepts AiFeatureStoreOnlineServingConfigScalingArgs and AiFeatureStoreOnlineServingConfigScalingOutput values.
// You can construct a concrete instance of `AiFeatureStoreOnlineServingConfigScalingInput` via:
//
//	AiFeatureStoreOnlineServingConfigScalingArgs{...}
type AiFeatureStoreOnlineServingConfigScalingInput interface {
	pulumi.Input

	ToAiFeatureStoreOnlineServingConfigScalingOutput() AiFeatureStoreOnlineServingConfigScalingOutput
	ToAiFeatureStoreOnlineServingConfigScalingOutputWithContext(context.Context) AiFeatureStoreOnlineServingConfigScalingOutput
}

type AiFeatureStoreOnlineServingConfigScalingArgs struct {
	// The maximum number of nodes to scale up to. Must be greater than minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
	MaxNodeCount pulumi.IntInput `pulumi:"maxNodeCount"`
	// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
	MinNodeCount pulumi.IntInput `pulumi:"minNodeCount"`
}

func (AiFeatureStoreOnlineServingConfigScalingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreOnlineServingConfigScaling)(nil)).Elem()
}

func (i AiFeatureStoreOnlineServingConfigScalingArgs) ToAiFeatureStoreOnlineServingConfigScalingOutput() AiFeatureStoreOnlineServingConfigScalingOutput {
	return i.ToAiFeatureStoreOnlineServingConfigScalingOutputWithContext(context.Background())
}

func (i AiFeatureStoreOnlineServingConfigScalingArgs) ToAiFeatureStoreOnlineServingConfigScalingOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigScalingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreOnlineServingConfigScalingOutput)
}

func (i AiFeatureStoreOnlineServingConfigScalingArgs) ToAiFeatureStoreOnlineServingConfigScalingPtrOutput() AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return i.ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(context.Background())
}

func (i AiFeatureStoreOnlineServingConfigScalingArgs) ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreOnlineServingConfigScalingOutput).ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(ctx)
}

// AiFeatureStoreOnlineServingConfigScalingPtrInput is an input type that accepts AiFeatureStoreOnlineServingConfigScalingArgs, AiFeatureStoreOnlineServingConfigScalingPtr and AiFeatureStoreOnlineServingConfigScalingPtrOutput values.
// You can construct a concrete instance of `AiFeatureStoreOnlineServingConfigScalingPtrInput` via:
//
//	        AiFeatureStoreOnlineServingConfigScalingArgs{...}
//
//	or:
//
//	        nil
type AiFeatureStoreOnlineServingConfigScalingPtrInput interface {
	pulumi.Input

	ToAiFeatureStoreOnlineServingConfigScalingPtrOutput() AiFeatureStoreOnlineServingConfigScalingPtrOutput
	ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(context.Context) AiFeatureStoreOnlineServingConfigScalingPtrOutput
}

type aiFeatureStoreOnlineServingConfigScalingPtrType AiFeatureStoreOnlineServingConfigScalingArgs

func AiFeatureStoreOnlineServingConfigScalingPtr(v *AiFeatureStoreOnlineServingConfigScalingArgs) AiFeatureStoreOnlineServingConfigScalingPtrInput {
	return (*aiFeatureStoreOnlineServingConfigScalingPtrType)(v)
}

func (*aiFeatureStoreOnlineServingConfigScalingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreOnlineServingConfigScaling)(nil)).Elem()
}

func (i *aiFeatureStoreOnlineServingConfigScalingPtrType) ToAiFeatureStoreOnlineServingConfigScalingPtrOutput() AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return i.ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(context.Background())
}

func (i *aiFeatureStoreOnlineServingConfigScalingPtrType) ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiFeatureStoreOnlineServingConfigScalingPtrOutput)
}

type AiFeatureStoreOnlineServingConfigScalingOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreOnlineServingConfigScalingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiFeatureStoreOnlineServingConfigScaling)(nil)).Elem()
}

func (o AiFeatureStoreOnlineServingConfigScalingOutput) ToAiFeatureStoreOnlineServingConfigScalingOutput() AiFeatureStoreOnlineServingConfigScalingOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigScalingOutput) ToAiFeatureStoreOnlineServingConfigScalingOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigScalingOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigScalingOutput) ToAiFeatureStoreOnlineServingConfigScalingPtrOutput() AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return o.ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(context.Background())
}

func (o AiFeatureStoreOnlineServingConfigScalingOutput) ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiFeatureStoreOnlineServingConfigScaling) *AiFeatureStoreOnlineServingConfigScaling {
		return &v
	}).(AiFeatureStoreOnlineServingConfigScalingPtrOutput)
}

// The maximum number of nodes to scale up to. Must be greater than minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
func (o AiFeatureStoreOnlineServingConfigScalingOutput) MaxNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v AiFeatureStoreOnlineServingConfigScaling) int { return v.MaxNodeCount }).(pulumi.IntOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o AiFeatureStoreOnlineServingConfigScalingOutput) MinNodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v AiFeatureStoreOnlineServingConfigScaling) int { return v.MinNodeCount }).(pulumi.IntOutput)
}

type AiFeatureStoreOnlineServingConfigScalingPtrOutput struct{ *pulumi.OutputState }

func (AiFeatureStoreOnlineServingConfigScalingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiFeatureStoreOnlineServingConfigScaling)(nil)).Elem()
}

func (o AiFeatureStoreOnlineServingConfigScalingPtrOutput) ToAiFeatureStoreOnlineServingConfigScalingPtrOutput() AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigScalingPtrOutput) ToAiFeatureStoreOnlineServingConfigScalingPtrOutputWithContext(ctx context.Context) AiFeatureStoreOnlineServingConfigScalingPtrOutput {
	return o
}

func (o AiFeatureStoreOnlineServingConfigScalingPtrOutput) Elem() AiFeatureStoreOnlineServingConfigScalingOutput {
	return o.ApplyT(func(v *AiFeatureStoreOnlineServingConfigScaling) AiFeatureStoreOnlineServingConfigScaling {
		if v != nil {
			return *v
		}
		var ret AiFeatureStoreOnlineServingConfigScaling
		return ret
	}).(AiFeatureStoreOnlineServingConfigScalingOutput)
}

// The maximum number of nodes to scale up to. Must be greater than minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
func (o AiFeatureStoreOnlineServingConfigScalingPtrOutput) MaxNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreOnlineServingConfigScaling) *int {
		if v == nil {
			return nil
		}
		return &v.MaxNodeCount
	}).(pulumi.IntPtrOutput)
}

// The minimum number of nodes to scale down to. Must be greater than or equal to 1.
func (o AiFeatureStoreOnlineServingConfigScalingPtrOutput) MinNodeCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiFeatureStoreOnlineServingConfigScaling) *int {
		if v == nil {
			return nil
		}
		return &v.MinNodeCount
	}).(pulumi.IntPtrOutput)
}

type AiIndexDeployedIndex struct {
	// (Output)
	// The ID of the DeployedIndex in the above IndexEndpoint.
	DeployedIndexId *string `pulumi:"deployedIndexId"`
	// (Output)
	// A resource name of the IndexEndpoint.
	IndexEndpoint *string `pulumi:"indexEndpoint"`
}

// AiIndexDeployedIndexInput is an input type that accepts AiIndexDeployedIndexArgs and AiIndexDeployedIndexOutput values.
// You can construct a concrete instance of `AiIndexDeployedIndexInput` via:
//
//	AiIndexDeployedIndexArgs{...}
type AiIndexDeployedIndexInput interface {
	pulumi.Input

	ToAiIndexDeployedIndexOutput() AiIndexDeployedIndexOutput
	ToAiIndexDeployedIndexOutputWithContext(context.Context) AiIndexDeployedIndexOutput
}

type AiIndexDeployedIndexArgs struct {
	// (Output)
	// The ID of the DeployedIndex in the above IndexEndpoint.
	DeployedIndexId pulumi.StringPtrInput `pulumi:"deployedIndexId"`
	// (Output)
	// A resource name of the IndexEndpoint.
	IndexEndpoint pulumi.StringPtrInput `pulumi:"indexEndpoint"`
}

func (AiIndexDeployedIndexArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexDeployedIndex)(nil)).Elem()
}

func (i AiIndexDeployedIndexArgs) ToAiIndexDeployedIndexOutput() AiIndexDeployedIndexOutput {
	return i.ToAiIndexDeployedIndexOutputWithContext(context.Background())
}

func (i AiIndexDeployedIndexArgs) ToAiIndexDeployedIndexOutputWithContext(ctx context.Context) AiIndexDeployedIndexOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexDeployedIndexOutput)
}

// AiIndexDeployedIndexArrayInput is an input type that accepts AiIndexDeployedIndexArray and AiIndexDeployedIndexArrayOutput values.
// You can construct a concrete instance of `AiIndexDeployedIndexArrayInput` via:
//
//	AiIndexDeployedIndexArray{ AiIndexDeployedIndexArgs{...} }
type AiIndexDeployedIndexArrayInput interface {
	pulumi.Input

	ToAiIndexDeployedIndexArrayOutput() AiIndexDeployedIndexArrayOutput
	ToAiIndexDeployedIndexArrayOutputWithContext(context.Context) AiIndexDeployedIndexArrayOutput
}

type AiIndexDeployedIndexArray []AiIndexDeployedIndexInput

func (AiIndexDeployedIndexArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiIndexDeployedIndex)(nil)).Elem()
}

func (i AiIndexDeployedIndexArray) ToAiIndexDeployedIndexArrayOutput() AiIndexDeployedIndexArrayOutput {
	return i.ToAiIndexDeployedIndexArrayOutputWithContext(context.Background())
}

func (i AiIndexDeployedIndexArray) ToAiIndexDeployedIndexArrayOutputWithContext(ctx context.Context) AiIndexDeployedIndexArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexDeployedIndexArrayOutput)
}

type AiIndexDeployedIndexOutput struct{ *pulumi.OutputState }

func (AiIndexDeployedIndexOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexDeployedIndex)(nil)).Elem()
}

func (o AiIndexDeployedIndexOutput) ToAiIndexDeployedIndexOutput() AiIndexDeployedIndexOutput {
	return o
}

func (o AiIndexDeployedIndexOutput) ToAiIndexDeployedIndexOutputWithContext(ctx context.Context) AiIndexDeployedIndexOutput {
	return o
}

// (Output)
// The ID of the DeployedIndex in the above IndexEndpoint.
func (o AiIndexDeployedIndexOutput) DeployedIndexId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexDeployedIndex) *string { return v.DeployedIndexId }).(pulumi.StringPtrOutput)
}

// (Output)
// A resource name of the IndexEndpoint.
func (o AiIndexDeployedIndexOutput) IndexEndpoint() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexDeployedIndex) *string { return v.IndexEndpoint }).(pulumi.StringPtrOutput)
}

type AiIndexDeployedIndexArrayOutput struct{ *pulumi.OutputState }

func (AiIndexDeployedIndexArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiIndexDeployedIndex)(nil)).Elem()
}

func (o AiIndexDeployedIndexArrayOutput) ToAiIndexDeployedIndexArrayOutput() AiIndexDeployedIndexArrayOutput {
	return o
}

func (o AiIndexDeployedIndexArrayOutput) ToAiIndexDeployedIndexArrayOutputWithContext(ctx context.Context) AiIndexDeployedIndexArrayOutput {
	return o
}

func (o AiIndexDeployedIndexArrayOutput) Index(i pulumi.IntInput) AiIndexDeployedIndexOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiIndexDeployedIndex {
		return vs[0].([]AiIndexDeployedIndex)[vs[1].(int)]
	}).(AiIndexDeployedIndexOutput)
}

type AiIndexEndpointDeployedIndexAutomaticResources struct {
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If maxReplicaCount is not set, the default value is minReplicaCount. The max allowed replica count is 1000.
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
	MaxReplicaCount *int `pulumi:"maxReplicaCount"`
	// The minimum number of replicas this DeployedModel will be always deployed on. If minReplicaCount is not set, the default value is 2 (we don't provide SLA when minReplicaCount=1).
	// If traffic against it increases, it may dynamically be deployed onto more replicas up to [maxReplicaCount](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/AutomaticResources#FIELDS.max_replica_count), and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
	MinReplicaCount *int `pulumi:"minReplicaCount"`
}

// AiIndexEndpointDeployedIndexAutomaticResourcesInput is an input type that accepts AiIndexEndpointDeployedIndexAutomaticResourcesArgs and AiIndexEndpointDeployedIndexAutomaticResourcesOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexAutomaticResourcesInput` via:
//
//	AiIndexEndpointDeployedIndexAutomaticResourcesArgs{...}
type AiIndexEndpointDeployedIndexAutomaticResourcesInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexAutomaticResourcesOutput() AiIndexEndpointDeployedIndexAutomaticResourcesOutput
	ToAiIndexEndpointDeployedIndexAutomaticResourcesOutputWithContext(context.Context) AiIndexEndpointDeployedIndexAutomaticResourcesOutput
}

type AiIndexEndpointDeployedIndexAutomaticResourcesArgs struct {
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If maxReplicaCount is not set, the default value is minReplicaCount. The max allowed replica count is 1000.
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
	MaxReplicaCount pulumi.IntPtrInput `pulumi:"maxReplicaCount"`
	// The minimum number of replicas this DeployedModel will be always deployed on. If minReplicaCount is not set, the default value is 2 (we don't provide SLA when minReplicaCount=1).
	// If traffic against it increases, it may dynamically be deployed onto more replicas up to [maxReplicaCount](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/AutomaticResources#FIELDS.max_replica_count), and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
	MinReplicaCount pulumi.IntPtrInput `pulumi:"minReplicaCount"`
}

func (AiIndexEndpointDeployedIndexAutomaticResourcesArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexAutomaticResources)(nil)).Elem()
}

func (i AiIndexEndpointDeployedIndexAutomaticResourcesArgs) ToAiIndexEndpointDeployedIndexAutomaticResourcesOutput() AiIndexEndpointDeployedIndexAutomaticResourcesOutput {
	return i.ToAiIndexEndpointDeployedIndexAutomaticResourcesOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexAutomaticResourcesArgs) ToAiIndexEndpointDeployedIndexAutomaticResourcesOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexAutomaticResourcesOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexAutomaticResourcesOutput)
}

func (i AiIndexEndpointDeployedIndexAutomaticResourcesArgs) ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput() AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput {
	return i.ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexAutomaticResourcesArgs) ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexAutomaticResourcesOutput).ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutputWithContext(ctx)
}

// AiIndexEndpointDeployedIndexAutomaticResourcesPtrInput is an input type that accepts AiIndexEndpointDeployedIndexAutomaticResourcesArgs, AiIndexEndpointDeployedIndexAutomaticResourcesPtr and AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexAutomaticResourcesPtrInput` via:
//
//	        AiIndexEndpointDeployedIndexAutomaticResourcesArgs{...}
//
//	or:
//
//	        nil
type AiIndexEndpointDeployedIndexAutomaticResourcesPtrInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput() AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput
	ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutputWithContext(context.Context) AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput
}

type aiIndexEndpointDeployedIndexAutomaticResourcesPtrType AiIndexEndpointDeployedIndexAutomaticResourcesArgs

func AiIndexEndpointDeployedIndexAutomaticResourcesPtr(v *AiIndexEndpointDeployedIndexAutomaticResourcesArgs) AiIndexEndpointDeployedIndexAutomaticResourcesPtrInput {
	return (*aiIndexEndpointDeployedIndexAutomaticResourcesPtrType)(v)
}

func (*aiIndexEndpointDeployedIndexAutomaticResourcesPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexEndpointDeployedIndexAutomaticResources)(nil)).Elem()
}

func (i *aiIndexEndpointDeployedIndexAutomaticResourcesPtrType) ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput() AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput {
	return i.ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutputWithContext(context.Background())
}

func (i *aiIndexEndpointDeployedIndexAutomaticResourcesPtrType) ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput)
}

type AiIndexEndpointDeployedIndexAutomaticResourcesOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexAutomaticResourcesOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexAutomaticResources)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexAutomaticResourcesOutput) ToAiIndexEndpointDeployedIndexAutomaticResourcesOutput() AiIndexEndpointDeployedIndexAutomaticResourcesOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexAutomaticResourcesOutput) ToAiIndexEndpointDeployedIndexAutomaticResourcesOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexAutomaticResourcesOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexAutomaticResourcesOutput) ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput() AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput {
	return o.ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutputWithContext(context.Background())
}

func (o AiIndexEndpointDeployedIndexAutomaticResourcesOutput) ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexEndpointDeployedIndexAutomaticResources) *AiIndexEndpointDeployedIndexAutomaticResources {
		return &v
	}).(AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput)
}

// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If maxReplicaCount is not set, the default value is minReplicaCount. The max allowed replica count is 1000.
// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
func (o AiIndexEndpointDeployedIndexAutomaticResourcesOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexAutomaticResources) *int { return v.MaxReplicaCount }).(pulumi.IntPtrOutput)
}

// The minimum number of replicas this DeployedModel will be always deployed on. If minReplicaCount is not set, the default value is 2 (we don't provide SLA when minReplicaCount=1).
// If traffic against it increases, it may dynamically be deployed onto more replicas up to [maxReplicaCount](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/AutomaticResources#FIELDS.max_replica_count), and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
func (o AiIndexEndpointDeployedIndexAutomaticResourcesOutput) MinReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexAutomaticResources) *int { return v.MinReplicaCount }).(pulumi.IntPtrOutput)
}

type AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexEndpointDeployedIndexAutomaticResources)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput) ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput() AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput) ToAiIndexEndpointDeployedIndexAutomaticResourcesPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput) Elem() AiIndexEndpointDeployedIndexAutomaticResourcesOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexAutomaticResources) AiIndexEndpointDeployedIndexAutomaticResources {
		if v != nil {
			return *v
		}
		var ret AiIndexEndpointDeployedIndexAutomaticResources
		return ret
	}).(AiIndexEndpointDeployedIndexAutomaticResourcesOutput)
}

// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If maxReplicaCount is not set, the default value is minReplicaCount. The max allowed replica count is 1000.
// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
func (o AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexAutomaticResources) *int {
		if v == nil {
			return nil
		}
		return v.MaxReplicaCount
	}).(pulumi.IntPtrOutput)
}

// The minimum number of replicas this DeployedModel will be always deployed on. If minReplicaCount is not set, the default value is 2 (we don't provide SLA when minReplicaCount=1).
// If traffic against it increases, it may dynamically be deployed onto more replicas up to [maxReplicaCount](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/AutomaticResources#FIELDS.max_replica_count), and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
func (o AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput) MinReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexAutomaticResources) *int {
		if v == nil {
			return nil
		}
		return v.MinReplicaCount
	}).(pulumi.IntPtrOutput)
}

type AiIndexEndpointDeployedIndexDedicatedResources struct {
	// The minimum number of replicas this DeployedModel will be always deployed on.
	// Structure is documented below.
	MachineSpec AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec `pulumi:"machineSpec"`
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If maxReplicaCount is not set, the default value is minReplicaCount
	MaxReplicaCount *int `pulumi:"maxReplicaCount"`
	// The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1.
	MinReplicaCount int `pulumi:"minReplicaCount"`
}

// AiIndexEndpointDeployedIndexDedicatedResourcesInput is an input type that accepts AiIndexEndpointDeployedIndexDedicatedResourcesArgs and AiIndexEndpointDeployedIndexDedicatedResourcesOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexDedicatedResourcesInput` via:
//
//	AiIndexEndpointDeployedIndexDedicatedResourcesArgs{...}
type AiIndexEndpointDeployedIndexDedicatedResourcesInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexDedicatedResourcesOutput() AiIndexEndpointDeployedIndexDedicatedResourcesOutput
	ToAiIndexEndpointDeployedIndexDedicatedResourcesOutputWithContext(context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesOutput
}

type AiIndexEndpointDeployedIndexDedicatedResourcesArgs struct {
	// The minimum number of replicas this DeployedModel will be always deployed on.
	// Structure is documented below.
	MachineSpec AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecInput `pulumi:"machineSpec"`
	// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If maxReplicaCount is not set, the default value is minReplicaCount
	MaxReplicaCount pulumi.IntPtrInput `pulumi:"maxReplicaCount"`
	// The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1.
	MinReplicaCount pulumi.IntInput `pulumi:"minReplicaCount"`
}

func (AiIndexEndpointDeployedIndexDedicatedResourcesArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexDedicatedResources)(nil)).Elem()
}

func (i AiIndexEndpointDeployedIndexDedicatedResourcesArgs) ToAiIndexEndpointDeployedIndexDedicatedResourcesOutput() AiIndexEndpointDeployedIndexDedicatedResourcesOutput {
	return i.ToAiIndexEndpointDeployedIndexDedicatedResourcesOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexDedicatedResourcesArgs) ToAiIndexEndpointDeployedIndexDedicatedResourcesOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexDedicatedResourcesOutput)
}

func (i AiIndexEndpointDeployedIndexDedicatedResourcesArgs) ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput() AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput {
	return i.ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexDedicatedResourcesArgs) ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexDedicatedResourcesOutput).ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutputWithContext(ctx)
}

// AiIndexEndpointDeployedIndexDedicatedResourcesPtrInput is an input type that accepts AiIndexEndpointDeployedIndexDedicatedResourcesArgs, AiIndexEndpointDeployedIndexDedicatedResourcesPtr and AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexDedicatedResourcesPtrInput` via:
//
//	        AiIndexEndpointDeployedIndexDedicatedResourcesArgs{...}
//
//	or:
//
//	        nil
type AiIndexEndpointDeployedIndexDedicatedResourcesPtrInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput() AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput
	ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutputWithContext(context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput
}

type aiIndexEndpointDeployedIndexDedicatedResourcesPtrType AiIndexEndpointDeployedIndexDedicatedResourcesArgs

func AiIndexEndpointDeployedIndexDedicatedResourcesPtr(v *AiIndexEndpointDeployedIndexDedicatedResourcesArgs) AiIndexEndpointDeployedIndexDedicatedResourcesPtrInput {
	return (*aiIndexEndpointDeployedIndexDedicatedResourcesPtrType)(v)
}

func (*aiIndexEndpointDeployedIndexDedicatedResourcesPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexEndpointDeployedIndexDedicatedResources)(nil)).Elem()
}

func (i *aiIndexEndpointDeployedIndexDedicatedResourcesPtrType) ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput() AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput {
	return i.ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (i *aiIndexEndpointDeployedIndexDedicatedResourcesPtrType) ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput)
}

type AiIndexEndpointDeployedIndexDedicatedResourcesOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexDedicatedResourcesOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexDedicatedResources)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesOutput) ToAiIndexEndpointDeployedIndexDedicatedResourcesOutput() AiIndexEndpointDeployedIndexDedicatedResourcesOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesOutput) ToAiIndexEndpointDeployedIndexDedicatedResourcesOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesOutput) ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput() AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput {
	return o.ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutputWithContext(context.Background())
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesOutput) ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexEndpointDeployedIndexDedicatedResources) *AiIndexEndpointDeployedIndexDedicatedResources {
		return &v
	}).(AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput)
}

// The minimum number of replicas this DeployedModel will be always deployed on.
// Structure is documented below.
func (o AiIndexEndpointDeployedIndexDedicatedResourcesOutput) MachineSpec() AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexDedicatedResources) AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec {
		return v.MachineSpec
	}).(AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput)
}

// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If maxReplicaCount is not set, the default value is minReplicaCount
func (o AiIndexEndpointDeployedIndexDedicatedResourcesOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexDedicatedResources) *int { return v.MaxReplicaCount }).(pulumi.IntPtrOutput)
}

// The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1.
func (o AiIndexEndpointDeployedIndexDedicatedResourcesOutput) MinReplicaCount() pulumi.IntOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexDedicatedResources) int { return v.MinReplicaCount }).(pulumi.IntOutput)
}

type AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexEndpointDeployedIndexDedicatedResources)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput) ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput() AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput) ToAiIndexEndpointDeployedIndexDedicatedResourcesPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput) Elem() AiIndexEndpointDeployedIndexDedicatedResourcesOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexDedicatedResources) AiIndexEndpointDeployedIndexDedicatedResources {
		if v != nil {
			return *v
		}
		var ret AiIndexEndpointDeployedIndexDedicatedResources
		return ret
	}).(AiIndexEndpointDeployedIndexDedicatedResourcesOutput)
}

// The minimum number of replicas this DeployedModel will be always deployed on.
// Structure is documented below.
func (o AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput) MachineSpec() AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexDedicatedResources) *AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec {
		if v == nil {
			return nil
		}
		return &v.MachineSpec
	}).(AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput)
}

// The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If maxReplicaCount is not set, the default value is minReplicaCount
func (o AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput) MaxReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexDedicatedResources) *int {
		if v == nil {
			return nil
		}
		return v.MaxReplicaCount
	}).(pulumi.IntPtrOutput)
}

// The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1.
func (o AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput) MinReplicaCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexDedicatedResources) *int {
		if v == nil {
			return nil
		}
		return &v.MinReplicaCount
	}).(pulumi.IntPtrOutput)
}

type AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec struct {
	// The type of the machine.
	// See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)
	// See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
	// For [DeployedModel](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints#DeployedModel) this field is optional, and the default value is n1-standard-2. For [BatchPredictionJob](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#BatchPredictionJob) or as part of [WorkerPoolSpec](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/CustomJobSpec#WorkerPoolSpec) this field is required.
	MachineType *string `pulumi:"machineType"`
}

// AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecInput is an input type that accepts AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs and AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecInput` via:
//
//	AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs{...}
type AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput() AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput
	ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutputWithContext(context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput
}

type AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs struct {
	// The type of the machine.
	// See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)
	// See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
	// For [DeployedModel](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints#DeployedModel) this field is optional, and the default value is n1-standard-2. For [BatchPredictionJob](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#BatchPredictionJob) or as part of [WorkerPoolSpec](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/CustomJobSpec#WorkerPoolSpec) this field is required.
	MachineType pulumi.StringPtrInput `pulumi:"machineType"`
}

func (AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec)(nil)).Elem()
}

func (i AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs) ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput() AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput {
	return i.ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs) ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput)
}

func (i AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs) ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput() AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput {
	return i.ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs) ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput).ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutputWithContext(ctx)
}

// AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrInput is an input type that accepts AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs, AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtr and AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrInput` via:
//
//	        AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs{...}
//
//	or:
//
//	        nil
type AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput() AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput
	ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutputWithContext(context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput
}

type aiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrType AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs

func AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtr(v *AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs) AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrInput {
	return (*aiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrType)(v)
}

func (*aiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec)(nil)).Elem()
}

func (i *aiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrType) ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput() AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput {
	return i.ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutputWithContext(context.Background())
}

func (i *aiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrType) ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput)
}

type AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput) ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput() AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput) ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput) ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput() AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput {
	return o.ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutputWithContext(context.Background())
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput) ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec) *AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec {
		return &v
	}).(AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput)
}

// The type of the machine.
// See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)
// See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
// For [DeployedModel](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints#DeployedModel) this field is optional, and the default value is n1-standard-2. For [BatchPredictionJob](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#BatchPredictionJob) or as part of [WorkerPoolSpec](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/CustomJobSpec#WorkerPoolSpec) this field is required.
func (o AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec) *string { return v.MachineType }).(pulumi.StringPtrOutput)
}

type AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput) ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput() AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput) ToAiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput) Elem() AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec) AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec {
		if v != nil {
			return *v
		}
		var ret AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec
		return ret
	}).(AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput)
}

// The type of the machine.
// See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)
// See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
// For [DeployedModel](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints#DeployedModel) this field is optional, and the default value is n1-standard-2. For [BatchPredictionJob](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#BatchPredictionJob) or as part of [WorkerPoolSpec](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/CustomJobSpec#WorkerPoolSpec) this field is required.
func (o AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpec) *string {
		if v == nil {
			return nil
		}
		return v.MachineType
	}).(pulumi.StringPtrOutput)
}

type AiIndexEndpointDeployedIndexDeployedIndexAuthConfig struct {
	// Defines the authentication provider that the DeployedIndex uses.
	// Structure is documented below.
	AuthProvider *AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider `pulumi:"authProvider"`
}

// AiIndexEndpointDeployedIndexDeployedIndexAuthConfigInput is an input type that accepts AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs and AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexDeployedIndexAuthConfigInput` via:
//
//	AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs{...}
type AiIndexEndpointDeployedIndexDeployedIndexAuthConfigInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput
	ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutputWithContext(context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput
}

type AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs struct {
	// Defines the authentication provider that the DeployedIndex uses.
	// Structure is documented below.
	AuthProvider AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrInput `pulumi:"authProvider"`
}

func (AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexDeployedIndexAuthConfig)(nil)).Elem()
}

func (i AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput {
	return i.ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput)
}

func (i AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput {
	return i.ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput).ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutputWithContext(ctx)
}

// AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrInput is an input type that accepts AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs, AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtr and AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrInput` via:
//
//	        AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs{...}
//
//	or:
//
//	        nil
type AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput
	ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutputWithContext(context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput
}

type aiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrType AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs

func AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtr(v *AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrInput {
	return (*aiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrType)(v)
}

func (*aiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexEndpointDeployedIndexDeployedIndexAuthConfig)(nil)).Elem()
}

func (i *aiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrType) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput {
	return i.ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutputWithContext(context.Background())
}

func (i *aiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrType) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput)
}

type AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexDeployedIndexAuthConfig)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput {
	return o.ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutputWithContext(context.Background())
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexEndpointDeployedIndexDeployedIndexAuthConfig) *AiIndexEndpointDeployedIndexDeployedIndexAuthConfig {
		return &v
	}).(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput)
}

// Defines the authentication provider that the DeployedIndex uses.
// Structure is documented below.
func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput) AuthProvider() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexDeployedIndexAuthConfig) *AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider {
		return v.AuthProvider
	}).(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput)
}

type AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexEndpointDeployedIndexDeployedIndexAuthConfig)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput) Elem() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexDeployedIndexAuthConfig) AiIndexEndpointDeployedIndexDeployedIndexAuthConfig {
		if v != nil {
			return *v
		}
		var ret AiIndexEndpointDeployedIndexDeployedIndexAuthConfig
		return ret
	}).(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput)
}

// Defines the authentication provider that the DeployedIndex uses.
// Structure is documented below.
func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput) AuthProvider() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexDeployedIndexAuthConfig) *AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider {
		if v == nil {
			return nil
		}
		return v.AuthProvider
	}).(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput)
}

type AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider struct {
	// A list of allowed JWT issuers. Each entry must be a valid Google service account, in the following format: service-account-name@project-id.iam.gserviceaccount.com
	AllowedIssuers []string `pulumi:"allowedIssuers"`
	// The list of JWT audiences. that are allowed to access. A JWT containing any of these audiences will be accepted.
	Audiences []string `pulumi:"audiences"`
}

// AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderInput is an input type that accepts AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs and AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderInput` via:
//
//	AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs{...}
type AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput
	ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutputWithContext(context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput
}

type AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs struct {
	// A list of allowed JWT issuers. Each entry must be a valid Google service account, in the following format: service-account-name@project-id.iam.gserviceaccount.com
	AllowedIssuers pulumi.StringArrayInput `pulumi:"allowedIssuers"`
	// The list of JWT audiences. that are allowed to access. A JWT containing any of these audiences will be accepted.
	Audiences pulumi.StringArrayInput `pulumi:"audiences"`
}

func (AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider)(nil)).Elem()
}

func (i AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput {
	return i.ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput)
}

func (i AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput {
	return i.ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput).ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutputWithContext(ctx)
}

// AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrInput is an input type that accepts AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs, AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtr and AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrInput` via:
//
//	        AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs{...}
//
//	or:
//
//	        nil
type AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput
	ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutputWithContext(context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput
}

type aiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrType AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs

func AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtr(v *AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrInput {
	return (*aiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrType)(v)
}

func (*aiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider)(nil)).Elem()
}

func (i *aiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrType) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput {
	return i.ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutputWithContext(context.Background())
}

func (i *aiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrType) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput)
}

type AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput {
	return o.ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutputWithContext(context.Background())
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider) *AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider {
		return &v
	}).(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput)
}

// A list of allowed JWT issuers. Each entry must be a valid Google service account, in the following format: service-account-name@project-id.iam.gserviceaccount.com
func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput) AllowedIssuers() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider) []string {
		return v.AllowedIssuers
	}).(pulumi.StringArrayOutput)
}

// The list of JWT audiences. that are allowed to access. A JWT containing any of these audiences will be accepted.
func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput) Audiences() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider) []string { return v.Audiences }).(pulumi.StringArrayOutput)
}

type AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput) ToAiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput) Elem() AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider) AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider {
		if v != nil {
			return *v
		}
		var ret AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider
		return ret
	}).(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput)
}

// A list of allowed JWT issuers. Each entry must be a valid Google service account, in the following format: service-account-name@project-id.iam.gserviceaccount.com
func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput) AllowedIssuers() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider) []string {
		if v == nil {
			return nil
		}
		return v.AllowedIssuers
	}).(pulumi.StringArrayOutput)
}

// The list of JWT audiences. that are allowed to access. A JWT containing any of these audiences will be accepted.
func (o AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput) Audiences() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProvider) []string {
		if v == nil {
			return nil
		}
		return v.Audiences
	}).(pulumi.StringArrayOutput)
}

type AiIndexEndpointDeployedIndexPrivateEndpoint struct {
	// (Output)
	// The ip address used to send match gRPC requests.
	MatchGrpcAddress *string `pulumi:"matchGrpcAddress"`
	// (Output)
	// PscAutomatedEndpoints is populated if private service connect is enabled if PscAutomatedConfig is set.
	// Structure is documented below.
	PscAutomatedEndpoints []AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpoint `pulumi:"pscAutomatedEndpoints"`
	// (Output)
	// The name of the service attachment resource. Populated if private service connect is enabled.
	ServiceAttachment *string `pulumi:"serviceAttachment"`
}

// AiIndexEndpointDeployedIndexPrivateEndpointInput is an input type that accepts AiIndexEndpointDeployedIndexPrivateEndpointArgs and AiIndexEndpointDeployedIndexPrivateEndpointOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexPrivateEndpointInput` via:
//
//	AiIndexEndpointDeployedIndexPrivateEndpointArgs{...}
type AiIndexEndpointDeployedIndexPrivateEndpointInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexPrivateEndpointOutput() AiIndexEndpointDeployedIndexPrivateEndpointOutput
	ToAiIndexEndpointDeployedIndexPrivateEndpointOutputWithContext(context.Context) AiIndexEndpointDeployedIndexPrivateEndpointOutput
}

type AiIndexEndpointDeployedIndexPrivateEndpointArgs struct {
	// (Output)
	// The ip address used to send match gRPC requests.
	MatchGrpcAddress pulumi.StringPtrInput `pulumi:"matchGrpcAddress"`
	// (Output)
	// PscAutomatedEndpoints is populated if private service connect is enabled if PscAutomatedConfig is set.
	// Structure is documented below.
	PscAutomatedEndpoints AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayInput `pulumi:"pscAutomatedEndpoints"`
	// (Output)
	// The name of the service attachment resource. Populated if private service connect is enabled.
	ServiceAttachment pulumi.StringPtrInput `pulumi:"serviceAttachment"`
}

func (AiIndexEndpointDeployedIndexPrivateEndpointArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexPrivateEndpoint)(nil)).Elem()
}

func (i AiIndexEndpointDeployedIndexPrivateEndpointArgs) ToAiIndexEndpointDeployedIndexPrivateEndpointOutput() AiIndexEndpointDeployedIndexPrivateEndpointOutput {
	return i.ToAiIndexEndpointDeployedIndexPrivateEndpointOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexPrivateEndpointArgs) ToAiIndexEndpointDeployedIndexPrivateEndpointOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexPrivateEndpointOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexPrivateEndpointOutput)
}

// AiIndexEndpointDeployedIndexPrivateEndpointArrayInput is an input type that accepts AiIndexEndpointDeployedIndexPrivateEndpointArray and AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexPrivateEndpointArrayInput` via:
//
//	AiIndexEndpointDeployedIndexPrivateEndpointArray{ AiIndexEndpointDeployedIndexPrivateEndpointArgs{...} }
type AiIndexEndpointDeployedIndexPrivateEndpointArrayInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexPrivateEndpointArrayOutput() AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput
	ToAiIndexEndpointDeployedIndexPrivateEndpointArrayOutputWithContext(context.Context) AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput
}

type AiIndexEndpointDeployedIndexPrivateEndpointArray []AiIndexEndpointDeployedIndexPrivateEndpointInput

func (AiIndexEndpointDeployedIndexPrivateEndpointArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiIndexEndpointDeployedIndexPrivateEndpoint)(nil)).Elem()
}

func (i AiIndexEndpointDeployedIndexPrivateEndpointArray) ToAiIndexEndpointDeployedIndexPrivateEndpointArrayOutput() AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput {
	return i.ToAiIndexEndpointDeployedIndexPrivateEndpointArrayOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexPrivateEndpointArray) ToAiIndexEndpointDeployedIndexPrivateEndpointArrayOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput)
}

type AiIndexEndpointDeployedIndexPrivateEndpointOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexPrivateEndpointOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexPrivateEndpoint)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexPrivateEndpointOutput) ToAiIndexEndpointDeployedIndexPrivateEndpointOutput() AiIndexEndpointDeployedIndexPrivateEndpointOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexPrivateEndpointOutput) ToAiIndexEndpointDeployedIndexPrivateEndpointOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexPrivateEndpointOutput {
	return o
}

// (Output)
// The ip address used to send match gRPC requests.
func (o AiIndexEndpointDeployedIndexPrivateEndpointOutput) MatchGrpcAddress() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexPrivateEndpoint) *string { return v.MatchGrpcAddress }).(pulumi.StringPtrOutput)
}

// (Output)
// PscAutomatedEndpoints is populated if private service connect is enabled if PscAutomatedConfig is set.
// Structure is documented below.
func (o AiIndexEndpointDeployedIndexPrivateEndpointOutput) PscAutomatedEndpoints() AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexPrivateEndpoint) []AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpoint {
		return v.PscAutomatedEndpoints
	}).(AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput)
}

// (Output)
// The name of the service attachment resource. Populated if private service connect is enabled.
func (o AiIndexEndpointDeployedIndexPrivateEndpointOutput) ServiceAttachment() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexPrivateEndpoint) *string { return v.ServiceAttachment }).(pulumi.StringPtrOutput)
}

type AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiIndexEndpointDeployedIndexPrivateEndpoint)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput) ToAiIndexEndpointDeployedIndexPrivateEndpointArrayOutput() AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput) ToAiIndexEndpointDeployedIndexPrivateEndpointArrayOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput) Index(i pulumi.IntInput) AiIndexEndpointDeployedIndexPrivateEndpointOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiIndexEndpointDeployedIndexPrivateEndpoint {
		return vs[0].([]AiIndexEndpointDeployedIndexPrivateEndpoint)[vs[1].(int)]
	}).(AiIndexEndpointDeployedIndexPrivateEndpointOutput)
}

type AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpoint struct {
	// (Output)
	// ip Address created by the automated forwarding rule.
	MatchAddress *string `pulumi:"matchAddress"`
	// (Output)
	// Corresponding network in pscAutomationConfigs.
	Network *string `pulumi:"network"`
	// (Output)
	// Corresponding projectId in pscAutomationConfigs
	ProjectId *string `pulumi:"projectId"`
}

// AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointInput is an input type that accepts AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArgs and AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointInput` via:
//
//	AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArgs{...}
type AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput() AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput
	ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutputWithContext(context.Context) AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput
}

type AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArgs struct {
	// (Output)
	// ip Address created by the automated forwarding rule.
	MatchAddress pulumi.StringPtrInput `pulumi:"matchAddress"`
	// (Output)
	// Corresponding network in pscAutomationConfigs.
	Network pulumi.StringPtrInput `pulumi:"network"`
	// (Output)
	// Corresponding projectId in pscAutomationConfigs
	ProjectId pulumi.StringPtrInput `pulumi:"projectId"`
}

func (AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpoint)(nil)).Elem()
}

func (i AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArgs) ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput() AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput {
	return i.ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArgs) ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput)
}

// AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayInput is an input type that accepts AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArray and AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput values.
// You can construct a concrete instance of `AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayInput` via:
//
//	AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArray{ AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArgs{...} }
type AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayInput interface {
	pulumi.Input

	ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput() AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput
	ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutputWithContext(context.Context) AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput
}

type AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArray []AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointInput

func (AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpoint)(nil)).Elem()
}

func (i AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArray) ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput() AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput {
	return i.ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutputWithContext(context.Background())
}

func (i AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArray) ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput)
}

type AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpoint)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput) ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput() AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput) ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput {
	return o
}

// (Output)
// ip Address created by the automated forwarding rule.
func (o AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput) MatchAddress() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpoint) *string { return v.MatchAddress }).(pulumi.StringPtrOutput)
}

// (Output)
// Corresponding network in pscAutomationConfigs.
func (o AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpoint) *string { return v.Network }).(pulumi.StringPtrOutput)
}

// (Output)
// Corresponding projectId in pscAutomationConfigs
func (o AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput) ProjectId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpoint) *string { return v.ProjectId }).(pulumi.StringPtrOutput)
}

type AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpoint)(nil)).Elem()
}

func (o AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput) ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput() AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput) ToAiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutputWithContext(ctx context.Context) AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput {
	return o
}

func (o AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput) Index(i pulumi.IntInput) AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpoint {
		return vs[0].([]AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpoint)[vs[1].(int)]
	}).(AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput)
}

type AiIndexEndpointPrivateServiceConnectConfig struct {
	// If set to true, the IndexEndpoint is created without private service access.
	EnablePrivateServiceConnect bool `pulumi:"enablePrivateServiceConnect"`
	// A list of Projects from which the forwarding rule will target the service attachment.
	ProjectAllowlists []string `pulumi:"projectAllowlists"`
}

// AiIndexEndpointPrivateServiceConnectConfigInput is an input type that accepts AiIndexEndpointPrivateServiceConnectConfigArgs and AiIndexEndpointPrivateServiceConnectConfigOutput values.
// You can construct a concrete instance of `AiIndexEndpointPrivateServiceConnectConfigInput` via:
//
//	AiIndexEndpointPrivateServiceConnectConfigArgs{...}
type AiIndexEndpointPrivateServiceConnectConfigInput interface {
	pulumi.Input

	ToAiIndexEndpointPrivateServiceConnectConfigOutput() AiIndexEndpointPrivateServiceConnectConfigOutput
	ToAiIndexEndpointPrivateServiceConnectConfigOutputWithContext(context.Context) AiIndexEndpointPrivateServiceConnectConfigOutput
}

type AiIndexEndpointPrivateServiceConnectConfigArgs struct {
	// If set to true, the IndexEndpoint is created without private service access.
	EnablePrivateServiceConnect pulumi.BoolInput `pulumi:"enablePrivateServiceConnect"`
	// A list of Projects from which the forwarding rule will target the service attachment.
	ProjectAllowlists pulumi.StringArrayInput `pulumi:"projectAllowlists"`
}

func (AiIndexEndpointPrivateServiceConnectConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointPrivateServiceConnectConfig)(nil)).Elem()
}

func (i AiIndexEndpointPrivateServiceConnectConfigArgs) ToAiIndexEndpointPrivateServiceConnectConfigOutput() AiIndexEndpointPrivateServiceConnectConfigOutput {
	return i.ToAiIndexEndpointPrivateServiceConnectConfigOutputWithContext(context.Background())
}

func (i AiIndexEndpointPrivateServiceConnectConfigArgs) ToAiIndexEndpointPrivateServiceConnectConfigOutputWithContext(ctx context.Context) AiIndexEndpointPrivateServiceConnectConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointPrivateServiceConnectConfigOutput)
}

func (i AiIndexEndpointPrivateServiceConnectConfigArgs) ToAiIndexEndpointPrivateServiceConnectConfigPtrOutput() AiIndexEndpointPrivateServiceConnectConfigPtrOutput {
	return i.ToAiIndexEndpointPrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (i AiIndexEndpointPrivateServiceConnectConfigArgs) ToAiIndexEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) AiIndexEndpointPrivateServiceConnectConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointPrivateServiceConnectConfigOutput).ToAiIndexEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx)
}

// AiIndexEndpointPrivateServiceConnectConfigPtrInput is an input type that accepts AiIndexEndpointPrivateServiceConnectConfigArgs, AiIndexEndpointPrivateServiceConnectConfigPtr and AiIndexEndpointPrivateServiceConnectConfigPtrOutput values.
// You can construct a concrete instance of `AiIndexEndpointPrivateServiceConnectConfigPtrInput` via:
//
//	        AiIndexEndpointPrivateServiceConnectConfigArgs{...}
//
//	or:
//
//	        nil
type AiIndexEndpointPrivateServiceConnectConfigPtrInput interface {
	pulumi.Input

	ToAiIndexEndpointPrivateServiceConnectConfigPtrOutput() AiIndexEndpointPrivateServiceConnectConfigPtrOutput
	ToAiIndexEndpointPrivateServiceConnectConfigPtrOutputWithContext(context.Context) AiIndexEndpointPrivateServiceConnectConfigPtrOutput
}

type aiIndexEndpointPrivateServiceConnectConfigPtrType AiIndexEndpointPrivateServiceConnectConfigArgs

func AiIndexEndpointPrivateServiceConnectConfigPtr(v *AiIndexEndpointPrivateServiceConnectConfigArgs) AiIndexEndpointPrivateServiceConnectConfigPtrInput {
	return (*aiIndexEndpointPrivateServiceConnectConfigPtrType)(v)
}

func (*aiIndexEndpointPrivateServiceConnectConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexEndpointPrivateServiceConnectConfig)(nil)).Elem()
}

func (i *aiIndexEndpointPrivateServiceConnectConfigPtrType) ToAiIndexEndpointPrivateServiceConnectConfigPtrOutput() AiIndexEndpointPrivateServiceConnectConfigPtrOutput {
	return i.ToAiIndexEndpointPrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (i *aiIndexEndpointPrivateServiceConnectConfigPtrType) ToAiIndexEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) AiIndexEndpointPrivateServiceConnectConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexEndpointPrivateServiceConnectConfigPtrOutput)
}

type AiIndexEndpointPrivateServiceConnectConfigOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointPrivateServiceConnectConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexEndpointPrivateServiceConnectConfig)(nil)).Elem()
}

func (o AiIndexEndpointPrivateServiceConnectConfigOutput) ToAiIndexEndpointPrivateServiceConnectConfigOutput() AiIndexEndpointPrivateServiceConnectConfigOutput {
	return o
}

func (o AiIndexEndpointPrivateServiceConnectConfigOutput) ToAiIndexEndpointPrivateServiceConnectConfigOutputWithContext(ctx context.Context) AiIndexEndpointPrivateServiceConnectConfigOutput {
	return o
}

func (o AiIndexEndpointPrivateServiceConnectConfigOutput) ToAiIndexEndpointPrivateServiceConnectConfigPtrOutput() AiIndexEndpointPrivateServiceConnectConfigPtrOutput {
	return o.ToAiIndexEndpointPrivateServiceConnectConfigPtrOutputWithContext(context.Background())
}

func (o AiIndexEndpointPrivateServiceConnectConfigOutput) ToAiIndexEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) AiIndexEndpointPrivateServiceConnectConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexEndpointPrivateServiceConnectConfig) *AiIndexEndpointPrivateServiceConnectConfig {
		return &v
	}).(AiIndexEndpointPrivateServiceConnectConfigPtrOutput)
}

// If set to true, the IndexEndpoint is created without private service access.
func (o AiIndexEndpointPrivateServiceConnectConfigOutput) EnablePrivateServiceConnect() pulumi.BoolOutput {
	return o.ApplyT(func(v AiIndexEndpointPrivateServiceConnectConfig) bool { return v.EnablePrivateServiceConnect }).(pulumi.BoolOutput)
}

// A list of Projects from which the forwarding rule will target the service attachment.
func (o AiIndexEndpointPrivateServiceConnectConfigOutput) ProjectAllowlists() pulumi.StringArrayOutput {
	return o.ApplyT(func(v AiIndexEndpointPrivateServiceConnectConfig) []string { return v.ProjectAllowlists }).(pulumi.StringArrayOutput)
}

type AiIndexEndpointPrivateServiceConnectConfigPtrOutput struct{ *pulumi.OutputState }

func (AiIndexEndpointPrivateServiceConnectConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexEndpointPrivateServiceConnectConfig)(nil)).Elem()
}

func (o AiIndexEndpointPrivateServiceConnectConfigPtrOutput) ToAiIndexEndpointPrivateServiceConnectConfigPtrOutput() AiIndexEndpointPrivateServiceConnectConfigPtrOutput {
	return o
}

func (o AiIndexEndpointPrivateServiceConnectConfigPtrOutput) ToAiIndexEndpointPrivateServiceConnectConfigPtrOutputWithContext(ctx context.Context) AiIndexEndpointPrivateServiceConnectConfigPtrOutput {
	return o
}

func (o AiIndexEndpointPrivateServiceConnectConfigPtrOutput) Elem() AiIndexEndpointPrivateServiceConnectConfigOutput {
	return o.ApplyT(func(v *AiIndexEndpointPrivateServiceConnectConfig) AiIndexEndpointPrivateServiceConnectConfig {
		if v != nil {
			return *v
		}
		var ret AiIndexEndpointPrivateServiceConnectConfig
		return ret
	}).(AiIndexEndpointPrivateServiceConnectConfigOutput)
}

// If set to true, the IndexEndpoint is created without private service access.
func (o AiIndexEndpointPrivateServiceConnectConfigPtrOutput) EnablePrivateServiceConnect() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiIndexEndpointPrivateServiceConnectConfig) *bool {
		if v == nil {
			return nil
		}
		return &v.EnablePrivateServiceConnect
	}).(pulumi.BoolPtrOutput)
}

// A list of Projects from which the forwarding rule will target the service attachment.
func (o AiIndexEndpointPrivateServiceConnectConfigPtrOutput) ProjectAllowlists() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *AiIndexEndpointPrivateServiceConnectConfig) []string {
		if v == nil {
			return nil
		}
		return v.ProjectAllowlists
	}).(pulumi.StringArrayOutput)
}

type AiIndexIndexStat struct {
	// (Output)
	// The number of shards in the Index.
	ShardsCount *int `pulumi:"shardsCount"`
	// (Output)
	// The number of vectors in the Index.
	VectorsCount *string `pulumi:"vectorsCount"`
}

// AiIndexIndexStatInput is an input type that accepts AiIndexIndexStatArgs and AiIndexIndexStatOutput values.
// You can construct a concrete instance of `AiIndexIndexStatInput` via:
//
//	AiIndexIndexStatArgs{...}
type AiIndexIndexStatInput interface {
	pulumi.Input

	ToAiIndexIndexStatOutput() AiIndexIndexStatOutput
	ToAiIndexIndexStatOutputWithContext(context.Context) AiIndexIndexStatOutput
}

type AiIndexIndexStatArgs struct {
	// (Output)
	// The number of shards in the Index.
	ShardsCount pulumi.IntPtrInput `pulumi:"shardsCount"`
	// (Output)
	// The number of vectors in the Index.
	VectorsCount pulumi.StringPtrInput `pulumi:"vectorsCount"`
}

func (AiIndexIndexStatArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexIndexStat)(nil)).Elem()
}

func (i AiIndexIndexStatArgs) ToAiIndexIndexStatOutput() AiIndexIndexStatOutput {
	return i.ToAiIndexIndexStatOutputWithContext(context.Background())
}

func (i AiIndexIndexStatArgs) ToAiIndexIndexStatOutputWithContext(ctx context.Context) AiIndexIndexStatOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexIndexStatOutput)
}

// AiIndexIndexStatArrayInput is an input type that accepts AiIndexIndexStatArray and AiIndexIndexStatArrayOutput values.
// You can construct a concrete instance of `AiIndexIndexStatArrayInput` via:
//
//	AiIndexIndexStatArray{ AiIndexIndexStatArgs{...} }
type AiIndexIndexStatArrayInput interface {
	pulumi.Input

	ToAiIndexIndexStatArrayOutput() AiIndexIndexStatArrayOutput
	ToAiIndexIndexStatArrayOutputWithContext(context.Context) AiIndexIndexStatArrayOutput
}

type AiIndexIndexStatArray []AiIndexIndexStatInput

func (AiIndexIndexStatArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiIndexIndexStat)(nil)).Elem()
}

func (i AiIndexIndexStatArray) ToAiIndexIndexStatArrayOutput() AiIndexIndexStatArrayOutput {
	return i.ToAiIndexIndexStatArrayOutputWithContext(context.Background())
}

func (i AiIndexIndexStatArray) ToAiIndexIndexStatArrayOutputWithContext(ctx context.Context) AiIndexIndexStatArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexIndexStatArrayOutput)
}

type AiIndexIndexStatOutput struct{ *pulumi.OutputState }

func (AiIndexIndexStatOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexIndexStat)(nil)).Elem()
}

func (o AiIndexIndexStatOutput) ToAiIndexIndexStatOutput() AiIndexIndexStatOutput {
	return o
}

func (o AiIndexIndexStatOutput) ToAiIndexIndexStatOutputWithContext(ctx context.Context) AiIndexIndexStatOutput {
	return o
}

// (Output)
// The number of shards in the Index.
func (o AiIndexIndexStatOutput) ShardsCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiIndexIndexStat) *int { return v.ShardsCount }).(pulumi.IntPtrOutput)
}

// (Output)
// The number of vectors in the Index.
func (o AiIndexIndexStatOutput) VectorsCount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexIndexStat) *string { return v.VectorsCount }).(pulumi.StringPtrOutput)
}

type AiIndexIndexStatArrayOutput struct{ *pulumi.OutputState }

func (AiIndexIndexStatArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiIndexIndexStat)(nil)).Elem()
}

func (o AiIndexIndexStatArrayOutput) ToAiIndexIndexStatArrayOutput() AiIndexIndexStatArrayOutput {
	return o
}

func (o AiIndexIndexStatArrayOutput) ToAiIndexIndexStatArrayOutputWithContext(ctx context.Context) AiIndexIndexStatArrayOutput {
	return o
}

func (o AiIndexIndexStatArrayOutput) Index(i pulumi.IntInput) AiIndexIndexStatOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiIndexIndexStat {
		return vs[0].([]AiIndexIndexStat)[vs[1].(int)]
	}).(AiIndexIndexStatOutput)
}

type AiIndexMetadata struct {
	// The configuration of the Matching Engine Index.
	// Structure is documented below.
	Config AiIndexMetadataConfig `pulumi:"config"`
	// Allows inserting, updating  or deleting the contents of the Matching Engine Index.
	// The string must be a valid Cloud Storage directory path. If this
	// field is set when calling IndexService.UpdateIndex, then no other
	// Index field can be also updated as part of the same call.
	// The expected structure and format of the files this URI points to is
	// described at https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#input-data-format
	ContentsDeltaUri *string `pulumi:"contentsDeltaUri"`
	// If this field is set together with contentsDeltaUri when calling IndexService.UpdateIndex,
	// then existing content of the Index will be replaced by the data from the contentsDeltaUri.
	IsCompleteOverwrite *bool `pulumi:"isCompleteOverwrite"`
}

// AiIndexMetadataInput is an input type that accepts AiIndexMetadataArgs and AiIndexMetadataOutput values.
// You can construct a concrete instance of `AiIndexMetadataInput` via:
//
//	AiIndexMetadataArgs{...}
type AiIndexMetadataInput interface {
	pulumi.Input

	ToAiIndexMetadataOutput() AiIndexMetadataOutput
	ToAiIndexMetadataOutputWithContext(context.Context) AiIndexMetadataOutput
}

type AiIndexMetadataArgs struct {
	// The configuration of the Matching Engine Index.
	// Structure is documented below.
	Config AiIndexMetadataConfigInput `pulumi:"config"`
	// Allows inserting, updating  or deleting the contents of the Matching Engine Index.
	// The string must be a valid Cloud Storage directory path. If this
	// field is set when calling IndexService.UpdateIndex, then no other
	// Index field can be also updated as part of the same call.
	// The expected structure and format of the files this URI points to is
	// described at https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#input-data-format
	ContentsDeltaUri pulumi.StringPtrInput `pulumi:"contentsDeltaUri"`
	// If this field is set together with contentsDeltaUri when calling IndexService.UpdateIndex,
	// then existing content of the Index will be replaced by the data from the contentsDeltaUri.
	IsCompleteOverwrite pulumi.BoolPtrInput `pulumi:"isCompleteOverwrite"`
}

func (AiIndexMetadataArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadata)(nil)).Elem()
}

func (i AiIndexMetadataArgs) ToAiIndexMetadataOutput() AiIndexMetadataOutput {
	return i.ToAiIndexMetadataOutputWithContext(context.Background())
}

func (i AiIndexMetadataArgs) ToAiIndexMetadataOutputWithContext(ctx context.Context) AiIndexMetadataOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataOutput)
}

func (i AiIndexMetadataArgs) ToAiIndexMetadataPtrOutput() AiIndexMetadataPtrOutput {
	return i.ToAiIndexMetadataPtrOutputWithContext(context.Background())
}

func (i AiIndexMetadataArgs) ToAiIndexMetadataPtrOutputWithContext(ctx context.Context) AiIndexMetadataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataOutput).ToAiIndexMetadataPtrOutputWithContext(ctx)
}

// AiIndexMetadataPtrInput is an input type that accepts AiIndexMetadataArgs, AiIndexMetadataPtr and AiIndexMetadataPtrOutput values.
// You can construct a concrete instance of `AiIndexMetadataPtrInput` via:
//
//	        AiIndexMetadataArgs{...}
//
//	or:
//
//	        nil
type AiIndexMetadataPtrInput interface {
	pulumi.Input

	ToAiIndexMetadataPtrOutput() AiIndexMetadataPtrOutput
	ToAiIndexMetadataPtrOutputWithContext(context.Context) AiIndexMetadataPtrOutput
}

type aiIndexMetadataPtrType AiIndexMetadataArgs

func AiIndexMetadataPtr(v *AiIndexMetadataArgs) AiIndexMetadataPtrInput {
	return (*aiIndexMetadataPtrType)(v)
}

func (*aiIndexMetadataPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadata)(nil)).Elem()
}

func (i *aiIndexMetadataPtrType) ToAiIndexMetadataPtrOutput() AiIndexMetadataPtrOutput {
	return i.ToAiIndexMetadataPtrOutputWithContext(context.Background())
}

func (i *aiIndexMetadataPtrType) ToAiIndexMetadataPtrOutputWithContext(ctx context.Context) AiIndexMetadataPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataPtrOutput)
}

type AiIndexMetadataOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadata)(nil)).Elem()
}

func (o AiIndexMetadataOutput) ToAiIndexMetadataOutput() AiIndexMetadataOutput {
	return o
}

func (o AiIndexMetadataOutput) ToAiIndexMetadataOutputWithContext(ctx context.Context) AiIndexMetadataOutput {
	return o
}

func (o AiIndexMetadataOutput) ToAiIndexMetadataPtrOutput() AiIndexMetadataPtrOutput {
	return o.ToAiIndexMetadataPtrOutputWithContext(context.Background())
}

func (o AiIndexMetadataOutput) ToAiIndexMetadataPtrOutputWithContext(ctx context.Context) AiIndexMetadataPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexMetadata) *AiIndexMetadata {
		return &v
	}).(AiIndexMetadataPtrOutput)
}

// The configuration of the Matching Engine Index.
// Structure is documented below.
func (o AiIndexMetadataOutput) Config() AiIndexMetadataConfigOutput {
	return o.ApplyT(func(v AiIndexMetadata) AiIndexMetadataConfig { return v.Config }).(AiIndexMetadataConfigOutput)
}

// Allows inserting, updating  or deleting the contents of the Matching Engine Index.
// The string must be a valid Cloud Storage directory path. If this
// field is set when calling IndexService.UpdateIndex, then no other
// Index field can be also updated as part of the same call.
// The expected structure and format of the files this URI points to is
// described at https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#input-data-format
func (o AiIndexMetadataOutput) ContentsDeltaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexMetadata) *string { return v.ContentsDeltaUri }).(pulumi.StringPtrOutput)
}

// If this field is set together with contentsDeltaUri when calling IndexService.UpdateIndex,
// then existing content of the Index will be replaced by the data from the contentsDeltaUri.
func (o AiIndexMetadataOutput) IsCompleteOverwrite() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v AiIndexMetadata) *bool { return v.IsCompleteOverwrite }).(pulumi.BoolPtrOutput)
}

type AiIndexMetadataPtrOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadata)(nil)).Elem()
}

func (o AiIndexMetadataPtrOutput) ToAiIndexMetadataPtrOutput() AiIndexMetadataPtrOutput {
	return o
}

func (o AiIndexMetadataPtrOutput) ToAiIndexMetadataPtrOutputWithContext(ctx context.Context) AiIndexMetadataPtrOutput {
	return o
}

func (o AiIndexMetadataPtrOutput) Elem() AiIndexMetadataOutput {
	return o.ApplyT(func(v *AiIndexMetadata) AiIndexMetadata {
		if v != nil {
			return *v
		}
		var ret AiIndexMetadata
		return ret
	}).(AiIndexMetadataOutput)
}

// The configuration of the Matching Engine Index.
// Structure is documented below.
func (o AiIndexMetadataPtrOutput) Config() AiIndexMetadataConfigPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadata) *AiIndexMetadataConfig {
		if v == nil {
			return nil
		}
		return &v.Config
	}).(AiIndexMetadataConfigPtrOutput)
}

// Allows inserting, updating  or deleting the contents of the Matching Engine Index.
// The string must be a valid Cloud Storage directory path. If this
// field is set when calling IndexService.UpdateIndex, then no other
// Index field can be also updated as part of the same call.
// The expected structure and format of the files this URI points to is
// described at https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#input-data-format
func (o AiIndexMetadataPtrOutput) ContentsDeltaUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadata) *string {
		if v == nil {
			return nil
		}
		return v.ContentsDeltaUri
	}).(pulumi.StringPtrOutput)
}

// If this field is set together with contentsDeltaUri when calling IndexService.UpdateIndex,
// then existing content of the Index will be replaced by the data from the contentsDeltaUri.
func (o AiIndexMetadataPtrOutput) IsCompleteOverwrite() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadata) *bool {
		if v == nil {
			return nil
		}
		return v.IsCompleteOverwrite
	}).(pulumi.BoolPtrOutput)
}

type AiIndexMetadataConfig struct {
	// The configuration with regard to the algorithms used for efficient search. This field may be required based on your configuration.
	// Structure is documented below.
	AlgorithmConfig *AiIndexMetadataConfigAlgorithmConfig `pulumi:"algorithmConfig"`
	// The default number of neighbors to find via approximate search before exact reordering is
	// performed. Exact reordering is a procedure where results returned by an
	// approximate search algorithm are reordered via a more expensive distance computation.
	// Required if tree-AH algorithm is used.
	ApproximateNeighborsCount *int `pulumi:"approximateNeighborsCount"`
	// The number of dimensions of the input vectors.
	Dimensions int `pulumi:"dimensions"`
	// The distance measure used in nearest neighbor search. The value must be one of the followings:
	// * SQUARED_L2_DISTANCE: Euclidean (L_2) Distance
	// * L1_DISTANCE: Manhattan (L_1) Distance
	// * COSINE_DISTANCE: Cosine Distance. Defined as 1 - cosine similarity.
	// * DOT_PRODUCT_DISTANCE: Dot Product Distance. Defined as a negative of the dot product
	DistanceMeasureType *string `pulumi:"distanceMeasureType"`
	// Type of normalization to be carried out on each vector. The value must be one of the followings:
	// * UNIT_L2_NORM: Unit L2 normalization type
	// * NONE: No normalization type is specified.
	FeatureNormType *string `pulumi:"featureNormType"`
	// Index data is split into equal parts to be processed. These are called "shards".
	// The shard size must be specified when creating an index. The value must be one of the followings:
	// * SHARD_SIZE_SMALL: Small (2GB)
	// * SHARD_SIZE_MEDIUM: Medium (20GB)
	// * SHARD_SIZE_LARGE: Large (50GB)
	ShardSize *string `pulumi:"shardSize"`
}

// AiIndexMetadataConfigInput is an input type that accepts AiIndexMetadataConfigArgs and AiIndexMetadataConfigOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigInput` via:
//
//	AiIndexMetadataConfigArgs{...}
type AiIndexMetadataConfigInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigOutput() AiIndexMetadataConfigOutput
	ToAiIndexMetadataConfigOutputWithContext(context.Context) AiIndexMetadataConfigOutput
}

type AiIndexMetadataConfigArgs struct {
	// The configuration with regard to the algorithms used for efficient search. This field may be required based on your configuration.
	// Structure is documented below.
	AlgorithmConfig AiIndexMetadataConfigAlgorithmConfigPtrInput `pulumi:"algorithmConfig"`
	// The default number of neighbors to find via approximate search before exact reordering is
	// performed. Exact reordering is a procedure where results returned by an
	// approximate search algorithm are reordered via a more expensive distance computation.
	// Required if tree-AH algorithm is used.
	ApproximateNeighborsCount pulumi.IntPtrInput `pulumi:"approximateNeighborsCount"`
	// The number of dimensions of the input vectors.
	Dimensions pulumi.IntInput `pulumi:"dimensions"`
	// The distance measure used in nearest neighbor search. The value must be one of the followings:
	// * SQUARED_L2_DISTANCE: Euclidean (L_2) Distance
	// * L1_DISTANCE: Manhattan (L_1) Distance
	// * COSINE_DISTANCE: Cosine Distance. Defined as 1 - cosine similarity.
	// * DOT_PRODUCT_DISTANCE: Dot Product Distance. Defined as a negative of the dot product
	DistanceMeasureType pulumi.StringPtrInput `pulumi:"distanceMeasureType"`
	// Type of normalization to be carried out on each vector. The value must be one of the followings:
	// * UNIT_L2_NORM: Unit L2 normalization type
	// * NONE: No normalization type is specified.
	FeatureNormType pulumi.StringPtrInput `pulumi:"featureNormType"`
	// Index data is split into equal parts to be processed. These are called "shards".
	// The shard size must be specified when creating an index. The value must be one of the followings:
	// * SHARD_SIZE_SMALL: Small (2GB)
	// * SHARD_SIZE_MEDIUM: Medium (20GB)
	// * SHARD_SIZE_LARGE: Large (50GB)
	ShardSize pulumi.StringPtrInput `pulumi:"shardSize"`
}

func (AiIndexMetadataConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfig)(nil)).Elem()
}

func (i AiIndexMetadataConfigArgs) ToAiIndexMetadataConfigOutput() AiIndexMetadataConfigOutput {
	return i.ToAiIndexMetadataConfigOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigArgs) ToAiIndexMetadataConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigOutput)
}

func (i AiIndexMetadataConfigArgs) ToAiIndexMetadataConfigPtrOutput() AiIndexMetadataConfigPtrOutput {
	return i.ToAiIndexMetadataConfigPtrOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigArgs) ToAiIndexMetadataConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigOutput).ToAiIndexMetadataConfigPtrOutputWithContext(ctx)
}

// AiIndexMetadataConfigPtrInput is an input type that accepts AiIndexMetadataConfigArgs, AiIndexMetadataConfigPtr and AiIndexMetadataConfigPtrOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigPtrInput` via:
//
//	        AiIndexMetadataConfigArgs{...}
//
//	or:
//
//	        nil
type AiIndexMetadataConfigPtrInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigPtrOutput() AiIndexMetadataConfigPtrOutput
	ToAiIndexMetadataConfigPtrOutputWithContext(context.Context) AiIndexMetadataConfigPtrOutput
}

type aiIndexMetadataConfigPtrType AiIndexMetadataConfigArgs

func AiIndexMetadataConfigPtr(v *AiIndexMetadataConfigArgs) AiIndexMetadataConfigPtrInput {
	return (*aiIndexMetadataConfigPtrType)(v)
}

func (*aiIndexMetadataConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfig)(nil)).Elem()
}

func (i *aiIndexMetadataConfigPtrType) ToAiIndexMetadataConfigPtrOutput() AiIndexMetadataConfigPtrOutput {
	return i.ToAiIndexMetadataConfigPtrOutputWithContext(context.Background())
}

func (i *aiIndexMetadataConfigPtrType) ToAiIndexMetadataConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigPtrOutput)
}

type AiIndexMetadataConfigOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigOutput) ToAiIndexMetadataConfigOutput() AiIndexMetadataConfigOutput {
	return o
}

func (o AiIndexMetadataConfigOutput) ToAiIndexMetadataConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigOutput {
	return o
}

func (o AiIndexMetadataConfigOutput) ToAiIndexMetadataConfigPtrOutput() AiIndexMetadataConfigPtrOutput {
	return o.ToAiIndexMetadataConfigPtrOutputWithContext(context.Background())
}

func (o AiIndexMetadataConfigOutput) ToAiIndexMetadataConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexMetadataConfig) *AiIndexMetadataConfig {
		return &v
	}).(AiIndexMetadataConfigPtrOutput)
}

// The configuration with regard to the algorithms used for efficient search. This field may be required based on your configuration.
// Structure is documented below.
func (o AiIndexMetadataConfigOutput) AlgorithmConfig() AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfig) *AiIndexMetadataConfigAlgorithmConfig { return v.AlgorithmConfig }).(AiIndexMetadataConfigAlgorithmConfigPtrOutput)
}

// The default number of neighbors to find via approximate search before exact reordering is
// performed. Exact reordering is a procedure where results returned by an
// approximate search algorithm are reordered via a more expensive distance computation.
// Required if tree-AH algorithm is used.
func (o AiIndexMetadataConfigOutput) ApproximateNeighborsCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfig) *int { return v.ApproximateNeighborsCount }).(pulumi.IntPtrOutput)
}

// The number of dimensions of the input vectors.
func (o AiIndexMetadataConfigOutput) Dimensions() pulumi.IntOutput {
	return o.ApplyT(func(v AiIndexMetadataConfig) int { return v.Dimensions }).(pulumi.IntOutput)
}

// The distance measure used in nearest neighbor search. The value must be one of the followings:
// * SQUARED_L2_DISTANCE: Euclidean (L_2) Distance
// * L1_DISTANCE: Manhattan (L_1) Distance
// * COSINE_DISTANCE: Cosine Distance. Defined as 1 - cosine similarity.
// * DOT_PRODUCT_DISTANCE: Dot Product Distance. Defined as a negative of the dot product
func (o AiIndexMetadataConfigOutput) DistanceMeasureType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfig) *string { return v.DistanceMeasureType }).(pulumi.StringPtrOutput)
}

// Type of normalization to be carried out on each vector. The value must be one of the followings:
// * UNIT_L2_NORM: Unit L2 normalization type
// * NONE: No normalization type is specified.
func (o AiIndexMetadataConfigOutput) FeatureNormType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfig) *string { return v.FeatureNormType }).(pulumi.StringPtrOutput)
}

// Index data is split into equal parts to be processed. These are called "shards".
// The shard size must be specified when creating an index. The value must be one of the followings:
// * SHARD_SIZE_SMALL: Small (2GB)
// * SHARD_SIZE_MEDIUM: Medium (20GB)
// * SHARD_SIZE_LARGE: Large (50GB)
func (o AiIndexMetadataConfigOutput) ShardSize() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfig) *string { return v.ShardSize }).(pulumi.StringPtrOutput)
}

type AiIndexMetadataConfigPtrOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigPtrOutput) ToAiIndexMetadataConfigPtrOutput() AiIndexMetadataConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigPtrOutput) ToAiIndexMetadataConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigPtrOutput) Elem() AiIndexMetadataConfigOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) AiIndexMetadataConfig {
		if v != nil {
			return *v
		}
		var ret AiIndexMetadataConfig
		return ret
	}).(AiIndexMetadataConfigOutput)
}

// The configuration with regard to the algorithms used for efficient search. This field may be required based on your configuration.
// Structure is documented below.
func (o AiIndexMetadataConfigPtrOutput) AlgorithmConfig() AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) *AiIndexMetadataConfigAlgorithmConfig {
		if v == nil {
			return nil
		}
		return v.AlgorithmConfig
	}).(AiIndexMetadataConfigAlgorithmConfigPtrOutput)
}

// The default number of neighbors to find via approximate search before exact reordering is
// performed. Exact reordering is a procedure where results returned by an
// approximate search algorithm are reordered via a more expensive distance computation.
// Required if tree-AH algorithm is used.
func (o AiIndexMetadataConfigPtrOutput) ApproximateNeighborsCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) *int {
		if v == nil {
			return nil
		}
		return v.ApproximateNeighborsCount
	}).(pulumi.IntPtrOutput)
}

// The number of dimensions of the input vectors.
func (o AiIndexMetadataConfigPtrOutput) Dimensions() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) *int {
		if v == nil {
			return nil
		}
		return &v.Dimensions
	}).(pulumi.IntPtrOutput)
}

// The distance measure used in nearest neighbor search. The value must be one of the followings:
// * SQUARED_L2_DISTANCE: Euclidean (L_2) Distance
// * L1_DISTANCE: Manhattan (L_1) Distance
// * COSINE_DISTANCE: Cosine Distance. Defined as 1 - cosine similarity.
// * DOT_PRODUCT_DISTANCE: Dot Product Distance. Defined as a negative of the dot product
func (o AiIndexMetadataConfigPtrOutput) DistanceMeasureType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) *string {
		if v == nil {
			return nil
		}
		return v.DistanceMeasureType
	}).(pulumi.StringPtrOutput)
}

// Type of normalization to be carried out on each vector. The value must be one of the followings:
// * UNIT_L2_NORM: Unit L2 normalization type
// * NONE: No normalization type is specified.
func (o AiIndexMetadataConfigPtrOutput) FeatureNormType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) *string {
		if v == nil {
			return nil
		}
		return v.FeatureNormType
	}).(pulumi.StringPtrOutput)
}

// Index data is split into equal parts to be processed. These are called "shards".
// The shard size must be specified when creating an index. The value must be one of the followings:
// * SHARD_SIZE_SMALL: Small (2GB)
// * SHARD_SIZE_MEDIUM: Medium (20GB)
// * SHARD_SIZE_LARGE: Large (50GB)
func (o AiIndexMetadataConfigPtrOutput) ShardSize() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfig) *string {
		if v == nil {
			return nil
		}
		return v.ShardSize
	}).(pulumi.StringPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfig struct {
	// Configuration options for using brute force search, which simply implements the
	// standard linear search in the database for each query.
	BruteForceConfig *AiIndexMetadataConfigAlgorithmConfigBruteForceConfig `pulumi:"bruteForceConfig"`
	// Configuration options for using the tree-AH algorithm (Shallow tree + Asymmetric Hashing).
	// Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
	// Structure is documented below.
	TreeAhConfig *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig `pulumi:"treeAhConfig"`
}

// AiIndexMetadataConfigAlgorithmConfigInput is an input type that accepts AiIndexMetadataConfigAlgorithmConfigArgs and AiIndexMetadataConfigAlgorithmConfigOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigAlgorithmConfigInput` via:
//
//	AiIndexMetadataConfigAlgorithmConfigArgs{...}
type AiIndexMetadataConfigAlgorithmConfigInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigAlgorithmConfigOutput() AiIndexMetadataConfigAlgorithmConfigOutput
	ToAiIndexMetadataConfigAlgorithmConfigOutputWithContext(context.Context) AiIndexMetadataConfigAlgorithmConfigOutput
}

type AiIndexMetadataConfigAlgorithmConfigArgs struct {
	// Configuration options for using brute force search, which simply implements the
	// standard linear search in the database for each query.
	BruteForceConfig AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrInput `pulumi:"bruteForceConfig"`
	// Configuration options for using the tree-AH algorithm (Shallow tree + Asymmetric Hashing).
	// Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
	// Structure is documented below.
	TreeAhConfig AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrInput `pulumi:"treeAhConfig"`
}

func (AiIndexMetadataConfigAlgorithmConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (i AiIndexMetadataConfigAlgorithmConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigOutput() AiIndexMetadataConfigAlgorithmConfigOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigAlgorithmConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigOutput)
}

func (i AiIndexMetadataConfigAlgorithmConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigAlgorithmConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigOutput).ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(ctx)
}

// AiIndexMetadataConfigAlgorithmConfigPtrInput is an input type that accepts AiIndexMetadataConfigAlgorithmConfigArgs, AiIndexMetadataConfigAlgorithmConfigPtr and AiIndexMetadataConfigAlgorithmConfigPtrOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigAlgorithmConfigPtrInput` via:
//
//	        AiIndexMetadataConfigAlgorithmConfigArgs{...}
//
//	or:
//
//	        nil
type AiIndexMetadataConfigAlgorithmConfigPtrInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigAlgorithmConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigPtrOutput
	ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(context.Context) AiIndexMetadataConfigAlgorithmConfigPtrOutput
}

type aiIndexMetadataConfigAlgorithmConfigPtrType AiIndexMetadataConfigAlgorithmConfigArgs

func AiIndexMetadataConfigAlgorithmConfigPtr(v *AiIndexMetadataConfigAlgorithmConfigArgs) AiIndexMetadataConfigAlgorithmConfigPtrInput {
	return (*aiIndexMetadataConfigAlgorithmConfigPtrType)(v)
}

func (*aiIndexMetadataConfigAlgorithmConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (i *aiIndexMetadataConfigAlgorithmConfigPtrType) ToAiIndexMetadataConfigAlgorithmConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(context.Background())
}

func (i *aiIndexMetadataConfigAlgorithmConfigPtrType) ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigAlgorithmConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigAlgorithmConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigOutput() AiIndexMetadataConfigAlgorithmConfigOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return o.ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(context.Background())
}

func (o AiIndexMetadataConfigAlgorithmConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexMetadataConfigAlgorithmConfig) *AiIndexMetadataConfigAlgorithmConfig {
		return &v
	}).(AiIndexMetadataConfigAlgorithmConfigPtrOutput)
}

// Configuration options for using brute force search, which simply implements the
// standard linear search in the database for each query.
func (o AiIndexMetadataConfigAlgorithmConfigOutput) BruteForceConfig() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfigAlgorithmConfig) *AiIndexMetadataConfigAlgorithmConfigBruteForceConfig {
		return v.BruteForceConfig
	}).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput)
}

// Configuration options for using the tree-AH algorithm (Shallow tree + Asymmetric Hashing).
// Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
// Structure is documented below.
func (o AiIndexMetadataConfigAlgorithmConfigOutput) TreeAhConfig() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfigAlgorithmConfig) *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig {
		return v.TreeAhConfig
	}).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigPtrOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigAlgorithmConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigAlgorithmConfigPtrOutput) ToAiIndexMetadataConfigAlgorithmConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigPtrOutput) ToAiIndexMetadataConfigAlgorithmConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigPtrOutput) Elem() AiIndexMetadataConfigAlgorithmConfigOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfig) AiIndexMetadataConfigAlgorithmConfig {
		if v != nil {
			return *v
		}
		var ret AiIndexMetadataConfigAlgorithmConfig
		return ret
	}).(AiIndexMetadataConfigAlgorithmConfigOutput)
}

// Configuration options for using brute force search, which simply implements the
// standard linear search in the database for each query.
func (o AiIndexMetadataConfigAlgorithmConfigPtrOutput) BruteForceConfig() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfig) *AiIndexMetadataConfigAlgorithmConfigBruteForceConfig {
		if v == nil {
			return nil
		}
		return v.BruteForceConfig
	}).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput)
}

// Configuration options for using the tree-AH algorithm (Shallow tree + Asymmetric Hashing).
// Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
// Structure is documented below.
func (o AiIndexMetadataConfigAlgorithmConfigPtrOutput) TreeAhConfig() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfig) *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig {
		if v == nil {
			return nil
		}
		return v.TreeAhConfig
	}).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigBruteForceConfig struct {
}

// AiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput is an input type that accepts AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs and AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput` via:
//
//	AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{...}
type AiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput
	ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput
}

type AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs struct {
}

func (AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (i AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput)
}

func (i AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput).ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(ctx)
}

// AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrInput is an input type that accepts AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs, AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtr and AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrInput` via:
//
//	        AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{...}
//
//	or:
//
//	        nil
type AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput
	ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput
}

type aiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrType AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs

func AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtr(v *AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrInput {
	return (*aiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrType)(v)
}

func (*aiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (i *aiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrType) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(context.Background())
}

func (i *aiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrType) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return o.ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(context.Background())
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexMetadataConfigAlgorithmConfigBruteForceConfig) *AiIndexMetadataConfigAlgorithmConfigBruteForceConfig {
		return &v
	}).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput) ToAiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput) Elem() AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfigBruteForceConfig) AiIndexMetadataConfigAlgorithmConfigBruteForceConfig {
		if v != nil {
			return *v
		}
		var ret AiIndexMetadataConfigAlgorithmConfigBruteForceConfig
		return ret
	}).(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput)
}

type AiIndexMetadataConfigAlgorithmConfigTreeAhConfig struct {
	// Number of embeddings on each leaf node. The default value is 1000 if not set.
	LeafNodeEmbeddingCount *int `pulumi:"leafNodeEmbeddingCount"`
	// The default percentage of leaf nodes that any query may be searched. Must be in
	// range 1-100, inclusive. The default value is 10 (means 10%) if not set.
	LeafNodesToSearchPercent *int `pulumi:"leafNodesToSearchPercent"`
}

// AiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput is an input type that accepts AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs and AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput` via:
//
//	AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{...}
type AiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput
	ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput
}

type AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs struct {
	// Number of embeddings on each leaf node. The default value is 1000 if not set.
	LeafNodeEmbeddingCount pulumi.IntPtrInput `pulumi:"leafNodeEmbeddingCount"`
	// The default percentage of leaf nodes that any query may be searched. Must be in
	// range 1-100, inclusive. The default value is 10 (means 10%) if not set.
	LeafNodesToSearchPercent pulumi.IntPtrInput `pulumi:"leafNodesToSearchPercent"`
}

func (AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (i AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput)
}

func (i AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(context.Background())
}

func (i AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput).ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(ctx)
}

// AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrInput is an input type that accepts AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs, AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtr and AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput values.
// You can construct a concrete instance of `AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrInput` via:
//
//	        AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{...}
//
//	or:
//
//	        nil
type AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrInput interface {
	pulumi.Input

	ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput
	ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput
}

type aiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrType AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs

func AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtr(v *AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrInput {
	return (*aiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrType)(v)
}

func (*aiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (i *aiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrType) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return i.ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(context.Background())
}

func (i *aiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrType) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return o.ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(context.Background())
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiIndexMetadataConfigAlgorithmConfigTreeAhConfig) *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig {
		return &v
	}).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput)
}

// Number of embeddings on each leaf node. The default value is 1000 if not set.
func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) LeafNodeEmbeddingCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfigAlgorithmConfigTreeAhConfig) *int { return v.LeafNodeEmbeddingCount }).(pulumi.IntPtrOutput)
}

// The default percentage of leaf nodes that any query may be searched. Must be in
// range 1-100, inclusive. The default value is 10 (means 10%) if not set.
func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) LeafNodesToSearchPercent() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AiIndexMetadataConfigAlgorithmConfigTreeAhConfig) *int { return v.LeafNodesToSearchPercent }).(pulumi.IntPtrOutput)
}

type AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput struct{ *pulumi.OutputState }

func (AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput) ToAiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutputWithContext(ctx context.Context) AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput {
	return o
}

func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput) Elem() AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig) AiIndexMetadataConfigAlgorithmConfigTreeAhConfig {
		if v != nil {
			return *v
		}
		var ret AiIndexMetadataConfigAlgorithmConfigTreeAhConfig
		return ret
	}).(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput)
}

// Number of embeddings on each leaf node. The default value is 1000 if not set.
func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput) LeafNodeEmbeddingCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig) *int {
		if v == nil {
			return nil
		}
		return v.LeafNodeEmbeddingCount
	}).(pulumi.IntPtrOutput)
}

// The default percentage of leaf nodes that any query may be searched. Must be in
// range 1-100, inclusive. The default value is 10 (means 10%) if not set.
func (o AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput) LeafNodesToSearchPercent() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *AiIndexMetadataConfigAlgorithmConfigTreeAhConfig) *int {
		if v == nil {
			return nil
		}
		return v.LeafNodesToSearchPercent
	}).(pulumi.IntPtrOutput)
}

type AiMetadataStoreEncryptionSpec struct {
	// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
	// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
	KmsKeyName *string `pulumi:"kmsKeyName"`
}

// AiMetadataStoreEncryptionSpecInput is an input type that accepts AiMetadataStoreEncryptionSpecArgs and AiMetadataStoreEncryptionSpecOutput values.
// You can construct a concrete instance of `AiMetadataStoreEncryptionSpecInput` via:
//
//	AiMetadataStoreEncryptionSpecArgs{...}
type AiMetadataStoreEncryptionSpecInput interface {
	pulumi.Input

	ToAiMetadataStoreEncryptionSpecOutput() AiMetadataStoreEncryptionSpecOutput
	ToAiMetadataStoreEncryptionSpecOutputWithContext(context.Context) AiMetadataStoreEncryptionSpecOutput
}

type AiMetadataStoreEncryptionSpecArgs struct {
	// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
	// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
	KmsKeyName pulumi.StringPtrInput `pulumi:"kmsKeyName"`
}

func (AiMetadataStoreEncryptionSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiMetadataStoreEncryptionSpec)(nil)).Elem()
}

func (i AiMetadataStoreEncryptionSpecArgs) ToAiMetadataStoreEncryptionSpecOutput() AiMetadataStoreEncryptionSpecOutput {
	return i.ToAiMetadataStoreEncryptionSpecOutputWithContext(context.Background())
}

func (i AiMetadataStoreEncryptionSpecArgs) ToAiMetadataStoreEncryptionSpecOutputWithContext(ctx context.Context) AiMetadataStoreEncryptionSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiMetadataStoreEncryptionSpecOutput)
}

func (i AiMetadataStoreEncryptionSpecArgs) ToAiMetadataStoreEncryptionSpecPtrOutput() AiMetadataStoreEncryptionSpecPtrOutput {
	return i.ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i AiMetadataStoreEncryptionSpecArgs) ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiMetadataStoreEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiMetadataStoreEncryptionSpecOutput).ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(ctx)
}

// AiMetadataStoreEncryptionSpecPtrInput is an input type that accepts AiMetadataStoreEncryptionSpecArgs, AiMetadataStoreEncryptionSpecPtr and AiMetadataStoreEncryptionSpecPtrOutput values.
// You can construct a concrete instance of `AiMetadataStoreEncryptionSpecPtrInput` via:
//
//	        AiMetadataStoreEncryptionSpecArgs{...}
//
//	or:
//
//	        nil
type AiMetadataStoreEncryptionSpecPtrInput interface {
	pulumi.Input

	ToAiMetadataStoreEncryptionSpecPtrOutput() AiMetadataStoreEncryptionSpecPtrOutput
	ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(context.Context) AiMetadataStoreEncryptionSpecPtrOutput
}

type aiMetadataStoreEncryptionSpecPtrType AiMetadataStoreEncryptionSpecArgs

func AiMetadataStoreEncryptionSpecPtr(v *AiMetadataStoreEncryptionSpecArgs) AiMetadataStoreEncryptionSpecPtrInput {
	return (*aiMetadataStoreEncryptionSpecPtrType)(v)
}

func (*aiMetadataStoreEncryptionSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiMetadataStoreEncryptionSpec)(nil)).Elem()
}

func (i *aiMetadataStoreEncryptionSpecPtrType) ToAiMetadataStoreEncryptionSpecPtrOutput() AiMetadataStoreEncryptionSpecPtrOutput {
	return i.ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i *aiMetadataStoreEncryptionSpecPtrType) ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiMetadataStoreEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiMetadataStoreEncryptionSpecPtrOutput)
}

type AiMetadataStoreEncryptionSpecOutput struct{ *pulumi.OutputState }

func (AiMetadataStoreEncryptionSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiMetadataStoreEncryptionSpec)(nil)).Elem()
}

func (o AiMetadataStoreEncryptionSpecOutput) ToAiMetadataStoreEncryptionSpecOutput() AiMetadataStoreEncryptionSpecOutput {
	return o
}

func (o AiMetadataStoreEncryptionSpecOutput) ToAiMetadataStoreEncryptionSpecOutputWithContext(ctx context.Context) AiMetadataStoreEncryptionSpecOutput {
	return o
}

func (o AiMetadataStoreEncryptionSpecOutput) ToAiMetadataStoreEncryptionSpecPtrOutput() AiMetadataStoreEncryptionSpecPtrOutput {
	return o.ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(context.Background())
}

func (o AiMetadataStoreEncryptionSpecOutput) ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiMetadataStoreEncryptionSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiMetadataStoreEncryptionSpec) *AiMetadataStoreEncryptionSpec {
		return &v
	}).(AiMetadataStoreEncryptionSpecPtrOutput)
}

// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
func (o AiMetadataStoreEncryptionSpecOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiMetadataStoreEncryptionSpec) *string { return v.KmsKeyName }).(pulumi.StringPtrOutput)
}

type AiMetadataStoreEncryptionSpecPtrOutput struct{ *pulumi.OutputState }

func (AiMetadataStoreEncryptionSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiMetadataStoreEncryptionSpec)(nil)).Elem()
}

func (o AiMetadataStoreEncryptionSpecPtrOutput) ToAiMetadataStoreEncryptionSpecPtrOutput() AiMetadataStoreEncryptionSpecPtrOutput {
	return o
}

func (o AiMetadataStoreEncryptionSpecPtrOutput) ToAiMetadataStoreEncryptionSpecPtrOutputWithContext(ctx context.Context) AiMetadataStoreEncryptionSpecPtrOutput {
	return o
}

func (o AiMetadataStoreEncryptionSpecPtrOutput) Elem() AiMetadataStoreEncryptionSpecOutput {
	return o.ApplyT(func(v *AiMetadataStoreEncryptionSpec) AiMetadataStoreEncryptionSpec {
		if v != nil {
			return *v
		}
		var ret AiMetadataStoreEncryptionSpec
		return ret
	}).(AiMetadataStoreEncryptionSpecOutput)
}

// Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
func (o AiMetadataStoreEncryptionSpecPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiMetadataStoreEncryptionSpec) *string {
		if v == nil {
			return nil
		}
		return v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type AiMetadataStoreStateType struct {
	// (Output)
	// The disk utilization of the MetadataStore in bytes.
	DiskUtilizationBytes *string `pulumi:"diskUtilizationBytes"`
}

// AiMetadataStoreStateTypeInput is an input type that accepts AiMetadataStoreStateTypeArgs and AiMetadataStoreStateTypeOutput values.
// You can construct a concrete instance of `AiMetadataStoreStateTypeInput` via:
//
//	AiMetadataStoreStateTypeArgs{...}
type AiMetadataStoreStateTypeInput interface {
	pulumi.Input

	ToAiMetadataStoreStateTypeOutput() AiMetadataStoreStateTypeOutput
	ToAiMetadataStoreStateTypeOutputWithContext(context.Context) AiMetadataStoreStateTypeOutput
}

type AiMetadataStoreStateTypeArgs struct {
	// (Output)
	// The disk utilization of the MetadataStore in bytes.
	DiskUtilizationBytes pulumi.StringPtrInput `pulumi:"diskUtilizationBytes"`
}

func (AiMetadataStoreStateTypeArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiMetadataStoreStateType)(nil)).Elem()
}

func (i AiMetadataStoreStateTypeArgs) ToAiMetadataStoreStateTypeOutput() AiMetadataStoreStateTypeOutput {
	return i.ToAiMetadataStoreStateTypeOutputWithContext(context.Background())
}

func (i AiMetadataStoreStateTypeArgs) ToAiMetadataStoreStateTypeOutputWithContext(ctx context.Context) AiMetadataStoreStateTypeOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiMetadataStoreStateTypeOutput)
}

// AiMetadataStoreStateTypeArrayInput is an input type that accepts AiMetadataStoreStateTypeArray and AiMetadataStoreStateTypeArrayOutput values.
// You can construct a concrete instance of `AiMetadataStoreStateTypeArrayInput` via:
//
//	AiMetadataStoreStateTypeArray{ AiMetadataStoreStateTypeArgs{...} }
type AiMetadataStoreStateTypeArrayInput interface {
	pulumi.Input

	ToAiMetadataStoreStateTypeArrayOutput() AiMetadataStoreStateTypeArrayOutput
	ToAiMetadataStoreStateTypeArrayOutputWithContext(context.Context) AiMetadataStoreStateTypeArrayOutput
}

type AiMetadataStoreStateTypeArray []AiMetadataStoreStateTypeInput

func (AiMetadataStoreStateTypeArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiMetadataStoreStateType)(nil)).Elem()
}

func (i AiMetadataStoreStateTypeArray) ToAiMetadataStoreStateTypeArrayOutput() AiMetadataStoreStateTypeArrayOutput {
	return i.ToAiMetadataStoreStateTypeArrayOutputWithContext(context.Background())
}

func (i AiMetadataStoreStateTypeArray) ToAiMetadataStoreStateTypeArrayOutputWithContext(ctx context.Context) AiMetadataStoreStateTypeArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiMetadataStoreStateTypeArrayOutput)
}

type AiMetadataStoreStateTypeOutput struct{ *pulumi.OutputState }

func (AiMetadataStoreStateTypeOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiMetadataStoreStateType)(nil)).Elem()
}

func (o AiMetadataStoreStateTypeOutput) ToAiMetadataStoreStateTypeOutput() AiMetadataStoreStateTypeOutput {
	return o
}

func (o AiMetadataStoreStateTypeOutput) ToAiMetadataStoreStateTypeOutputWithContext(ctx context.Context) AiMetadataStoreStateTypeOutput {
	return o
}

// (Output)
// The disk utilization of the MetadataStore in bytes.
func (o AiMetadataStoreStateTypeOutput) DiskUtilizationBytes() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AiMetadataStoreStateType) *string { return v.DiskUtilizationBytes }).(pulumi.StringPtrOutput)
}

type AiMetadataStoreStateTypeArrayOutput struct{ *pulumi.OutputState }

func (AiMetadataStoreStateTypeArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AiMetadataStoreStateType)(nil)).Elem()
}

func (o AiMetadataStoreStateTypeArrayOutput) ToAiMetadataStoreStateTypeArrayOutput() AiMetadataStoreStateTypeArrayOutput {
	return o
}

func (o AiMetadataStoreStateTypeArrayOutput) ToAiMetadataStoreStateTypeArrayOutputWithContext(ctx context.Context) AiMetadataStoreStateTypeArrayOutput {
	return o
}

func (o AiMetadataStoreStateTypeArrayOutput) Index(i pulumi.IntInput) AiMetadataStoreStateTypeOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AiMetadataStoreStateType {
		return vs[0].([]AiMetadataStoreStateType)[vs[1].(int)]
	}).(AiMetadataStoreStateTypeOutput)
}

type AiRagEngineConfigRagManagedDbConfig struct {
	// Basic tier is a cost-effective and low compute tier suitable for the following cases: Experimenting with RagManagedDb, Small data size, Latency insensitive workload, Only using RAG Engine with external vector DBs.
	// NOTE: This is the default tier if not explicitly chosen.
	Basic *AiRagEngineConfigRagManagedDbConfigBasic `pulumi:"basic"`
	// Scaled tier offers production grade performance along with autoscaling functionality. It is suitable for customers with large amounts of data or performance sensitive workloads.
	Scaled *AiRagEngineConfigRagManagedDbConfigScaled `pulumi:"scaled"`
	// Disables the RAG Engine service and deletes all your data held within this service. This will halt the billing of the service.
	// NOTE: Once deleted the data cannot be recovered. To start using RAG Engine again, you will need to update the tier by calling the UpdateRagEngineConfig API.
	Unprovisioned *AiRagEngineConfigRagManagedDbConfigUnprovisioned `pulumi:"unprovisioned"`
}

// AiRagEngineConfigRagManagedDbConfigInput is an input type that accepts AiRagEngineConfigRagManagedDbConfigArgs and AiRagEngineConfigRagManagedDbConfigOutput values.
// You can construct a concrete instance of `AiRagEngineConfigRagManagedDbConfigInput` via:
//
//	AiRagEngineConfigRagManagedDbConfigArgs{...}
type AiRagEngineConfigRagManagedDbConfigInput interface {
	pulumi.Input

	ToAiRagEngineConfigRagManagedDbConfigOutput() AiRagEngineConfigRagManagedDbConfigOutput
	ToAiRagEngineConfigRagManagedDbConfigOutputWithContext(context.Context) AiRagEngineConfigRagManagedDbConfigOutput
}

type AiRagEngineConfigRagManagedDbConfigArgs struct {
	// Basic tier is a cost-effective and low compute tier suitable for the following cases: Experimenting with RagManagedDb, Small data size, Latency insensitive workload, Only using RAG Engine with external vector DBs.
	// NOTE: This is the default tier if not explicitly chosen.
	Basic AiRagEngineConfigRagManagedDbConfigBasicPtrInput `pulumi:"basic"`
	// Scaled tier offers production grade performance along with autoscaling functionality. It is suitable for customers with large amounts of data or performance sensitive workloads.
	Scaled AiRagEngineConfigRagManagedDbConfigScaledPtrInput `pulumi:"scaled"`
	// Disables the RAG Engine service and deletes all your data held within this service. This will halt the billing of the service.
	// NOTE: Once deleted the data cannot be recovered. To start using RAG Engine again, you will need to update the tier by calling the UpdateRagEngineConfig API.
	Unprovisioned AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrInput `pulumi:"unprovisioned"`
}

func (AiRagEngineConfigRagManagedDbConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfig)(nil)).Elem()
}

func (i AiRagEngineConfigRagManagedDbConfigArgs) ToAiRagEngineConfigRagManagedDbConfigOutput() AiRagEngineConfigRagManagedDbConfigOutput {
	return i.ToAiRagEngineConfigRagManagedDbConfigOutputWithContext(context.Background())
}

func (i AiRagEngineConfigRagManagedDbConfigArgs) ToAiRagEngineConfigRagManagedDbConfigOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiRagEngineConfigRagManagedDbConfigOutput)
}

func (i AiRagEngineConfigRagManagedDbConfigArgs) ToAiRagEngineConfigRagManagedDbConfigPtrOutput() AiRagEngineConfigRagManagedDbConfigPtrOutput {
	return i.ToAiRagEngineConfigRagManagedDbConfigPtrOutputWithContext(context.Background())
}

func (i AiRagEngineConfigRagManagedDbConfigArgs) ToAiRagEngineConfigRagManagedDbConfigPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiRagEngineConfigRagManagedDbConfigOutput).ToAiRagEngineConfigRagManagedDbConfigPtrOutputWithContext(ctx)
}

// AiRagEngineConfigRagManagedDbConfigPtrInput is an input type that accepts AiRagEngineConfigRagManagedDbConfigArgs, AiRagEngineConfigRagManagedDbConfigPtr and AiRagEngineConfigRagManagedDbConfigPtrOutput values.
// You can construct a concrete instance of `AiRagEngineConfigRagManagedDbConfigPtrInput` via:
//
//	        AiRagEngineConfigRagManagedDbConfigArgs{...}
//
//	or:
//
//	        nil
type AiRagEngineConfigRagManagedDbConfigPtrInput interface {
	pulumi.Input

	ToAiRagEngineConfigRagManagedDbConfigPtrOutput() AiRagEngineConfigRagManagedDbConfigPtrOutput
	ToAiRagEngineConfigRagManagedDbConfigPtrOutputWithContext(context.Context) AiRagEngineConfigRagManagedDbConfigPtrOutput
}

type aiRagEngineConfigRagManagedDbConfigPtrType AiRagEngineConfigRagManagedDbConfigArgs

func AiRagEngineConfigRagManagedDbConfigPtr(v *AiRagEngineConfigRagManagedDbConfigArgs) AiRagEngineConfigRagManagedDbConfigPtrInput {
	return (*aiRagEngineConfigRagManagedDbConfigPtrType)(v)
}

func (*aiRagEngineConfigRagManagedDbConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiRagEngineConfigRagManagedDbConfig)(nil)).Elem()
}

func (i *aiRagEngineConfigRagManagedDbConfigPtrType) ToAiRagEngineConfigRagManagedDbConfigPtrOutput() AiRagEngineConfigRagManagedDbConfigPtrOutput {
	return i.ToAiRagEngineConfigRagManagedDbConfigPtrOutputWithContext(context.Background())
}

func (i *aiRagEngineConfigRagManagedDbConfigPtrType) ToAiRagEngineConfigRagManagedDbConfigPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiRagEngineConfigRagManagedDbConfigPtrOutput)
}

type AiRagEngineConfigRagManagedDbConfigOutput struct{ *pulumi.OutputState }

func (AiRagEngineConfigRagManagedDbConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfig)(nil)).Elem()
}

func (o AiRagEngineConfigRagManagedDbConfigOutput) ToAiRagEngineConfigRagManagedDbConfigOutput() AiRagEngineConfigRagManagedDbConfigOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigOutput) ToAiRagEngineConfigRagManagedDbConfigOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigOutput) ToAiRagEngineConfigRagManagedDbConfigPtrOutput() AiRagEngineConfigRagManagedDbConfigPtrOutput {
	return o.ToAiRagEngineConfigRagManagedDbConfigPtrOutputWithContext(context.Background())
}

func (o AiRagEngineConfigRagManagedDbConfigOutput) ToAiRagEngineConfigRagManagedDbConfigPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiRagEngineConfigRagManagedDbConfig) *AiRagEngineConfigRagManagedDbConfig {
		return &v
	}).(AiRagEngineConfigRagManagedDbConfigPtrOutput)
}

// Basic tier is a cost-effective and low compute tier suitable for the following cases: Experimenting with RagManagedDb, Small data size, Latency insensitive workload, Only using RAG Engine with external vector DBs.
// NOTE: This is the default tier if not explicitly chosen.
func (o AiRagEngineConfigRagManagedDbConfigOutput) Basic() AiRagEngineConfigRagManagedDbConfigBasicPtrOutput {
	return o.ApplyT(func(v AiRagEngineConfigRagManagedDbConfig) *AiRagEngineConfigRagManagedDbConfigBasic { return v.Basic }).(AiRagEngineConfigRagManagedDbConfigBasicPtrOutput)
}

// Scaled tier offers production grade performance along with autoscaling functionality. It is suitable for customers with large amounts of data or performance sensitive workloads.
func (o AiRagEngineConfigRagManagedDbConfigOutput) Scaled() AiRagEngineConfigRagManagedDbConfigScaledPtrOutput {
	return o.ApplyT(func(v AiRagEngineConfigRagManagedDbConfig) *AiRagEngineConfigRagManagedDbConfigScaled {
		return v.Scaled
	}).(AiRagEngineConfigRagManagedDbConfigScaledPtrOutput)
}

// Disables the RAG Engine service and deletes all your data held within this service. This will halt the billing of the service.
// NOTE: Once deleted the data cannot be recovered. To start using RAG Engine again, you will need to update the tier by calling the UpdateRagEngineConfig API.
func (o AiRagEngineConfigRagManagedDbConfigOutput) Unprovisioned() AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput {
	return o.ApplyT(func(v AiRagEngineConfigRagManagedDbConfig) *AiRagEngineConfigRagManagedDbConfigUnprovisioned {
		return v.Unprovisioned
	}).(AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput)
}

type AiRagEngineConfigRagManagedDbConfigPtrOutput struct{ *pulumi.OutputState }

func (AiRagEngineConfigRagManagedDbConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiRagEngineConfigRagManagedDbConfig)(nil)).Elem()
}

func (o AiRagEngineConfigRagManagedDbConfigPtrOutput) ToAiRagEngineConfigRagManagedDbConfigPtrOutput() AiRagEngineConfigRagManagedDbConfigPtrOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigPtrOutput) ToAiRagEngineConfigRagManagedDbConfigPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigPtrOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigPtrOutput) Elem() AiRagEngineConfigRagManagedDbConfigOutput {
	return o.ApplyT(func(v *AiRagEngineConfigRagManagedDbConfig) AiRagEngineConfigRagManagedDbConfig {
		if v != nil {
			return *v
		}
		var ret AiRagEngineConfigRagManagedDbConfig
		return ret
	}).(AiRagEngineConfigRagManagedDbConfigOutput)
}

// Basic tier is a cost-effective and low compute tier suitable for the following cases: Experimenting with RagManagedDb, Small data size, Latency insensitive workload, Only using RAG Engine with external vector DBs.
// NOTE: This is the default tier if not explicitly chosen.
func (o AiRagEngineConfigRagManagedDbConfigPtrOutput) Basic() AiRagEngineConfigRagManagedDbConfigBasicPtrOutput {
	return o.ApplyT(func(v *AiRagEngineConfigRagManagedDbConfig) *AiRagEngineConfigRagManagedDbConfigBasic {
		if v == nil {
			return nil
		}
		return v.Basic
	}).(AiRagEngineConfigRagManagedDbConfigBasicPtrOutput)
}

// Scaled tier offers production grade performance along with autoscaling functionality. It is suitable for customers with large amounts of data or performance sensitive workloads.
func (o AiRagEngineConfigRagManagedDbConfigPtrOutput) Scaled() AiRagEngineConfigRagManagedDbConfigScaledPtrOutput {
	return o.ApplyT(func(v *AiRagEngineConfigRagManagedDbConfig) *AiRagEngineConfigRagManagedDbConfigScaled {
		if v == nil {
			return nil
		}
		return v.Scaled
	}).(AiRagEngineConfigRagManagedDbConfigScaledPtrOutput)
}

// Disables the RAG Engine service and deletes all your data held within this service. This will halt the billing of the service.
// NOTE: Once deleted the data cannot be recovered. To start using RAG Engine again, you will need to update the tier by calling the UpdateRagEngineConfig API.
func (o AiRagEngineConfigRagManagedDbConfigPtrOutput) Unprovisioned() AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput {
	return o.ApplyT(func(v *AiRagEngineConfigRagManagedDbConfig) *AiRagEngineConfigRagManagedDbConfigUnprovisioned {
		if v == nil {
			return nil
		}
		return v.Unprovisioned
	}).(AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput)
}

type AiRagEngineConfigRagManagedDbConfigBasic struct {
}

// AiRagEngineConfigRagManagedDbConfigBasicInput is an input type that accepts AiRagEngineConfigRagManagedDbConfigBasicArgs and AiRagEngineConfigRagManagedDbConfigBasicOutput values.
// You can construct a concrete instance of `AiRagEngineConfigRagManagedDbConfigBasicInput` via:
//
//	AiRagEngineConfigRagManagedDbConfigBasicArgs{...}
type AiRagEngineConfigRagManagedDbConfigBasicInput interface {
	pulumi.Input

	ToAiRagEngineConfigRagManagedDbConfigBasicOutput() AiRagEngineConfigRagManagedDbConfigBasicOutput
	ToAiRagEngineConfigRagManagedDbConfigBasicOutputWithContext(context.Context) AiRagEngineConfigRagManagedDbConfigBasicOutput
}

type AiRagEngineConfigRagManagedDbConfigBasicArgs struct {
}

func (AiRagEngineConfigRagManagedDbConfigBasicArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigBasic)(nil)).Elem()
}

func (i AiRagEngineConfigRagManagedDbConfigBasicArgs) ToAiRagEngineConfigRagManagedDbConfigBasicOutput() AiRagEngineConfigRagManagedDbConfigBasicOutput {
	return i.ToAiRagEngineConfigRagManagedDbConfigBasicOutputWithContext(context.Background())
}

func (i AiRagEngineConfigRagManagedDbConfigBasicArgs) ToAiRagEngineConfigRagManagedDbConfigBasicOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigBasicOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiRagEngineConfigRagManagedDbConfigBasicOutput)
}

func (i AiRagEngineConfigRagManagedDbConfigBasicArgs) ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutput() AiRagEngineConfigRagManagedDbConfigBasicPtrOutput {
	return i.ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutputWithContext(context.Background())
}

func (i AiRagEngineConfigRagManagedDbConfigBasicArgs) ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigBasicPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiRagEngineConfigRagManagedDbConfigBasicOutput).ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutputWithContext(ctx)
}

// AiRagEngineConfigRagManagedDbConfigBasicPtrInput is an input type that accepts AiRagEngineConfigRagManagedDbConfigBasicArgs, AiRagEngineConfigRagManagedDbConfigBasicPtr and AiRagEngineConfigRagManagedDbConfigBasicPtrOutput values.
// You can construct a concrete instance of `AiRagEngineConfigRagManagedDbConfigBasicPtrInput` via:
//
//	        AiRagEngineConfigRagManagedDbConfigBasicArgs{...}
//
//	or:
//
//	        nil
type AiRagEngineConfigRagManagedDbConfigBasicPtrInput interface {
	pulumi.Input

	ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutput() AiRagEngineConfigRagManagedDbConfigBasicPtrOutput
	ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutputWithContext(context.Context) AiRagEngineConfigRagManagedDbConfigBasicPtrOutput
}

type aiRagEngineConfigRagManagedDbConfigBasicPtrType AiRagEngineConfigRagManagedDbConfigBasicArgs

func AiRagEngineConfigRagManagedDbConfigBasicPtr(v *AiRagEngineConfigRagManagedDbConfigBasicArgs) AiRagEngineConfigRagManagedDbConfigBasicPtrInput {
	return (*aiRagEngineConfigRagManagedDbConfigBasicPtrType)(v)
}

func (*aiRagEngineConfigRagManagedDbConfigBasicPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiRagEngineConfigRagManagedDbConfigBasic)(nil)).Elem()
}

func (i *aiRagEngineConfigRagManagedDbConfigBasicPtrType) ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutput() AiRagEngineConfigRagManagedDbConfigBasicPtrOutput {
	return i.ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutputWithContext(context.Background())
}

func (i *aiRagEngineConfigRagManagedDbConfigBasicPtrType) ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigBasicPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiRagEngineConfigRagManagedDbConfigBasicPtrOutput)
}

type AiRagEngineConfigRagManagedDbConfigBasicOutput struct{ *pulumi.OutputState }

func (AiRagEngineConfigRagManagedDbConfigBasicOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigBasic)(nil)).Elem()
}

func (o AiRagEngineConfigRagManagedDbConfigBasicOutput) ToAiRagEngineConfigRagManagedDbConfigBasicOutput() AiRagEngineConfigRagManagedDbConfigBasicOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigBasicOutput) ToAiRagEngineConfigRagManagedDbConfigBasicOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigBasicOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigBasicOutput) ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutput() AiRagEngineConfigRagManagedDbConfigBasicPtrOutput {
	return o.ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutputWithContext(context.Background())
}

func (o AiRagEngineConfigRagManagedDbConfigBasicOutput) ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigBasicPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiRagEngineConfigRagManagedDbConfigBasic) *AiRagEngineConfigRagManagedDbConfigBasic {
		return &v
	}).(AiRagEngineConfigRagManagedDbConfigBasicPtrOutput)
}

type AiRagEngineConfigRagManagedDbConfigBasicPtrOutput struct{ *pulumi.OutputState }

func (AiRagEngineConfigRagManagedDbConfigBasicPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiRagEngineConfigRagManagedDbConfigBasic)(nil)).Elem()
}

func (o AiRagEngineConfigRagManagedDbConfigBasicPtrOutput) ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutput() AiRagEngineConfigRagManagedDbConfigBasicPtrOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigBasicPtrOutput) ToAiRagEngineConfigRagManagedDbConfigBasicPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigBasicPtrOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigBasicPtrOutput) Elem() AiRagEngineConfigRagManagedDbConfigBasicOutput {
	return o.ApplyT(func(v *AiRagEngineConfigRagManagedDbConfigBasic) AiRagEngineConfigRagManagedDbConfigBasic {
		if v != nil {
			return *v
		}
		var ret AiRagEngineConfigRagManagedDbConfigBasic
		return ret
	}).(AiRagEngineConfigRagManagedDbConfigBasicOutput)
}

type AiRagEngineConfigRagManagedDbConfigScaled struct {
}

// AiRagEngineConfigRagManagedDbConfigScaledInput is an input type that accepts AiRagEngineConfigRagManagedDbConfigScaledArgs and AiRagEngineConfigRagManagedDbConfigScaledOutput values.
// You can construct a concrete instance of `AiRagEngineConfigRagManagedDbConfigScaledInput` via:
//
//	AiRagEngineConfigRagManagedDbConfigScaledArgs{...}
type AiRagEngineConfigRagManagedDbConfigScaledInput interface {
	pulumi.Input

	ToAiRagEngineConfigRagManagedDbConfigScaledOutput() AiRagEngineConfigRagManagedDbConfigScaledOutput
	ToAiRagEngineConfigRagManagedDbConfigScaledOutputWithContext(context.Context) AiRagEngineConfigRagManagedDbConfigScaledOutput
}

type AiRagEngineConfigRagManagedDbConfigScaledArgs struct {
}

func (AiRagEngineConfigRagManagedDbConfigScaledArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigScaled)(nil)).Elem()
}

func (i AiRagEngineConfigRagManagedDbConfigScaledArgs) ToAiRagEngineConfigRagManagedDbConfigScaledOutput() AiRagEngineConfigRagManagedDbConfigScaledOutput {
	return i.ToAiRagEngineConfigRagManagedDbConfigScaledOutputWithContext(context.Background())
}

func (i AiRagEngineConfigRagManagedDbConfigScaledArgs) ToAiRagEngineConfigRagManagedDbConfigScaledOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigScaledOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiRagEngineConfigRagManagedDbConfigScaledOutput)
}

func (i AiRagEngineConfigRagManagedDbConfigScaledArgs) ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutput() AiRagEngineConfigRagManagedDbConfigScaledPtrOutput {
	return i.ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutputWithContext(context.Background())
}

func (i AiRagEngineConfigRagManagedDbConfigScaledArgs) ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigScaledPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiRagEngineConfigRagManagedDbConfigScaledOutput).ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutputWithContext(ctx)
}

// AiRagEngineConfigRagManagedDbConfigScaledPtrInput is an input type that accepts AiRagEngineConfigRagManagedDbConfigScaledArgs, AiRagEngineConfigRagManagedDbConfigScaledPtr and AiRagEngineConfigRagManagedDbConfigScaledPtrOutput values.
// You can construct a concrete instance of `AiRagEngineConfigRagManagedDbConfigScaledPtrInput` via:
//
//	        AiRagEngineConfigRagManagedDbConfigScaledArgs{...}
//
//	or:
//
//	        nil
type AiRagEngineConfigRagManagedDbConfigScaledPtrInput interface {
	pulumi.Input

	ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutput() AiRagEngineConfigRagManagedDbConfigScaledPtrOutput
	ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutputWithContext(context.Context) AiRagEngineConfigRagManagedDbConfigScaledPtrOutput
}

type aiRagEngineConfigRagManagedDbConfigScaledPtrType AiRagEngineConfigRagManagedDbConfigScaledArgs

func AiRagEngineConfigRagManagedDbConfigScaledPtr(v *AiRagEngineConfigRagManagedDbConfigScaledArgs) AiRagEngineConfigRagManagedDbConfigScaledPtrInput {
	return (*aiRagEngineConfigRagManagedDbConfigScaledPtrType)(v)
}

func (*aiRagEngineConfigRagManagedDbConfigScaledPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiRagEngineConfigRagManagedDbConfigScaled)(nil)).Elem()
}

func (i *aiRagEngineConfigRagManagedDbConfigScaledPtrType) ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutput() AiRagEngineConfigRagManagedDbConfigScaledPtrOutput {
	return i.ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutputWithContext(context.Background())
}

func (i *aiRagEngineConfigRagManagedDbConfigScaledPtrType) ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigScaledPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiRagEngineConfigRagManagedDbConfigScaledPtrOutput)
}

type AiRagEngineConfigRagManagedDbConfigScaledOutput struct{ *pulumi.OutputState }

func (AiRagEngineConfigRagManagedDbConfigScaledOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigScaled)(nil)).Elem()
}

func (o AiRagEngineConfigRagManagedDbConfigScaledOutput) ToAiRagEngineConfigRagManagedDbConfigScaledOutput() AiRagEngineConfigRagManagedDbConfigScaledOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigScaledOutput) ToAiRagEngineConfigRagManagedDbConfigScaledOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigScaledOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigScaledOutput) ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutput() AiRagEngineConfigRagManagedDbConfigScaledPtrOutput {
	return o.ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutputWithContext(context.Background())
}

func (o AiRagEngineConfigRagManagedDbConfigScaledOutput) ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigScaledPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiRagEngineConfigRagManagedDbConfigScaled) *AiRagEngineConfigRagManagedDbConfigScaled {
		return &v
	}).(AiRagEngineConfigRagManagedDbConfigScaledPtrOutput)
}

type AiRagEngineConfigRagManagedDbConfigScaledPtrOutput struct{ *pulumi.OutputState }

func (AiRagEngineConfigRagManagedDbConfigScaledPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiRagEngineConfigRagManagedDbConfigScaled)(nil)).Elem()
}

func (o AiRagEngineConfigRagManagedDbConfigScaledPtrOutput) ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutput() AiRagEngineConfigRagManagedDbConfigScaledPtrOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigScaledPtrOutput) ToAiRagEngineConfigRagManagedDbConfigScaledPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigScaledPtrOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigScaledPtrOutput) Elem() AiRagEngineConfigRagManagedDbConfigScaledOutput {
	return o.ApplyT(func(v *AiRagEngineConfigRagManagedDbConfigScaled) AiRagEngineConfigRagManagedDbConfigScaled {
		if v != nil {
			return *v
		}
		var ret AiRagEngineConfigRagManagedDbConfigScaled
		return ret
	}).(AiRagEngineConfigRagManagedDbConfigScaledOutput)
}

type AiRagEngineConfigRagManagedDbConfigUnprovisioned struct {
}

// AiRagEngineConfigRagManagedDbConfigUnprovisionedInput is an input type that accepts AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs and AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput values.
// You can construct a concrete instance of `AiRagEngineConfigRagManagedDbConfigUnprovisionedInput` via:
//
//	AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs{...}
type AiRagEngineConfigRagManagedDbConfigUnprovisionedInput interface {
	pulumi.Input

	ToAiRagEngineConfigRagManagedDbConfigUnprovisionedOutput() AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput
	ToAiRagEngineConfigRagManagedDbConfigUnprovisionedOutputWithContext(context.Context) AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput
}

type AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs struct {
}

func (AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigUnprovisioned)(nil)).Elem()
}

func (i AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs) ToAiRagEngineConfigRagManagedDbConfigUnprovisionedOutput() AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput {
	return i.ToAiRagEngineConfigRagManagedDbConfigUnprovisionedOutputWithContext(context.Background())
}

func (i AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs) ToAiRagEngineConfigRagManagedDbConfigUnprovisionedOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput)
}

func (i AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs) ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput() AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput {
	return i.ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutputWithContext(context.Background())
}

func (i AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs) ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput).ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutputWithContext(ctx)
}

// AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrInput is an input type that accepts AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs, AiRagEngineConfigRagManagedDbConfigUnprovisionedPtr and AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput values.
// You can construct a concrete instance of `AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrInput` via:
//
//	        AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs{...}
//
//	or:
//
//	        nil
type AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrInput interface {
	pulumi.Input

	ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput() AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput
	ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutputWithContext(context.Context) AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput
}

type aiRagEngineConfigRagManagedDbConfigUnprovisionedPtrType AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs

func AiRagEngineConfigRagManagedDbConfigUnprovisionedPtr(v *AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs) AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrInput {
	return (*aiRagEngineConfigRagManagedDbConfigUnprovisionedPtrType)(v)
}

func (*aiRagEngineConfigRagManagedDbConfigUnprovisionedPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiRagEngineConfigRagManagedDbConfigUnprovisioned)(nil)).Elem()
}

func (i *aiRagEngineConfigRagManagedDbConfigUnprovisionedPtrType) ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput() AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput {
	return i.ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutputWithContext(context.Background())
}

func (i *aiRagEngineConfigRagManagedDbConfigUnprovisionedPtrType) ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput)
}

type AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput struct{ *pulumi.OutputState }

func (AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigUnprovisioned)(nil)).Elem()
}

func (o AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput) ToAiRagEngineConfigRagManagedDbConfigUnprovisionedOutput() AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput) ToAiRagEngineConfigRagManagedDbConfigUnprovisionedOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput) ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput() AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput {
	return o.ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutputWithContext(context.Background())
}

func (o AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput) ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiRagEngineConfigRagManagedDbConfigUnprovisioned) *AiRagEngineConfigRagManagedDbConfigUnprovisioned {
		return &v
	}).(AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput)
}

type AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput struct{ *pulumi.OutputState }

func (AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiRagEngineConfigRagManagedDbConfigUnprovisioned)(nil)).Elem()
}

func (o AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput) ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput() AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput) ToAiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutputWithContext(ctx context.Context) AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput {
	return o
}

func (o AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput) Elem() AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput {
	return o.ApplyT(func(v *AiRagEngineConfigRagManagedDbConfigUnprovisioned) AiRagEngineConfigRagManagedDbConfigUnprovisioned {
		if v != nil {
			return *v
		}
		var ret AiRagEngineConfigRagManagedDbConfigUnprovisioned
		return ret
	}).(AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput)
}

type AiTensorboardEncryptionSpec struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
	// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
	KmsKeyName string `pulumi:"kmsKeyName"`
}

// AiTensorboardEncryptionSpecInput is an input type that accepts AiTensorboardEncryptionSpecArgs and AiTensorboardEncryptionSpecOutput values.
// You can construct a concrete instance of `AiTensorboardEncryptionSpecInput` via:
//
//	AiTensorboardEncryptionSpecArgs{...}
type AiTensorboardEncryptionSpecInput interface {
	pulumi.Input

	ToAiTensorboardEncryptionSpecOutput() AiTensorboardEncryptionSpecOutput
	ToAiTensorboardEncryptionSpecOutputWithContext(context.Context) AiTensorboardEncryptionSpecOutput
}

type AiTensorboardEncryptionSpecArgs struct {
	// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
	// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
	KmsKeyName pulumi.StringInput `pulumi:"kmsKeyName"`
}

func (AiTensorboardEncryptionSpecArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AiTensorboardEncryptionSpec)(nil)).Elem()
}

func (i AiTensorboardEncryptionSpecArgs) ToAiTensorboardEncryptionSpecOutput() AiTensorboardEncryptionSpecOutput {
	return i.ToAiTensorboardEncryptionSpecOutputWithContext(context.Background())
}

func (i AiTensorboardEncryptionSpecArgs) ToAiTensorboardEncryptionSpecOutputWithContext(ctx context.Context) AiTensorboardEncryptionSpecOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiTensorboardEncryptionSpecOutput)
}

func (i AiTensorboardEncryptionSpecArgs) ToAiTensorboardEncryptionSpecPtrOutput() AiTensorboardEncryptionSpecPtrOutput {
	return i.ToAiTensorboardEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i AiTensorboardEncryptionSpecArgs) ToAiTensorboardEncryptionSpecPtrOutputWithContext(ctx context.Context) AiTensorboardEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiTensorboardEncryptionSpecOutput).ToAiTensorboardEncryptionSpecPtrOutputWithContext(ctx)
}

// AiTensorboardEncryptionSpecPtrInput is an input type that accepts AiTensorboardEncryptionSpecArgs, AiTensorboardEncryptionSpecPtr and AiTensorboardEncryptionSpecPtrOutput values.
// You can construct a concrete instance of `AiTensorboardEncryptionSpecPtrInput` via:
//
//	        AiTensorboardEncryptionSpecArgs{...}
//
//	or:
//
//	        nil
type AiTensorboardEncryptionSpecPtrInput interface {
	pulumi.Input

	ToAiTensorboardEncryptionSpecPtrOutput() AiTensorboardEncryptionSpecPtrOutput
	ToAiTensorboardEncryptionSpecPtrOutputWithContext(context.Context) AiTensorboardEncryptionSpecPtrOutput
}

type aiTensorboardEncryptionSpecPtrType AiTensorboardEncryptionSpecArgs

func AiTensorboardEncryptionSpecPtr(v *AiTensorboardEncryptionSpecArgs) AiTensorboardEncryptionSpecPtrInput {
	return (*aiTensorboardEncryptionSpecPtrType)(v)
}

func (*aiTensorboardEncryptionSpecPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AiTensorboardEncryptionSpec)(nil)).Elem()
}

func (i *aiTensorboardEncryptionSpecPtrType) ToAiTensorboardEncryptionSpecPtrOutput() AiTensorboardEncryptionSpecPtrOutput {
	return i.ToAiTensorboardEncryptionSpecPtrOutputWithContext(context.Background())
}

func (i *aiTensorboardEncryptionSpecPtrType) ToAiTensorboardEncryptionSpecPtrOutputWithContext(ctx context.Context) AiTensorboardEncryptionSpecPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiTensorboardEncryptionSpecPtrOutput)
}

type AiTensorboardEncryptionSpecOutput struct{ *pulumi.OutputState }

func (AiTensorboardEncryptionSpecOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AiTensorboardEncryptionSpec)(nil)).Elem()
}

func (o AiTensorboardEncryptionSpecOutput) ToAiTensorboardEncryptionSpecOutput() AiTensorboardEncryptionSpecOutput {
	return o
}

func (o AiTensorboardEncryptionSpecOutput) ToAiTensorboardEncryptionSpecOutputWithContext(ctx context.Context) AiTensorboardEncryptionSpecOutput {
	return o
}

func (o AiTensorboardEncryptionSpecOutput) ToAiTensorboardEncryptionSpecPtrOutput() AiTensorboardEncryptionSpecPtrOutput {
	return o.ToAiTensorboardEncryptionSpecPtrOutputWithContext(context.Background())
}

func (o AiTensorboardEncryptionSpecOutput) ToAiTensorboardEncryptionSpecPtrOutputWithContext(ctx context.Context) AiTensorboardEncryptionSpecPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v AiTensorboardEncryptionSpec) *AiTensorboardEncryptionSpec {
		return &v
	}).(AiTensorboardEncryptionSpecPtrOutput)
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
func (o AiTensorboardEncryptionSpecOutput) KmsKeyName() pulumi.StringOutput {
	return o.ApplyT(func(v AiTensorboardEncryptionSpec) string { return v.KmsKeyName }).(pulumi.StringOutput)
}

type AiTensorboardEncryptionSpecPtrOutput struct{ *pulumi.OutputState }

func (AiTensorboardEncryptionSpecPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiTensorboardEncryptionSpec)(nil)).Elem()
}

func (o AiTensorboardEncryptionSpecPtrOutput) ToAiTensorboardEncryptionSpecPtrOutput() AiTensorboardEncryptionSpecPtrOutput {
	return o
}

func (o AiTensorboardEncryptionSpecPtrOutput) ToAiTensorboardEncryptionSpecPtrOutputWithContext(ctx context.Context) AiTensorboardEncryptionSpecPtrOutput {
	return o
}

func (o AiTensorboardEncryptionSpecPtrOutput) Elem() AiTensorboardEncryptionSpecOutput {
	return o.ApplyT(func(v *AiTensorboardEncryptionSpec) AiTensorboardEncryptionSpec {
		if v != nil {
			return *v
		}
		var ret AiTensorboardEncryptionSpec
		return ret
	}).(AiTensorboardEncryptionSpecOutput)
}

// The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
// Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
func (o AiTensorboardEncryptionSpecPtrOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiTensorboardEncryptionSpec) *string {
		if v == nil {
			return nil
		}
		return &v.KmsKeyName
	}).(pulumi.StringPtrOutput)
}

type GetAiIndexDeployedIndex struct {
	// The ID of the DeployedIndex in the above IndexEndpoint.
	DeployedIndexId string `pulumi:"deployedIndexId"`
	// A resource name of the IndexEndpoint.
	IndexEndpoint string `pulumi:"indexEndpoint"`
}

// GetAiIndexDeployedIndexInput is an input type that accepts GetAiIndexDeployedIndexArgs and GetAiIndexDeployedIndexOutput values.
// You can construct a concrete instance of `GetAiIndexDeployedIndexInput` via:
//
//	GetAiIndexDeployedIndexArgs{...}
type GetAiIndexDeployedIndexInput interface {
	pulumi.Input

	ToGetAiIndexDeployedIndexOutput() GetAiIndexDeployedIndexOutput
	ToGetAiIndexDeployedIndexOutputWithContext(context.Context) GetAiIndexDeployedIndexOutput
}

type GetAiIndexDeployedIndexArgs struct {
	// The ID of the DeployedIndex in the above IndexEndpoint.
	DeployedIndexId pulumi.StringInput `pulumi:"deployedIndexId"`
	// A resource name of the IndexEndpoint.
	IndexEndpoint pulumi.StringInput `pulumi:"indexEndpoint"`
}

func (GetAiIndexDeployedIndexArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexDeployedIndex)(nil)).Elem()
}

func (i GetAiIndexDeployedIndexArgs) ToGetAiIndexDeployedIndexOutput() GetAiIndexDeployedIndexOutput {
	return i.ToGetAiIndexDeployedIndexOutputWithContext(context.Background())
}

func (i GetAiIndexDeployedIndexArgs) ToGetAiIndexDeployedIndexOutputWithContext(ctx context.Context) GetAiIndexDeployedIndexOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexDeployedIndexOutput)
}

// GetAiIndexDeployedIndexArrayInput is an input type that accepts GetAiIndexDeployedIndexArray and GetAiIndexDeployedIndexArrayOutput values.
// You can construct a concrete instance of `GetAiIndexDeployedIndexArrayInput` via:
//
//	GetAiIndexDeployedIndexArray{ GetAiIndexDeployedIndexArgs{...} }
type GetAiIndexDeployedIndexArrayInput interface {
	pulumi.Input

	ToGetAiIndexDeployedIndexArrayOutput() GetAiIndexDeployedIndexArrayOutput
	ToGetAiIndexDeployedIndexArrayOutputWithContext(context.Context) GetAiIndexDeployedIndexArrayOutput
}

type GetAiIndexDeployedIndexArray []GetAiIndexDeployedIndexInput

func (GetAiIndexDeployedIndexArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexDeployedIndex)(nil)).Elem()
}

func (i GetAiIndexDeployedIndexArray) ToGetAiIndexDeployedIndexArrayOutput() GetAiIndexDeployedIndexArrayOutput {
	return i.ToGetAiIndexDeployedIndexArrayOutputWithContext(context.Background())
}

func (i GetAiIndexDeployedIndexArray) ToGetAiIndexDeployedIndexArrayOutputWithContext(ctx context.Context) GetAiIndexDeployedIndexArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexDeployedIndexArrayOutput)
}

type GetAiIndexDeployedIndexOutput struct{ *pulumi.OutputState }

func (GetAiIndexDeployedIndexOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexDeployedIndex)(nil)).Elem()
}

func (o GetAiIndexDeployedIndexOutput) ToGetAiIndexDeployedIndexOutput() GetAiIndexDeployedIndexOutput {
	return o
}

func (o GetAiIndexDeployedIndexOutput) ToGetAiIndexDeployedIndexOutputWithContext(ctx context.Context) GetAiIndexDeployedIndexOutput {
	return o
}

// The ID of the DeployedIndex in the above IndexEndpoint.
func (o GetAiIndexDeployedIndexOutput) DeployedIndexId() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexDeployedIndex) string { return v.DeployedIndexId }).(pulumi.StringOutput)
}

// A resource name of the IndexEndpoint.
func (o GetAiIndexDeployedIndexOutput) IndexEndpoint() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexDeployedIndex) string { return v.IndexEndpoint }).(pulumi.StringOutput)
}

type GetAiIndexDeployedIndexArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexDeployedIndexArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexDeployedIndex)(nil)).Elem()
}

func (o GetAiIndexDeployedIndexArrayOutput) ToGetAiIndexDeployedIndexArrayOutput() GetAiIndexDeployedIndexArrayOutput {
	return o
}

func (o GetAiIndexDeployedIndexArrayOutput) ToGetAiIndexDeployedIndexArrayOutputWithContext(ctx context.Context) GetAiIndexDeployedIndexArrayOutput {
	return o
}

func (o GetAiIndexDeployedIndexArrayOutput) Index(i pulumi.IntInput) GetAiIndexDeployedIndexOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexDeployedIndex {
		return vs[0].([]GetAiIndexDeployedIndex)[vs[1].(int)]
	}).(GetAiIndexDeployedIndexOutput)
}

type GetAiIndexIndexStat struct {
	// The number of shards in the Index.
	ShardsCount int `pulumi:"shardsCount"`
	// The number of vectors in the Index.
	VectorsCount string `pulumi:"vectorsCount"`
}

// GetAiIndexIndexStatInput is an input type that accepts GetAiIndexIndexStatArgs and GetAiIndexIndexStatOutput values.
// You can construct a concrete instance of `GetAiIndexIndexStatInput` via:
//
//	GetAiIndexIndexStatArgs{...}
type GetAiIndexIndexStatInput interface {
	pulumi.Input

	ToGetAiIndexIndexStatOutput() GetAiIndexIndexStatOutput
	ToGetAiIndexIndexStatOutputWithContext(context.Context) GetAiIndexIndexStatOutput
}

type GetAiIndexIndexStatArgs struct {
	// The number of shards in the Index.
	ShardsCount pulumi.IntInput `pulumi:"shardsCount"`
	// The number of vectors in the Index.
	VectorsCount pulumi.StringInput `pulumi:"vectorsCount"`
}

func (GetAiIndexIndexStatArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexIndexStat)(nil)).Elem()
}

func (i GetAiIndexIndexStatArgs) ToGetAiIndexIndexStatOutput() GetAiIndexIndexStatOutput {
	return i.ToGetAiIndexIndexStatOutputWithContext(context.Background())
}

func (i GetAiIndexIndexStatArgs) ToGetAiIndexIndexStatOutputWithContext(ctx context.Context) GetAiIndexIndexStatOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexIndexStatOutput)
}

// GetAiIndexIndexStatArrayInput is an input type that accepts GetAiIndexIndexStatArray and GetAiIndexIndexStatArrayOutput values.
// You can construct a concrete instance of `GetAiIndexIndexStatArrayInput` via:
//
//	GetAiIndexIndexStatArray{ GetAiIndexIndexStatArgs{...} }
type GetAiIndexIndexStatArrayInput interface {
	pulumi.Input

	ToGetAiIndexIndexStatArrayOutput() GetAiIndexIndexStatArrayOutput
	ToGetAiIndexIndexStatArrayOutputWithContext(context.Context) GetAiIndexIndexStatArrayOutput
}

type GetAiIndexIndexStatArray []GetAiIndexIndexStatInput

func (GetAiIndexIndexStatArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexIndexStat)(nil)).Elem()
}

func (i GetAiIndexIndexStatArray) ToGetAiIndexIndexStatArrayOutput() GetAiIndexIndexStatArrayOutput {
	return i.ToGetAiIndexIndexStatArrayOutputWithContext(context.Background())
}

func (i GetAiIndexIndexStatArray) ToGetAiIndexIndexStatArrayOutputWithContext(ctx context.Context) GetAiIndexIndexStatArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexIndexStatArrayOutput)
}

type GetAiIndexIndexStatOutput struct{ *pulumi.OutputState }

func (GetAiIndexIndexStatOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexIndexStat)(nil)).Elem()
}

func (o GetAiIndexIndexStatOutput) ToGetAiIndexIndexStatOutput() GetAiIndexIndexStatOutput {
	return o
}

func (o GetAiIndexIndexStatOutput) ToGetAiIndexIndexStatOutputWithContext(ctx context.Context) GetAiIndexIndexStatOutput {
	return o
}

// The number of shards in the Index.
func (o GetAiIndexIndexStatOutput) ShardsCount() pulumi.IntOutput {
	return o.ApplyT(func(v GetAiIndexIndexStat) int { return v.ShardsCount }).(pulumi.IntOutput)
}

// The number of vectors in the Index.
func (o GetAiIndexIndexStatOutput) VectorsCount() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexIndexStat) string { return v.VectorsCount }).(pulumi.StringOutput)
}

type GetAiIndexIndexStatArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexIndexStatArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexIndexStat)(nil)).Elem()
}

func (o GetAiIndexIndexStatArrayOutput) ToGetAiIndexIndexStatArrayOutput() GetAiIndexIndexStatArrayOutput {
	return o
}

func (o GetAiIndexIndexStatArrayOutput) ToGetAiIndexIndexStatArrayOutputWithContext(ctx context.Context) GetAiIndexIndexStatArrayOutput {
	return o
}

func (o GetAiIndexIndexStatArrayOutput) Index(i pulumi.IntInput) GetAiIndexIndexStatOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexIndexStat {
		return vs[0].([]GetAiIndexIndexStat)[vs[1].(int)]
	}).(GetAiIndexIndexStatOutput)
}

type GetAiIndexMetadata struct {
	// The configuration of the Matching Engine Index.
	Configs []GetAiIndexMetadataConfig `pulumi:"configs"`
	// Allows inserting, updating  or deleting the contents of the Matching Engine Index.
	// The string must be a valid Cloud Storage directory path. If this
	// field is set when calling IndexService.UpdateIndex, then no other
	// Index field can be also updated as part of the same call.
	// The expected structure and format of the files this URI points to is
	// described at https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#input-data-format
	ContentsDeltaUri string `pulumi:"contentsDeltaUri"`
	// If this field is set together with contentsDeltaUri when calling IndexService.UpdateIndex,
	// then existing content of the Index will be replaced by the data from the contentsDeltaUri.
	IsCompleteOverwrite bool `pulumi:"isCompleteOverwrite"`
}

// GetAiIndexMetadataInput is an input type that accepts GetAiIndexMetadataArgs and GetAiIndexMetadataOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataInput` via:
//
//	GetAiIndexMetadataArgs{...}
type GetAiIndexMetadataInput interface {
	pulumi.Input

	ToGetAiIndexMetadataOutput() GetAiIndexMetadataOutput
	ToGetAiIndexMetadataOutputWithContext(context.Context) GetAiIndexMetadataOutput
}

type GetAiIndexMetadataArgs struct {
	// The configuration of the Matching Engine Index.
	Configs GetAiIndexMetadataConfigArrayInput `pulumi:"configs"`
	// Allows inserting, updating  or deleting the contents of the Matching Engine Index.
	// The string must be a valid Cloud Storage directory path. If this
	// field is set when calling IndexService.UpdateIndex, then no other
	// Index field can be also updated as part of the same call.
	// The expected structure and format of the files this URI points to is
	// described at https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#input-data-format
	ContentsDeltaUri pulumi.StringInput `pulumi:"contentsDeltaUri"`
	// If this field is set together with contentsDeltaUri when calling IndexService.UpdateIndex,
	// then existing content of the Index will be replaced by the data from the contentsDeltaUri.
	IsCompleteOverwrite pulumi.BoolInput `pulumi:"isCompleteOverwrite"`
}

func (GetAiIndexMetadataArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadata)(nil)).Elem()
}

func (i GetAiIndexMetadataArgs) ToGetAiIndexMetadataOutput() GetAiIndexMetadataOutput {
	return i.ToGetAiIndexMetadataOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataArgs) ToGetAiIndexMetadataOutputWithContext(ctx context.Context) GetAiIndexMetadataOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataOutput)
}

// GetAiIndexMetadataArrayInput is an input type that accepts GetAiIndexMetadataArray and GetAiIndexMetadataArrayOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataArrayInput` via:
//
//	GetAiIndexMetadataArray{ GetAiIndexMetadataArgs{...} }
type GetAiIndexMetadataArrayInput interface {
	pulumi.Input

	ToGetAiIndexMetadataArrayOutput() GetAiIndexMetadataArrayOutput
	ToGetAiIndexMetadataArrayOutputWithContext(context.Context) GetAiIndexMetadataArrayOutput
}

type GetAiIndexMetadataArray []GetAiIndexMetadataInput

func (GetAiIndexMetadataArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadata)(nil)).Elem()
}

func (i GetAiIndexMetadataArray) ToGetAiIndexMetadataArrayOutput() GetAiIndexMetadataArrayOutput {
	return i.ToGetAiIndexMetadataArrayOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataArray) ToGetAiIndexMetadataArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataArrayOutput)
}

type GetAiIndexMetadataOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadata)(nil)).Elem()
}

func (o GetAiIndexMetadataOutput) ToGetAiIndexMetadataOutput() GetAiIndexMetadataOutput {
	return o
}

func (o GetAiIndexMetadataOutput) ToGetAiIndexMetadataOutputWithContext(ctx context.Context) GetAiIndexMetadataOutput {
	return o
}

// The configuration of the Matching Engine Index.
func (o GetAiIndexMetadataOutput) Configs() GetAiIndexMetadataConfigArrayOutput {
	return o.ApplyT(func(v GetAiIndexMetadata) []GetAiIndexMetadataConfig { return v.Configs }).(GetAiIndexMetadataConfigArrayOutput)
}

// Allows inserting, updating  or deleting the contents of the Matching Engine Index.
// The string must be a valid Cloud Storage directory path. If this
// field is set when calling IndexService.UpdateIndex, then no other
// Index field can be also updated as part of the same call.
// The expected structure and format of the files this URI points to is
// described at https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#input-data-format
func (o GetAiIndexMetadataOutput) ContentsDeltaUri() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexMetadata) string { return v.ContentsDeltaUri }).(pulumi.StringOutput)
}

// If this field is set together with contentsDeltaUri when calling IndexService.UpdateIndex,
// then existing content of the Index will be replaced by the data from the contentsDeltaUri.
func (o GetAiIndexMetadataOutput) IsCompleteOverwrite() pulumi.BoolOutput {
	return o.ApplyT(func(v GetAiIndexMetadata) bool { return v.IsCompleteOverwrite }).(pulumi.BoolOutput)
}

type GetAiIndexMetadataArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadata)(nil)).Elem()
}

func (o GetAiIndexMetadataArrayOutput) ToGetAiIndexMetadataArrayOutput() GetAiIndexMetadataArrayOutput {
	return o
}

func (o GetAiIndexMetadataArrayOutput) ToGetAiIndexMetadataArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataArrayOutput {
	return o
}

func (o GetAiIndexMetadataArrayOutput) Index(i pulumi.IntInput) GetAiIndexMetadataOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexMetadata {
		return vs[0].([]GetAiIndexMetadata)[vs[1].(int)]
	}).(GetAiIndexMetadataOutput)
}

type GetAiIndexMetadataConfig struct {
	// The configuration with regard to the algorithms used for efficient search. This field may be required based on your configuration.
	AlgorithmConfigs []GetAiIndexMetadataConfigAlgorithmConfig `pulumi:"algorithmConfigs"`
	// The default number of neighbors to find via approximate search before exact reordering is
	// performed. Exact reordering is a procedure where results returned by an
	// approximate search algorithm are reordered via a more expensive distance computation.
	// Required if tree-AH algorithm is used.
	ApproximateNeighborsCount int `pulumi:"approximateNeighborsCount"`
	// The number of dimensions of the input vectors.
	Dimensions int `pulumi:"dimensions"`
	// The distance measure used in nearest neighbor search. The value must be one of the followings:
	// * SQUARED_L2_DISTANCE: Euclidean (L_2) Distance
	// * L1_DISTANCE: Manhattan (L_1) Distance
	// * COSINE_DISTANCE: Cosine Distance. Defined as 1 - cosine similarity.
	// * DOT_PRODUCT_DISTANCE: Dot Product Distance. Defined as a negative of the dot product
	DistanceMeasureType string `pulumi:"distanceMeasureType"`
	// Type of normalization to be carried out on each vector. The value must be one of the followings:
	// * UNIT_L2_NORM: Unit L2 normalization type
	// * NONE: No normalization type is specified.
	FeatureNormType string `pulumi:"featureNormType"`
	// Index data is split into equal parts to be processed. These are called "shards".
	// The shard size must be specified when creating an index. The value must be one of the followings:
	// * SHARD_SIZE_SMALL: Small (2GB)
	// * SHARD_SIZE_MEDIUM: Medium (20GB)
	// * SHARD_SIZE_LARGE: Large (50GB)
	ShardSize string `pulumi:"shardSize"`
}

// GetAiIndexMetadataConfigInput is an input type that accepts GetAiIndexMetadataConfigArgs and GetAiIndexMetadataConfigOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigInput` via:
//
//	GetAiIndexMetadataConfigArgs{...}
type GetAiIndexMetadataConfigInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigOutput() GetAiIndexMetadataConfigOutput
	ToGetAiIndexMetadataConfigOutputWithContext(context.Context) GetAiIndexMetadataConfigOutput
}

type GetAiIndexMetadataConfigArgs struct {
	// The configuration with regard to the algorithms used for efficient search. This field may be required based on your configuration.
	AlgorithmConfigs GetAiIndexMetadataConfigAlgorithmConfigArrayInput `pulumi:"algorithmConfigs"`
	// The default number of neighbors to find via approximate search before exact reordering is
	// performed. Exact reordering is a procedure where results returned by an
	// approximate search algorithm are reordered via a more expensive distance computation.
	// Required if tree-AH algorithm is used.
	ApproximateNeighborsCount pulumi.IntInput `pulumi:"approximateNeighborsCount"`
	// The number of dimensions of the input vectors.
	Dimensions pulumi.IntInput `pulumi:"dimensions"`
	// The distance measure used in nearest neighbor search. The value must be one of the followings:
	// * SQUARED_L2_DISTANCE: Euclidean (L_2) Distance
	// * L1_DISTANCE: Manhattan (L_1) Distance
	// * COSINE_DISTANCE: Cosine Distance. Defined as 1 - cosine similarity.
	// * DOT_PRODUCT_DISTANCE: Dot Product Distance. Defined as a negative of the dot product
	DistanceMeasureType pulumi.StringInput `pulumi:"distanceMeasureType"`
	// Type of normalization to be carried out on each vector. The value must be one of the followings:
	// * UNIT_L2_NORM: Unit L2 normalization type
	// * NONE: No normalization type is specified.
	FeatureNormType pulumi.StringInput `pulumi:"featureNormType"`
	// Index data is split into equal parts to be processed. These are called "shards".
	// The shard size must be specified when creating an index. The value must be one of the followings:
	// * SHARD_SIZE_SMALL: Small (2GB)
	// * SHARD_SIZE_MEDIUM: Medium (20GB)
	// * SHARD_SIZE_LARGE: Large (50GB)
	ShardSize pulumi.StringInput `pulumi:"shardSize"`
}

func (GetAiIndexMetadataConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigArgs) ToGetAiIndexMetadataConfigOutput() GetAiIndexMetadataConfigOutput {
	return i.ToGetAiIndexMetadataConfigOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigArgs) ToGetAiIndexMetadataConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigOutput)
}

// GetAiIndexMetadataConfigArrayInput is an input type that accepts GetAiIndexMetadataConfigArray and GetAiIndexMetadataConfigArrayOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigArrayInput` via:
//
//	GetAiIndexMetadataConfigArray{ GetAiIndexMetadataConfigArgs{...} }
type GetAiIndexMetadataConfigArrayInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigArrayOutput() GetAiIndexMetadataConfigArrayOutput
	ToGetAiIndexMetadataConfigArrayOutputWithContext(context.Context) GetAiIndexMetadataConfigArrayOutput
}

type GetAiIndexMetadataConfigArray []GetAiIndexMetadataConfigInput

func (GetAiIndexMetadataConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigArray) ToGetAiIndexMetadataConfigArrayOutput() GetAiIndexMetadataConfigArrayOutput {
	return i.ToGetAiIndexMetadataConfigArrayOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigArray) ToGetAiIndexMetadataConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigArrayOutput)
}

type GetAiIndexMetadataConfigOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigOutput) ToGetAiIndexMetadataConfigOutput() GetAiIndexMetadataConfigOutput {
	return o
}

func (o GetAiIndexMetadataConfigOutput) ToGetAiIndexMetadataConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigOutput {
	return o
}

// The configuration with regard to the algorithms used for efficient search. This field may be required based on your configuration.
func (o GetAiIndexMetadataConfigOutput) AlgorithmConfigs() GetAiIndexMetadataConfigAlgorithmConfigArrayOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfig) []GetAiIndexMetadataConfigAlgorithmConfig { return v.AlgorithmConfigs }).(GetAiIndexMetadataConfigAlgorithmConfigArrayOutput)
}

// The default number of neighbors to find via approximate search before exact reordering is
// performed. Exact reordering is a procedure where results returned by an
// approximate search algorithm are reordered via a more expensive distance computation.
// Required if tree-AH algorithm is used.
func (o GetAiIndexMetadataConfigOutput) ApproximateNeighborsCount() pulumi.IntOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfig) int { return v.ApproximateNeighborsCount }).(pulumi.IntOutput)
}

// The number of dimensions of the input vectors.
func (o GetAiIndexMetadataConfigOutput) Dimensions() pulumi.IntOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfig) int { return v.Dimensions }).(pulumi.IntOutput)
}

// The distance measure used in nearest neighbor search. The value must be one of the followings:
// * SQUARED_L2_DISTANCE: Euclidean (L_2) Distance
// * L1_DISTANCE: Manhattan (L_1) Distance
// * COSINE_DISTANCE: Cosine Distance. Defined as 1 - cosine similarity.
// * DOT_PRODUCT_DISTANCE: Dot Product Distance. Defined as a negative of the dot product
func (o GetAiIndexMetadataConfigOutput) DistanceMeasureType() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfig) string { return v.DistanceMeasureType }).(pulumi.StringOutput)
}

// Type of normalization to be carried out on each vector. The value must be one of the followings:
// * UNIT_L2_NORM: Unit L2 normalization type
// * NONE: No normalization type is specified.
func (o GetAiIndexMetadataConfigOutput) FeatureNormType() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfig) string { return v.FeatureNormType }).(pulumi.StringOutput)
}

// Index data is split into equal parts to be processed. These are called "shards".
// The shard size must be specified when creating an index. The value must be one of the followings:
// * SHARD_SIZE_SMALL: Small (2GB)
// * SHARD_SIZE_MEDIUM: Medium (20GB)
// * SHARD_SIZE_LARGE: Large (50GB)
func (o GetAiIndexMetadataConfigOutput) ShardSize() pulumi.StringOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfig) string { return v.ShardSize }).(pulumi.StringOutput)
}

type GetAiIndexMetadataConfigArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigArrayOutput) ToGetAiIndexMetadataConfigArrayOutput() GetAiIndexMetadataConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigArrayOutput) ToGetAiIndexMetadataConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigArrayOutput) Index(i pulumi.IntInput) GetAiIndexMetadataConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexMetadataConfig {
		return vs[0].([]GetAiIndexMetadataConfig)[vs[1].(int)]
	}).(GetAiIndexMetadataConfigOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfig struct {
	// Configuration options for using brute force search, which simply implements the
	// standard linear search in the database for each query.
	BruteForceConfigs []GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig `pulumi:"bruteForceConfigs"`
	// Configuration options for using the tree-AH algorithm (Shallow tree + Asymmetric Hashing).
	// Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
	TreeAhConfigs []GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig `pulumi:"treeAhConfigs"`
}

// GetAiIndexMetadataConfigAlgorithmConfigInput is an input type that accepts GetAiIndexMetadataConfigAlgorithmConfigArgs and GetAiIndexMetadataConfigAlgorithmConfigOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigAlgorithmConfigInput` via:
//
//	GetAiIndexMetadataConfigAlgorithmConfigArgs{...}
type GetAiIndexMetadataConfigAlgorithmConfigInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigAlgorithmConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigOutput
	ToGetAiIndexMetadataConfigAlgorithmConfigOutputWithContext(context.Context) GetAiIndexMetadataConfigAlgorithmConfigOutput
}

type GetAiIndexMetadataConfigAlgorithmConfigArgs struct {
	// Configuration options for using brute force search, which simply implements the
	// standard linear search in the database for each query.
	BruteForceConfigs GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayInput `pulumi:"bruteForceConfigs"`
	// Configuration options for using the tree-AH algorithm (Shallow tree + Asymmetric Hashing).
	// Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
	TreeAhConfigs GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayInput `pulumi:"treeAhConfigs"`
}

func (GetAiIndexMetadataConfigAlgorithmConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigAlgorithmConfigArgs) ToGetAiIndexMetadataConfigAlgorithmConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigOutput {
	return i.ToGetAiIndexMetadataConfigAlgorithmConfigOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigAlgorithmConfigArgs) ToGetAiIndexMetadataConfigAlgorithmConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigAlgorithmConfigOutput)
}

// GetAiIndexMetadataConfigAlgorithmConfigArrayInput is an input type that accepts GetAiIndexMetadataConfigAlgorithmConfigArray and GetAiIndexMetadataConfigAlgorithmConfigArrayOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigAlgorithmConfigArrayInput` via:
//
//	GetAiIndexMetadataConfigAlgorithmConfigArray{ GetAiIndexMetadataConfigAlgorithmConfigArgs{...} }
type GetAiIndexMetadataConfigAlgorithmConfigArrayInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigArrayOutput
	ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutputWithContext(context.Context) GetAiIndexMetadataConfigAlgorithmConfigArrayOutput
}

type GetAiIndexMetadataConfigAlgorithmConfigArray []GetAiIndexMetadataConfigAlgorithmConfigInput

func (GetAiIndexMetadataConfigAlgorithmConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigAlgorithmConfigArray) ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigArrayOutput {
	return i.ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigAlgorithmConfigArray) ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigAlgorithmConfigArrayOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigAlgorithmConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigAlgorithmConfigOutput) ToGetAiIndexMetadataConfigAlgorithmConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigOutput) ToGetAiIndexMetadataConfigAlgorithmConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigOutput {
	return o
}

// Configuration options for using brute force search, which simply implements the
// standard linear search in the database for each query.
func (o GetAiIndexMetadataConfigAlgorithmConfigOutput) BruteForceConfigs() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfigAlgorithmConfig) []GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig {
		return v.BruteForceConfigs
	}).(GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput)
}

// Configuration options for using the tree-AH algorithm (Shallow tree + Asymmetric Hashing).
// Please refer to this paper for more details: https://arxiv.org/abs/1908.10396
func (o GetAiIndexMetadataConfigAlgorithmConfigOutput) TreeAhConfigs() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfigAlgorithmConfig) []GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig {
		return v.TreeAhConfigs
	}).(GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigAlgorithmConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfigAlgorithmConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigAlgorithmConfigArrayOutput) ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigArrayOutput) ToGetAiIndexMetadataConfigAlgorithmConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigArrayOutput) Index(i pulumi.IntInput) GetAiIndexMetadataConfigAlgorithmConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexMetadataConfigAlgorithmConfig {
		return vs[0].([]GetAiIndexMetadataConfigAlgorithmConfig)[vs[1].(int)]
	}).(GetAiIndexMetadataConfigAlgorithmConfigOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig struct {
}

// GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput is an input type that accepts GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs and GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput` via:
//
//	GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{...}
type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput
	ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(context.Context) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput
}

type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs struct {
}

func (GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return i.ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput)
}

// GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayInput is an input type that accepts GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray and GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayInput` via:
//
//	GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray{ GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{...} }
type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput
	ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutputWithContext(context.Context) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput
}

type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray []GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput

func (GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput {
	return i.ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return o
}

type GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput) ToGetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput) Index(i pulumi.IntInput) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig {
		return vs[0].([]GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfig)[vs[1].(int)]
	}).(GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig struct {
	// Number of embeddings on each leaf node. The default value is 1000 if not set.
	LeafNodeEmbeddingCount int `pulumi:"leafNodeEmbeddingCount"`
	// The default percentage of leaf nodes that any query may be searched. Must be in
	// range 1-100, inclusive. The default value is 10 (means 10%) if not set.
	LeafNodesToSearchPercent int `pulumi:"leafNodesToSearchPercent"`
}

// GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput is an input type that accepts GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs and GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput` via:
//
//	GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{...}
type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput
	ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(context.Context) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput
}

type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs struct {
	// Number of embeddings on each leaf node. The default value is 1000 if not set.
	LeafNodeEmbeddingCount pulumi.IntInput `pulumi:"leafNodeEmbeddingCount"`
	// The default percentage of leaf nodes that any query may be searched. Must be in
	// range 1-100, inclusive. The default value is 10 (means 10%) if not set.
	LeafNodesToSearchPercent pulumi.IntInput `pulumi:"leafNodesToSearchPercent"`
}

func (GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return i.ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput)
}

// GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayInput is an input type that accepts GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray and GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput values.
// You can construct a concrete instance of `GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayInput` via:
//
//	GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray{ GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{...} }
type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayInput interface {
	pulumi.Input

	ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput
	ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutputWithContext(context.Context) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput
}

type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray []GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput

func (GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (i GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput {
	return i.ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutputWithContext(context.Background())
}

func (i GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return o
}

// Number of embeddings on each leaf node. The default value is 1000 if not set.
func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) LeafNodeEmbeddingCount() pulumi.IntOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig) int { return v.LeafNodeEmbeddingCount }).(pulumi.IntOutput)
}

// The default percentage of leaf nodes that any query may be searched. Must be in
// range 1-100, inclusive. The default value is 10 (means 10%) if not set.
func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput) LeafNodesToSearchPercent() pulumi.IntOutput {
	return o.ApplyT(func(v GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig) int { return v.LeafNodesToSearchPercent }).(pulumi.IntOutput)
}

type GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput struct{ *pulumi.OutputState }

func (GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig)(nil)).Elem()
}

func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput() GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput) ToGetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutputWithContext(ctx context.Context) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput {
	return o
}

func (o GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput) Index(i pulumi.IntInput) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig {
		return vs[0].([]GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfig)[vs[1].(int)]
	}).(GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*AiDatasetEncryptionSpecInput)(nil)).Elem(), AiDatasetEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiDatasetEncryptionSpecPtrInput)(nil)).Elem(), AiDatasetEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiDeploymentResourcePoolDedicatedResourcesInput)(nil)).Elem(), AiDeploymentResourcePoolDedicatedResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiDeploymentResourcePoolDedicatedResourcesPtrInput)(nil)).Elem(), AiDeploymentResourcePoolDedicatedResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecInput)(nil)).Elem(), AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayInput)(nil)).Elem(), AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiDeploymentResourcePoolDedicatedResourcesMachineSpecInput)(nil)).Elem(), AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrInput)(nil)).Elem(), AiDeploymentResourcePoolDedicatedResourcesMachineSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelInput)(nil)).Elem(), AiEndpointDeployedModelArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelArrayInput)(nil)).Elem(), AiEndpointDeployedModelArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelAutomaticResourceInput)(nil)).Elem(), AiEndpointDeployedModelAutomaticResourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelAutomaticResourceArrayInput)(nil)).Elem(), AiEndpointDeployedModelAutomaticResourceArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceInput)(nil)).Elem(), AiEndpointDeployedModelDedicatedResourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceArrayInput)(nil)).Elem(), AiEndpointDeployedModelDedicatedResourceArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecInput)(nil)).Elem(), AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayInput)(nil)).Elem(), AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceMachineSpecInput)(nil)).Elem(), AiEndpointDeployedModelDedicatedResourceMachineSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelDedicatedResourceMachineSpecArrayInput)(nil)).Elem(), AiEndpointDeployedModelDedicatedResourceMachineSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelPrivateEndpointInput)(nil)).Elem(), AiEndpointDeployedModelPrivateEndpointArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointDeployedModelPrivateEndpointArrayInput)(nil)).Elem(), AiEndpointDeployedModelPrivateEndpointArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointEncryptionSpecInput)(nil)).Elem(), AiEndpointEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointEncryptionSpecPtrInput)(nil)).Elem(), AiEndpointEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointIamBindingConditionInput)(nil)).Elem(), AiEndpointIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointIamBindingConditionPtrInput)(nil)).Elem(), AiEndpointIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointIamMemberConditionInput)(nil)).Elem(), AiEndpointIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointIamMemberConditionPtrInput)(nil)).Elem(), AiEndpointIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointPredictRequestResponseLoggingConfigInput)(nil)).Elem(), AiEndpointPredictRequestResponseLoggingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointPredictRequestResponseLoggingConfigPtrInput)(nil)).Elem(), AiEndpointPredictRequestResponseLoggingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationInput)(nil)).Elem(), AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrInput)(nil)).Elem(), AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointPrivateServiceConnectConfigInput)(nil)).Elem(), AiEndpointPrivateServiceConnectConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointPrivateServiceConnectConfigPtrInput)(nil)).Elem(), AiEndpointPrivateServiceConnectConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentDeployConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentDeployConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentEndpointConfigInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentEndpointConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentEndpointConfigPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentEndpointConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureGroupBigQueryInput)(nil)).Elem(), AiFeatureGroupBigQueryArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureGroupBigQueryPtrInput)(nil)).Elem(), AiFeatureGroupBigQueryArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureGroupBigQueryBigQuerySourceInput)(nil)).Elem(), AiFeatureGroupBigQueryBigQuerySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureGroupBigQueryBigQuerySourcePtrInput)(nil)).Elem(), AiFeatureGroupBigQueryBigQuerySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureGroupIamBindingConditionInput)(nil)).Elem(), AiFeatureGroupIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureGroupIamBindingConditionPtrInput)(nil)).Elem(), AiFeatureGroupIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureGroupIamMemberConditionInput)(nil)).Elem(), AiFeatureGroupIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureGroupIamMemberConditionPtrInput)(nil)).Elem(), AiFeatureGroupIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreBigtableInput)(nil)).Elem(), AiFeatureOnlineStoreBigtableArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreBigtablePtrInput)(nil)).Elem(), AiFeatureOnlineStoreBigtableArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreBigtableAutoScalingInput)(nil)).Elem(), AiFeatureOnlineStoreBigtableAutoScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreBigtableAutoScalingPtrInput)(nil)).Elem(), AiFeatureOnlineStoreBigtableAutoScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreDedicatedServingEndpointInput)(nil)).Elem(), AiFeatureOnlineStoreDedicatedServingEndpointArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreDedicatedServingEndpointPtrInput)(nil)).Elem(), AiFeatureOnlineStoreDedicatedServingEndpointArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigInput)(nil)).Elem(), AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrInput)(nil)).Elem(), AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreEmbeddingManagementInput)(nil)).Elem(), AiFeatureOnlineStoreEmbeddingManagementArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreEmbeddingManagementPtrInput)(nil)).Elem(), AiFeatureOnlineStoreEmbeddingManagementArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewBigQuerySourceInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewBigQuerySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewIamBindingConditionInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewIamMemberConditionInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewSyncConfigInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewSyncConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewSyncConfigPtrInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewSyncConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewVectorSearchConfigInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewVectorSearchConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrInput)(nil)).Elem(), AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreIamBindingConditionInput)(nil)).Elem(), AiFeatureOnlineStoreIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreIamBindingConditionPtrInput)(nil)).Elem(), AiFeatureOnlineStoreIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreIamMemberConditionInput)(nil)).Elem(), AiFeatureOnlineStoreIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreIamMemberConditionPtrInput)(nil)).Elem(), AiFeatureOnlineStoreIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreOptimizedInput)(nil)).Elem(), AiFeatureOnlineStoreOptimizedArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureOnlineStoreOptimizedPtrInput)(nil)).Elem(), AiFeatureOnlineStoreOptimizedArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEncryptionSpecInput)(nil)).Elem(), AiFeatureStoreEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEncryptionSpecPtrInput)(nil)).Elem(), AiFeatureStoreEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeIamBindingConditionInput)(nil)).Elem(), AiFeatureStoreEntityTypeIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeIamBindingConditionPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeIamMemberConditionInput)(nil)).Elem(), AiFeatureStoreEntityTypeIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeIamMemberConditionPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrInput)(nil)).Elem(), AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreIamBindingConditionInput)(nil)).Elem(), AiFeatureStoreIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreIamBindingConditionPtrInput)(nil)).Elem(), AiFeatureStoreIamBindingConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreIamMemberConditionInput)(nil)).Elem(), AiFeatureStoreIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreIamMemberConditionPtrInput)(nil)).Elem(), AiFeatureStoreIamMemberConditionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreOnlineServingConfigInput)(nil)).Elem(), AiFeatureStoreOnlineServingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreOnlineServingConfigPtrInput)(nil)).Elem(), AiFeatureStoreOnlineServingConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreOnlineServingConfigScalingInput)(nil)).Elem(), AiFeatureStoreOnlineServingConfigScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiFeatureStoreOnlineServingConfigScalingPtrInput)(nil)).Elem(), AiFeatureStoreOnlineServingConfigScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexDeployedIndexInput)(nil)).Elem(), AiIndexDeployedIndexArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexDeployedIndexArrayInput)(nil)).Elem(), AiIndexDeployedIndexArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexAutomaticResourcesInput)(nil)).Elem(), AiIndexEndpointDeployedIndexAutomaticResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexAutomaticResourcesPtrInput)(nil)).Elem(), AiIndexEndpointDeployedIndexAutomaticResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexDedicatedResourcesInput)(nil)).Elem(), AiIndexEndpointDeployedIndexDedicatedResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexDedicatedResourcesPtrInput)(nil)).Elem(), AiIndexEndpointDeployedIndexDedicatedResourcesArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecInput)(nil)).Elem(), AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrInput)(nil)).Elem(), AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexDeployedIndexAuthConfigInput)(nil)).Elem(), AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrInput)(nil)).Elem(), AiIndexEndpointDeployedIndexDeployedIndexAuthConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderInput)(nil)).Elem(), AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrInput)(nil)).Elem(), AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexPrivateEndpointInput)(nil)).Elem(), AiIndexEndpointDeployedIndexPrivateEndpointArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexPrivateEndpointArrayInput)(nil)).Elem(), AiIndexEndpointDeployedIndexPrivateEndpointArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointInput)(nil)).Elem(), AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayInput)(nil)).Elem(), AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointPrivateServiceConnectConfigInput)(nil)).Elem(), AiIndexEndpointPrivateServiceConnectConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexEndpointPrivateServiceConnectConfigPtrInput)(nil)).Elem(), AiIndexEndpointPrivateServiceConnectConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexIndexStatInput)(nil)).Elem(), AiIndexIndexStatArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexIndexStatArrayInput)(nil)).Elem(), AiIndexIndexStatArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataInput)(nil)).Elem(), AiIndexMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataPtrInput)(nil)).Elem(), AiIndexMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigInput)(nil)).Elem(), AiIndexMetadataConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigPtrInput)(nil)).Elem(), AiIndexMetadataConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigInput)(nil)).Elem(), AiIndexMetadataConfigAlgorithmConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigPtrInput)(nil)).Elem(), AiIndexMetadataConfigAlgorithmConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput)(nil)).Elem(), AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrInput)(nil)).Elem(), AiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput)(nil)).Elem(), AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrInput)(nil)).Elem(), AiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiMetadataStoreEncryptionSpecInput)(nil)).Elem(), AiMetadataStoreEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiMetadataStoreEncryptionSpecPtrInput)(nil)).Elem(), AiMetadataStoreEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiMetadataStoreStateTypeInput)(nil)).Elem(), AiMetadataStoreStateTypeArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiMetadataStoreStateTypeArrayInput)(nil)).Elem(), AiMetadataStoreStateTypeArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigInput)(nil)).Elem(), AiRagEngineConfigRagManagedDbConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigPtrInput)(nil)).Elem(), AiRagEngineConfigRagManagedDbConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigBasicInput)(nil)).Elem(), AiRagEngineConfigRagManagedDbConfigBasicArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigBasicPtrInput)(nil)).Elem(), AiRagEngineConfigRagManagedDbConfigBasicArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigScaledInput)(nil)).Elem(), AiRagEngineConfigRagManagedDbConfigScaledArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigScaledPtrInput)(nil)).Elem(), AiRagEngineConfigRagManagedDbConfigScaledArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigUnprovisionedInput)(nil)).Elem(), AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrInput)(nil)).Elem(), AiRagEngineConfigRagManagedDbConfigUnprovisionedArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiTensorboardEncryptionSpecInput)(nil)).Elem(), AiTensorboardEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiTensorboardEncryptionSpecPtrInput)(nil)).Elem(), AiTensorboardEncryptionSpecArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexDeployedIndexInput)(nil)).Elem(), GetAiIndexDeployedIndexArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexDeployedIndexArrayInput)(nil)).Elem(), GetAiIndexDeployedIndexArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexIndexStatInput)(nil)).Elem(), GetAiIndexIndexStatArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexIndexStatArrayInput)(nil)).Elem(), GetAiIndexIndexStatArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataInput)(nil)).Elem(), GetAiIndexMetadataArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataArrayInput)(nil)).Elem(), GetAiIndexMetadataArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigInput)(nil)).Elem(), GetAiIndexMetadataConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigArrayInput)(nil)).Elem(), GetAiIndexMetadataConfigArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigInput)(nil)).Elem(), GetAiIndexMetadataConfigAlgorithmConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigArrayInput)(nil)).Elem(), GetAiIndexMetadataConfigAlgorithmConfigArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigInput)(nil)).Elem(), GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayInput)(nil)).Elem(), GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigInput)(nil)).Elem(), GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayInput)(nil)).Elem(), GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArray{})
	pulumi.RegisterOutputType(AiDatasetEncryptionSpecOutput{})
	pulumi.RegisterOutputType(AiDatasetEncryptionSpecPtrOutput{})
	pulumi.RegisterOutputType(AiDeploymentResourcePoolDedicatedResourcesOutput{})
	pulumi.RegisterOutputType(AiDeploymentResourcePoolDedicatedResourcesPtrOutput{})
	pulumi.RegisterOutputType(AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecOutput{})
	pulumi.RegisterOutputType(AiDeploymentResourcePoolDedicatedResourcesAutoscalingMetricSpecArrayOutput{})
	pulumi.RegisterOutputType(AiDeploymentResourcePoolDedicatedResourcesMachineSpecOutput{})
	pulumi.RegisterOutputType(AiDeploymentResourcePoolDedicatedResourcesMachineSpecPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelAutomaticResourceOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelAutomaticResourceArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelDedicatedResourceOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelDedicatedResourceArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelDedicatedResourceAutoscalingMetricSpecArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelDedicatedResourceMachineSpecOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelDedicatedResourceMachineSpecArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelPrivateEndpointOutput{})
	pulumi.RegisterOutputType(AiEndpointDeployedModelPrivateEndpointArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointEncryptionSpecOutput{})
	pulumi.RegisterOutputType(AiEndpointEncryptionSpecPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointIamBindingConditionOutput{})
	pulumi.RegisterOutputType(AiEndpointIamBindingConditionPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointIamMemberConditionOutput{})
	pulumi.RegisterOutputType(AiEndpointIamMemberConditionPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointPredictRequestResponseLoggingConfigOutput{})
	pulumi.RegisterOutputType(AiEndpointPredictRequestResponseLoggingConfigPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationOutput{})
	pulumi.RegisterOutputType(AiEndpointPredictRequestResponseLoggingConfigBigqueryDestinationPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointPrivateServiceConnectConfigOutput{})
	pulumi.RegisterOutputType(AiEndpointPrivateServiceConnectConfigPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentDeployConfigOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesAutoscalingMetricSpecArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecReservationAffinityPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentEndpointConfigOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecEnvArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecGrpcPortArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbePtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeExecPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeGrpcPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeHttpGetHttpHeaderArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecHealthProbeTcpSocketPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbePtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeExecPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeGrpcPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeHttpGetHttpHeaderArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecLivenessProbeTcpSocketPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecPortArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbePtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeExecPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeGrpcPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetPtrOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeHttpGetHttpHeaderArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentModelConfigContainerSpecStartupProbeTcpSocketPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureGroupBigQueryOutput{})
	pulumi.RegisterOutputType(AiFeatureGroupBigQueryPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureGroupBigQueryBigQuerySourceOutput{})
	pulumi.RegisterOutputType(AiFeatureGroupBigQueryBigQuerySourcePtrOutput{})
	pulumi.RegisterOutputType(AiFeatureGroupIamBindingConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureGroupIamBindingConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureGroupIamMemberConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureGroupIamMemberConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreBigtableOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreBigtablePtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreBigtableAutoScalingOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreBigtableAutoScalingPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreDedicatedServingEndpointOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreDedicatedServingEndpointPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreDedicatedServingEndpointPrivateServiceConnectConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreEmbeddingManagementOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreEmbeddingManagementPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewBigQuerySourceOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewBigQuerySourcePtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourcePtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewFeatureRegistrySourceFeatureGroupArrayOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewIamBindingConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewIamBindingConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewIamMemberConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewIamMemberConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewSyncConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewSyncConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewVectorSearchConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewVectorSearchConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewVectorSearchConfigBruteForceConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreFeatureviewVectorSearchConfigTreeAhConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreIamBindingConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreIamBindingConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreIamMemberConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreIamMemberConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreOptimizedOutput{})
	pulumi.RegisterOutputType(AiFeatureOnlineStoreOptimizedPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEncryptionSpecOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEncryptionSpecPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeIamBindingConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeIamBindingConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeIamMemberConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeIamMemberConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigCategoricalThresholdConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigImportFeaturesAnalysisPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigNumericalThresholdConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreEntityTypeMonitoringConfigSnapshotAnalysisPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreIamBindingConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreIamBindingConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreIamMemberConditionOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreIamMemberConditionPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreOnlineServingConfigOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreOnlineServingConfigPtrOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreOnlineServingConfigScalingOutput{})
	pulumi.RegisterOutputType(AiFeatureStoreOnlineServingConfigScalingPtrOutput{})
	pulumi.RegisterOutputType(AiIndexDeployedIndexOutput{})
	pulumi.RegisterOutputType(AiIndexDeployedIndexArrayOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexAutomaticResourcesOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexAutomaticResourcesPtrOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexDedicatedResourcesOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexDedicatedResourcesPtrOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexDedicatedResourcesMachineSpecPtrOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigPtrOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexDeployedIndexAuthConfigAuthProviderPtrOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexPrivateEndpointOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexPrivateEndpointArrayOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointDeployedIndexPrivateEndpointPscAutomatedEndpointArrayOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointPrivateServiceConnectConfigOutput{})
	pulumi.RegisterOutputType(AiIndexEndpointPrivateServiceConnectConfigPtrOutput{})
	pulumi.RegisterOutputType(AiIndexIndexStatOutput{})
	pulumi.RegisterOutputType(AiIndexIndexStatArrayOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataPtrOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigPtrOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigAlgorithmConfigOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigAlgorithmConfigPtrOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigAlgorithmConfigBruteForceConfigPtrOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput{})
	pulumi.RegisterOutputType(AiIndexMetadataConfigAlgorithmConfigTreeAhConfigPtrOutput{})
	pulumi.RegisterOutputType(AiMetadataStoreEncryptionSpecOutput{})
	pulumi.RegisterOutputType(AiMetadataStoreEncryptionSpecPtrOutput{})
	pulumi.RegisterOutputType(AiMetadataStoreStateTypeOutput{})
	pulumi.RegisterOutputType(AiMetadataStoreStateTypeArrayOutput{})
	pulumi.RegisterOutputType(AiRagEngineConfigRagManagedDbConfigOutput{})
	pulumi.RegisterOutputType(AiRagEngineConfigRagManagedDbConfigPtrOutput{})
	pulumi.RegisterOutputType(AiRagEngineConfigRagManagedDbConfigBasicOutput{})
	pulumi.RegisterOutputType(AiRagEngineConfigRagManagedDbConfigBasicPtrOutput{})
	pulumi.RegisterOutputType(AiRagEngineConfigRagManagedDbConfigScaledOutput{})
	pulumi.RegisterOutputType(AiRagEngineConfigRagManagedDbConfigScaledPtrOutput{})
	pulumi.RegisterOutputType(AiRagEngineConfigRagManagedDbConfigUnprovisionedOutput{})
	pulumi.RegisterOutputType(AiRagEngineConfigRagManagedDbConfigUnprovisionedPtrOutput{})
	pulumi.RegisterOutputType(AiTensorboardEncryptionSpecOutput{})
	pulumi.RegisterOutputType(AiTensorboardEncryptionSpecPtrOutput{})
	pulumi.RegisterOutputType(GetAiIndexDeployedIndexOutput{})
	pulumi.RegisterOutputType(GetAiIndexDeployedIndexArrayOutput{})
	pulumi.RegisterOutputType(GetAiIndexIndexStatOutput{})
	pulumi.RegisterOutputType(GetAiIndexIndexStatArrayOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataArrayOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigArrayOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigAlgorithmConfigOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigAlgorithmConfigArrayOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigAlgorithmConfigBruteForceConfigArrayOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigOutput{})
	pulumi.RegisterOutputType(GetAiIndexMetadataConfigAlgorithmConfigTreeAhConfigArrayOutput{})
}
