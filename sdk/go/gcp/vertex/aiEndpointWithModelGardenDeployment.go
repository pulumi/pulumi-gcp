// Code generated by pulumi-language-go DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package vertex

import (
	"context"
	"reflect"

	"errors"
	"github.com/pulumi/pulumi-gcp/sdk/v9/go/gcp/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// Create an Endpoint and deploy a Model Garden model to it.
//
// To get more information about EndpointWithModelGardenDeployment, see:
//
// * [API documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations/deploy)
// * How-to Guides
//   - [Overview of Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)
//   - [Overview of self-deployed models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/self-deployed-models)
//   - [Use models in Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/use-models)
//
// ## Example Usage
//
// ### Vertex Ai Deploy Basic
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-gcp/sdk/v9/go/gcp/vertex"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := vertex.NewAiEndpointWithModelGardenDeployment(ctx, "deploy", &vertex.AiEndpointWithModelGardenDeploymentArgs{
//				PublisherModelName: pulumi.String("publishers/google/models/paligemma@paligemma-224-float32"),
//				Location:           pulumi.String("us-central1"),
//				ModelConfig: &vertex.AiEndpointWithModelGardenDeploymentModelConfigArgs{
//					AcceptEula: pulumi.Bool(true),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// ### Vertex Ai Deploy Huggingface Model
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-gcp/sdk/v9/go/gcp/vertex"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := vertex.NewAiEndpointWithModelGardenDeployment(ctx, "deploy", &vertex.AiEndpointWithModelGardenDeploymentArgs{
//				HuggingFaceModelId: pulumi.String("Qwen/Qwen3-0.6B"),
//				Location:           pulumi.String("us-central1"),
//				ModelConfig: &vertex.AiEndpointWithModelGardenDeploymentModelConfigArgs{
//					AcceptEula: pulumi.Bool(true),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// ### Vertex Ai Deploy With Configs
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-gcp/sdk/v9/go/gcp/vertex"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := vertex.NewAiEndpointWithModelGardenDeployment(ctx, "deploy", &vertex.AiEndpointWithModelGardenDeploymentArgs{
//				PublisherModelName: pulumi.String("publishers/google/models/paligemma@paligemma-224-float32"),
//				Location:           pulumi.String("us-central1"),
//				ModelConfig: &vertex.AiEndpointWithModelGardenDeploymentModelConfigArgs{
//					AcceptEula: pulumi.Bool(true),
//				},
//				DeployConfig: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigArgs{
//					DedicatedResources: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs{
//						MachineSpec: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs{
//							MachineType:      pulumi.String("g2-standard-16"),
//							AcceleratorType:  pulumi.String("NVIDIA_L4"),
//							AcceleratorCount: pulumi.Int(1),
//						},
//						MinReplicaCount: pulumi.Int(1),
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// ### Vertex Ai Deploy Multiple Models In Parallel
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-gcp/sdk/v9/go/gcp/vertex"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := vertex.NewAiEndpointWithModelGardenDeployment(ctx, "deploy-gemma-1_1-2b-it", &vertex.AiEndpointWithModelGardenDeploymentArgs{
//				PublisherModelName: pulumi.String("publishers/google/models/gemma@gemma-1.1-2b-it"),
//				Location:           pulumi.String("us-central1"),
//				ModelConfig: &vertex.AiEndpointWithModelGardenDeploymentModelConfigArgs{
//					AcceptEula: pulumi.Bool(true),
//				},
//				DeployConfig: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigArgs{
//					DedicatedResources: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs{
//						MachineSpec: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs{
//							MachineType:      pulumi.String("g2-standard-12"),
//							AcceleratorType:  pulumi.String("us-central1"),
//							AcceleratorCount: pulumi.Int(1),
//						},
//						MinReplicaCount: pulumi.Int(1),
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			_, err = vertex.NewAiEndpointWithModelGardenDeployment(ctx, "deploy-qwen3-0_6b", &vertex.AiEndpointWithModelGardenDeploymentArgs{
//				HuggingFaceModelId: pulumi.String("Qwen/Qwen3-0.6B"),
//				Location:           pulumi.String("us-central1"),
//				ModelConfig: &vertex.AiEndpointWithModelGardenDeploymentModelConfigArgs{
//					AcceptEula: pulumi.Bool(true),
//				},
//				DeployConfig: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigArgs{
//					DedicatedResources: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs{
//						MachineSpec: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs{
//							MachineType:      pulumi.String("g2-standard-12"),
//							AcceleratorType:  pulumi.String("NVIDIA_L4"),
//							AcceleratorCount: pulumi.Int(1),
//						},
//						MinReplicaCount: pulumi.Int(1),
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			_, err = vertex.NewAiEndpointWithModelGardenDeployment(ctx, "deploy-llama-3_2-1b", &vertex.AiEndpointWithModelGardenDeploymentArgs{
//				PublisherModelName: pulumi.String("publishers/meta/models/llama3-2@llama-3.2-1b"),
//				Location:           pulumi.String("us-central1"),
//				ModelConfig: &vertex.AiEndpointWithModelGardenDeploymentModelConfigArgs{
//					AcceptEula: pulumi.Bool(true),
//				},
//				DeployConfig: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigArgs{
//					DedicatedResources: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs{
//						MachineSpec: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs{
//							MachineType:      pulumi.String("g2-standard-12"),
//							AcceleratorType:  pulumi.String("NVIDIA_L4"),
//							AcceleratorCount: pulumi.Int(1),
//						},
//						MinReplicaCount: pulumi.Int(1),
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// ### Vertex Ai Deploy Multiple Models In Sequence
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-gcp/sdk/v9/go/gcp/vertex"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			deploy_gemma_11_2b_it, err := vertex.NewAiEndpointWithModelGardenDeployment(ctx, "deploy-gemma-1_1-2b-it", &vertex.AiEndpointWithModelGardenDeploymentArgs{
//				PublisherModelName: pulumi.String("publishers/google/models/gemma@gemma-1.1-2b-it"),
//				Location:           pulumi.String("us-central1"),
//				ModelConfig: &vertex.AiEndpointWithModelGardenDeploymentModelConfigArgs{
//					AcceptEula: pulumi.Bool(true),
//				},
//				DeployConfig: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigArgs{
//					DedicatedResources: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs{
//						MachineSpec: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs{
//							MachineType:      pulumi.String("g2-standard-12"),
//							AcceleratorType:  pulumi.String("NVIDIA_L4"),
//							AcceleratorCount: pulumi.Int(1),
//						},
//						MinReplicaCount: pulumi.Int(1),
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			deploy_qwen3_06b, err := vertex.NewAiEndpointWithModelGardenDeployment(ctx, "deploy-qwen3-0_6b", &vertex.AiEndpointWithModelGardenDeploymentArgs{
//				HuggingFaceModelId: pulumi.String("Qwen/Qwen3-0.6B"),
//				Location:           pulumi.String("us-central1"),
//				ModelConfig: &vertex.AiEndpointWithModelGardenDeploymentModelConfigArgs{
//					AcceptEula: pulumi.Bool(true),
//				},
//				DeployConfig: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigArgs{
//					DedicatedResources: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs{
//						MachineSpec: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs{
//							MachineType:      pulumi.String("g2-standard-12"),
//							AcceleratorType:  pulumi.String("NVIDIA_L4"),
//							AcceleratorCount: pulumi.Int(1),
//						},
//						MinReplicaCount: pulumi.Int(1),
//					},
//				},
//			}, pulumi.DependsOn([]pulumi.Resource{
//				deploy_gemma_11_2b_it,
//			}))
//			if err != nil {
//				return err
//			}
//			_, err = vertex.NewAiEndpointWithModelGardenDeployment(ctx, "deploy-llama-3_2-1b", &vertex.AiEndpointWithModelGardenDeploymentArgs{
//				PublisherModelName: pulumi.String("publishers/meta/models/llama3-2@llama-3.2-1b"),
//				Location:           pulumi.String("us-central1"),
//				ModelConfig: &vertex.AiEndpointWithModelGardenDeploymentModelConfigArgs{
//					AcceptEula: pulumi.Bool(true),
//				},
//				DeployConfig: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigArgs{
//					DedicatedResources: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesArgs{
//						MachineSpec: &vertex.AiEndpointWithModelGardenDeploymentDeployConfigDedicatedResourcesMachineSpecArgs{
//							MachineType:      pulumi.String("g2-standard-12"),
//							AcceleratorType:  pulumi.String("NVIDIA_L4"),
//							AcceleratorCount: pulumi.Int(1),
//						},
//						MinReplicaCount: pulumi.Int(1),
//					},
//				},
//			}, pulumi.DependsOn([]pulumi.Resource{
//				deploy_qwen3_06b,
//			}))
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// ### Vertex Ai Deploy Psc Endpoint
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-gcp/sdk/v9/go/gcp/vertex"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := vertex.NewAiEndpointWithModelGardenDeployment(ctx, "deploy", &vertex.AiEndpointWithModelGardenDeploymentArgs{
//				PublisherModelName: pulumi.String("publishers/google/models/paligemma@paligemma-224-float32"),
//				Location:           pulumi.String("us-central1"),
//				ModelConfig: &vertex.AiEndpointWithModelGardenDeploymentModelConfigArgs{
//					AcceptEula: pulumi.Bool(true),
//				},
//				EndpointConfig: &vertex.AiEndpointWithModelGardenDeploymentEndpointConfigArgs{
//					PrivateServiceConnectConfig: &vertex.AiEndpointWithModelGardenDeploymentEndpointConfigPrivateServiceConnectConfigArgs{
//						EnablePrivateServiceConnect: pulumi.Bool(true),
//						ProjectAllowlists: pulumi.StringArray{
//							pulumi.String("my-project-id"),
//						},
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// ### Vertex Ai Deploy Psc Endpoint Automated
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-gcp/sdk/v9/go/gcp/compute"
//	"github.com/pulumi/pulumi-gcp/sdk/v9/go/gcp/organizations"
//	"github.com/pulumi/pulumi-gcp/sdk/v9/go/gcp/vertex"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			network, err := compute.NewNetwork(ctx, "network", &compute.NetworkArgs{
//				Name:                  pulumi.String("network"),
//				AutoCreateSubnetworks: pulumi.Bool(false),
//			})
//			if err != nil {
//				return err
//			}
//			project, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
//			if err != nil {
//				return err
//			}
//			_, err = vertex.NewAiEndpointWithModelGardenDeployment(ctx, "deploy", &vertex.AiEndpointWithModelGardenDeploymentArgs{
//				PublisherModelName: pulumi.String("publishers/google/models/paligemma@paligemma-224-float32"),
//				Location:           pulumi.String("us-central1"),
//				ModelConfig: &vertex.AiEndpointWithModelGardenDeploymentModelConfigArgs{
//					AcceptEula: pulumi.Bool(true),
//				},
//				EndpointConfig: &vertex.AiEndpointWithModelGardenDeploymentEndpointConfigArgs{
//					PrivateServiceConnectConfig: &vertex.AiEndpointWithModelGardenDeploymentEndpointConfigPrivateServiceConnectConfigArgs{
//						EnablePrivateServiceConnect: pulumi.Bool(true),
//						ProjectAllowlists: pulumi.StringArray{
//							pulumi.String(project.Id),
//						},
//						PscAutomationConfigs: &vertex.AiEndpointWithModelGardenDeploymentEndpointConfigPrivateServiceConnectConfigPscAutomationConfigsArgs{
//							ProjectId: pulumi.String(project.Id),
//							Network:   network.ID(),
//						},
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			_, err = compute.NewSubnetwork(ctx, "subnetwork", &compute.SubnetworkArgs{
//				Name:        pulumi.String("subnetwork"),
//				IpCidrRange: pulumi.String("192.168.0.0/24"),
//				Region:      pulumi.String("us-central1"),
//				Network:     network.ID(),
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// ## Import
//
// This resource does not support import.
type AiEndpointWithModelGardenDeployment struct {
	pulumi.CustomResourceState

	// The deploy config to use for the deployment.
	// Structure is documented below.
	DeployConfig AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput `pulumi:"deployConfig"`
	// Output only. The display name assigned to the model deployed to the endpoint.
	// This is not required to delete the resource but is used for debug logging.
	DeployedModelDisplayName pulumi.StringOutput `pulumi:"deployedModelDisplayName"`
	// Output only. The unique numeric ID that Vertex AI assigns to the model at the time it is deployed to the endpoint.
	// It is required to undeploy the model from the endpoint during resource deletion as described in
	// https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/undeployModel.
	DeployedModelId pulumi.StringOutput `pulumi:"deployedModelId"`
	// Resource ID segment making up resource `endpoint`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
	Endpoint pulumi.StringOutput `pulumi:"endpoint"`
	// The endpoint config to use for the deployment.
	// Structure is documented below.
	EndpointConfig AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput `pulumi:"endpointConfig"`
	// The Hugging Face model to deploy.
	// Format: Hugging Face model ID like `google/gemma-2-2b-it`.
	HuggingFaceModelId pulumi.StringPtrOutput `pulumi:"huggingFaceModelId"`
	// Resource ID segment making up resource `location`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
	Location pulumi.StringOutput `pulumi:"location"`
	// The model config to use for the deployment.
	// Structure is documented below.
	ModelConfig AiEndpointWithModelGardenDeploymentModelConfigPtrOutput `pulumi:"modelConfig"`
	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	Project pulumi.StringOutput `pulumi:"project"`
	// The Model Garden model to deploy.
	// Format:
	// `publishers/{publisher}/models/{publisher_model}@{version_id}`, or
	// `publishers/hf-{hugging-face-author}/models/{hugging-face-model-name}@001`.
	PublisherModelName pulumi.StringPtrOutput `pulumi:"publisherModelName"`
}

// NewAiEndpointWithModelGardenDeployment registers a new resource with the given unique name, arguments, and options.
func NewAiEndpointWithModelGardenDeployment(ctx *pulumi.Context,
	name string, args *AiEndpointWithModelGardenDeploymentArgs, opts ...pulumi.ResourceOption) (*AiEndpointWithModelGardenDeployment, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.Location == nil {
		return nil, errors.New("invalid value for required argument 'Location'")
	}
	opts = internal.PkgResourceDefaultOpts(opts)
	var resource AiEndpointWithModelGardenDeployment
	err := ctx.RegisterResource("gcp:vertex/aiEndpointWithModelGardenDeployment:AiEndpointWithModelGardenDeployment", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetAiEndpointWithModelGardenDeployment gets an existing AiEndpointWithModelGardenDeployment resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetAiEndpointWithModelGardenDeployment(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *AiEndpointWithModelGardenDeploymentState, opts ...pulumi.ResourceOption) (*AiEndpointWithModelGardenDeployment, error) {
	var resource AiEndpointWithModelGardenDeployment
	err := ctx.ReadResource("gcp:vertex/aiEndpointWithModelGardenDeployment:AiEndpointWithModelGardenDeployment", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering AiEndpointWithModelGardenDeployment resources.
type aiEndpointWithModelGardenDeploymentState struct {
	// The deploy config to use for the deployment.
	// Structure is documented below.
	DeployConfig *AiEndpointWithModelGardenDeploymentDeployConfig `pulumi:"deployConfig"`
	// Output only. The display name assigned to the model deployed to the endpoint.
	// This is not required to delete the resource but is used for debug logging.
	DeployedModelDisplayName *string `pulumi:"deployedModelDisplayName"`
	// Output only. The unique numeric ID that Vertex AI assigns to the model at the time it is deployed to the endpoint.
	// It is required to undeploy the model from the endpoint during resource deletion as described in
	// https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/undeployModel.
	DeployedModelId *string `pulumi:"deployedModelId"`
	// Resource ID segment making up resource `endpoint`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
	Endpoint *string `pulumi:"endpoint"`
	// The endpoint config to use for the deployment.
	// Structure is documented below.
	EndpointConfig *AiEndpointWithModelGardenDeploymentEndpointConfig `pulumi:"endpointConfig"`
	// The Hugging Face model to deploy.
	// Format: Hugging Face model ID like `google/gemma-2-2b-it`.
	HuggingFaceModelId *string `pulumi:"huggingFaceModelId"`
	// Resource ID segment making up resource `location`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
	Location *string `pulumi:"location"`
	// The model config to use for the deployment.
	// Structure is documented below.
	ModelConfig *AiEndpointWithModelGardenDeploymentModelConfig `pulumi:"modelConfig"`
	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	Project *string `pulumi:"project"`
	// The Model Garden model to deploy.
	// Format:
	// `publishers/{publisher}/models/{publisher_model}@{version_id}`, or
	// `publishers/hf-{hugging-face-author}/models/{hugging-face-model-name}@001`.
	PublisherModelName *string `pulumi:"publisherModelName"`
}

type AiEndpointWithModelGardenDeploymentState struct {
	// The deploy config to use for the deployment.
	// Structure is documented below.
	DeployConfig AiEndpointWithModelGardenDeploymentDeployConfigPtrInput
	// Output only. The display name assigned to the model deployed to the endpoint.
	// This is not required to delete the resource but is used for debug logging.
	DeployedModelDisplayName pulumi.StringPtrInput
	// Output only. The unique numeric ID that Vertex AI assigns to the model at the time it is deployed to the endpoint.
	// It is required to undeploy the model from the endpoint during resource deletion as described in
	// https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/undeployModel.
	DeployedModelId pulumi.StringPtrInput
	// Resource ID segment making up resource `endpoint`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
	Endpoint pulumi.StringPtrInput
	// The endpoint config to use for the deployment.
	// Structure is documented below.
	EndpointConfig AiEndpointWithModelGardenDeploymentEndpointConfigPtrInput
	// The Hugging Face model to deploy.
	// Format: Hugging Face model ID like `google/gemma-2-2b-it`.
	HuggingFaceModelId pulumi.StringPtrInput
	// Resource ID segment making up resource `location`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
	Location pulumi.StringPtrInput
	// The model config to use for the deployment.
	// Structure is documented below.
	ModelConfig AiEndpointWithModelGardenDeploymentModelConfigPtrInput
	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	Project pulumi.StringPtrInput
	// The Model Garden model to deploy.
	// Format:
	// `publishers/{publisher}/models/{publisher_model}@{version_id}`, or
	// `publishers/hf-{hugging-face-author}/models/{hugging-face-model-name}@001`.
	PublisherModelName pulumi.StringPtrInput
}

func (AiEndpointWithModelGardenDeploymentState) ElementType() reflect.Type {
	return reflect.TypeOf((*aiEndpointWithModelGardenDeploymentState)(nil)).Elem()
}

type aiEndpointWithModelGardenDeploymentArgs struct {
	// The deploy config to use for the deployment.
	// Structure is documented below.
	DeployConfig *AiEndpointWithModelGardenDeploymentDeployConfig `pulumi:"deployConfig"`
	// The endpoint config to use for the deployment.
	// Structure is documented below.
	EndpointConfig *AiEndpointWithModelGardenDeploymentEndpointConfig `pulumi:"endpointConfig"`
	// The Hugging Face model to deploy.
	// Format: Hugging Face model ID like `google/gemma-2-2b-it`.
	HuggingFaceModelId *string `pulumi:"huggingFaceModelId"`
	// Resource ID segment making up resource `location`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
	Location string `pulumi:"location"`
	// The model config to use for the deployment.
	// Structure is documented below.
	ModelConfig *AiEndpointWithModelGardenDeploymentModelConfig `pulumi:"modelConfig"`
	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	Project *string `pulumi:"project"`
	// The Model Garden model to deploy.
	// Format:
	// `publishers/{publisher}/models/{publisher_model}@{version_id}`, or
	// `publishers/hf-{hugging-face-author}/models/{hugging-face-model-name}@001`.
	PublisherModelName *string `pulumi:"publisherModelName"`
}

// The set of arguments for constructing a AiEndpointWithModelGardenDeployment resource.
type AiEndpointWithModelGardenDeploymentArgs struct {
	// The deploy config to use for the deployment.
	// Structure is documented below.
	DeployConfig AiEndpointWithModelGardenDeploymentDeployConfigPtrInput
	// The endpoint config to use for the deployment.
	// Structure is documented below.
	EndpointConfig AiEndpointWithModelGardenDeploymentEndpointConfigPtrInput
	// The Hugging Face model to deploy.
	// Format: Hugging Face model ID like `google/gemma-2-2b-it`.
	HuggingFaceModelId pulumi.StringPtrInput
	// Resource ID segment making up resource `location`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
	Location pulumi.StringInput
	// The model config to use for the deployment.
	// Structure is documented below.
	ModelConfig AiEndpointWithModelGardenDeploymentModelConfigPtrInput
	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	Project pulumi.StringPtrInput
	// The Model Garden model to deploy.
	// Format:
	// `publishers/{publisher}/models/{publisher_model}@{version_id}`, or
	// `publishers/hf-{hugging-face-author}/models/{hugging-face-model-name}@001`.
	PublisherModelName pulumi.StringPtrInput
}

func (AiEndpointWithModelGardenDeploymentArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*aiEndpointWithModelGardenDeploymentArgs)(nil)).Elem()
}

type AiEndpointWithModelGardenDeploymentInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentOutput() AiEndpointWithModelGardenDeploymentOutput
	ToAiEndpointWithModelGardenDeploymentOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentOutput
}

func (*AiEndpointWithModelGardenDeployment) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeployment)(nil)).Elem()
}

func (i *AiEndpointWithModelGardenDeployment) ToAiEndpointWithModelGardenDeploymentOutput() AiEndpointWithModelGardenDeploymentOutput {
	return i.ToAiEndpointWithModelGardenDeploymentOutputWithContext(context.Background())
}

func (i *AiEndpointWithModelGardenDeployment) ToAiEndpointWithModelGardenDeploymentOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentOutput)
}

// AiEndpointWithModelGardenDeploymentArrayInput is an input type that accepts AiEndpointWithModelGardenDeploymentArray and AiEndpointWithModelGardenDeploymentArrayOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentArrayInput` via:
//
//	AiEndpointWithModelGardenDeploymentArray{ AiEndpointWithModelGardenDeploymentArgs{...} }
type AiEndpointWithModelGardenDeploymentArrayInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentArrayOutput() AiEndpointWithModelGardenDeploymentArrayOutput
	ToAiEndpointWithModelGardenDeploymentArrayOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentArrayOutput
}

type AiEndpointWithModelGardenDeploymentArray []AiEndpointWithModelGardenDeploymentInput

func (AiEndpointWithModelGardenDeploymentArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*AiEndpointWithModelGardenDeployment)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentArray) ToAiEndpointWithModelGardenDeploymentArrayOutput() AiEndpointWithModelGardenDeploymentArrayOutput {
	return i.ToAiEndpointWithModelGardenDeploymentArrayOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentArray) ToAiEndpointWithModelGardenDeploymentArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentArrayOutput)
}

// AiEndpointWithModelGardenDeploymentMapInput is an input type that accepts AiEndpointWithModelGardenDeploymentMap and AiEndpointWithModelGardenDeploymentMapOutput values.
// You can construct a concrete instance of `AiEndpointWithModelGardenDeploymentMapInput` via:
//
//	AiEndpointWithModelGardenDeploymentMap{ "key": AiEndpointWithModelGardenDeploymentArgs{...} }
type AiEndpointWithModelGardenDeploymentMapInput interface {
	pulumi.Input

	ToAiEndpointWithModelGardenDeploymentMapOutput() AiEndpointWithModelGardenDeploymentMapOutput
	ToAiEndpointWithModelGardenDeploymentMapOutputWithContext(context.Context) AiEndpointWithModelGardenDeploymentMapOutput
}

type AiEndpointWithModelGardenDeploymentMap map[string]AiEndpointWithModelGardenDeploymentInput

func (AiEndpointWithModelGardenDeploymentMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*AiEndpointWithModelGardenDeployment)(nil)).Elem()
}

func (i AiEndpointWithModelGardenDeploymentMap) ToAiEndpointWithModelGardenDeploymentMapOutput() AiEndpointWithModelGardenDeploymentMapOutput {
	return i.ToAiEndpointWithModelGardenDeploymentMapOutputWithContext(context.Background())
}

func (i AiEndpointWithModelGardenDeploymentMap) ToAiEndpointWithModelGardenDeploymentMapOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AiEndpointWithModelGardenDeploymentMapOutput)
}

type AiEndpointWithModelGardenDeploymentOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AiEndpointWithModelGardenDeployment)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentOutput) ToAiEndpointWithModelGardenDeploymentOutput() AiEndpointWithModelGardenDeploymentOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentOutput) ToAiEndpointWithModelGardenDeploymentOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentOutput {
	return o
}

// The deploy config to use for the deployment.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentOutput) DeployConfig() AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeployment) AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput {
		return v.DeployConfig
	}).(AiEndpointWithModelGardenDeploymentDeployConfigPtrOutput)
}

// Output only. The display name assigned to the model deployed to the endpoint.
// This is not required to delete the resource but is used for debug logging.
func (o AiEndpointWithModelGardenDeploymentOutput) DeployedModelDisplayName() pulumi.StringOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeployment) pulumi.StringOutput { return v.DeployedModelDisplayName }).(pulumi.StringOutput)
}

// Output only. The unique numeric ID that Vertex AI assigns to the model at the time it is deployed to the endpoint.
// It is required to undeploy the model from the endpoint during resource deletion as described in
// https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/undeployModel.
func (o AiEndpointWithModelGardenDeploymentOutput) DeployedModelId() pulumi.StringOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeployment) pulumi.StringOutput { return v.DeployedModelId }).(pulumi.StringOutput)
}

// Resource ID segment making up resource `endpoint`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
func (o AiEndpointWithModelGardenDeploymentOutput) Endpoint() pulumi.StringOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeployment) pulumi.StringOutput { return v.Endpoint }).(pulumi.StringOutput)
}

// The endpoint config to use for the deployment.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentOutput) EndpointConfig() AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeployment) AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput {
		return v.EndpointConfig
	}).(AiEndpointWithModelGardenDeploymentEndpointConfigPtrOutput)
}

// The Hugging Face model to deploy.
// Format: Hugging Face model ID like `google/gemma-2-2b-it`.
func (o AiEndpointWithModelGardenDeploymentOutput) HuggingFaceModelId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeployment) pulumi.StringPtrOutput { return v.HuggingFaceModelId }).(pulumi.StringPtrOutput)
}

// Resource ID segment making up resource `location`. It identifies the resource within its parent collection as described in https://google.aip.dev/122.
func (o AiEndpointWithModelGardenDeploymentOutput) Location() pulumi.StringOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeployment) pulumi.StringOutput { return v.Location }).(pulumi.StringOutput)
}

// The model config to use for the deployment.
// Structure is documented below.
func (o AiEndpointWithModelGardenDeploymentOutput) ModelConfig() AiEndpointWithModelGardenDeploymentModelConfigPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeployment) AiEndpointWithModelGardenDeploymentModelConfigPtrOutput {
		return v.ModelConfig
	}).(AiEndpointWithModelGardenDeploymentModelConfigPtrOutput)
}

// The ID of the project in which the resource belongs.
// If it is not provided, the provider project is used.
func (o AiEndpointWithModelGardenDeploymentOutput) Project() pulumi.StringOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeployment) pulumi.StringOutput { return v.Project }).(pulumi.StringOutput)
}

// The Model Garden model to deploy.
// Format:
// `publishers/{publisher}/models/{publisher_model}@{version_id}`, or
// `publishers/hf-{hugging-face-author}/models/{hugging-face-model-name}@001`.
func (o AiEndpointWithModelGardenDeploymentOutput) PublisherModelName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AiEndpointWithModelGardenDeployment) pulumi.StringPtrOutput { return v.PublisherModelName }).(pulumi.StringPtrOutput)
}

type AiEndpointWithModelGardenDeploymentArrayOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*AiEndpointWithModelGardenDeployment)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentArrayOutput) ToAiEndpointWithModelGardenDeploymentArrayOutput() AiEndpointWithModelGardenDeploymentArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentArrayOutput) ToAiEndpointWithModelGardenDeploymentArrayOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentArrayOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentArrayOutput) Index(i pulumi.IntInput) AiEndpointWithModelGardenDeploymentOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *AiEndpointWithModelGardenDeployment {
		return vs[0].([]*AiEndpointWithModelGardenDeployment)[vs[1].(int)]
	}).(AiEndpointWithModelGardenDeploymentOutput)
}

type AiEndpointWithModelGardenDeploymentMapOutput struct{ *pulumi.OutputState }

func (AiEndpointWithModelGardenDeploymentMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*AiEndpointWithModelGardenDeployment)(nil)).Elem()
}

func (o AiEndpointWithModelGardenDeploymentMapOutput) ToAiEndpointWithModelGardenDeploymentMapOutput() AiEndpointWithModelGardenDeploymentMapOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentMapOutput) ToAiEndpointWithModelGardenDeploymentMapOutputWithContext(ctx context.Context) AiEndpointWithModelGardenDeploymentMapOutput {
	return o
}

func (o AiEndpointWithModelGardenDeploymentMapOutput) MapIndex(k pulumi.StringInput) AiEndpointWithModelGardenDeploymentOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *AiEndpointWithModelGardenDeployment {
		return vs[0].(map[string]*AiEndpointWithModelGardenDeployment)[vs[1].(string)]
	}).(AiEndpointWithModelGardenDeploymentOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentInput)(nil)).Elem(), &AiEndpointWithModelGardenDeployment{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentArrayInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*AiEndpointWithModelGardenDeploymentMapInput)(nil)).Elem(), AiEndpointWithModelGardenDeploymentMap{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentArrayOutput{})
	pulumi.RegisterOutputType(AiEndpointWithModelGardenDeploymentMapOutput{})
}
