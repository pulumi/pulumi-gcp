// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package dataflow

import (
	"context"
	"reflect"

	"errors"
	"github.com/pulumi/pulumi-gcp/sdk/v7/go/gcp/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// The main pipeline entity and all the necessary metadata for launching and managing linked jobs.
//
// To get more information about Pipeline, see:
//
// * [API documentation](https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines)
// * How-to Guides
//   - [Official Documentation](https://cloud.google.com/dataflow)
//
// ## Example Usage
// ### Data Pipeline Pipeline
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-gcp/sdk/v7/go/gcp/dataflow"
//	"github.com/pulumi/pulumi-gcp/sdk/v7/go/gcp/serviceaccount"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			serviceAccount, err := serviceaccount.NewAccount(ctx, "serviceAccount", &serviceaccount.AccountArgs{
//				AccountId:   pulumi.String("my-account"),
//				DisplayName: pulumi.String("Service Account"),
//			})
//			if err != nil {
//				return err
//			}
//			_, err = dataflow.NewPipeline(ctx, "primary", &dataflow.PipelineArgs{
//				DisplayName: pulumi.String("my-pipeline"),
//				Type:        pulumi.String("PIPELINE_TYPE_BATCH"),
//				State:       pulumi.String("STATE_ACTIVE"),
//				Region:      pulumi.String("us-central1"),
//				Workload: &dataflow.PipelineWorkloadArgs{
//					DataflowLaunchTemplateRequest: &dataflow.PipelineWorkloadDataflowLaunchTemplateRequestArgs{
//						ProjectId: pulumi.String("my-project"),
//						GcsPath:   pulumi.String("gs://my-bucket/path"),
//						LaunchParameters: &dataflow.PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersArgs{
//							JobName: pulumi.String("my-job"),
//							Parameters: pulumi.StringMap{
//								"name": pulumi.String("wrench"),
//							},
//							Environment: &dataflow.PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentArgs{
//								NumWorkers:              pulumi.Int(5),
//								MaxWorkers:              pulumi.Int(5),
//								Zone:                    pulumi.String("us-centra1-a"),
//								ServiceAccountEmail:     serviceAccount.Email,
//								Network:                 pulumi.String("default"),
//								TempLocation:            pulumi.String("gs://my-bucket/tmp_dir"),
//								BypassTempDirValidation: pulumi.Bool(false),
//								MachineType:             pulumi.String("E2"),
//								AdditionalUserLabels: pulumi.StringMap{
//									"context": pulumi.String("test"),
//								},
//								WorkerRegion:          pulumi.String("us-central1"),
//								WorkerZone:            pulumi.String("us-central1-a"),
//								EnableStreamingEngine: pulumi.Bool(false),
//							},
//							Update: pulumi.Bool(false),
//							TransformNameMapping: pulumi.StringMap{
//								"name": pulumi.String("wrench"),
//							},
//						},
//						Location: pulumi.String("us-central1"),
//					},
//				},
//				ScheduleInfo: &dataflow.PipelineScheduleInfoArgs{
//					Schedule: pulumi.String("* */2 * * *"),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// ## Import
//
// # Pipeline can be imported using any of these accepted formats
//
// ```sh
//
//	$ pulumi import gcp:dataflow/pipeline:Pipeline default projects/{{project}}/locations/{{region}}/pipelines/{{name}}
//
// ```
//
// ```sh
//
//	$ pulumi import gcp:dataflow/pipeline:Pipeline default {{project}}/{{region}}/{{name}}
//
// ```
//
// ```sh
//
//	$ pulumi import gcp:dataflow/pipeline:Pipeline default {{region}}/{{name}}
//
// ```
//
// ```sh
//
//	$ pulumi import gcp:dataflow/pipeline:Pipeline default {{name}}
//
// ```
type Pipeline struct {
	pulumi.CustomResourceState

	// The timestamp when the pipeline was initially created. Set by the Data Pipelines service.
	// A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
	CreateTime pulumi.StringOutput `pulumi:"createTime"`
	// The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores (_).
	DisplayName pulumi.StringPtrOutput `pulumi:"displayName"`
	// Number of jobs.
	JobCount pulumi.IntOutput `pulumi:"jobCount"`
	// The timestamp when the pipeline was last modified. Set by the Data Pipelines service.
	// A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
	LastUpdateTime pulumi.StringOutput `pulumi:"lastUpdateTime"`
	// "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID."
	// "- PROJECT_ID can contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see Identifying projects."
	// "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine regions."
	// "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
	Name pulumi.StringOutput `pulumi:"name"`
	// The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during pipeline creation.
	// An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
	PipelineSources pulumi.StringMapOutput `pulumi:"pipelineSources"`
	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	Project pulumi.StringOutput `pulumi:"project"`
	// A reference to the region
	Region pulumi.StringPtrOutput `pulumi:"region"`
	// Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the schedule. If not, users are responsible for creating jobs externally.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
	// Structure is documented below.
	ScheduleInfo PipelineScheduleInfoPtrOutput `pulumi:"scheduleInfo"`
	// Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine service account will be used.
	SchedulerServiceAccountEmail pulumi.StringPtrOutput `pulumi:"schedulerServiceAccountEmail"`
	// The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through pipelines.patch requests.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state
	// Possible values are: `STATE_UNSPECIFIED`, `STATE_RESUMING`, `STATE_ACTIVE`, `STATE_STOPPING`, `STATE_ARCHIVED`, `STATE_PAUSED`.
	//
	// ***
	State pulumi.StringOutput `pulumi:"state"`
	// The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the pipeline.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
	// Possible values are: `PIPELINE_TYPE_UNSPECIFIED`, `PIPELINE_TYPE_BATCH`, `PIPELINE_TYPE_STREAMING`.
	Type pulumi.StringOutput `pulumi:"type"`
	// Workload information for creating new jobs.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
	// Structure is documented below.
	Workload PipelineWorkloadPtrOutput `pulumi:"workload"`
}

// NewPipeline registers a new resource with the given unique name, arguments, and options.
func NewPipeline(ctx *pulumi.Context,
	name string, args *PipelineArgs, opts ...pulumi.ResourceOption) (*Pipeline, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.State == nil {
		return nil, errors.New("invalid value for required argument 'State'")
	}
	if args.Type == nil {
		return nil, errors.New("invalid value for required argument 'Type'")
	}
	opts = internal.PkgResourceDefaultOpts(opts)
	var resource Pipeline
	err := ctx.RegisterResource("gcp:dataflow/pipeline:Pipeline", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetPipeline gets an existing Pipeline resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetPipeline(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *PipelineState, opts ...pulumi.ResourceOption) (*Pipeline, error) {
	var resource Pipeline
	err := ctx.ReadResource("gcp:dataflow/pipeline:Pipeline", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering Pipeline resources.
type pipelineState struct {
	// The timestamp when the pipeline was initially created. Set by the Data Pipelines service.
	// A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
	CreateTime *string `pulumi:"createTime"`
	// The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores (_).
	DisplayName *string `pulumi:"displayName"`
	// Number of jobs.
	JobCount *int `pulumi:"jobCount"`
	// The timestamp when the pipeline was last modified. Set by the Data Pipelines service.
	// A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
	LastUpdateTime *string `pulumi:"lastUpdateTime"`
	// "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID."
	// "- PROJECT_ID can contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see Identifying projects."
	// "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine regions."
	// "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
	Name *string `pulumi:"name"`
	// The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during pipeline creation.
	// An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
	PipelineSources map[string]string `pulumi:"pipelineSources"`
	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	Project *string `pulumi:"project"`
	// A reference to the region
	Region *string `pulumi:"region"`
	// Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the schedule. If not, users are responsible for creating jobs externally.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
	// Structure is documented below.
	ScheduleInfo *PipelineScheduleInfo `pulumi:"scheduleInfo"`
	// Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine service account will be used.
	SchedulerServiceAccountEmail *string `pulumi:"schedulerServiceAccountEmail"`
	// The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through pipelines.patch requests.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state
	// Possible values are: `STATE_UNSPECIFIED`, `STATE_RESUMING`, `STATE_ACTIVE`, `STATE_STOPPING`, `STATE_ARCHIVED`, `STATE_PAUSED`.
	//
	// ***
	State *string `pulumi:"state"`
	// The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the pipeline.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
	// Possible values are: `PIPELINE_TYPE_UNSPECIFIED`, `PIPELINE_TYPE_BATCH`, `PIPELINE_TYPE_STREAMING`.
	Type *string `pulumi:"type"`
	// Workload information for creating new jobs.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
	// Structure is documented below.
	Workload *PipelineWorkload `pulumi:"workload"`
}

type PipelineState struct {
	// The timestamp when the pipeline was initially created. Set by the Data Pipelines service.
	// A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
	CreateTime pulumi.StringPtrInput
	// The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores (_).
	DisplayName pulumi.StringPtrInput
	// Number of jobs.
	JobCount pulumi.IntPtrInput
	// The timestamp when the pipeline was last modified. Set by the Data Pipelines service.
	// A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
	LastUpdateTime pulumi.StringPtrInput
	// "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID."
	// "- PROJECT_ID can contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see Identifying projects."
	// "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine regions."
	// "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
	Name pulumi.StringPtrInput
	// The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during pipeline creation.
	// An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
	PipelineSources pulumi.StringMapInput
	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	Project pulumi.StringPtrInput
	// A reference to the region
	Region pulumi.StringPtrInput
	// Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the schedule. If not, users are responsible for creating jobs externally.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
	// Structure is documented below.
	ScheduleInfo PipelineScheduleInfoPtrInput
	// Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine service account will be used.
	SchedulerServiceAccountEmail pulumi.StringPtrInput
	// The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through pipelines.patch requests.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state
	// Possible values are: `STATE_UNSPECIFIED`, `STATE_RESUMING`, `STATE_ACTIVE`, `STATE_STOPPING`, `STATE_ARCHIVED`, `STATE_PAUSED`.
	//
	// ***
	State pulumi.StringPtrInput
	// The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the pipeline.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
	// Possible values are: `PIPELINE_TYPE_UNSPECIFIED`, `PIPELINE_TYPE_BATCH`, `PIPELINE_TYPE_STREAMING`.
	Type pulumi.StringPtrInput
	// Workload information for creating new jobs.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
	// Structure is documented below.
	Workload PipelineWorkloadPtrInput
}

func (PipelineState) ElementType() reflect.Type {
	return reflect.TypeOf((*pipelineState)(nil)).Elem()
}

type pipelineArgs struct {
	// The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores (_).
	DisplayName *string `pulumi:"displayName"`
	// "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID."
	// "- PROJECT_ID can contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see Identifying projects."
	// "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine regions."
	// "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
	Name *string `pulumi:"name"`
	// The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during pipeline creation.
	// An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
	PipelineSources map[string]string `pulumi:"pipelineSources"`
	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	Project *string `pulumi:"project"`
	// A reference to the region
	Region *string `pulumi:"region"`
	// Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the schedule. If not, users are responsible for creating jobs externally.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
	// Structure is documented below.
	ScheduleInfo *PipelineScheduleInfo `pulumi:"scheduleInfo"`
	// Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine service account will be used.
	SchedulerServiceAccountEmail *string `pulumi:"schedulerServiceAccountEmail"`
	// The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through pipelines.patch requests.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state
	// Possible values are: `STATE_UNSPECIFIED`, `STATE_RESUMING`, `STATE_ACTIVE`, `STATE_STOPPING`, `STATE_ARCHIVED`, `STATE_PAUSED`.
	//
	// ***
	State string `pulumi:"state"`
	// The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the pipeline.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
	// Possible values are: `PIPELINE_TYPE_UNSPECIFIED`, `PIPELINE_TYPE_BATCH`, `PIPELINE_TYPE_STREAMING`.
	Type string `pulumi:"type"`
	// Workload information for creating new jobs.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
	// Structure is documented below.
	Workload *PipelineWorkload `pulumi:"workload"`
}

// The set of arguments for constructing a Pipeline resource.
type PipelineArgs struct {
	// The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores (_).
	DisplayName pulumi.StringPtrInput
	// "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID."
	// "- PROJECT_ID can contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see Identifying projects."
	// "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine regions."
	// "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
	Name pulumi.StringPtrInput
	// The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during pipeline creation.
	// An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
	PipelineSources pulumi.StringMapInput
	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	Project pulumi.StringPtrInput
	// A reference to the region
	Region pulumi.StringPtrInput
	// Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the schedule. If not, users are responsible for creating jobs externally.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
	// Structure is documented below.
	ScheduleInfo PipelineScheduleInfoPtrInput
	// Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine service account will be used.
	SchedulerServiceAccountEmail pulumi.StringPtrInput
	// The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through pipelines.patch requests.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state
	// Possible values are: `STATE_UNSPECIFIED`, `STATE_RESUMING`, `STATE_ACTIVE`, `STATE_STOPPING`, `STATE_ARCHIVED`, `STATE_PAUSED`.
	//
	// ***
	State pulumi.StringInput
	// The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the pipeline.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
	// Possible values are: `PIPELINE_TYPE_UNSPECIFIED`, `PIPELINE_TYPE_BATCH`, `PIPELINE_TYPE_STREAMING`.
	Type pulumi.StringInput
	// Workload information for creating new jobs.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
	// Structure is documented below.
	Workload PipelineWorkloadPtrInput
}

func (PipelineArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*pipelineArgs)(nil)).Elem()
}

type PipelineInput interface {
	pulumi.Input

	ToPipelineOutput() PipelineOutput
	ToPipelineOutputWithContext(ctx context.Context) PipelineOutput
}

func (*Pipeline) ElementType() reflect.Type {
	return reflect.TypeOf((**Pipeline)(nil)).Elem()
}

func (i *Pipeline) ToPipelineOutput() PipelineOutput {
	return i.ToPipelineOutputWithContext(context.Background())
}

func (i *Pipeline) ToPipelineOutputWithContext(ctx context.Context) PipelineOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PipelineOutput)
}

// PipelineArrayInput is an input type that accepts PipelineArray and PipelineArrayOutput values.
// You can construct a concrete instance of `PipelineArrayInput` via:
//
//	PipelineArray{ PipelineArgs{...} }
type PipelineArrayInput interface {
	pulumi.Input

	ToPipelineArrayOutput() PipelineArrayOutput
	ToPipelineArrayOutputWithContext(context.Context) PipelineArrayOutput
}

type PipelineArray []PipelineInput

func (PipelineArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*Pipeline)(nil)).Elem()
}

func (i PipelineArray) ToPipelineArrayOutput() PipelineArrayOutput {
	return i.ToPipelineArrayOutputWithContext(context.Background())
}

func (i PipelineArray) ToPipelineArrayOutputWithContext(ctx context.Context) PipelineArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PipelineArrayOutput)
}

// PipelineMapInput is an input type that accepts PipelineMap and PipelineMapOutput values.
// You can construct a concrete instance of `PipelineMapInput` via:
//
//	PipelineMap{ "key": PipelineArgs{...} }
type PipelineMapInput interface {
	pulumi.Input

	ToPipelineMapOutput() PipelineMapOutput
	ToPipelineMapOutputWithContext(context.Context) PipelineMapOutput
}

type PipelineMap map[string]PipelineInput

func (PipelineMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*Pipeline)(nil)).Elem()
}

func (i PipelineMap) ToPipelineMapOutput() PipelineMapOutput {
	return i.ToPipelineMapOutputWithContext(context.Background())
}

func (i PipelineMap) ToPipelineMapOutputWithContext(ctx context.Context) PipelineMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PipelineMapOutput)
}

type PipelineOutput struct{ *pulumi.OutputState }

func (PipelineOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**Pipeline)(nil)).Elem()
}

func (o PipelineOutput) ToPipelineOutput() PipelineOutput {
	return o
}

func (o PipelineOutput) ToPipelineOutputWithContext(ctx context.Context) PipelineOutput {
	return o
}

// The timestamp when the pipeline was initially created. Set by the Data Pipelines service.
// A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
func (o PipelineOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v *Pipeline) pulumi.StringOutput { return v.CreateTime }).(pulumi.StringOutput)
}

// The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores (_).
func (o PipelineOutput) DisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Pipeline) pulumi.StringPtrOutput { return v.DisplayName }).(pulumi.StringPtrOutput)
}

// Number of jobs.
func (o PipelineOutput) JobCount() pulumi.IntOutput {
	return o.ApplyT(func(v *Pipeline) pulumi.IntOutput { return v.JobCount }).(pulumi.IntOutput)
}

// The timestamp when the pipeline was last modified. Set by the Data Pipelines service.
// A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
func (o PipelineOutput) LastUpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v *Pipeline) pulumi.StringOutput { return v.LastUpdateTime }).(pulumi.StringOutput)
}

// "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID."
// "- PROJECT_ID can contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see Identifying projects."
// "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine regions."
// "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
func (o PipelineOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *Pipeline) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

// The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during pipeline creation.
// An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
func (o PipelineOutput) PipelineSources() pulumi.StringMapOutput {
	return o.ApplyT(func(v *Pipeline) pulumi.StringMapOutput { return v.PipelineSources }).(pulumi.StringMapOutput)
}

// The ID of the project in which the resource belongs.
// If it is not provided, the provider project is used.
func (o PipelineOutput) Project() pulumi.StringOutput {
	return o.ApplyT(func(v *Pipeline) pulumi.StringOutput { return v.Project }).(pulumi.StringOutput)
}

// A reference to the region
func (o PipelineOutput) Region() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Pipeline) pulumi.StringPtrOutput { return v.Region }).(pulumi.StringPtrOutput)
}

// Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the schedule. If not, users are responsible for creating jobs externally.
// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
// Structure is documented below.
func (o PipelineOutput) ScheduleInfo() PipelineScheduleInfoPtrOutput {
	return o.ApplyT(func(v *Pipeline) PipelineScheduleInfoPtrOutput { return v.ScheduleInfo }).(PipelineScheduleInfoPtrOutput)
}

// Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine service account will be used.
func (o PipelineOutput) SchedulerServiceAccountEmail() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Pipeline) pulumi.StringPtrOutput { return v.SchedulerServiceAccountEmail }).(pulumi.StringPtrOutput)
}

// The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through pipelines.patch requests.
// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state
// Possible values are: `STATE_UNSPECIFIED`, `STATE_RESUMING`, `STATE_ACTIVE`, `STATE_STOPPING`, `STATE_ARCHIVED`, `STATE_PAUSED`.
//
// ***
func (o PipelineOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v *Pipeline) pulumi.StringOutput { return v.State }).(pulumi.StringOutput)
}

// The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the pipeline.
// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
// Possible values are: `PIPELINE_TYPE_UNSPECIFIED`, `PIPELINE_TYPE_BATCH`, `PIPELINE_TYPE_STREAMING`.
func (o PipelineOutput) Type() pulumi.StringOutput {
	return o.ApplyT(func(v *Pipeline) pulumi.StringOutput { return v.Type }).(pulumi.StringOutput)
}

// Workload information for creating new jobs.
// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
// Structure is documented below.
func (o PipelineOutput) Workload() PipelineWorkloadPtrOutput {
	return o.ApplyT(func(v *Pipeline) PipelineWorkloadPtrOutput { return v.Workload }).(PipelineWorkloadPtrOutput)
}

type PipelineArrayOutput struct{ *pulumi.OutputState }

func (PipelineArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*Pipeline)(nil)).Elem()
}

func (o PipelineArrayOutput) ToPipelineArrayOutput() PipelineArrayOutput {
	return o
}

func (o PipelineArrayOutput) ToPipelineArrayOutputWithContext(ctx context.Context) PipelineArrayOutput {
	return o
}

func (o PipelineArrayOutput) Index(i pulumi.IntInput) PipelineOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *Pipeline {
		return vs[0].([]*Pipeline)[vs[1].(int)]
	}).(PipelineOutput)
}

type PipelineMapOutput struct{ *pulumi.OutputState }

func (PipelineMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*Pipeline)(nil)).Elem()
}

func (o PipelineMapOutput) ToPipelineMapOutput() PipelineMapOutput {
	return o
}

func (o PipelineMapOutput) ToPipelineMapOutputWithContext(ctx context.Context) PipelineMapOutput {
	return o
}

func (o PipelineMapOutput) MapIndex(k pulumi.StringInput) PipelineOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *Pipeline {
		return vs[0].(map[string]*Pipeline)[vs[1].(string)]
	}).(PipelineOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*PipelineInput)(nil)).Elem(), &Pipeline{})
	pulumi.RegisterInputType(reflect.TypeOf((*PipelineArrayInput)(nil)).Elem(), PipelineArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*PipelineMapInput)(nil)).Elem(), PipelineMap{})
	pulumi.RegisterOutputType(PipelineOutput{})
	pulumi.RegisterOutputType(PipelineArrayOutput{})
	pulumi.RegisterOutputType(PipelineMapOutput{})
}
